# llm_client config is the setting applied in lm_client.py
llm_client_config:
    model_list:
        gpt:
            # - "gpt-3.5-turbo-1106"
            - "gpt-4-turbo-2024-04-09"
            # - "gpt-4o-2024-11-20"
            - "gpt-4o-mini-2024-07-18"
            # - "o1-2024-12-17"
            - "o1-mini-2024-09-12"
            - "o3-mini-2025-01-31"
            

        llama:
        gemini:
        grok:
        deepseek:

    credentials:
        openai_key: "your_key"
        firework_key: "fw_YOURKEY"
        gemini_key: "g_YOURKEY"
        deepseek_key: "ds_YOURKEY"
        xai_key: "x_YOURKEY"

    default_model: "gpt-4o-mini-2024-07-18"
    max_tokens: 500
    temperature: 1.0
    logprobs: False
    frequency_penalty: 0
    presence_penalty: 0

# task_config is the overall structure of our experiment reflected in tasks.py and evaluation.py
task_config:
    task_list:
        - "identification"
        - "classification"
        - "recommendation"
        - "generation"
        - "output_evaluation"
    data_path: './data'
    save_path: './output' # path to get exp results
    out_path: './eval_output' # path to get eval results
    budget_mode: False # set to True when want to limit llm yes response
    budget_num: 2
    critical: False # set to True when want more critical LLM





    # random_seed: 42
    # data_name: one_subject_negative_part_1
    # save_results: True
