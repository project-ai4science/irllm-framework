{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Code for IDR Indentification, Classification, and Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from tasks import TaskHandler\n",
    "from evaluation_v2 import Evaluator\n",
    "from utils import load_config\n",
    "\n",
    "\n",
    "# if you want to change model params, logprob, output paths, etc. go to config.yml\n",
    "config_path = './config.yml'\n",
    "CONFIG = load_config(config_path)\n",
    "task_config = CONFIG['task_config']\n",
    "\n",
    "# user decide which exp to run\n",
    "exp_tasks = [\"identification\", \"classification\", \"recommendation\", \"generation\", \"output_evaluation\"]\n",
    "current_task = exp_tasks[1]\n",
    "eval_type = None\n",
    "provider, model_name = \"gpt\", \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "# map the args to actual task\n",
    "if current_task == \"output_evaluation\":\n",
    "    eval_type = eval_type\n",
    "    evaluator = Evaluator(type=eval_type)\n",
    "else:\n",
    "    # task_handler = TaskHandler(provider=args.provider, model_name=args.model_name, lm_config_path=config_path, save_path=save_path, **task_config)\n",
    "    task_handler = TaskHandler(provider=provider, model_name=model_name, lm_config_path=config_path, **task_config)\n",
    "    task_func = task_handler[current_task]\n",
    "    task_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swiss Tournament Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1 ---\n",
      "Alice wins against Bob\n",
      "David wins against Charlie\n",
      "May wins against Eva\n",
      "\n",
      "Standings after Round 1\n",
      "Alice (Score: 1)\n",
      "David (Score: 1)\n",
      "May (Score: 1)\n",
      "Bob (Score: 0)\n",
      "Charlie (Score: 0)\n",
      "Eva (Score: 0)\n",
      "\n",
      "--- Round 2 ---\n",
      "David wins against Alice\n",
      "Bob wins against May\n",
      "Charlie wins against Eva\n",
      "\n",
      "Standings after Round 2\n",
      "David (Score: 2)\n",
      "Alice (Score: 1)\n",
      "Bob (Score: 1)\n",
      "Charlie (Score: 1)\n",
      "May (Score: 1)\n",
      "Eva (Score: 0)\n",
      "\n",
      "--- Round 3 ---\n",
      "Bob wins against David\n",
      "Alice wins against Charlie\n",
      "\n",
      "Standings after Round 3\n",
      "Alice (Score: 2)\n",
      "Bob (Score: 2)\n",
      "David (Score: 2)\n",
      "Charlie (Score: 1)\n",
      "May (Score: 1)\n",
      "Eva (Score: 0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.score = 0\n",
    "        self.opponents = []  # Keep track of player names this player has already faced\n",
    "        self.bye = False     # Flag to check if this player already received a bye\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name} (Score: {self.score})\"\n",
    "\n",
    "def swiss_pairings(players):\n",
    "    \"\"\"\n",
    "    Pair players based on current scores.\n",
    "    If the number of players is odd, a bye is given to the lowest-ranked\n",
    "    player who hasn't already received one.\n",
    "    \"\"\"\n",
    "    # Sort players first by score (highest first), then alphabetically\n",
    "    players_sorted = sorted(players, key=lambda x: (-x.score, x.name))\n",
    "    pairings = []\n",
    "    used = set()  # Keep track of players already paired this round\n",
    "\n",
    "    # Handle odd number of players: give a bye to one player\n",
    "    if len(players_sorted) % 2 == 1:\n",
    "        # choose the lowest-ranked player (last in the sorted list)\n",
    "        for player in reversed(players_sorted):\n",
    "            if not player.bye:\n",
    "                print(f\"{player.name} receives a bye this round.\")\n",
    "                player.score += 1   # Award one point for the bye\n",
    "                player.bye = True\n",
    "                used.add(player)\n",
    "                break\n",
    "\n",
    "    # Pair remaining players\n",
    "    # We loop through the sorted list and for each unpaired player, \n",
    "    # find the next unpaired opponent that they haven't faced before.\n",
    "    for i, player in enumerate(players_sorted):\n",
    "        if player in used:\n",
    "            continue\n",
    "        for j in range(i + 1, len(players_sorted)):\n",
    "            opponent = players_sorted[j]\n",
    "            if opponent in used:\n",
    "                continue\n",
    "            # Pair if the two players haven't met yet\n",
    "            if opponent.name not in player.opponents:\n",
    "                pairings.append((player, opponent))\n",
    "                used.add(player)\n",
    "                used.add(opponent)\n",
    "                break\n",
    "\n",
    "    return pairings\n",
    "\n",
    "def simulate_match(player1, player2):\n",
    "    \"\"\"\n",
    "    Simulate a match between two players by choosing a random winner.\n",
    "    Update their scores and record the matchup.\n",
    "    \"\"\"\n",
    "    winner = random.choice([player1, player2])\n",
    "    if winner == player1:\n",
    "        player1.score += 1\n",
    "        print(f\"{player1.name} wins against {player2.name}\")\n",
    "    else:\n",
    "        player2.score += 1\n",
    "        print(f\"{player2.name} wins against {player1.name}\")\n",
    "    # Record that these players have met\n",
    "    player1.opponents.append(player2.name)\n",
    "    player2.opponents.append(player1.name)\n",
    "\n",
    "def swiss_tournament(players, rounds=3):\n",
    "    \"\"\"\n",
    "    Run a Swiss tournament for a specified number of rounds.\n",
    "    Each round, pair players according to their scores and then simulate their matches.\n",
    "    After each round, print the current standings.\n",
    "    \"\"\"\n",
    "    for round_number in range(1, rounds + 1):\n",
    "        print(f\"\\n--- Round {round_number} ---\")\n",
    "        pairings = swiss_pairings(players)\n",
    "        # Simulate all the matches in this round\n",
    "        for p1, p2 in pairings:\n",
    "            simulate_match(p1, p2)\n",
    "        \n",
    "        # Print the standings after this round\n",
    "        standings = sorted(players, key=lambda x: (-x.score, x.name))\n",
    "        print(\"\\nStandings after Round\", round_number)\n",
    "        for player in standings:\n",
    "            print(player)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a list of players for the tournament\n",
    "    player_names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\", \"May\"]\n",
    "    players = [Player(name) for name in player_names]\n",
    "    \n",
    "    # Run the Swiss tournament for 3 rounds\n",
    "    swiss_tournament(players, rounds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verdict': 'Yes', 'score': '90'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = None\n",
    "text = \"Your verdict:Yes.\\nConfidence score:90.\\nhhl Reason:The response is correct.\"\n",
    "pattern = r\"Your verdict:\\s*(?P<verdict>Yes|No).?\\s*Confidence score:\\s*(?P<score>\\d+).?\"\n",
    "match = re.search(pattern, text, re.IGNORECASE)\n",
    "if match:\n",
    "    data = match.groupdict()\n",
    "\n",
    "if data:\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"No match found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file exp_1_llama-3.3-70b-instruct_critical.json...\n",
      "ECE for exp_1_llama-3.3-70b-instruct_critical.json: 0.0549\n",
      "\n",
      "Plot saved to ./eval_output/figures/exp_1_llama-3.3-70b-instruct_critical.png\n",
      "Reading file exp_3_1_gpt-4o-mini-2024-07-18.json...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/multi_disci_exp/.venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     72\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./eval_output/figures\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mcalculate_ece_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 26\u001b[0m, in \u001b[0;36mcalculate_ece_and_plot\u001b[0;34m(file_path, output_path, type)\u001b[0m\n\u001b[1;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverb_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     25\u001b[0m bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m bin_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madj_correct\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m bin_acc \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Downloads/multi_disci_exp/.venv/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:5936\u001b[0m, in \u001b[0;36mdigitize\u001b[0;34m(x, bins, right)\u001b[0m\n\u001b[1;32m   5934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m _nx\u001b[38;5;241m.\u001b[39msearchsorted(bins[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], x, side\u001b[38;5;241m=\u001b[39mside)\n\u001b[1;32m   5935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/multi_disci_exp/.venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:1471\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \n\u001b[1;32m   1470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/multi_disci_exp/.venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/multi_disci_exp/.venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:46\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m arr, \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mas_arrays(subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 46\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(result, to_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'list'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_ece_and_plot(file_path, output_path, type=None):\n",
    "    \"\"\"\n",
    "    Reads JSON files from the given file path, calculates ECE, and saves plots to the output path.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the directory containing JSON files.\n",
    "        output_path (str): Path to the directory where plots will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    files = os.listdir(file_path)\n",
    "    files = [f for f in files if f.endswith('.json') and (f.startswith('exp_1') or f.startswith('exp_2'))]\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"Reading file {f}...\")\n",
    "        # Read single file\n",
    "        df = pd.read_json(os.path.join(file_path, f))\n",
    "        output = df[\"verb_conf\"]\n",
    "        bins = np.linspace(0, 100, 10)\n",
    "        bin_indices = np.digitize(output, bins=bins)\n",
    "        df[\"adj_correct\"] = df.apply(lambda row: row[\"y_true\"] == row[\"y_pred\"], axis=1)\n",
    "\n",
    "        bin_acc = {}\n",
    "        for i, b in enumerate(bin_indices):\n",
    "            which_bin = 0.1 * np.average([b - 1, b])\n",
    "            if which_bin in bin_acc:\n",
    "                bin_acc[which_bin].append(df[\"adj_correct\"].iloc[i])\n",
    "            else:\n",
    "                bin_acc[which_bin] = [df[\"adj_correct\"].iloc[i]]\n",
    "\n",
    "        # Calculate ECE for each bin\n",
    "        ece = 0\n",
    "        for key in bin_acc:\n",
    "            if key > 0.05:\n",
    "                ece += len(bin_acc[key]) / len(df) * np.abs(np.average(bin_acc[key]) - key)\n",
    "\n",
    "        print(f\"ECE for {f}: {format(ece, '.4f')}\\n\")\n",
    "\n",
    "        # Prepare data for plotting\n",
    "        plt_data = sorted(bin_acc.items())\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.title(f\"ECE for {f}: {format(ece, '.4f')}\\n\", fontsize=25)\n",
    "        plt.plot(np.linspace(0, 1, 20), np.linspace(0, 1, 20), linestyle='dashed')\n",
    "        plt.scatter([d[0] for d in plt_data], [np.average(d[1]) for d in plt_data],\n",
    "                    s=[len(d[1]) / len(df) * 10000 for d in plt_data], alpha=0.5, color='red', marker='.')\n",
    "\n",
    "        plt.xlabel(\"Confidence Bin\", fontsize=20)\n",
    "        plt.ylabel(\"Accuracy\", fontsize=20)\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save the plot\n",
    "        if type:\n",
    "            output_file_name = f\"{os.path.splitext(f)[0]}_{type}.png\"\n",
    "        else:\n",
    "            output_file_name = f\"{os.path.splitext(f)[0]}.png\"\n",
    "        output_file = os.path.join(output_path, output_file_name)\n",
    "        plt.savefig(output_file)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved to {output_file}\")\n",
    "\n",
    "input_path = './output'\n",
    "output_path = './eval_output/figures'\n",
    "calculate_ece_and_plot(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 8971.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = {\n",
    "    \"col_1\": [1, 2, 3],\n",
    "    \"col_2\": [4, 5, 6],\n",
    "    \"col_3\": [2, 3, 4],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_size = df.shape[0]\n",
    "\n",
    "df = df[1:]\n",
    "\n",
    "for i, each in tqdm(df.iterrows(), total=df_size-1):\n",
    "    pass\n",
    "    # print(\"IN!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data_exp_1.json, Size: 1074\n",
      "File: data_exp_2_1.json, Size: 1074\n",
      "File: data_exp_2_2.json, Size: 1134\n",
      "File: data_exp_2_3.json, Size: 1074\n",
      "File: data_exp_3_1.json, Size: 154\n",
      "File: data_exp_3_2.json, Size: 111\n",
      "File: data_exp_4_1.json, Size: 182\n",
      "File: exp_1_claude-3.7-sonnet:thinking_critical.json, Size: 1075\n",
      "File: exp_1_claude-3.7-sonnet:thinking_critical_fewshot.json, Size: 1025\n",
      "File: exp_1_deepseek-chat_critical.json, Size: 1075\n",
      "File: exp_1_deepseek-chat_critical_fewshot.json, Size: 1025\n",
      "File: exp_1_deepseek-reasoner_critical.json, Size: 1025\n",
      "File: exp_1_deepseek-reasoner_critical_fewshot.json, Size: 1025\n",
      "File: exp_1_gemini-2.0-flash_critical.json, Size: 1075\n",
      "File: exp_1_gemini-2.0-flash_critical_fewshot.json, Size: 1075\n",
      "File: exp_1_gpt-4o-mini-2024-07-18_critical.json, Size: 1075\n",
      "File: exp_1_gpt-4o-mini-2024-07-18_critical_fewshot.json, Size: 1075\n",
      "File: exp_1_llama-3.1-70b-instruct_critical.json, Size: 1075\n",
      "File: exp_1_llama-3.1-70b-instruct_critical_fewshot.json, Size: 1075\n",
      "File: exp_1_llama-3.3-70b-instruct_critical.json, Size: 1075\n",
      "File: exp_1_llama-3.3-70b-instruct_critical_fewshot.json, Size: 1023\n",
      "File: exp_1_o1-mini-2024-09-12_critical.json, Size: 1075\n",
      "File: exp_1_o1-mini-2024-09-12_critical_fewshot.json, Size: 1025\n",
      "File: exp_1_o3-mini-2025-01-31_critical.json, Size: 1074\n",
      "File: exp_1_o3-mini-2025-01-31_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_1_claude-3.7-sonnet:thinking_critical.json, Size: 1075\n",
      "File: exp_2_1_claude-3.7-sonnet:thinking_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_1_deepseek-chat_critical.json, Size: 1075\n",
      "File: exp_2_1_deepseek-chat_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_1_deepseek-reasoner_critical.json, Size: 1025\n",
      "File: exp_2_1_deepseek-reasoner_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_1_gemini-2.0-flash_critical.json, Size: 1075\n",
      "File: exp_2_1_gemini-2.0-flash_critical_fewshot.json, Size: 1075\n",
      "File: exp_2_1_gpt-4o-mini-2024-07-18_critical.json, Size: 1075\n",
      "File: exp_2_1_gpt-4o-mini-2024-07-18_critical_fewshot.json, Size: 1075\n",
      "File: exp_2_1_llama-3.1-70b-instruct_critical.json, Size: 1073\n",
      "File: exp_2_1_llama-3.1-70b-instruct_critical_fewshot.json, Size: 1075\n",
      "File: exp_2_1_llama-3.3-70b-instruct_critical.json, Size: 1075\n",
      "File: exp_2_1_llama-3.3-70b-instruct_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_1_o1-mini-2024-09-12_critical.json, Size: 1075\n",
      "File: exp_2_1_o1-mini-2024-09-12_critical_fewshot.json, Size: 1020\n",
      "File: exp_2_1_o3-mini-2025-01-31_critical.json, Size: 1075\n",
      "File: exp_2_1_o3-mini-2025-01-31_critical_fewshot.json, Size: 1025\n",
      "File: exp_2_2_claude-3.7-sonnet:thinking_critical.json, Size: 548\n",
      "File: exp_2_2_claude-3.7-sonnet:thinking_critical_fewshot.json, Size: 252\n",
      "File: exp_2_2_deepseek-chat_critical.json, Size: 481\n",
      "File: exp_2_2_deepseek-chat_critical_fewshot.json, Size: 252\n",
      "File: exp_2_2_deepseek-reasoner_critical.json, Size: 252\n",
      "File: exp_2_2_deepseek-reasoner_critical_fewshot.json, Size: 252\n",
      "File: exp_2_2_gemini-2.0-flash_critical.json, Size: 1134\n",
      "File: exp_2_2_gemini-2.0-flash_critical_fewshot.json, Size: 1122\n",
      "File: exp_2_2_gpt-4o-mini-2024-07-18_critical.json, Size: 1134\n",
      "File: exp_2_2_gpt-4o-mini-2024-07-18_critical_fewshot.json, Size: 1041\n",
      "File: exp_2_2_llama-3.1-70b-instruct_critical.json, Size: 857\n",
      "File: exp_2_2_llama-3.1-70b-instruct_critical_fewshot.json, Size: 526\n",
      "File: exp_2_2_llama-3.3-70b-instruct_critical.json, Size: 1076\n",
      "File: exp_2_2_llama-3.3-70b-instruct_critical_fewshot.json, Size: 252\n",
      "File: exp_2_2_o1-mini-2024-09-12_critical.json, Size: 675\n",
      "File: exp_2_2_o1-mini-2024-09-12_critical_fewshot.json, Size: 252\n",
      "File: exp_2_2_o3-mini-2025-01-31_critical.json, Size: 536\n",
      "File: exp_2_2_o3-mini-2025-01-31_critical_fewshot.json, Size: 252\n",
      "File: exp_3_1_claude-3.7-sonnet:thinking_critical.json, Size: 46\n",
      "File: exp_3_1_deepseek-chat_critical.json, Size: 54\n",
      "File: exp_3_1_deepseek-reasoner_critical.json, Size: 54\n",
      "File: exp_3_1_gemini-2.0-flash_critical.json, Size: 73\n",
      "File: exp_3_1_gpt-4o-mini-2024-07-18_critical.json, Size: 64\n",
      "File: exp_3_1_llama-3.1-70b-instruct_critical.json, Size: 55\n",
      "File: exp_3_1_llama-3.3-70b-instruct_critical.json, Size: 52\n",
      "File: exp_3_1_o1-mini-2024-09-12_critical.json, Size: 54\n",
      "File: exp_3_1_o3-mini-2025-01-31_critical.json, Size: 54\n",
      "File: exp_3_2_claude-3.7-sonnet:thinking_critical.json, Size: 21\n",
      "File: exp_3_2_deepseek-chat_critical.json, Size: 27\n",
      "File: exp_3_2_deepseek-reasoner_critical.json, Size: 17\n",
      "File: exp_3_2_gemini-2.0-flash_critical.json, Size: 27\n",
      "File: exp_3_2_gpt-4o-mini-2024-07-18_critical.json, Size: 27\n",
      "File: exp_3_2_llama-3.1-70b-instruct_critical.json, Size: 27\n",
      "File: exp_3_2_llama-3.3-70b-instruct_critical.json, Size: 27\n",
      "File: exp_3_2_o1-mini-2024-09-12_critical.json, Size: 27\n",
      "File: exp_3_2_o3-mini-2025-01-31_critical.json, Size: 27\n"
     ]
    }
   ],
   "source": [
    "# check size of data files\n",
    "data_files = os.listdir(\"./data\")\n",
    "data_files = sorted([f for f in data_files if f.endswith('.json')])\n",
    "for f in data_files:\n",
    "    # get the length of the file\n",
    "    file_path = os.path.join(\"./data\", f)\n",
    "    df = pd.read_json(file_path)\n",
    "    df_size = df.shape[0]\n",
    "    print(f\"File: {f}, Size: {df_size}\")\n",
    "\n",
    "# check size of result files\n",
    "res_files = os.listdir(\"./output\")\n",
    "res_files = sorted([f for f in res_files if f.endswith('.json')])\n",
    "for f in res_files:\n",
    "    # get the length of the file\n",
    "    file_path = os.path.join(\"./output\", f)\n",
    "    df = pd.read_json(file_path)\n",
    "    df_size = df.shape[0]\n",
    "    print(f\"File: {f}, Size: {df_size}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
