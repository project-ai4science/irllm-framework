# llm_client config is the setting applied in lm_client.py
llm_client_config:
    model_list:
        gpt:
            # - "gpt-3.5-turbo-1106"
            # - "gpt-4-turbo-2024-04-09"
            # - "gpt-4o-2024-11-20"
            - "gpt-4o-mini-2024-07-18"
            # - "o1-2024-12-17"
            - "o1-mini-2024-09-12"
            - "o3-mini-2025-01-31"

        gemini:
            - "gemini-2.0-flash"
            - "gemini-2.5-pro-preview-03-25"
            - "gemini-1.5-pro"

        llama:
            - "llama-3.3-70b-instruct"
            - "llama-3.1-70b-instruct"

        claude:
            - "claude-3.7-sonnet:thinking"
            - "claude-3-7-sonnet-20250219"

        grok:
            - "grok-3-mini-beta"

        deepseek:
            - "deepseek-chat"
            - "deepseek-reasoner"

        qwen:
            - "qwen2.5-vl-32b-instruct:free"

    credentials:
        openai_key: "your_key"
        gemini_key: "your_key"
        deepseek_key: "sk-372ce22523804df3980593c80a46e761"
        openrouter_key: "your_key"
        claude_key: "your_key"
        # xai_key: "your_key"
        # firework_key: "your_key"

    default_model: "deepseek-chat"
    max_tokens: 500
    temperature: 1.0
    logprobs: True
    frequency_penalty: 0
    presence_penalty: 0

# task_config is the overall structure of our experiment reflected in tasks.py and evaluation.py
task_config:
    task_list:
        - "identification"
        - "classification"
        - "recommendation"
        - "generation"
        - "output_evaluation"
    data_path: "./data"
    save_path: "./output" # path to get exp results
    out_path: "./eval_output" # path to get eval results
    budget_mode: False # set to True when want to limit llm yes response
    budget_num: 2
    critical: True # set to True when want more critical LLM
    few_shot: False # set to True for few-shot learning
    few_shot_num: 5 # number of few-shot examples


    # random_seed: 42
    # data_name: one_subject_negative_part_1
    # save_results: True
