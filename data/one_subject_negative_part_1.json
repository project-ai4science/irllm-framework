[
  [
    {
      "paper_id": "2101.03214v1",
      "title": "Exploring the association between R&D expenditure and the job quality in\n  the European Union",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Investment in research and development is a key factor in increasing\ncountries' competitiveness. However, its impact can potentially be broader and\ninclude other socially relevant elements like job quality. In effect, the\nquantity of generated jobs is an incomplete indicator since it does not allow\nto conclude on the quality of the job generated. In this sense, this paper\nintends to explore the relevance of R&D investments for the job quality in the\nEuropean Union between 2009 and 2018. For this purpose, we investigate the\neffects of R&D expenditures made by the business sector, government, and higher\neducation sector on three dimensions of job quality. Three research methods are\nemployed, i.e. univariate linear analysis, multiple linear analysis, and\ncluster analysis. The findings only confirm the association between R&D\nexpenditure and the number of hours worked, such that the European Union\ncountries with the highest R&D expenses are those with the lowest average\nweekly working hours."
    },
    {
      "paper_id": "2101.03259v2",
      "title": "Ramadan and Infants Health Outcomes",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Previous studies show that prenatal shocks to embryos could have adverse\nimpacts on health endowment at birth. Using the universe of birth data and a\ndifference-in-difference-in-difference strategy, I find that exposure to\nRamadan during prenatal development has negative birth outcomes. Exposure to a\nfull month of fasting is associated with 96 grams lower birth-weight. These\nresults are robust across specifications and do not appear to be driven by\nmothers selective fertility."
    }
  ],
  [
    {
      "paper_id": "2211.02854v3",
      "title": "Rate-Distortion Optimized Post-Training Quantization for Learned Image\n  Compression",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Quantizing a floating-point neural network to its fixed-point representation\nis crucial for Learned Image Compression (LIC) because it improves decoding\nconsistency for interoperability and reduces space-time complexity for\nimplementation. Existing solutions often have to retrain the network for model\nquantization, which is time-consuming and impractical to some extent. This work\nsuggests using Post-Training Quantization (PTQ) to process pretrained,\noff-the-shelf LIC models. We theoretically prove that minimizing\nquantization-induced mean square error (MSE) of model parameters (e.g., weight,\nbias, and activation) in PTQ is sub-optimal for compression tasks and thus\ndevelop a novel Rate-Distortion (R-D) Optimized PTQ (RDO-PTQ) to best retain\nthe compression performance. Given a LIC model, RDO-PTQ layer-wisely determines\nthe quantization parameters to transform the original floating-point parameters\nin 32-bit precision (FP32) to fixed-point ones at 8-bit precision (INT8), for\nwhich a tiny calibration image set is compressed in optimization to minimize\nR-D loss. Experiments reveal the outstanding efficiency of the proposed method\non different LICs, showing the closest coding performance to their\nfloating-point counterparts. Our method is a lightweight and plug-and-play\napproach without retraining model parameters but just adjusting quantization\nparameters, which is attractive to practitioners. Such an RDO-PTQ is a\ntask-oriented PTQ scheme, which is then extended to quantize popular\nsuper-resolution and image classification models with negligible performance\nloss, further evidencing the generalization of our methodology. Related\nmaterials will be released at https://njuvision.github.io/RDO-PTQ."
    },
    {
      "paper_id": "2211.04238v1",
      "title": "HDRfeat: A Feature-Rich Network for High Dynamic Range Image\n  Reconstruction",
      "subject": [
        "eess.IV"
      ],
      "abstract": "A major challenge for high dynamic range (HDR) image reconstruction from\nmulti-exposed low dynamic range (LDR) images, especially with dynamic scenes,\nis the extraction and merging of relevant contextual features in order to\nsuppress any ghosting and blurring artifacts from moving objects. To tackle\nthis, in this work we propose a novel network for HDR reconstruction with deep\nand rich feature extraction layers, including residual attention blocks with\nsequential channel and spatial attention. For the compression of the\nrich-features to the HDR domain, a residual feature distillation block (RFDB)\nbased architecture is adopted. In contrast to earlier deep-learning methods for\nHDR, the above contributions shift focus from merging/compression to feature\nextraction, the added value of which we demonstrate with ablation experiments.\nWe present qualitative and quantitative comparisons on a public benchmark\ndataset, showing that our proposed method outperforms the state-of-the-art."
    }
  ],
  [
    {
      "paper_id": "2408.07227v1",
      "title": "Stablecoin Runs and Disclosure Policy in the Presence of Large Sales",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "Stablecoins have historically depegged due from par to large sales, possibly\nof speculative nature, or poor reserve asset quality. Using a global game which\naddresses both concerns, we show that the selling pressure on stablecoin\nholders increases in the presence of a large sale. While precise public\nknowledge reduces (increases) the probability of a run when fundamentals are\nstrong (weak), interestingly, more precise private signals increase (reduce)\nthe probability of a run when fundamentals are strong (weak), potentially\nexplaining the stability of opaque stablecoins. The total run probability can\nbe decomposed into components representing risks from large sales and poor\ncollateral. By analyzing how these risk components vary with respect to\ninformation uncertainty and fundamentals, we can split the fundamental space\ninto regions based on the type of risk a stablecoin issuer is more prone to. We\nsuggest testable implications and connect our model's implications to\nreal-world applications, including depegging events and the no-questions-asked\nproperty of money."
    },
    {
      "paper_id": "2408.08866v1",
      "title": "High-Frequency Options Trading | With Portfolio Optimization",
      "subject": [
        "q-fin.TR",
        "q-fin.CP"
      ],
      "abstract": "This paper explores the effectiveness of high-frequency options trading\nstrategies enhanced by advanced portfolio optimization techniques,\ninvestigating their ability to consistently generate positive returns compared\nto traditional long or short positions on options. Utilizing SPY options data\nrecorded in five-minute intervals over a one-month period, we calculate key\nmetrics such as Option Greeks and implied volatility, applying the Binomial\nTree model for American options pricing and the Newton-Raphson algorithm for\nimplied volatility calculation. Investment universes are constructed based on\ncriteria like implied volatility and Greeks, followed by the application of\nvarious portfolio optimization models, including Standard Mean-Variance and\nRobust Methods. Our research finds that while basic long-short strategies\ncentered on implied volatility and Greeks generally underperform, more\nsophisticated strategies incorporating advanced Greeks, such as Vega and Rho,\nalong with dynamic portfolio optimization, show potential in effectively\nnavigating the complexities of the options market. The study highlights the\nimportance of adaptability and responsiveness in dynamic portfolio strategies\nwithin the high-frequency trading environment, particularly under volatile\nmarket conditions. Future research could refine strategy parameters and explore\nless frequently traded options, offering new insights into high-frequency\noptions trading and portfolio management."
    }
  ],
  [
    {
      "paper_id": "2405.17656v1",
      "title": "Alignment is Key for Applying Diffusion Models to Retrosynthesis",
      "subject": [
        "q-bio.QM"
      ],
      "abstract": "Retrosynthesis, the task of identifying precursors for a given molecule, can\nbe naturally framed as a conditional graph generation task. Diffusion models\nare a particularly promising modelling approach, enabling post-hoc conditioning\nand trading off quality for speed during generation. We show mathematically\nthat permutation equivariant denoisers severely limit the expressiveness of\ngraph diffusion models and thus their adaptation to retrosynthesis. To address\nthis limitation, we relax the equivariance requirement such that it only\napplies to aligned permutations of the conditioning and the generated graphs\nobtained through atom mapping. Our new denoiser achieves the highest top-$1$\naccuracy ($54.7$\\%) across template-free and template-based methods on\nUSPTO-50k. We also demonstrate the ability for flexible post-training\nconditioning and good sample quality with small diffusion step counts,\nhighlighting the potential for interactive applications and additional controls\nfor multi-step planning."
    },
    {
      "paper_id": "2405.18051v3",
      "title": "Predicting Progression Events in Multiple Myeloma from Routine Blood\n  Work",
      "subject": [
        "q-bio.QM"
      ],
      "abstract": "The ability to accurately predict disease progression is paramount for\noptimizing multiple myeloma patient care. This study introduces a hybrid neural\nnetwork architecture, combining Long Short-Term Memory networks with a\nConditional Restricted Boltzmann Machine, to predict future blood work of\naffected patients from a series of historical laboratory results. We\ndemonstrate that our model can replicate the statistical moments of the time\nseries ($0.95~\\pm~0.01~\\geq~R^2~\\geq~0.83~\\pm~0.03$) and forecast future blood\nwork features with high correlation to actual patient data\n($0.92\\pm0.02~\\geq~r~\\geq~0.52~\\pm~0.09$). Subsequently, a second Long\nShort-Term Memory network is employed to detect and annotate disease\nprogression events within the forecasted blood work time series. We show that\nthese annotations enable the prediction of progression events with significant\nreliability (AUROC$~=~0.88~\\pm~0.01$), up to 12 months in advance\n(AUROC($t+12~$mos)$~=0.65~\\pm~0.01$). Our system is designed in a modular\nfashion, featuring separate entities for forecasting and progression event\nannotation. This structure not only enhances interpretability but also\nfacilitates the integration of additional modules to perform subsequent\noperations on the generated outputs. Our approach utilizes a minimal set of\nroutine blood work measurements, which avoids the need for expensive or\nresource-intensive tests and ensures accessibility of the system in clinical\nroutine. This capability allows for individualized risk assessment and making\ninformed treatment decisions tailored to a patient's unique disease kinetics.\nThe represented approach contributes to the development of a scalable and\ncost-effective virtual human twin system for optimized healthcare resource\nutilization and improved patient outcomes in multiple myeloma care."
    }
  ],
  [
    {
      "paper_id": "1701.03139v2",
      "title": "Bounding, an accessible method for estimating principal causal effects,\n  examined and explained",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Estimating treatment effects for subgroups defined by post-treatment behavior\n(i.e., estimating causal effects in a principal stratification framework) can\nbe technically challenging and heavily reliant on strong assumptions. We\ninvestigate an alternative path: using bounds to identify ranges of possible\neffects that are consistent with the data. This simple approach relies on fewer\nassumptions and yet can result in policy-relevant findings. As we show,\ncovariates can be used to substantially tighten bounds in a straightforward\nmanner. Via simulation, we demonstrate which types of covariates are maximally\nbeneficial. We conclude with an analysis of a multi-site experimental study of\nEarly College High Schools. When examining the program's impact on students\ncompleting the ninth grade \"on-track\" for college, we find little impact for\nECHS students who would otherwise attend a high quality high school, but\nsubstantial effects for those who would not. This suggests potential benefit in\nexpanding these programs in areas primarily served by lower quality schools."
    },
    {
      "paper_id": "1701.03569v1",
      "title": "Bivariate Discrete Generalized Exponential Distribution",
      "subject": [
        "stat.AP"
      ],
      "abstract": "In this paper we develop a bivariate discrete generalized exponential\ndistribution, whose marginals are discrete generalized exponential distribution\nas proposed by Nekoukhou, Alamatsaz and Bidram (\"Discrete generalized\nexponential distribution of a second type\", Statistics, 47, 876 - 887, 2013).\nIt is observed that the proposed bivariate distribution is a very flexible\ndistribution and the bivariate geometric distribution can be obtained as a\nspecial case of this distribution. The proposed distribution can be seen as a\nnatural discrete analogue of the bivariate generalized exponential distribution\nproposed by Kundu and Gupta (\"Bivariate generalized exponential distribution\",\nJournal of Multivariate Analysis, 100, 581 - 593, 2009). We study different\nproperties of this distribution and explore its dependence structures. We\npropose a new EM algorithm to compute the maximum likelihood estimators of the\nunknown parameters which can be implemented very efficiently, and discuss some\ninferential issues also. The analysis of one data set has been performed to\nshow the effectiveness of the proposed model. Finally we propose some open\nproblems and conclude the paper."
    }
  ],
  [
    {
      "paper_id": "2412.19555v1",
      "title": "Asymptotic Properties of the Maximum Likelihood Estimator for\n  Markov-switching Observation-driven Models",
      "subject": [
        "econ.EM"
      ],
      "abstract": "A Markov-switching observation-driven model is a stochastic process\n$((S_t,Y_t))_{t \\in \\mathbb{Z}}$ where (i) $(S_t)_{t \\in \\mathbb{Z}}$ is an\nunobserved Markov process taking values in a finite set and (ii) $(Y_t)_{t \\in\n\\mathbb{Z}}$ is an observed process such that the conditional distribution of\n$Y_t$ given all past $Y$'s and the current and all past $S$'s depends only on\nall past $Y$'s and $S_t$. In this paper, we prove the consistency and\nasymptotic normality of the maximum likelihood estimator for such model. As a\nspecial case hereof, we give conditions under which the maximum likelihood\nestimator for the widely applied Markov-switching generalised autoregressive\nconditional heteroscedasticity model introduced by Haas et al. (2004b) is\nconsistent and asymptotic normal."
    },
    {
      "paper_id": "2412.21181v1",
      "title": "Causal Hangover Effects",
      "subject": [
        "econ.EM"
      ],
      "abstract": "It's not unreasonable to think that in-game sporting performance can be\naffected partly by what takes place off the court. We can't observe what\nhappens between games directly. Instead, we proxy for the possibility of\nathletes partying by looking at play following games in party cities. We are\ninterested to see if teams exhibit a decline in performance the day following a\ngame in a city with active nightlife; we call this a \"hangover effect\". Part of\nthe question is determining a reasonable way to measure levels of nightlife,\nand correspondingly which cities are notorious for it; we colloquially refer to\nsuch cities as \"party cities\". To carry out this study, we exploit data on\nbookmaker spreads: the expected score differential between two teams after\nconditioning on observable performance in past games and expectations about the\nupcoming game. We expect a team to meet the spread half the time, since this is\none of the easiest ways for bookmakers to guarantee a profit. We construct a\nmodel which attempts to estimate the causal effect of visiting a \"party city\"\non subsequent day performance as measured by the odds of beating the spread. In\nparticular, we only consider the hangover effect on games played back-to-back\nwithin 24 hours of each other. To the extent that odds of beating the spread\nagainst next day opponent is uncorrelated with playing in a party city the day\nbefore, which should be the case under an efficient betting market, we have\nidentification in our variable of interest. We find that visiting a city with\nactive nightlife the day prior to a game does have a statistically significant\nnegative effect on a team's likelihood of meeting bookmakers' expectations for\nboth NBA and MLB."
    }
  ],
  [
    {
      "paper_id": "1412.0459v2",
      "title": "On Bayesian based adaptive confidence sets for linear functionals",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We consider the problem of constructing Bayesian based confidence sets for\nlinear functionals in the inverse Gaussian white noise model. We work with a\nscale of Gaussian priors indexed by a regularity hyper-parameter and apply the\ndata-driven (slightly modified) marginal likelihood empirical Bayes method for\nthe choice of this hyper-parameter. We show by theory and simulations that the\ncredible sets constructed by this method have sub-optimal behaviour in general.\nHowever, by assuming \"self-similarity\" the credible sets have rate-adaptive\nsize and optimal coverage. As an application of these results we construct\n$L_{\\infty}$-credible bands for the true functional parameter with adaptive\nsize and optimal coverage under self-similarity constraint."
    },
    {
      "paper_id": "1412.0705v4",
      "title": "Exponentaited generalized Weibull Gompertz distribution",
      "subject": [
        "stat.TH"
      ],
      "abstract": "This paper introduces studies on exponentaited generalized Weibull Gompertz\ndistribution EGWGD which generalizes a lot of distributions. Several properties\nof the EGWGD such as reversed (hazard) function, moments, maximum likelihood\nestimation, mean residual (past) lifetime, MTTF, MTTR, MTBF, maintainability,\navailability and order statistics are studied in this paper. A real data set is\nanalyzed and it is observed that the present distribution can provide a better\nfit than some other very well known distributions"
    }
  ],
  [
    {
      "paper_id": "1206.2212v3",
      "title": "A simple method for finite range decomposition of quadratic forms and\n  Gaussian fields",
      "subject": [
        "math.PR",
        "math.AP",
        "math.MP"
      ],
      "abstract": "We present a simple method to decompose the Green forms corresponding to a\nlarge class of interesting symmetric Dirichlet forms into integrals over\nsymmetric positive semi-definite and finite range (properly supported) forms\nthat are smoother than the original Green form. This result gives rise to\nmultiscale decompositions of the associated Gaussian free fields into sums of\nindependent smoother Gaussian fields with spatially localized correlations. Our\nmethod makes use of the finite propagation speed of the wave equation and\nChebyshev polynomials. It improves several existing results and also gives\nsimpler proofs."
    },
    {
      "paper_id": "1206.2251v2",
      "title": "A Necessary and Sufficient Condition for Edge Universality of Wigner\n  matrices",
      "subject": [
        "math.PR",
        "math.MP"
      ],
      "abstract": "In this paper, we prove a necessary and sufficient condition for Tracy-Widom\nlaw of Wigner matrices. Consider $N \\times N$ symmetric Wigner matrices $H$\nwith $H_{ij} = N^{-1/2} x_{ij}$, whose upper right entries $x_{ij}$ $(1\\le i<\nj\\le N)$ are $i.i.d.$ random variables with distribution $\\mu$ and diagonal\nentries $x_{ii}$ $(1\\le i\\le N)$ are $i.i.d.$ random variables with\ndistribution $\\wt \\mu$. The means of $\\mu$ and $\\wt \\mu$ are zero, the variance\nof $\\mu$ is 1, and the variance of $\\wt \\mu $ is finite. We prove that\nTracy-Widom law holds if and only if $\\lim_{s\\to \\infty}s^4\\p(|x_{12}| \\ge\ns)=0$. The same criterion holds for Hermitian Wigner matrices."
    }
  ],
  [
    {
      "paper_id": "2105.08626v1",
      "title": "Light Gradient Boosting Machine as a Regression Method for Quantitative\n  Structure-Activity Relationships",
      "subject": [
        "q-bio.BM"
      ],
      "abstract": "In the pharmaceutical industry, where it is common to generate many QSAR\nmodels with large numbers of molecules and descriptors, the best QSAR methods\nare those that can generate the most accurate predictions but that are also\ninsensitive to hyperparameters and are computationally efficient. Here we\ncompare Light Gradient Boosting Machine (LightGBM) to random forest,\nsingle-task deep neural nets, and Extreme Gradient Boosting (XGBoost) on 30\nin-house data sets. While any boosting algorithm has many adjustable\nhyperparameters, we can define a set of standard hyperparameters at which\nLightGBM makes predictions about as accurate as single-task deep neural nets,\nbut is a factor of 1000-fold faster than random forest and ~4-fold faster than\nXGBoost in terms of total computational time for the largest models. Another\nvery useful feature of LightGBM is that it includes a native method for\nestimating prediction intervals."
    },
    {
      "paper_id": "2105.08835v2",
      "title": "Conformational variability of loops in the SARS-CoV-2 spike protein",
      "subject": [
        "q-bio.BM"
      ],
      "abstract": "The SARS-CoV-2 spike (S) protein facilitates viral infection, and has been\nthe focus of many structure determination efforts. Its flexible loop regions\nare known to be involved in protein binding and may adopt multiple\nconformations. This paper identifies the S protein loops and studies their\nconformational variability based on the available Protein Data Bank (PDB)\nstructures. While most loops had essentially one stable conformation, 17 of 44\nloop regions were observed to be structurally variable with multiple\nsubstantively distinct conformations based on a cluster analysis. Loop modeling\nmethods were then applied to the S protein loop targets, and the prediction\naccuracies discussed in relation to the characteristics of the conformational\nclusters identified. Loops with multiple conformations were found to be\nchallenging to model based on a single structural template."
    }
  ],
  [
    {
      "paper_id": "1603.03593v1",
      "title": "Fast Detection of Block Boundaries in Block Wise Constant Matrices: An\n  Application to HiC data",
      "subject": [
        "stat.AP"
      ],
      "abstract": "We propose a novel approach for estimating the location of block boundaries\n(change-points) in a random matrix consisting of a block wise constant matrix\nobserved in white noise. Our method consists in rephrasing this task as a\nvariable selection issue. We use a penalized least-squares criterion with an\n$\\ell_1$-type penalty for dealing with this issue. We first provide some\ntheoretical results ensuring the consistency of our change-point estimators.\nThen, we explain how to implement our method in a very efficient way. Finally,\nwe provide some empirical evidence to support our claims and apply our approach\nto HiC data which are used in molecular biology for better understanding the\ninfluence of the chromosomal conformation on the cells functioning."
    },
    {
      "paper_id": "1603.04189v2",
      "title": "A Change-Point Model for Detecting Heterogeneity in Ordered Survival\n  Responses",
      "subject": [
        "stat.AP"
      ],
      "abstract": "In this article we suggest a new statistical approach considering survival\nheterogeneity as a breakpoint model in an ordered sequence of time to event\nvariables. The survival responses need to be ordered according to a numerical\ncovariate. Our esti- mation method will aim at detecting heterogeneity that\ncould arise through the or- dering covariate. We formally introduce our model\nas a constrained Hidden Markov Model (HMM) where the hidden states are the\nunknown segmentation (breakpoint locations) and the observed states are the\nsurvival responses. We derive an efficient Expectation-Maximization (EM)\nframework for maximizing the likelihood of this model for a wide range of\nbaseline hazard forms (parametrics or nonparametric). The posterior\ndistribution of the breakpoints is also derived and the selection of the number\nof segments using penalized likelihood criterion is discussed. The performance\nof our survival breakpoint model is finally illustrated on a diabetes dataset\nwhere the observed survival times are ordered according to the calendar time of\ndisease onset."
    }
  ],
  [
    {
      "paper_id": "2407.05777v1",
      "title": "Probabilistic Shoenfield Machines",
      "subject": [
        "cs.SC"
      ],
      "abstract": "This article provides the theoretical framework of Probabilistic Shoenfield\nMachines (PSMs), an extension of the classical Shoenfield Machine that models\nrandomness in the computation process. PSMs are brought in contexts where\ndeterministic computation is insufficient, such as randomized algorithms. By\nallowing transitions to multiple possible states with certain probabilities,\nPSMs can solve problems and make decisions based on probabilistic outcomes,\nhence expanding the variety of possible computations. We provide an overview of\nPSMs, detailing their formal definitions as well as the computation mechanism\nand their equivalence with Non-deterministic Shoenfield Machines (NSM)."
    },
    {
      "paper_id": "2407.15721v2",
      "title": "Equality of morphic sequences",
      "subject": [
        "cs.SC"
      ],
      "abstract": "Morphic sequences form a natural class of infinite sequences, typically\ndefined as the coding of a fixed point of a morphism. Different morphisms and\ncodings may yield the same morphic sequence. This paper investigates how to\nprove that two such representations of a morphic sequence by morphisms\nrepresent the same sequence. In particular, we focus on the smallest\nrepresentations of the subsequences of the binary Fibonacci sequence obtained\nby only taking the even or odd elements. The proofs we give are induction\nproofs of several properties simultaneously, and are typically found fully\nautomatically by a tool that we developed."
    }
  ],
  [
    {
      "paper_id": "2108.10449v1",
      "title": "Differential Music: Automated Music Generation Using LSTM Networks with\n  Representation Based on Melodic and Harmonic Intervals",
      "subject": [
        "eess.AS"
      ],
      "abstract": "This paper presents a generative AI model for automated music composition\nwith LSTM networks that takes a novel approach at encoding musical information\nwhich is based on movement in music rather than absolute pitch. Melodies are\nencoded as a series of intervals rather than a series of pitches, and chords\nare encoded as the set of intervals that each chord note makes with the melody\nat each timestep. Experimental results show promise as they sound musical and\ntonal. There are also weaknesses to this method, mainly excessive modulations\nin the compositions, but that is expected from the nature of the encoding. This\nissue is discussed later in the paper and is a potential topic for future work."
    },
    {
      "paper_id": "2108.10714v1",
      "title": "Curricular SincNet: Towards Robust Deep Speaker Recognition by\n  Emphasizing Hard Samples in Latent Space",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Deep learning models have become an increasingly preferred option for\nbiometric recognition systems, such as speaker recognition. SincNet, a deep\nneural network architecture, gained popularity in speaker recognition tasks due\nto its parameterized sinc functions that allow it to work directly on the\nspeech signal. The original SincNet architecture uses the softmax loss, which\nmay not be the most suitable choice for recognition-based tasks. Such loss\nfunctions do not impose inter-class margins nor differentiate between easy and\nhard training samples. Curriculum learning, particularly those leveraging\nangular margin-based losses, has proven very successful in other biometric\napplications such as face recognition. The advantage of such a curriculum\nlearning-based techniques is that it will impose inter-class margins as well as\ntaking to account easy and hard samples. In this paper, we propose Curricular\nSincNet (CL-SincNet), an improved SincNet model where we use a curricular loss\nfunction to train the SincNet architecture. The proposed model is evaluated on\nmultiple datasets using intra-dataset and inter-dataset evaluation protocols.\nIn both settings, the model performs competitively with other previously\npublished work. In the case of inter-dataset testing, it achieves the best\noverall results with a reduction of 4\\% error rate compare to SincNet and other\npublished work."
    }
  ],
  [
    {
      "paper_id": "1608.04541v1",
      "title": "Influence of gene copy number on self-regulated gene expression",
      "subject": [
        "q-bio.MN"
      ],
      "abstract": "Using an analytically solvable stochastic model, we study the properties of a\nsimple genetic circuit consisting of multiple copies of an self-regulating\ngene. We analyse how the variation in gene copy number and the mutations\nchanging the auto-regulation strength affect the steady-state distribution of\nprotein concentration.\n  We predict that one-reporter assay, an experimental method where the\nextrinsic noise level is inferred from the comparison of expression variance of\na single and duplicated reporter gene, may give an incorrect estimation of the\nextrinsic noise contribution when applied to self-regulating genes.\n  We also show that an imperfect duplication of an auto-activated gene,\nchanging the regulation strength of one of the copies, may lead to a hybrid,\nbinary+graded response of these genes to external signal.\n  The analysis of relative changes in mean gene expression before and after\nduplication suggests that evolutionary accumulation of gene duplications may\nnon-trivially depend on the inherent noisiness of a given gene, quantified by\nmaximal mean frequency of bursts.\n  Moreover, we find that the dependence of gene expression noise on gene copy\nnumber and auto-regulation strength may qualitatively differ, e.g. in\nmonotonicity, depending on whether the noise is measured by Fano factor or\ncoefficient of variation. Thus, experimentally-based hypotheses linking gene\nexpression noise and evolutionary optimisation may be ambiguous as they are\ndependent on the particular function chosen to quantify noise."
    },
    {
      "paper_id": "1608.08007v3",
      "title": "Ultrasensitivity on signaling cascades revisited: Linking local and\n  global ultrasensitivity estimations",
      "subject": [
        "q-bio.MN"
      ],
      "abstract": "Ultrasensitive response motifs, which are capable of converting graded\nstimulus in binary responses, are very well-conserved in signal transduction\nnetworks. Although it has been shown that a cascade arrangement of multiple\nultrasensitive modules can produce an enhancement of the system's\nultrasensitivity, how the combination of layers affects the cascade's\nultrasensitivity remains an open question for the general case. Here we\nintroduced a methodology that allowed us to determine the presence of\nsequestration effects and to quantify the relative contribution of each module\nto the overall cascade's ultrasensitivity. The proposed analysis framework\nprovides a natural link between global and local ultrasensitivity descriptors\nand is particularly well-suited to characterize and better understand\nmathematical models used to study real biological systems. As a case study we\nconsidered three mathematical models introduced by O'Shaughnessy et al. to\nstudy a tunable synthetic MAPK cascade, and showed how our methodology might\nhelp modelers to better understand modeling alternatives."
    }
  ],
  [
    {
      "paper_id": "2407.17172v1",
      "title": "Speech Editing -- a Summary",
      "subject": [
        "eess.AS"
      ],
      "abstract": "With the rise of video production and social media, speech editing has become\ncrucial for creators to address issues like mispronunciations, missing words,\nor stuttering in audio recordings. This paper explores text-based speech\nediting methods that modify audio via text transcripts without manual waveform\nediting. These approaches ensure edited audio is indistinguishable from the\noriginal by altering the mel-spectrogram. Recent advancements, such as\ncontext-aware prosody correction and advanced attention mechanisms, have\nimproved speech editing quality. This paper reviews state-of-the-art methods,\ncompares key metrics, and examines widely used datasets. The aim is to\nhighlight ongoing issues and inspire further research and innovation in speech\nediting."
    },
    {
      "paper_id": "2407.17416v1",
      "title": "Explaining Spectrograms in Machine Learning: A Study on Neural Networks\n  for Speech Classification",
      "subject": [
        "eess.AS"
      ],
      "abstract": "This study investigates discriminative patterns learned by neural networks\nfor accurate speech classification, with a specific focus on vowel\nclassification tasks. By examining the activations and features of neural\nnetworks for vowel classification, we gain insights into what the networks\n\"see\" in spectrograms. Through the use of class activation mapping, we identify\nthe frequencies that contribute to vowel classification and compare these\nfindings with linguistic knowledge. Experiments on a American English dataset\nof vowels showcases the explainability of neural networks and provides valuable\ninsights into the causes of misclassifications and their characteristics when\ndifferentiating them from unvoiced speech. This study not only enhances our\nunderstanding of the underlying acoustic cues in vowel classification but also\noffers opportunities for improving speech recognition by bridging the gap\nbetween abstract representations in neural networks and established linguistic\nknowledge"
    }
  ],
  [
    {
      "paper_id": "1611.09824v1",
      "title": "Interspecific allometric scaling of unicellular organisms as an\n  evolutionary process of food chain creation",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "Metabolism of living organisms is a foundation of life. The metabolic rate\n(energy production per unit time) increases slower than organisms' mass. When\nthis phenomenon is considered across different species, it is called\ninterspecific allometric scaling, whose causes are unknown. We argue that the\ncause of interspecific allometric scaling is the total effect of physiological\nand adaptation mechanisms inherent to organisms composing a food chain.\nTogether, the workings of these mechanisms are united by a primary goal of any\nliving creature - its successful reproduction. This primary necessity of each\norganism and of the entire food chain is that common denominator, to which all\norganisms adjust their metabolic rates. In this article, we consider\nunicellular organisms, while the second paper studies multicellular organisms\nand the entire concept in more detail. Here, using the proposed concepts and\nexperimentally verified growth models of five different unicellular organisms,\nwe obtain close to experimental findings values of allometric exponents of\n0.757 for the end of growth and 0.853 for the beginning of growth. These\nresults comply with experimental observations and prove our theory that the\nrequirement of successful reproduction within the food chain is an important\nfactor shaping interspecific allometric scaling."
    },
    {
      "paper_id": "1612.00036v1",
      "title": "A quantitative definition of organismality and its application to lichen",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "The organism is a fundamental concept in biology. However there is no\nuniversally accepted, formal, and yet broadly applicable definition of what an\norganism is. Here we introduce a candidate definition. We adopt the view that\nthe \"organism\" is a functional concept, used by scientists to address\nparticular questions concerning the future state of a biological system, rather\nthan something wholly defined by that system. In this approach organisms are a\ncoarse-graining of a fine-grained dynamical model of a biological system.\nCrucially, the coarse-graining of the system into organisms is chosen so that\ntheir dynamics can be used by scientists to make accurate predictions of those\nfeatures of the biological system that interests them, and do so with minimal\ncomputational burden. To illustrate our framework we apply it to a dynamic\nmodel of lichen symbiosis---a system where either the lichen or its constituent\nfungi and algae could reasonably be considered \"organisms.\" We find that the\nbest choice for what organisms are in this scenario are complex mixtures of\nmany entities that do not resemble standard notions of organisms. When we\nrestrict our allowed coarse-grainings to more traditional types of organisms,\nwe find that ecological conditions, such as niche competition and predation\npressure, play a significant role in determining the best choice for organisms."
    }
  ],
  [
    {
      "paper_id": "2305.01980v1",
      "title": "Diverse and Vivid Sound Generation from Text Descriptions",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Previous audio generation mainly focuses on specified sound classes such as\nspeech or music, whose form and content are greatly restricted. In this paper,\nwe go beyond specific audio generation by using natural language description as\na clue to generate broad sounds. Unlike visual information, a text description\nis concise by its nature but has rich hidden meanings beneath, which poses a\nhigher possibility and complexity on the audio to be generated. A\nVariation-Quantized GAN is used to train a codebook learning discrete\nrepresentations of spectrograms. For a given text description, its pre-trained\nembedding is fed to a Transformer to sample codebook indices to decode a\nspectrogram to be further transformed into waveform by a melgan vocoder. The\ngenerated waveform has high quality and fidelity while excellently\ncorresponding to the given text. Experiments show that our proposed method is\ncapable of generating natural, vivid audios, achieving superb quantitative and\nqualitative results."
    },
    {
      "paper_id": "2305.02147v3",
      "title": "Improved Vocal Effort Transfer Vector Estimation for Vocal Effort-Robust\n  Speaker Verification",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Despite the maturity of modern speaker verification technology, its\nperformance still significantly degrades when facing non-neutrally-phonated\n(e.g., shouted and whispered) speech. To address this issue, in this paper, we\npropose a new speaker embedding compensation method based on a minimum mean\nsquare error (MMSE) estimator. This method models the joint distribution of the\nvocal effort transfer vector and non-neutrally-phonated embedding spaces and\noperates in a principal component analysis domain to cope with\nnon-neutrally-phonated speech data scarcity. Experiments are carried out using\na cutting-edge speaker verification system integrating a powerful\nself-supervised pre-trained model for speech representation. In comparison with\na state-of-the-art embedding compensation method, the proposed MMSE estimator\nyields superior and competitive equal error rate results when tackling shouted\nand whispered speech, respectively."
    }
  ],
  [
    {
      "paper_id": "1602.08927v3",
      "title": "High-Dimensional $L_2$Boosting: Rate of Convergence",
      "subject": [
        "econ.EM"
      ],
      "abstract": "Boosting is one of the most significant developments in machine learning.\nThis paper studies the rate of convergence of $L_2$Boosting, which is tailored\nfor regression, in a high-dimensional setting. Moreover, we introduce so-called\n\\textquotedblleft post-Boosting\\textquotedblright. This is a post-selection\nestimator which applies ordinary least squares to the variables selected in the\nfirst stage by $L_2$Boosting. Another variant is \\textquotedblleft Orthogonal\nBoosting\\textquotedblright\\ where after each step an orthogonal projection is\nconducted. We show that both post-$L_2$Boosting and the orthogonal boosting\nachieve the same rate of convergence as LASSO in a sparse, high-dimensional\nsetting. We show that the rate of convergence of the classical $L_2$Boosting\ndepends on the design matrix described by a sparse eigenvalue constant. To show\nthe latter results, we derive new approximation results for the pure greedy\nalgorithm, based on analyzing the revisiting behavior of $L_2$Boosting. We also\nintroduce feasible rules for early stopping, which can be easily implemented\nand used in applied work. Our results also allow a direct comparison between\nLASSO and boosting which has been missing from the literature. Finally, we\npresent simulation studies and applications to illustrate the relevance of our\ntheoretical results and to provide insights into the practical aspects of\nboosting. In these simulation studies, post-$L_2$Boosting clearly outperforms\nLASSO."
    },
    {
      "paper_id": "1803.07164v2",
      "title": "Adversarial Generalized Method of Moments",
      "subject": [
        "econ.EM"
      ],
      "abstract": "We provide an approach for learning deep neural net representations of models\ndescribed via conditional moment restrictions. Conditional moment restrictions\nare widely used, as they are the language by which social scientists describe\nthe assumptions they make to enable causal inference. We formulate the problem\nof estimating the underling model as a zero-sum game between a modeler and an\nadversary and apply adversarial training. Our approach is similar in nature to\nGenerative Adversarial Networks (GAN), though here the modeler is learning a\nrepresentation of a function that satisfies a continuum of moment conditions\nand the adversary is identifying violating moments. We outline ways of\nconstructing effective adversaries in practice, including kernels centered by\nk-means clustering, and random forests. We examine the practical performance of\nour approach in the setting of non-parametric instrumental variable regression."
    }
  ],
  [
    {
      "paper_id": "cs/0511033v1",
      "title": "Fast (Multi-)Evaluation of Linearly Recurrent Sequences: Improvements\n  and Applications",
      "subject": [
        "cs.SC"
      ],
      "abstract": "For a linearly recurrent vector sequence P[n+1] = A(n) * P[n], consider the\nproblem of calculating either the n-th term P[n] or L<=n arbitrary terms\nP[n_1],...,P[n_L], both for the case of constant coefficients A(n)=A and for a\nmatrix A(n) with entries polynomial in n. We improve and extend known\nalgorithms for this problem and present new applications for it. Specifically\nit turns out that for instance * any family (p_n) of classical orthogonal\npolynomials admits evaluation at given x within O(n^{1/2} log n) operations\nINDEPENDENT of the family (p_n) under consideration. * For any L indices\nn_1,...,n_L <= n, the values p_{n_i}(x) can be calculated simultaneously using\nO(n^{1/2} log n + L log(n/L)) arithmetic operations; again this running time\nbound holds uniformly. * Every hypergeometric (or, more generally, holonomic)\nfunction admits approximate evaluation up to absolute error e>0 within\nO((log(1/e)^{1/2} loglog(1/e)) -- as opposed to O(log(1/e)) -- arithmetic\nsteps. * Given m and a polynomial p of degree d over a field of characteristic\nzero, the coefficient of p^m to term X^n can be computed within O(d^2\nM(n^{1/2})) steps where M(n) denotes the cost of multiplying two degree-n\npolynomials. * The same time bound holds for the joint calculation of any\nL<=n^{1/2} desired coefficients of p^m to terms X^{n_i}, n_1,...,n_L <= n."
    },
    {
      "paper_id": "cs/0511066v5",
      "title": "An introspective algorithm for the integer determinant",
      "subject": [
        "cs.SC"
      ],
      "abstract": "We present an algorithm computing the determinant of an integer matrix A. The\nalgorithm is introspective in the sense that it uses several distinct\nalgorithms that run in a concurrent manner. During the course of the algorithm\npartial results coming from distinct methods can be combined. Then, depending\non the current running time of each method, the algorithm can emphasize a\nparticular variant. With the use of very fast modular routines for linear\nalgebra, our implementation is an order of magnitude faster than other existing\nimplementations. Moreover, we prove that the expected complexity of our\nalgorithm is only O(n^3 log^{2.5}(n ||A||)) bit operations in the dense case\nand O(Omega n^{1.5} log^2(n ||A||) + n^{2.5}log^3(n||A||)) in the sparse case,\nwhere ||A|| is the largest entry in absolute value of the matrix and Omega is\nthe cost of matrix-vector multiplication in the case of a sparse matrix."
    }
  ],
  [
    {
      "paper_id": "1602.08652v3",
      "title": "A Tutorial: Adaptive Runge-Kutta Integration for Stiff Systems :\n  Comparing the Nos\u00e9 and Nos\u00e9-Hoover Oscillator Dynamics",
      "subject": [
        "cond-mat.stat-mech",
        "nlin.CD",
        "physics.class-ph",
        "physics.comp-ph"
      ],
      "abstract": "\"Stiff\" differential equations are commonplace in engineering and dynamical\nsystems. To solve them we need flexible integrators that can deal with\nrapidly-changing righthand sides. This tutorial describes the application of\n\"adaptive\" [ variable timestep ] integrators to \"stiff\" mechanical problems\nencountered in modern applications of Gibbs' 1902 statistical mechanics. Linear\nharmonic oscillators subject to nonlinear thermal constraints can exhibit\neither stiff or smooth dynamics. Two closely-related examples, Nos\\'e's 1984\ndynamics and Nos\\'e-Hoover 1985 dynamics, are both based on Hamiltonian\nmechanics, as was ultimately clarified by Dettmann and Morriss in 1996. Both\nthese dynamics are consistent with Gibbs' canonical ensemble. Nos\\'e's dynamics\nis \"stiff\" and can present severe numerical difficulties. Nos\\'e-Hoover\ndynamics, though it follows exactly the same trajectory, is \"smooth\" and\nrelatively trouble-free. Our tutorial emphasises the power of adaptive\nintegrators to resolve stiff problems like the Nos\\'e oscillator. The solutions\nobtained illustrate the power of computer graphics to enrich numerical\nsolutions. Adaptive integration with computer graphics are basic to an\nunderstanding of dynamical systems and statistical mechanics. These tools lead\nnaturally into the visualization of intricate fractal structures formed by\nchaos as well as elaborate knots tied by regular nonchaotic dynamics. This work\nwas invited by the American Journal of Physics."
    },
    {
      "paper_id": "1603.02106v5",
      "title": "Carrier Phase Estimation in Dispersion-Unmanaged Optical Transmission\n  Systems",
      "subject": [
        "physics.class-ph",
        "physics.optics"
      ],
      "abstract": "The study on carrier phase estimation (CPE) approaches, involving a one-tap\nnormalized least-mean-square (NLMS) algorithm, a block-wise average algorithm,\nand a Viterbi-Viterbi algorithm has been carried out in the long-haul\nhigh-capacity dispersion-unmanaged coherent optical systems. The close-form\nexpressions and analytical predictions for bit-error-rate behaviors in these\nCPE methods have been analyzed by considering both the laser phase noise and\nthe equalization enhanced phase noise. It is found that the Viterbi-Viterbi\nalgorithm outperforms the one-tap NLMS and the block-wise average algorithms\nfor a small phase noise variance (or effective phase noise variance), while the\nthree CPE methods converge to a similar performance for a large phase noise\nvariance (or effective phase noise variance). In addition, the differences\nbetween the three CPE approaches become smaller for higher-level modulation\nformats."
    }
  ],
  [
    {
      "paper_id": "2410.10665v1",
      "title": "Double Jeopardy and Climate Impact in the Use of Large Language Models:\n  Socio-economic Disparities and Reduced Utility for Non-English Speakers",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Artificial Intelligence (AI), particularly large language models (LLMs),\nholds the potential to bridge language and information gaps, which can benefit\nthe economies of developing nations. However, our analysis of FLORES-200,\nFLORES+, Ethnologue, and World Development Indicators data reveals that these\nbenefits largely favor English speakers. Speakers of languages in low-income\nand lower-middle-income countries face higher costs when using OpenAI's GPT\nmodels via APIs because of how the system processes the input -- tokenization.\nAround 1.5 billion people, speaking languages primarily from\nlower-middle-income countries, could incur costs that are 4 to 6 times higher\nthan those faced by English speakers. Disparities in LLM performance are\nsignificant, and tokenization in models priced per token amplifies inequalities\nin access, cost, and utility. Moreover, using the quality of translation tasks\nas a proxy measure, we show that LLMs perform poorly in low-resource languages,\npresenting a ``double jeopardy\" of higher costs and poor performance for these\nusers. We also discuss the direct impact of fragmentation in tokenizing\nlow-resource languages on climate. This underscores the need for fairer\nalgorithm development to benefit all linguistic groups."
    },
    {
      "paper_id": "2410.17587v1",
      "title": "Predicting Company Growth by Econophysics informed Machine Learning",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Predicting company growth is crucial for strategic adjustment, operational\ndecision-making, risk assessment, and loan eligibility reviews. Traditional\nmodels for company growth often focus too much on theory, overlooking practical\nforecasting, or they rely solely on time series forecasting techniques,\nignoring interpretability and the inherent mechanisms of company growth. In\nthis paper, we propose a machine learning-based prediction framework that\nincorporates an econophysics model for company growth. Our model captures both\nthe intrinsic growth mechanisms of companies led by scaling laws and the\nfluctuations influenced by random factors and individual decisions,\ndemonstrating superior predictive performance compared with methods that use\ntime series techniques alone. Its advantages are more pronounced in long-range\nprediction tasks. By explicitly modeling the baseline growth and volatility\ncomponents, our model is more interpretable."
    }
  ],
  [
    {
      "paper_id": "1808.09267v2",
      "title": "Creating a surrogate commuter network from Australian Bureau of\n  Statistics census data",
      "subject": [
        "cs.DB"
      ],
      "abstract": "Between the 2011 and 2016 national censuses, the Australian Bureau of\nStatistics changed its anonymity policy compliance system for the distribution\nof census data. The new method has resulted in dramatic inconsistencies when\ncomparing low-resolution data to aggregated high-resolution data. Hence,\naggregated totals do not match true totals, and the mismatch gets worse as the\ndata resolution gets finer. Here, we address several aspects of this\ninconsistency with respect to the 2016 usual-residence to place-of-work travel\ndata. We introduce a re-sampling system that rectifies many of the artifacts\nintroduced by the new ABS protocol, ensuring a higher level of consistency\nacross partition sizes. We offer a surrogate high-resolution 2016 commuter\ndataset that reduces the difference between aggregated and true commuter totals\nfrom ~34% to only ~7%, which is on the order of the discrepancy across\npartition resolutions in data from earlier years."
    },
    {
      "paper_id": "1808.09545v1",
      "title": "Cost-efficient Data Acquisition on Online Data Marketplaces for\n  Correlation Analysis",
      "subject": [
        "cs.DB"
      ],
      "abstract": "Incentivized by the enormous economic profits, the data marketplace platform\nhas been proliferated recently. In this paper, we consider the data marketplace\nsetting where a data shopper would like to buy data instances from the data\nmarketplace for correlation analysis of certain attributes. We assume that the\ndata in the marketplace is dirty and not free. The goal is to find the data\ninstances from a large number of datasets in the marketplace whose join result\nnot only is of high-quality and rich join informativeness, but also delivers\nthe best correlation between the requested attributes. To achieve this goal, we\ndesign DANCE, a middleware that provides the desired data acquisition service.\nDANCE consists of two phases: (1) In the off-line phase, it constructs a\ntwo-layer join graph from samples. The join graph consists of the information\nof the datasets in the marketplace at both schema and instance levels; (2) In\nthe online phase, it searches for the data instances that satisfy the\nconstraints of data quality, budget, and join informativeness, while maximize\nthe correlation of source and target attribute sets. We prove that the\ncomplexity of the search problem is NP-hard, and design a heuristic algorithm\nbased on Markov chain Monte Carlo (MCMC). Experiment results on two benchmark\ndatasets demonstrate the efficiency and effectiveness of our heuristic data\nacquisition algorithm."
    }
  ],
  [
    {
      "paper_id": "1904.11949v2",
      "title": "Machine Learning Tips and Tricks for Power Line Communications",
      "subject": [
        "eess.SP"
      ],
      "abstract": "A great deal of attention has been recently given to Machine Learning (ML)\ntechniques in many different application fields. This paper provides a vision\nof what ML can do in Power Line Communications (PLC). We firstly and briefly\ndescribe classical formulations of ML, and distinguish deterministic from\nstatistical learning models with relevance to communications. We then discuss\nML applications in PLC for each layer, namely, for characterization and\nmodeling, for the development of physical layer algorithms, for media access\ncontrol and networking. Finally, other applications of PLC that can benefit\nfrom the usage of ML, as grid diagnostics, are analyzed. Illustrative numerical\nexamples are reported to serve the purpose of validating the ideas and motivate\nfuture research endeavors in this stimulating signal/data processing field."
    },
    {
      "paper_id": "1904.11950v1",
      "title": "Attention-based Transfer Learning for Brain-computer Interface",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Different functional areas of the human brain play different roles in brain\nactivity, which has not been paid sufficient research attention in the\nbrain-computer interface (BCI) field. This paper presents a new approach for\nelectroencephalography (EEG) classification that applies attention-based\ntransfer learning. Our approach considers the importance of different brain\nfunctional areas to improve the accuracy of EEG classification, and provides an\nadditional way to automatically identify brain functional areas associated with\nnew activities without the involvement of a medical professional. We\ndemonstrate empirically that our approach out-performs state-of-the-art\napproaches in the task of EEG classification, and the results of visualization\nindicate that our approach can detect brain functional areas related to a\ncertain task."
    }
  ],
  [
    {
      "paper_id": "1808.06040v1",
      "title": "Optimal proposals for Approximate Bayesian Computation",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We derive the optimal proposal density for Approximate Bayesian Computation\n(ABC) using Sequential Monte Carlo (SMC) (or Population Monte Carlo, PMC). The\ncriterion for optimality is that the SMC/PMC-ABC sampler maximise the effective\nnumber of samples per parameter proposal. The optimal proposal density\nrepresents the optimal trade-off between favoring high acceptance rate and\nreducing the variance of the importance weights of accepted samples. We discuss\ntwo convenient approximations of this proposal and show that the optimal\nproposal density gives a significant boost in the expected sampling efficiency\ncompared to standard kernels that are in common use in the ABC literature,\nespecially as the number of parameters increases."
    },
    {
      "paper_id": "1808.06310v2",
      "title": "Analysis of \"Learn-As-You-Go\" (LAGO) Studies",
      "subject": [
        "stat.AP",
        "stat.TH"
      ],
      "abstract": "In learn-as-you-go (LAGO) adaptive studies, the intervention is a complex\npackage consisting of multiple components, and is adapted in stages during the\nstudy based on past outcome data. This design formalizes standard practice, and\ndesires for practice, in public health intervention studies. An effective\nintervention package is sought, while minimizing intervention package cost.\nWhen analyzing data from a learn-as-you-go study, the interventions in later\nstages depend upon the outcomes in the previous stages, violating standard\nstatistical theory. We develop methods for estimating the intervention effects\nin a LAGO study. We prove consistency and asymptotic normality using a novel\ncoupling argument, ensuring the validity of the test for the hypothesis of no\noverall intervention effect. We develop a confidence set for the optimal\nintervention package and confidence bands for the success probabilities under\nalternative package compositions. We illustrate our methods in the BetterBirth\nStudy, which aimed to improve maternal and neonatal outcomes among 157,689\nbirths in Uttar Pradesh, India through a complex, multi-component intervention\npackage."
    }
  ],
  [
    {
      "paper_id": "2502.17382v1",
      "title": "Unraveling the geometry of visual relational reasoning",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "Humans and other animals readily generalize abstract relations, such as\nrecognizing constant in shape or color, whereas neural networks struggle. To\ninvestigate how neural networks generalize abstract relations, we introduce\nSimplifiedRPM, a novel benchmark for systematic evaluation. In parallel, we\nconduct human experiments to benchmark relational difficulty, enabling direct\nmodel-human comparisons. Testing four architectures--ResNet-50, Vision\nTransformer, Wild Relation Network, and Scattering Compositional Learner\n(SCL)--we find that SCL best aligns with human behavior and generalizes best.\nBuilding on a geometric theory of neural representations, we show\nrepresentational geometries that predict generalization. Layer-wise analysis\nreveals distinct relational reasoning strategies across models and suggests a\ntrade-off where unseen rule representations compress into training-shaped\nsubspaces. Guided by our geometric perspective, we propose and evaluate\nSNRloss, a novel objective balancing representation geometry. Our findings\noffer geometric insights into how neural networks generalize abstract\nrelations, paving the way for more human-like visual reasoning in AI."
    },
    {
      "paper_id": "2502.18318v1",
      "title": "Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic\n  Modelling and LLM applied to Stroboscopic Phenomenology",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "Stroboscopic light stimulation (SLS) on closed eyes typically induces simple\nvisual hallucinations (VHs), characterised by vivid, geometric and colourful\npatterns. A dataset of 862 sentences, extracted from 422 open subjective\nreports, was recently compiled as part of the Dreamachine programme (Collective\nAct, 2022), an immersive multisensory experience that combines SLS and spatial\nsound in a collective setting. Although open reports extend the range of\nreportable phenomenology, their analysis presents significant challenges,\nparticularly in systematically identifying patterns. To address this challenge,\nwe implemented a data-driven approach leveraging Large Language Models and\nTopic Modelling to uncover and interpret latent experiential topics directly\nfrom the Dreamachine's text-based reports. Our analysis confirmed the presence\nof simple VHs typically documented in scientific studies of SLS, while also\nrevealing experiences of altered states of consciousness and complex\nhallucinations. Building on these findings, our computational approach expands\nthe systematic study of subjective experience by enabling data-driven analyses\nof open-ended phenomenological reports, capturing experiences not readily\nidentified through standard questionnaires. By revealing rich and multifaceted\naspects of experiences, our study broadens our understanding of\nstroboscopically-induced phenomena while highlighting the potential of Natural\nLanguage Processing and Large Language Models in the emerging field of\ncomputational (neuro)phenomenology. More generally, this approach provides a\npractically applicable methodology for uncovering subtle hidden patterns of\nsubjective experience across diverse research domains."
    }
  ],
  [
    {
      "paper_id": "2403.03648v1",
      "title": "A Connector for Integrating NGSI-LD Data into Open Data Portals",
      "subject": [
        "cs.DB",
        "cs.NI"
      ],
      "abstract": "Nowadays, there are plenty of data sources generating massive amounts of\ninformation that, combined with novel data analytics frameworks, are meant to\nsupport optimisation in many application domains. Nonetheless, there are still\nshortcomings in terms of data discoverability, accessibility and\ninteroperability. Open Data portals have emerged as a shift towards openness\nand discoverability. However, they do not impose any condition to the data\nitself, just stipulate how datasets have to be described. Alternatively, the\nNGSI-LD standard pursues harmonisation in terms of data modelling and\naccessibility. This paper presents a solution that bridges these two domains\n(i.e., Open Data portals and NGSI-LD-based data) in order to keep benefiting\nfrom the structured description of datasets offered by Open Data portals, while\nensuring the interoperability provided by the NGSI-LD standard. Our solution\naggregates the data into coherent datasets and generate high-quality\ndescriptions, ensuring comprehensiveness, interoperability and accessibility.\nThe proposed solution has been validated through a real-world implementation\nthat exposes IoT data in NGSI-LD format through the European Data Portal (EDP).\nMoreover, the results from the Metadata Quality Assessment that the EDP\nimplements, show that the datasets' descriptions generated achieve excellent\nranking in terms of the Findability, Accessibility, Interoperability and\nReusability (FAIR) data principles."
    },
    {
      "paper_id": "2403.04327v2",
      "title": "ProMoAI: Process Modeling with Generative AI",
      "subject": [
        "cs.DB",
        "cs.CL"
      ],
      "abstract": "ProMoAI is a novel tool that leverages Large Language Models (LLMs) to\nautomatically generate process models from textual descriptions, incorporating\nadvanced prompt engineering, error handling, and code generation techniques.\nBeyond automating the generation of complex process models, ProMoAI also\nsupports process model optimization. Users can interact with the tool by\nproviding feedback on the generated model, which is then used for refining the\nprocess model. ProMoAI utilizes the capabilities LLMs to offer a novel,\nAI-driven approach to process modeling, significantly reducing the barrier to\nentry for users without deep technical knowledge in process modeling."
    }
  ],
  [
    {
      "paper_id": "2407.13908v1",
      "title": "Construction and Hedging of Equity Index Options Portfolios",
      "subject": [
        "q-fin.RM",
        "q-fin.TR"
      ],
      "abstract": "This research presents a comprehensive evaluation of systematic index\noption-writing strategies, focusing on S&P500 index options. We compare the\nperformance of hedging strategies using the Black-Scholes-Merton (BSM) model\nand the Variance-Gamma (VG) model, emphasizing varying moneyness levels and\ndifferent sizing methods based on delta and the VIX Index. The study employs\n1-minute data of S&P500 index options and index quotes spanning from 2018 to\n2023. The analysis benchmarks hedged strategies against buy-and-hold and naked\noption-writing strategies, with a focus on risk-adjusted performance metrics\nincluding transaction costs. Portfolio delta approximations are derived using\nimplied volatility for the BSM model and market-calibrated parameters for the\nVG model. Key findings reveal that systematic option-writing strategies can\npotentially yield superior returns compared to buy-and-hold benchmarks. The BSM\nmodel generally provided better hedging outcomes than the VG model, although\nthe VG model showed profitability in certain naked strategies as a tool for\nposition sizing. In terms of rehedging frequency, we found that intraday\nhedging in 130-minute intervals provided both reliable protection against\nadverse market movements and a satisfactory returns profile."
    },
    {
      "paper_id": "2407.14844v1",
      "title": "Political Leanings in Web3 Betting: Decoding the Interplay of Political\n  and Profitable Motives",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "Harnessing the transparent blockchain user behavior data, we construct the\nPolitical Betting Leaning Score (PBLS) to measure political leanings based on\nbetting within Web3 prediction markets. Focusing on Polymarket and starting\nfrom the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000\naddresses across 4,500 events and 8,500 markets, capturing the intensity and\ndirection of their political leanings by the PBLS. We validate the PBLS through\ninternal consistency checks and external comparisons. We uncover relationships\nbetween our PBLS and betting behaviors through over 800 features capturing\nvarious behavioral aspects. A case study of the 2022 U.S. Senate election\nfurther demonstrates the ability of our measurement while decoding the dynamic\ninteraction between political and profitable motives. Our findings contribute\nto understanding decision-making in decentralized markets, enhancing the\nanalysis of behaviors within Web3 prediction environments. The insights of this\nstudy reveal the potential of blockchain in enabling innovative,\nmultidisciplinary studies and could inform the development of more effective\nonline prediction markets, improve the accuracy of forecast, and help the\ndesign and optimization of platform mechanisms. The data and code for the paper\nare accessible at the following link: https://github.com/anonymous."
    }
  ],
  [
    {
      "paper_id": "1702.01418v2",
      "title": "Choosing the number of groups in a latent stochastic block model for\n  dynamic networks",
      "subject": [
        "stat.CO"
      ],
      "abstract": "Latent stochastic block models are flexible statistical models that are\nwidely used in social network analysis. In recent years, efforts have been made\nto extend these models to temporal dynamic networks, whereby the connections\nbetween nodes are observed at a number of different times. In this paper we\nextend the original stochastic block model by using a Markovian property to\ndescribe the evolution of nodes' cluster memberships over time. We recast the\nproblem of clustering the nodes of the network into a model-based context, and\nshow that the integrated completed likelihood can be evaluated analytically for\na number of likelihood models. Then, we propose a scalable greedy algorithm to\nmaximise this quantity, thereby estimating both the optimal partition and the\nideal number of groups in a single inferential framework. Finally we propose\napplications of our methodology to both real and artificial datasets."
    },
    {
      "paper_id": "1702.01618v2",
      "title": "Learning of state-space models with highly informative observations: a\n  tempered Sequential Monte Carlo solution",
      "subject": [
        "stat.CO",
        "stat.ML"
      ],
      "abstract": "Probabilistic (or Bayesian) modeling and learning offers interesting\npossibilities for systematic representation of uncertainty using probability\ntheory. However, probabilistic learning often leads to computationally\nchallenging problems. Some problems of this type that were previously\nintractable can now be solved on standard personal computers thanks to recent\nadvances in Monte Carlo methods. In particular, for learning of unknown\nparameters in nonlinear state-space models, methods based on the particle\nfilter (a Monte Carlo method) have proven very useful. A notoriously\nchallenging problem, however, still occurs when the observations in the\nstate-space model are highly informative, i.e. when there is very little or no\nmeasurement noise present, relative to the amount of process noise. The\nparticle filter will then struggle in estimating one of the basic components\nfor probabilistic learning, namely the likelihood $p($data$|$parameters$)$. To\nthis end we suggest an algorithm which initially assumes that there is\nsubstantial amount of artificial measurement noise present. The variance of\nthis noise is sequentially decreased in an adaptive fashion such that we, in\nthe end, recover the original problem or possibly a very close approximation of\nit. The main component in our algorithm is a sequential Monte Carlo (SMC)\nsampler, which gives our proposed method a clear resemblance to the SMC^2\nmethod. Another natural link is also made to the ideas underlying the\napproximate Bayesian computation (ABC). We illustrate it with numerical\nexamples, and in particular show promising results for a challenging\nWiener-Hammerstein benchmark problem."
    }
  ],
  [
    {
      "paper_id": "1909.01439v1",
      "title": "Universality of clone dynamics during tissue development",
      "subject": [
        "q-bio.TO"
      ],
      "abstract": "The emergence of complex organs is driven by the coordinated proliferation,\nmigration and differentiation of precursor cells. The fate behaviour of these\ncells is reflected in the time evolution their progeny, termed clones, which\nserve as a key experimental observable. In adult tissues, where cell dynamics\nis constrained by the condition of homeostasis, clonal tracing studies based on\ntransgenic animal models have advanced our understanding of cell fate behaviour\nand its dysregulation in disease. But what can be learned from clonal dynamics\nin development, where the spatial cohesiveness of clones is impaired by tissue\ndeformations during tissue growth? Drawing on the results of clonal tracing\nstudies, we show that, despite the complexity of organ development, clonal\ndynamics may converge to a critical state characterized by universal scaling\nbehaviour of clone sizes. By mapping clonal dynamics onto a generalization of\nthe classical theory of aerosols, we elucidate the origin and range of scaling\nbehaviours and show how the identification of universal scaling dependences may\nallow lineage-specific information to be distilled from experiments. Our study\nshows the emergence of core concepts of statistical physics in an unexpected\ncontext, identifying cellular systems as a laboratory to study non-equilibrium\nstatistical physics."
    },
    {
      "paper_id": "1909.01711v1",
      "title": "Simulation and computational analysis of multiscale graph agent-based\n  tumor model",
      "subject": [
        "q-bio.TO"
      ],
      "abstract": "This paper deals with the cellular biological network analysis of the\ntumor-growth model, consisting of multiple spaces and time scales. In this\npaper, we present a model in graph simulation using ABM for tumor growth. In\nparticular, we propose a graph agent-based modeling and simulation system in\nthe format of tumor growth scenario for evolving analysis. To manage cellular\nbiological network analysis, we developed a workflow that allows us to estimate\nthe tumor model and the complexity of the evolving behavior in a principled\nmanner. By developing the model using Python, which has enabled us to run the\nmodel multiple times (more than what is possible by conventional means) to\ngenerate a large amount of data, we have succeeded in getting deep in to the\nmicro-environment of the tumor, employing network analysis. Combining\nagent-based modeling with graph-based modeling to simulate the structure,\ndynamics, and functions of complex networks is exclusively important for\nbiological systems with a large number of open parameters, e.g., epidemic\nmodels of disease spreading or cancer. Extracting data from evolutionary\ndirected graphs and a set of centrality algorithms helps us to tackle the\nproblems of pathway analysis and to develop the ability to predict, control,\nand design the function of metabolisms. Reproducing and performing complex\nparametric simulations a known phenomenon at a sufficient level of detail for\ncomputational biology could be an impressive achievement for fast analysis\npurposes in clinics, both on the predictive diagnostic and therapeutic side."
    }
  ],
  [
    {
      "paper_id": "2004.07429v1",
      "title": "Exactly computing the tail of the Poisson-Binomial Distribution",
      "subject": [
        "stat.CO"
      ],
      "abstract": "We offer ShiftConvolvePoibin, a fast exact method to compute the tail of a\nPoisson-Binomial distribution (PBD). Our method employs an exponential shift to\nretain its accuracy when computing a tail probability, and in practice we find\nthat it is immune to the significant relative errors that other methods, exact\nor approximate, can suffer from when computing very small tail probabilities of\nthe PBD. The accompanying R package is also competitive with the fastest\nimplementations for computing the entire PBD."
    },
    {
      "paper_id": "2004.07471v3",
      "title": "Efficient Bernoulli factory MCMC for intractable posteriors",
      "subject": [
        "stat.CO"
      ],
      "abstract": "Accept-reject based Markov chain Monte Carlo (MCMC) algorithms have\ntraditionally utilised acceptance probabilities that can be explicitly written\nas a function of the ratio of the target density at the two contested points.\nThis feature is rendered almost useless in Bayesian posteriors with unknown\nfunctional forms. We introduce a new family of MCMC acceptance probabilities\nthat has the distinguishing feature of not being a function of the ratio of the\ntarget density at the two points. We present two stable Bernoulli factories\nthat generate events within this class of acceptance probabilities. The\nefficiency of our methods rely on obtaining reasonable local upper or lower\nbounds on the target density and we present two classes of problems where such\nbounds are viable: Bayesian inference for diffusions and MCMC on constrained\nspaces. The resulting portkey Barker's algorithms are exact and computationally\nmore efficient that the current state-of-the-art."
    }
  ],
  [
    {
      "paper_id": "2308.11495v2",
      "title": "Evaluating the accuracy of Gaussian approximations in VSWIR imaging\n  spectroscopy retrievals",
      "subject": [
        "stat.AP",
        "stat.CO"
      ],
      "abstract": "The joint retrieval of surface reflectances and atmospheric parameters in\nVSWIR imaging spectroscopy is a computationally challenging high-dimensional\nproblem. Using NASA's Surface Biology and Geology mission as the motivational\ncontext, the uncertainty associated with the retrievals is crucial for further\napplication of the retrieved results for environmental applications. Although\nMarkov chain Monte Carlo (MCMC) is a Bayesian method ideal for uncertainty\nquantification, the full-dimensional implementation of MCMC for the retrieval\nis computationally intractable.\n  In this work, we developed a block Metropolis MCMC algorithm for the\nhigh-dimensional VSWIR surface reflectance retrieval that leverages the\nstructure of the forward radiative transfer model to enable tractable fully\nBayesian computation. We use the posterior distribution from this MCMC\nalgorithm to assess the limitations of optimal estimation, the state-of-the-art\nBayesian algorithm in operational retrievals which is more computationally\nefficient but uses a Gaussian approximation to characterize the posterior.\nAnalyzing the differences in the posterior computed by each method, the MCMC\nalgorithm was shown to give more physically sensible results and reveals the\nnon-Gaussian structure of the posterior, specifically in the atmospheric\naerosol optical depth parameter and the low-wavelength surface reflectances."
    },
    {
      "paper_id": "2308.11548v1",
      "title": "Modelling Structural Breaks In Stock Price Time Series Using Stochastic\n  Differential Equations",
      "subject": [
        "stat.AP"
      ],
      "abstract": "This paper studies the effect of quarterly earnings reports on the stock\nprice. The profitability of the stock is modelled by geometric Brownian\ndiffusion and the Constant Elasticity of Variance model. We fit several\nvariations of stochastic differential equations to the pre-and after-report\nperiod using the Maximum Likelihood Estimation and Grid Search of parameters\nmethod. By examining the change in the model parameters after reports'\npublication, the study reveals that the reports have enough evidence to be a\nstructural breakpoint, meaning that all the forecast models exploited are not\napplicable for forecasting and should be refitted shortly."
    }
  ],
  [
    {
      "paper_id": "2212.07052v2",
      "title": "On LASSO for High Dimensional Predictive Regression",
      "subject": [
        "econ.EM"
      ],
      "abstract": "This paper examines LASSO, a widely-used $L_{1}$-penalized regression method,\nin high dimensional linear predictive regressions, particularly when the number\nof potential predictors exceeds the sample size and numerous unit root\nregressors are present. The consistency of LASSO is contingent upon two key\ncomponents: the deviation bound of the cross product of the regressors and the\nerror term, and the restricted eigenvalue of the Gram matrix. We present new\nprobabilistic bounds for these components, suggesting that LASSO's rates of\nconvergence are different from those typically observed in cross-sectional\ncases. When applied to a mixture of stationary, nonstationary, and cointegrated\npredictors, LASSO maintains its asymptotic guarantee if predictors are\nscale-standardized. Leveraging machine learning and macroeconomic domain\nexpertise, LASSO demonstrates strong performance in forecasting the\nunemployment rate, as evidenced by its application to the FRED-MD database."
    },
    {
      "paper_id": "2212.08615v1",
      "title": "A smooth transition autoregressive model for matrix-variate time series",
      "subject": [
        "econ.EM"
      ],
      "abstract": "In many applications, data are observed as matrices with temporal dependence.\nMatrix-variate time series modeling is a new branch of econometrics. Although\nstylized facts in several fields, the existing models do not account for regime\nswitches in the dynamics of matrices that are not abrupt. In this paper, we\nextend linear matrix-variate autoregressive models by introducing a\nregime-switching model capable of accounting for smooth changes, the matrix\nsmooth transition autoregressive model. We present the estimation processes\nwith the asymptotic properties demonstrated with simulated and real data."
    }
  ],
  [
    {
      "paper_id": "2405.01988v1",
      "title": "Joint sentiment analysis of lyrics and audio in music",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Sentiment or mood can express themselves on various levels in music. In\nautomatic analysis, the actual audio data is usually analyzed, but the lyrics\ncan also play a crucial role in the perception of moods. We first evaluate\nvarious models for sentiment analysis based on lyrics and audio separately. The\ncorresponding approaches already show satisfactory results, but they also\nexhibit weaknesses, the causes of which we examine in more detail. Furthermore,\ndifferent approaches to combining the audio and lyrics results are proposed and\nevaluated. Considering both modalities generally leads to improved performance.\nWe investigate misclassifications and (also intentional) contradictions between\naudio and lyrics sentiment more closely, and identify possible causes. Finally,\nwe address fundamental problems in this research area, such as high\nsubjectivity, lack of data, and inconsistency in emotion taxonomies."
    },
    {
      "paper_id": "2405.02821v2",
      "title": "Sim2Real Transfer for Audio-Visual Navigation with Frequency-Adaptive\n  Acoustic Field Prediction",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Sim2real transfer has received increasing attention lately due to the success\nof learning robotic tasks in simulation end-to-end. While there has been a lot\nof progress in transferring vision-based navigation policies, the existing\nsim2real strategy for audio-visual navigation performs data augmentation\nempirically without measuring the acoustic gap. The sound differs from light in\nthat it spans across much wider frequencies and thus requires a different\nsolution for sim2real. We propose the first treatment of sim2real for\naudio-visual navigation by disentangling it into acoustic field prediction\n(AFP) and waypoint navigation. We first validate our design choice in the\nSoundSpaces simulator and show improvement on the Continuous AudioGoal\nnavigation benchmark. We then collect real-world data to measure the spectral\ndifference between the simulation and the real world by training AFP models\nthat only take a specific frequency subband as input. We further propose a\nfrequency-adaptive strategy that intelligently selects the best frequency band\nfor prediction based on both the measured spectral difference and the energy\ndistribution of the received audio, which improves the performance on the real\ndata. Lastly, we build a real robot platform and show that the transferred\npolicy can successfully navigate to sounding objects. This work demonstrates\nthe potential of building intelligent agents that can see, hear, and act\nentirely from simulation, and transferring them to the real world."
    }
  ],
  [
    {
      "paper_id": "0807.0471v4",
      "title": "Complete intersection Approximation, Dual Filtrations and Applications",
      "subject": [
        "math.AC",
        "math.AG"
      ],
      "abstract": "We give a two step method to study certain questions regarding associated\ngraded module of a Cohen-Macaulay (CM) module $M$ w.r.t an\n$\\mathfrak{m}$-primary ideal $\\mathfrak{a}$ in a complete Noetherian local ring\n$(A,\\mathfrak{m})$. The first step, we call it complete intersection\napproximation, enables us to reduce to the case when both $A$, $\nG_\\mathfrak{a}(A) = \\bigoplus_{n \\geq 0} \\mathfrak{a}^n/\\mathfrak{a}^{n+1} $\nare complete intersections and $M$ is a maximal CM $A$-module. The second step\nconsists of analyzing the classical filtration $\\{Hom_A(M,\\mathfrak{a}^n)\n\\}_{\\mathbb{Z}}$ of the dual $Hom_A(M,A)$. We give many applications of this\npoint of view. For instance let $(A,\\mathfrak{m})$ be equicharacteristic and\nCM. Let $a(G_\\mathfrak{a}(A))$ be the $a$-invariant of $G_\\mathfrak{a}(A)$. We\nprove:\n  1. $a(G_\\mathfrak{a}(A)) = -\\dim A$ iff $\\mathfrak{a}$ is generated by a\nregular sequence.\n  2. If $\\mathfrak{a}$ is integrally closed and $a(G_\\mathfrak{a}(A)) = -\\dim A\n+ 1$ then $\\mathfrak{a}$ has minimal multiplicity.\n  We extend to modules a result of Ooishi relating symmetry of $h$-vectors. As\nanother application\n  we prove a conjecture of Itoh, if $A$ is a CM local ring and\n  $\\mathfrak{a}$ is a normal ideal with $e_3^\\mathfrak{a}(A) = 0$ then\n$G_\\mathfrak{a}(A)$ is CM."
    },
    {
      "paper_id": "0807.1654v4",
      "title": "Centers of F-purity",
      "subject": [
        "math.AC",
        "math.AG"
      ],
      "abstract": "In this paper, we study a positive characteristic analogue of the centers of\nlog canonicity of a pair $(R, \\Delta)$. We call these analogues centers of\n$F$-purity. We prove positive characteristic analogues of subadjunction-like\nresults, prove new stronger subadjunction-like results, and in some cases, lift\nthese new results to characteristic zero. Using a generalization of centers of\n$F$-purity which we call uniformly $F$-compatible ideals, we give a\ncharacterization of the test ideal (which unifies several previous\ncharacterizations). Finally, in the case that $\\Delta = 0$, we show that\nuniformly $F$-compatible ideals coincide with the annihilators of the\n$\\mathcal{F}(E_R(k))$-submodules of $E_R(k)$ as defined by Smith and Lyubeznik."
    }
  ],
  [
    {
      "paper_id": "2003.13751v1",
      "title": "An Interface-enriched Generalized Finite Element Method for\n  Levelset-based Topology Optimization",
      "subject": [
        "cs.CE"
      ],
      "abstract": "During design optimization, a smooth description of the geometry is\nimportant, especially for problems that are sensitive to the way interfaces are\nresolved, e.g., wave propagation or fluid-structure interaction. A levelset\ndescription of the boundary, when combined with an enriched finite element\nformulation, offers a smoother description of the design than traditional\ndensity-based methods. However, existing enriched methods have drawbacks,\nincluding ill-conditioning and difficulties in prescribing essential boundary\nconditions. In this work we introduce a new enriched topology optimization\nmethodology that overcomes the aforementioned drawbacks; boundaries are\nresolved accurately by means of the Interface-enriched Generalized Finite\nElement Method (IGFEM), coupled to a levelset function constructed by radial\nbasis functions. The enriched method used in this new approach to topology\noptimization has the same level of accuracy in the analysis as standard the\nfinite element method with matching meshes, but without the need for remeshing.\nWe derive the analytical sensitivities and we discuss the behavior of the\noptimization process in detail. We establish that IGFEM-based levelset topology\noptimization generates correct topologies for well-known compliance\nminimization problems."
    },
    {
      "paper_id": "2005.01332v1",
      "title": "Stochastic phase-field modeling of brittle fracture: computing multiple\n  crack patterns and their probabilities",
      "subject": [
        "cs.CE"
      ],
      "abstract": "In variational phase-field modeling of brittle fracture, the functional to be\nminimized is not convex, so that the necessary stationarity conditions of the\nfunctional may admit multiple solutions. The solution obtained in an actual\ncomputation is typically one out of several local minimizers. Evidence of\nmultiple solutions induced by small perturbations of numerical or physical\nparameters was occasionally recorded but not explicitly investigated in the\nliterature. In this work, we focus on this issue and advocate a paradigm shift,\naway from the search for one particular solution towards the simultaneous\ndescription of all possible solutions (local minimizers), along with the\nprobabilities of their occurrence. Inspired by recent approaches advocating\nmeasure-valued solutions (Young measures as well as their generalization to\nstatistical solutions) and their numerical approximations in fluid mechanics,\nwe propose the stochastic relaxation of the variational brittle fracture\nproblem through random perturbations of the functional. We introduce the\nconcept of stochastic solution, with the main advantage that point-to-point\ncorrelations of the crack phase fields in the underlying domain can be\ncaptured. These stochastic solutions are represented by random fields or random\nvariables with values in the classical deterministic solution spaces. In the\nnumerical experiments, we use a simple Monte Carlo approach to compute\napproximations to such stochastic solutions. The final result of the\ncomputation is not a single crack pattern, but rather several possible crack\npatterns and their probabilities. The stochastic solution framework using\nevolving random fields allows additionally the interesting possibility of\nconditioning the probabilities of further crack paths on intermediate crack\npatterns."
    }
  ],
  [
    {
      "paper_id": "2311.10216v2",
      "title": "Bayesian mechanics of self-organising systems",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "Bayesian mechanics provides a framework that addresses dynamical systems that\ncan be conceptualised as Bayesian inference. However, elucidating the requisite\ngenerative models is essential for empirical applications to realistic\nself-organising systems. This work shows that the Hamiltonian of generic\ndynamical systems constitutes a class of generative models, thus rendering\ntheir Helmholtz energy equivalent to variational free energy under the\nidentified generative model. The self-organisation that minimises the Helmholtz\nenergy entails matching the system's Hamiltonian with that of the environment,\nleading to the ensuing emergence of their generalised synchrony. In essence,\nthese self-organising systems can be read as performing variational Bayesian\ninference of their interacting environment. These properties have been\ndemonstrated using coupled oscillators, simulated and living neural networks,\nand quantum computers. This framework offers foundational characterisations and\npredictions regarding asymptotic properties of self-organising systems\ninteracting with their environment, providing insights into potential\nmechanisms underlying the emergence of intelligence."
    },
    {
      "paper_id": "2311.10383v1",
      "title": "Affordance switching in self-organizing brain-body-environment systems",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "In the ecological approach to perception and action, information that\nspecifies affordances is available in the energy arrays surrounding organisms,\nand this information is detected by organisms in order to perceptually guide\ntheir actions. At the behavioral scale, organisms responding to affordances are\nunderstood as self-organizing and reorganizing softly-assembled synergies.\nWithin the ecological community, little effort has so far been devoted to\nstudying this process at the neural scale, though interest in the topic is\ngrowing under the header of ecological neuroscience. From this perspective,\nswitches between affordances may be conceptualized as transitions within\nbrain-body-environment systems as a whole rather than under the control of a\nprivileged (neural) scale. We discuss extant empirical research at the\nbehavioral scale in support of this view as well as ongoing and planned work at\nthe neural scale that attempts to further flesh out this view by characterizing\nthe neural dynamics that are associated with these transitions while\nparticipants dynamically respond to affordances."
    }
  ],
  [
    {
      "paper_id": "0904.1653v2",
      "title": "An extension of Davis and Lo's contagion model",
      "subject": [
        "q-fin.RM",
        "q-fin.PR"
      ],
      "abstract": "The present paper provides a multi-period contagion model in the credit risk\nfield. Our model is an extension of Davis and Lo's infectious default model. We\nconsider an economy of n firms which may default directly or may be infected by\nother defaulting firms (a domino effect being also possible). The spontaneous\ndefault without external influence and the infections are described by not\nnecessarily independent Bernoulli-type random variables. Moreover, several\ncontaminations could be required to infect another firm. In this paper we\ncompute the probability distribution function of the total number of defaults\nin a dependency context. We also give a simple recursive algorithm to compute\nthis distribution in an exchangeability context. Numerical applications\nillustrate the impact of exchangeability among direct defaults and among\ncontaminations, on different indicators calculated from the law of the total\nnumber of defaults. We then examine the calibration of the model on iTraxx data\nbefore and during the crisis. The dynamic feature together with the contagion\neffect seem to have a significant impact on the model performance, especially\nduring the recent distressed period."
    },
    {
      "paper_id": "0904.2731v2",
      "title": "An Introduction to Hedge Funds",
      "subject": [
        "q-fin.RM"
      ],
      "abstract": "This report was originally written as an industry white paper on Hedge Funds.\nThis paper gives an overview to Hedge Funds, with a focus on risk management\nissues. We define and explain the general characteristics of Hedge Funds, their\nmain investment strategies and the risk models employed. We address the\nproblems in Hedge Fund modelling, survey current Hedge Funds available on the\nmarket and those that have been withdrawn. Finally, we summarise the supporting\nand opposing arguments for Hedge Fund usage. A unique value of this paper,\ncompared to other Hedge Fund literature freely available on the internet, is\nthat this review is fully sourced from academic references (such as peer\nreviewed journals) and is thus a bona fide study. This paper will be of\ninterest to: Hedge Fund and Mutual Fund Managers, Quantitative Analysts,\n\"Front\" and \"Middle\" office banking functions e.g. Treasury Management,\nRegulators concerned with Hedge Fund Financial Risk Management, Private and\nInstitutional Investors, Academic Researchers in the area of Financial Risk\nManagement and the general Finance community."
    }
  ],
  [
    {
      "paper_id": "2006.03476v1",
      "title": "COVID-19 diagnosis by routine blood tests using machine learning",
      "subject": [
        "physics.med-ph"
      ],
      "abstract": "Physicians taking care of patients with coronavirus disease (COVID-19) have\ndescribed different changes in routine blood parameters. However, these\nchanges, hinder them from performing COVID-19 diagnosis. We constructed a\nmachine learning predictive model for COVID-19 diagnosis. The model was based\nand cross-validated on the routine blood tests of 5,333 patients with various\nbacterial and viral infections, and 160 COVID-19-positive patients. We selected\noperational ROC point at a sensitivity of 81.9% and specificity of 97.9%. The\ncross-validated area under the curve (AUC) was 0.97. The five most useful\nroutine blood parameters for COVID19 diagnosis according to the feature\nimportance scoring of the XGBoost algorithm were MCHC, eosinophil count,\nalbumin, INR, and prothrombin activity percentage. tSNE visualization showed\nthat the blood parameters of the patients with severe COVID-19 course are more\nlike the parameters of bacterial than viral infection. The reported diagnostic\naccuracy is at least comparable and probably complementary to RT-PCR and chest\nCT studies. Patients with fever, cough, myalgia, and other symptoms can now\nhave initial routine blood tests assessed by our diagnostic tool. All patients\nwith a positive COVID-19 prediction would then undergo standard RT-PCR studies\nto confirm the diagnosis. We believe that our results present a significant\ncontribution to improvements in COVID-19 diagnosis."
    },
    {
      "paper_id": "2006.03913v2",
      "title": "A computer simulation protocol to assess the accuracy of a Radio\n  Stereometric Analysis (RSA) image processor according to the ISO-5725",
      "subject": [
        "physics.med-ph",
        "physics.app-ph",
        "physics.data-an"
      ],
      "abstract": "Radio-Stereometric-Analysis and x-ray fluoroscopy are radiological techniques\nthat require dedicated software to process data. The accurate calibration of\nthese software is therefore critical. The aim of this work is to produce a\nprotocol for evaluating the softwares' accuracy according to the ISO-5725. A\nseries of computer simulations of the radiological setup and images were\nemployed. The noise level of the images was also changed to evaluate the\naccuracy with different image qualities. The protocol was tested on a custom\nsoftware developed by the authors. Radiological scene reconstruction accuracy\nwas of (0.092 +- 0.14) mm for tube position, and (0.38 +- 0.31) mm / (2.09 +-\n1.39) deg for detectors oriented in a direction other than the source-detector\ndirection. In the source-detector direction the accuracy was of (2.68 +- 3.08)\nmm for tube position, and of (0.16 +- 0.27) mm / (0.075 +- 1.16) deg for the\ndetectors. These disparate results are widely discussed in the literature.\nModel positioning and orientation was also highly accurate: (0.22 +- 0.46) mm /\n(0.26 +- 0.22) deg. Accuracy was not affected by the noise level. The protocol\nwas able to assess the accuracy of the RSA system. It was also useful to detect\nand fix hidden bugs. It was also useful to detect and resolve hidden bugs in\nthe software, and in optimizing the algorithms."
    }
  ],
  [
    {
      "paper_id": "1112.2638v1",
      "title": "Dual representations for general multiple stopping problems",
      "subject": [
        "q-fin.CP",
        "q-fin.PR"
      ],
      "abstract": "In this paper, we study the dual representation for generalized multiple\nstopping problems, hence the pricing problem of general multiple exercise\noptions. We derive a dual representation which allows for cashflows which are\nsubject to volume constraints modeled by integer valued adapted processes and\nrefraction periods modeled by stopping times. As such, this extends the works\nby Schoenmakers (2010), Bender (2011a), Bender (2011b), Aleksandrov and Hambly\n(2010), and Meinshausen and Hambly (2004) on multiple exercise options, which\neither take into consideration a refraction period or volume constraints, but\nnot both simultaneously. We also allow more flexible cashflow structures than\nthe additive structure in the above references. For example some exponential\nutility problems are covered by our setting. We supplement the theoretical\nresults with an explicit Monte Carlo algorithm for constructing confidence\nintervals for the price of multiple exercise options and exemplify it by a\nnumerical study on the pricing of a swing option in an electricity market."
    },
    {
      "paper_id": "1112.4534v1",
      "title": "An application of the method of moments to volatility estimation using\n  daily high, low, opening and closing prices",
      "subject": [
        "q-fin.ST",
        "q-fin.PR"
      ],
      "abstract": "We use the expectation of the range of an arithmetic Brownian motion and the\nmethod of moments on the daily high, low, opening and closing prices to\nestimate the volatility of the stock price. The daily price jump at the opening\nis considered to be the result of the unobserved evolution of an after-hours\nvirtual trading day.The annualized volatility is used to calculate\nBlack-Scholes prices for European options, and a trading strategy is devised to\nprofit when these prices differ flagrantly from the market prices."
    }
  ],
  [
    {
      "paper_id": "2008.06437v1",
      "title": "Stochastic approach to entropy production in chemical chaos",
      "subject": [
        "nlin.CD",
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ],
      "abstract": "Methods are presented to evaluate the entropy production rate in stochastic\nreactive systems. These methods are shown to be consistent with known results\nfrom nonequilibrium chemical thermodynamics. Moreover, it is proved that the\ntime average of the entropy production rate can be decomposed into the\ncontributions of the cycles obtained from the stoichiometric matrix in both\nstochastic processes and deterministic systems. These methods are applied to a\ncomplex reaction network constructed on the basis of Roessler's reinjection\nprinciple and featuring chemical chaos."
    },
    {
      "paper_id": "2008.07419v1",
      "title": "Semiclassical treatment of quantum chaotic transport with a tunnel\n  barrier",
      "subject": [
        "nlin.CD",
        "cond-mat.mes-hall",
        "math-ph"
      ],
      "abstract": "We consider the problem of a semiclassical description of quantum chaotic\ntransport, when a tunnel barrier is present in one of the leads. Using a\nsemiclassical approach formulated in terms of a matrix model, we obtain\ntransport moments as power series in the reflection probability of the barrier,\nwhose coefficients are rational functions of the number of open channels M. Our\nresults are therefore valid in the quantum regime and not only when $M\\gg 1$.\nThe expressions we arrive at are not identical with the corresponding\npredictions from random matrix theory, but are in fact much simpler. Both\ntheories agree as far as we can test."
    }
  ],
  [
    {
      "paper_id": "2003.01809v1",
      "title": "Numerical Solution of Dynamic Portfolio Optimization with Transaction\n  Costs",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We apply numerical dynamic programming techniques to solve discrete-time\nmulti-asset dynamic portfolio optimization problems with proportional\ntransaction costs and shorting/borrowing constraints. Examples include problems\nwith multiple assets, and many trading periods in a finite horizon problem. We\nalso solve dynamic stochastic problems, with a portfolio including one\nrisk-free asset, an option, and its underlying risky asset, under the existence\nof transaction costs and constraints. These examples show that it is now\ntractable to solve such problems."
    },
    {
      "paper_id": "2003.06987v1",
      "title": "Degrees of displacement: The impact of household PV battery prosumage on\n  utility generation and storage",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Reductions in the cost of PV and batteries encourage households to invest in\nPV battery prosumage. We explore the implications for the rest of the power\nsector by applying two open-source techno-economic models to scenarios in\nWestern Australia for the year 2030. Household PV capacity generally\nsubstitutes utility PV, but slightly less so as additional household batteries\nare installed. Wind power is less affected, especially in scenarios with higher\nshares of renewables. With household batteries operating to maximise\nself-consumption, utility battery capacities are hardly substituted. Wholesale\nprices to supply households, including those not engaging in prosumage,\nslightly decrease, while prices for other consumers slightly increase. We\nconclude that the growth of prosumage has implications on the various elements\nof the power sector and should be more thoroughly considered by investors,\nregulators, and power sector planners."
    }
  ],
  [
    {
      "paper_id": "1511.08621v2",
      "title": "Pfcrmp May Play a Key Role in Chloroquine Antimalarial Action and\n  Resistance Development",
      "subject": [
        "q-bio.SC",
        "q-bio.GN"
      ],
      "abstract": "It was proposed earlier that Pfcrmp (Plasmodium falciparum chloroquine\nresistance marker protein) may be the chloroquine's target protein in nucleus.\nIn this communication, further evidence is presented to support the view that\nPfcrmp may play a key role in chloroquine antimalarial actions as well as\nresistance development."
    },
    {
      "paper_id": "1511.09076v1",
      "title": "Mechanism of dynamic reorientation of cortical microtubules due to\n  mechanical stress",
      "subject": [
        "q-bio.SC"
      ],
      "abstract": "Directional growth caused by gravitropism and corresponding bending of plant\ncells has been explored since 19th century, however, many aspects of mechanisms\nunderlying the perception of gravity at the molecular level are still not well\nknown. Perception of gravity in root and shoot gravitropisms is usually\nattributed to gravisensitive cells, called statocytes, which exploit\nsedimentation of macroscopic and heavy organelles, amyloplasts, to sense the\ndirection of gravity. Gravity stimulus is then transduced into distal\nelongation zone, which is several mm far from statocytes, where it causes\nstretching. It is suggested that gravity stimulus is conveyed by gradients in\nauxin flux. We propose a theoretical model that may explain how concentration\ngradients and/or stretching may indirectly affect the global orientation of\ncortical microtubules, attached to the cell membrane and induce their dynamic\nreorientation perpendicular to the gradients. In turn, oriented microtubules\narrays direct the growth and orientation of cellulose microfibrils, forming\npart of the cell external skeleton and determine the shape of the cell.\nReorientation of microtubules is also observed in reaction to light in\nphototropism and mechanical bending, thus suggesting universality of the\nproposed mechanism."
    }
  ],
  [
    {
      "paper_id": "2204.03718v2",
      "title": "First-passage times in complex energy landscapes: a case study with\n  nonmuscle myosin II assembly",
      "subject": [
        "q-bio.SC",
        "q-bio.BM"
      ],
      "abstract": "Complex energy landscapes often arise in biological systems, e.g. for protein\nfolding, biochemical reactions or intracellular transport processes. Their\nphysical effects are often reflected in the first-passage times arising from\nthese energy landscapes. However, their calculation is notoriously challenging\nand it is often difficult to identify the most relevant features of a given\nenergy landscape. Here we show how this can be achieved by coarse-graining the\nFokker-Planck equation to a master equation and decomposing its first-passage\ntimes in an iterative process. We apply this method to the electrostatic\ninteraction between two rods of nonmuscle myosin II (NM2), which is the main\nmolecular motor for force generation in nonmuscle cells. Energy landscapes are\ncomputed directly from the amino acid sequences of the three different\nisoforms. Our approach allows us to identify the most relevant energy barriers\nfor their self-assembly into nonmuscle myosin II minifilaments and how they\nchange under force. In particular, we find that antiparallel configurations are\nmore stable than parallel ones, but also show more changes under mechanical\nloading. Our work demonstrates the rich dynamics that can be expected for\nNM2-assemblies under mechanical load and in general shows how one can identify\nthe most relevant energy barriers in complex energy landscapes."
    },
    {
      "paper_id": "2204.12623v1",
      "title": "SANA: Cross-Species Prediction of Gene Ontology GO Annotations via\n  Topological Network Alignment",
      "subject": [
        "q-bio.MN",
        "q-bio.BM",
        "q-bio.SC"
      ],
      "abstract": "Topological network alignment aims to align two networks node-wise in order\nto maximize the observed common connection (edge) topology between them. The\ntopological alignment of two Protein-Protein Interaction (PPI) networks should\nthus expose protein pairs with similar interaction partners allowing, for\nexample, the prediction of common Gene Ontology (GO) terms. Unfortunately, no\nnetwork alignment algorithm based on topology alone has been able to achieve\nthis aim, though those that include sequence similarity have seen some success.\nWe argue that this failure of topology alone is due to the sparsity and\nincompleteness of the PPI network data of almost all species, which provides\nthe network topology with a small signal-to-noise ratio that is effectively\nswamped when sequence information is added to the mix. Here we show that the\nweak signal can be detected using multiple stochastic samples of \"good\"\ntopological network alignments, which allows us to observe regions of the two\nnetworks that are robustly aligned across multiple samples. The resulting\nNetwork Alignment Frequency (NAF) strongly correlates with GO-based Resnik\nsemantic similarity and enables the first successful cross-species predictions\nof GO terms based on topology-only network alignments. Our best predictions\nhave an AUPR of about 0.4, which is competitive with state-of-the-art\nalgorithms, even when there is no observable sequence similarity and no known\nhomology relationship. While our results provide only a \"proof of concept\" on\nexisting network data, we hypothesize that predicting GO terms from\ntopology-only network alignments will become increasingly practical as the\nvolume and quality of PPI network data increase."
    }
  ],
  [
    {
      "paper_id": "1111.1113v2",
      "title": "Copula-based Hierarchical Aggregation of Correlated Risks. The behaviour\n  of the diversification benefit in Gaussian and Lognormal Trees",
      "subject": [
        "q-fin.RM",
        "q-fin.CP",
        "q-fin.ST"
      ],
      "abstract": "The benefits of diversifying risks are difficult to estimate quantitatively\nbecause of the uncertainties in the dependence structure between the risks.\nAlso, the modelling of multidimensional dependencies is a non-trivial task.\nThis paper focuses on one such technique for portfolio aggregation, namely the\naggregation of risks within trees, where dependencies are set at each step of\nthe aggregation with the help of some copulas. We define rigorously this\nprocedure and then study extensively the Gaussian Tree of quite arbitrary size\nand shape, where individual risks are normal, and where the Gaussian copula is\nused. We derive exact analytical results for the diversification benefit of the\nGaussian tree as a function of its shape and of the dependency parameters.\n  Such a \"toy-model\" of an aggregation tree enables one to understand the basic\nphenomena's at play while aggregating risks in this way. In particular, it is\nshown that, for a fixed number of individual risks, \"thin\" trees diversify\nbetter than \"fat\" trees. Related to this, it is shown that hierarchical trees\nhave the natural tendency to lower the overall dependency with respect to the\ndependency parameter chosen at each step of the aggregation. We also show that\nthese results hold in more general cases outside the gaussian world, and apply\nnotably to more realistic portfolios (LogNormal trees). We believe that any\ninsurer or reinsurer using such a tool should be aware of these systematic\neffects, and that this awareness should strongly call for designing trees that\nadequately fit the business.\n  We finally address the issue of specifying the full joint distribution\nbetween the risks. We show that the hierarchical mechanism does not require nor\nspecify the joint distribution, but that the latter can be determined exactly\n(in the Gaussian case) by adding conditional independence hypotheses between\nthe risks and their sums."
    },
    {
      "paper_id": "1111.2584v1",
      "title": "Numerical Solutions of Optimal Risk Control and Dividend Optimization\n  Policies under A Generalized Singular Control Formulation",
      "subject": [
        "q-fin.CP",
        "q-fin.RM"
      ],
      "abstract": "This paper develops numerical methods for finding optimal dividend pay-out\nand reinsurance policies. A generalized singular control formulation of surplus\nand discounted payoff function are introduced, where the surplus is modeled by\na regime-switching process subject to both regular and singular controls. To\napproximate the value function and optimal controls, Markov chain approximation\ntechniques are used to construct a discrete-time controlled Markov chain with\ntwo components. The proofs of the convergence of the approximation sequence to\nthe surplus process and the value function are given. Examples of proportional\nand excess-of-loss reinsurance are presented to illustrate the applicability of\nthe numerical methods."
    }
  ],
  [
    {
      "paper_id": "1910.04868v2",
      "title": "Estimating localized complexity of white-matter wiring with GANs",
      "subject": [
        "eess.IV"
      ],
      "abstract": "In-vivo examination of the physical connectivity of axonal projections\nthrough the white matter of the human brain is made possible by diffusion\nweighted magnetic resonance imaging (dMRI) Analysis of dMRI commonly considers\nderived scalar metrics such as fractional anisotrophy as proxies for \"white\nmatter integrity,\" and differences of such measures have been observed as\nsignificantly correlating with various neurological diagnosis and clinical\nmeasures such as executive function, presence of multiple sclerosis, and\ngenetic similarity. The analysis of such voxel measures is confounded in areas\nof more complicated fiber wiring due to crossing, kissing, and dispersing\nfibers. Recently, Volz et al. introduced a simple probabilistic measure of the\ncount of distinct fiber populations within a voxel, which was shown to reduce\nvariance in group comparisons. We propose a complementary measure that\nconsiders the complexity of a voxel in context of its local region, with an aim\nto quantify the localized wiring complexity of every part of white matter. This\nallows, for example, identification of particularly ambiguous regions of the\nbrain for tractographic approaches of modeling global wiring connectivity. Our\nmethod builds on recent advances in image inpainting, in which the task is to\nplausibly fill in a missing region of an image. Our proposed method builds on a\nBayesian estimate of heteroscedastic aleatoric uncertainty of a region of white\nmatter by inpainting it from its context. We define the localized wiring\ncomplexity of white matter as how accurately and confidently a well-trained\nmodel can predict the missing patch. In our results, we observe low aleatoric\nuncertainty along major neuronal pathways which increases at junctions and\ntowards cortex boundaries. This directly quantifies the difficulty of lesion\ninpainting of dMRI images at all parts of white matter."
    },
    {
      "paper_id": "1910.06741v1",
      "title": "Adaptive template systems: Data-driven feature selection for learning\n  with persistence diagrams",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Feature extraction from persistence diagrams, as a tool to enrich machine\nlearning techniques, has received increasing attention in recent years. In this\npaper we explore an adaptive methodology to localize features in persistent\ndiagrams, which are then used in learning tasks. Specifically, we investigate\nthree algorithms, CDER, GMM and HDBSCAN, to obtain adaptive template\nfunctions/features. Said features are evaluated in three classification\nexperiments with persistence diagrams. Namely, manifold, human shapes and\nprotein classification. The main conclusion of our analysis is that adaptive\ntemplate systems, as a feature extraction technique, yield competitive and\noften superior results in the studied examples. Moreover, from the adaptive\nalgorithms here studied, CDER consistently provides the most reliable and\nrobust adaptive featurization."
    }
  ],
  [
    {
      "paper_id": "1101.1415v1",
      "title": "Bayesian semiparametric inference for multivariate\n  doubly-interval-censored data",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Based on a data set obtained in a dental longitudinal study, conducted in\nFlanders (Belgium), the joint time to caries distribution of permanent first\nmolars was modeled as a function of covariates. This involves an analysis of\nmultivariate continuous doubly-interval-censored data since: (i) the emergence\ntime of a tooth and the time it experiences caries were recorded yearly, and\n(ii) events on teeth of the same child are dependent. To model the joint\ndistribution of the emergence times and the times to caries, we propose a\ndependent Bayesian semiparametric model. A major feature of the proposed\napproach is that survival curves can be estimated without imposing assumptions\nsuch as proportional hazards, additive hazards, proportional odds or\naccelerated failure time."
    },
    {
      "paper_id": "1101.1421v1",
      "title": "Sparse modeling of categorial explanatory variables",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Shrinking methods in regression analysis are usually designed for metric\npredictors. In this article, however, shrinkage methods for categorial\npredictors are proposed. As an application we consider data from the Munich\nrent standard, where, for example, urban districts are treated as a categorial\npredictor. If independent variables are categorial, some modifications to usual\nshrinking procedures are necessary. Two $L_1$-penalty based methods for factor\nselection and clustering of categories are presented and investigated. The\nfirst approach is designed for nominal scale levels, the second one for ordinal\npredictors. Besides applying them to the Munich rent standard, methods are\nillustrated and compared in simulation studies."
    }
  ],
  [
    {
      "paper_id": "2205.09890v2",
      "title": "Replicating Portfolios: Constructing Permissionless Derivatives",
      "subject": [
        "q-fin.CP",
        "q-fin.PR"
      ],
      "abstract": "The current design space of derivatives in Decentralized Finance (DeFi)\nrelies heavily on oracle systems. Replicating market makers (RMMs) provide a\nmechanism for converting specific payoff functions to an associated Constant\nFunction Market Makers (CFMMs). We leverage RMMs to replicate the approximate\npayoff of a Black-Scholes covered call option. RMM-01 is the first\nimplementation of an on-chain expiring option mechanism that relies on\narbitrage rather than an external oracle for price. We provide frameworks for\nderivative instruments and structured products achievable on-chain without\nrelying on oracles. We construct long and binary options and briefly discuss\nperpetual covered call strategies commonly referred to as \"theta vaults.\"\nMoreover, we introduce a procedure to eliminate liquidation risk in lending\nmarkets. The results suggest that CFMMs are essential for structured product\ndesign with minimized trust dependencies."
    },
    {
      "paper_id": "2205.13321v2",
      "title": "A new self-exciting jump-diffusion process for option pricing",
      "subject": [
        "q-fin.PR",
        "q-fin.CP"
      ],
      "abstract": "We propose a new jump-diffusion process, the Heston-Queue-Hawkes (HQH) model,\ncombining the well-known Heston model and the recently introduced Queue-Hawkes\n(Q-Hawkes) jump process. Like the Hawkes process, the HQH model can capture the\neffects of self-excitation and contagion. However, since the characteristic\nfunction of the HQH process is known in closed-form, Fourier-based fast pricing\nalgorithms, like the COS method, can be fully exploited with this model.\nFurthermore, we show that by using partial integrals of the characteristic\nfunction, which are also explicitly known for the HQH process, we can reduce\nthe dimensionality of the COS method, and so its numerical complexity.\nNumerical results for European and Bermudan options show that the HQH model\noffers a wider range of volatility smiles compared to the Bates model, while\nits computational burden is considerably smaller than that of the Heston-Hawkes\n(HH) process."
    }
  ],
  [
    {
      "paper_id": "2001.05095v2",
      "title": "Production externalities and dispersion process in a multi-region\n  economy",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We consider an economic geography model with two inter-regional proximity\nstructures: one governing goods trade and the other governing production\nexternalities across regions. We investigate how the introduction of the latter\naffects the timing of endogenous agglomeration and the spatial distribution of\nworkers across regions. As transportation costs decline, the economy undergoes\na progressive dispersion process. Mono-centric agglomeration emerges when\ninter-regional trade and/or production externalities incur high transportation\ncosts, while uniform dispersion occurs when these costs become negligibly small\n(i.e., when distance dies). In multi-regional geography, the network structure\nof production externalities can determine the geographical distribution of\nworkers as economic integration increases. If production externalities are\ngoverned solely by geographical distance, a mono-centric spatial distribution\nemerges in the form of suburbanization. However, if geographically distant\npairs of regions are connected through tight production linkages, multi-centric\nspatial distribution can be sustainable."
    },
    {
      "paper_id": "2001.06052v1",
      "title": "Recovering Network Structure from Aggregated Relational Data using\n  Penalized Regression",
      "subject": [
        "econ.EM",
        "econ.GN"
      ],
      "abstract": "Social network data can be expensive to collect. Breza et al. (2017) propose\naggregated relational data (ARD) as a low-cost substitute that can be used to\nrecover the structure of a latent social network when it is generated by a\nspecific parametric random effects model. Our main observation is that many\neconomic network formation models produce networks that are effectively\nlow-rank. As a consequence, network recovery from ARD is generally possible\nwithout parametric assumptions using a nuclear-norm penalized regression. We\ndemonstrate how to implement this method and provide finite-sample bounds on\nthe mean squared error of the resulting estimator for the distribution of\nnetwork links. Computation takes seconds for samples with hundreds of\nobservations. Easy-to-use code in R and Python can be found at\nhttps://github.com/mpleung/ARD."
    }
  ],
  [
    {
      "paper_id": "0907.4680v1",
      "title": "Network motifs come in sets: correlations in the randomization process",
      "subject": [
        "q-bio.MN",
        "q-bio.QM"
      ],
      "abstract": "The identification of motifs--subgraphs that appear significantly more often\nin a particular network than in an ensemble of randomized networks--has become\na ubiquitous method for uncovering potentially important subunits within\nnetworks drawn from a wide variety of fields. We find that the most common\nalgorithms used to generate the ensemble from the real network change subgraph\ncounts in a highly correlated manner, so that one subgraph's status as a motif\nmay not be independent from the statuses of the other subgraphs. We demonstrate\nthis effect for the problem of 3- and 4-node motif identification in the\ntranscriptional regulatory networks of E. coli and S. cerevisiae in which\nrandomized networks are generated via an edge-swapping algorithm (Milo et al.,\nScience 298:824, 2002). We show that correlations among 3-node subgraphs are\neasily interpreted, and we present an information-theoretic tool that may be\nused to identify correlations among subgraphs of any size."
    },
    {
      "paper_id": "0908.0146v1",
      "title": "Inferring genetic networks: An information theoretic approach",
      "subject": [
        "q-bio.MN",
        "q-bio.QM"
      ],
      "abstract": "In the postgenome era many efforts have been dedicated to systematically\nelucidate the complex web of interacting genes and proteins. These efforts\ninclude experimental and computational methods. Microarray technology offers an\nopportunity for monitoring gene expression level at the genome scale. By\nrecourse to information theory, this study proposes a mathematical approach to\nreconstruct gene regulatory networks at coarse-grain level from high throughput\ngene expression data. The method provides the {\\it a posteriori} probability\nthat a given gene regulates positively, negatively or does not regulate each\none of the network genes. This approach also allows the introduction of prior\nknowledge and the quantification of the information gain from experimental data\nused in the inference procedure. This information gain can be used to chose\ngenes to be perturbed in subsequent experiments in order to refine the\nknowledge about the architecture of an underlying gene regulatory network. The\nperformance of the proposed approach has been studied by {\\it in numero}\nexperiments. Our results suggest that the approach is suitable for focusing on\nsize-limited problems, such as, recovering a small subnetwork of interest by\nperforming perturbation over selected genes."
    }
  ],
  [
    {
      "paper_id": "2210.07129v1",
      "title": "Economic incentives for capacity reductions on interconnectors in the\n  day-ahead market",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We consider a zonal international power market and investigate potential\neconomic incentives for short-term reductions of transmission capacities on\nexisting interconnectors by the responsible transmission system operators\n(TSOs). We show that if a TSO aims to maximize domestic total welfare, it often\nhas an incentive to reduce the capacity on the interconnectors to neighboring\ncountries.\n  In contrast with the (limited) literature on this subject, which focuses on\nincentives through the avoidance of future balancing costs, we show that\nincentives can exist even if one ignores balancing and focuses solely on\nwelfare gains in the day-ahead market itself. Our analysis consists of two\nparts. In the first part, we develop an analytical framework that explains why\nthese incentives exist. In particular, we distinguish two mechanisms: one based\non price differences with neighboring countries and one based on the domestic\nelectricity price. In the second part, we perform numerical experiments using a\nmodel of the Northern-European power system, focusing on the Danish TSO. In 97%\nof the historical hours tested, we indeed observe economic incentives for\ncapacity reductions, leading to significant welfare gains for Denmark and\nwelfare losses for the system as a whole. We show that the potential for\nwelfare gains greatly depends on the ability of the TSO to adapt interconnector\ncapacities to short-term market conditions. Finally, we explore the extent to\nwhich the recently introduced European \"70%-rule\" can mitigate the incentives\nfor capacity reductions and their welfare effects."
    },
    {
      "paper_id": "2210.08785v1",
      "title": "Welfare estimations from imagery. A test of domain experts ability to\n  rate poverty from visual inspection of satellite imagery",
      "subject": [
        "econ.GN"
      ],
      "abstract": "The present study uses domain experts to estimate welfare levels and\nindicators from high-resolution satellite imagery. We use the wealth quintiles\nfrom the 2015 Tanzania DHS dataset as ground truth data. We analyse the\nperformance of the visual estimation of relative wealth at the cluster level\nand compare these with wealth rankings from the DHS survey of 2015 for that\ncountry using correlations, ordinal regressions and multinomial logistic\nregressions. Of the 608 clusters, 115 received the same ratings from human\nexperts and the independent DHS rankings. For 59 percent of the clusters,\nexperts ratings were slightly lower. On the one hand, significant positive\npredictors of wealth are the presence of modern roofs and wider roads. For\ninstance, the log odds of receiving a rating in a higher quintile on the wealth\nrankings is 0.917 points higher on average for clusters with buildings with\nslate or tile roofing compared to those without. On the other hand, significant\nnegative predictors included poor road coverage, low to medium greenery\ncoverage, and low to medium building density. Other key predictors from the\nmultinomial regression model include settlement structure and farm sizes. These\nfindings are significant to the extent that these correlates of wealth and\npoverty are visually readable from satellite imagery and can be used to train\nmachine learning models in poverty predictions. Using these features for\ntraining will contribute to more transparent ML models and, consequently,\nexplainable AI."
    }
  ],
  [
    {
      "paper_id": "2103.13039v1",
      "title": "Note on the offspring distribution for group testing in the linear\n  regime",
      "subject": [
        "cs.IT",
        "cs.DM"
      ],
      "abstract": "The group testing problem is concerned with identifying a small set of $k$\ninfected individuals in a large population of $n$ people. At our disposal is a\ntesting scheme that can test groups of individuals. A test comes back positive\nif and only if at least one individual is infected. In this note, we lay\ngroundwork for analysing belief propagation for group testing when $k$ scales\nlinearly in $n$. To this end, we derive the offspring distribution for\ndifferent types of individuals. With these distributions at hand, one can\nemploy the population dynamics algorithm to simulate the posterior marginal\ndistribution resulting from belief propagation."
    },
    {
      "paper_id": "2103.14599v1",
      "title": "Minimum Scan Cover and Variants -- Theory and Experiments",
      "subject": [
        "cs.CG",
        "cs.CC",
        "cs.DM"
      ],
      "abstract": "We consider a spectrum of geometric optimization problems motivated by\ncontexts such as satellite communication and astrophysics. In the problem\nMinimum Scan Cover with Angular Costs, we are given a graph $G$ that is\nembedded in Euclidean space. The edges of $G$ need to be scanned, i.e., probed\nfrom both of their vertices. In order to scan their edge, two vertices need to\nface each other; changing the heading of a vertex incurs some cost in terms of\nenergy or rotation time that is proportional to the corresponding rotation\nangle. Our goal is to compute schedules that minimize the following objective\nfunctions: (i) in Minimum Makespan Scan Cover (MSC-MS), this is the time until\nall edges are scanned; (ii) in Minimum Total Energy Scan Cover (MSC-TE), the\nsum of all rotation angles; (iii) in Minimum Bottleneck Energy Scan Cover\n(MSC-BE), the maximum total rotation angle at one vertex.\n  Previous theoretical work on MSC-MS revealed a close connection to graph\ncoloring and the cut cover problem, leading to hardness and approximability\nresults. In this paper, we present polynomial-time algorithms for 1D instances\nof MSC-TE and MSC-BE, but NP-hardness proofs for bipartite 2D instances. For\nbipartite graphs in 2D, we also give 2-approximation algorithms for both MSC-TE\nand MSC-BE. Most importantly, we provide a comprehensive study of practical\nmethods for all three problems. We compare three different mixed-integer\nprogramming and two constraint programming approaches, and show how to compute\nprovably optimal solutions for geometric instances with up to 300 edges.\nAdditionally, we compare the performance of different meta-heuristics for even\nlarger instances."
    }
  ],
  [
    {
      "paper_id": "1103.5716v1",
      "title": "Star-covering properties: generalized $\u03a8$-spaces, countability\n  conditions, reflection",
      "subject": [
        "math.GN"
      ],
      "abstract": "We investigate star-covering properties of $\\Psi$-like spaces. We show\nstar-Lindel\\\"ofness is reflected by open perfect mappings. In addition, we\noffer a new equivalence of CH."
    },
    {
      "paper_id": "1104.2793v1",
      "title": "Lindelof spaces which are indestructible, productive, or D",
      "subject": [
        "math.GN"
      ],
      "abstract": "We discuss relationships in Lindelof spaces among the properties\n\"indestructible\", \"productive\", \"D\", and related properties."
    }
  ],
  [
    {
      "paper_id": "2002.09926v1",
      "title": "CATCH: Characterizing and Tracking Colloids Holographically using deep\n  neural networks",
      "subject": [
        "eess.IV"
      ],
      "abstract": "In-line holographic microscopy provides an unparalleled wealth of information\nabout the properties of colloidal dispersions. Analyzing one colloidal\nparticle's hologram with the Lorenz-Mie theory of light scattering yields the\nparticle's three-dimensional position with nanometer precision while\nsimultaneously reporting its size and refractive index with part-per-thousand\nresolution. Analyzing a few thousand holograms in this way provides a\ncomprehensive picture of the particles that make up a dispersion, even for\ncomplex multicomponent systems. All of this valuable information comes at the\ncost of three computationally expensive steps: (1) identifying and localizing\nfeatures of interest within recorded holograms, (2) estimating each particle's\nproperties based on characteristics of the associated features, and finally (3)\noptimizing those estimates through pixel-by-pixel fits to a generative model.\nHere, we demonstrate an end-to-end implementation that is based entirely on\nmachine-learning techniques. Characterizing and Tracking Colloids\nHolographically (CATCH) with deep convolutional neural networks is fast enough\nfor real-time applications and otherwise outperforms conventional analytical\nalgorithms, particularly for heterogeneous and crowded samples. We demonstrate\nthis system's capabilities with experiments on free-flowing and holographically\ntrapped colloidal spheres."
    },
    {
      "paper_id": "2002.10032v3",
      "title": "Generalized Octave Convolutions for Learned Multi-Frequency Image\n  Compression",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Learned image compression has recently shown the potential to outperform the\nstandard codecs. State-of-the-art rate-distortion (R-D) performance has been\nachieved by context-adaptive entropy coding approaches in which hyperprior and\nautoregressive models are jointly utilized to effectively capture the spatial\ndependencies in the latent representations. However, the latents are feature\nmaps of the same spatial resolution in previous works, which contain some\nredundancies that affect the R-D performance. In this paper, we propose the\nfirst learned multi-frequency image compression and entropy coding approach\nthat is based on the recently developed octave convolutions to factorize the\nlatents into high and low frequency (resolution) components, where the low\nfrequency is represented by a lower resolution. Therefore, its spatial\nredundancy is reduced, which improves the R-D performance. Novel generalized\noctave convolution and octave transposed-convolution architectures with\ninternal activation layers are also proposed to preserve more spatial structure\nof the information. Experimental results show that the proposed scheme not only\noutperforms all existing learned methods as well as standard codecs such as the\nnext-generation video coding standard VVC (4:2:0) on the Kodak dataset in both\nPSNR and MS-SSIM. We also show that the proposed generalized octave convolution\ncan improve the performance of other auto-encoder-based computer vision tasks\nsuch as semantic segmentation and image denoising."
    }
  ],
  [
    {
      "paper_id": "2104.01127v1",
      "title": "Perpetual callable American volatility options in a mean-reverting\n  volatility model",
      "subject": [
        "q-fin.PR"
      ],
      "abstract": "This paper investigates problems associated with the valuation of callable\nAmerican volatility put options. Our approach involves modeling volatility\ndynamics as a mean-reverting 3/2 volatility process. We first propose a pricing\nformula for the perpetual American knock-out put. Under the given conditions,\nthe value of perpetual callable American volatility put options is discussed."
    },
    {
      "paper_id": "2108.05747v1",
      "title": "Comment on \"An appropriate approach to pricing european-style options\n  with the Adomian decomposition method\"",
      "subject": [
        "q-fin.PR"
      ],
      "abstract": "We show that the Adomian decomposition method proposed by Ke et al [ANZIAM J.\n\\textbf{59} (2018) 349] is just the Taylor series approach in disguise. The\nlatter approach is simpler, more straightforward and yields a recurrence\nrelation free from integrals."
    }
  ],
  [
    {
      "paper_id": "2410.20597v1",
      "title": "Extracting Alpha from Financial Analyst Networks",
      "subject": [
        "q-fin.CP"
      ],
      "abstract": "We investigate the effectiveness of a momentum trading signal based on the\ncoverage network of financial analysts. This signal builds on the key\ninformation-brokerage role financial sell-side analysts play in modern stock\nmarkets. The baskets of stocks covered by each analyst can be used to construct\na network between firms whose edge weights represent the number of analysts\njointly covering both firms. Although the link between financial analysts\ncoverage and co-movement of firms' stock prices has been investigated in the\nliterature, little effort has been made to systematically learn the most\neffective combination of signals from firms covered jointly by analysts in\norder to benefit from any spillover effect. To fill this gap, we build a\ntrading strategy which leverages the analyst coverage network using a graph\nattention network. More specifically, our model learns to aggregate information\nfrom individual firm features and signals from neighbouring firms in a\nnode-level forecasting task. We develop a portfolio based on those predictions\nwhich we demonstrate to exhibit an annualized returns of 29.44% and a Sharpe\nratio of 4.06 substantially outperforming market baselines and existing graph\nmachine learning based frameworks. We further investigate the performance and\nrobustness of this strategy through extensive empirical analysis. Our paper\nrepresents one of the first attempts in using graph machine learning to extract\nactionable knowledge from the analyst coverage network for practical financial\napplications."
    },
    {
      "paper_id": "2410.22519v1",
      "title": "Evaluating utility in synthetic banking microdata applications",
      "subject": [
        "q-fin.CP"
      ],
      "abstract": "Financial regulators such as central banks collect vast amounts of data, but\naccess to the resulting fine-grained banking microdata is severely restricted\nby banking secrecy laws. Recent developments have resulted in mechanisms that\ngenerate faithful synthetic data, but current evaluation frameworks lack a\nfocus on the specific challenges of banking institutions and microdata. We\ndevelop a framework that considers the utility and privacy requirements of\nregulators, and apply this to financial usage indices, term deposit yield\ncurves, and credit card transition matrices. Using the Central Bank of\nParaguay's data, we provide the first implementation of synthetic banking\nmicrodata using a central bank's collected information, with the resulting\nsynthetic datasets for all three domain applications being publicly available\nand featuring information not yet released in statistical disclosure. We find\nthat applications less susceptible to post-processing information loss, which\nare based on frequency tables, are particularly suited for this approach, and\nthat marginal-based inference mechanisms to outperform generative adversarial\nnetwork models for these applications. Our results demonstrate that synthetic\ndata generation is a promising privacy-enhancing technology for financial\nregulators seeking to complement their statistical disclosure, while\nhighlighting the crucial role of evaluating such endeavors in terms of utility\nand privacy requirements."
    }
  ],
  [
    {
      "paper_id": "1909.09641v3",
      "title": "Productivity propagation with networks transformation",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We model sectoral production by cascading binary compounding processes. The\nsequence of processes is discovered in a self-similar hierarchical structure\nstylized in the economy-wide networks of production. Nested substitution\nelasticities and Hicks-neutral productivity growth are measured such that the\ngeneral equilibrium feedbacks between all sectoral unit cost functions\nreplicate the transformation of networks observed as a set of two temporally\ndistant input-output coefficient matrices. We examine this system of unit cost\nfunctions to determine how idiosyncratic sectoral productivity shocks propagate\ninto aggregate macroeconomic fluctuations in light of potential network\ntransformation. Additionally, we study how sectoral productivity increments\npropagate into the dynamic general equilibrium, thereby allowing network\ntransformation and ultimately producing social benefits."
    },
    {
      "paper_id": "1909.09824v3",
      "title": "Desperate times call for desperate measures: government spending\n  multipliers in hard times",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We investigate state-dependent effects of fiscal multipliers and allow for\nendogenous sample splitting to determine whether the US economy is in a slack\nstate. When the endogenized slack state is estimated as the period of the\nunemployment rate higher than about 12 percent, the estimated cumulative\nmultipliers are significantly larger during slack periods than non-slack\nperiods and are above unity. We also examine the possibility of time-varying\nregimes of slackness and find that our empirical results are robust under a\nmore flexible framework. Our estimation results point out the importance of the\nheterogenous effects of fiscal policy and shed light on the prospect of fiscal\npolicy in response to economic shocks from the current COVID-19 pandemic."
    }
  ],
  [
    {
      "paper_id": "2312.05189v1",
      "title": "Distributed Autonomous Organizations as Public Services Supplying\n  Platform",
      "subject": [
        "cs.MA"
      ],
      "abstract": "Servizi Elaborazioni Dati SpA is a public company owned by Municipality of L\nAquila, it supplies the institution with network services and software\napplications for distributing services to citizens. The future policy of the\ncompany is to enlarge the offer of its services to nearby communities that are\nunable to set up and maintain their own network and software structures. This\npaper presents thus a possible architecture model to support small\nmunicipalities in supplying public services to citizens, with the aid of SED\nSpa. Through second level platforms based on Blockchain networks and\nMulti-agents Systems running on smart contracts, the system will focus on Waste\nTax (Ta.Ri) management system in the Fascicolo del Cittadino environment."
    },
    {
      "paper_id": "2312.07001v1",
      "title": "Stein Coverage: a Variational Inference Approach to\n  Distribution-matching Multisensor Deployment",
      "subject": [
        "cs.MA"
      ],
      "abstract": "This paper examines the spatial coverage optimization problem for multiple\nsensors in a known convex environment, where the coverage service of each\nsensor is heterogeneous and anisotropic. We introduce the Stein Coverage\nalgorithm, a distribution-matching coverage approach that aims to place sensors\nat positions and orientations such that their collective coverage distribution\nis as close as possible to the event distribution. To select the most important\nrepresentative points from the coverage event distribution, Stein Coverage\nutilizes the Stein Variational Gradient Descent (SVGD), a deterministic\nsampling method from the variational inference literature. An innovation in our\nwork is the introduction of a repulsive force between the samples in the SVGD\nalgorithm to spread the samples and avoid footprint overlap for the deployed\nsensors. After pinpointing the points of interest for deployment, Stein\nCoverage solves the multisensor assignment problem using a bipartite optimal\nmatching process. Simulations demonstrate the advantages of the Stein Coverage\nmethod compared to conventional Voronoi partitioning multisensor deployment\nmethods."
    }
  ],
  [
    {
      "paper_id": "2203.13820v3",
      "title": "Rough volatility: fact or artefact?",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "We investigate the statistical evidence for the use of `rough' fractional\nprocesses with Hurst exponent $H< 0.5$ for the modeling of volatility of\nfinancial assets, using a model-free approach. We introduce a non-parametric\nmethod for estimating the roughness of a function based on discrete sample,\nusing the concept of normalized $p$-th variation along a sequence of\npartitions. We investigate the finite sample performance of our estimator for\nmeasuring the roughness of sample paths of stochastic processes using detailed\nnumerical experiments based on sample paths of fractional Brownian motion and\nother fractional processes. We then apply this method to estimate the roughness\nof realized volatility signals based on high-frequency observations. Detailed\nnumerical experiments based on stochastic volatility models show that, even\nwhen the instantaneous volatility has diffusive dynamics with the same\nroughness as Brownian motion, the realized volatility exhibits rough behaviour\ncorresponding to a Hurst exponent significantly smaller than $0.5$. Comparison\nof roughness estimates for realized and instantaneous volatility in fractional\nvolatility models with different values of Hurst exponent shows that,\nirrespective of the roughness of the spot volatility process, realized\nvolatility always exhibits `rough' behaviour with an apparent Hurst index\n$\\hat{H}<0.5$. These results suggest that the origin of the roughness observed\nin realized volatility time-series lies in the microstructure noise rather than\nthe volatility process itself."
    },
    {
      "paper_id": "2204.00872v1",
      "title": "Calibration window selection based on change-point detection for\n  forecasting electricity prices",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "We employ a recently proposed change-point detection algorithm, the\nNarrowest-Over-Threshold (NOT) method, to select subperiods of past\nobservations that are similar to the currently recorded values. Then,\ncontrarily to the traditional time series approach in which the most recent\n$\\tau$ observations are taken as the calibration sample, we estimate\nautoregressive models only for data in these subperiods. We illustrate our\napproach using a challenging dataset - day-ahead electricity prices in the\nGerman EPEX SPOT market - and observe a significant improvement in forecasting\naccuracy compared to commonly used approaches, including the Autoregressive\nHybrid Nearest Neighbors (ARHNN) method."
    }
  ],
  [
    {
      "paper_id": "2112.10986v1",
      "title": "Shared Frailty Models Based on Cancer Data",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Traditional survival analysis techniques focus on the occurrence of failures\nover the time. During analysis of such events, ignoring the related unobserved\ncovariates or heterogeneity involved in data sample may leads us to adverse\nconsequences. In this context, frailty models are the viable choice to\ninvestigate the effect of the unobserved covariates. In this article, we assume\nthat frailty acts multiplicatively to hazard rate. We propose inverse Gaussian\n(IG) and generalized Lindley (GL) shared frailty models with generalized\nWeibull (GW) as baseline distribution in order to analyze the unobserved\nheterogeneity. To estimate the parameters in models, Bayesian paradigm of\nMarkov Chain Monte Carlo technique has been proposed. Model selection criteria\nhave been used for the comparison of models. Three different cancer data sets\nhave been analyzed using the shared frailty models. Better models have been\nsuggested for the data sets."
    },
    {
      "paper_id": "2112.11338v3",
      "title": "Role of Variable Renewable Energy Penetration on Electricity Price and\n  its Volatility Across Independent System Operators in the United States",
      "subject": [
        "stat.AP"
      ],
      "abstract": "The U.S. electrical grid has undergone substantial transformation with\nincreased penetration of wind and solar -- forms of variable renewable energy\n(VRE). Despite the benefits of VRE for decarbonization, it has garnered some\ncontroversy for inducing unwanted effects in regional electricity markets. In\nthis study, the role of VRE penetration is examined on the system electricity\nprice and price volatility based on hourly, real-time, historical data from six\nIndependent System Operators (ISOs) in the U.S. using quantile and skew\nt-distribution regressions. After correcting for temporal effects, we found an\nincrease in VRE penetration is associated with decrease in system electricity\nprice in all ISOs studied. The increase in VRE penetration is associated with\ndecrease in temporal price volatility in five out of six ISOs studied. The\nrelationships are non-linear. These results are consistent with the modern\nportfolio theory where diverse volatile assets may lead to more stable and less\nrisky portfolios."
    }
  ],
  [
    {
      "paper_id": "2409.09314v1",
      "title": "The Future of Decoding Non-Standard Nucleotides: Leveraging Nanopore\n  Sequencing for Expanded Genetic Codes",
      "subject": [
        "q-bio.GN",
        "q-bio.PE"
      ],
      "abstract": "Expanding genetic codes from natural standard nucleotides to artificial\nnon-standard nucleotides marks a significant advancement in synthetic biology,\nwith profound implications for biotechnology and medicine. Decoding the\nbiological information encoded in these non-standard nucleotides presents new\nchallenges, as traditional sequencing technologies are unable to recognize or\ninterpret novel base pairings. In this perspective, we explore the potential of\nnanopore sequencing, which is uniquely suited to decipher both standard and\nnon-standard nucleotides by directly measuring the biophysical properties of\nnucleic acids. Nanopore technology offers real-time, long-read sequencing\nwithout the need for amplification or synthesis, making it particularly\nadvantageous for expanded genetic systems like Artificially Expanded Genetic\nInformation Systems (AEGIS). We discuss how the adaptability of nanopore\nsequencing and advancements in data processing can unlock the potential of\nthese synthetic genomes and open new frontiers in understanding and utilizing\nexpanded genetic codes."
    },
    {
      "paper_id": "2409.11683v1",
      "title": "k-mer-based approaches to bridging pangenomics and population genetics",
      "subject": [
        "q-bio.PE",
        "q-bio.GN"
      ],
      "abstract": "Many commonly studied species now have more than one chromosome-scale genome\nassembly, revealing a large amount of genetic diversity previously missed by\napproaches that map short reads to a single reference. However, many species\nstill lack multiple reference genomes and correctly aligning references to\nbuild pangenomes is challenging, limiting our ability to study this missing\ngenomic variation in population genetics. Here, we argue that $k$-mers are a\ncrucial stepping stone to bridging the reference-focused paradigms of\npopulation genetics with the reference-free paradigms of pangenomics. We review\ncurrent literature on the uses of $k$-mers for performing three core components\nof most population genetics analyses: identifying, measuring, and explaining\npatterns of genetic variation. We also demonstrate how different $k$-mer-based\nmeasures of genetic variation behave in population genetic simulations\naccording to the choice of $k$, depth of sequencing coverage, and degree of\ndata compression. Overall, we find that $k$-mer-based measures of genetic\ndiversity scale consistently with pairwise nucleotide diversity ($\\pi$) up to\nvalues of about $\\pi = 0.025$ ($R^2 = 0.97$) for neutrally evolving\npopulations. For populations with even more variation, using shorter $k$-mers\nwill maintain the scalability up to at least $\\pi = 0.1$. Furthermore, in our\nsimulated populations, $k$-mer dissimilarity values can be reliably\napproximated from counting bloom filters, highlighting a potential avenue to\ndecreasing the memory burden of $k$-mer based genomic dissimilarity analyses.\nFor future studies, there is a great opportunity to further develop methods to\nidentifying selected loci using $k$-mers."
    }
  ],
  [
    {
      "paper_id": "2110.11623v3",
      "title": "Dg Loday-Pirashvili modules over Lie algebras",
      "subject": [
        "math.RA",
        "math.MP",
        "math.QA"
      ],
      "abstract": "A Loday-Pirashvili module over a Lie algebra $\\mathfrak{g}$ is a Lie algebra\nobject $\\bigl(G\\xrightarrow{X} \\mathfrak{g} \\bigr)$ in the category of linear\nmaps, or equivalently, a $\\mathfrak{g}$-module $G$ which admits a\n$\\mathfrak{g}$-equivariant linear map $X:G\\to \\mathfrak{g}$. We study dg\nLoday-Pirashvili modules over Lie algebras, which is a generalization of\nLoday-Pirashvili modules in a natural way, and establish several equivalent\ncharacterizations of dg Loday-Pirashvili modules. To provide a concise\ncharacterization, a dg Loday-Pirashvili module is a non-negative and bounded dg\n$\\mathfrak{g}$-module $V$ paired with a weak morphism of dg\n$\\mathfrak{g}$-modules $\\alpha\\colon V\\rightsquigarrow \\mathfrak{g}$. Such a dg\nLoday-Pirashvili module resolves an arbitrarily specified classical\nLoday-Pirashvili module in the sense that it exists and is unique (up to\nhomotopy). Dg Loday-Pirashvili modules can be characterized through dg\nderivations. This perspective allows the calculation of the corresponding\ntwisted Atiyah classes. By leveraging the Kapranov functor on the dg derivation\narising from a dg Loday-Pirashvili module $(V,\\alpha)$, a Leibniz$_\\infty[1]$\nalgebra structure can be derived on $\\wedge^\\bullet \\mathfrak{g}^\\vee\\otimes\nV[1]$. The binary bracket of this structure corresponds to the twisted Atiyah\ncocycle. To exemplify these intricate algebraic structures through specific\ncases, we utilize this machinery to a particular type of dg Loday-Pirashvili\nmodules stemming from Lie algebra pairs."
    },
    {
      "paper_id": "2110.12784v2",
      "title": "Representations of the super Yangians of types $A$ and $C$",
      "subject": [
        "math.RT",
        "math.MP",
        "math.QA"
      ],
      "abstract": "We classify the finite-dimensional irreducible representations of the super\nYangian associated with the orthosymplectic Lie superalgebra ${\\frak\nosp}_{2|2n}$. The classification is given in terms of the highest weights and\nDrinfeld polynomials. We also include an $R$-matrix construction of the\npolynomial evaluation modules over the Yangian associated with the Lie\nsuperalgebra ${\\frak gl}_{m|n}$, as an appendix. This is a super-version of the\nwell-known construction for the ${\\frak gl}_n$ Yangian and it relies on the\nSchur--Sergeev duality."
    }
  ],
  [
    {
      "paper_id": "1701.03709v1",
      "title": "Power and Execution Time Measurement Methodology for SDF Applications on\n  FPGA-based MPSoCs",
      "subject": [
        "cs.DC",
        "cs.OS"
      ],
      "abstract": "Timing and power consumption play an important role in the design of embedded\nsystems. Furthermore, both properties are directly related to the safety\nrequirements of many embedded systems. With regard to availability\nrequirements, power considerations are of uttermost importance for battery\noperated systems. Validation of timing and power requires observability of\nthese properties. In many cases this is difficult, because the observability is\neither not possible or requires big extra effort in the system validation\nprocess. In this paper, we present a measurement-based approach for the joint\ntiming and power analysis of Synchronous Dataflow (SDF) applications running on\na shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a\nproof-of-concept, we implement an MPSoC system with configurable power and\ntiming measurement interfaces inside a Field Programmable Gate Array (FPGA).\nOur experiments demonstrate the viability of our approach being able of\naccurately analyzing different mappings of image processing applications (Sobel\nfilter and JPEG encoder) on an FPGA-based MPSoC implementation."
    },
    {
      "paper_id": "1703.02925v1",
      "title": "Assessing Code Authorship: The Case of the Linux Kernel",
      "subject": [
        "cs.SE",
        "cs.OS",
        "cs.SI"
      ],
      "abstract": "Code authorship is a key information in large-scale open source systems.\nAmong others, it allows maintainers to assess division of work and identify key\ncollaborators. Interestingly, open-source communities lack guidelines on how to\nmanage authorship. This could be mitigated by setting to build an empirical\nbody of knowledge on how authorship-related measures evolve in successful\nopen-source communities. Towards that direction, we perform a case study on the\nLinux kernel. Our results show that: (a) only a small portion of developers (26\n%) makes significant contributions to the code base; (b) the distribution of\nthe number of files per author is highly skewed --- a small group of top\nauthors (3 %) is responsible for hundreds of files, while most authors (75 %)\nare responsible for at most 11 files; (c) most authors (62 %) have a specialist\nprofile; (d) authors with a high number of co-authorship connections tend to\ncollaborate with others with less connections."
    }
  ],
  [
    {
      "paper_id": "1806.01645v1",
      "title": "Several Conclusions on another site setting problem",
      "subject": [
        "math.GM"
      ],
      "abstract": "Let $S = \\{ {A_1},{A_2}, \\cdots ,{A_n}\\} $ be a finite point set in\nm-dimensional Euclidean space ${E^m}$, and$\\left\\| {{A_i}{A_j}} \\right\\|$ be\nthe distance between $A_i$ and $A_j$. Define $\\sigma (S) = \\sum\\limits_{1 \\le i\n< j \\le n} {\\left\\| {{A_i}{A_j}} \\right\\|} $, $D(S) = \\mathop {\\max }\\limits_{1\n\\le i < j \\le n} \\left\\{ {\\left\\| {{A_i}{A_j}} \\right\\|} \\right\\}$, $\\omega\n(m,n) = \\frac{{\\sigma (S)}}{{D(S)}}$, $\\sup \\omega (m,n) = \\max \\left\\{ {\\left.\n{\\frac{{\\sigma (S)}}{{D(S)}}} \\right|S \\subset {E^m},\\left| S \\right| = n}\n\\right\\}$. This paper proves that, for any point P in an n-dimensional simplex\n${A_1}{A_2} \\cdots {A_{n + 1}}$ in Euclidean space, $\\sum\\limits_{i = 1}^{n +\n1} {\\left\\| {P{A_i}} \\right\\|} $ <= $\\mathop {\\sup }\\limits_{{i_t},{j_t} \\in \\{\n1,2, \\cdots ,n + 1\\} } \\left\\{ {\\sum\\limits_{t = 1}^n {\\left\\|\n{{A_{{i_t}}}{A_{{j_t}}}} \\right\\|} } \\right\\}$ By using this inequality and\nseveral results in differential geometry this paper also proves that $\\sup\n\\omega (2,4) = 4 + 2\\sqrt {2 - \\sqrt 3 } $, $\\sup \\omega (n,n + 2)$ >= $C_{n +\n1}^2 + 1 + n\\sqrt {2\\left( {1 - \\sqrt {{\\textstyle{{n + 1} \\over {2n}}}} }\n\\right)} $."
    },
    {
      "paper_id": "1806.02187v1",
      "title": "Fuzzy $\u03b1$-cut and related structures",
      "subject": [
        "math.GM"
      ],
      "abstract": "This paper deals with a new notion called fuzzy $\\alpha$-cut and its\nproperties. A notion called localic frame is also introduced. Algebraic\nstructures arising out of the family of fuzzy $\\alpha$-cuts have been\ninvestigated. It will be seen that this family forms a localic frame. Some\nsignificance and usefulness of fuzzy $\\alpha$-cuts are discussed."
    }
  ],
  [
    {
      "paper_id": "q-bio/0411012v1",
      "title": "Graded and Binary Responses in Stochastic Gene Expression",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "Recently, several theoretical and experimental studies have been undertaken\nto probe the effect of stochasticity on gene expression (GE). In experiments,\nthe GE response to an inducing signal in a cell, measured by the amount of\nmRNAs/proteins synthesized, is found to be either graded or binary. The latter\ntype of response gives rise to a bimodal distribution in protein levels in an\nensemble of cells. One possible origin of binary response is cellular\nbistability achieved through positive feedback or autoregulation. In this\npaper, we study a simple, stochastic model of GE and show that the origin of\nbinary response lies exclusively in stochasticity. The transitions between the\nactive and inactive states of the gene are random in nature. Graded and binary\nresponses occur in the model depending on the relative stability of the\nactivated and deactivated gene states with respect to that of\nmRNAs/proteins.The theoretical results on binary response provide a good\ndescription of the ``all-or-none'' phenomenon observed in an eukaryotic system."
    },
    {
      "paper_id": "q-bio/0412014v1",
      "title": "Robust formation of morphogen gradients",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "We discuss the formation of graded morphogen profiles in a cell layer by\nnonlinear transport phenomena, important for patterning developing organisms.\nWe focus on a process termed transcytosis, where morphogen transport results\nfrom binding of ligands to receptors on the cell surface, incorporation into\nthe cell and subsequent externalization. Starting from a microscopic model, we\nderive effective transport equations. We show that, in contrast to morphogen\ntransport by extracellular diffusion, transcytosis leads to robust ligand\nprofiles which are insensitive to the rate of ligand production."
    }
  ],
  [
    {
      "paper_id": "1102.2878v1",
      "title": "Dual-Tree Fast Gauss Transforms",
      "subject": [
        "stat.CO",
        "stat.ML"
      ],
      "abstract": "Kernel density estimation (KDE) is a popular statistical technique for\nestimating the underlying density distribution with minimal assumptions.\nAlthough they can be shown to achieve asymptotic estimation optimality for any\ninput distribution, cross-validating for an optimal parameter requires\nsignificant computation dominated by kernel summations. In this paper we\npresent an improvement to the dual-tree algorithm, the first practical kernel\nsummation algorithm for general dimension. Our extension is based on the\nseries-expansion for the Gaussian kernel used by fast Gauss transform. First,\nwe derive two additional analytical machinery for extending the original\nalgorithm to utilize a hierarchical data structure, demonstrating the first\ntruly hierarchical fast Gauss transform. Second, we show how to integrate the\nseries-expansion approximation within the dual-tree approach to compute kernel\nsummations with a user-controllable relative error bound. We evaluate our\nalgorithm on real-world datasets in the context of optimal bandwidth selection\nin kernel density estimation. Our results demonstrate that our new algorithm is\nthe only one that guarantees a hard relative error bound and offers fast\nperformance across a wide range of bandwidths evaluated in cross validation\nprocedures."
    },
    {
      "paper_id": "1102.3176v3",
      "title": "Selecting the rank of truncated SVD by Maximum Approximation Capacity",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Truncated Singular Value Decomposition (SVD) calculates the closest rank-$k$\napproximation of a given input matrix. Selecting the appropriate rank $k$\ndefines a critical model order choice in most applications of SVD. To obtain a\nprincipled cut-off criterion for the spectrum, we convert the underlying\noptimization problem into a noisy channel coding problem. The optimal\napproximation capacity of this channel controls the appropriate strength of\nregularization to suppress noise. In simulation experiments, this information\ntheoretic method to determine the optimal rank competes with state-of-the art\nmodel selection techniques."
    }
  ],
  [
    {
      "paper_id": "2105.03656v3",
      "title": "Estimates of the social cost of carbon have increased over time",
      "subject": [
        "econ.GN"
      ],
      "abstract": "A meta-analysis of published estimates shows that the social cost of carbon\nhas increased as knowledge about climate change accumulates. Correcting for\ninflation and emission year and controlling for the discount rate, kernel\ndensity decomposition reveals a non-stationary distribution. In the last 10\nyears, estimates of the social cost of carbon have increased from $33/tC to\n$146/tC for a high discount rate and from $446/tC to $1925/tC for a low\ndiscount rate. Actual carbon prices are almost everywhere below its estimated\nvalue and should therefore go up."
    },
    {
      "paper_id": "2105.04718v1",
      "title": "Economic analysis of tidal stream turbine arrays: a review",
      "subject": [
        "econ.GN"
      ],
      "abstract": "This tidal stream energy industry has to date been comprised of small\ndemonstrator projects made up of one to a four turbines. However, there are\ncurrently plans to expand to commercially sized projects with tens of turbines\nor more. As the industry moves to large-scale arrays for the first time, there\nhas been a push to develop tools to optimise the array design and help bring\ndown the costs. This review investigates different methods of modelling the\neconomic performance of tidal-stream arrays, for use within these optimisation\ntools. The different cost reduction pathways are discussed from costs falling\nas the global installed capacity increases, due to greater experience, improved\npower curves through larger-diameter higher-rated turbines, to economic\nefficiencies that can be found by moving to large-scale arrays. A literature\nreview is conducted to establish the most appropriate input values for use in\neconomic models. This includes finding a best case, worst case and typical\nvalues for costs and other related parameters. The information collated in this\nreview can provide a useful steering for the many optimisation tools that have\nbeen developed, especially when cost information is commercially sensitive and\na realistic parameter range is difficult to obtain."
    }
  ],
  [
    {
      "paper_id": "2208.00411v1",
      "title": "Predicting Failure times for some Unobserved Events with Application to\n  Real-Life Data",
      "subject": [
        "stat.TH"
      ],
      "abstract": "This study aims to predict failure times for some units in some lifetime\nexperiments. In some practical situations, the experimenter may not be able to\nregister the failure times of all units during the experiment. Recently, this\nsituation can be described by a new type of censored data called\nmultiply-hybrid censored data. In this paper, the linear failure rate\ndistribution is well-fitted to some real-life data and hence some statistical\ninference approaches are applied to estimate the distribution parameters. A\ntwo-sample prediction approach applied to extrapolate a new sample simulates\nthe observed data for predicting the failure times for the unobserved units."
    },
    {
      "paper_id": "2208.00715v2",
      "title": "Highly Efficient Estimators with High Breakdown Point for Linear Models\n  with Structured Covariance Matrices",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We provide a unified approach to a method of estimation of the regression\nparameter in balanced linear models with a structured covariance matrix that\ncombines a high breakdown point and bounded influence with high asymptotic\nefficiency at models with multivariate normal errors. Of main interest are\nlinear mixed effects models, but our approach also includes several other\nstandard multivariate models, such as multiple regression, multivariate\nregression, and multivariate location and scatter. We provide sufficient\nconditions for the existence of the estimators and corresponding functionals,\nestablish asymptotic properties such as consistency and asymptotic normality,\nand derive their robustness properties in terms of breakdown point and\ninfluence function. All the results are obtained for general identifiable\ncovariance structures and are established under mild conditions on the\ndistribution of the observations, which goes far beyond models with\nelliptically contoured densities. Some of our results are new and others are\nmore general than existing ones in the literature. In this way this manuscript\ncompletes and improves results on high breakdown estimation with high\nefficiency in a wide variety of multivariate models."
    }
  ],
  [
    {
      "paper_id": "2403.17513v5",
      "title": "A unified framework for coarse grained molecular dynamics of proteins\n  with high-fidelity reconstruction",
      "subject": [
        "q-bio.BM"
      ],
      "abstract": "Simulating large proteins using traditional molecular dynamics (MD) is\ncomputationally demanding. To address this challenge, we propose a novel\ntree-structured coarse-grained model that efficiently captures protein\ndynamics. By leveraging a hierarchical protein representation, our model\naccurately reconstructs high-resolution protein structures, with sub-angstrom\nprecision achieved for a 168-amino acid protein. We combine this coarse-grained\nmodel with a deep learning framework based on stochastic differential equations\n(SDEs). A neural network is trained to model the drift force, while a\nRealNVP-based noise generator approximates the stochastic component. This\napproach enables a significant speedup of over 20,000 times compared to\ntraditional MD, allowing for the generation of microsecond-long trajectories\nwithin a few minutes and providing valuable insights into protein behavior. Our\nmethod demonstrates high accuracy, achieving sub-angstrom reconstruction for\nshort (25 ns) trajectories and maintaining statistical consistency across\nmultiple independent simulations."
    },
    {
      "paper_id": "2403.17954v1",
      "title": "Sort & Slice: A Simple and Superior Alternative to Hash-Based Folding\n  for Extended-Connectivity Fingerprints",
      "subject": [
        "q-bio.BM"
      ],
      "abstract": "Extended-connectivity fingerprints (ECFPs) are a ubiquitous tool in current\ncheminformatics and molecular machine learning, and one of the most prevalent\nmolecular feature extraction techniques used for chemical prediction. Atom\nfeatures learned by graph neural networks can be aggregated to compound-level\nrepresentations using a large spectrum of graph pooling methods; in contrast,\nsets of detected ECFP substructures are by default transformed into bit vectors\nusing only a simple hash-based folding procedure. We introduce a general\nmathematical framework for the vectorisation of structural fingerprints via a\nformal operation called substructure pooling that encompasses hash-based\nfolding, algorithmic substructure-selection, and a wide variety of other\npotential techniques. We go on to describe Sort & Slice, an easy-to-implement\nand bit-collision-free alternative to hash-based folding for the pooling of\nECFP substructures. Sort & Slice first sorts ECFP substructures according to\ntheir relative prevalence in a given set of training compounds and then slices\naway all but the $L$ most frequent substructures which are subsequently used to\ngenerate a binary fingerprint of desired length, $L$. We computationally\ncompare the performance of hash-based folding, Sort & Slice, and two advanced\nsupervised substructure-selection schemes (filtering and mutual-information\nmaximisation) for ECFP-based molecular property prediction. Our results\nindicate that, despite its technical simplicity, Sort & Slice robustly (and at\ntimes substantially) outperforms traditional hash-based folding as well as the\nother investigated methods across prediction tasks, data splitting techniques,\nmachine-learning models and ECFP hyperparameters. We thus recommend that Sort &\nSlice canonically replace hash-based folding as the default\nsubstructure-pooling technique to vectorise ECFPs for supervised molecular\nmachine learning."
    }
  ],
  [
    {
      "paper_id": "1411.5888v1",
      "title": "Weak convergence of the empirical copula process with respect to\n  weighted metrics",
      "subject": [
        "stat.TH"
      ],
      "abstract": "The empirical copula process plays a central role in the asymptotic analysis\nof many statistical procedures which are based on copulas or ranks. Among other\napplications, results regarding its weak convergence can be used to develop\nasymptotic theory for estimators of dependence measures or copula densities,\nthey allow to derive tests for stochastic independence or specific copula\nstructures, or they may serve as a fundamental tool for the analysis of\nmultivariate rank statistics. In the present paper, we establish weak\nconvergence of the empirical copula process (for observations that are allowed\nto be serially dependent) with respect to weighted supremum distances. The\nusefulness of our results is illustrated by applications to general bivariate\nrank statistics and to estimation procedures for the Pickands dependence\nfunction arising in multivariate extreme-value theory."
    },
    {
      "paper_id": "1411.6419v4",
      "title": "Uniform central limit theorems for the Grenander estimator",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We consider the Grenander estimator that is the maximum likelihood estimator\nfor non-increasing densities. We prove uniform central limit theorems for\ncertain subclasses of bounded variation functions and for H\\\"older balls of\nsmoothness s>1/2. We do not assume that the density is differentiable or\ncontinuous. The proof can be seen as an adaptation of the method for the\nparametric maximum likelihood estimator to the nonparametric setting. Since\nnonparametric maximum likelihood estimators lie on the boundary, the derivative\nof the likelihood cannot be expected to equal zero as in the parametric case.\nNevertheless, our proofs rely on the fact that the derivative of the likelihood\ncan be shown to be small at the maximum likelihood estimator."
    }
  ],
  [
    {
      "paper_id": "1905.12164v1",
      "title": "An Interactive Insight Identification and Annotation Framework for Power\n  Grid Pixel Maps using DenseU-Hierarchical VAE",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Insights in power grid pixel maps (PGPMs) refer to important facility\noperating states and unexpected changes in the power grid. Identifying insights\nhelps analysts understand the collaboration of various parts of the grid so\nthat preventive and correct operations can be taken to avoid potential\naccidents. Existing solutions for identifying insights in PGPMs are performed\nmanually, which may be laborious and expertise-dependent. In this paper, we\npropose an interactive insight identification and annotation framework by\nleveraging an enhanced variational autoencoder (VAE). In particular, a new\narchitecture, DenseU-Hierarchical VAE (DUHiV), is designed to learn\nrepresentations from large-sized PGPMs, which achieves a significantly tighter\nevidence lower bound (ELBO) than existing Hierarchical VAEs with a Multilayer\nPerceptron architecture. Our approach supports modulating the derived\nrepresentations in an interactive visual interface, discover potential insights\nand create multi-label annotations. Evaluations using real-world PGPMs datasets\nshow that our framework outperforms the baseline models in identifying and\nannotating insights."
    },
    {
      "paper_id": "1905.12596v1",
      "title": "Segmentation of blood vessels in retinal fundus images",
      "subject": [
        "eess.IV"
      ],
      "abstract": "In recent years, several automatic segmentation methods have been proposed\nfor blood vessels in retinal fundus images, ranging from using cheap and fast\ntrainable filters to complicated neural networks and even deep learning. One\nexample of a filted-based segmentation method is B-COSFIRE. In this approach\nthe image filter is trained with example prototype patterns, to which the\nfilter becomes selective by finding points in a Difference of Gaussian response\non circles around the center with large intensity variation. In this paper we\ndiscuss and evaluate several of these vessel segmentation methods. We take a\ncloser look at B-COSFIRE and study the performance of B-COSFIRE on the recently\npublished IOSTAR dataset by experiments and we examine how the parameter values\naffect the performance. In the experiment we manage to reach a segmentation\naccuracy of 0.9419. Based on our findings we discuss when B-COSFIRE is the\npreferred method to use and in which circumstances it could be beneficial to\nuse a more (computationally) complex segmentation method. We also shortly\ndiscuss areas beyond blood vessel segmentation where these methods can be used\nto segment elongated structures, such as rivers in satellite images or nerves\nof a leaf."
    }
  ],
  [
    {
      "paper_id": "2207.02359v1",
      "title": "L\u00e9vy models amenable to efficient calculations",
      "subject": [
        "q-fin.CP"
      ],
      "abstract": "In our previous publications (IJTAF 2019, Math. Finance 2020), we introduced\na general class of SINH-regular processes and demonstrated that efficient\nnumerical methods for the evaluation of the Wiener-Hopf factors and various\nprobability distributions (prices of options of several types) in L\\'evy models\ncan be developed using only a few general properties of the characteristic\nexponent $\\psi$. Essentially all popular L\\'evy processes enjoy these\nproperties. In the present paper, we define classes of Stieltjes-L\\'evy\nprocesses (SL-processes) as processes with completely monotone L\\'evy densities\nof positive and negative jumps, and signed Stieltjes-L\\'evy processes\n(sSL-processes) as processes with densities representable as differences of\ncompletely monotone densities. We demonstrate that 1) all crucial properties of\n$\\psi$ are consequences of the representation\n$\\psi(\\xi)=(a^+_2\\xi^2-ia^+_1\\xi)ST(\\cG_+)(-i\\xi)+(a^-_2\\xi^2+ia^-_1\\xi)ST(\\cG_-)(i\\xi)+(\\sg^2/2)\\xi^2-i\\mu\\xi$,\nwhere $ST(\\cG)$ is the Stieltjes transform of the (signed) Stieltjes measure\n$\\cG$ and $a^\\pm_j\\ge 0$; 2) essentially all popular processes other than\nMerton's model and Meixner processes areSL-processes; 3) Meixner processes are\nsSL-processes; 4) under a natural symmetry condition, essentially all popular\nclasses of L\\'evy processes are SL- or sSL-subordinated Brownian motion."
    },
    {
      "paper_id": "2207.02858v2",
      "title": "Efficient inverse $Z$-transform and pricing barrier and lookback options\n  with discrete monitoring",
      "subject": [
        "q-fin.CP"
      ],
      "abstract": "We prove simple general formulas for expectations of functions of a random\nwalk and its running extremum. Under additional conditions, we derive\nanalytical formulas using the inverse $Z$-transform, the Fourier/Laplace\ninversion and Wiener-Hopf factorization, and discuss efficient numerical\nmethods for realization of these formulas. As applications, the cumulative\nprobability distribution function of the process and its running maximum and\nthe price of the option to exchange the power of a stock for its maximum are\ncalculated. The most efficient numerical methods use a new efficient numerical\nrealization of the inverse $Z$-transform, the sinh-acceleration technique and\nsimplified trapezoid rule. The program in Matlab running on a Mac with moderate\ncharacteristics achieves the precision E-10 and better in several dozen of\nmilliseconds, and E-14 - in a fraction of a isecond."
    }
  ],
  [
    {
      "paper_id": "1810.10495v2",
      "title": "Posterior Convergence of Gaussian and General Stochastic Process\n  Regression Under Possible Misspecifications",
      "subject": [
        "stat.TH"
      ],
      "abstract": "In this article, we investigate posterior convergence in nonparametric\nregression models where the unknown regression function is modeled by some\nappropriate stochastic process. In this regard, we consider two setups. The\nfirst setup is based on Gaussian processes, where the covariates are either\nrandom or non-random and the noise may be either normally or\ndouble-exponentially distributed. In the second setup, we assume that the\nunderlying regression function is modeled by some reasonably smooth, but\nunspecified stochastic process satisfying reasonable conditions. The\ndistribution of the noise is also left unspecified, but assumed to be\nthick-tailed. As in the previous studies regarding the same problems, we do not\nassume that the truth lies in the postulated parameter space, thus explicitly\nallowing the possibilities of misspecification. We exploit the general results\nof Shalizi (2009) for our purpose and establish not only posterior consistency,\nbut also the rates at which the posterior probabilities converge, which turns\nout to be the Kullback-Leibler divergence rate. We also investigate the more\nfamiliar posterior convergence rates. Interestingly, we show that the posterior\npredictive distribution can accurately approximate the best possible predictive\ndistribution in the sense that the Hellinger distance, as well as the total\nvariation distance between the two distributions can tend to zero, in spite of\nmisspecifications."
    },
    {
      "paper_id": "1810.10633v1",
      "title": "Strong laws of large numbers for arrays of random variables and stable\n  random fields",
      "subject": [
        "stat.TH"
      ],
      "abstract": "Strong laws of large numbers are established for random fields with weak or\nstrong dependence. These limit theorems are applicable to random fields with\nheavy-tailed distributions including fractional stable random fields.\n  The conditions for SLLN are described in terms of the $p$-th moments of the\npartial sums of the random fields, which are convenient to verify. The main\ntechnical tool in this paper is a maximal inequality for the moments of partial\nsums of random fields that extends the technique of Levental, Chobanyan and\nSalehi \\cite{chobanyan-l-s} for a sequence of random variables indexed by a\none-parameter."
    }
  ],
  [
    {
      "paper_id": "2502.20417v1",
      "title": "Accurate 3D Grapevine Structure Extraction from High-Resolution Point\n  Clouds",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "Accurate 3D modelling of grapevines is crucial for precision viticulture,\nparticularly for informed pruning decisions and automated management\ntechniques. However, the intricate structure of grapevines poses significant\nchallenges for traditional skeletonization algorithms. This paper presents an\nadaptation of the Smart-Tree algorithm for 3D grapevine modelling, addressing\nthe unique characteristics of grapevine structures. We introduce a graph-based\nmethod for disambiguating skeletonization. Our method delineates individual\ncane skeletons, which are crucial for precise analysis and management. We\nvalidate our approach using annotated real-world grapevine point clouds,\ndemonstrating improvement of 15.8% in the F1 score compared to the original\nSmart-Tree algorithm. This research contributes to advancing 3D grapevine\nmodelling techniques, potentially enhancing both the sustainability and\nprofitability of grape production through more precise and automated\nviticulture practices"
    },
    {
      "paper_id": "2503.07837v1",
      "title": "Slowing translation to avoid ribosome population extinction and maintain\n  stable allocation at slow growth rates",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "To double the cellular population of ribosomes, a fraction of the active\nribosomes is allocated to synthesize ribosomal proteins. Subsequently, these\nribosomal proteins enter the ribosome self-assembly process, synthesizing new\nribosomes and forming the well-known ribosome autocatalytic subcycle.\nNeglecting ribosome lifetime and the duration of the self-assembly process, the\ndoubling rate of all cellular biomass can be equated with the fraction of\nribosomes allocated to synthesize an essential ribosomal protein times its\nsynthesis rate. However, ribosomes have a finite lifetime, and the assembly\nprocess has a finite duration. Furthermore, the number of ribosomes is known to\ndecrease with slow growth rates. The finite lifetime of ribosomes and the\ndecline in their numbers present a challenge in sustaining slow growth solely\nthrough controlling the allocation of ribosomes to synthesize more ribosomal\nproteins. When the number of ribosomes allocated per mRNA of an essential\nribosomal protein is approximately one, the resulting fluctuations in the\nproduction rate of new ribosomes increase, causing a potential risk that the\nactual production rate will fall below the ribosome death rate. Thus, in this\nregime, a significant risk of extinction of the ribosome population emerges. To\nmitigate this risk, we suggest that the ribosome translation speed is used as\nan alternative control parameter, which facilitates the maintenance of slow\ngrowth rates with a larger ribosome pool. We clarify the observed reduction in\ntranslation speed at harsh environments in E. coli and C. Glutamicum, explore\nother mitigation strategies, and suggest additional falsifiable predictions of\nour model."
    }
  ],
  [
    {
      "paper_id": "math/0605080v2",
      "title": "Equivariant operads, string topology, and Tate cohomology",
      "subject": [
        "math.AT",
        "math.GT"
      ],
      "abstract": "From an operad C with an action of a group G, we construct new operads using\nthe homotopy fixed point and orbit spectra. These new operads are shown to be\nequivalent when the generalized G-Tate cohomology of C is trivial. Applying\nthis theory to the little disk operad C_2 (which is an S^1 operad) we obtain\nvariations on Getzler's gravity operad, which we show governs the Chas-Sullivan\nstring bracket."
    },
    {
      "paper_id": "math/0605133v3",
      "title": "The fundamental group of symplectic manifolds with Hamiltonian Lie group\n  actions",
      "subject": [
        "math.AT"
      ],
      "abstract": "Let $(M, \\omega)$ be a connected, compact symplectic manifold equipped with a\nHamiltonian $G$ action, where $G$ is a connected compact Lie group. Let $\\phi$\nbe the moment map. In \\cite{L}, we proved the following result for $G=S^1$\naction: as fundamental groups of topological spaces, $\\pi_1(M)=\\pi_1(M_{red})$,\nwhere $M_{red}$ is the symplectic quotient at any value of the moment map\n$\\phi$. In this paper, we generalize this result to other connected compact Lie\ngroup $G$ actions. We also prove that the above fundamental group is isomorphic\nto that of $M/G$. We briefly discuss the generalization of the first part of\nthe results to non-compact manifolds with proper moment maps."
    }
  ],
  [
    {
      "paper_id": "physics/0503206v3",
      "title": "Neutrinos in the Electron",
      "subject": [
        "physics.gen-ph"
      ],
      "abstract": "We will show that one half of the rest mass of the electron is equal to the\nsum of the rest masses of electron neutrinos and that the other half of the\nrest mass of the electron is given by the energy in the sum of electric\noscillations. With this composition we can explain the rest mass, the electric\ncharge, the spin and the magnetic moment of the electron."
    },
    {
      "paper_id": "physics/0503207v1",
      "title": "Brownstein's Whole-Partial Derivatives: The Case of the Lorentz Gauge",
      "subject": [
        "physics.gen-ph"
      ],
      "abstract": "In this brief note we show that the usual Lorentz gauge is not satisfied by\nthe Lienard-Wiechert potentials, then, using Brownstein's concept of\n\"whole-partial\" derivatives we introduce the generalized expression for the\nLorentz gauge showing that it is satisfied by the LW-potentials."
    }
  ],
  [
    {
      "paper_id": "2305.19102v1",
      "title": "Closed ecosystems extract energy through self-organized nutrient cycles",
      "subject": [
        "q-bio.PE",
        "q-bio.MN"
      ],
      "abstract": "Our planet is roughly closed to matter, but open to energy input from the\nsun. However, to harness this energy, organisms must transform matter from one\nchemical (redox) state to another. For example, photosynthetic organisms can\ncapture light energy by carrying out a pair of electron donor and acceptor\ntransformations (e.g., water to oxygen, CO$_2$ to organic carbon). Closure of\necosystems to matter requires that all such transformations are ultimately\nbalanced, i.e., other organisms must carry out corresponding reverse\ntransformations, resulting in cycles that are coupled to each other. A\nsustainable closed ecosystem thus requires self-organized cycles of matter, in\nwhich every transformation has sufficient thermodynamic favorability to\nmaintain an adequate number of organisms carrying out that process. Here, we\npropose a new conceptual model that explains the self-organization and emergent\nfeatures of closed ecosystems. We study this model with varying levels of\nmetabolic diversity and energy input, finding that several thermodynamic\nfeatures converge across ecosystems. Specifically, irrespective of their\nspecies composition, large and metabolically diverse communities self-organize\nto extract roughly 10% of the maximum extractable energy, or 100 fold more than\nrandomized communities. Moreover, distinct communities implement energy\nextraction in convergent ways, as indicated by strongly correlated fluxes\nthrough nutrient cycles. As the driving force from light increases, however,\nthese features -- fluxes and total energy extraction -- become more variable\nacross communities, indicating that energy limitation imposes tight\nthermodynamic constraints on collective metabolism."
    },
    {
      "paper_id": "2306.08261v3",
      "title": "Strong regulatory graphs",
      "subject": [
        "q-bio.MN",
        "q-bio.QM"
      ],
      "abstract": "Logical modeling is a powerful tool in biology, offering a system-level\nunderstanding of the complex interactions that govern biological processes. A\ngap that hinders the scalability of logical models is the need to specify the\nupdate function of every vertex in the network depending on the status of its\npredecessors. To address this, we introduce in this paper the concept of strong\nregulation, where a vertex is only updated to active/inactive if all its\npredecessors agree in their influences; otherwise, it is set to ambiguous. We\nexplore the interplay between active, inactive, and ambiguous influences in a\nnetwork. We discuss the existence of phenotype attractors in such networks,\nwhere the status of some of the variables is fixed to active/inactive, while\nthe others can have an arbitrary status, including ambiguous."
    }
  ],
  [
    {
      "paper_id": "1910.11480v2",
      "title": "Parallel WaveGAN: A fast waveform generation model based on generative\n  adversarial networks with multi-resolution spectrogram",
      "subject": [
        "eess.AS",
        "eess.SP"
      ],
      "abstract": "We propose Parallel WaveGAN, a distillation-free, fast, and small-footprint\nwaveform generation method using a generative adversarial network. In the\nproposed method, a non-autoregressive WaveNet is trained by jointly optimizing\nmulti-resolution spectrogram and adversarial loss functions, which can\neffectively capture the time-frequency distribution of the realistic speech\nwaveform. As our method does not require density distillation used in the\nconventional teacher-student framework, the entire model can be easily trained.\nFurthermore, our model is able to generate high-fidelity speech even with its\ncompact architecture. In particular, the proposed Parallel WaveGAN has only\n1.44 M parameters and can generate 24 kHz speech waveform 28.68 times faster\nthan real-time on a single GPU environment. Perceptual listening test results\nverify that our proposed method achieves 4.16 mean opinion score within a\nTransformer-based text-to-speech framework, which is comparative to the best\ndistillation-based Parallel WaveNet system."
    },
    {
      "paper_id": "1910.11496v1",
      "title": "L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Modern Automatic Speech Recognition (ASR) systems primarily rely on scores\nfrom an Acoustic Model (AM) and a Language Model (LM) to rescore the N-best\nlists. With the abundance of recent natural language processing advances, the\ninformation utilized by current ASR for evaluating the linguistic and semantic\nlegitimacy of the N-best hypotheses is rather limited. In this paper, we\npropose a novel Learning-to-Rescore (L2RS) mechanism, which is specialized for\nutilizing a wide range of textual information from the state-of-the-art NLP\nmodels and automatically deciding their weights to rescore the N-best lists for\nASR systems. Specifically, we incorporate features including BERT sentence\nembedding, topic vector, and perplexity scores produced by n-gram LM, topic\nmodeling LM, BERT LM and RNNLM to train a rescoring model. We conduct extensive\nexperiments based on a public dataset, and experimental results show that L2RS\noutperforms not only traditional rescoring methods but also its deep neural\nnetwork counterparts by a substantial improvement of 20.67% in terms of\nNDCG@10. L2RS paves the way for developing more effective rescoring models for\nASR."
    }
  ],
  [
    {
      "paper_id": "2307.03726v2",
      "title": "LTE SFBC MIMO Transmitter Modelling and Performance Evaluation",
      "subject": [
        "eess.SP"
      ],
      "abstract": "High data rates are one of the most prevalent requirements in current mobile\ncommunications. To cover this and other high standards regarding performance,\nincreasing coverage, capacity, and reliability, numerous works have proposed\nthe development of systems employing the combination of several techniques such\nas Multiple Input Multiple Output (MIMO) wireless technologies with Orthogonal\nFrequency Division Multiplexing (OFDM) in the evolving 4G wireless\ncommunications. Our proposed system is based on the 2x2 MIMO antenna technique,\nwhich is defined to enhance the performance of radio communication systems in\nterms of capacity and spectral efficiency, and the OFDM technique, which can be\nimplemented using two types of sub-carrier mapping modes: Space-Time Block\nCoding and Space Frequency Block Code. SFBC has been considered in our\ndeveloped model. The main advantage of SFBC over STBC is that SFBC encodes two\nmodulated symbols over two subcarriers of the same OFDM symbol, whereas STBC\nencodes two modulated symbols over two subcarriers of the same OFDM symbol;\nthus, the coding is performed in the frequency domain. Our solution aims to\ndemonstrate the performance analysis of the Space Frequency Block Codes scheme,\nincreasing the Signal Noise Ratio (SNR) at the receiver and decreasing the Bit\nError Rate (BER) through the use of 4 QAM, 16 QAM and 64QAM modulation over a\n2x2 MIMO channel for an LTE downlink transmission, in different channel radio\nenvironments. In this work, an analytical tool to evaluate the performance of\nSFBC - Orthogonal Frequency Division Multiplexing, using two transmit antennas\nand two receive antennas has been implemented, and the analysis using the\naverage SNR has been considered as a sufficient statistic to describe the\nperformance of SFBC in the 3GPP Long Term Evolution system over Multiple Input\nMultiple Output channels."
    },
    {
      "paper_id": "2307.03829v1",
      "title": "Robot Motion Prediction by Channel State Information",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Autonomous robotic systems have gained a lot of attention, in recent years.\nHowever, accurate prediction of robot motion in indoor environments with\nlimited visibility is challenging. While vision-based and light detection and\nranging (LiDAR) sensors are commonly used for motion detection and localization\nof robotic arms, they are privacy-invasive and depend on a clear line-of-sight\n(LOS) for precise measurements. In cases where additional sensors are not\navailable or LOS is not possible, these technologies may not be the best\noption. This paper proposes a novel method that employs channel state\ninformation (CSI) from WiFi signals affected by robotic arm motion. We\ndeveloped a convolutional neural network (CNN) model to classify four different\nactivities of a Franka Emika robotic arm. The implemented method seeks to\naccurately predict robot motion even in scenarios in which the robot is\nobscured by obstacles, without relying on any attached or internal sensors."
    }
  ],
  [
    {
      "paper_id": "2208.06115v5",
      "title": "A Nonparametric Approach with Marginals for Modeling Consumer Choice",
      "subject": [
        "math.OC"
      ],
      "abstract": "Given data on the choices made by consumers for different offer sets, a key\nchallenge is to develop parsimonious models that describe and predict consumer\nchoice behavior while being amenable to prescriptive tasks such as pricing and\nassortment optimization. The marginal distribution model (MDM) is one such\nmodel, which requires only the specification of marginal distributions of the\nrandom utilities. This paper aims to establish necessary and sufficient\nconditions for given choice data to be consistent with the MDM hypothesis,\ninspired by the usefulness of similar characterizations for the random utility\nmodel (RUM). This endeavor leads to an exact characterization of the set of\nchoice probabilities that the MDM can represent. Verifying the consistency of\nchoice data with this characterization is equivalent to solving a\npolynomial-sized linear program. Since the analogous verification task for RUM\nis computationally intractable and neither of these models subsumes the other,\nMDM is helpful in striking a balance between tractability and representational\npower. The characterization is then used with robust optimization for making\ndata-driven sales and revenue predictions for new unseen assortments. When the\nchoice data lacks consistency with the MDM hypothesis, finding the best-fitting\nMDM choice probabilities reduces to solving a mixed integer convex program.\nNumerical results using real world data and synthetic data demonstrate that MDM\nexhibits competitive representational power and prediction performance compared\nto RUM and parametric models while being significantly faster in computation\nthan RUM."
    },
    {
      "paper_id": "2208.06152v1",
      "title": "ALS: Augmented Lagrangian Sketching Methods for Linear Systems",
      "subject": [
        "math.OC"
      ],
      "abstract": "We develop two fundamental stochastic sketching techniques; Penalty Sketching\n(PS) and Augmented Lagrangian Sketching (ALS) for solving consistent linear\nsystems. The proposed PS and ALS techniques extend and generalize the scope of\nSketch & Project (SP) method by introducing Lagrangian penalty sketches. In\ndoing so, we recover SP methods as special cases and furthermore develop a\nfamily of new stochastic iterative methods. By varying sketch parameters in the\nproposed PS method, we recover novel stochastic methods such as Penalty Newton\nDescent, Penalty Kaczmarz, Penalty Stochastic Descent, Penalty Coordinate\nDescent, Penalty Gaussian Pursuit, and Penalty Block Kaczmarz. Furthermore, the\nproposed ALS method synthesizes a wide variety of new stochastic methods such\nas Augmented Newton Descent, Augmented Kaczmarz, Augmented Stochastic Descent,\nAugmented Coordinate Descent, Augmented Gaussian Pursuit, and Augmented Block\nKaczmarz into one framework. Moreover, we show that the developed PS and ALS\nframeworks can be used to reformulate the original linear system into\nequivalent stochastic optimization problems namely the Penalty Stochastic\nReformulation and Augmented Stochastic Reformulation. We prove global\nconvergence rates for the PS and ALS methods as well as sub-linear\n$\\mathcal{O}(\\frac{1}{k})$ rates for the Cesaro average of iterates. The\nproposed convergence results hold for a wide family of distributions of random\nmatrices, which provides the opportunity of fine-tuning the randomness of the\nmethod suitable for specific applications. Finally, we perform computational\nexperiments that demonstrate the efficiency of our methods compared to the\nexisting SP methods."
    }
  ],
  [
    {
      "paper_id": "2201.05712v2",
      "title": "Expectile-based hydrological modelling for uncertainty estimation: Life\n  after mean",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Predictions of hydrological models should be probabilistic in nature. Our aim\nis to introduce a method that estimates directly the uncertainty of\nhydrological simulations using expectiles, thus complementing previous\nquantile-based direct approaches as well as generalizing mean-based approaches.\nExpectiles are new risk measures in hydrology. Compared to quantiles that use\ninformation of the frequency of process realizations over a specified value,\nexpectiles use additional information of the magnitude of the exceedances over\nthe specified value. Expectiles are least square analogues of quantiles and can\ncharacterize the probability distribution in much the same way as quantiles do.\nMoreover, the mean of the probability distribution is the special case of the\nexpectile at level 0.5. To this end, we propose calibrating hydrological models\nusing the expectile loss function, which is strictly consistent for expectiles.\nWe apply our method to 511 basins in contiguous US and deliver predictive\nexpectiles of hydrological simulations with the GR4J, GR5J and GR6J\nhydrological models at expectile levels 0.5, 0.9, 0.95 and 0.975. An honest\nassessment empirically proves that the GR6J model outperforms the other two\nmodels at all expectile levels. Great opportunities are offered for moving\nbeyond the mean in hydrological modelling by simply adjusting the objective\nfunction."
    },
    {
      "paper_id": "2201.06332v1",
      "title": "Optimal monitoring location for risk tracking of geotechnical systems:\n  theory and application to tunneling excavation risks",
      "subject": [
        "stat.AP"
      ],
      "abstract": "The maturity of structural health monitoring technology brings\never-increasing opportunities for geotechnical structures and underground\ninfrastructure systems to track the risk of structural failure, such as\nsettlement-induced building damage, based on the monitored data. Reliability\nupdating techniques can offer solutions to estimate the probability of failing\nto meet a prescribed objective using various types of information that are\ninclusive of equality and inequality. However, the update in reliability can be\nhighly sensitive to monitoring location. Therefore, there may exist optimal\nlocations in a system for monitoring that yield the maximum value for\nreliability updating. This paper proposes a computational framework for optimal\nmonitoring location based on an innovative metric called sensitivity of\ninformation (SOI) that quantifies the relative change in unconditional and\nconditional reliability indexes. A state-of-the-practice case of risks posed by\ntunneling-induced settlement to buildings is explored in-depth to demonstrate\nand evaluate the computational efficiency of the proposed framework."
    }
  ],
  [
    {
      "paper_id": "1706.05823v1",
      "title": "Algebraic cycles on Fano varieties of some cubics",
      "subject": [
        "math.AG"
      ],
      "abstract": "This note is about cycle-theoretic properties of the Fano variety of lines on\na smooth cubic fivefold. The arguments are based on the fact that this Fano\nvariety has finite-dimensional motive. We also present some results concerning\nChow groups of Fano varieties of lines on certain cubics in other dimensions."
    },
    {
      "paper_id": "1706.05908v1",
      "title": "Fixed points and entropy of endomorphisms on simple abelian varieties",
      "subject": [
        "math.AG"
      ],
      "abstract": "In this paper we investigate fixed-point numbers and entropies of\nendomorphisms on abelian varieties. It was shown quite recently that the number\nof fixed-points of an iterated endomorphism on a simple complex torus is either\nperiodic or grows exponentially. Criteria to decide whether a given\nendomorphism is of the one type or the other are still missing. Our first\nresult provides such criteria for simple abelian varieties in terms of the\npossible types of endomorphism algebras. The number of fixed-points depends on\nthe eigenvalues and we exactly show which analytic eigenvalues occur. This\ninsight is also the starting point to ask for the entropy of an endomorphism.\nOur second result offers criteria for an endomorphism to be of zero or positive\nentropy. The entropy is computed as the logarithm of a real number and our\nthird result characterizes the algebraic structure of this number."
    }
  ],
  [
    {
      "paper_id": "1701.00875v2",
      "title": "Optimal Mean-Reverting Spread Trading: Nonlinear Integral Equation\n  Approach",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "We study several optimal stopping problems that arise from trading a\nmean-reverting price spread over a finite horizon. Modeling the spread by the\nOrnstein-Uhlenbeck process, we analyze three different trading strategies: (i)\nthe long-short strategy; (ii) the short-long strategy, and (iii) the chooser\nstrategy, i.e. the trader can enter into the spread by taking either long or\nshort position. In each of these cases, we solve an optimal double stopping\nproblem to determine the optimal timing for starting and subsequently closing\nthe position. We utilize the local time-space calculus of Peskir (2005a) and\nderive the nonlinear integral equations of Volterra-type that uniquely char-\nacterize the boundaries associated with the optimal timing decisions in all\nthree problems. These integral equations are used to numerically compute the\noptimal boundaries."
    },
    {
      "paper_id": "1701.01327v3",
      "title": "Optimal liquidation in a Level-I limit order book for large tick stocks",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "We propose a framework to study the optimal liquidation strategy in a limit\norder book for large-tick stocks, with spread equal to one tick. All order book\nevents (market orders, limit orders and cancellations) occur according to\nindependent Poisson processes, with parameters depending on price move\ndirections. Our goal is to maximise the expected terminal wealth of an agent\nwho needs to liquidate her positions within a fixed time horizon. Assuming that\nthe agent trades (through sell limit order or/and sell market order) only when\nthe price moves, we model her liquidation procedure as a semi-Markov decision\nprocess, and compute the semi-Markov kernel using Laplace method in the\nlanguage of queueing theory. The optimal liquidation policy is then solved by\ndynamic programming, and illustrated numerically."
    }
  ],
  [
    {
      "paper_id": "0801.0253v1",
      "title": "Toward a statistical mechanics of four letter words",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "We consider words as a network of interacting letters, and approximate the\nprobability distribution of states taken on by this network. Despite the\nintuition that the rules of English spelling are highly combinatorial (and\narbitrary), we find that maximum entropy models consistent with pairwise\ncorrelations among letters provide a surprisingly good approximation to the\nfull statistics of four letter words, capturing ~92% of the multi-information\namong letters and even \"discovering\" real words that were not represented in\nthe data from which the pairwise correlations were estimated. The maximum\nentropy model defines an energy landscape on the space of possible words, and\nlocal minima in this landscape account for nearly two-thirds of words used in\nwritten English."
    },
    {
      "paper_id": "0801.3056v2",
      "title": "Transient and Equilibrium Synchronization in Complex Neuronal Networks",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "Transient and equilibrium synchronizations in complex neuronal networks as a\nconsequence of dynamics induced by having sources placed at specific neurons\nare investigated. The basic integrate-and-fire neuron is adopted, and the\ndynamics is estimated computationally so as to obtain the activation at each\nnode along each instant of time. In the transient case, the dynamics is\nimplemented so as to conserve the total activation entering the system. In our\nequilibrium investigations, the internally stored activation is limited to the\nvalue of the respective threshold. The synchronization of the activation of the\nnetwork is then quantified in terms of its normalized entropy. The equilibrium\ninvestigations involve the application of a number of complementary\ncharacterization methods, including spectra and Principal Component Analysis,\nas well as of an equivalent model capable of reproducing both the transient and\nequilibrium dynamics. The potential of such concepts and measurements is\nexplored with respect to several theoretical models, as well as for the\nneuronal network of \\emph{C. elegans}. A series of interesting results are\nobtained and discussed, including the fact that all models led to a transient\nperiod of synchronization, whose specific features depend on the topological\nstructures of the networks. The investigations of the equilibrium dynamics\nrevealed a series of remarkable insights, including the relationship between\nspiking oscillations and the hierarchical structure of the networks and the\nidentification of twin correlation patterns between node degree and total\nactivation, implying that hubs of connectivity are also hubs of\nintegrate-and-fire activation."
    }
  ],
  [
    {
      "paper_id": "2203.01207v1",
      "title": "Container Localisation and Mass Estimation with an RGB-D Camera",
      "subject": [
        "eess.IV"
      ],
      "abstract": "In the research area of human-robot interactions, the automatic estimation of\nthe mass of a container manipulated by a person leveraging only visual\ninformation is a challenging task. The main challenges consist of occlusions,\ndifferent filling materials and lighting conditions. The mass of an object\nconstitutes key information for the robot to correctly regulate the force\nrequired to grasp the container. We propose a single RGB-D camera-based method\nto locate a manipulated container and estimate its empty mass i.e.,\nindependently of the presence of the content. The method first automatically\nselects a number of candidate containers based on the distance with the fixed\nfrontal view, then averages the mass predictions of a lightweight model to\nprovide the final estimation. Results on the CORSMAL Containers Manipulation\ndataset show that the proposed method estimates empty container mass obtaining\na score of 71.08% under different lighting or filling conditions."
    },
    {
      "paper_id": "2203.01296v1",
      "title": "Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Low-Light Image Enhancement is a computer vision task which intensifies the\ndark images to appropriate brightness. It can also be seen as an ill-posed\nproblem in image restoration domain. With the success of deep neural networks,\nthe convolutional neural networks surpass the traditional algorithm-based\nmethods and become the mainstream in the computer vision area. To advance the\nperformance of enhancement algorithms, we propose an image enhancement network\n(HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use\na half wavelet attention block on M-Net+ to enrich the features from wavelet\ndomain. Furthermore, our HWMNet has competitive performance results on two\nimage enhancement datasets in terms of quantitative metrics and visual quality.\nThe source code and pretrained model are available at\nhttps://github.com/FanChiMao/HWMNet."
    }
  ],
  [
    {
      "paper_id": "2305.00385v2",
      "title": "Cross-Shaped Windows Transformer with Self-supervised Pretraining for\n  Clinically Significant Prostate Cancer Detection in Bi-parametric MRI",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Biparametric magnetic resonance imaging (bpMRI) has demonstrated promising\nresults in prostate cancer (PCa) detection using convolutional neural networks\n(CNNs). Recently, transformers have achieved competitive performance compared\nto CNNs in computer vision. Large scale transformers need abundant annotated\ndata for training, which are difficult to obtain in medical imaging.\nSelf-supervised learning (SSL) utilizes unlabeled data to generate meaningful\nsemantic representations without the need for costly annotations, enhancing\nmodel performance on tasks with limited labeled data. We introduce a novel\nend-to-end Cross-Shaped windows (CSwin) transformer UNet model, CSwin UNet, to\ndetect clinically significant prostate cancer (csPCa) in prostate bi-parametric\nMR imaging (bpMRI) and demonstrate the effectiveness of our proposed\nself-supervised pre-training framework. Using a large prostate bpMRI dataset\nwith 1500 patients, we first pretrain CSwin transformer using multi-task\nself-supervised learning to improve data-efficiency and network\ngeneralizability. We then finetune using lesion annotations to perform csPCa\ndetection. Five-fold cross validation shows that self-supervised CSwin UNet\nachieves 0.888 AUC and 0.545 Average Precision (AP), significantly\noutperforming four comparable models (Swin UNETR, DynUNet, Attention UNet,\nUNet). Using a separate bpMRI dataset with 158 patients, we evaluate our method\nrobustness to external hold-out data. Self-supervised CSwin UNet achieves 0.79\nAUC and 0.45 AP, still outperforming all other comparable methods and\ndemonstrating good generalization to external data."
    },
    {
      "paper_id": "2305.00627v2",
      "title": "CNN-based fully automatic mitral valve extraction using CT images and\n  existence probability maps",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Accurate extraction of mitral valve shape from clinical tomographic images\nacquired in patients has proven useful for planning surgical and interventional\nmitral valve treatments. However, manual extraction of the mitral valve shape\nis laborious, and the existing automatic extraction methods have not been\nsufficiently accurate. In this paper, we propose a fully automated method of\nextracting mitral valve shape from computed tomography (CT) images for the all\nphases of the cardiac cycle. This method extracts the mitral valve shape based\non DenseNet using both the original CT image and the existence probability maps\nof the mitral valve area inferred by U-Net as input. A total of 1585 CT images\nfrom 204 patients with various cardiac diseases including mitral regurgitation\n(MR) were collected and manually annotated for mitral valve region. The\nproposed method was trained and evaluated by 10-fold cross validation using the\ncollected data and was compared with the method without the existence\nprobability maps. The mean error of shape extraction error in the proposed\nmethod is 0.88 mm, which is an improvement of 0.32 mm compared with the method\nwithout the existence probability maps."
    }
  ],
  [
    {
      "paper_id": "2305.08615v1",
      "title": "Sakaguchi Swarmalators",
      "subject": [
        "nlin.PS"
      ],
      "abstract": "Swarmalators are phase oscillators that cluster in space, like fireflies\nflashing on a swarm to attract mates. Interactions between particles, which\ntend to synchronize their phases and align their motion, decrease with the\ndistance and phase difference between them, coupling the spatial and phase\ndynamics. In this work, we explore the effects of disorder induced by phase\nfrustration on a system of Swarmalators that move on a one-dimensional ring.\nOur model is inspired by the well-known Kuramoto-Sakaguchi equations. We find,\nnumerically and analytically, the ordered and disordered states that emerge in\nthe system. The active states, not present in the model without disorder,\nresemble states found previously in numerical studies for the 2D Swarmalators\nsystem. One of these states, in particular, shows similarities to turbulence\ngenerated in a flattened media. We show that all ordered states can be\ngenerated for any values of the coupling constants by tuning the phase\nfrustration parameters only. Moreover, many of these combinations display\nmulti-stability."
    },
    {
      "paper_id": "2305.12346v1",
      "title": "Asymptotic theory of not completely integrable soliton equations",
      "subject": [
        "nlin.PS"
      ],
      "abstract": "We develop the theory of transformation of intensive initial nonlinear wave\npulses to trains of solitons emerging at asymptotically large time of\nevolution. Our approach is based on the theory of dispersive shock waves in\nwhich the number of nonlinear oscillations in the shock becomes the number of\nsolitons at the asymptotic state. We show that this number of oscillations,\nwhich is proportional to the classical action of particles associated with the\nsmall-amplitude edges of shocks, is preserved by the dispersionless flow. Then\nthe Poincar\\'e-Cartan integral invariant is also constant and therefore it\nreduces to the quantization rule similar to the Bohr-Sommerfeld quantization\nrule for linear spectral problem associated with completely integrable\nequations. This rule yields a set of `eigenvalues' which are related with the\nasymptotic solitons' velocities and other their characteristics. Our analytical\nresults agree very well with the results of numerical solutions of the\ngeneralized nonlinear Schr\\\"odinger equation."
    }
  ],
  [
    {
      "paper_id": "1612.00133v3",
      "title": "Geoneutrinos at Jinping: Flux prediction and oscillation analysis",
      "subject": [
        "hep-ex",
        "physics.geo-ph",
        "physics.ins-det"
      ],
      "abstract": "Geoneutrinos are electron antineutrinos ($\\bar\\nu_e$) generated by the\nbeta-decays of radionuclides naturally occurring inside the Earth, in\nparticular $^{238}$U, $^{232}$Th, and $^{40}$K. Measurement of these neutrinos\nprovides powerful constraints on the radiogenic heat of the Earth and tests on\nthe Earth models. Since the prediction of $\\bar\\nu_e$'s in geoneutrino flux is\nsubject to neutrino oscillation effects, we performed a calculation including\ndetailed oscillation analysis in the propagation of geoneutrinos and reactor\nneutrinos generated around the Earth. The expected geoneutrino signal, the\nreactor neutrino background rates and the systematic error budget are provided\nfor a proposed 3-kiloton neutrino detector at the Jinping underground lab in\nSichuan, China. In addition, we evaluated sensitivities for the geoneutrino\nflux, Th/U ratio and power of a possible fission reactor in the interior of\nEarth."
    },
    {
      "paper_id": "1612.00705v1",
      "title": "An Optical Atmospheric Phenomenon Observed in 1670 over the City of\n  Astrakhan Was not a Mid-Latitude Aurora",
      "subject": [
        "physics.ao-ph",
        "astro-ph.EP",
        "physics.geo-ph"
      ],
      "abstract": "It has been recently claimed (Zolotova and Ponyavin, Solar Phys., 291, 2869,\n2016, ZP16 henceforth) that a mid-latitude optical phenomenon, which took place\nover the city of Astrakhan in July 1670, according to Russian chronicles, was a\nstrong aurora borealis. If this was true, it would imply a very strong or even\nsevere geomagnetic storm during the quietest part of the Maunder minimum.\nHowever, as we argue in this article, this conclusion is erroneous and caused\nby a misinterpretation of the chronicle record. As a result of a thorough\nanalysis of the chronicle text, we show that the described phenomenon occurred\nduring the daylight period of the day (\"the last morning hour\"), in the south\ndirection (\"towards noon\"), and its description does not match that of an\naurora. The date of the event was also incorrectly interpreted. We conclude\nthat this phenomenon was not a mid-latitude aurora but an atmospheric\nphenomenon, the so-called sundog (or parhelion) which is a particular type of\nsolar halo. Accordingly, the claim about a strong mid-latitude aurora during\nthe deep Maunder minimum is not correct and should be dismissed."
    }
  ],
  [
    {
      "paper_id": "1811.06750v2",
      "title": "It\u00f4 vs Stratonovich in the presence of absorbing states",
      "subject": [
        "math.PR",
        "math.MP"
      ],
      "abstract": "It is widely assumed that there exists a simple transformation from the It\\^o\ninterpretation to the one by Stratonovich and back for any stochastic\ndifferential equation of applied interest. While this transformation exists\nunder suitable conditions, and transforms one interpretation into the other at\nthe price of modifying the drift of the equation, it cannot be considered\nuniversal. We show that a class of stochastic differential equations,\ncharacterized by the presence of absorbing states and of interest in\napplications, does not admit such a transformation. In particular, formally\napplying this transformation may lead to the disappearance of some absorbing\nstates. In turn, this modifies the long-time, and even the intermediate-time,\nbehavior of the solutions. The number of solutions can also be modified by the\nunjustified application of the mentioned transformation, as well as by a change\nin the interpretation of the noise. We discuss how these facts affect the\nclassical debate on the It\\^o vs Stratonovich dilemma."
    },
    {
      "paper_id": "1811.06904v3",
      "title": "Well-Posedness for Some Non-Linear Diffusion Processes and Related PDE\n  on the Wasserstein Space",
      "subject": [
        "math.CA",
        "math.AP",
        "math.FA",
        "math.PR"
      ],
      "abstract": "In this paper, we investigate the well-posedness of the martingale problem\nassociated to non-linear stochastic differential equations (SDEs) in the sense\nof McKean-Vlasov under mild assumptions on the coefficients as well as\nclassical solutions for a class of associated linear partial differential\nequations (PDEs) defined on $[0,T] \\times \\mathbb{R}^d \\times\n\\mathcal{P}\\_2(\\mathbb{R}^d)$, for any $T>0$, $\\mathcal{P}\\_2(\\mathbb{R}^d)$\nbeing the Wasserstein space (i.e. the space of probability measures on\n$\\mathbb{R}^d$ with a finite second-order moment). In this case, the derivative\nof a map along a probability measure is understood in the Lions' sense. The\nmartingale problem is addressed by a fixed point argument on a suitable\ncomplete metric space, under some mild regularity assumptions on the\ncoefficients that covers a large class of interaction. Also, new well-posedness\nresults in the strong sense are obtained from the previous analysis. Under\nadditional assumptions, we then prove the existence of the associated density\nand investigate its smoothness property. In particular, we establish some\nGaussian type bounds for its derivatives. We eventually address the existence\nand uniqueness for the related linear Cauchy problem with irregular terminal\ncondition and source term."
    }
  ],
  [
    {
      "paper_id": "2306.16924v2",
      "title": "Ultimate parameters of an all-optical MX resonance in Cs in ultra-weak\n  magnetic field",
      "subject": [
        "physics.optics",
        "physics.atom-ph",
        "physics.med-ph"
      ],
      "abstract": "We present the results of studying the parameters of the magnetic MX\nresonance in an all-optical sensor built according to the two-beam Bell-Bloom\nscheme in nonzero ultra-weak magnetic fields in which the effects of\nspin-exchange broadening suppression are partially manifested. We report on the\nfeatures of the resonance under these conditions. We also optimize the\nresonance parameters to achieve maximum sensitivity in magnetoencephalographic\nsensors. We demonstrate an improvement in the ultimate achievable sensitivity\nof an all-optical MX sensor by a factor of four or more, which in our\nexperiment corresponds to a decrease from 13 to 3 fT/Hz1/2 in a volume of 0.13\ncm3. We also report the effect of incomplete suppression of spin-exchange\nbroadening under conditions of strong transverse modulated optical pumping, and\npropose a semi-empirical model to describe it."
    },
    {
      "paper_id": "2306.16967v1",
      "title": "On the relevance of acoustic measurements for creating realistic virtual\n  acoustic environments",
      "subject": [
        "physics.med-ph"
      ],
      "abstract": "Geometrical approaches for room acoustics simulation have the advantage of\nrequiring limited computational resources while still achieving a high\nperceptual plausibility. A common approach is using the image source model for\ndirect and early reflections in connection with further simplified models such\nas a feedback delay network for the diffuse reverberant tail. When recreating\nreal spaces as virtual acoustic environments using room acoustics simulation,\nthe perceptual relevance of individual parameters in the simulation is unclear.\nHere we investigate the importance of underlying acoustical measurements and\ntechnical evaluation methods to obtain high-quality room acoustics simulations\nin agreement with dummy-head recordings of a real space. We focus on the role\nof source directivity. The effect of including measured, modelled, and\nomnidirectional source directivity in room acoustics simulations was assessed\nin comparison to the measured reference. Technical evaluation strategies to\nverify and improve the accuracy of various elements in the simulation\nprocessing chain from source, the room properties, to the receiver are\npresented. Perceptual results from an ABX listening experiment with random\nspeech tokens are shown and compared with technical measures for a ranking of\nsimulation approaches."
    }
  ],
  [
    {
      "paper_id": "math-ph/0508068v2",
      "title": "Lam\u00e9 equation, quantum top and elliptic Bernoulli polynomials",
      "subject": [
        "math.GM",
        "math.MP"
      ],
      "abstract": "A generalisation of the odd Bernoulli polynomials related to the quantum\nEuler top is introduced and investigated. This is applied to compute the\ncoefficients of the spectral polynomials for the classical Lam\\'e operator."
    },
    {
      "paper_id": "math-ph/0512055v1",
      "title": "p-Adic analysis in the Lizorkin type spaces: fractional operators,\n  pseudo-differential equations and Tauberian theorems",
      "subject": [
        "math.GM",
        "math.MP"
      ],
      "abstract": "In this paper the p -adic Lizorkin spaces of test functions and distributions\nare introduced, and multidimensional Vladimirov's and Taibleson's fractional\noperators are studied on these spaces. Since the p -adic Lizorkin spaces are\ninvariant under the Vladimirov and Taibleson operators, they can play a key\nrole in considerations related to fractional operator problems. A class of p\n-adic pseudo-differential operators in the Lizorkin spaces is also introduced\nand solutions of pseudo-differential equations are constructed. p -Adic\nmultidimensional Tauberian theorems connected with fractional operators and\npseudo-differential operators for the Lizorkin distributions are also proved."
    }
  ],
  [
    {
      "paper_id": "1609.07319v1",
      "title": "Equidistribution in S-arithmetic and adelic spaces",
      "subject": [
        "math.DS",
        "math.NT"
      ],
      "abstract": "We give an introduction to adelic mixing and its applications for\nmathematicians knowing about the mixing of the geodesic flow on hyperbolic\nsurfaces. We focus on the example of the Hecke trees in the modular surface."
    },
    {
      "paper_id": "1609.07323v1",
      "title": "Optimal Control Problems in Transport Dynamics",
      "subject": [
        "math.OC",
        "math.DS"
      ],
      "abstract": "In the present paper we deal with an optimal control problem related to a\nmodel in population dynamics; more precisely, the goal is to modify the\nbehavior of a given density of individuals via another population of agents\ninteracting with the first. The cost functional to be minimized to determine\nthe dynamics of the second population takes into account the desired target or\nconfiguration to be reached as well as the quantity of control agents. Several\napplications may fall into this framework, as for instance driving a mass of\npedestrian in (or out of) a certain location; influencing the stock market by\nacting on a small quantity of key investors; controlling a swarm of unmanned\naerial vehicles by means of few piloted drones."
    }
  ],
  [
    {
      "paper_id": "1110.6595v2",
      "title": "Ground waves in atomic chains with bi-monomial double-well potential",
      "subject": [
        "math.DS",
        "math.MP"
      ],
      "abstract": "Ground waves in atomic chains are traveling waves that corresponds to minimal\nnon-trivial critical values of the underlying action functional. In this paper\nwe study FPU-type chains with bi-monomial double-well potential and prove the\nexistence of both periodic and solitary ground waves. To this end we minimize\nthe action on the Nehari manifold and show that periodic ground waves converge\nto solitary ones. Finally, we compute ground waves numerically by a suitable\ndiscretization of a constrained gradient flow."
    },
    {
      "paper_id": "1111.0205v1",
      "title": "Random attractors for singular stochastic partial differential equations",
      "subject": [
        "math.PR",
        "math.AP",
        "math.DS"
      ],
      "abstract": "The existence of random attractors for singular stochastic partial\ndifferential equations (SPDE) perturbed by general additive noise is proven.\nThe drift is assumed only to satisfy the standard assumptions of the\nvariational approach to SPDE with compact embeddings in the Gelfand triple and\nsingular coercivity. For ergodic, monotone, contractive random dynamical\nsystems it is proven that the attractor consists of a single random point. In\ncase of real, linear multiplicative noise finite time extinction is obtained.\nApplications include stochastic generalized fast diffusion equations and\nstochastic generalized singular p-Laplace equations perturbed by Levy noise\nwith jump measure having finite first and second moments."
    }
  ],
  [
    {
      "paper_id": "2209.10489v1",
      "title": "Recurrent Super-Resolution Method for Enhancing Low Quality Thermal\n  Facial Data",
      "subject": [
        "eess.IV"
      ],
      "abstract": "The process of obtaining high-resolution images from single or multiple\nlow-resolution images of the same scene is of great interest for real-world\nimage and signal processing applications. This study is about exploring the\npotential usage of deep learning based image super-resolution algorithms on\nthermal data for producing high quality thermal imaging results for in-cabin\nvehicular driver monitoring systems. In this work we have proposed and\ndeveloped a novel multi-image super-resolution recurrent neural network to\nenhance the resolution and improve the quality of low-resolution thermal\nimaging data captured from uncooled thermal cameras. The end-to-end fully\nconvolutional neural network is trained from scratch on newly acquired thermal\ndata of 30 different subjects in indoor environmental conditions. The\neffectiveness of the thermally tuned super-resolution network is validated\nquantitatively as well as qualitatively on test data of 6 distinct subjects.\nThe network was able to achieve a mean peak signal to noise ratio of 39.24 on\nthe validation dataset for 4x super-resolution, outperforming bicubic\ninterpolation both quantitatively and qualitatively."
    },
    {
      "paper_id": "2209.10675v2",
      "title": "A Validation Approach to Over-parameterized Matrix and Image Recovery",
      "subject": [
        "eess.IV"
      ],
      "abstract": "This paper studies the problem of recovering a low-rank matrix from several\nnoisy random linear measurements. We consider the setting where the rank of the\nground-truth matrix is unknown a priori and use an objective function built\nfrom a rank-overspecified factored representation of the matrix variable, where\nthe global optimal solutions overfit and do not correspond to the underlying\nground truth. We then solve the associated nonconvex problem using gradient\ndescent with small random initialization. We show that as long as the\nmeasurement operators satisfy the restricted isometry property (RIP) with its\nrank parameter scaling with the rank of the ground-truth matrix rather than\nscaling with the overspecified matrix rank, gradient descent iterations are on\na particular trajectory towards the ground-truth matrix and achieve nearly\ninformation-theoretically optimal recovery when it is stopped appropriately. We\nthen propose an efficient stopping strategy based on the common hold-out method\nand show that it detects a nearly optimal estimator provably. Moreover,\nexperiments show that the proposed validation approach can also be efficiently\nused for image restoration with deep image prior, which over-parameterizes an\nimage with a deep network."
    }
  ],
  [
    {
      "paper_id": "1809.08946v1",
      "title": "Direct visualization of the 3D structure of silicon impurities in\n  graphene",
      "subject": [
        "physics.app-ph",
        "cond-mat.mtrl-sci"
      ],
      "abstract": "We directly visualize the three-dimensional (3D) geometry and dynamics of\nsilicon impurities in graphene as well as their dynamics by\naberration-corrected scanning transmission electron microscopy. By acquiring\nimages when the sample is tilted, we show that an asymmetry of the atomic\nposition of the heteroatom in the projection reveals the non-planarity of the\nstructure. From a sequence of images, we further demonstrate that the Si atom\nswitches between up- and down- configurations with respect to the graphene\nplane, with an asymmetric cross-section. We further analyze the 3D structure\nand dynamics of a silicon tetramer in graphene. Our results clarify the\nout-of-plane structure of impurities in graphene by direct experimental\nobservation and open a new route to study their dynamics in three dimensions."
    },
    {
      "paper_id": "1809.09301v1",
      "title": "Reconfigurable Shape-Morphing Dielectric Elastomers Using Spatially\n  Varying Electric Fields",
      "subject": [
        "physics.app-ph",
        "cond-mat.mtrl-sci"
      ],
      "abstract": "Exceptionally large strains can be produced in soft elastomers by the\napplication of an electric field and the strains can be exploited for a variety\nof novel actuators, such as tunable lenses and tactile actuators. However,\nshape morphing with dielectric elastomers has not been possible since no\ngeneralizable method for changing their Gaussian curvature has been devised. It\nis shown that this fundamental limitation can be lifted by introducing\ninternal, spatially varying electric fields through a layer-by-layer\nfabrication method incorporating shaped, carbon-nanotubes-based electrodes\nbetween thin elastomer sheets. To illustrate the potential of the method,\nvoltage-tunable negative and positive Gaussian curvatures shapes are produced.\nFurthermore, by applying voltages to different sets of internal electrodes, the\nshapes can be re-configured. All the shape changes are reversible when the\nvoltage is removed."
    }
  ],
  [
    {
      "paper_id": "2308.14388v2",
      "title": "Biclustering Methods via Sparse Penalty",
      "subject": [
        "q-bio.GN"
      ],
      "abstract": "In this paper, we first reviewed several biclustering methods that are used\nto identify the most significant clusters in gene expression data. Here we\nmainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty\nnamed \"Prenet penalty\" which has been used only in factor analysis to gain\nsparsity. Then in the simulation study, we tried different types of generated\ndatasets (with different sparsity and dimension) and tried 1-layer\napproximation then for k-layers which shows the mixed Prenet penalty is very\neffective for non-overlapped data. Finally, we used some real gene expression\ndata to show the behavior of our methods."
    },
    {
      "paper_id": "2309.03242v1",
      "title": "Automated Bioinformatics Analysis via AutoBA",
      "subject": [
        "q-bio.GN"
      ],
      "abstract": "With the fast-growing and evolving omics data, the demand for streamlined and\nadaptable tools to handle the analysis continues to grow. In response to this\nneed, we introduce Auto Bioinformatics Analysis (AutoBA), an autonomous AI\nagent based on a large language model designed explicitly for conventional\nomics data analysis. AutoBA simplifies the analytical process by requiring\nminimal user input while delivering detailed step-by-step plans for various\nbioinformatics tasks. Through rigorous validation by expert bioinformaticians,\nAutoBA's robustness and adaptability are affirmed across a diverse range of\nomics analysis cases, including whole genome sequencing (WGS), RNA sequencing\n(RNA-seq), single-cell RNA-seq, ChIP-seq, and spatial transcriptomics. AutoBA's\nunique capacity to self-design analysis processes based on input data\nvariations further underscores its versatility. Compared with online\nbioinformatic services, AutoBA deploys the analysis locally, preserving data\nprivacy. Moreover, different from the predefined pipeline, AutoBA has\nadaptability in sync with emerging bioinformatics tools. Overall, AutoBA\nrepresents a convenient tool, offering robustness and adaptability for complex\nomics data analysis."
    }
  ],
  [
    {
      "paper_id": "2412.07074v1",
      "title": "Channel Spreading Function-Inspired Channel Transfer Function Estimation\n  for OFDM Systems with High-Mobility",
      "subject": [
        "eess.SP"
      ],
      "abstract": "In this letter, we propose a novel channel transfer function (CTF) estimation\napproach for orthogonal frequency division multiplexing (OFDM) systems in\nhigh-mobility scenarios, that leverages the stationary properties of the\ndelay-Doppler domain channel spreading function (CSF). First, we develop a CSF\nestimation model for OFDM systems that relies solely on discrete pilot symbols\nin the time-frequency (TF) domain, positioned at predefined resource elements.\nWe then present theorems to elucidate the relationship between CSF compactness\nand pilot spacing in the TF domain for accurate CSF acquisition. Based on the\nestimated CSF, we finally estimate the CTF for data symbols. Numerical results\nshow that, in high-mobility scenarios, the proposed approach outperforms\ntraditional interpolation-based methods and closely matches the optimal\nestimator in terms of estimation accuracy. This work may pave the way for CSF\nestimation in commercial OFDM systems, benefiting high-mobility communications,\nintegrated sensing and communications, and related applications."
    },
    {
      "paper_id": "2412.07173v1",
      "title": "Semantic Communications for Digital Signals via Carrier Images",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Most of current semantic communication (SemCom) frameworks focus on the image\ntransmission, which, however, do not address the problem on how to deliver\ndigital signals without any semantic features. This paper proposes a novel\nSemCom approach to transmit digital signals by using the image as the carrier\nsignal. Specifically, the proposed approach encodes the digital signal as a\nbinary stream and maps it to mask locations on an image. This allows binary\ndata to be visually represented, enabling the use of existing model,\npre-trained Masked Autoencoders (MAE), which are optimized for masked image\nreconstruction, as the SemCom encoder and decoder. Since MAE can both process\nand recover masked images, this approach allows for the joint transmission of\ndigital signals and images without additional overhead. In addition,\nconsidering the mask tokens transmission encoded by the MAE still faces extra\ncosts, we design a sparse encoding module at the transmitter to encode the mask\ntokens into a sparse matrix, and it can be recovered at the receiver. Thus,\nthis approach simply needs to transmit the latent representations of the\nunmasked patches and a sparse matrix, which further reduce the transmission\noverhead compared with the original MAE encoder. Simulation results show that\nthe approach maintains reliable transmission of digital signals and images even\nin a high mask ratio of transmitted images."
    }
  ],
  [
    {
      "paper_id": "2310.18418v1",
      "title": "STV+Reductions: Towards Practical Verification of Strategic Ability\n  Using Model Reductions",
      "subject": [
        "cs.LO",
        "cs.MA"
      ],
      "abstract": "We present a substantially expanded version of our tool STV for strategy\nsynthesis and verification of strategic abilities. The new version adds\nuser-definable models and support for model reduction through partial order\nreduction and checking for bisimulation."
    },
    {
      "paper_id": "2310.19579v1",
      "title": "A Navigation Logic for Recursive Programs with Dynamic Thread Creation",
      "subject": [
        "cs.LO",
        "cs.FL"
      ],
      "abstract": "Dynamic Pushdown Networks (DPNs) are a model for multithreaded programs with\nrecursion and dynamic creation of threads. In this paper, we propose a temporal\nlogic called NTL for reasoning about the call- and return- as well as thread\ncreation behaviour of DPNs. Using tree automata techniques, we investigate the\nmodel checking problem for the novel logic and show that its complexity is not\nhigher than that of LTL model checking against pushdown systems despite a more\nexpressive logic and a more powerful system model. The same holds true for the\nsatisfiability problem when compared to the satisfiability problem for a\nrelated logic for reasoning about the call- and return-behaviour of pushdown\nsystems. Overall, this novel logic offers a promising approach for the\nverification of recursive programs with dynamic thread creation."
    }
  ],
  [
    {
      "paper_id": "2212.06078v1",
      "title": "Non-smooth dynamics of buckling based metainterfaces: rocking-like\n  motion and bifurcations",
      "subject": [
        "physics.class-ph"
      ],
      "abstract": "The non-smooth dynamics is investigated for an elastic planar metainterface\ncomposed by two layers of buckling elements, each one allowing motion on one\nside only. Through the analogy between buckling and unilateral contact and by\nassuming no-bouncing at impact, the motion of the relevant two degrees of\nfreedom system is reduced to that of a single degree governed by a\npiecewise-smooth differential equation. The metainterface dynamics has strong\nsimilarities with the rocking motion of rigid blocks and displays several types\nof dynamic bifurcations in the presence of oscillatory forces, including period\ndoubling, branch point cycle, grazing, as well as quasi-periodic and chaotic\nresponses. Moreover, the multistable response is found to be broaden to\nconditions representative of monostable states within a quasi-static setting,\ndisclosing a multistability anticipation by dynamics. The wide landscape of the\ndynamic response for the buckling based metainterface provides a novel\ntheoretical framework to be exploited in the design of mechanical devices for\nvibration attenuation and for energy harvesting."
    },
    {
      "paper_id": "2212.07005v1",
      "title": "A systematic search for a three-velocity gyrodistributive law in special\n  relativity with the lorentz R package",
      "subject": [
        "physics.class-ph"
      ],
      "abstract": "Here I present the lorentz package for working with relativistic physics. The\npackage includes functionality for four-vector transformations, three-velocity\naddition, and other relativistic processes such as the behaviour of photons. It\nwas designed to facilitate the search for a gyrodistributive law. In special\nrelativity, three-velocities and scalars constitute a gyrovector space with\naddition $\\oplus$ and scalar multiplication $\\odot$. Standard vector spaces\nobey the distributive law $a(x + y) = ax + ay$ for scalar $a$ and vectors $x$,\n$y$; but no analogous gyrodistributive law for $r\\odot (u \\oplus v)$ is known.\nThe package was designed to facilitate the search for a gyrodistributive law\nand includes functionality for four-vector transformations and three-velocity\naddition, which is noncommutative and nonassociative. I use the package to\nsystematically sweep a large space of potential gyrodistributive laws, without\nsuccess. The package is available on CRAN, at\n\\url{https://CRAN.R-project.org/package=lorentz}."
    }
  ],
  [
    {
      "paper_id": "math/9902149v1",
      "title": "Towards a Mori theory on compact Kaehler threefolds, III",
      "subject": [
        "math.AG"
      ],
      "abstract": "We prove abundance for a minimal Kaehler threefold which is not both simple\nand non-Kummer. Recall that a variety is simple if there is no compact\nsubvariety of positive dimension through a sufficiently general point .\nFurthermore we prove that a smooth compact Kaehler threefold whose canonical\nbundle is not nef, carries a contraction unless (possibly) the manifold is\nsimple non-Kummer. It is generally conjectured that simple threefolds must be\nKummer."
    },
    {
      "paper_id": "math/9902152v1",
      "title": "New Invariants for surfaces",
      "subject": [
        "math.AG"
      ],
      "abstract": "We take the fundamental group of the complement of the branch curve of a\ngeneric projection induced from canonical embedding of a surface. This group is\nstable on connected components of moduli spaces of surfaces. Since for many\nclasses of surfaces it is expected that the fundamental group has a polycyclic\nstructure, we define a new invariant that comes from this structure. We compute\nthis invariant for a few examples. Braid monodromy factorizations related to\ncurves is a first step in computing the fundamental group of the complement of\nthe curve, and thus we also indicate the possibility of using braid monodromy\nfactorizations of branch curves as an invariant of a surface."
    }
  ],
  [
    {
      "paper_id": "1906.06289v2",
      "title": "Multi-Carrier Agile Phased Array Radar",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Modern radar systems are expected to operate reliably in congested\nenvironments. A candidate technology for meeting these demands is frequency\nagile radar (FAR), which randomly changes its carrier frequencies. FAR is known\nto improve the electronic counter-countermeasures (ECCM) performance while\nfacilitating operation in congested setups. To enhance the target recovery\nperformance of FAR in complex electromagnetic environments, we propose two\nradar schemes extending FAR to multi-carrier waveforms. The first is Wideband\nMulti-carrier Agile Radar (WMAR), which transmits/receives wideband waveforms\nsimultaneously with every antenna. To mitigate the demanding hardware\nrequirements associated with wideband waveforms used by WMAR, we next propose\nmulti-Carrier AgilE phaSed Array Radar (CAESAR). CAESAR uses narrowband\nmonotone waveforms, thus facilitating ease of implementation of the system,\nwhile introducing {\\em spatial agility}. We characterize the transmitted and\nreceived signals of the proposed schemes, and develop an algorithm for\nrecovering the targets, based on concepts from compressed sensing to estimate\nthe range-Doppler parameters of the targets. We then derive conditions which\nguarantee their accurate reconstruction. Our numerical study demonstrates that\nboth multi-carrier schemes improve performance compared to FAR while\nmaintaining its practical benefits. We also demonstrate that the performance of\nCAESAR, which uses monotone waveforms, is within a small gap from the wideband\nradar."
    },
    {
      "paper_id": "1906.06380v1",
      "title": "Time Synchronization in 5G Wireless Edge: Requirements and Solutions for\n  Critical-MTC",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Wireless edge is about distributing intelligence to the wireless devices\nwherein the distribution of accurate time reference is essential for\ntime-critical machine-type communication (cMTC). In 5G-based cMTC, enabling\ntime synchronization in the wireless edge means moving beyond the current\nsynchronization needs and solutions in 5G radio access. In this article, we\nanalyze the device-level synchronization needs of potential cMTC applications:\nindustrial automation, power distribution, vehicular communication, and live\naudio/video production. We present an over-the-air (OTA) synchronization scheme\ncomprised of 5G air interface parameters, and discuss their associated timing\nerrors. We evaluate the estimation error in device-to-base station propagation\ndelay from timing advance (TA) under random errors and show how to reduce the\nestimation error. In the end, we identify the random errors specific to dense\nmultipath fading environments and discuss countermeasures."
    }
  ],
  [
    {
      "paper_id": "2412.15281v1",
      "title": "Minimal subshifts of prescribed mean dimension over general alphabets",
      "subject": [
        "math.DS"
      ],
      "abstract": "Let $G$ be a countable infinite amenable group, $K$ a finite-dimensional\ncompact metrizable space, and $(K^G,\\sigma)$ the full $G$-shift on $K^G$. For\nany $r\\in [0,{\\rm mdim}(K^G,\\sigma))$, we construct a minimal subshift\n$(X,\\sigma)$ of $(K^G,\\sigma)$ with mdim$(X,\\sigma)=r$. Furthermore, we\nconstruct a subshift of $([0,1]^G,\\sigma)$ such that its mean dimension is $1$,\nand that the set of all attainable values of the mean dimension of its minimal\nsubsystems is exactly the interval $[0,1)$."
    },
    {
      "paper_id": "2412.15528v1",
      "title": "Pullback measure attractors and limiting behaviors of McKean-Vlasov\n  stochastic delay lattice systems",
      "subject": [
        "math.DS"
      ],
      "abstract": "We study the long-term behavior of the distribution of the solution process\nto the non-autonomous McKean-Vlasov stochastic delay lattice system defined on\nthe integer set $\\mathbb{Z}$. Specifically, we first establish the\nwell-posedness of solutions for this non-autonomous, distribution-dependent\nstochastic delay lattice system. Then, we prove the existence and uniqueness of\npullback measure attractors for the non-autonomous dynamical system generated\nby the solution operators, defined in the space of probability measures.\nFurthermore, as an application of the pullback measure attractor, we prove the\nergodicity and exponentially mixing of invariant measures for the system under\nappropriate conditions. Finally, we establish the upper semi-continuity of\nthese attractors as the distribution-dependent stochastic delay lattice system\nconverges to a distribution-independent system."
    }
  ]
]