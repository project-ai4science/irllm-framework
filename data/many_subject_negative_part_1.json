[
  [
    {
      "paper_id": "1206.2966v2",
      "title": "Panel Data Models with Nonadditive Unobserved Heterogeneity: Estimation\n  and Inference",
      "subject": [
        "stat.AP",
        "stat.TH"
      ],
      "abstract": "This paper considers fixed effects estimation and inference in linear and\nnonlinear panel data models with random coefficients and endogenous regressors.\nThe quantities of interest -- means, variances, and other moments of the random\ncoefficients -- are estimated by cross sectional sample moments of GMM\nestimators applied separately to the time series of each individual. To deal\nwith the incidental parameter problem introduced by the noise of the\nwithin-individual estimators in short panels, we develop bias corrections.\nThese corrections are based on higher-order asymptotic expansions of the GMM\nestimators and produce improved point and interval estimates in moderately long\npanels. Under asymptotic sequences where the cross sectional and time series\ndimensions of the panel pass to infinity at the same rate, the uncorrected\nestimator has an asymptotic bias of the same order as the asymptotic variance.\nThe bias corrections remove the bias without increasing variance. An empirical\nexample on cigarette demand based on Becker, Grossman and Murphy (1994) shows\nsignificant heterogeneity in the price effect across U.S. states."
    },
    {
      "paper_id": "2202.03234v1",
      "title": "Generalised norm resolvent convergence: comparison of different concepts",
      "subject": [
        "math.FA",
        "math.SP"
      ],
      "abstract": "In this paper, we show that the two concepts of generalised norm resolvent\nconvergence introduced by Weidmann and the first author of this paper are\nequivalent. We also focus on the convergence speed and provide conditions under\nwhich the convergence speed is the same for both concepts. We illustrate the\nabstract results by a large number of examples."
    }
  ],
  [
    {
      "paper_id": "1506.05620v2",
      "title": "A parameterized approximation algorithm for the mixed and windy\n  Capacitated Arc Routing Problem: theory and experiments",
      "subject": [
        "cs.DS",
        "cs.DM"
      ],
      "abstract": "We prove that any polynomial-time $\\alpha(n)$-approximation algorithm for the\n$n$-vertex metric asymmetric Traveling Salesperson Problem yields a\npolynomial-time $O(\\alpha(C))$-approximation algorithm for the mixed and windy\nCapacitated Arc Routing Problem, where $C$ is the number of weakly connected\ncomponents in the subgraph induced by the positive-demand arcs---a small number\nin many applications. In conjunction with known results, we obtain\nconstant-factor approximations for $C\\in O(\\log n)$ and $O(\\log C/\\log\\log\nC)$-approximations in general. Experiments show that our algorithm, together\nwith several heuristic enhancements, outperforms many previous polynomial-time\nheuristics. Finally, since the solution quality achievable in polynomial time\nappears to mainly depend on $C$ and since $C=1$ in almost all benchmark\ninstances, we propose the Ob benchmark set, simulating cities that are divided\ninto several components by a river."
    },
    {
      "paper_id": "0901.1400v1",
      "title": "Variation of quasiconformal mappings on lines",
      "subject": [
        "math.CV",
        "math.AP"
      ],
      "abstract": "We obtain improved regularity of homeomorphic solutions of the reduced\nBeltrami equation, as compared to the standard Beltrami equation. Such an\nimprovement is not possible in terms of Holder or Sobolev regularity; instead,\nour results concern the generalized variation of restrictions to lines.\nSpecifically, we prove that the restriction to any line segment has finite\np-variation for all p>1 but not necessarily for p=1."
    }
  ],
  [
    {
      "paper_id": "1710.01236v6",
      "title": "netgwas: An R Package for Network-Based Genome-Wide Association Studies",
      "subject": [
        "q-bio.BM",
        "q-bio.GN",
        "q-bio.MN",
        "q-bio.PE"
      ],
      "abstract": "Graphical models are a powerful tool in modelling and analysing complex\nbiological associations in high-dimensional data. The R-package netgwas\nimplements the recent methodological development on copula graphical models to\n(i) construct linkage maps, (ii) infer linkage disequilibrium networks from\ngenotype data, and (iii) detect high-dimensional genotype-phenotype networks.\nThe netgwas learns the structure of networks from ordinal data and mixed\nordinal-and-continuous data. Here, we apply the functionality in netgwas to\nvarious multivariate example datasets taken from the literature to demonstrate\nthe kind of insight that can be obtained from the package. We show that our\npackage offers a more realistic association analysis than the classical\napproaches, as it discriminates between direct and induced correlations by\nadjusting for the effect of all other variables while performing pairwise\nassociations. This feature controls for spurious interactions between variables\nthat can arise from conventional approaches in a biological sense. The netgwas\npackage uses a parallelization strategy on multi-core processors to speed-up\ncomputations. The netgwas package is freely available at\nhttps://cran.r-project.org/web/packages/netgwas"
    },
    {
      "paper_id": "2103.05504v1",
      "title": "Status of the wave function of Quantum Mechanics, or, What is Quantum\n  Mechanics trying to tell us?",
      "subject": [
        "physics.hist-ph",
        "hep-th",
        "quant-ph"
      ],
      "abstract": "The most debated status of the wave function of Quantum Mechanics is\ndiscussed in the light of the epistemological vs ontological opposition."
    }
  ],
  [
    {
      "paper_id": "1011.6268v1",
      "title": "Quantitative Analysis of Bloggers Collective Behavior Powered by\n  Emotions",
      "subject": [
        "physics.soc-ph",
        "cond-mat.stat-mech"
      ],
      "abstract": "Large-scale data resulting from users online interactions provide the\nultimate source of information to study emergent social phenomena on the Web.\nFrom individual actions of users to observable collective behaviors, different\nmechanisms involving emotions expressed in the posted text play a role. Here we\ncombine approaches of statistical physics with machine-learning methods of text\nanalysis to study emergence of the emotional behavior among Web users. Mapping\nthe high-resolution data from digg.com onto bipartite network of users and\ntheir comments onto posted stories, we identify user communities centered\naround certain popular posts and determine emotional contents of the related\ncomments by the emotion-classifier developed for this type of texts. Applied\nover different time periods, this framework reveals strong correlations between\nthe excess of negative emotions and the evolution of communities. We observe\navalanches of emotional comments exhibiting significant self-organized critical\nbehavior and temporal correlations. To explore robustness of these critical\nstates, we design a network automaton model on realistic network connections\nand several control parameters, which can be inferred from the dataset.\nDissemination of emotions by a small fraction of very active users appears to\ncritically tune the collective states."
    },
    {
      "paper_id": "1905.10982v1",
      "title": "An Intelligent Monitoring System of Vehicles on Highway Traffic",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Vehicle speed monitoring and management of highways is the critical problem\nof the road in this modern age of growing technology and population. A poor\nmanagement results in frequent traffic jam, traffic rules violation and fatal\nroad accidents. Using traditional techniques of RADAR, LIDAR and LASAR to\naddress this problem is time-consuming, expensive and tedious. This paper\npresents an efficient framework to produce a simple, cost efficient and\nintelligent system for vehicle speed monitoring. The proposed method uses an HD\n(High Definition) camera mounted on the road side either on a pole or on a\ntraffic signal for recording video frames. On the basis of these frames, a\nvehicle can be tracked by using radius growing method, and its speed can be\ncalculated by calculating vehicle mask and its displacement in consecutive\nframes. The method uses pattern recognition, digital image processing and\nmathematical techniques for vehicle detection, tracking and speed calculation.\nThe validity of the proposed model is proved by testing it on different\nhighways."
    }
  ],
  [
    {
      "paper_id": "1911.00431v2",
      "title": "Composition of Bhargava's Cubes over Number Fields",
      "subject": [
        "math.NT"
      ],
      "abstract": "In this paper, the composition of Bhargava's cubes is generalized to the ring\nof integers of a number field of narrow class number one, excluding the case of\ntotally imaginary number fields."
    },
    {
      "paper_id": "1604.05350v1",
      "title": "Counting and Enumerating Crossing-free Geometric Graphs",
      "subject": [
        "cs.CG"
      ],
      "abstract": "We describe a framework for counting and enumerating various types of\ncrossing-free geometric graphs on a planar point set. The framework generalizes\nideas of Alvarez and Seidel, who used them to count triangulations in time\n$O(2^nn^2)$ where $n$ is the number of points. The main idea is to reduce the\nproblem of counting geometric graphs to counting source-sink paths in a\ndirected acyclic graph.\n  The following new results will emerge. The number of all crossing-free\ngeometric graphs can be computed in time $O(c^nn^4)$ for some $c < 2.83929$.\nThe number of crossing-free convex partitions can be computed in time\n$O(2^nn^4)$. The number of crossing-free perfect matchings can be computed in\ntime $O(2^nn^4)$. The number of convex subdivisions can be computed in time\n$O(2^nn^4)$. The number of crossing-free spanning trees can be computed in time\n$O(c^nn^4)$ for some $c < 7.04313$. The number of crossing-free spanning cycles\ncan be computed in time $O(c^nn^4)$ for some $c < 5.61804$.\n  With the same bounds on the running time we can construct data structures\nwhich allow fast enumeration of the respective classes. For example, after\n$O(2^nn^4)$ time of preprocessing we can enumerate the set of all crossing-free\nperfect matchings using polynomial time per enumerated object. For\ncrossing-free perfect matchings and convex partitions we further obtain\nenumeration algorithms where the time delay for each (in particular, the first)\noutput is bounded by a polynomial in $n$.\n  All described algorithms are comparatively simple, both in terms of their\nanalysis and implementation."
    }
  ],
  [
    {
      "paper_id": "2111.09414v1",
      "title": "Developmental Status and Perspectives for Tissue Engineering in Urology",
      "subject": [
        "q-bio.TO"
      ],
      "abstract": "Tissue engineering technology and tissue cell-based stem cell research have\nmade great strides in treating tissue and organ damage, correcting tissue and\norgan dysfunction, and reducing surgical complications. In the past,\ntraditional methods have used biological substitutes for tissue repair\nmaterials, while tissue engineering technology has focused on merging sperm\ncells with biological materials to form biological tissues with the same\nstructure and function as their own tissues. The advantage is that tissue\nengineering technology can overcome donors. Material procurement restrictions\ncan effectively reduce complications. The aim of studying tissue engineering\ntechnology is to find sperm cells and suitable biological materials to replace\nthe original biological functions of tissues and to establish a suitable in\nvivo microenvironment. This article mainly describes the current developments\nof tissue engineering in various fields of urology and discusses the future\ntrends of tissue engineering technology in the treatment of complex diseases of\nthe urinary system. The results of the research in this article indicate that\nwhile the current clinical studies are relatively few, the good results from\nexisting animal model studies indicate good prospects of tissue engineering\ntechnology for the treatment of various urinary tract diseases in the future."
    },
    {
      "paper_id": "1401.0087v1",
      "title": "Contributors of carbon dioxide in the atmosphere in Europe: the surface\n  response analysis",
      "subject": [
        "stat.AP",
        "stat.CO",
        "stat.TH"
      ],
      "abstract": "This paper is a continuation of the statistical modeling of the nonlinear\nrelationship between atmospheric CO2 and attributable variables that can\naccount for emissions, based on data from EU countries, in order to compare the\nrelevant findings to those obtained in the case of US data, in [1, 2]. The\ncurrent study was initiated in [3], leading to the optimal second-order model,\nbased on three linear terms and five second-order terms. We conclude this study\nin the present work, by finding the canonical decomposition of the nonlinear\nmodel, and by computing the specific two-dimensional confidence regions that it\nleads to. We then use the model in order to quantify the net effect of various\nrisk factors, and compare to the results obtained in the US case."
    }
  ],
  [
    {
      "paper_id": "2104.11365v1",
      "title": "Can You Trust Your Trust Measure?",
      "subject": [
        "cs.HC",
        "cs.RO"
      ],
      "abstract": "Trust in human-robot interactions (HRI) is measured in two main ways: through\nsubjective questionnaires and through behavioral tasks. To optimize\nmeasurements of trust through questionnaires, the field of HRI faces two\nchallenges: the development of standardized measures that apply to a variety of\nrobots with different capabilities, and the exploration of social and\nrelational dimensions of trust in robots (e.g., benevolence). In this paper we\nlook at how different trust questionnaires fare given these challenges that\npull in different directions (being general vs. being exploratory) by studying\nwhether people think the items in these questionnaires are applicable to\ndifferent kinds of robots and interactions. In Study 1 we show that after being\npresented with a robot (non-humanoid) and an interaction scenario (fire\nevacuation), participants rated multiple questionnaire items such as \"This\nrobot is principled\" as \"Non-applicable to robots in general\" or\n\"Non-applicable to this robot\". In Study 2 we show that the frequency of these\nratings change (indeed, even for items rated as N/A to robots in general) when\na new scenario is presented (game playing with a humanoid robot). Finally,\nwhile overall trust scores remained robust to N/A ratings, our results revealed\npotential fallacies in the way these scores are commonly interpreted. We\nconclude with recommendations for the development, use and results-reporting of\ntrust questionnaires for future studies, as well as theoretical implications\nfor the field of HRI."
    },
    {
      "paper_id": "1806.06696v1",
      "title": "SMOGS: Social Network Metrics of Game Success",
      "subject": [
        "stat.AP"
      ],
      "abstract": "This paper develops metrics from a social network perspective that are\ndirectly translatable to the outcome of a basketball game. We extend a\nstate-of-the-art multi-resolution stochastic process approach to modeling\nbasketball by modeling passes between teammates as directed dynamic relational\nlinks on a network and introduce multiplicative latent factors to study\nhigher-order patterns in players' interactions that distinguish a successful\ngame from a loss. Parameters are estimated using a Markov chain Monte Carlo\nsampler. Results in simulation experiments suggest that the sampling scheme is\neffective in recovering the parameters. We then apply the model to the first\nhigh-resolution optical tracking dataset collected in college basketball games.\nThe learned latent factors demonstrate significant differences between players'\npassing and receiving tendencies in a loss than those in a win. The model is\napplicable to team sports other than basketball, as well as other time-varying\nnetwork observations."
    }
  ],
  [
    {
      "paper_id": "2311.05862v1",
      "title": "Emergence and reconfiguration of modular structure for synaptic neural\n  networks during continual familiarity detection",
      "subject": [
        "q-bio.NC",
        "q-bio.QM"
      ],
      "abstract": "While advances in artificial intelligence and neuroscience have enabled the\nemergence of neural networks capable of learning a wide variety of tasks, our\nunderstanding of the temporal dynamics of these networks remains limited. Here,\nwe study the temporal dynamics during learning of Hebbian Feedforward (HebbFF)\nneural networks in tasks of continual familiarity detection. Drawing\ninspiration from the field of network neuroscience, we examine the network's\ndynamic reconfiguration, focusing on how network modules evolve throughout\nlearning. Through a comprehensive assessment involving metrics like network\naccuracy, modular flexibility, and distribution entropy across diverse learning\nmodes, our approach reveals various previously unknown patterns of network\nreconfiguration. In particular, we find that the emergence of network\nmodularity is a salient predictor of performance, and that modularization\nstrengthens with increasing flexibility throughout learning. These insights not\nonly elucidate the nuanced interplay of network modularity, accuracy, and\nlearning dynamics but also bridge our understanding of learning in artificial\nand biological realms."
    },
    {
      "paper_id": "1305.0983v2",
      "title": "Real-Time Welfare-Maximizing Regulation Allocation in Dynamic\n  Aggregator-EVs System",
      "subject": [
        "cs.SY",
        "cs.PF"
      ],
      "abstract": "The concept of vehicle-to-grid (V2G) has gained recent interest as more and\nmore electric vehicles (EVs) are put to use. In this paper, we consider a\ndynamic aggregator-EVs system, where an aggregator centrally coordinates a\nlarge number of dynamic EVs to perform regulation service. We propose a\nWelfare-Maximizing Regulation Allocation (WMRA) algorithm for the aggregator to\nfairly allocate the regulation amount among its EVs. Compared to previous\nworks, WMRA accommodates a wide spectrum of vital system characteristics,\nincluding dynamics of EV, limited EV battery size, EV battery degradation cost,\nand the cost of using external energy sources for the aggregator. The algorithm\noperates in real time and does not require any prior knowledge of the\nstatistical information of the system. Theoretically, we demonstrate that WMRA\nis away from the optimum by O(1/V), where V is a controlling parameter\ndepending on EV's battery size. In addition, our simulation results indicate\nthat WMRA can substantially outperform a suboptimal greedy algorithm."
    }
  ],
  [
    {
      "paper_id": "1309.6610v3",
      "title": "Adversarial Multiple Access Channels with Individual Injection Rates",
      "subject": [
        "cs.DC",
        "cs.NI"
      ],
      "abstract": "We study deterministic distributed broadcasting in synchronous\nmultiple-access channels. Packets are injected into $n$ nodes by a window-type\nadversary that is constrained by a window $w$ and injection rates individually\nassigned to all nodes. We investigate what queue size and packet latency can be\nachieved with the maximum aggregate injection rate of one packet per round,\ndepending on properties of channels and algorithms. We give a non-adaptive\nalgorithm for channels with collision detection and an adaptive algorithm for\nchannels without collision detection that achieve $O(\\min(n+w,w\\log n))$ packet\nlatency. We show that packet latency has to be either $\\Omega(w \\max (1,\\log_w\nn))$, when $w\\le n$, or $\\Omega(w+n)$, when $w>n$, as a matching lower bound to\nthese algorithms. We develop a non-adaptive algorithm for channels without\ncollision detection that achieves $O(n+w)$ queue size and $O(nw)$ packet\nlatency. This is in contrast with the adversarial model of global injection\nrates, in which non-adaptive algorithms with bounded packet latency do not\nexist (Chlebus et al. Distributed Computing 22(2): 93 - 116, 2009). Our\nalgorithm avoids collisions produced by simultaneous transmissions; we show\nthat any algorithm with this property must have $\\Omega(nw)$ packet latency."
    },
    {
      "paper_id": "1103.5665v1",
      "title": "Evaluating the Precision of Estimators of Quantile-Based Risk Measures",
      "subject": [
        "q-fin.RM",
        "q-fin.ST"
      ],
      "abstract": "This paper examines the precision of estimators of Quantile-Based Risk\nMeasures (Value at Risk, Expected Shortfall, Spectral Risk Measures). It first\naddresses the question of how to estimate the precision of these estimators,\nand proposes a Monte Carlo method that is free of some of the limitations of\nexisting approaches. It then investigates the distribution of risk estimators,\nand presents simulation results suggesting that the common practice of relying\non asymptotic normality results might be unreliable with the sample sizes\ncommonly available to them. Finally, it investigates the relationship between\nthe precision of different risk estimators and the distribution of underlying\nlosses (or returns), and yields a number of useful conclusions."
    }
  ],
  [
    {
      "paper_id": "2303.17696v1",
      "title": "Dual Cross-Attention for Medical Image Segmentation",
      "subject": [
        "eess.IV"
      ],
      "abstract": "We propose Dual Cross-Attention (DCA), a simple yet effective attention\nmodule that is able to enhance skip-connections in U-Net-based architectures\nfor medical image segmentation. DCA addresses the semantic gap between encoder\nand decoder features by sequentially capturing channel and spatial dependencies\nacross multi-scale encoder features. First, the Channel Cross-Attention (CCA)\nextracts global channel-wise dependencies by utilizing cross-attention across\nchannel tokens of multi-scale encoder features. Then, the Spatial\nCross-Attention (SCA) module performs cross-attention to capture spatial\ndependencies across spatial tokens. Finally, these fine-grained encoder\nfeatures are up-sampled and connected to their corresponding decoder parts to\nform the skip-connection scheme. Our proposed DCA module can be integrated into\nany encoder-decoder architecture with skip-connections such as U-Net and its\nvariants. We test our DCA module by integrating it into six U-Net-based\narchitectures such as U-Net, V-Net, R2Unet, ResUnet++, DoubleUnet and\nMultiResUnet. Our DCA module shows Dice Score improvements up to 2.05% on GlaS,\n2.74% on MoNuSeg, 1.37% on CVC-ClinicDB, 1.12% on Kvasir-Seg and 1.44% on\nSynapse datasets. Our codes are available at:\nhttps://github.com/gorkemcanates/Dual-Cross-Attention"
    },
    {
      "paper_id": "2010.13149v3",
      "title": "Approximating Aggregated SQL Queries With LSTM Networks",
      "subject": [
        "cs.DB",
        "cs.AI"
      ],
      "abstract": "Despite continuous investments in data technologies, the latency of querying\ndata still poses a significant challenge. Modern analytic solutions require\nnear real-time responsiveness both to make them interactive and to support\nautomated processing. Current technologies (Hadoop, Spark, Dataflow) scan the\ndataset to execute queries. They focus on providing a scalable data storage to\nmaximize task execution speed. We argue that these solutions fail to offer an\nadequate level of interactivity since they depend on continual access to data.\nIn this paper we present a method for query approximation, also known as\napproximate query processing (AQP), that reduce the need to scan data during\ninference (query calculation), thus enabling a rapid query processing tool. We\nuse LSTM network to learn the relationship between queries and their results,\nand to provide a rapid inference layer for predicting query results. Our method\n(referred as ``Hunch``) produces a lightweight LSTM network which provides a\nhigh query throughput. We evaluated our method using twelve datasets and\ncompared to state-of-the-art AQP engines (VerdictDB, BlinkDB) from query\nlatency, model weight and accuracy perspectives. The results show that our\nmethod predicted queries' results with a normalized root mean squared error\n(NRMSE) ranging from approximately 1\\% to 4\\% which in the majority of our data\nsets was better then the compared benchmarks. Moreover, our method was able to\npredict up to 120,000 queries in a second (streamed together), and with a\nsingle query latency of no more than 2ms."
    }
  ],
  [
    {
      "paper_id": "2401.15253v1",
      "title": "Testing the Exogeneity of Instrumental Variables and Regressors in\n  Linear Regression Models Using Copulas",
      "subject": [
        "econ.EM"
      ],
      "abstract": "We provide a Copula-based approach to test the exogeneity of instrumental\nvariables in linear regression models. We show that the exogeneity of\ninstrumental variables is equivalent to the exogeneity of their standard normal\ntransformations with the same CDF value. Then, we establish a Wald test for the\nexogeneity of the instrumental variables. We demonstrate the performance of our\ntest using simulation studies. Our simulations show that if the instruments are\nactually endogenous, our test rejects the exogeneity hypothesis approximately\n93% of the time at the 5% significance level. Conversely, when instruments are\ntruly exogenous, it dismisses the exogeneity assumption less than 30% of the\ntime on average for data with 200 observations and less than 2% of the time for\ndata with 1,000 observations. Our results demonstrate our test's effectiveness,\noffering significant value to applied econometricians."
    },
    {
      "paper_id": "2111.04199v2",
      "title": "Proteins Evolution Upon Point Mutations",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "The primary aim of this work is to explore how proteins point mutations\nimpact their marginal stability and, hence, their evolvability. With this\npurpose, we show that the use of four classic notions, namely, those from\nLeibniz & Kant (1768), Maynard Smith (1970), Einstein & Infeld (1961), and\nAnfinsen (1973), is sufficient for a better understanding of the\nprotein-evolution and, consequently, to determine the factors that could\ncontrol it. The preliminary results -- without considering epistasis effects\nexplicitly -- indicate that the protein marginal-stability change upon point\nmutations provides the necessary and sufficient information to describe,\nthrough a Boltzmann factor, the evolution of the amide hydrogen-exchange\nprotection factors. This finding is of paramount importance because it\nillustrates the impact of point mutations on both the protein\nmarginal-stability and the ensemble of folded conformations coexisting with the\nnative state and, in the presence of metamorphism, on the propensity for the\nappearance of new folds and functions."
    }
  ],
  [
    {
      "paper_id": "1311.0654v1",
      "title": "Reunion probabilities of $N$ one-dimensional random walkers with mixed\n  boundary conditions",
      "subject": [
        "math.MP"
      ],
      "abstract": "In this work we extend the results of the reunion probability of $N$\none-dimensional random walkers to include mixed boundary conditions between\ntheir trajectories. The level of the mixture is controlled by a parameter $c$,\nwhich can be varied from $c=0$ (independent walkers) to $c\\to\\infty$ (vicious\nwalkers). The expressions are derived by using Quantum Mechanics formalism\n(QMf) which allows us to map this problem into a Lieb-Liniger gas (LLg) of $N$\none-dimensional particles. We use Bethe ansatz and Gaudin's conjecture to\nobtain the normalized wave-functions and use this information to construct the\npropagator. As it is well-known, depending on the boundary conditions imposed\nat the endpoints of a line segment, the statistics of the maximum heights of\nthe reunited trajectories have some connections with different ensembles in\nRandom Matrix Theory (RMT). Here we seek to extend those results and consider\nfour models: absorbing, periodic, reflecting, and mixed. In all four cases, the\nprobability that the maximum height is less or equal than $L$ takes the form\n$F_N(L)=A_N\\sum_{k\\in\\Omega_{B}}\\int Dz\ne^{-\\sum_{j=1}^Nk_j^2+G_N(k)-\\sum_{j,\\ell=1}^N\nz_jV_{j\\ell}(k)\\overline{z}_\\ell}$, where $A_N$ is a normalization constant,\n$G_N(k)$ and $V_{j\\ell}(k)$ depend on the type of boundary condition, and\n$\\Omega_{B}$ is the solution set of quasi-momenta $k$ obeying the Bethe\nequations for that particular boundary condition."
    },
    {
      "paper_id": "2112.07268v2",
      "title": "Finding the Instrumental Variables of Household Registration: A\n  discussion of the impact of China's household registration system on the\n  citizenship of the migrant population",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Due to the specificity of China's dualistic household registration system and\nthe differences in the rights and interests attached to it, household\nregistration is prevalent as a control variable in the empirical evidence. In\nthe context of family planning policies, this paper proposes to use family size\nand number of children as instrumental variables for household registration,\nand discusses qualitatively and statistically verifies their relevance and\nexogeneity, while empirically analyzing the impact of the household\nregistration system on citizenship of the mobile population. After controlling\nfor city, individual control variables and fixed effects, the following\nconclusions are drawn: family size and number of children pass the\nover-identification test when used as instrumental variables for household\nregistration; non-agricultural households have about 20.2% lower settlement\nintentions and 7.28% lower employment levels in inflow cities than agricultural\nhouseholds; the mechanism of the effect of the nature of household registration\non employment still holds for the non-mobile population group."
    }
  ],
  [
    {
      "paper_id": "1204.3126v2",
      "title": "Characterisation of placental malaria in olive baboons (Papio anubis)\n  infected with Plasmodium knowlesi H strain",
      "subject": [
        "q-bio.CB"
      ],
      "abstract": "Pregnant women have increased susceptibility to malaria infection. In these\nwomen, malaria parasites are frequently found sequestered in the placental\nintervillous spaces, a condition referred to as placental malaria (PM).\nPlacental malaria threatens the health of the mother and the child's life by\ncausing still births and reduction in gestational age. An estimated 24 million\npregnant women in Sub-Saharan Africa are at risk. Mechanisms responsible for\nincreased susceptibility in pregnant women are not fully understood. Pregnancy\nmalaria studies have been limited by the lack of a suitable animal model. This\nresearch aimed to develop a baboon (Papio anubis) model for studying PM. The\npregnancies of three adult female baboons were synchronized and their\ngestational levels confirmed by ultrasonography. On the 150th day of gestation\nthe pregnant baboons were infected with Plasmodium knowlesi H strain parasites\ntogether with four nulligravid control baboons. Parasitaemia was monitored from\ntwo days post inoculation until the 159th day of gestation when caesarean\nsection was done on one baboon in order to obtain the placenta. Two baboons\naborted their conceptus. Smears prepared from placental blood demonstrated the\npresence of Plasmodium knowlesi parasites in all the three sampled placentas.\nThese new findings show that P. knowlesi sequesters in the baboon placenta. In\naddition, this study has characterized haemoglobin, eosinophil, Immunoglobulin\nG and Immunoglobulin M profiles in this model. Thus a non human primate\n(baboon) model for studying PM has been established. The established baboon -\nP. knowlesi model for studying human placental/pregnancy malaria now offers an\nopportunity for circumventing the obstacles experienced during human studies\nlike having inadequate tissue for analysis, inaccurate estimation of\ngestational age, moral, ethical and financial limitations."
    },
    {
      "paper_id": "2411.01857v2",
      "title": "On $\\ell_p$-Vietoris-Rips complexes",
      "subject": [
        "cs.CG"
      ],
      "abstract": "We study the concepts of the $\\ell_p$-Vietoris-Rips simplicial set and the\n$\\ell_p$-Vietoris-Rips complex of a metric space, where $1\\leq p \\leq \\infty.$\nThis theory unifies two established theories: for $p=\\infty,$ this is the\nclassical theory of Vietoris-Rips complexes, and for $p=1,$ this corresponds to\nthe blurred magnitude homology theory. We prove several results that are known\nfor the Vietoris-Rips complex in the general case: (1) we prove a stability\ntheorem for the corresponding version of the persistent homology; (2) we show\nthat, for a compact Riemannian manifold and a sufficiently small scale\nparameter, all the \"$\\ell_p$-Vietoris-Rips spaces\" are homotopy equivalent to\nthe manifold; (3) we demonstrate that the $\\ell_p$-Vietoris-Rips spaces are\ninvariant (up to homotopy) under taking the metric completion. Additionally, we\nshow that the limit of the homology groups of the $\\ell_p$-Vietoris-Rips\nspaces, as the scale parameter tends to zero, does not depend on $p$; and that\nthe homology groups of the $\\ell_p$-Vietoris-Rips spaces commute with filtered\ncolimits of metric spaces."
    }
  ],
  [
    {
      "paper_id": "1508.00399v4",
      "title": "Capturing rogue waves by multi-point statistics",
      "subject": [
        "physics.data-an",
        "nlin.PS",
        "physics.ao-ph"
      ],
      "abstract": "As an example for complex systems with extreme events we investigate ocean\nwave states exhibiting rogue waves. We present a statistical method of data\nanalysis based on multi-point statistics which for the first time allows\ngrasping extreme rogue wave events in a statistically highly satisfactory\nmanner. The key to the success of the approach is mapping the complexity of\nmulti-point data onto the statistics of hierarchically ordered height\nincrements for different time scales for which we can show that a stochastic\ncascade process with Markov properties is governed by a Fokker-Planck equation.\nConditional probabilities as well as the Fokker-Planck equation itself can be\nestimated directly from the available observational data. With this stochastic\ndescription surrogate data sets can in turn be generated allowing to work out\narbitrary statistical features of the complex sea state in general and extreme\nrogue wave events in particular. The results also open up new perspectives for\nforecasting the occurrence probability of extreme rogue wave events, and even\nfor forecasting the occurrence of individual rogue waves based on precursory\ndynamics."
    },
    {
      "paper_id": "2209.01378v1",
      "title": "Tree-Based Learning in RNNs for Power Consumption Forecasting",
      "subject": [
        "eess.SP"
      ],
      "abstract": "A Recurrent Neural Network that operates on several time lags, called an\nRNN(p), is the natural generalization of an Autoregressive ARX(p) model. It is\na powerful forecasting tool when different time scales can influence a given\nphenomenon, as it happens in the energy sector where hourly, daily, weekly and\nyearly interactions coexist. The cost-effective BPTT is the industry standard\nas learning algorithm for RNNs. We prove that, when training RNN(p) models,\nother learning algorithms turn out to be much more efficient in terms of both\ntime and space complexity. We also introduce a new learning algorithm, the Tree\nRecombined Recurrent Learning, that leverages on a tree representation of the\nunrolled network and appears to be even more effective. We present an\napplication of RNN(p) models for power consumption forecasting on the hourly\nscale: experimental results demonstrate the efficiency of the proposed\nalgorithm and the excellent predictive accuracy achieved by the selected model\nboth in point and in probabilistic forecasting of the energy consumption."
    }
  ],
  [
    {
      "paper_id": "1104.0910v1",
      "title": "Classes of fast and specific search mechanisms for proteins on DNA",
      "subject": [
        "q-bio.BM",
        "q-bio.SC"
      ],
      "abstract": "Problems of search and recognition appear over different scales in biological\nsystems. In this review we focus on the challenges posed by interactions\nbetween proteins, in particular transcription factors, and DNA and possible\nmechanisms which allow for a fast and selective target location. Initially we\nargue that DNA-binding proteins can be classified, broadly, into three distinct\nclasses which we illustrate using experimental data. Each class calls for a\ndifferent search process and we discuss the possible application of different\nsearch mechanisms proposed over the years to each class. The main thrust of\nthis review is a new mechanism which is based on barrier discrimination. We\nintroduce the model and analyze in detail its consequences. It is shown that\nthis mechanism applies to all classes of transcription factors and can lead to\na fast and specific search. Moreover, it is shown that the mechanism has\ninteresting transient features which allow for stability at the target despite\nrapid binding and unbinding of the transcription factor from the target."
    },
    {
      "paper_id": "1810.10805v1",
      "title": "Light-Quark Resonances at COMPASS",
      "subject": [
        "hep-ex",
        "hep-ph"
      ],
      "abstract": "The main goal of the spectroscopy program at COMPASS is to explore the\nlight-meson spectrum in the mass range below about $2\\,\\text{GeV}/c^2$ using\ndiffractive dissociation reactions. Our flagship channel is the production of\nthree charged pions in the reaction: $\\pi^- + p \\to \\pi^-\\pi^-\\pi^+ +\np_\\text{recoil}$, for which COMPASS has acquired the so far world's largest\ndataset of roughly $50\\,\\text{M}$ exclusive events using an $190\\,\\text{GeV}/c$\n$\\pi^-$ beam.\n  In order to extract the parameters of the $\\pi_J$ and $a_J$ resonances that\nappear in the $\\pi^-\\pi^-\\pi^+$ system, we performed the so far most\ncomprehensive resonance-model fit, using Breit-Wigner parametrizations. This\nmethod in combination with the high statistical precision of our data allows us\nto study ground and excited states. We study the $a_4(2040)$ resonance in the\n$\\rho(770)\\pi G$ and $f_2(1270)\\pi F$ decays. In addition to the ground state\nresonance $a_1(1260)$, we have found evidence for the $a_1(1640)$. We also\nstudy the spectrum of $\\pi_2$ states by simultaneously describing four\n$J^{PC}=2^{-+}$ waves using three $\\pi_2$ resonances, the $\\pi_2(1670)$, the\n$\\pi_2(1880)$, and the $\\pi_2(2005)$.\n  Using a novel analysis approach, where the resonance-model fit is performed\nsimultaneously in narrow bins of the squared four-momentum transfer $t'$\nbetween the beam pion and the target proton, allows us to study the $t'$\ndependence of resonant and non-resonant components included in our model. We\nobserve that for most of the partial waves, the non-resonant components show a\nsteeper $t'$ spectrum compared to the resonances and that the $t'$ spectrum of\nmost of the resonances becomes shallower with increasing resonance mass. We\nalso study the $t'$ dependence of the relative phases between resonance\ncomponents. The pattern we observe is consistent with a common production\nmechanism of these states."
    }
  ],
  [
    {
      "paper_id": "2011.05658v1",
      "title": "Disentangling Community-level Changes in Crime Trends During the\n  COVID-19 Pandemic in Chicago",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Recent studies exploiting city-level time series have shown that, around the\nworld, several crimes declined after COVID-19 containment policies have been\nput in place. Using data at the community-level in Chicago, this work aims to\nadvance our understanding on how public interventions affected criminal\nactivities at a finer spatial scale. The analysis relies on a two-step\nmethodology. First, it estimates the community-wise causal impact of social\ndistancing and shelter-in-place policies adopted in Chicago via Structural\nBayesian Time-Series across four crime categories (i.e., burglary, assault,\nnarcotics-related offenses, and robbery). Once the models detected the\ndirection, magnitude and significance of the trend changes, Firth's Logistic\nRegression is used to investigate the factors associated to the statistically\nsignificant crime reduction found in the first step of the analyses.\nStatistical results first show that changes in crime trends differ across\ncommunities and crime types. This suggests that beyond the results of aggregate\nmodels lies a complex picture characterized by diverging patterns. Second,\nregression models provide mixed findings regarding the correlates associated\nwith significant crime reduction: several relations have opposite directions\nacross crimes with population being the only factor that is stably and\npositively associated with significant crime reduction."
    },
    {
      "paper_id": "1212.0388v1",
      "title": "Hypergraph and protein function prediction with gene expression data",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Most network-based protein (or gene) function prediction methods are based on\nthe assumption that the labels of two adjacent proteins in the network are\nlikely to be the same. However, assuming the pairwise relationship between\nproteins or genes is not complete, the information a group of genes that show\nvery similar patterns of expression and tend to have similar functions (i.e.\nthe functional modules) is missed. The natural way overcoming the information\nloss of the above assumption is to represent the gene expression data as the\nhypergraph. Thus, in this paper, the three un-normalized, random walk, and\nsymmetric normalized hypergraph Laplacian based semi-supervised learning\nmethods applied to hypergraph constructed from the gene expression data in\norder to predict the functions of yeast proteins are introduced. Experiment\nresults show that the average accuracy performance measures of these three\nhypergraph Laplacian based semi-supervised learning methods are the same.\nHowever, their average accuracy performance measures of these three methods are\nmuch greater than the average accuracy performance measures of un-normalized\ngraph Laplacian based semi-supervised learning method (i.e. the baseline method\nof this paper) applied to gene co-expression network created from the gene\nexpression data."
    }
  ],
  [
    {
      "paper_id": "2310.04907v1",
      "title": "An Information Theory Approach to the Stock and Cryptocurrency Market: A\n  Statistical Equilibrium Perspective",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "We study the stochastic structure of cryptocurrency rates of returns as\ncompared to stock returns by focusing on the associated cross-sectional\ndistributions. We build two datasets. The first comprises forty-six major\ncryptocurrencies, and the second includes all the companies listed in the S&P\n500. We collect individual data from January 2017 until December 2022. We then\napply the Quantal Response Statistical Equilibrium (QRSE) model to recover the\ncross-sectional frequency distribution of the daily returns of cryptocurrencies\nand S&P 500 companies. We study the stochastic structure of these two markets\nand the properties of investors' behavior over bear and bull trends. Finally,\nwe compare the degree of informational efficiency of these two markets."
    },
    {
      "paper_id": "1303.1633v1",
      "title": "Joint power and admission control via p norm minimization deflation",
      "subject": [
        "math.IT"
      ],
      "abstract": "In an interference network, joint power and admission control aims to support\na maximum number of links at their specified signal to interference plus noise\nratio (SINR) targets while using a minimum total transmission power. In our\nprevious work, we formulated the joint control problem as a sparse\n$\\ell_0$-minimization problem and relaxed it to a $\\ell_1$-minimization\nproblem. In this work, we propose to approximate the $\\ell_0$-optimization\nproblem to a p norm minimization problem where $0<p<1$, since intuitively p\nnorm will approximate 0 norm better than 1 norm. We first show that the\n$\\ell_p$-minimization problem is strongly NP-hard and then derive a\nreformulation of it such that the well developed interior-point algorithms can\nbe applied to solve it. The solution to the $\\ell_p$-minimization problem can\nefficiently guide the link's removals (deflation). Numerical simulations show\nthe proposed heuristic outperforms the existing algorithms."
    }
  ],
  [
    {
      "paper_id": "2002.11954v1",
      "title": "Energy-Efficient Buffer-Aided Relaying Systems with Opportunistic\n  Spectrum Access",
      "subject": [
        "eess.SP"
      ],
      "abstract": "In this paper, an energy-efficient cross-layer design framework is proposed\nfor cooperative relaying networks, which takes into account the influence of\nspectrum utilization probability. Specifically, random arrival traffic is\nconsidered and an adaptive modulation and coding (AMC) scheme is adopted in the\ncooperative transmission system to improve the system performance. The average\npacket dropping rate of the relay-buffer is studied at first. With the packet\ndropping rate and stationary distribution of the system state, the closed-form\nexpression of the delay is derived. Then the energy efficiency for\nrelay-assisted transmission is investigated, which takes into account the\nqueueing process of the relay and the source. In this context, an energy\nefficiency optimization problem is formulated to determine the optimum strategy\nof power and time allocation for the relay-assisted cooperative system.\nFinally, the energy efficient switching strategy between the relay assisted\ntransmission and the direct transmission is obtained, where packet\ntransmissions have different delay requirements. In addition, energy efficient\ntransmission policy with AMC is obtained. Numerical results demonstrate the\neffectiveness of the proposed design improving the energy efficiency."
    },
    {
      "paper_id": "2207.14294v2",
      "title": "Knowledge-Driven Mechanistic Enrichment of the Preeclampsia Ignorome",
      "subject": [
        "cs.AI"
      ],
      "abstract": "Preeclampsia is a leading cause of maternal and fetal morbidity and\nmortality. Currently, the only definitive treatment of preeclampsia is delivery\nof the placenta, which is central to the pathogenesis of the disease.\nTranscriptional profiling of human placenta from pregnancies complicated by\npreeclampsia has been extensively performed to identify differentially\nexpressed genes (DEGs). The decisions to investigate DEGs experimentally are\nbiased by many factors, causing many DEGs to remain uninvestigated. A set of\nDEGs which are associated with a disease experimentally, but which have no\nknown association to the disease in the literature are known as the ignorome.\nPreeclampsia has an extensive body of scientific literature, a large pool of\nDEG data, and only one definitive treatment. Tools facilitating knowledge-based\nanalyses, which are capable of combining disparate data from many sources in\norder to suggest underlying mechanisms of action, may be a valuable resource to\nsupport discovery and improve our understanding of this disease. In this work\nwe demonstrate how a biomedical knowledge graph (KG) can be used to identify\nnovel preeclampsia molecular mechanisms. Existing open source biomedical\nresources and publicly available high-throughput transcriptional profiling data\nwere used to identify and annotate the function of currently uninvestigated\npreeclampsia-associated DEGs. Experimentally investigated genes associated with\npreeclampsia were identified from PubMed abstracts using text-mining\nmethodologies. The relative complement of the text-mined- and\nmeta-analysis-derived lists were identified as the uninvestigated\npreeclampsia-associated DEGs (n=445), i.e., the preeclampsia ignorome. Using\nthe KG to investigate relevant DEGs revealed 53 novel clinically relevant and\nbiologically actionable mechanistic associations."
    }
  ],
  [
    {
      "paper_id": "2410.22179v1",
      "title": "Very Attentive Tacotron: Robust and Unbounded Length Generalization in\n  Autoregressive Transformer-Based Text-to-Speech",
      "subject": [
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "abstract": "Autoregressive (AR) Transformer-based sequence models are known to have\ndifficulty generalizing to sequences longer than those seen during training.\nWhen applied to text-to-speech (TTS), these models tend to drop or repeat words\nor produce erratic output, especially for longer utterances. In this paper, we\nintroduce enhancements aimed at AR Transformer-based encoder-decoder TTS\nsystems that address these robustness and length generalization issues. Our\napproach uses an alignment mechanism to provide cross-attention operations with\nrelative location information. The associated alignment position is learned as\na latent property of the model via backprop and requires no external alignment\ninformation during training. While the approach is tailored to the monotonic\nnature of TTS input-output alignment, it is still able to benefit from the\nflexible modeling power of interleaved multi-head self- and cross-attention\noperations. A system incorporating these improvements, which we call Very\nAttentive Tacotron, matches the naturalness and expressiveness of a baseline\nT5-based TTS system, while eliminating problems with repeated or dropped words\nand enabling generalization to any practical utterance length."
    },
    {
      "paper_id": "2406.12721v2",
      "title": "Sound event detection based on auxiliary decoder and maximum probability\n  aggregation for DCASE Challenge 2024 Task 4",
      "subject": [
        "eess.AS"
      ],
      "abstract": "In this report, we propose three novel methods for developing a sound event\ndetection (SED) model for the DCASE 2024 Challenge Task 4. First, we propose an\nauxiliary decoder attached to the final convolutional block to improve feature\nextraction capabilities while reducing dependency on embeddings from\npre-trained large models. The proposed auxiliary decoder operates independently\nfrom the main decoder, enhancing performance of the convolutional block during\nthe initial training stages by assigning a different weight strategy between\nmain and auxiliary decoder losses. Next, to address the time interval issue\nbetween the DESED and MAESTRO datasets, we propose maximum probability\naggregation (MPA) during the training step. The proposed MPA method enables the\nmodel's output to be aligned with soft labels of 1 s in the MAESTRO dataset.\nFinally, we propose a multi-channel input feature that employs various versions\nof logmel and MFCC features to generate time-frequency pattern. The\nexperimental results demonstrate the efficacy of these proposed methods in a\nview of improving SED performance by achieving a balanced enhancement across\ndifferent datasets and label types. Ultimately, this approach presents a\nsignificant step forward in developing more robust and flexible SED models"
    }
  ],
  [
    {
      "paper_id": "2108.02328v1",
      "title": "A Distributed Application Placement and Migration Management Techniques\n  for Edge and Fog Computing Environments",
      "subject": [
        "cs.DC",
        "cs.PF"
      ],
      "abstract": "Fog/Edge computing model allows harnessing of resources in the proximity of\nthe Internet of Things (IoT) devices to support various types of real-time IoT\napplications. However, due to the mobility of users and a wide range of IoT\napplications with different requirements, it is a challenging issue to satisfy\nthese applications' requirements. The execution of IoT applications exclusively\non one fog/edge server may not be always feasible due to limited resources,\nwhile execution of IoT applications on different servers needs further\ncollaboration among servers. Also, considering user mobility, some modules of\neach IoT application may require migration to other servers for execution,\nleading to service interruption and extra execution costs. In this article, we\npropose a new weighted cost model for hierarchical fog computing environments,\nin terms of the response time of IoT applications and energy consumption of IoT\ndevices, to minimize the cost of running IoT applications and potential\nmigrations. Besides, a distributed clustering technique is proposed to enable\nthe collaborative execution of tasks, emitted from application modules, among\nservers. Also, we propose an application placement technique to minimize the\noverall cost of executing IoT applications on multiple servers in a distributed\nmanner. Furthermore, a distributed migration management technique is proposed\nfor the potential migration of applications' modules to other remote servers as\nthe users move along their path. Besides, failure recovery methods are embedded\nin the clustering, application placement, and migration management techniques\nto recover from unpredicted failures. The performance results show that our\ntechnique significantly improves its counterparts in terms of placement\ndeployment time, average execution cost of tasks, total number of migrations,\ntotal number of interrupted tasks, and cumulative migration cost."
    },
    {
      "paper_id": "1403.0627v1",
      "title": "Exchange Rate Predictability in a Changing World",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "An expanding literature articulates the view that Taylor rules are helpful in\npredicting exchange rates. In a changing world however, Taylor rule parameters\nmay be subject to structural instabilities, for example during the Global\nFinancial Crisis. This paper forecasts exchange rates using such Taylor rules\nwith Time Varying Parameters (TVP) estimated by Bayesian methods. In core\nout-of-sample results, we improve upon a random walk benchmark for at least\nhalf, and for as many as eight out of ten, of the currencies considered. This\ncontrasts with a constant parameter Taylor rule model that yields a more\nlimited improvement upon the benchmark. In further results, Purchasing Power\nParity and Uncovered Interest Rate Parity TVP models beat a random walk\nbenchmark, implying our methods have some generality in exchange rate\nprediction."
    }
  ],
  [
    {
      "paper_id": "2002.04402v1",
      "title": "Defining mass transfer in a capillary wave micro-bioreactor",
      "subject": [
        "q-bio.QM"
      ],
      "abstract": "For high-throughput cell culture and associated analytics, droplet-based\ncultivation systems open up the opportunities for parallelization and rapid\ndata generation. In contrast to microfluidics with continuous flow, sessile\ndroplet approaches enhance the flexibility for fluid manipulation with usually\nless operational effort. Generating biologically favorable conditions and\npromoting cell growth in a droplet, however, is particularly challenging due to\nmass transfer limitations, which has to be solved by implementing an effective\nmixing technique. Here, capillary waves induced by vertical oscillation are\nused to mix inside a sessile droplet micro-bioreactor (MBR) system avoiding\nadditional moving parts inside the fluid. Depending on the excitation\nfrequency, different patterns are formed on the oscillating liquid surface,\nwhich are described by a model of a vibrated sessile droplet. Analyzing mixing\ntimes and oxygen transport into the liquid, a strong dependency of mass\ntransfer on the oscillation parameters, especially the excitation frequency, is\ndemonstrated. Oscillations at distinct capillary wave resonant frequencies lead\nto rapid homogenization with mixing times of 2 s and volumetric liquid-phase\nmass transfer coefficients of more than 340 h-1. This shows that the mass\ntransfer in a droplet MBR can be specifically controlled via capillary waves,\nwhat is subsequently demonstrated for cultivations of Escherichia coli BL21\ncells. Therefore, the presented MBR in combination with vertical oscillation\nmixing for intensified mass transfer is a promising tool for highly parallel\ncultivation and data generation."
    },
    {
      "paper_id": "2210.16642v1",
      "title": "Unifying the Discrete and Continuous Emotion labels for Speech Emotion\n  Recognition",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Traditionally, in paralinguistic analysis for emotion detection from speech,\nemotions have been identified with discrete or dimensional (continuous-valued)\nlabels. Accordingly, models that have been proposed for emotion detection use\none or the other of these label types. However, psychologists like Russell and\nPlutchik have proposed theories and models that unite these views, maintaining\nthat these representations have shared and complementary information. This\npaper is an attempt to validate these viewpoints computationally. To this end,\nwe propose a model to jointly predict continuous and discrete emotional\nattributes and show how the relationship between these can be utilized to\nimprove the robustness and performance of emotion recognition tasks. Our\napproach comprises multi-task and hierarchical multi-task learning frameworks\nthat jointly model the relationships between continuous-valued and discrete\nemotion labels. Experimental results on two widely used datasets (IEMOCAP and\nMSPPodcast) for speech-based emotion recognition show that our model results in\nstatistically significant improvements in performance over strong baselines\nwith non-unified approaches. We also demonstrate that using one type of label\n(discrete or continuous-valued) for training improves recognition performance\nin tasks that use the other type of label. Experimental results and reasoning\nfor this approach (called the mismatched training approach) are also presented."
    }
  ],
  [
    {
      "paper_id": "1410.3853v1",
      "title": "Peer assessment enhances student learning",
      "subject": [
        "stat.AP"
      ],
      "abstract": "Feedback has a powerful influence on learning, but it is also expensive to\nprovide. In large classes, it may even be impossible for instructors to provide\nindividualized feedback. Peer assessment has received attention lately as a way\nof providing personalized feedback that scales to large classes. Besides these\nobvious benefits, some researchers have also conjectured that students learn by\npeer assessing, although no studies have ever conclusively demonstrated this\neffect. By conducting a randomized controlled trial in an introductory\nstatistics class, we provide evidence that peer assessment causes significant\ngains in student achievement. The strength of our conclusions depends\ncritically on the careful design of the experiment, which was made possible by\na web-based platform that we developed. Hence, our study is also a proof of\nconcept of the high-quality experiments that are possible with online tools."
    },
    {
      "paper_id": "1905.01862v2",
      "title": "Finitely generated abelian groups of units",
      "subject": [
        "math.RA",
        "math.NT"
      ],
      "abstract": "In 1960 Fuchs posed the problem of characterizing the groups which are the\ngroups of units of commutative rings. In the following years, some partial\nanswers have been given to this question in particular cases. In this paper we\naddress Fuchs' question for {\\it finitely generated abelian} groups and we\nconsider the problem of characterizing those groups which arise in some fixed\nclasses of rings $\\mathcal C$, namely the integral domains, the torsion free\nrings and the reduced rings. To determine the realizable groups we have to\nestablish what finite abelian groups $T$ (up to isomorphism) occur as torsion\nsubgroup of $A^*$ when $A$ varies in $\\mathcal C$, and on the other hand, we\nhave to determine what are the possible values of the rank of $A^*$ when\n$(A^*)_{tors}\\cong T$. Most of the paper is devoted to the study of the class\nof torsion-free rings, which needs a substantially deeper study."
    }
  ],
  [
    {
      "paper_id": "0909.1154v1",
      "title": "A note on the Lindeberg condition for convergence to stable laws in\n  Mallows distance",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We correct a condition in a result of Johnson and Samworth (Bernoulli 11\n(2005) 829--845) concerning convergence to stable laws in Mallows distance. We\nalso give an improved version of this result, setting it in the more familiar\ncontext of a Lindeberg-like condition."
    },
    {
      "paper_id": "1806.00646v3",
      "title": "Osmosis through a Semi-permeable Membrane: a Consistent Approach to\n  Interactions",
      "subject": [
        "q-bio.QM"
      ],
      "abstract": "The movement of ionic solutions is an essential part of biology and\ntechnology. Fluidics, from nano- to micro- to microfluidics, is a burgeoning\narea of technology which is all about the movement of ionic solutions, on\nvarious scales. Many cells, tissues, and organs of animals and plants depend on\nosmosis, as the movement of fluids is called in biology. Indeed, the movement\nof fluids through channel proteins (that have a hole down their middle) is\nfluidics on an atomic scale. Ionic fluids are complex fluids, with energy\nstored in many ways. Ionic fluids flow driven by gradients of concentration,\nchemical and electrical potential, and hydrostatic pressure. Each flow is\nclassically described by its own field theory, independent of the others, but\nof course, in reality every gradient drives every kind of flow to a varying\nextent. Combining field equations is tricky and so the theory of complex fluids\nderives the equations, rather than assumes their interactions. When field\nequations are derived, rather than assumed, their variables are consistent.\nThat is to say all variables satisfy all equations under all conditions with\none set of parameters. Here we treat a classical osmotic cell in this spirit,\nusing a sharp interface method to derive boundary conditions consistent with\nall flows and fields. We allow volume to change with concentration, since\nchanges of volume are a property of ionic solutions known to all who make them\nin the laboratory. We consider flexible and inflexible membranes. We show how\nto combine the energetics of the membrane with the energetics of the\nsurrounding complex fluids. The results seem general but need application to\nspecific situations of technological, biological and experimental importance\nbefore the consequences of consistency can be understood."
    }
  ],
  [
    {
      "paper_id": "1804.03758v1",
      "title": "Universal Successor Representations for Transfer Reinforcement Learning",
      "subject": [
        "stat.ML"
      ],
      "abstract": "The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization."
    },
    {
      "paper_id": "2407.02548v1",
      "title": "Speed-accuracy tradeoff and its effect in the game of cricket:\n  predictive modeling from statistical mechanics perspective",
      "subject": [
        "physics.soc-ph",
        "cond-mat.stat-mech",
        "physics.pop-ph"
      ],
      "abstract": "The speed-accuracy tradeoffs are prevalent in a wide range of physical\nsystems. In this paper, we demonstrate speed-accuracy tradeoffs in the game of\ncricket, where 'batters' score runs on the balls bowled by the 'bowlers'. It is\nshown that the run scoring rate by a batter and the probability of dismissal\nfollow a power-law relation. Due to availability of extensive data, game of\ncricket is an excellent model for the study of the effect of speed-accuracy\ntradeoff on the overall performance of the system. It is shown that the\nexponent of the power-law governs the nature of the adaptability of the player\nin different conditions and can be used for their assessment. Further, it is\ndemonstrated that the players with extreme values of the power-law exponent are\nbetter suited for different playing conditions as compared to the ones with\nmoderate values. These findings can be utilized to identify the potential of\nthe cricket players for different game formats and can further help team\nmanagement in devising strategies for the best outcomes with a given set of\nplayers."
    }
  ],
  [
    {
      "paper_id": "1906.02876v5",
      "title": "Compressing RNNs for IoT devices by 15-38x using Kronecker Products",
      "subject": [
        "cs.LG",
        "cs.NE"
      ],
      "abstract": "Recurrent Neural Networks (RNN) can be difficult to deploy on resource\nconstrained devices due to their size.As a result, there is a need for\ncompression techniques that can significantly compress RNNs without negatively\nimpacting task accuracy. This paper introduces a method to compress RNNs for\nresource constrained environments using Kronecker product (KP). KPs can\ncompress RNN layers by 15-38x with minimal accuracy loss. By quantizing the\nresulting models to 8-bits, we further push the compression factor to 50x. We\nshow that KP can beat the task accuracy achieved by other state-of-the-art\ncompression techniques across 5 benchmarks spanning 3 different applications,\nwhile simultaneously improving inference run-time. We show that the KP\ncompression mechanism does introduce an accuracy loss, which can be mitigated\nby a proposed hybrid KP (HKP) approach. Our HKP algorithm provides fine-grained\ncontrol over the compression ratio, enabling us to regain accuracy lost during\ncompression by adding a small number of model parameters."
    },
    {
      "paper_id": "0803.3330v2",
      "title": "Matrix genetics, part 2: the degeneracy of the genetic code and the\n  octave algebra with two quasi-real units (the genetic octave\n  Yin-Yang-algebra)",
      "subject": [
        "q-bio.QM",
        "q-bio.GN",
        "q-bio.OT"
      ],
      "abstract": "Algebraic properties of the genetic code are analyzed. The investigations of\nthe genetic code on the basis of matrix approaches (\"matrix genetics\") are\ndescribed. The degeneracy of the vertebrate mitochondria genetic code is\nreflected in the black-and-white mosaic of the (8*8)-matrix of 64 triplets, 20\namino acids and stop-signals. This mosaic genetic matrix is connected with the\nmatrix form of presentation of the special 8-dimensional Yin-Yang-algebra and\nof its particular 4-dimensional case. The special algorithm, which is based on\nfeatures of genetic molecules, exists to transform the mosaic genomatrix into\nthe matrices of these algebras. Two new numeric systems are defined by these\n8-dimensional and 4-dimensional algebras: genetic Yin-Yang-octaves and genetic\ntetrions. Their comparison with quaternions by Hamilton is presented. Elements\nof new \"genovector calculation\" and ideas of \"genetic mechanics\" are discussed.\nThese algebras are considered as models of the genetic code and as its possible\npre-code basis. They are related with binary oppositions of the Yin-Yang type\nand they give new opportunities to investigate evolution of the genetic code.\nThe revealed fact of the relation between the genetic code and these genetic\nalgebras is discussed in connection with the idea by Pythagoras: \"All things\nare numbers\". Simultaneously these genetic algebras can be utilized as the\nalgebras of genetic operators in biological organisms. The described results\nare related with the problem of algebraization of bioinformatics. They take\nattention to the question: what is life from the viewpoint of algebra?"
    }
  ],
  [
    {
      "paper_id": "2208.01131v2",
      "title": "Automorphisms of real semisimple Lie algebras and their restricted root\n  systems",
      "subject": [
        "math.DG"
      ],
      "abstract": "We prove that every automorphism of the restricted root system of a real\nsemisimple Lie algebra -- when defined properly -- can be lifted to an\nautomorphism of that Lie algebra. In particular, this can be applied to\nautomorphisms of the Dynkin diagram of the restricted root system. We also\ndiscuss some applications of this result to the theory of symmetric spaces of\nnoncompact type."
    },
    {
      "paper_id": "2401.06172v1",
      "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine\n  Learning Methods",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "Historically, the economic recession often came abruptly and disastrously.\nFor instance, during the 2008 financial crisis, the SP 500 fell 46 percent from\nOctober 2007 to March 2009. If we could detect the signals of the crisis\nearlier, we could have taken preventive measures. Therefore, driven by such\nmotivation, we use advanced machine learning techniques, including Random\nForest and Extreme Gradient Boosting, to predict any potential market crashes\nmainly in the US market. Also, we would like to compare the performance of\nthese methods and examine which model is better for forecasting US stock market\ncrashes. We apply our models on the daily financial market data, which tend to\nbe more responsive with higher reporting frequencies. We consider 75\nexplanatory variables, including general US stock market indexes, SP 500 sector\nindexes, as well as market indicators that can be used for the purpose of\ncrisis prediction. Finally, we conclude, with selected classification metrics,\nthat the Extreme Gradient Boosting method performs the best in predicting US\nstock market crisis events."
    }
  ],
  [
    {
      "paper_id": "1908.01479v1",
      "title": "Imaging with highly incomplete and corrupted data",
      "subject": [
        "eess.IV"
      ],
      "abstract": "We consider the problem of imaging sparse scenes from a few noisy data using\nan $l_1$-minimization approach. This problem can be cast as a linear system of\nthe form $A \\, \\rho =b$, where $A$ is an $N\\times K$ measurement matrix. We\nassume that the dimension of the unknown sparse vector $\\rho \\in\n{\\mathbb{C}}^K$ is much larger than the dimension of the data vector $b \\in\n{\\mathbb{C}}^N$, i.e, $K \\gg N$. We provide a theoretical framework that allows\nus to examine under what conditions the $\\ell_1$-minimization problem admits a\nsolution that is close to the exact one in the presence of noise. Our analysis\nshows that $l_1$-minimization is not robust for imaging with noisy data when\nhigh resolution is required. To improve the performance of $l_1$-minimization\nwe propose to solve instead the augmented linear system $ [A \\, | \\, C] \\rho\n=b$, where the $N \\times \\Sigma$ matrix $C$ is a noise collector. It is\nconstructed so as its column vectors provide a frame on which the noise of the\ndata, a vector of dimension $N$, can be well approximated. Theoretically, the\ndimension $\\Sigma$ of the noise collector should be $e^N$ which would make its\nuse not practical. However, our numerical results illustrate that robust\nresults in the presence of noise can be obtained with a large enough number of\ncolumns $\\Sigma \\approx 10 K$."
    },
    {
      "paper_id": "1907.09103v1",
      "title": "A Unified Algebraic Framework for Non-Monotonicity",
      "subject": [
        "cs.LO",
        "cs.AI",
        "cs.SC"
      ],
      "abstract": "Tremendous research effort has been dedicated over the years to thoroughly\ninvestigate non-monotonic reasoning. With the abundance of non-monotonic\nlogical formalisms, a unified theory that enables comparing the different\napproaches is much called for. In this paper, we present an algebraic graded\nlogic we refer to as LogAG capable of encompassing a wide variety of\nnon-monotonic formalisms. We build on Lin and Shoham's argument systems first\ndeveloped to formalize non-monotonic commonsense reasoning. We show how to\nencode argument systems as LogAG theories, and prove that LogAG captures the\nnotion of belief spaces in argument systems. Since argument systems capture\ndefault logic, autoepistemic logic, the principle of negation as failure, and\ncircumscription, our results show that LogAG captures the before-mentioned\nnon-monotonic logical formalisms as well. Previous results show that LogAG\nsubsumes possibilistic logic and any non-monotonic inference relation\nsatisfying Makinson's rationality postulates. In this way, LogAG provides a\npowerful unified framework for non-monotonicity."
    }
  ],
  [
    {
      "paper_id": "1710.09832v1",
      "title": "Effective chemical potential for non-equilibrium systems and its\n  application to molecular beam epitaxy of Bi2Se3",
      "subject": [
        "cond-mat.mtrl-sci"
      ],
      "abstract": "First-principles studies often rely on the assumption of equilibrium, which\ncan be a poor approximation, e.g., for growth. Here, an effective chemical\npotential method for non-equilibrium systems is developed. A salient feature of\nthe theory is that it maintains the equilibrium limits as the correct limit. In\napplication to molecular beam epitaxy, rate equations are solved for the\nconcentrations of small clusters, which serve as feedstock for growth. We find\nthat the effective chemical potential is determined by the most probable,\nrather than by the lowest-energy, cluster. In the case of Bi2Se3, the chemical\npotential is found to be highly supersaturated, leading to a high nucleus\nconcentration in agreement with experiment."
    },
    {
      "paper_id": "physics/0608018v3",
      "title": "The dynamics of traded value revisited",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "We conclude from an analysis of high resolution NYSE data that the\ndistribution of the traded value $f_i$ (or volume) has a finite variance\n$\\sigma_i$ for the very large majority of stocks $i$, and the distribution\nitself is non-universal across stocks. The Hurst exponent of the same time\nseries displays a crossover from weakly to strongly correlated behavior around\nthe time scale of 1 day. The persistence in the strongly correlated regime\nincreases with the average trading activity $\\ev{f_i}$ as\n$H_i=H_0+\\gamma\\log\\ev{f_i}$, which is another sign of non-universal behavior.\nThe existence of such liquidity dependent correlations is consistent with the\nempirical observation that $\\sigma_i\\propto\\ev{f_i}^\\alpha$, where $\\alpha$ is\na non-trivial, time scale dependent exponent."
    }
  ],
  [
    {
      "paper_id": "1010.3602v1",
      "title": "Collisions of particles in locally AdS spacetimes I. Local description\n  and global examples",
      "subject": [
        "math.DG",
        "math.GT",
        "math.MP"
      ],
      "abstract": "We investigate 3-dimensional globally hyperbolic AdS manifolds containing\n\"particles\", i.e., cone singularities along a graph $\\Gamma$. We impose\nphysically relevant conditions on the cone singularities, e.g. positivity of\nmass (angle less than $2\\pi$ on time-like singular segments). We construct\nexamples of such manifolds, describe the cone singularities that can arise and\nthe way they can interact (the local geometry near the vertices of $\\Gamma$).\nWe then adapt to this setting some notions like global hyperbolicity which are\nnatural for Lorentz manifolds, and construct some examples of globally\nhyperbolic AdS manifolds with interacting particles."
    },
    {
      "paper_id": "0908.1677v1",
      "title": "Most Efficient Homogeneous Volatility Estimators",
      "subject": [
        "q-fin.ST",
        "q-fin.RM"
      ],
      "abstract": "We present a comprehensive theory of homogeneous volatility (and variance)\nestimators of arbitrary stochastic processes that fully exploit the OHLC (open,\nhigh, low, close) prices. For this, we develop the theory of most efficient\npoint-wise homogeneous OHLC volatility estimators, valid for any price\nprocesses. We introduce the \"quasi-unbiased estimators\", that can address any\ntype of desirable constraints. The main tool of our theory is the parsimonious\nencoding of all the information contained in the OHLC prices for a given time\ninterval in the form of the joint distributions of the high-minus-open,\nlow-minus-open and close-minus-open values, whose analytical expression is\nderived exactly for Wiener processes with drift. The distributions can be\ncalculated to yield the most efficient estimators associated with any\nstatistical properties of the underlying log-price stochastic process. Applied\nto Wiener processes for log-prices with drift, we provide explicit analytical\nexpressions for the most efficient point-wise volatility and variance\nestimators, based on the analytical expression of the joint distribution of the\nhigh-minus-open, low-minus-open and close-minus-open values. The efficiency of\nthe new proposed estimators is favorably compared with that of the\nGarman-Klass, Roger-Satchell and maximum likelihood estimators."
    }
  ],
  [
    {
      "paper_id": "2104.08010v1",
      "title": "Welfare Measure for Resource Allocation with Algorithmic Implementation:\n  Beyond Average and Max-Min",
      "subject": [
        "cs.MA",
        "cs.NI",
        "cs.SY"
      ],
      "abstract": "In this work, we propose an axiomatic approach for measuring the\nperformance/welfare of a system consisting of concurrent agents in a\nresource-driven system. Our approach provides a unifying view on popular system\noptimality principles, such as the maximal average/total utilities and the\nmax-min fairness. Moreover, it gives rise to other system optimality notions\nthat have not been fully exploited yet, such as the maximal lowest total\nsubgroup utilities. For the axiomatically defined welfare measures, we provide\na generic gradient-based method to find an optimal resource allocation and\npresent a theoretical guarantee for its success. Lastly, we demonstrate the\npower of our approach through the power control application in wireless\nnetworks."
    },
    {
      "paper_id": "1909.11910v1",
      "title": "Concentration of product spaces",
      "subject": [
        "math.MG"
      ],
      "abstract": "We investigate the relation between the concentration and the product of\nmetric measure spaces. We have the natural question whether, for two\nconcentrating sequences of metric measure spaces, the sequence of their product\nspaces also concentrates. A partial answer is mentioned in Gromov's book. We\nobtain a complete answer for this question."
    }
  ],
  [
    {
      "paper_id": "2101.01548v1",
      "title": "Extraction, isolation, structure elucidation and evaluation of toxicity,\n  anti-inflammatory and analgesic activity of Pituranthos scoparius\n  constituents",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "The present work aimed to investigate an ethnobotanical survey about\nPituranthos scoparius and assess the toxicity, anti-inflammatory (in vitro, and\nin vivo) potential, in vitro antioxidant, and analgesic effects of stems and\nroots of Pituranthos scoparius. Furthermore; to isolate and elucidate the\nchemical constituents of the n-butanol stem extract of P. scoparius (ButE) and\ndetermine the toxicity and anti-inflammatory effects of these compounds added\nto the ButE. Data from an ethnopharmacological study showed that 24.47 % of\npeople used this plant in folk medicine. Four compounds were isolated from\nButE. These compounds were characterized by means of NMR and high-resolution\nmass spectral (HRMS) data."
    },
    {
      "paper_id": "2211.07035v1",
      "title": "Elementary Bitcoin economics: from production and transaction demand to\n  values",
      "subject": [
        "econ.GN"
      ],
      "abstract": "In this paper we give an elementary analysis of economics of Bitcoin that\ncombines the transaction demand by the consumers and the supply of hashrate by\nminers. We argue that the decreasing block reward will have no significant\neffect on the exchange rate (price) of Bitcoin and thus the network will be\ntransitioning to a regime where transaction fees will play a bigger part of\nminers' revenue. We consider a simple model where consumers demand bitcoins for\ntransactions, but not for hoarding bitcoins, and we analyze market equilibrium\nwhere the demand is matched with the hashrate supplied by miners. Our main\nconclusion is that the exchange rate of Bitcoin cannot be determined from the\nmarket equilibrium and so our arguments support the hypothesis that Bitcoin\nprice has no economic fundamentals and is free to fluctuate according to the\npresent demand for hoarding and speculation. We point out that increasing fees\nbear the risk of Bitcoin being outcompeted by its main rival Ethereum, and that\ndecreasing revenues to miners depreciate the perception of Bitcoin as a medium\nfor store value (hoarding demand) which will have effect its exchange rate."
    }
  ],
  [
    {
      "paper_id": "1810.09063v3",
      "title": "Optimal electricity demand response contracting with responsiveness\n  incentives",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Despite the success of demand response programs in retail electricity markets\nin reducing average consumption, the random responsiveness of consumers to\nprice event makes their efficiency questionable to achieve the flexibility\nneeded for electric systems with a large share of renewable energy. The\nvariance of consumers' responses depreciates the value of these mechanisms and\nmakes them weakly reliable. This paper aims at designing demand response\ncontracts which allow to act on both the average consumption and its variance.\nThe interaction between a risk--averse producer and a risk--averse consumer is\nmodelled through a Principal--Agent problem, thus accounting for the moral\nhazard underlying demand response contracts. We provide closed--form solution\nfor the optimal contract in the case of constant marginal costs of energy and\nvolatility for the producer and constant marginal value of energy for the\nconsumer. We show that the optimal contract has a rebate form where the initial\ncondition of the consumption serves as a baseline. Further, the consumer cannot\nmanipulate the baseline at his own advantage. The second--best price for energy\nand volatility are non--constant and non--increasing in time. The price for\nenergy is lower (resp. higher) than the marginal cost of energy during\npeak--load (resp. off--peak) periods. We illustrate the potential benefit\nissued from the implementation of an incentive mechanism on the responsiveness\nof the consumer by calibrating our model with publicly available data. We\npredict a significant increase of responsiveness under our optimal contract and\na significant increase of the producer satisfaction."
    },
    {
      "paper_id": "0705.4073v2",
      "title": "Quasi-linear dynamics in nonlinear Schr\\\" odinger equation with periodic\n  boundary conditions",
      "subject": [
        "math.MP"
      ],
      "abstract": "It is shown that a large subset of initial data with finite energy ($L^2$\nnorm)evolves nearly linearly in nonlinear Schr\\\" odinger equation with periodic\nboundary conditions. These new solutions are not perturbations of the known\nones such as solitons, semiclassical or weakly linear solutions."
    }
  ],
  [
    {
      "paper_id": "1210.2363v2",
      "title": "LDx: estimation of linkage disequilibrium from high-throughput pooled\n  resequencing data",
      "subject": [
        "q-bio.GN",
        "q-bio.PE",
        "q-bio.QM"
      ],
      "abstract": "High-throughput pooled resequencing offers significant potential for whole\ngenome population sequencing. However, its main drawback is the loss of\nhaplotype information. In order to regain some of this information, we present\nLDx, a computational tool for estimating linkage disequilibrium (LD) from\npooled resequencing data. LDx uses an approximate maximum likelihood approach\nto estimate LD (r2) between pairs of SNPs that can be observed within and among\nsingle reads. LDx also reports r2 estimates derived solely from observed\ngenotype counts. We demonstrate that the LDx estimates are highly correlated\nwith r2 estimated from individually resequenced strains. We discuss the\nperformance of LDx using more stringent quality conditions and infer via\nsimulation the degree to which performance can improve based on read depth.\nFinally we demonstrate two possible uses of LDx with real and simulated pooled\nresequencing data. First, we use LDx to infer genomewide patterns of decay of\nLD with physical distance in D. melanogaster population resequencing data.\nSecond, we demonstrate that r2 estimates from LDx are capable of distinguishing\nalternative demographic models representing plausible demographic histories of\nD. melanogaster."
    },
    {
      "paper_id": "1508.03817v1",
      "title": "Visualizing long vectors of measurements by use of the Hilbert curve",
      "subject": [
        "physics.data-an",
        "physics.comp-ph"
      ],
      "abstract": "The use of Hilbert curves to visualize massive vector of data is revisited\nfollowing previous authors. The Hilbert curve mapping preserves locality and\nmakes meaningful representation of the data. We call such visualization as\nHilbert plots. The combination of a Hilbert plot with its Fourier transform\nallows to identify patterns in the underlying data sequence. The use of\ndifferent granularity representation also allows to identify periodic intervals\nwithin the data. Data from different sources are presented: periodic,\naperiodic, logistic map and 1/2-Ising model. A real data example from the study\nof heartbeat data is also discussed."
    }
  ],
  [
    {
      "paper_id": "2410.09503v1",
      "title": "SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and\n  CLAP-Refine through LLMs",
      "subject": [
        "cs.SD"
      ],
      "abstract": "Automated Audio Captioning (AAC) aims to generate natural textual\ndescriptions for input audio signals. Recent progress in audio pre-trained\nmodels and large language models (LLMs) has significantly enhanced audio\nunderstanding and textual reasoning capabilities, making improvements in AAC\npossible. In this paper, we propose SLAM-AAC to further enhance AAC with\nparaphrasing augmentation and CLAP-Refine through LLMs. Our approach uses the\nself-supervised EAT model to extract fine-grained audio representations, which\nare then aligned with textual embeddings via lightweight linear layers. The\ncaption generation LLM is efficiently fine-tuned using the LoRA adapter.\nDrawing inspiration from the back-translation method in machine translation, we\nimplement paraphrasing augmentation to expand the Clotho dataset during\npre-training. This strategy helps alleviate the limitation of scarce audio-text\npairs and generates more diverse captions from a small set of audio clips.\nDuring inference, we introduce the plug-and-play CLAP-Refine strategy to fully\nexploit multiple decoding outputs, akin to the n-best rescoring strategy in\nspeech recognition. Using the CLAP model for audio-text similarity calculation,\nwe could select the textual descriptions generated by multiple searching beams\nthat best match the input audio. Experimental results show that SLAM-AAC\nachieves state-of-the-art performance on Clotho V2 and AudioCaps, surpassing\nprevious mainstream models."
    },
    {
      "paper_id": "1706.04633v1",
      "title": "Subjects classification from high-dimensional and small-sample size\n  datasets using a strategy based on Clustering Variables around Latent\n  Components (CLV) method",
      "subject": [
        "stat.AP"
      ],
      "abstract": "High-dimensional complex systems can be studied through multivariate\nanalysis, as Principal Component Analysis, however large samples of\nobservations frequently are needed for it. Here it is examined a method for\nsmall samples based on clustering variables around latent variables (CLV) to\nsubject classification in two presumed groups. For it, a predictive model was\ndeveloped to generate datasets with two groups of cases whose variables show\nrandomness features (up to 30% of variables manifest difference between groups,\nand up to 7% of those are correlated between them). The method recovered the\ninformation of the latent factors to classify the subjects with 80 to 95% of\nagreement, with positive relationship between the classifier precision and the\nrate [number of variables / number of subjects]."
    }
  ],
  [
    {
      "paper_id": "1402.0344v1",
      "title": "Formes quadratiques de discriminants embo\u00eet\u00e9s",
      "subject": [
        "cs.CR",
        "cs.DM"
      ],
      "abstract": "Quadratic forms with embedded discriminants. Integral binary quadratic forms\nhave multiple applications, for example in factorization or cryptography. The\nNice family of cryptographic systems makes use of quadratic forms with\ndifferent discriminants $\\pm p$, and $\\pm pq^2$ where $p$, $q$ are large\nprimes. This paper shows the precise links between forms with $D$ discriminant\nand forms with $Df^2$ discriminant, which are crucial in the analysis of the\nsystems Nice and theirs attacks. We also introduce the notion of\nsemi-equivalence of binary quadratic forms, and give some characterizations of\nsemi-equivalent forms, which are useful in the analysis of these attacks.\n  -----\n  Les formes quadratiques binaires fournissent un moyen explicite pour\nmanipuler des id\\'eaux de corps quadratiques, et leurs applications pratiques\nsont multiples. De nombreux algorithmes de factorisation les utilisent. Elle\nsont aussi utilis\\'ees en cryptographie, en particulier pour les syst\\`emes\nNice. Les syst\\`emes de chiffrement Nice utilisent des formes quadratiques de\ndiscriminants $\\pm p$ et $\\pm pq^2$ o\\`u $p$ et $q$ sont des nombres premiers.\nCet article pr\\'ecise les liens entre les formes de discriminant $D$ et celles\nde discriminant $Df^2$, ce qui est essentiel pour l'analyse de Nice et de ses\nattaques. Il introduit aussi la notion de formes quadratiques\nsemi-\\'equivalentes et en explicite plusieurs caract\\'erisations, utiles pour\nl'analyse de ces attaques."
    },
    {
      "paper_id": "1902.06143v1",
      "title": "Weak Identification and Estimation of Social Interaction Models",
      "subject": [
        "econ.EM"
      ],
      "abstract": "The identification of the network effect is based on either group size\nvariation, the structure of the network or the relative position in the\nnetwork. I provide easy-to-verify necessary conditions for identification of\nundirected network models based on the number of distinct eigenvalues of the\nadjacency matrix. Identification of network effects is possible; although in\nmany empirical situations existing identification strategies may require the\nuse of many instruments or instruments that could be strongly correlated with\neach other. The use of highly correlated instruments or many instruments may\nlead to weak identification or many instruments bias. This paper proposes\nregularized versions of the two-stage least squares (2SLS) estimators as a\nsolution to these problems. The proposed estimators are consistent and\nasymptotically normal. A Monte Carlo study illustrates the properties of the\nregularized estimators. An empirical application, assessing a local government\ntax competition model, shows the empirical relevance of using regularization\nmethods."
    }
  ],
  [
    {
      "paper_id": "2105.09581v1",
      "title": "Valuation of European Options under an Uncertain Market Price of\n  Volatility Risk",
      "subject": [
        "q-fin.PR",
        "q-fin.CP"
      ],
      "abstract": "We propose a model to quantify the effect of parameter uncertainty on the\noption price in the Heston model. More precisely, we present a\nHamilton-Jacobi-Bellman framework which allows us to evaluate best and worst\ncase scenarios under an uncertain market price of volatility risk. For the\nnumerical approximation the Hamilton--Jacobi--Bellman equation is reformulated\nto enable the solution with a finite element method. A case study with\nbutterfly options exhibits how the dependence of Delta on the magnitude of the\nuncertainty is nonlinear and highly varied across the parameter regime.\n  Keywords: Uncertain market price, Volatility risk, Hamilton-Jacobi-Bellman\nequation, Finite element method, Uncertainty quantification"
    },
    {
      "paper_id": "2205.00051v3",
      "title": "Useful formulas for non-magnetized electron cooling",
      "subject": [
        "physics.acc-ph"
      ],
      "abstract": "Recent success of Low Energy RHIC Electron Cooler (LEReC) opened a road for\ndevelopment of high energy electron coolers based on non-magnetized electron\nbunches accelerated by RF cavities. Electrons in such coolers can have velocity\ndistribution with various unequal horizontal, vertical and longitudinal\nvelocity spreads. In this paper we revisit a formula of friction force in\nnon-magnetized cooling and derive a number of useful expressions for different\nlimiting cases."
    }
  ],
  [
    {
      "paper_id": "1810.07674v5",
      "title": "Dynkin games with incomplete and asymmetric information",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We study the value and the optimal strategies for a two-player zero-sum\noptimal stopping game with incomplete and asymmetric information. In our\nBayesian set-up, the drift of the underlying diffusion process is unknown to\none player (incomplete information feature), but known to the other one\n(asymmetric information feature). We formulate the problem and reduce it to a\nfully Markovian setup where the uninformed player optimises over stopping times\nand the informed one uses randomised stopping times in order to hide their\ninformational advantage. Then we provide a general verification result which\nallows us to find the value of the game and players' optimal strategies by\nsolving suitable quasi-variational inequalities with some non-standard\nconstraints. Finally, we study an example with linear payoffs, in which an\nexplicit solution of the corresponding quasi-variational inequalities can be\nobtained."
    },
    {
      "paper_id": "0711.0149v2",
      "title": "Leibniz rules for enveloping algebras in symmetric ordering",
      "subject": [
        "math.QA",
        "math.RA",
        "math.RT"
      ],
      "abstract": "Given a finite-dimensional Lie algebra, and a representation by derivations\non the completed symmetric algebra of its dual, a number of interesting twisted\nconstructions appear: certain twisted Weyl algebras, deformed Leibniz rules,\nquantized ``star'' product. We first illuminate a number of interrelations\nbetween these constructions and then proceed to study a special case in certain\nprecise sense corresponding to the symmetric or Weyl ordering. This case has\nbeen known earlier to be related to computations with Hausdorff series, for\nexample the expression for the star product is in such terms. For the deformed\nLeibniz rule, hence a coproduct, we present here a new nonsymmetric expression,\nwhich is then expanded into a sum of expressions labelled by a class of planar\ntrees, and for a given tree evaluated by Feynman-like rules. These expressions\nare filtered by a bidegree and we show recursion formulas for the sums of\nexpressions of a given bidegree, and compare the recursions to recursions for\nHausdorff series, including the comparison of initial conditions. This way we\nshow a direct corespondence between the Hausdorff series and the expression for\ntwisted coproduct."
    }
  ],
  [
    {
      "paper_id": "1809.00080v1",
      "title": "Location and Capacity Planning of Facilities with General Service-Time\n  Distributions Using Conic Optimization",
      "subject": [
        "cs.DM"
      ],
      "abstract": "This paper studies a stochastic congested location problem in the network of\na service system that consists of facilities to be established in a finite\nnumber of candidate locations. Population zones allocated to each open service\nfacility together creates a stream of demand that follows a Poisson process and\nmay cause congestion at the facility. The service time at each facility is\nstochastic and depends on the service capacity and follows a general\ndistribution that can differ for each facility. The service capacity is\nselected from a given (bounded or unbounded) interval. The objective of our\nproblem is to optimize a balanced performance measure that compromises between\nfacility-induced and customer-related costs. Service times are represented by a\nflexible location-scale stochastic model. The problem is formulated using\nquadratic conic optimization. Valid inequalities and a cut-generation procedure\nare developed to increase computational efficiency. A comprehensive numerical\nstudy is carried out to show the efficiency and effectiveness of the solution\nprocedure. Moreover, our numerical experiments using real data of a preventive\nhealthcare system in Toronto show that the optimal service network\nconfiguration is highly sensitive to the service-time distribution. Our method\nfor convexifying the waiting-time formulas of M/G/1 queues is general and\nextends the existing convexity results in queueing theory such that they can be\nused in optimization problems where the service rates are continuous."
    },
    {
      "paper_id": "2410.20680v1",
      "title": "Multi-modal Data based Semi-Supervised Learning for Vehicle Positioning",
      "subject": [
        "eess.SP"
      ],
      "abstract": "In this paper, a multi-modal data based semi-supervised learning (SSL)\nframework that jointly use channel state information (CSI) data and RGB images\nfor vehicle positioning is designed. In particular, an outdoor positioning\nsystem where the vehicle locations are determined by a base station (BS) is\nconsidered. The BS equipped with several cameras can collect a large amount of\nunlabeled CSI data and a small number of labeled CSI data of vehicles, and the\nimages taken by cameras. Although the collected images contain partial\ninformation of vehicles (i.e. azimuth angles of vehicles), the relationship\nbetween the unlabeled CSI data and its azimuth angle, and the distances between\nthe BS and the vehicles captured by images are both unknown. Therefore, the\nimages cannot be directly used as the labels of unlabeled CSI data to train a\npositioning model. To exploit unlabeled CSI data and images, a SSL framework\nthat consists of a pretraining stage and a downstream training stage is\nproposed. In the pretraining stage, the azimuth angles obtained from the images\nare considered as the labels of unlabeled CSI data to pretrain the positioning\nmodel. In the downstream training stage, a small sized labeled dataset in which\nthe accurate vehicle positions are considered as labels is used to retrain the\nmodel. Simulation results show that the proposed method can reduce the\npositioning error by up to 30% compared to a baseline where the model is not\npretrained."
    }
  ],
  [
    {
      "paper_id": "2004.09963v3",
      "title": "Structural clustering of volatility regimes for dynamic trading\n  strategies",
      "subject": [
        "q-fin.ST",
        "q-fin.RM"
      ],
      "abstract": "We develop a new method to find the number of volatility regimes in a\nnonstationary financial time series by applying unsupervised learning to its\nvolatility structure. We use change point detection to partition a time series\ninto locally stationary segments and then compute a distance matrix between\nsegment distributions. The segments are clustered into a learned number of\ndiscrete volatility regimes via an optimization routine. Using this framework,\nwe determine a volatility clustering structure for financial indices, large-cap\nequities, exchange-traded funds and currency pairs. Our method overcomes the\nrigid assumptions necessary to implement many parametric regime-switching\nmodels, while effectively distilling a time series into several characteristic\nbehaviours. Our results provide significant simplification of these time series\nand a strong descriptive analysis of prior behaviours of volatility. Finally,\nwe create and validate a dynamic trading strategy that learns the optimal match\nbetween the current distribution of a time series and its past regimes, thereby\nmaking online risk-avoidance decisions in the present."
    },
    {
      "paper_id": "2401.00966v1",
      "title": "Improved estimators in Bell regression model with application",
      "subject": [
        "math.ST"
      ],
      "abstract": "In this paper, we propose the application of shrinkage strategies to estimate\ncoefficients in the Bell regression models when prior information about the\ncoefficients is available. The Bell regression models are well-suited for\nmodeling count data with multiple covariates. Furthermore, we provide a\ndetailed explanation of the asymptotic properties of the proposed estimators,\nincluding asymptotic biases and mean squared errors. To assess the performance\nof the estimators, we conduct numerical studies using Monte Carlo simulations\nand evaluate their simulated relative efficiency. The results demonstrate that\nthe suggested estimators outperform the unrestricted estimator when prior\ninformation is taken into account. Additionally, we present an empirical\napplication to demonstrate the practical utility of the suggested estimators."
    }
  ],
  [
    {
      "paper_id": "1902.08923v1",
      "title": "Ideals in $B_1(X)$ and residue class rings of $B_1(X)$ modulo an ideal",
      "subject": [
        "math.GN"
      ],
      "abstract": "This paper explores the duality between ideals of the ring $B_1(X)$ of all\nreal valued Baire one functions on a topological space $X$ and typical families\nof zero sets, called $Z_B$-filters, on $X$. As a natural outcome of this study,\nit is observed that $B_1(X)$ is a Gelfand ring but non-Noetherian in general.\nIntroducing fixed and free maximal ideals in the context of $B_1(X)$, complete\ndescriptions of the fixed maximal ideals of both $B_1(X)$ and $B_1^*(X)$ are\nobtained. Though free maximal ideals of $B_1(X)$ and those of $B_1^*(X)$ do not\nshow any relationship in general, their counterparts, i.e., the fixed maximal\nideals obey natural relations. It is proved here that for a perfectly normal\n$T_1$ space $X$, free maximal ideals of $B_1(X)$ are determined by a typical\nclass of Baire one functions. In the concluding part of this paper, we study\nresidue class ring of $B_1(X)$ modulo an ideal, with special emphasize on real\nand hyper real maximal ideals of $B_1(X)$."
    },
    {
      "paper_id": "2212.03351v2",
      "title": "The long-term effect of childhood exposure to technology using\n  surrogates",
      "subject": [
        "econ.EM"
      ],
      "abstract": "We study how childhood exposure to technology at ages 5-15 via the occupation\nof the parents affects the ability to climb the social ladder in terms of\nincome at ages 45-49 using the Danish micro data from years 1961-2019. Our\nmeasure of technology exposure covers the degree to which using computers\n(hardware and software) is required to perform an occupation, and it is created\nby merging occupational codes with detailed data from O*NET. The challenge in\nestimating this effect is that long-term outcome is observed over a different\ntime horizon than our treatment of interest. We therefore adapt the surrogate\nindex methodology, linking the effect of our childhood treatment on\nintermediate surrogates, such as income and education at ages 25-29, to the\neffect on adulthood income. We estimate that a one standard error increase in\nexposure to technology increases the income rank by 2\\%-points, which is\neconomically and statistically significant and robust to cluster-correlation\nwithin families. The derived policy recommendation is to update the educational\ncurriculum to expose children to computers to a higher degree, which may then\nact as a social leveler."
    }
  ],
  [
    {
      "paper_id": "2404.03455v3",
      "title": "Synergy as the failure of distributivity",
      "subject": [
        "physics.bio-ph",
        "physics.data-an"
      ],
      "abstract": "The concept of emergence, or synergy in its simplest form, is widely used but\nlacks a rigorous definition. Our work connects information and set theory to\nuncover the mathematical nature of synergy as the failure of distributivity. It\nresolves the persistent self-contradiction of information decomposition theory\nand reinstates it as a primary route toward a rigorous definition of emergence.\nOur results suggest that non-distributive variants of set theory may be used to\ndescribe emergent physical systems."
    },
    {
      "paper_id": "2002.11415v1",
      "title": "Extensions, deformation and categorification of $\\text{AssDer}$ pairs",
      "subject": [
        "math.RA",
        "math.KT",
        "math.RT"
      ],
      "abstract": "In this paper, we consider associative algebras equipped with derivations.\nSuch a pair of an associative algebra with a derivation is called an AssDer\npair. Using the Hochschild cohomology for associative algebras, we define\ncohomology for an AssDer pair with coefficients in a representation. We study\ncentral extensions and abelian extensions of AssDer pairs. Moreover, we\nconsider extensions of a pair of derivations in central extensions of\nassociative algebras. Next, we study formal one-parameter deformations of\nAssDer pair by deforming both the associative product and the derivation. They\nare governed by the cohomology of the AssDer pair with representation in\nitself. In the next part, we study $2$-term $A_\\infty$-algebras with homotopy\nderivations considered by Loday and Doubek-Lada. Finally, we introduce\n$2$-derivations on associative $2$-algebras and show that the category of\nassociative $2$-algebras with $2$-derivations are equivalent to the category of\n$2$-term $A_\\infty$-algebras with homotopy derivations."
    }
  ],
  [
    {
      "paper_id": "2412.18566v2",
      "title": "Zero-resource Speech Translation and Recognition with LLMs",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Despite recent advancements in speech processing, zero-resource speech\ntranslation (ST) and automatic speech recognition (ASR) remain challenging\nproblems. In this work, we propose to leverage a multilingual Large Language\nModel (LLM) to perform ST and ASR in languages for which the model has never\nseen paired audio-text data. We achieve this by using a pre-trained\nmultilingual speech encoder, a multilingual LLM, and a lightweight adaptation\nmodule that maps the audio representations to the token embedding space of the\nLLM. We perform several experiments both in ST and ASR to understand how to\nbest train the model and what data has the most impact on performance in\npreviously unseen languages. In ST, our best model is capable to achieve BLEU\nscores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we\nachieve WERs of up to 28.2\\%. We finally show that the performance of our\nsystem is bounded by the ability of the LLM to output text in the desired\nlanguage."
    },
    {
      "paper_id": "2208.09372v3",
      "title": "Non-Stationary Dynamic Pricing Via Actor-Critic Information-Directed\n  Pricing",
      "subject": [
        "econ.GN"
      ],
      "abstract": "This paper presents a novel non-stationary dynamic pricing algorithm design,\nwhere pricing agents face incomplete demand information and market environment\nshifts. The agents run price experiments to learn about each product's demand\ncurve and the profit-maximizing price, while being aware of market environment\nshifts to avoid high opportunity costs from offering sub-optimal prices. The\nproposed ACIDP extends information-directed sampling (IDS) algorithms from\nstatistical machine learning to include microeconomic choice theory, with a\nnovel pricing strategy auditing procedure to escape sub-optimal pricing after\nmarket environment shift. The proposed ACIDP outperforms competing bandit\nalgorithms including Upper Confidence Bound (UCB) and Thompson sampling (TS) in\na series of market environment shifts."
    }
  ],
  [
    {
      "paper_id": "2111.08786v1",
      "title": "LibSC: Library for Scaling Correction Methods in Density Functional\n  Theory",
      "subject": [
        "physics.chem-ph"
      ],
      "abstract": "In recent years, a series of scaling correction (SC) methods have been\ndeveloped in the Yang laboratory to reduce and eliminate the delocalization\nerror, which is an intrinsic and systematic error existing in conventional\ndensity functional approximations (DFAs) within density functional theory\n(DFT). Based on extensive numerical results, the SC methods have been\ndemonstrated to be capable of reducing the delocalization error effectively and\nproducing accurate descriptions for many critical and challenging problems,\nincluding the fundamental gap, photoemission spectroscopy, charge transfer\nexcitations and polarizability. In the development of SC methods, the SC\nmethods were mainly implemented in the QM4D package that was developed in the\nYang laboratory for research development. The heavy dependency on the QM4D\npackage hinders the SC methods from access by researchers for broad\napplications. In this work, we developed a reliable and efficient\nimplementation , LibSC for the global scaling correction (GSC) method and the\nlocalized orbital scaling correction (LOSC) method. LibSC will serve as a\nlight-weight and open-source library that can be easily accessed by the quantum\nchemistry community. The implementation of LibSC is carefully modularized to\nprovide the essential functionalities for conducting calculations of the SC\nmethods. In addition, LibSC provides simple and consistent interfaces to\nsupport multiple popular programing languages, including C, C++ and Python. In\naddition to the development of the library, we also integrated LibSC with two\npopular and open-source quantum chemistry packages, the Psi4 package and the\nPySCF package, which provides immediate access for general users to perform\ncalculations with SC methods."
    },
    {
      "paper_id": "2210.05868v1",
      "title": "On Secure Uplink Transmission in Hybrid RF-FSO Cooperative\n  Satellite-Aerial-Terrestrial Networks",
      "subject": [
        "eess.SP"
      ],
      "abstract": "This work investigates the secrecy outage performance of the uplink\ntransmission of a radio-frequency (RF)-free-space optical (FSO) hybrid\ncooperative satellite-aerial-terrestrial network (SATN). Specifically, in the\nconsidered cooperative SATN, a terrestrial source (S) transmits its information\nto a satellite receiver (D) via the help of a cache-enabled aerial relay (R)\nterminal with the most popular content caching scheme, while a group of\neavesdropping aerial terminals (Eves) trying to overhear the transmitted\nconfidential information. Moreover, RF and FSO transmissions are employed over\nS-R and R-D links, respectively. Considering the randomness of R, D, and Eves,\nand employing a stochastic geometry framework, the secrecy outage performance\nof the cooperative uplink transmission in the considered SATN is investigated\nand a closed-form analytical expression for the end-to-end secrecy outage\nprobability is derived. Finally, Monte-Carlo simulations are shown to verify\nthe accuracy of our analysis."
    }
  ],
  [
    {
      "paper_id": "2007.02109v1",
      "title": "Scenarios for a post-COVID-19 world airline network",
      "subject": [
        "econ.GN"
      ],
      "abstract": "The airline industry was severely hit by the COVID-19 crisis with an average\ndemand decrease of about $64\\%$ (IATA, April 2020) which triggered already\nseveral bankruptcies of airline companies all over the world. While the\nrobustness of the world airline network (WAN) was mostly studied as an\nhomogeneous network, we introduce a new tool for analyzing the impact of a\ncompany failure: the `airline company network' where two airlines are connected\nif they share at least one route segment. Using this tool, we observe that the\nfailure of companies well connected with others has the largest impact on the\nconnectivity of the WAN. We then explore how the global demand reduction\naffects airlines differently, and provide an analysis of different scenarios if\nits stays low and does not come back to its pre-crisis level. Using traffic\ndata from the Official Aviation Guide (OAG) and simple assumptions about\ncustomer's airline choice strategies, we find that the local effective demand\ncan be much lower than the average one, especially for companies that are not\nmonopolistic and share their segments with larger companies. Even if the\naverage demand comes back to $60\\%$ of the total capacity, we find that between\n$46\\%$ and $59\\%$ of the companies could experience a reduction of more than\n$50\\%$ of their traffic, depending on the type of competitive advantage that\ndrives customer's airline choice. These results highlight how the complex\ncompetitive structure of the WAN weakens its robustness when facing such a\nlarge crisis."
    },
    {
      "paper_id": "2112.13111v1",
      "title": "Measuring Quality of DNA Sequence Data via Degradation",
      "subject": [
        "stat.ML",
        "stat.AP"
      ],
      "abstract": "We propose and apply a novel paradigm for characterization of genome data\nquality, which quantifies the effects of intentional degradation of quality.\nThe rationale is that the higher the initial quality, the more fragile the\ngenome and the greater the effects of degradation. We demonstrate that this\nphenomenon is ubiquitous, and that quantified measures of degradation can be\nused for multiple purposes. We focus on identifying outliers that may be\nproblematic with respect to data quality, but might also be true anomalies or\neven attempts to subvert the database."
    }
  ],
  [
    {
      "paper_id": "2402.02384v1",
      "title": "Acoustic Local Positioning With Encoded Emission Beacons",
      "subject": [
        "eess.SP",
        "eess.AS"
      ],
      "abstract": "Acoustic local positioning systems (ALPSs) are an interesting alternative for\nindoor positioning due to certain advantages over other approaches, including\ntheir relatively high accuracy, low cost, and room-level signal propagation.\nCentimeter-level or fine-grained indoor positioning can be an asset for robot\nnavigation, guiding a person to, for instance, a particular piece in a museum\nor to a specific product in a shop, targeted advertising, or augmented reality.\nIn airborne system applications, acoustic positioning can be based on using\nopportunistic signals or sounds produced by the person or object to be located\n(e.g., noise from appliances or the speech from a speaker) or from encoded\nemission beacons (or anchors) specifically designed for this purpose. This work\npresents a review of the different challenges that designers of systems based\non encoded emission beacons must address in order to achieve suitable\nperformance. At low-level processing, the waveform design (coding and\nmodulation) and the processing of the received signal are key factors to\naddress such drawbacks as multipath propagation, multiple-access interference,\nnearfar effect, or Doppler shifting. With regards to high-level system design,\nthe issues to be addressed are related to the distribution of beacons, ease of\ndeployment, and calibration and positioning algorithms, including the possible\nfusion of information. Apart from theoretical discussions, this work also\nincludes the description of an ALPS that was implemented, installed in a large\narea and tested for mobile robot navigation. In addition to practical interest\nfor real applications, airborne ALPSs can also be used as an excellent platform\nto test complex algorithms, which can be subsequently adapted for other\npositioning systems, such as underwater acoustic systems or ultrawideband\nradiofrequency (UWB RF) systems."
    },
    {
      "paper_id": "2308.02843v1",
      "title": "One Microservice per Developer: Is This the Trend in OSS?",
      "subject": [
        "cs.SE"
      ],
      "abstract": "When developing and managing microservice systems, practitioners suggest that\neach microservice should be owned by a particular team. In effect, there is\nonly one team with the responsibility to manage a given service. Consequently,\none developer should belong to only one team. This practice of\n\"one-microservice-per-developer\" is especially prevalent in large projects with\nan extensive development team. Based on the bazaar-style software development\nmodel of Open Source Projects, in which different programmers, like vendors at\na bazaar, offer to help out developing different parts of the system, this\narticle investigates whether we can observe the\n\"one-microservice-per-developer\" behavior, a strategy we assume anticipated\nwithin microservice based Open Source Projects. We conducted an empirical study\namong 38 microservice-based OS projects. Our findings indicate that the\nstrategy is rarely respected by open-source developers except for projects that\nhave dedicated DevOps teams."
    }
  ],
  [
    {
      "paper_id": "2205.12917v2",
      "title": "Identification of Auction Models Using Order Statistics",
      "subject": [
        "econ.EM"
      ],
      "abstract": "Auction data often contain information on only the most competitive bids as\nopposed to all bids. The usual measurement error approaches to unobserved\nheterogeneity are inapplicable due to dependence among order statistics. We\nbridge this gap by providing a set of positive identification results. First,\nwe show that symmetric auctions with discrete unobserved heterogeneity are\nidentifiable using two consecutive order statistics and an instrument. Second,\nwe extend the results to ascending auctions with unknown competition and\nunobserved heterogeneity."
    },
    {
      "paper_id": "2412.00437v1",
      "title": "DeepFGS: Fine-Grained Scalable Coding for Learned Image Compression",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Scalable coding, which can adapt to channel bandwidth variation, performs\nwell in today's complex network environment. However, most existing scalable\ncompression methods face two challenges: reduced compression performance and\ninsufficient scalability. To overcome the above problems, this paper proposes a\nlearned fine-grained scalable image compression framework, namely DeepFGS.\nSpecifically, we introduce a feature separation backbone to divide the image\ninformation into basic and scalable features, then redistribute the features\nchannel by channel through an information rearrangement strategy. In this way,\nwe can generate a continuously scalable bitstream via one-pass encoding. For\nentropy coding, we design a mutual entropy model to fully explore the\ncorrelation between the basic and scalable features. In addition, we reuse the\ndecoder to reduce the parameters and computational complexity. Experiments\ndemonstrate that our proposed DeepFGS outperforms previous learning-based\nscalable image compression models and traditional scalable image codecs in both\nPSNR and MS-SSIM metrics."
    }
  ],
  [
    {
      "paper_id": "2103.02821v1",
      "title": "MT* : Multi-Robot Path Planning for Temporal Logic Specifications",
      "subject": [
        "cs.RO"
      ],
      "abstract": "We address the path planning problem for a team of robots satisfying a\ncomplex high-level mission specification given in the form of an Linear\nTemporal Logic (LTL) formula. The state-of-the-art approach to this problem\nemploys the automata-theoretic model checking technique to solve this problem.\nThis approach involves computation of a product graph of the Buchi automaton\ngenerated from the LTL specification and a joint transition system which\ncaptures the collective motion of the robots and then computation of the\nshortest path using Dijkstra's shortest path algorithm. We propose MT*, an\nalgorithm that reduces the computation burden for generating such plans for\nmulti-robot systems significantly. Our approach generates a reduced version of\nthe product graph without computing the complete joint transition system, which\nis computationally expensive. It then divides the complete mission\nspecification among the participating robots and generates the trajectories for\nthe individual robots independently. Our approach demonstrates substantial\nspeedup in terms of computation time over the state-of-the-art approach, and\nunlike the state of the art approach, scales well with both the number of\nrobots and the size of the workspace"
    },
    {
      "paper_id": "2404.07331v1",
      "title": "Financial climate risk: a review of recent advances and key challenges",
      "subject": [
        "econ.GN"
      ],
      "abstract": "The document provides an overview of financial climate risks. It delves into\nhow climate change impacts the global financial system, distinguishing between\nphysical risks (such as extreme weather events) and transition risks (stemming\nfrom policy changes and economic transitions towards low carbon technologies).\nThe paper underlines the complexity of accurately defining financial climate\nrisk, citing the integration of climate science with financial risk analysis as\na significant challenge. The paper highlights the pivotal role of microfinance\ninstitutions (MFIs) in addressing financial climate risk, especially for\npopulations vulnerable to climate change. The document emphasizes the\nimportance of updating risk management practices within MFIs to explicitly\ninclude climate risk assessments and suggests leveraging technology to improve\nthese practices."
    }
  ],
  [
    {
      "paper_id": "2407.19585v1",
      "title": "The Rees algebra and analytic spread of a divisorial filtration",
      "subject": [
        "math.AC",
        "math.AG"
      ],
      "abstract": "In this paper we investigate some properties of Rees algebras of divisorial\nfiltrations and their analytic spread. A classical theorem of McAdam shows that\nthe analytic spread of an ideal $I$ in a formally equidimensional local ring is\nequal to the dimension of the ring if and only if the maximal ideal is an\nassociated prime of $R/\\overline{I^n}$ for some $n$. We show in Theorem 1.6\nthat McAdam's theorem holds for $\\mathbb Q$-divisorial filtrations in an\nequidimensional local ring which is essentially of finite type over a field.\nThis generalizes an earlier result for $\\mathbb Q$-divisorial filtrations in an\nequicharacteristic zero excellent local domain by the author. This theorem does\nnot hold for more general filtrations.\n  We consider the question of the asymptotic behavior of the function $n\\mapsto\n\\lambda_R(R/I_n)$ for a $\\mathbb Q$-divisorial filtration $\\mathcal I=\\{I_n\\}$\nof $m_R$-primary ideals on a $d$-dimensional normal excellent local ring. It is\nknown from earlier work of the author that the multiplicity $$ e(\\mathcal I)=d!\n\\lim_{n\\rightarrow\\infty}\\frac{\\lambda_R(R/I_n)}{n^d} $$ can be irrational. We\nshow in Lemma 4.1 that the limsup of the first difference function $$\n\\limsup_{n\\rightarrow\\infty}\\frac{\\lambda_R(I_n/I_{n+1})}{n^{d-1}} $$ is always\nfinite for a $\\mathbb Q$-divisorial filtration. We then give an example in\nSection 4 showing that this limsup may not exist as a limit.\n  In the final section, we give an example of a symbolic filtration\n$\\{P^{(n)}\\}$ of a prime ideal $P$ in a normal two dimensional excellent local\nring which has the property that the set of Rees valuations of all the symbolic\npowers $P^{(n)}$ of $P$ is infinite."
    },
    {
      "paper_id": "cond-mat/0503156v1",
      "title": "Simulations of financial markets in a Potts-like model",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "A three-state model based on the Potts model is proposed to simulate\nfinancial markets. The three states are assigned to \"buy\", \"sell\" and\n\"inactive\" states. The model shows the main stylized facts observed in the\nfinancial market: fat-tailed distributions of returns and long time\ncorrelations in the absolute returns. At low inactivity rate, the model\neffectively reduces to the two-state model of Bornholdt and shows similar\nresults to the Bornholdt model. As the inactivity increases, we observe the\nexponential distributions of returns."
    }
  ],
  [
    {
      "paper_id": "2009.07055v7",
      "title": "Causal Inference of General Treatment Effects using Neural Networks with\n  A Diverging Number of Confounders",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Semiparametric efficient estimation of various multi-valued causal effects,\nincluding quantile treatment effects, is important in economic, biomedical, and\nother social sciences. Under the unconfoundedness condition, adjustment for\nconfounders requires estimating the nuisance functions relating outcome or\ntreatment to confounders nonparametrically. This paper considers a generalized\noptimization framework for efficient estimation of general treatment effects\nusing artificial neural networks (ANNs) to approximate the unknown nuisance\nfunction of growing-dimensional confounders. We establish a new approximation\nerror bound for the ANNs to the nuisance function belonging to a mixed\nsmoothness class without a known sparsity structure. We show that the ANNs can\nalleviate the \"curse of dimensionality\" under this circumstance. We establish\nthe root-$n$ consistency and asymptotic normality of the proposed general\ntreatment effects estimators, and apply a weighted bootstrap procedure for\nconducting inference. The proposed methods are illustrated via simulation\nstudies and a real data application."
    },
    {
      "paper_id": "1708.05938v2",
      "title": "Emergent L\u00e9vy behavior in single-cell stochastic gene expression",
      "subject": [
        "q-bio.MN",
        "q-bio.CB",
        "q-bio.QM"
      ],
      "abstract": "Single-cell gene expression is inherently stochastic; its emergent behavior\ncan be defined in terms of the chemical master equation describing the\nevolution of the mRNA and protein copy numbers as the latter tends to infinity.\nWe establish two types of \"macroscopic limits\": the Kurtz limit is consistent\nwith the classical chemical kinetics, while the L\\'{e}vy limit provides a\ntheoretical foundation for an empirical equation proposed in [Phys. Rev. Lett.\n97:168302, 2006]. Furthermore, we clarify the biochemical implications and\nranges of applicability for various macroscopic limits and calculate a\ncomprehensive analytic expression for the protein concentration distribution in\nautoregulatory gene networks. The relationship between our work and modern\npopulation genetics is discussed."
    }
  ],
  [
    {
      "paper_id": "2409.02025v1",
      "title": "Logarithmic regret in the ergodic Avellaneda-Stoikov market making model",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "We analyse the regret arising from learning the price sensitivity parameter\n$\\kappa$ of liquidity takers in the ergodic version of the Avellaneda-Stoikov\nmarket making model. We show that a learning algorithm based on a regularised\nmaximum-likelihood estimator for the parameter achieves the regret upper bound\nof order $\\ln^2 T$ in expectation. To obtain the result we need two key\ningredients. The first are tight upper bounds on the derivative of the ergodic\nconstant in the Hamilton-Jacobi-Bellman (HJB) equation with respect to\n$\\kappa$. The second is the learning rate of the maximum-likelihood estimator\nwhich is obtained from concentration inequalities for Bernoulli signals.\nNumerical experiment confirms the convergence and the robustness of the\nproposed algorithm."
    },
    {
      "paper_id": "1811.06877v1",
      "title": "Smart Grid Co-Simulation with MOSAIK and HLA: A Comparison Study",
      "subject": [
        "cs.OH"
      ],
      "abstract": "Evaluating new technological developments for energy systems is becoming more\nand more complex. The overall application environment is a continuously growing\nand interconnected cyber-physical system so that analytical assessment is\npractically impossible to realize. Consequently, new solutions must be\nevaluated in simulation studies. Due to the interdisciplinarity of the\nsimulation scenarios, various heterogeneous tools must be connected. This\napproach is known as co-simulation. During the last years, different approaches\nhave been developed or adapted for applications in energy systems. In this\npaper, two co-simulation approaches are compared that follow generic, versatile\nconcepts. The tool mosaik, which has been explicitly developed for the purpose\nof co-simulation in complex energy systems, is compared to the High Level\nArchitecture (HLA), which possesses a domain-independent scope but is often\nemployed in the energy domain. The comparison is twofold, considering the\ntools' conceptual architectures as well as results from the simulation of\nrepresentative test cases. It suggests that mosaik may be the better choice for\nentry-level, prototypical co-simulation while HLA is more suited for complex\nand extensive studies."
    }
  ],
  [
    {
      "paper_id": "1801.01777v4",
      "title": "Deep Learning for Forecasting Stock Returns in the Cross-Section",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "Many studies have been undertaken by using machine learning techniques,\nincluding neural networks, to predict stock returns. Recently, a method known\nas deep learning, which achieves high performance mainly in image recognition\nand speech recognition, has attracted attention in the machine learning field.\nThis paper implements deep learning to predict one-month-ahead stock returns in\nthe cross-section in the Japanese stock market and investigates the performance\nof the method. Our results show that deep neural networks generally outperform\nshallow neural networks, and the best networks also outperform representative\nmachine learning models. These results indicate that deep learning shows\npromise as a skillful machine learning method to predict stock returns in the\ncross-section."
    },
    {
      "paper_id": "2410.08939v1",
      "title": "Linear-cost unbiased posterior estimates for crossed effects and matrix\n  factorization models via couplings",
      "subject": [
        "stat.CO",
        "stat.ML"
      ],
      "abstract": "We design and analyze unbiased Markov chain Monte Carlo (MCMC) schemes based\non couplings of blocked Gibbs samplers (BGSs), whose total computational costs\nscale linearly with the number of parameters and data points. Our methodology\nis designed for and applicable to high-dimensional BGS with conditionally\nindependent blocks, which are often encountered in Bayesian modeling. We\nprovide bounds on the expected number of iterations needed for coalescence for\nGaussian targets, which imply that practical two-step coupling strategies\nachieve coalescence times that match the relaxation times of the original BGS\nscheme up to a logarithmic factor. To illustrate the practical relevance of our\nmethodology, we apply it to high-dimensional crossed random effect and\nprobabilistic matrix factorization models, for which we develop a novel BGS\nscheme with improved convergence speed. Our methodology provides unbiased\nposterior estimates at linear cost (usually requiring only a few BGS iterations\nfor problems with thousands of parameters), matching state-of-the-art\nprocedures for both frequentist and Bayesian estimation of those models."
    }
  ],
  [
    {
      "paper_id": "1303.2289v2",
      "title": "Distributed optimization over time-varying directed graphs",
      "subject": [
        "cs.DC",
        "cs.SY"
      ],
      "abstract": "We consider distributed optimization by a collection of nodes, each having\naccess to its own convex function, whose collective goal is to minimize the sum\nof the functions. The communications between nodes are described by a\ntime-varying sequence of directed graphs, which is uniformly strongly\nconnected. For such communications, assuming that every node knows its\nout-degree, we develop a broadcast-based algorithm, termed the\nsubgradient-push, which steers every node to an optimal value under a standard\nassumption of subgradient boundedness. The subgradient-push requires no\nknowledge of either the number of agents or the graph sequence to implement.\nOur analysis shows that the subgradient-push algorithm converges at a rate of\n$O(\\ln(t)/\\sqrt{t})$, where the constant depends on the initial values at the\nnodes, the subgradient norms, and, more interestingly, on both the consensus\nspeed and the imbalances of influence among the nodes."
    },
    {
      "paper_id": "2402.13604v2",
      "title": "Breaking the HISCO Barrier: Automatic Occupational Standardization with\n  OccCANINE",
      "subject": [
        "econ.EM"
      ],
      "abstract": "This paper introduces a new tool, OccCANINE, to automatically transform\noccupational descriptions into the HISCO classification system. The manual work\ninvolved in processing and classifying occupational descriptions is\nerror-prone, tedious, and time-consuming. We finetune a preexisting language\nmodel (CANINE) to do this automatically, thereby performing in seconds and\nminutes what previously took days and weeks. The model is trained on 14 million\npairs of occupational descriptions and HISCO codes in 13 different languages\ncontributed by 22 different sources. Our approach is shown to have accuracy,\nrecall, and precision above 90 percent. Our tool breaks the metaphorical HISCO\nbarrier and makes this data readily available for analysis of occupational\nstructures with broad applicability in economics, economic history, and various\nrelated disciplines."
    }
  ],
  [
    {
      "paper_id": "1608.02143v2",
      "title": "Bayesian Sparse Linear Regression with Unknown Symmetric Error",
      "subject": [
        "stat.TH"
      ],
      "abstract": "We study full Bayesian procedures for sparse linear regression when errors\nhave a symmetric but otherwise unknown distribution. The unknown error\ndistribution is endowed with a symmetrized Dirichlet process mixture of\nGaussians. For the prior on regression coefficients, a mixture of point masses\nat zero and continuous distributions is considered. We study behavior of the\nposterior with diverging number of predictors. Conditions are provided for\nconsistency in the mean Hellinger distance. The compatibility and restricted\neigenvalue conditions yield the minimax convergence rate of the regression\ncoefficients in $\\ell_1$- and $\\ell_2$-norms, respectively. The convergence\nrate is adaptive to both the unknown sparsity level and the unknown symmetric\nerror density under compatibility conditions. In addition, strong model\nselection consistency and a semi-parametric Bernstein-von Mises theorem are\nproven under slightly stronger conditions."
    },
    {
      "paper_id": "2401.05888v1",
      "title": "Incorporation of Confidence Interval into Rate Selection Based on the\n  Extreme Value Theory for Ultra-Reliable Communications",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Proper determination of the transmission rate in ultra-reliable low latency\ncommunication (URLLC) needs to incorporate a confidence interval (CI) for the\nestimated parameters due to the large amount of data required for their\naccurate estimation. In this paper, we propose a framework based on the extreme\nvalue theory (EVT) for determining the transmission rate along with its\ncorresponding CI for an ultra-reliable communication system. This framework\nconsists of characterizing the statistics of extreme events by fitting the\ngeneralized Pareto distribution (GPD) to the channel tail, deriving the GPD\nparameters and their associated CIs, and obtaining the transmission rate within\na confidence interval. Based on the data collected within the engine\ncompartment of Fiat Linea, we demonstrate the accuracy of the estimated rate\nobtained through the EVT-based framework considering the confidence interval\nfor the GPD parameters. Additionally, we show that proper estimation of the\ntransmission rate based on the proposed framework requires a lower number of\nsamples compared to the traditional extrapolation-based approaches."
    }
  ],
  [
    {
      "paper_id": "2103.04517v1",
      "title": "Optimal H\u00f6lder regularity for the $\\bar\\partial$ problem on product\n  domains in $\\mathbb C^2$",
      "subject": [
        "math.CV"
      ],
      "abstract": "The note concerns the $\\bar\\partial$ problem on product domains in $\\mathbb\nC^2$. We show that there exists a bounded solution operator from $C^{k,\n\\alpha}$ into itself, $k\\in \\mathbb Z^+\\cup \\{0\\}, 0<\\alpha< 1$. The regularity\nresult is optimal in view of an example of Stein-Kerzman."
    },
    {
      "paper_id": "1401.5398v1",
      "title": "Dirichlet-Laplace priors for optimal shrinkage",
      "subject": [
        "stat.TH"
      ],
      "abstract": "Penalized regression methods, such as $L_1$ regularization, are routinely\nused in high-dimensional applications, and there is a rich literature on\noptimality properties under sparsity assumptions. In the Bayesian paradigm,\nsparsity is routinely induced through two-component mixture priors having a\nprobability mass at zero, but such priors encounter daunting computational\nproblems in high dimensions. This has motivated an amazing variety of\ncontinuous shrinkage priors, which can be expressed as global-local scale\nmixtures of Gaussians, facilitating computation. In sharp contrast to the\nfrequentist literature, little is known about the properties of such priors and\nthe convergence and concentration of the corresponding posterior distribution.\nIn this article, we propose a new class of Dirichlet--Laplace (DL) priors,\nwhich possess optimal posterior concentration and lead to efficient posterior\ncomputation exploiting results from normalized random measure theory. Finite\nsample performance of Dirichlet--Laplace priors relative to alternatives is\nassessed in simulated and real data examples."
    }
  ],
  [
    {
      "paper_id": "1305.0361v1",
      "title": "Braess's Paradox in Epidemic Game: Better Condition Results in Less\n  Payoff",
      "subject": [
        "q-bio.PE"
      ],
      "abstract": "Facing the threats of infectious diseases, we take various actions to protect\nourselves, but few studies considered an evolving system with competing\nstrategies. In view of that, we propose an evolutionary epidemic model coupled\nwith human behaviors, where individuals have three strategies: vaccination,\nself-protection and laissez faire, and could adjust their strategies according\nto their neighbors' strategies and payoffs at the beginning of each new season\nof epidemic spreading. We found a counter-intuitive phenomenon analogous to the\nwell-known \\emph{Braess's Paradox}, namely a better condition may lead to worse\nperformance. Specifically speaking, increasing the successful rate of\nself-protection does not necessarily reduce the epidemic size or improve the\nsystem payoff. This phenomenon is insensitive to the network topologies, and\ncan be well explained by a mean-field approximation. Our study demonstrates an\nimportant fact that a better condition for individuals may yield a worse\noutcome for the society."
    },
    {
      "paper_id": "1805.05259v1",
      "title": "The strong Fatou property of risk measures",
      "subject": [
        "q-fin.RM"
      ],
      "abstract": "In this paper, we explore several Fatou-type properties of risk measures. The\npaper continues to reveal that the strong Fatou property, which was introduced\nin [17], seems to be most suitable to ensure nice dual representations of risk\nmeasures. Our main result asserts that every quasiconvex law-invariant\nfunctional on a rearrangement invariant space $\\mathcal{X}$ with the strong\nFatou property is $\\sigma(\\mathcal{X},L^\\infty)$ lower semicontinuous and that\nthe converse is true on a wide range of rearrangement invariant spaces. We also\nstudy inf-convolutions of law-invariant or surplus-invariant risk measures that\npreserve the (strong) Fatou property."
    }
  ],
  [
    {
      "paper_id": "1911.10552v1",
      "title": "High-Dimensional Forecasting in the Presence of Unit Roots and\n  Cointegration",
      "subject": [
        "econ.EM"
      ],
      "abstract": "We investigate how the possible presence of unit roots and cointegration\naffects forecasting with Big Data. As most macroeoconomic time series are very\npersistent and may contain unit roots, a proper handling of unit roots and\ncointegration is of paramount importance for macroeconomic forecasting. The\nhigh-dimensional nature of Big Data complicates the analysis of unit roots and\ncointegration in two ways. First, transformations to stationarity require\nperforming many unit root tests, increasing room for errors in the\nclassification. Second, modelling unit roots and cointegration directly is more\ndifficult, as standard high-dimensional techniques such as factor models and\npenalized regression are not directly applicable to (co)integrated data and\nneed to be adapted. We provide an overview of both issues and review methods\nproposed to address these issues. These methods are also illustrated with two\nempirical applications."
    },
    {
      "paper_id": "2003.04007v1",
      "title": "Copula-based local dependence between energy, agriculture and metal\n  commodity markets",
      "subject": [
        "q-fin.CP",
        "q-fin.ST"
      ],
      "abstract": "This paper studies the extreme dependencies between energy, agriculture and\nmetal commodity markets, with a focus on local co-movements, allowing the\nidentification of asymmetries and changing trend in the degree of co-movements.\nMore precisely, starting from a non-parametric mixture copula, we use a novel\ncopula-based local Kendall's tau approach to measure nonlinear local dependence\nin regions. In all pairs of commodity indexes, we find increased co-movements\nin extreme situations, a stronger dependence between energy and other commodity\nmarkets at lower tails, and a 'V-type' local dependence for the energy-metal\npairs. The three-dimensional Kendall's tau plot for upper tails in quantiles\nshows asymmetric co-movements in the energy-metal pairs, which tend to become\nnegative at peak returns. Therefore, we show that the energy market can offer\ndiversification solutions for risk management in the case of extreme bull\nmarket events."
    }
  ],
  [
    {
      "paper_id": "1402.5390v1",
      "title": "Spontaneous oscillations from turnover of an elastic contractile\n  material",
      "subject": [
        "q-bio.CB"
      ],
      "abstract": "Single and collective cellular oscillations involving the actomyosin\ncytoskeleton have been observed in numerous biological systems. We show here\nthat a generic model of a contractile material, which is turning over and\ncontracts against an elastic element, exhibits spontaneous oscillations. Such a\nmodel can thus account for shape oscillations observed in amnioserosa cells\nduring dorsal closure of the Drosophila embryo. We investigate the collective\ndynamics of an ensemble of such oscillators and show that the relative\ncontribution of viscous and friction losses yield different regimes of\ncollective oscillations. Taking into account the diffusion of contractile\nelements, our theoretical framework predicts the appearance of traveling waves\nwhich might account for the propagation of actomyosin contractile waves\nobserved during morphogenesis."
    },
    {
      "paper_id": "2312.11944v2",
      "title": "FPT Approximation using Treewidth: Capacitated Vertex Cover, Target Set\n  Selection and Vector Dominating Set",
      "subject": [
        "cs.DS",
        "cs.CC"
      ],
      "abstract": "Treewidth is a useful tool in designing graph algorithms. Although many\nNP-hard graph problems can be solved in linear time when the input graphs have\nsmall treewidth, there are problems which remain hard on graphs of bounded\ntreewidth. In this paper, we consider three vertex selection problems that are\nW[1]-hard when parameterized by the treewidth of the input graph, namely the\ncapacitated vertex cover problem, the target set selection problem and the\nvector dominating set problem. We provide two new methods to obtain FPT\napproximation algorithms for these problems. For the capacitated vertex cover\nproblem and the vector dominating set problem, we obtain\n$(1+o(1))$-approximation FPT algorithms. For the target set selection problem,\nwe give an FPT algorithm providing a tradeoff between its running time and the\napproximation ratio."
    }
  ],
  [
    {
      "paper_id": "2007.11941v1",
      "title": "(Unintended) Consequences of export restrictions on medical goods during\n  the Covid-19 pandemic",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "In the first half of 2020, several countries have responded to the challenges\nposed by the Covid-19 pandemic by restricting their export of medical supplies.\nSuch measures are meant to increase the domestic availability of critical\ngoods, and are commonly used in times of crisis. Yet, not much is known about\ntheir impact, especially on countries imposing them. Here we show that export\nbans are, by and large, counterproductive. Using a model of shock diffusion\nthrough the network of international trade, we simulate the impact of\nrestrictions under different scenarios. We observe that while they would be\nbeneficial to a country implementing them in isolation, their generalized use\nmakes most countries worse off relative to a no-ban scenario. As a corollary,\nwe estimate that prices increase in many countries imposing the restrictions.\nWe also find that the cost of restraining from export bans is small, even when\nothers continue to implement them. Finally, we document a change in countries'\nposition within the international trade network, suggesting that export bans\nhave geopolitical implications."
    },
    {
      "paper_id": "2412.06226v1",
      "title": "Can Generalized Extreme Value Model Fit the Real Stocks",
      "subject": [
        "stat.AP"
      ],
      "abstract": "The Generalized Extreme Value (GEV) distribution plays a critical role in\nrisk assessment across various domains, such as hydrology, climate science, and\nfinance. In this study, we investigate its application in analyzing intraday\ntrading risks within the Chinese stock market, focusing on abrupt price\nmovements influenced by unique trading regulations. To address limitations of\ntraditional GEV parameter estimators, we leverage recently developed robust and\nasymptotically normal estimators, enabling accurate modeling of extreme\nintraday price fluctuations. We introduce two risk indicators: the mean risk\nlevel (mEVI) and a Stability Indicator (STI) to evaluate the stability of the\nshape parameter over time. Using data from 261 Chinese and 32 U.S. stocks\n(2015-2017), we find that Chinese stocks exhibit higher mEVI, corresponding to\ngreater tail risk, while maintaining high model stability. Additionally, we\nshow that Value at Risk (VaR) estimates derived from our GEV models outperform\ntraditional GP and normal-based VaR methods in terms of variance and portfolio\noptimization. These findings underscore the versatility and efficiency of GEV\nmodeling for intraday risk management and portfolio strategies."
    }
  ],
  [
    {
      "paper_id": "2404.00806v2",
      "title": "Algorithmic Collusion by Large Language Models",
      "subject": [
        "econ.GN"
      ],
      "abstract": "The rise of algorithmic pricing raises concerns of algorithmic collusion. We\nconduct experiments with algorithmic pricing agents based on Large Language\nModels (LLMs). We find that (1) LLM-based agents are adept at pricing tasks,\n(2) LLM-based pricing agents autonomously collude in oligopoly settings to the\ndetriment of consumers, and (3) variation in seemingly innocuous phrases in LLM\ninstructions (\"prompts\") may increase collusion. Novel off-path analysis\ntechniques uncover price-war concerns as contributing to these phenomena. Our\nresults extend to auction settings. Our findings uncover unique challenges to\nany future regulation of LLM-based pricing agents, and black-box pricing agents\nmore broadly."
    },
    {
      "paper_id": "0902.4417v1",
      "title": "A Dimension Reduction Method for Inferring Biochemical Networks",
      "subject": [
        "q-bio.MN",
        "q-bio.QM"
      ],
      "abstract": "We present herein an extension of an algebraic statistical method for\ninferring biochemical reaction networks from experimental data, proposed\nrecently in [3]. This extension allows us to analyze reaction networks that are\nnot necessarily full-dimensional, i.e., the dimension of their stoichiometric\nspace is smaller than the number of species. Specifically, we propose to\naugment the original algebraic-statistical algorithm for network inference with\na preprocessing step that identifies the subspace spanned by the correct\nreaction vectors, within the space spanned by the species. This dimension\nreduction step is based on principal component analysis of the input data and\nits relationship with various subspaces generated by sets of candidate reaction\nvectors. Simulated examples are provided to illustrate the main ideas involved\nin implementing this method, and to asses its performance."
    }
  ],
  [
    {
      "paper_id": "2202.05731v1",
      "title": "Flags, Landscapes and Signaling: Contact-mediated inter-cellular\n  interactions enable plasticity in fate determination driven by positional\n  information",
      "subject": [
        "q-bio.TO"
      ],
      "abstract": "Multicellular organisms exhibit a high degree of structural organization with\nspecific cell types always occurring in characteristic locations. The\nconventional framework for describing the emergence of such consistent spatial\npatterns is provided by Wolpert's \"French flag\" paradigm. According to this\nview, intra-cellular genetic regulatory mechanisms use positional information\nprovided by morphogen concentration gradients to differentially express\ndistinct fates, resulting in a characteristic pattern of differentiated cells.\nHowever, recent experiments have shown that suppression of inter-cellular\ninteractions can alter these spatial patterns, suggesting that cell fates are\nnot exclusively determined by the regulation of gene expression by local\nmorphogen concentration. Using an explicit model where adjacent cells\ncommunicate by Notch signaling, we provide a mechanistic description of how\ncontact-mediated interactions allow information from the cellular environment\nto be incorporated into cell fate decisions. Viewing cellular differentiation\nin terms of trajectories along an epigenetic landscape (as first enunciated by\nWaddington), our results suggest that the contours of the landscape are moulded\ndifferently in a cell position-dependent manner, not only by the global signal\nprovided by the morphogen but also by the local environment via cell-cell\ninteractions. We show that our results are robust with respect to different\nchoices of coupling between the inter-cellular signaling apparatus and the\nintra-cellular gene regulatory dynamics. Indeed, we show that the broad\nfeatures can be observed even in abstract spin models. Our work reconciles\ninteraction-mediated self-organized pattern formation with boundary-organized\nmechanisms involving signals that break symmetry."
    },
    {
      "paper_id": "physics/0610013v1",
      "title": "Hydrogen atom in crossed electric and magnetic fields: Phase space\n  topology and torus quantization via periodic orbits",
      "subject": [
        "physics.atom-ph",
        "nlin.CD"
      ],
      "abstract": "A hierarchical ordering is demonstrated for the periodic orbits in a strongly\ncoupled multidimensional Hamiltonian system, namely the hydrogen atom in\ncrossed electric and magnetic fields. It mirrors the hierarchy of broken\nresonant tori and thereby allows one to characterize the periodic orbits by a\nset of winding numbers. With this knowledge, we construct the action variables\nas functions of the frequency ratios and carry out a semiclassical torus\nquantization. The semiclassical energy levels thus obtained agree well with\nexact quantum calculations."
    }
  ],
  [
    {
      "paper_id": "1404.4416v1",
      "title": "A characterization of eventually periodicity",
      "subject": [
        "cs.CC"
      ],
      "abstract": "In this article, we show that the Kamae-Xue complexity function for an\ninfinite sequence classifies eventual periodicity completely. We prove that an\ninfinite binary word $x_1x_2 \\cdots $ is eventually periodic if and only if\n$\\Sigma(x_1x_2\\cdots x_n)/n^3$ has a positive limit, where $\\Sigma(x_1x_2\\cdots\nx_n)$ is the sum of the squares of all the numbers of appearance of finite\nwords in $x_1 x_2 \\cdots x_n$, which was introduced by Kamae-Xue as a criterion\nof randomness in the sense that $x_1x_2\\cdots x_n$ is more random if\n$\\Sigma(x_1x_2\\cdots x_n)$ is smaller. In fact, it is known that the lower\nlimit of $\\Sigma(x_1x_2\\cdots x_n) /n^2 $ is at least 3/2 for any sequence\n$x_1x_2 \\cdots$, while the limit exists as 3/2 almost surely for the\n$(1/2,1/2)$ product measure. For the other extreme, the upper limit of\n$\\Sigma(x_1x_2\\cdots x_n)/n^3$ is bounded by 1/3. There are sequences which are\nnot eventually periodic but the lower limit of $\\Sigma(x_1x_2\\cdots x_n)/n^3$\nis positive, while the limit does not exist."
    },
    {
      "paper_id": "0902.0600v5",
      "title": "Reconstruction of Epsilon-Machines in Predictive Frameworks and\n  Decisional States",
      "subject": [
        "stat.ML"
      ],
      "abstract": "This article introduces both a new algorithm for reconstructing\nepsilon-machines from data, as well as the decisional states. These are defined\nas the internal states of a system that lead to the same decision, based on a\nuser-provided utility or pay-off function. The utility function encodes some a\npriori knowledge external to the system, it quantifies how bad it is to make\nmistakes. The intrinsic underlying structure of the system is modeled by an\nepsilon-machine and its causal states. The decisional states form a partition\nof the lower-level causal states that is defined according to the higher-level\nuser's knowledge. In a complex systems perspective, the decisional states are\nthus the \"emerging\" patterns corresponding to the utility function. The\ntransitions between these decisional states correspond to events that lead to a\nchange of decision. The new REMAPF algorithm estimates both the epsilon-machine\nand the decisional states from data. Application examples are given for hidden\nmodel reconstruction, cellular automata filtering, and edge detection in\nimages."
    }
  ],
  [
    {
      "paper_id": "1207.4589v1",
      "title": "Minimum-Length Scheduling with Finite Queues: Solution Characterization\n  and Algorithmic Framework",
      "subject": [
        "cs.IT",
        "cs.NI"
      ],
      "abstract": "We consider a set of transmitter-receiver pairs, or links, that share a\ncommon channel and address the problem of emptying backlogged queues at the\ntransmitters in minimum time. The problem amounts to determining activation\nsubsets of links and their time durations to form a minimum-length schedule.\nThe problem of scheduling has been studied under various formulations before.\nIn this paper, we present fundamental insights and solution characterizations\nthat include: (i) showing that the complexity of the problem remains high for\nany continuous and increasing rate function, (ii) formulating and proving\nsufficient and necessary optimality conditions of two base scheduling\nstrategies that correspond to emptying the queues using \"one-at-a-time\" or\n\"all-at-once\" strategies, (iii) presenting and proving the tractability of the\nspecial case in which the transmission rates are functions only of the\ncardinality of the link activation sets. These results are independent of\nphysical-layer system specifications and are valid for any form of rate\nfunction. We then develop an algorithmic framework. The framework encompasses\nexact as well as sub-optimal, but fast, scheduling algorithms, all under a\nunified principle design. Through computational experiments we finally\ninvestigate the performance of several specific algorithms."
    },
    {
      "paper_id": "2204.12850v2",
      "title": "Diurnal variation of the surface temperature of Mars with the Emirates\n  Mars Mission: A comparison with Curiosity and Perseverance rover measurements",
      "subject": [
        "astro-ph.EP",
        "physics.space-ph"
      ],
      "abstract": "For the first time, the Emirates Mars Infrared Spectrometer (EMIRS)\ninstrument on board the Emirates Mars Mission (EMM) \"Hope\", is providing us\nwith the temperature measurements of Mars at all local times covering most of\nthe planet. As a result, it is now possible to compare surface temperature\nmeasurements made from orbit with those from the surface by rovers during the\nsame time period. We use data of diurnal temperature variation from the Rover\nEnvironmental Monitoring Station (REMS) suite on board the Mars Science\nLaboratory (MSL) \"Curiosity\" rover, and the Mars Environmental Dynamics\nAnalyzer (MEDA) suite on board the Mars 2020 \"Perseverance\" rover, between June\nand August 2021 and compare them with EMIRS observations and estimates of the\nMars Climate Database (MCD) model. We show that although the overall trend of\ntemperature variation is in excellent agreement across missions, EMIRS\nmeasurements are systematically lower at night compared to Mars 2020. The lower\nspatial resolution of EMIRS compared to the rovers and consequently lower\naverage thermal inertia of the observed regions in this particular case\nprimarily contributed to this discrepancy, among other factors. We discuss the\nimplications of these results in improving our understanding of the Martian\nclimate which would lead to better modeling of local weather prediction, useful\nfor future robotic and crewed missions."
    }
  ],
  [
    {
      "paper_id": "2501.02303v1",
      "title": "Design and Benchmarking of A Multi-Modality Sensor for Robotic\n  Manipulation with GAN-Based Cross-Modality Interpretation",
      "subject": [
        "eess.SP"
      ],
      "abstract": "In this paper, we present the design and benchmark of an innovative sensor,\nViTacTip, which fulfills the demand for advanced multi-modal sensing in a\ncompact design. A notable feature of ViTacTip is its transparent skin, which\nincorporates a `see-through-skin' mechanism. This mechanism aims at capturing\ndetailed object features upon contact, significantly improving both\nvision-based and proximity perception capabilities. In parallel, the biomimetic\ntips embedded in the sensor's skin are designed to amplify contact details,\nthus substantially augmenting tactile and derived force perception abilities.\nTo demonstrate the multi-modal capabilities of ViTacTip, we developed a\nmulti-task learning model that enables simultaneous recognition of hardness,\nmaterial, and textures. To assess the functionality and validate the\nversatility of ViTacTip, we conducted extensive benchmarking experiments,\nincluding object recognition, contact point detection, pose regression, and\ngrating identification. To facilitate seamless switching between various\nsensing modalities, we employed a Generative Adversarial Network (GAN)-based\napproach. This method enhances the applicability of the ViTacTip sensor across\ndiverse environments by enabling cross-modality interpretation."
    },
    {
      "paper_id": "q-bio/0605033v1",
      "title": "Impact of observational incompleteness on the structural properties of\n  protein interaction networks",
      "subject": [
        "q-bio.MN"
      ],
      "abstract": "The observed structure of protein interaction networks is corrupted by many\nfalse positive/negative links. This observational incompleteness is abstracted\nas random link removal and a specific, experimentally motivated (spoke) link\nrearrangement. Their impact on the structural properties of\ngene-duplication-and-mutation network models is studied. For the degree\ndistribution a curve collapse is found, showing no sensitive dependence on the\nlink removal/rearrangement strengths and disallowing a quantitative extraction\nof model parameters. The spoke link rearrangement process moves other\nstructural observables, like degree correlations, cluster coefficient and motif\nfrequencies, closer to their counterparts extracted from the yeast data. This\nunderlines the importance to take a precise modeling of the observational\nincompleteness into account when network structure models are to be\nquantitatively compared to data."
    }
  ],
  [
    {
      "paper_id": "2312.04464v1",
      "title": "Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement\n  Learning with General Function Approximation",
      "subject": [
        "stat.ML"
      ],
      "abstract": "To tackle long planning horizon problems in reinforcement learning with\ngeneral function approximation, we propose the first algorithm, termed as\nUCRL-WVTR, that achieves both \\emph{horizon-free} and\n\\emph{instance-dependent}, since it eliminates the polynomial dependency on the\nplanning horizon. The derived regret bound is deemed \\emph{sharp}, as it\nmatches the minimax lower bound when specialized to linear mixture MDPs up to\nlogarithmic factors. Furthermore, UCRL-WVTR is \\emph{computationally efficient}\nwith access to a regression oracle. The achievement of such a horizon-free,\ninstance-dependent, and sharp regret bound hinges upon (i) novel algorithm\ndesigns: weighted value-targeted regression and a high-order moment estimator\nin the context of general function approximation; and (ii) fine-grained\nanalyses: a novel concentration bound of weighted non-linear least squares and\na refined analysis which leads to the tight instance-dependent bound. We also\nconduct comprehensive experiments to corroborate our theoretical findings."
    },
    {
      "paper_id": "2410.22757v1",
      "title": "Synthesis of Timeline-Based Planning Strategies Avoiding Determinization",
      "subject": [
        "cs.FL",
        "cs.CC"
      ],
      "abstract": "Qualitative timeline-based planning models domains as sets of independent,\nbut interacting, components whose behaviors over time, the timelines, are\ngoverned by sets of qualitative temporal constraints (ordering relations),\ncalled synchronization rules. Its plan-existence problem has been shown to be\nPSPACE-complete; in particular, PSPACE-membership has been proved via reduction\nto the nonemptiness problem for nondeterministic finite automata. However,\nnondeterministic automata cannot be directly used to synthesize planning\nstrategies as a costly determinization step is needed. In this paper, we\nidentify a large fragment of qualitative timeline-based planning whose\nplan-existence problem can be directly mapped into the nonemptiness problem of\ndeterministic finite automata, which can then be exploited to synthesize\nstrategies. In addition, we identify a maximal subset of Allen's relations that\nfits into such a deterministic fragment."
    }
  ],
  [
    {
      "paper_id": "2411.07547v1",
      "title": "AuscultaBase: A Foundational Step Towards AI-Powered Body Sound\n  Diagnostics",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Auscultation of internal body sounds is essential for diagnosing a range of\nhealth conditions, yet its effectiveness is often limited by clinicians'\nexpertise and the acoustic constraints of human hearing, restricting its use\nacross various clinical scenarios. To address these challenges, we introduce\nAuscultaBase, a foundational framework aimed at advancing body sound\ndiagnostics through innovative data integration and contrastive learning\ntechniques. Our contributions include the following: First, we compile\nAuscultaBase-Corpus, a large-scale, multi-source body sound database\nencompassing 11 datasets with 40,317 audio recordings and totaling 322.4 hours\nof heart, lung, and bowel sounds. Second, we develop AuscultaBase-Model, a\nfoundational diagnostic model for body sounds, utilizing contrastive learning\non the compiled corpus. Third, we establish AuscultaBase-Bench, a comprehensive\nbenchmark containing 16 sub-tasks, assessing the performance of various\nopen-source acoustic pre-trained models. Evaluation results indicate that our\nmodel outperforms all other open-source models in 12 out of 16 tasks,\ndemonstrating the efficacy of our approach in advancing diagnostic capabilities\nfor body sound analysis."
    },
    {
      "paper_id": "1303.1296v1",
      "title": "The Pricing of A Moving Barrier Option",
      "subject": [
        "q-fin.PR",
        "q-fin.CP",
        "q-fin.RM"
      ],
      "abstract": "We provided an analytical representation of the price of a barrier option\nwith one type of special moving barrier. We consider the case that risk free\nrate, dividend rate and stock volatility are time dependent. We get a pricing\nformula and put call parity for barrier option when the moving barrier has a\nspecial relation with risk free rate, dividend rate and stock volatility."
    }
  ],
  [
    {
      "paper_id": "0902.1373v3",
      "title": "Inverse spectral problem for analytic $(Z/2Z)^n$-symmetric domains in\n  $R^n$",
      "subject": [
        "math.AP",
        "math.SP"
      ],
      "abstract": "In this paper we show that bounded analytic domains in $\\R^n$ with mirror\nsymmetries across all coordinate axes are spectrally determined among other\nsuch domains. Our approach builds on finding concrete formulas for the wave\ninvariants at a bouncing ball orbit. The wave invariants are calculated from a\nstationary phase expansion applied to a well-constructed microlocal parametrix\nfor the trace of the resolvent."
    },
    {
      "paper_id": "1409.8497v2",
      "title": "Apparent impact: the hidden cost of one-shot trades",
      "subject": [
        "q-fin.TR"
      ],
      "abstract": "We study the problem of the execution of a moderate size order in an illiquid\nmarket within the framework of a solvable Markovian model. We suppose that in\norder to avoid impact costs, a trader decides to execute her order through a\nunique trade, waiting for enough liquidity to accumulate at the best quote. We\nfind that despite the absence of a proper price impact, such trader faces an\nexecution cost arising from a non-vanishing correlation among volume at the\nbest quotes and price changes. We characterize analytically the statistics of\nthe execution time and its cost by mapping the problem to the simpler one of\ncalculating a set of first-passage probabilities on a semi-infinite strip. We\nfinally argue that price impact cannot be completely avoided by conditioning\nthe execution of an order to a more favorable liquidity scenario."
    }
  ],
  [
    {
      "paper_id": "1511.06639v1",
      "title": "Compressed and quantized correlation estimators",
      "subject": [
        "math.IT"
      ],
      "abstract": "In passive monitoring using sensor networks, low energy supplies drastically\nconstrain sensors in terms of calculation and communication abilities.\nDesigning processing algorithms at the sensor level that take into account\nthese constraints is an important problem in this context. We study here the\nestimation of correlation functions between sensors using compressed\nacquisition and one-bit-quantization. The estimation is achieved directly using\ncompressed samples, without considering any reconstruction of the signals. We\nshow that if the signals of interest are far from white noise, estimation of\nthe correlation using $M$ compressed samples out of $N\\geq M$ can be more\nadvantageous than estimation of the correlation using $M$ consecutive samples.\nThe analysis consists of studying the asymptotic performance of the estimators\nat a fixed compression rate. We provide the analysis when the compression is\nrealized by a random projection matrix composed of independent and identically\ndistributed entries. The framework includes widely used random projection\nmatrices, such as Gaussian and Bernoulli matrices, and it also includes very\nsparse matrices. However, it does not include subsampling without replacement,\nfor which a separate analysis is provided. When considering\none-bit-quantization as well, the theoretical analysis is not tractable.\nHowever, empirical evidence allows the conclusion that in practical situations,\ncompressed and quantized estimators behave sufficiently correctly to be useful\nin, for example, time-delay estimation and model estimation."
    },
    {
      "paper_id": "2002.02657v1",
      "title": "Optimization of Structural Similarity in Mathematical Imaging",
      "subject": [
        "eess.IV"
      ],
      "abstract": "It is now generally accepted that Euclidean-based metrics may not always\nadequately represent the subjective judgement of a human observer. As a result,\nmany image processing methodologies have been recently extended to take\nadvantage of alternative visual quality measures, the most prominent of which\nis the Structural Similarity Index Measure (SSIM). The superiority of the\nlatter over Euclidean-based metrics have been demonstrated in several studies.\nHowever, being focused on specific applications, the findings of such studies\noften lack generality which, if otherwise acknowledged, could have provided a\nuseful guidance for further development of SSIM-based image processing\nalgorithms. Accordingly, instead of focusing on a particular image processing\ntask, in this paper, we introduce a general framework that encompasses a wide\nrange of imaging applications in which the SSIM can be employed as a fidelity\nmeasure. Subsequently, we show how the framework can be used to cast some\nstandard as well as original imaging tasks into optimization problems, followed\nby a discussion of a number of novel numerical strategies for their solution."
    }
  ],
  [
    {
      "paper_id": "cond-mat/0510154v3",
      "title": "Role of Noise in a Market Model with Stochastic Volatility",
      "subject": [
        "q-fin.ST"
      ],
      "abstract": "We study a generalization of the Heston model, which consists of two coupled\nstochastic differential equations, one for the stock price and the other one\nfor the volatility. We consider a cubic nonlinearity in the first equation and\na correlation between the two Wiener processes, which model the two white noise\nsources. This model can be useful to describe the market dynamics characterized\nby different regimes corresponding to normal and extreme days. We analyze the\neffect of the noise on the statistical properties of the escape time with\nreference to the noise enhanced stability (NES) phenomenon, that is the noise\ninduced enhancement of the lifetime of a metastable state. We observe NES\neffect in our model with stochastic volatility. We investigate the role of the\ncorrelation between the two noise sources on the NES effect."
    },
    {
      "paper_id": "1511.08102v3",
      "title": "L1-Regularized Least Squares for Support Recovery of High Dimensional\n  Single Index Models with Gaussian Designs",
      "subject": [
        "stat.ML",
        "stat.TH"
      ],
      "abstract": "It is known that for a certain class of single index models (SIMs) $Y =\nf(\\boldsymbol{X}_{p \\times 1}^\\intercal\\boldsymbol{\\beta}_0, \\varepsilon)$,\nsupport recovery is impossible when $\\boldsymbol{X} \\sim \\mathcal{N}(0,\n\\mathbb{I}_{p \\times p})$ and a model complexity adjusted sample size is below\na critical threshold. Recently, optimal algorithms based on Sliced Inverse\nRegression (SIR) were suggested. These algorithms work provably under the\nassumption that the design $\\boldsymbol{X}$ comes from an i.i.d. Gaussian\ndistribution. In the present paper we analyze algorithms based on covariance\nscreening and least squares with $L_1$ penalization (i.e. LASSO) and\ndemonstrate that they can also enjoy optimal (up to a scalar) rescaled sample\nsize in terms of support recovery, albeit under slightly different assumptions\non $f$ and $\\varepsilon$ compared to the SIR based algorithms. Furthermore, we\nshow more generally, that LASSO succeeds in recovering the signed support of\n$\\boldsymbol{\\beta}_0$ if $\\boldsymbol{X} \\sim \\mathcal{N}(0,\n\\boldsymbol{\\Sigma})$, and the covariance $\\boldsymbol{\\Sigma}$ satisfies the\nirrepresentable condition. Our work extends existing results on the support\nrecovery of LASSO for the linear model, to a more general class of SIMs."
    }
  ],
  [
    {
      "paper_id": "1811.02478v3",
      "title": "Proofs of life: molecular-biology reasoning simulates cell behaviors\n  from first principles",
      "subject": [
        "q-bio.OT"
      ],
      "abstract": "We axiomatize the molecular-biology reasoning style, show compliance of the\nstandard reference: Ptashne, A Genetic Switch, and present proof-theory-induced\ntechnologies to help infer phenotypes and to predict life cycles from\ngenotypes. The key is to note that `reductionist discipline' entails\nconstructive reasoning: any proof of a compound property can be decomposed to\nproofs of constituent properties. Proof theory makes explicit the inner\nstructure of the axiomatized reasoning style and allows the permissible\ndynamics to be presented as a mode of computation that can be executed and\nanalyzed. Constructivity and execution guarantee simulation when working over\ndomain-specific languages. Here, we exhibit phenotype properties for genotype\nreasons: a molecular-biology argument is an open-system concurrent computation\nthat results in compartment changes and is performed among processes of\nphysiology change as determined from the molecular programming of given DNA.\nLife cycles are the possible sequentializations of the processes. A main\nimplication of our construction is that formal correctness provides a\ncomplementary perspective on science that is as fundamental there as for pure\nmathematics. The bulk of the presented work has been verified formally correct\nby computer."
    },
    {
      "paper_id": "2007.14846v1",
      "title": "An Uncertainty-aware Transfer Learning-based Framework for Covid-19\n  Diagnosis",
      "subject": [
        "eess.IV"
      ],
      "abstract": "The early and reliable detection of COVID-19 infected patients is essential\nto prevent and limit its outbreak. The PCR tests for COVID-19 detection are not\navailable in many countries and also there are genuine concerns about their\nreliability and performance. Motivated by these shortcomings, this paper\nproposes a deep uncertainty-aware transfer learning framework for COVID-19\ndetection using medical images. Four popular convolutional neural networks\n(CNNs) including VGG16, ResNet50, DenseNet121, and InceptionResNetV2 are first\napplied to extract deep features from chest X-ray and computed tomography (CT)\nimages. Extracted features are then processed by different machine learning and\nstatistical modelling techniques to identify COVID-19 cases. We also calculate\nand report the epistemic uncertainty of classification results to identify\nregions where the trained models are not confident about their decisions (out\nof distribution problem). Comprehensive simulation results for X-ray and CT\nimage datasets indicate that linear support vector machine and neural network\nmodels achieve the best results as measured by accuracy, sensitivity,\nspecificity, and AUC. Also it is found that predictive uncertainty estimates\nare much higher for CT images compared to X-ray images."
    }
  ],
  [
    {
      "paper_id": "0910.5052v3",
      "title": "Backaction of a charge detector on a double quantum dot",
      "subject": [
        "cond-mat.mes-hall"
      ],
      "abstract": "We develop a master equation approach to study the backaction of quantum\npoint contact (QPC) on a double quantum dot (DQD) at zero bias voltage. We\nreveal why electrons can pass through the zero-bias DQD only when the bias\nvoltage across the QPC exceeds a threshold value determined by the eigenstate\nenergy difference of the DQD. This derived excitation condition agrees well\nwith experiments on QPC-induced inelastic electron tunneling through a DQD [S.\nGustavsson et al., Phys. Rev. Lett. 99, 206804(2007)]. Moreover, we propose a\nnew scheme to generate a pure spin current by the QPC in the absence of a\ncharge current."
    },
    {
      "paper_id": "2407.08174v1",
      "title": "An Adaptively Weighted Averaging Method for Regional Time Series\n  Extraction of fMRI-based Brain Decoding",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "Brain decoding that classifies cognitive states using the functional\nfluctuations of the brain can provide insightful information for understanding\nthe brain mechanisms of cognitive functions. Among the common procedures of\ndecoding the brain cognitive states with functional magnetic resonance imaging\n(fMRI), extracting the time series of each brain region after brain\nparcellation traditionally averages across the voxels within a brain region.\nThis neglects the spatial information among the voxels and the requirement of\nextracting information for the downstream tasks. In this study, we propose to\nuse a fully connected neural network that is jointly trained with the brain\ndecoder to perform an adaptively weighted average across the voxels within each\nbrain region. We perform extensive evaluations by cognitive state decoding,\nmanifold learning, and interpretability analysis on the Human Connectome\nProject (HCP) dataset. The performance comparison of the cognitive state\ndecoding presents an accuracy increase of up to 5\\% and stable accuracy\nimprovement under different time window sizes, resampling sizes, and training\ndata sizes. The results of manifold learning show that our method presents a\nconsiderable separability among cognitive states and basically excludes\nsubject-specific information. The interpretability analysis shows that our\nmethod can identify reasonable brain regions corresponding to each cognitive\nstate. Our study would aid the improvement of the basic pipeline of fMRI\nprocessing."
    }
  ],
  [
    {
      "paper_id": "hep-ph/9706440v1",
      "title": "Large Squark-Mixing Impact on H^+ Decay in the MSSM",
      "subject": [
        "hep-ph",
        "hep-ex"
      ],
      "abstract": "We study the decays of the charged Higgs boson H^+ within the Minimal\nSupersymmetric Standard Model. We find that the supersymetric mode 'stop +\nsbottom-bar' can dominate the H^+ decays in a wide range of the model\nparameters due to the large Yukawa couplings and mixings of stop and sbottom.\nCompared to the conventional modes 'tau^+ nu' and 't b-bar', this mode has very\ndistinctive signatures. This could have a decisive impact on H^+ searches at\nfuture colliders. We find also that the QCD corrections to the 'stop +\nsbottom-bar' mode are significant, but that they do not invalidate our\ntree-level conclusion above."
    },
    {
      "paper_id": "2307.11553v1",
      "title": "Adaptively switching between a particle marginal Metropolis-Hastings and\n  a particle Gibbs kernel in SMC$^2$",
      "subject": [
        "stat.CO"
      ],
      "abstract": "Sequential Monte Carlo squared (SMC$^2$; Chopin et al., 2012) methods can be\nused to sample from the exact posterior distribution of intractable likelihood\nstate space models. These methods are the SMC analogue to particle Markov chain\nMonte Carlo (MCMC; Andrieu et al., 2010) and rely on particle MCMC kernels to\nmutate the particles at each iteration. Two options for the particle MCMC\nkernels are particle marginal Metropolis-Hastings (PMMH) and particle Gibbs\n(PG). We introduce a method to adaptively select the particle MCMC kernel at\neach iteration of SMC$^2$, with a particular focus on switching between a PMMH\nand PG kernel. The resulting method can significantly improve the efficiency of\nSMC$^2$ compared to using a fixed particle MCMC kernel throughout the\nalgorithm. Code for our methods is available at\nhttps://github.com/imkebotha/kernel_switching_smc2."
    }
  ],
  [
    {
      "paper_id": "2010.10327v1",
      "title": "Can Steering Wheel Detect Your Driving Fatigue?",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Automated Driving System (ADS) has attracted increasing attention from both\nindustrial and academic communities due to its potential for increasing the\nsafety, mobility and efficiency of existing transportation systems. The\nstate-of-the-art ADS follows the human-in-the-loop (HITL) design, where the\ndriver's anomalous behaviour is closely monitored by the system. Though many\napproaches have been proposed for detecting driver fatigue, they largely depend\non vehicle driving parameters and facial features, which lacks reliability.\nApproaches using physiological based sensors (e.g., electroencephalogram or\nelectrocardiogram) are either too clumsy to wear or impractical to install. In\nthis paper, we propose a novel driver fatigue detection method by embedding\nsurface electromyography (sEMG) sensors on a steering wheel. Compared with the\nexisting methods, our approach is able to collect bio-signals in a\nnon-intrusive way and detect driver fatigue at an earlier stage. The\nexperimental results show that our approach outperforms existing methods with\nthe weighted average F1 scores about 90%. We also propose promising future\ndirections to deploy this approach in real-life settings, such as applying\nmultimodal learning using several supplementary sensors."
    },
    {
      "paper_id": "2211.11179v1",
      "title": "Spatio-temporal point processes with deep non-stationary kernels",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Point process data are becoming ubiquitous in modern applications, such as\nsocial networks, health care, and finance. Despite the powerful expressiveness\nof the popular recurrent neural network (RNN) models for point process data,\nthey may not successfully capture sophisticated non-stationary dependencies in\nthe data due to their recurrent structures. Another popular type of deep model\nfor point process data is based on representing the influence kernel (rather\nthan the intensity function) by neural networks. We take the latter approach\nand develop a new deep non-stationary influence kernel that can model\nnon-stationary spatio-temporal point processes. The main idea is to approximate\nthe influence kernel with a novel and general low-rank decomposition, enabling\nefficient representation through deep neural networks and computational\nefficiency and better performance. We also take a new approach to maintain the\nnon-negativity constraint of the conditional intensity by introducing a\nlog-barrier penalty. We demonstrate our proposed method's good performance and\ncomputational efficiency compared with the state-of-the-art on simulated and\nreal data."
    }
  ],
  [
    {
      "paper_id": "2112.05308v2",
      "title": "Option Pricing with State-dependent Pricing Kernel",
      "subject": [
        "econ.EM"
      ],
      "abstract": "We introduce a new volatility model for option pricing that combines Markov\nswitching with the Realized GARCH framework. This leads to a novel pricing\nkernel with a state-dependent variance risk premium and a pricing formula for\nEuropean options, which is derived with an analytical approximation method. We\napply the Markov switching Realized GARCH model to S&P 500 index options from\n1990 to 2019 and find that investors' aversion to volatility-specific risk is\ntime-varying. The proposed framework outperforms competing models and reduces\n(in-sample and out-of-sample) option pricing errors by 15% or more."
    },
    {
      "paper_id": "2001.10749v1",
      "title": "Photonic Realization of a Quantum Finite Automaton",
      "subject": [
        "cs.ET"
      ],
      "abstract": "We describe a physical implementation of a quantum finite automaton\nrecognizing a well known family of periodic languages. The realization exploits\nthe polarization degree of freedom of single photons and their manipulation\nthrough linear optical elements. We use techniques of confidence amplification\nto reduce the acceptance error probability of the automaton. It is worth\nremarking that the quantum finite automaton we physically realize is not only\ninteresting per se, but it turns out to be a crucial building block in many\nquantum finite automaton design frameworks theoretically settled in the\nliterature."
    }
  ],
  [
    {
      "paper_id": "1609.00977v1",
      "title": "Modeling sRNA-regulated Plasmid Maintenance",
      "subject": [
        "q-bio.CB",
        "q-bio.MN"
      ],
      "abstract": "We study a theoretical model for the toxin-antitoxin (hok/sok) mechanism for\nplasmid maintenance in bacteria. Toxin-antitoxin systems enforce the\nmaintenance of a plasmid through post-segregational killing of cells that have\nlost the plasmid. Key to their function is the tight regulation of expression\nof a protein toxin by an sRNA antitoxin. Here, we focus on the nonlinear nature\nof the regulatory circuit dynamics of the toxin-antitoxin mechanism. The\nmechanism relies on a transient increase in protein concentration rather than\non the steady state of the genetic circuit. Through a systematic analysis of\nthe parameter dependence of this transient increase, we confirm some known\ndesign features of this system and identify new ones: for an efficient\ntoxin-antitoxin mechanism, the synthesis rate of the toxin's mRNA template\nshould be lower that of the sRNA antitoxin, the mRNA template should be more\nstable than the sRNA antitoxin, and the mRNA-sRNA complex should be more stable\nthan the sRNA antitoxin. Moreover, a short half-life of the protein toxin is\nalso beneficial to the function of the toxin-antitoxin system. In addition, we\nstudy a therapeutic scenario in which a competitor mRNA is introduced to\nsequester the sRNA antitoxin, causing the toxic protein to be expressed."
    },
    {
      "paper_id": "2310.08704v2",
      "title": "How Does Artificial Intelligence Improve Human Decision-Making? Evidence\n  from the AI-Powered Go Program",
      "subject": [
        "econ.GN"
      ],
      "abstract": "We study how humans learn from AI, leveraging an introduction of an\nAI-powered Go program (APG) that unexpectedly outperformed the best\nprofessional player. We compare the move quality of professional players to\nAPG's superior solutions around its public release. Our analysis of 749,190\nmoves demonstrates significant improvements in players' move quality,\nespecially in the early stages of the game where uncertainty is highest. This\nimprovement was accompanied by a higher alignment with AI's suggestions and a\ndecreased number and magnitude of errors. Young players show greater\nimprovement, suggesting potential inequality in learning from AI. Further,\nwhile players of all skill levels benefit, less skilled players gain higher\nmarginal benefits. These findings have implications for managers seeking to\nadopt and utilize AI in their organizations."
    }
  ],
  [
    {
      "paper_id": "1802.10117v3",
      "title": "Economic Implications of Blockchain Platforms",
      "subject": [
        "q-fin.PR"
      ],
      "abstract": "In an economy with asymmetric information, the smart contract in the\nblockchain protocol mitigates uncertainty. Since, as a new trading platform,\nthe blockchain triggers segmentation of market and differentiation of agents in\nboth the sell and buy sides of the market, it recomposes the asymmetric\ninformation and generates spreads in asset price and quality between itself and\na traditional platform. We show that marginal innovation and sophistication of\nthe smart contract have non-monotonic effects on the trading value in the\nblockchain platform, its fundamental value, the price of cryptocurrency, and\nconsumers' welfare. Moreover, a blockchain manager who controls the level of\nthe innovation of the smart contract has an incentive to keep it lower than the\nfirst best when the underlying information asymmetry is not severe, leading to\nwelfare loss for consumers."
    },
    {
      "paper_id": "2001.06348v2",
      "title": "Preservation of Equations by Monoidal Monads",
      "subject": [
        "math.CT"
      ],
      "abstract": "If a monad $T$ is monoidal, then operations on a set $X$ can be lifted\ncanonically to operations on $TX$. In this paper we study structural properties\nunder which $T$ preserves equations between those operations. It has already\nbeen shown that any monoidal monad preserves linear equations; affine monads\npreserve drop equations (where some variable appears only on one side, such as\n$x\\cdot y = y$) and relevant monads preserve dup equations (where some variable\nis duplicated, such as $x \\cdot x = x$). We start the paper by showing a\nconverse: if the monad at hand preserves a drop equation, then it must be\naffine. From this, we show that the problem whether a given (drop) equation is\npreserved is undecidable. A converse for relevance turns out to be more subtle:\npreservation of certain dup equations implies a weaker notion which we call\n$n$-relevance. Finally, we identify the subclass of equations such that their\npreservation is equivalent to relevance."
    }
  ],
  [
    {
      "paper_id": "1907.05387v1",
      "title": "An alternative for the average income estimation using small area\n  methods",
      "subject": [
        "stat.AP"
      ],
      "abstract": "The average household income is one of the most important indexes for\ndecision making and the modelling of economic inequity and poverty. In this\nwork we propose a practical procedure to estimate the average income using\nsmall area methods. We illustrate our proposal using information from a\nmultipurpose survey and suitable economic and demographic variables such as the\nmultidimensional poverty and the valorization indexes and the official\npopulation projections. We find that the standard relative errors for the\nincome average estimates improve substantially when the proposed methodology is\nimplemented."
    },
    {
      "paper_id": "2105.02567v4",
      "title": "Floer Homology: From Generalized Morse-Smale Dynamical Systems to\n  Forman's Combinatorial Vector Fields",
      "subject": [
        "math.DS",
        "math.AT",
        "math.CO",
        "math.DG"
      ],
      "abstract": "We construct a Floer type boundary operator for generalised Morse-Smale\ndynamical systems on compact smooth manifolds by counting the number of\nsuitable flow lines between closed (both homoclinic and periodic) orbits and\nisolated critical points. The same principle works for the discrete situation\nof general combinatorial vector fields, defined by Forman, on CW complexes. We\ncan thus recover the $\\mathbb{Z}_2$ homology of both smooth and discrete\nstructures directly from the flow lines (V-paths) of our vector field."
    }
  ],
  [
    {
      "paper_id": "0705.2504v1",
      "title": "Nonlinear Relaxation Dynamics in Elastic Networks and Design Principles\n  of Molecular Machines",
      "subject": [
        "cond-mat.soft",
        "physics.chem-ph"
      ],
      "abstract": "Analyzing nonlinear conformational relaxation dynamics in elastic networks\ncorresponding to two classical motor proteins, we find that they respond by\nwell-defined internal mechanical motions to various initial deformations and\nthat these motions are robust against external perturbations. We show that this\nbehavior is not characteristic for random elastic networks. However, special\nnetwork architectures with such properties can be designed by evolutionary\noptimization methods. Using them, an example of an artificial elastic network,\noperating as a cyclic machine powered by ligand binding, is constructed."
    },
    {
      "paper_id": "2302.08921v1",
      "title": "Deep Implicit Distribution Alignment Networks for Cross-Corpus Speech\n  Emotion Recognition",
      "subject": [
        "eess.AS"
      ],
      "abstract": "In this paper, we propose a novel deep transfer learning method called deep\nimplicit distribution alignment networks (DIDAN) to deal with cross-corpus\nspeech emotion recognition (SER) problem, in which the labeled training\n(source) and unlabeled testing (target) speech signals come from different\ncorpora. Specifically, DIDAN first adopts a simple deep regression network\nconsisting of a set of convolutional and fully connected layers to directly\nregress the source speech spectrums into the emotional labels such that the\nproposed DIDAN can own the emotion discriminative ability. Then, such ability\nis transferred to be also applicable to the target speech samples regardless of\ncorpus variance by resorting to a well-designed regularization term called\nimplicit distribution alignment (IDA). Unlike widely-used maximum mean\ndiscrepancy (MMD) and its variants, the proposed IDA absorbs the idea of sample\nreconstruction to implicitly align the distribution gap, which enables DIDAN to\nlearn both emotion discriminative and corpus invariant features from speech\nspectrums. To evaluate the proposed DIDAN, extensive cross-corpus SER\nexperiments on widely-used speech emotion corpora are carried out. Experimental\nresults show that the proposed DIDAN can outperform lots of recent\nstate-of-the-art methods in coping with the cross-corpus SER tasks."
    }
  ],
  [
    {
      "paper_id": "2303.08874v2",
      "title": "Bayesian Quadrature for Neural Ensemble Search",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Ensembling can improve the performance of Neural Networks, but existing\napproaches struggle when the architecture likelihood surface has dispersed,\nnarrow peaks. Furthermore, existing methods construct equally weighted\nensembles, and this is likely to be vulnerable to the failure modes of the\nweaker architectures. By viewing ensembling as approximately marginalising over\narchitectures we construct ensembles using the tools of Bayesian Quadrature --\ntools which are well suited to the exploration of likelihood surfaces with\ndispersed, narrow peaks. Additionally, the resulting ensembles consist of\narchitectures weighted commensurate with their performance. We show empirically\n-- in terms of test likelihood, accuracy, and expected calibration error --\nthat our method outperforms state-of-the-art baselines, and verify via ablation\nstudies that its components do so independently."
    },
    {
      "paper_id": "2210.16640v1",
      "title": "2D and 3D CT Radiomic Features Performance Comparison in\n  Characterization of Gastric Cancer: A Multi-center Study",
      "subject": [
        "q-bio.QM"
      ],
      "abstract": "Objective: Radiomics, an emerging tool for medical image analysis, is\npotential towards precisely characterizing gastric cancer (GC). Whether using\none-slice 2D annotation or whole-volume 3D annotation remains a long-time\ndebate, especially for heterogeneous GC. We comprehensively compared 2D and 3D\nradiomic features' representation and discrimination capacity regarding GC, via\nthree tasks.\n  Methods: Four-center 539 GC patients were retrospectively enrolled and\ndivided into the training and validation cohorts. From 2D or 3D regions of\ninterest (ROIs) annotated by radiologists, radiomic features were extracted\nrespectively. Feature selection and model construction procedures were customed\nfor each combination of two modalities (2D or 3D) and three tasks.\nSubsequently, six machine learning models (Model_2D^LNM, Model_3D^LNM;\nModel_2D^LVI, Model_3D^LVI; Model_2D^pT, Model_3D^pT) were derived and\nevaluated to reflect modalities' performances in characterizing GC.\nFurthermore, we performed an auxiliary experiment to assess modalities'\nperformances when resampling spacing is different.\n  Results: Regarding three tasks, the yielded areas under the curve (AUCs)\nwere: Model_2D^LNM's 0.712 (95% confidence interval, 0.613-0.811),\nModel_3D^LNM's 0.680 (0.584-0.775); Model_2D^LVI's 0.677 (0.595-0.761),\nModel_3D^LVI's 0.615 (0.528-0.703); Model_2D^pT's 0.840 (0.779-0.901),\nModel_3D^pT's 0.813 (0.747-0.879). Moreover, the auxiliary experiment indicated\nthat Models_2D are statistically more advantageous than Models3D with different\nresampling spacings.\n  Conclusion: Models constructed with 2D radiomic features revealed comparable\nperformances with those constructed with 3D features in characterizing GC.\n  Significance: Our work indicated that time-saving 2D annotation would be the\nbetter choice in GC, and provided a related reference to further\nradiomics-based researches."
    }
  ],
  [
    {
      "paper_id": "1707.01028v1",
      "title": "Multi-state models for evaluating conversion options in life insurance",
      "subject": [
        "q-fin.PR"
      ],
      "abstract": "In this paper we propose a multi-state model for the evaluation of the\nconversion option contract. The multi-state model is based on age-indexed\nsemi-Markov chains that are able to reproduce many important aspects that\ninfluence the valuation of the option such as the duration problem, the time\nnon-homogeneity and the ageing effect. The value of the conversion option is\nevaluated after the formal description of this contract."
    },
    {
      "paper_id": "1805.00497v1",
      "title": "Expression profiles of TRPV1, TRPV4, TLR4 and ERK1/2 in the dorsal root\n  ganglionic neurons of a cancer-induced neuropathy rat model",
      "subject": [
        "q-bio.TO"
      ],
      "abstract": "Background: The spread of tumors through neural routes is common in several\ntypes of cancer in which patients suffer from a moderate-to-severe neuropathy,\nneural damage and a distorted quality of life. Here we aim to examine the\nexpression profiles of transient receptor potential vanilloid 1 (TRPV1) and of\ntransient receptor potential vanilloid 4 (TRPV4), toll-like receptor 4 (TLR4)\nand extracellular signal-regulated kinase (ERK1/2), and to assess the possible\ntherapeutic strategies through blockade of transient receptor potential (TRP)\nchannels. Methods: Cancer was induced within the sciatic nerves of male\nCopenhagen rats, and tissues from dorsal root ganglia (DRG) were collected and\nused for measurements of immunofluorescence and Western blotting. The TRPV1\nantagonist capsazepine, the selective TRPV4 antagonist HC-067047 and the\ncalcium ions inhibitor ruthenium red were used to treat thermal and/or\nmechanical hyperalgesia. Results: Transient receptor potential vanilloid 1\nshowed a lower expression in DRGs on days 7 and 14. The expression of TRPV4,\nTLR4 and ERK1/2 showed an increase on day 3 then a decrease on days 7 and 14.\nTRPV1 and TLR4 as well as TRPV4 and ERK1/2 co-existed on the same neuronal\ncells. The neuropathic pain was reversed in dose-dependent manners by using the\nTRP antagonists and the calcium ions inhibitor. Conclusion: The decreased\nexpression of TRPV1 and TRPV4 is associated with high activation. The increased\nexpression of TLR4 and ERK1/2 reveals earlier immune response and tumor\nprogression, respectively, and their ultimate decrease is an indicator of nerve\ndamage. We studied the possible role of TRPV1 and TRPV4 in transducing\ncancer-induced hyperalgesia. The possible treatment strategies of\ncancer-induced thermal and/or mechanical hyperalgesia using capsazepine,\nHC-067047 and ruthenium red are examined."
    }
  ],
  [
    {
      "paper_id": "2408.05764v1",
      "title": "A robust baro-radar-inertial odometry m-estimator for multicopter\n  navigation in cities and forests",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Search and rescue operations require mobile robots to navigate unstructured\nindoor and outdoor environments. In particular, actively stabilized multirotor\ndrones need precise movement data to balance and avoid obstacles. Combining\nradial velocities from on-chip radar with MEMS inertial sensing has proven to\nprovide robust, lightweight, and consistent state estimation, even in visually\nor geometrically degraded environments. Statistical tests robustify these\nestimators against radar outliers. However, available work with binary outlier\nfilters lacks adaptability to various hardware setups and environments. Other\nwork has predominantly been tested in handheld static environments or\nautomotive contexts. This work introduces a robust baro-radar-inertial odometry\n(BRIO) m-estimator for quadcopter flights in typical GNSS-denied scenarios.\nExtensive real-world closed-loop flights in cities and forests demonstrate\nrobustness to moving objects and ghost targets, maintaining a consistent\nperformance with 0.5 % to 3.2 % drift per distance traveled. Benchmarks on\npublic datasets validate the system's generalizability. The code, dataset, and\nvideo are available at https://github.com/ethz-asl/rio."
    },
    {
      "paper_id": "2112.13087v2",
      "title": "A semi-bijective algorithm for saturated extended 2-regular simple\n  stacks",
      "subject": [
        "q-bio.BM"
      ],
      "abstract": "Combinatorics of biopolymer structures, especially enumeration of various RNA\nsecondary structures and protein contact maps, is of significant interest for\ncommunities of both combinatorics and computational biology. However, most of\nthe previous combinatorial enumeration results for these structures are\npresented in terms of generating functions, and few are explicit formulas. This\npaper is mainly concerned with finding explicit enumeration formulas for a\nparticular class of biologically relevant structures, say, saturated 2-regular\nsimple stacks, whose configuration is related to protein folds in the 2D\nhoneycomb lattice. We establish a semi-bijective algorithm that converts\nsaturated 2-regular simple stacks into forests of small trees, which produces a\nuniform formula for saturated extended 2-regular simple stacks with any of the\nsix primary component types. Summarizing the six different primary component\ntypes, we obtain a bivariate explicit formula for saturated extended 2-regular\nsimple stacks with $n$ vertices and $k$ arcs. As consequences, the uniform\nformula can be reduced to Clote's results on $k$-saturated 2-regular simple\nstacks and the optimal 2-regular simple stacks, and Guo et al.'s result on the\noptimal extended 2-regular simple stacks."
    }
  ],
  [
    {
      "paper_id": "2304.12447v1",
      "title": "Predicting Pulmonary Hypertension by Electrocardiograms Using Machine\n  Learning",
      "subject": [
        "eess.SP"
      ],
      "abstract": "Pulmonary hypertension (PH) is a condition of high blood pressure that\naffects the arteries in the lungs and the right side of the heart (Mayo Clinic,\n2017). A mean pulmonary artery pressure greater than 25 mmHg is defined as\nPulmonary hypertension. The estimated 5-year survival rate from the time of\ndiagnosis of pulmonary hypertension is only 57% without therapy and patients\nwith right heart failure only survive for approximately 1 year without\ntreatment (Benza et al., 2012). Given the indolent nature of the disease, early\ndetection of PH remains a challenge leading to delays in therapy.\nEchocardiography is currently used as a screening tool for diagnosing PH.\nHowever, electrocardiography (ECG), a more accessible, simple to use, and\ncost-effective tool compared to echocardiography, is less studied and explored\nfor screening at-risk patients for PH. The goal of this project is to create a\nneural network model which can process an ECG signal and detect the presence of\nPH with a confidence probability. I created a dense neural network (DNN) model\nthat has an accuracy of 98% over the available training sample. For future\nsteps, the current model will be updated with a model suited for time-series\ndata. To balance the dataset with proper training samples, I will generate\nadditional data using data augmentation techniques. Through early and accurate\ndetection of conditions such as PH, we widen the spectrum of innovation in\ndetecting chronic life-threatening health conditions and reduce associated\nmortality and morbidity."
    },
    {
      "paper_id": "2106.05240v2",
      "title": "A Century of Economic Policy Uncertainty Through the French-Canadian\n  Lens",
      "subject": [
        "econ.GN"
      ],
      "abstract": "A novel token-distance-based triple approach is proposed for identifying EPU\nmentions in textual documents. The method is applied to a corpus of\nFrench-language news to construct a century-long historical EPU index for the\nCanadian province of Quebec. The relevance of the index is shown in a\nmacroeconomic nowcasting experiment."
    }
  ],
  [
    {
      "paper_id": "2304.07851v1",
      "title": "Study on the tea market in India",
      "subject": [
        "econ.GN"
      ],
      "abstract": "India's tea business has a long history and plays a significant role in the\neconomics of the nation. India is the world's second-largest producer of tea,\nwith Assam and Darjeeling being the most well-known tea-growing regions. Since\nthe British introduced tea cultivation to India in the 1820s, the nation has\nproduced tea. Millions of people are employed in the tea sector today, and it\ncontributes significantly to the Indian economy in terms of revenue. The\nproduction of tea has changed significantly in India over the years, moving\nmore and more towards organic and sustainable practices. The industry has also\nhad to deal with difficulties like competition from other nations that produce\ntea, varying tea prices, and labor-related problems. Despite these obstacles,\nthe Indian tea business is still growing and produces a wide variety of teas,\nsuch as black tea, green tea, and chai tea. Additionally, the sector encourages\ntravel through \"tea tourism,\" which allows tourists to see how tea is made and\ndiscover its origins in India. Overall, India's tea business continues to play\na significant role in its history, culture, and economy."
    },
    {
      "paper_id": "2406.11429v1",
      "title": "Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach\n  for Zero-Shot Relation Extraction",
      "subject": [
        "cs.CL",
        "cs.AI"
      ],
      "abstract": "Predicting unseen relations that cannot be observed during the training phase\nis a challenging task in relation extraction. Previous works have made progress\nby matching the semantics between input instances and label descriptions.\nHowever, fine-grained matching often requires laborious manual annotation, and\nrich interactions between instances and label descriptions come with\nsignificant computational overhead. In this work, we propose an efficient\nmulti-grained matching approach that uses virtual entity matching to reduce\nmanual annotation cost, and fuses coarse-grained recall and fine-grained\nclassification for rich interactions with guaranteed inference speed.\nExperimental results show that our approach outperforms the previous State Of\nThe Art (SOTA) methods, and achieves a balance between inference efficiency and\nprediction accuracy in zero-shot relation extraction tasks. Our code is\navailable at https://github.com/longls777/EMMA."
    }
  ],
  [
    {
      "paper_id": "1606.03950v8",
      "title": "The real parts of the nontrivial Riemann zeta function zeros",
      "subject": [
        "math.GM"
      ],
      "abstract": "This theorem is based on holomorphy of studied functions and the fact that\nnear a singularity point the real part of some rational function can take an\narbitrary preassigned value."
    },
    {
      "paper_id": "2404.03707v1",
      "title": "Investigating the Robustness of Counterfactual Learning to Rank Models:\n  A Reproducibility Study",
      "subject": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "abstract": "Counterfactual learning to rank (CLTR) has attracted extensive attention in\nthe IR community for its ability to leverage massive logged user interaction\ndata to train ranking models. While the CLTR models can be theoretically\nunbiased when the user behavior assumption is correct and the propensity\nestimation is accurate, their effectiveness is usually empirically evaluated\nvia simulation-based experiments due to a lack of widely-available,\nlarge-scale, real click logs. However, the mainstream simulation-based\nexperiments are somewhat limited as they often feature a single, deterministic\nproduction ranker and simplified user simulation models to generate the\nsynthetic click logs. As a result, the robustness of CLTR models in complex and\ndiverse situations is largely unknown and needs further investigation.\n  To address this problem, in this paper, we aim to investigate the robustness\nof existing CLTR models in a reproducibility study with extensive\nsimulation-based experiments that (1) use both deterministic and stochastic\nproduction rankers, each with different ranking performance, and (2) leverage\nmultiple user simulation models with different user behavior assumptions. We\nfind that the DLA models and IPS-DCM show better robustness under various\nsimulation settings than IPS-PBM and PRS with offline propensity estimation.\nBesides, the existing CLTR models often fail to outperform the naive click\nbaselines when the production ranker has relatively high ranking performance or\ncertain randomness, which suggests an urgent need for developing new CLTR\nalgorithms that work for these settings."
    }
  ],
  [
    {
      "paper_id": "2402.16375v1",
      "title": "Valuing insurance against small probability risks: A meta-analysis",
      "subject": [
        "q-fin.RM"
      ],
      "abstract": "The demand for voluntary insurance against low-probability, high-impact risks\nis lower than expected. To assess the magnitude of the demand, we conduct a\nmeta-analysis of contingent valuation studies using a dataset of experimentally\nelicited and survey-based estimates. We find that the average stated\nwillingness to pay (WTP) for insurance is 87% of expected losses. We perform a\nmeta-regression analysis to examine the heterogeneity in aggregate WTP across\nthese studies. The meta-regression reveals that information about loss\nprobability and probability levels positively influence relative willingness to\npay, whereas respondents' average income and age have a negative effect.\nMoreover, we identify cultural sub-factors, such as power distance and\nuncertainty avoidance, that provided additional explanations for differences in\nWTP across international samples. Methodological factors related to the\nsampling and data collection process significantly influence the stated WTP.\nOur results, robust to model specification and publication bias, are relevant\nto current debates on stated preferences for low-probability risks management."
    },
    {
      "paper_id": "2302.10521v1",
      "title": "Cognitive characteristics of intellectually gifted children with a\n  diagnosis of ADHD",
      "subject": [
        "math.HO"
      ],
      "abstract": "Some children may be intellectually gifted, and yet experience behavioral and\nacademic difficulties. We examined 82 twice exceptional children (2eADHD),\nhaving an excellent General Ability Index (GAI) derived from the Wechsler\nIntelligence Scale for Children-IV (GAI >= 125), and a diagnosis of Attention\nDeficit and Hyperactivity Disorder (ADHD). They accounted for 8.8% of a large\nsample of children with ADHD, which is twice as high as the proportion of\nintellectually gifted children in a typical population. This\nover-representation does not reflect a misdiagnosis of ADHD, as these children\nshowed the typical features predicted on the grounds of data regarding the ADHD\nsample, including lower scores in working memory and processing speed measures,\ncombined with the inclusion criteria for giftedness. Based on information\nconcerning intellectually gifted children with either a Specific Learning\nDisorder (SLD) or typical development, we observed that these characteristics\nof intelligence are similar to those seen in SLD, but not in typical\ndevelopment, irrespective of whether 2e-ADHD children had a comorbid SLD."
    }
  ],
  [
    {
      "paper_id": "2402.05573v1",
      "title": "Research on the evolution of domestic multi-functional meter technology",
      "subject": [
        "cs.OH"
      ],
      "abstract": "The technical evolution of domestic multi-functional electricity meter is\ndeeply discussed. With the rapid development of the domestic power market and\nthe continuous innovation of technology, the domestic multi-functional\nelectricity meters have experienced the transformation from simple billing to\ncomplex multi-functional, from a single application to a wide range of fields.\nThis transformation has not only driven the rapid development of electricity\nmeter technology, but also met the increasing power demand and management\nrequirements. This paper expounds the concept of multi-function meter, the\nworking principle and algorithm of digital multiplier, the initiation and\nevolution of multi-function electricity meter standard, and the initiation and\nevolution of domestic multi-function electricity meter products. Although the\ndomestic independent production of multi-functional meter has made great\nachievements in performance, but in the reliability and key process technology\nstill need to be improved. In addition, the development of communication\ntechnology also provides a new opportunity for the progress of electricity\nmeter technology. The application of the new technology provides a more\nconvenient and efficient way for the data transmission and remote management of\nelectricity meters. Domestic multi-functional electricity meters have made\nremarkable achievements in technology evolution and application and expansion,\nbut they still face some challenges and opportunities. In the future, with the\ncontinuous development of the power market and the promotion of smart grid\nconstruction, domestic multi-functional electricity meters need to continue to\nstrengthen technological innovation and product research and development,\nimprove the reliability and competitiveness of products, in order to meet\nhigher application needs and market requirements."
    },
    {
      "paper_id": "1408.4221v2",
      "title": "Evolution of regulatory networks towards adaptability and stability in a\n  changing environment",
      "subject": [
        "q-bio.MN",
        "q-bio.PE"
      ],
      "abstract": "Diverse biological networks exhibit universal features distinguished from\nthose of random networks, calling much attention to their origins and\nimplications. Here we propose a minimal evolution model of Boolean regulatory\nnetworks, which evolve by selectively rewiring links towards enhancing\nadaptability to a changing environment and stability against dynamical\nperturbations. We find that sparse and heterogeneous connectivity patterns\nemerge, which show qualitative agreement with real transcriptional regulatory\nnetworks and metabolic networks. The characteristic scaling behavior of\nstability reflects the balance between robustness and flexibility. The scaling\nof fluctuation in the perturbation spread shows a dynamic crossover, which is\nanalyzed by investigating separately the stochasticity of internal dynamics and\nthe network structures different depending on the evolution pathways. Our study\ndelineates how the ambivalent pressure of evolution shapes biological networks,\nwhich can be helpful for studying general complex systems interacting with\nenvironments."
    }
  ],
  [
    {
      "paper_id": "1801.06423v1",
      "title": "Minimum spanning tree release under differential privacy constraints",
      "subject": [
        "stat.ML",
        "stat.TH"
      ],
      "abstract": "We investigate the problem of nodes clustering under privacy constraints when\nrepresenting a dataset as a graph. Our contribution is threefold. First we\nformally define the concept of differential privacy for structured databases\nsuch as graphs, and give an alternative definition based on a new neighborhood\nnotion between graphs. This definition is adapted to particular frameworks that\ncan be met in various application fields such as genomics, world wide web,\npopulation survey, etc. Second, we introduce a new algorithm to tackle the\nissue of privately releasing an approximated minimum spanning tree topology for\na simple-undirected-weighted graph. It provides a simple way of producing the\ntopology of a private almost minimum spanning tree which outperforms, in most\ncases, the state of the art \"Laplace mechanism\" in terms of\nweight-approximation error.\n  Finally, we propose a theoretically motivated method combining a sanitizing\nmechanism (such as Laplace or our new algorithm) with a Minimum Spanning Tree\n(MST)-based clustering algorithm. It provides an accurate method for nodes\nclustering in a graph while keeping the sensitive information contained in the\nedges weights of the private graph. We provide some theoretical results on the\nrobustness of an almost minimum spanning tree construction for Laplace\nsanitizing mechanisms. These results exhibit which conditions the graph weights\nshould respect in order to consider that the nodes form well separated clusters\nboth for Laplace and our algorithm as sanitizing mechanism. The method has been\nexperimentally evaluated on simulated data, and preliminary results show the\ngood behavior of the algorithm while identifying well separated clusters."
    },
    {
      "paper_id": "1701.05008v2",
      "title": "Secret Key Agreement under Discussion Rate Constraints",
      "subject": [
        "cs.IT"
      ],
      "abstract": "For the multiterminal secret key agreement problem, new single-letter lower\nbounds are obtained on the public discussion rate required to achieve any given\nsecret key rate below the secrecy capacity. The results apply to general source\nmodel without helpers or wiretapper's side information but can be strengthened\nfor hypergraphical sources. In particular, for the pairwise independent\nnetwork, the results give rise to a complete characterization of the maximum\nsecret key rate achievable under a constraint on the total discussion rate."
    }
  ],
  [
    {
      "paper_id": "1410.6097v2",
      "title": "Freeness of automata groups vs boundary dynamics",
      "subject": [
        "cs.FL"
      ],
      "abstract": "We prove that the boundary dynamics of the (semi)group generated by the\nenriched dual transducer characterizes the algebraic property of being free for\nan automaton group. We specialize this result to the class of bireversible\ntransducers and we show that the property of being not free is equivalent to\nhave a finite Schreier graph in the boundary of the enriched dual pointed on\nsome essentially non-trivial point. From these results we derive some\nconsequences from the dynamical, algorithmic and algebraic point of view. In\nthe last part of the paper we address the problem of finding examples of\nnon-bireversible transducers defining free groups, we show examples of\ntransducers with sink accessible from every state which generate free groups,\nand, in general, we link this problem to the nonexistence of certain words with\ninteresting combinatorial and geometrical properties."
    },
    {
      "paper_id": "2201.03213v1",
      "title": "New volatility evolution model after extreme events",
      "subject": [
        "q-fin.ST",
        "q-fin.CP"
      ],
      "abstract": "In this paper, we propose a new dynamical model to study the two-stage\nvolatility evolution of stock market index after extreme events, and find that\nthe volatility after extreme events follows a stretched exponential decay in\nthe initial stage and becomes a power law decay at later times by using high\nfrequency minute data. Empirical study of the evolutionary behaviors of\nvolatility after endogenous and exogenous events further demonstrates the\ndescriptive power of our new model. To further explore the underlying\nmechanisms of volatility evolution, we introduce the sequential arrival of\ninformation hypothesis (SAIH) and the mixture of distribution hypothesis (MDH)\nto test the two-stage assumption, and find that investors transform from the\nuninformed state to the informed state in the first stage and informed\ninvestors subsequently dominate in the second stage. The testing results offer\na supporting explanation for the validity of our new model and the fitted\nvalues of relevant parameters."
    }
  ],
  [
    {
      "paper_id": "2108.03690v1",
      "title": "Enhanced Invertible Encoding for Learned Image Compression",
      "subject": [
        "eess.IV"
      ],
      "abstract": "Although deep learning based image compression methods have achieved\npromising progress these days, the performance of these methods still cannot\nmatch the latest compression standard Versatile Video Coding (VVC). Most of the\nrecent developments focus on designing a more accurate and flexible entropy\nmodel that can better parameterize the distributions of the latent features.\nHowever, few efforts are devoted to structuring a better transformation between\nthe image space and the latent feature space. In this paper, instead of\nemploying previous autoencoder style networks to build this transformation, we\npropose an enhanced Invertible Encoding Network with invertible neural networks\n(INNs) to largely mitigate the information loss problem for better compression.\nExperimental results on the Kodak, CLIC, and Tecnick datasets show that our\nmethod outperforms the existing learned image compression methods and\ncompression standards, including VVC (VTM 12.1), especially for high-resolution\nimages. Our source code is available at https://github.com/xyq7/InvCompress."
    },
    {
      "paper_id": "2203.05595v1",
      "title": "Social Networks and Spatial Mobility: Evidence from Facebook in India",
      "subject": [
        "econ.GN"
      ],
      "abstract": "This paper studies the role of social networks in spatial mobility across\nIndia. Using aggregated and de-identified data from the world's largest online\nsocial network, we (i) document new descriptive findings on the structure of\nsocial networks and spatial mobility in India; (ii) quantify the effects of\nsocial networks on annual migration choice; and (iii) embed these estimates in\na spatial equilibrium model to study the wage implications of increasing social\nconnectedness. Across millions of individuals, we find that multiple measures\nof social capital are concentrated among the rich and educated and among\nmigrants. Across destinations, both mobility patterns and social networks are\nconcentrated toward richer areas. A model of migration suggests individuals are\nindifferent between a 10% increase in destination wages and a 12-16% increase\nin destination social networks. Accounting for networks reduces the\nmigration-distance relationship by 19%. In equilibrium, equalizing social\nnetworks across locations improves average wages by 3% (24% for the bottom\nwage-quartile), a larger impact than removing the marginal cost of distance. We\nfind evidence of an economic support mechanism, with destination economic\nimprovements reducing the migration-network elasticity. We also find suggestive\nevidence for an emotional support mechanism from qualitative surveys among\nFacebook users. Difference-in-difference estimates suggest college attendance\ndelivers a 20% increase in network size and diversity. Taken together, our data\nsuggest that - by reducing effective moving costs - increasing social\nconnectedness across space may have considerable economic gains."
    }
  ],
  [
    {
      "paper_id": "2003.07860v1",
      "title": "NISE Estimation of an Economic Model of Crime",
      "subject": [
        "econ.GN"
      ],
      "abstract": "An economic model of crime is used to explore the consistent estimation of a\nsimultaneous linear equation without recourse to instrumental variables. A\nmaximum-likelihood procedure (NISE) is introduced, and its results are compared\nto ordinary least squares and two-stage least squares. The paper is motivated\nby previous research on the crime model and by the well-known practical problem\nthat valid instruments are frequently unavailable."
    },
    {
      "paper_id": "1907.06637v1",
      "title": "The Bach Doodle: Approachable music composition with machine learning at\n  scale",
      "subject": [
        "eess.AS"
      ],
      "abstract": "To make music composition more approachable, we designed the first AI-powered\nGoogle Doodle, the Bach Doodle, where users can create their own melody and\nhave it harmonized by a machine learning model Coconet (Huang et al., 2017) in\nthe style of Bach. For users to input melodies, we designed a simplified\nsheet-music based interface. To support an interactive experience at scale, we\nre-implemented Coconet in TensorFlow.js (Smilkov et al., 2019) to run in the\nbrowser and reduced its runtime from 40s to 2s by adopting dilated depth-wise\nseparable convolutions and fusing operations. We also reduced the model\ndownload size to approximately 400KB through post-training weight quantization.\nWe calibrated a speed test based on partial model evaluation time to determine\nif the harmonization request should be performed locally or sent to remote TPU\nservers. In three days, people spent 350 years worth of time playing with the\nBach Doodle, and Coconet received more than 55 million queries. Users could\nchoose to rate their compositions and contribute them to a public dataset,\nwhich we are releasing with this paper. We hope that the community finds this\ndataset useful for applications ranging from ethnomusicological studies, to\nmusic education, to improving machine learning models."
    }
  ],
  [
    {
      "paper_id": "1010.2826v1",
      "title": "Tau Be or not Tau Be? - A Perspective on Service Compatibility and\n  Substitutability",
      "subject": [
        "cs.SE",
        "cs.LO"
      ],
      "abstract": "One of the main open research issues in Service Oriented Computing is to\npropose automated techniques to analyse service interfaces. A first problem,\ncalled compatibility, aims at determining whether a set of services (two in\nthis paper) can be composed together and interact with each other as expected.\nAnother related problem is to check the substitutability of one service with\nanother. These problems are especially difficult when behavioural descriptions\n(i.e., message calls and their ordering) are taken into account in service\ninterfaces. Interfaces should capture as faithfully as possible the service\nbehaviour to make their automated analysis possible while not exhibiting\nimplementation details. In this position paper, we choose Labelled Transition\nSystems to specify the behavioural part of service interfaces. In particular,\nwe show that internal behaviours (tau transitions) are necessary in these\ntransition systems in order to detect subtle errors that may occur when\ncomposing a set of services together. We also show that tau transitions should\nbe handled differently in the compatibility and substitutability problem: the\nformer problem requires to check if the compatibility is preserved every time a\ntau transition is traversed in one interface, whereas the latter requires a\nprecise analysis of tau branchings in order to make the substitution preserve\nthe properties (e.g., a compatibility notion) which were ensured before\nreplacement."
    },
    {
      "paper_id": "2301.02954v1",
      "title": "A New Noncoherent Gaussian Signaling Scheme for Low Probability of\n  Detection Communications",
      "subject": [
        "eess.SP"
      ],
      "abstract": "We propose a novel, Gaussian signaling mechanism for low probability of\ndetection (LPD) communication systems with either single or multiple antennas.\nThe new scheme is designed to allow the noncoherent detection of\nGaussian-distributed signals, enabling LPD communications using signals that\nfollow the complex Gaussian distribution in the time and frequency domains. It\nis demonstrated via simulations that the proposed scheme achieves better\nperformance than a comparable conventional scheme over the entire SNR region,\nwith the advantage becoming more significant in scenarios with lower overhead."
    }
  ],
  [
    {
      "paper_id": "2010.15966v1",
      "title": "Machine Learning for Experimental Design: Methods for Improved Blocking",
      "subject": [
        "econ.EM"
      ],
      "abstract": "Restricting randomization in the design of experiments (e.g., using\nblocking/stratification, pair-wise matching, or rerandomization) can improve\nthe treatment-control balance on important covariates and therefore improve the\nestimation of the treatment effect, particularly for small- and medium-sized\nexperiments. Existing guidance on how to identify these variables and implement\nthe restrictions is incomplete and conflicting. We identify that differences\nare mainly due to the fact that what is important in the pre-treatment data may\nnot translate to the post-treatment data. We highlight settings where there is\nsufficient data to provide clear guidance and outline improved methods to\nmostly automate the process using modern machine learning (ML) techniques. We\nshow in simulations using real-world data, that these methods reduce both the\nmean squared error of the estimate (14%-34%) and the size of the standard error\n(6%-16%)."
    },
    {
      "paper_id": "2208.11847v1",
      "title": "CNN-based Prediction of Network Robustness With Missing Edges",
      "subject": [
        "cs.LG",
        "cs.SY"
      ],
      "abstract": "Connectivity and controllability of a complex network are two important\nissues that guarantee a networked system to function. Robustness of\nconnectivity and controllability guarantees the system to function properly and\nstably under various malicious attacks. Evaluating network robustness using\nattack simulations is time consuming, while the convolutional neural network\n(CNN)-based prediction approach provides a cost-efficient method to approximate\nthe network robustness. In this paper, we investigate the performance of\nCNN-based approaches for connectivity and controllability robustness\nprediction, when partial network information is missing, namely the adjacency\nmatrix is incomplete. Extensive experimental studies are carried out. A\nthreshold is explored that if a total amount of more than 7.29\\% information is\nlost, the performance of CNN-based prediction will be significantly degenerated\nfor all cases in the experiments. Two scenarios of missing edge representations\nare compared, 1) a missing edge is marked `no edge' in the input for\nprediction, and 2) a missing edge is denoted using a special marker of\n`unknown'. Experimental results reveal that the first representation is\nmisleading to the CNN-based predictors."
    }
  ],
  [
    {
      "paper_id": "2311.18301v2",
      "title": "Rainbow common graphs must be forests",
      "subject": [
        "math.CO"
      ],
      "abstract": "We study the rainbow version of the graph commonness property: a graph $H$ is\n$r$-rainbow common if the number of rainbow copies of $H$ (where all edges have\ndistinct colors) in an $r$-coloring of edges of $K_n$ is maximized\nasymptotically by independently coloring each edge uniformly at random. $H$ is\n\\emph{$r$-rainbow uncommon} otherwise. We show that if $H$ has a cycle, then it\nis $r$-rainbow uncommon for every $r$ at least the number of edges of $H$. This\ngeneralizes a result of Erd\\H{o}s and Hajnal, and proves a conjecture of De\nSilva, Si, Tait, Tun\\c{c}bilek, Yang, and Young."
    },
    {
      "paper_id": "2102.04296v3",
      "title": "Data-driven design of targeted gene panels for estimating immunotherapy\n  biomarkers",
      "subject": [
        "stat.AP"
      ],
      "abstract": "We introduce a novel data-driven framework for the design of targeted gene\npanels for estimating exome-wide biomarkers in cancer immunotherapy. Our first\ngoal is to develop a generative model for the profile of mutation across the\nexome, which allows for gene- and variant type-dependent mutation rates. Based\non this model, we then propose a new procedure for estimating biomarkers such\nas tumour mutation burden and tumour indel nurden. Our approach allows the\npractitioner to select a targeted gene panel of a prespecified size, and then\nconstruct an estimator that only depends on the selected genes. Alternatively,\nthe practitioner may apply our method to make predictions based on an existing\ngene panel, or to augment a gene panel to a given size. We demonstrate the\nexcellent performance of our proposal using data from three non-small cell lung\ncancer studies, as well as data from six other cancer types."
    }
  ],
  [
    {
      "paper_id": "2412.17822v1",
      "title": "Emergent poverty traps and inequality at multiple levels impedes social\n  mobility",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Eradicating extreme poverty and inequality are the key leverage points to\nachieve the seventeen Sustainable Development goals. Yet, the reduction in\nextreme poverty and inequality are vulnerable to shocks such as the pandemic\nand climate change. We find that that these vulnerabilities emerge from the\ninteraction between individual and institutional mechanisms. Individual\ncharacteristics like risk aversion, attention, and saving propensity can lead\nto sub-optimal diversification and low capital accumulation. These individual\ndrivers are reinforced by institutional mechanisms such as lack of financial\ninclusion, access to technology, and economic segregation, leading to\npersistent inequality and poverty traps. Our experiments demonstrate that\naddressing above factors yields 'double dividend' - reducing poverty and\ninequality within-and-between communities and create positive feedback that can\nwithstand shocks."
    },
    {
      "paper_id": "2204.11425v2",
      "title": "BCI: Breast Cancer Immunohistochemical Image Generation through Pyramid\n  Pix2pix",
      "subject": [
        "eess.IV"
      ],
      "abstract": "The evaluation of human epidermal growth factor receptor 2 (HER2) expression\nis essential to formulate a precise treatment for breast cancer. The routine\nevaluation of HER2 is conducted with immunohistochemical techniques (IHC),\nwhich is very expensive. Therefore, for the first time, we propose a breast\ncancer immunohistochemical (BCI) benchmark attempting to synthesize IHC data\ndirectly with the paired hematoxylin and eosin (HE) stained images. The dataset\ncontains 4870 registered image pairs, covering a variety of HER2 expression\nlevels. Based on BCI, as a minor contribution, we further build a pyramid\npix2pix image generation method, which achieves better HE to IHC translation\nresults than the other current popular algorithms. Extensive experiments\ndemonstrate that BCI poses new challenges to the existing image translation\nresearch. Besides, BCI also opens the door for future pathology studies in HER2\nexpression evaluation based on the synthesized IHC images. BCI dataset can be\ndownloaded from https://bupt-ai-cz.github.io/BCI."
    }
  ],
  [
    {
      "paper_id": "1307.0781v1",
      "title": "Distributed Online Big Data Classification Using Context Information",
      "subject": [
        "stat.ML"
      ],
      "abstract": "Distributed, online data mining systems have emerged as a result of\napplications requiring analysis of large amounts of correlated and\nhigh-dimensional data produced by multiple distributed data sources. We propose\na distributed online data classification framework where data is gathered by\ndistributed data sources and processed by a heterogeneous set of distributed\nlearners which learn online, at run-time, how to classify the different data\nstreams either by using their locally available classification functions or by\nhelping each other by classifying each other's data. Importantly, since the\ndata is gathered at different locations, sending the data to another learner to\nprocess incurs additional costs such as delays, and hence this will be only\nbeneficial if the benefits obtained from a better classification will exceed\nthe costs. We model the problem of joint classification by the distributed and\nheterogeneous learners from multiple data sources as a distributed contextual\nbandit problem where each data is characterized by a specific context. We\ndevelop a distributed online learning algorithm for which we can prove\nsublinear regret. Compared to prior work in distributed online data mining, our\nwork is the first to provide analytic regret results characterizing the\nperformance of the proposed algorithm."
    },
    {
      "paper_id": "1811.10274v1",
      "title": "Sound Approximation of Programs with Elementary Functions",
      "subject": [
        "cs.MS",
        "cs.PL"
      ],
      "abstract": "Elementary function calls are a common feature in numerical programs. While\ntheir implementions in library functions are highly optimized, their\ncomputation is nonetheless very expensive compared to plain arithmetic. Full\naccuracy is, however, not always needed. Unlike arithmetic, where the\nperformance difference between for example single and double precision\nfloating-point arithmetic is relatively small, elementary function calls\nprovide a much richer tradeoff space between accuracy and efficiency.\nNavigating this space is challenging. First, generating approximations of\nelementary function calls which are guaranteed to satisfy accuracy error bounds\nis highly nontrivial. Second, the performance of such approximations generally\ndepends on several parameters which are unintuitive to choose manually,\nespecially for non-experts.\n  We present a fully automated approach and tool which approximates elementary\nfunction calls inside small programs while guaranteeing overall user provided\nerror bounds. Our tool leverages existing techniques for roundoff error\ncomputation and approximation of individual elementary function calls, and\nprovides automated selection of many parameters. Our experiments show that\nsignificant efficiency improvements are possible in exchange for reduced, but\nguaranteed, accuracy."
    }
  ],
  [
    {
      "paper_id": "2410.08061v3",
      "title": "A study of nil Hecke algebras via Hopf algebroids",
      "subject": [
        "math.RT",
        "math.CO",
        "math.QA",
        "math.RA"
      ],
      "abstract": "Hopf algebroids are generalizations of Hopf algebras to less commutative\nsettings. We show how the comultiplication defined by Kostant and Kumar turns\nthe affine nil Hecke algebra associated to a Coxeter system into a Hopf\nalgebroid without an antipode. The proof relies on mixed dihedral braid\nrelations between Demazure operators and simple reflections. For researchers\nnew to Hopf algebroids we include additional examples from ring theory,\nrepresentation theory, and algebraic geometry."
    },
    {
      "paper_id": "1905.01644v1",
      "title": "Testable Properties in General Graphs and Random Order Streaming",
      "subject": [
        "cs.DS"
      ],
      "abstract": "We present a novel framework closely linking the areas of property testing\nand data streaming algorithms in the setting of general graphs. It has been\nrecently shown (Monemizadeh et al. 2017) that for bounded-degree graphs, any\nconstant-query tester can be emulated in the random order streaming model by a\nstreaming algorithm that uses only space required to store a constant number of\nwords. However, in a more natural setting of general graphs, with no\nrestriction on the maximum degree, no such results were known because of our\nlack of understanding of constant-query testers in general graphs and lack of\ntechniques to appropriately emulate in the streaming setting off-line\nalgorithms allowing many high-degree vertices.\n  In this work we advance our understanding on both of these challenges. First,\nwe provide canonical testers for all constant-query testers for general graphs,\nboth, for one-sided and two-sided errors. Such canonizations were only known\nbefore (in the adjacency matrix model) for dense graphs (Goldreich and Trevisan\n2003) and (in the adjacency list model) for bounded degree (di-)graphs\n(Goldreich and Ron 2011, Czumaj et al. 2016). Using the concept of canonical\ntesters, we then prove that every property of general graphs that is\nconstant-query testable with one-sided error can also be tested in\nconstant-space with one-sided error in the random order streaming model.\n  Our results imply, among others, that properties like $(s,t)$\ndisconnectivity, $k$-path-freeness, etc. are constant-space testable in random\norder streams."
    }
  ],
  [
    {
      "paper_id": "2003.09300v1",
      "title": "Graham's Formula for Valuing Growth Stocks",
      "subject": [
        "q-fin.TR",
        "q-fin.RM"
      ],
      "abstract": "Benjamin Graham introduced a very simple formula for valuing a growth stock\nin 1962. How does it work and why? What is a sensible way to calculate this\nacross many stocks and provide a scoring system to compare stocks amongst each\nother? We are presenting a methodology here which is put into practice."
    },
    {
      "paper_id": "2411.01710v1",
      "title": "SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation",
      "subject": [
        "cs.CL",
        "cs.SD"
      ],
      "abstract": "Spurred by the demand for interpretable models, research on eXplainable AI\nfor language technologies has experienced significant growth, with feature\nattribution methods emerging as a cornerstone of this progress. While prior\nwork in NLP explored such methods for classification tasks and textual\napplications, explainability intersecting generation and speech is lagging,\nwith existing techniques failing to account for the autoregressive nature of\nstate-of-the-art models and to provide fine-grained, phonetically meaningful\nexplanations. We address this gap by introducing Spectrogram Perturbation for\nExplainable Speech-to-text Generation (SPES), a feature attribution technique\napplicable to sequence generation tasks with autoregressive models. SPES\nprovides explanations for each predicted token based on both the input\nspectrogram and the previously generated tokens. Extensive evaluation on speech\nrecognition and translation demonstrates that SPES generates explanations that\nare faithful and plausible to humans."
    }
  ],
  [
    {
      "paper_id": "2305.03818v3",
      "title": "The Generalized Makeev Problem Revisited",
      "subject": [
        "math.CO",
        "math.MG"
      ],
      "abstract": "Based on a result of Makeev, in 2012 Blagojevi\\'c and Karasev proposed the\nfollowing problem: given any positive integers $m$ and $1\\leq \\ell\\leq k$, find\nthe minimum dimension $d=\\Delta(m;\\ell/k)$ such that for any $m$ mass\ndistributions on $\\mathbb{R}^d$, there exist $k$ hyperplanes, any $\\ell$ of\nwhich equipartition each mass. The $\\ell=k$ case is a central question in\ngeometric and topological combinatorics which remains open except for few\nvalues of $m$ and $k$. For $\\ell< k$ and arbitrary $m$, we establish new upper\nbounds on $\\Delta(m;\\ell/k)$ when (1) $\\ell=2$ and $k$ is arbitrary and (2)\n$\\ell=3$ and $k=4$. When $\\ell=k-1$ and $m+1$ is a power of two these bounds\nare nearly optimal and are exponentially smaller than the current best upper\nbounds when $\\ell=k$. Similar remarks apply to our upper bounds when the\nhyperplanes are prescribed to be pairwise orthogonal. Lastly, we provide\ntransversal extensions of our results along the lines recently established by\nFrick et al.: given $m$ families of compact convex sets in $\\mathbb{R}^d$ such\nthat no $2^\\ell$ members of any family are pairwise disjoint, we show that\nevery member of each family is pierced by the union of any $\\ell$ of some\ncollection of $k$ hyperplanes."
    },
    {
      "paper_id": "2305.14131v2",
      "title": "Temporally Causal Discovery Tests for Discrete Time Series and Neural\n  Spike Trains",
      "subject": [
        "q-bio.NC"
      ],
      "abstract": "We consider the problem of detecting causal relationships between discrete\ntime series, in the presence of potential confounders. A hypothesis test is\nintroduced for identifying the temporally causal influence of $(x_n)$ on\n$(y_n)$, causally conditioned on a possibly confounding third time series\n$(z_n)$. Under natural Markovian modeling assumptions, it is shown that the\nnull hypothesis, corresponding to the absence of temporally causal influence,\nis equivalent to the underlying `causal conditional directed information rate'\nbeing equal to zero. The plug-in estimator for this functional is identified\nwith the log-likelihood ratio test statistic for the desired test. This\nstatistic is shown to be asymptotically normal under the alternative hypothesis\nand asymptotically $\\chi^2$ distributed under the null, facilitating the\ncomputation of $p$-values when used on empirical data. The effectiveness of the\nresulting hypothesis test is illustrated on simulated data, validating the\nunderlying theory. The test is also employed in the analysis of spike train\ndata recorded from neurons in the V4 and FEF brain regions of behaving animals\nduring a visual attention task. There, the test results are seen to identify\ninteresting and biologically relevant information."
    }
  ],
  [
    {
      "paper_id": "1807.05786v4",
      "title": "MIDV-500: A Dataset for Identity Documents Analysis and Recognition on\n  Mobile Devices in Video Stream",
      "subject": [
        "cs.CV",
        "cs.DL"
      ],
      "abstract": "A lot of research has been devoted to identity documents analysis and\nrecognition on mobile devices. However, no publicly available datasets designed\nfor this particular problem currently exist. There are a few datasets which are\nuseful for associated subtasks but in order to facilitate a more comprehensive\nscientific and technical approach to identity document recognition more\nspecialized datasets are required. In this paper we present a Mobile Identity\nDocument Video dataset (MIDV-500) consisting of 500 video clips for 50\ndifferent identity document types with ground truth which allows to perform\nresearch in a wide scope of document analysis problems. The paper presents\ncharacteristics of the dataset and evaluation results for existing methods of\nface detection, text line recognition, and document fields data extraction.\nSince an important feature of identity documents is their sensitiveness as they\ncontain personal data, all source document images used in MIDV-500 are either\nin public domain or distributed under public copyright licenses.\n  The main goal of this paper is to present a dataset. However, in addition and\nas a baseline, we present evaluation results for existing methods for face\ndetection, text line recognition, and document data extraction, using the\npresented dataset.\n  (The dataset is available for download at ftp://smartengines.com/midv-500/.)"
    },
    {
      "paper_id": "2111.14281v1",
      "title": "Passive Indoor Localization with WiFi Fingerprints",
      "subject": [
        "eess.SP"
      ],
      "abstract": "This paper proposes passive WiFi indoor localization. Instead of using WiFi\nsignals received by mobile devices as fingerprints, we use signals received by\nrouters to locate the mobile carrier. Consequently, software installation on\nthe mobile device is not required. To resolve the data insufficiency problem,\nflow control signals such as request to send (RTS) and clear to send (CTS) are\nutilized. In our model, received signal strength indicator (RSSI) and channel\nstate information (CSI) are used as fingerprints for several algorithms,\nincluding deterministic, probabilistic and neural networks localization\nalgorithms. We further investigated localization algorithms performance through\nextensive on-site experiments with various models of phones at hundreds of\ntesting locations. We demonstrate that our passive scheme achieves an average\nlocalization error of 0.8 m when the phone is actively transmitting data frames\nand 1.5 m when it is not transmitting data frames."
    }
  ],
  [
    {
      "paper_id": "2407.13220v3",
      "title": "MEDIC: Zero-shot Music Editing with Disentangled Inversion Control",
      "subject": [
        "eess.AS"
      ],
      "abstract": "Text-guided diffusion models make a paradigm shift in audio generation,\nfacilitating the adaptability of source audio to conform to specific textual\nprompts. Recent works introduce inversion techniques, like DDIM inversion, to\nzero-shot editing, exploiting pretrained diffusion models for audio\nmodification. Nonetheless, our investigation exposes that DDIM inversion\nsuffers from an accumulation of errors across each diffusion step, undermining\nits efficacy. Moreover, existing editing methods fail to achieve effective\ncomplex non-rigid music editing while maintaining essential content\npreservation and high editing fidelity. To counteract these issues, we\nintroduce the Disentangled Inversion technique to disentangle the diffusion\nprocess into triple branches, rectifying the deviated path of the source branch\ncaused by DDIM inversion. In addition, we propose the Harmonized Attention\nControl framework, which unifies the mutual self-attention control and\ncross-attention control with an intermediate Harmonic Branch to progressively\nachieve the desired harmonic and melodic information in the target music.\nCollectively, these innovations comprise the Disentangled Inversion Control\n(DIC) framework, enabling accurate music editing while safeguarding content\nintegrity. To benchmark audio editing efficacy, we introduce ZoME-Bench, a\ncomprehensive music editing benchmark hosting 1,100 samples spread across ten\ndistinct editing categories. This facilitates both zero-shot and\ninstruction-based music editing tasks. Our method achieves unparalleled\nperformance in edit fidelity and essential content preservation, outperforming\ncontemporary state-of-the-art inversion techniques."
    },
    {
      "paper_id": "2502.01640v1",
      "title": "Study on the impact of trade policy uncertainty on the performance of\n  enterprise ESG performance",
      "subject": [
        "econ.GN"
      ],
      "abstract": "Trade policy uncertainty has become a significant feature of today's global\neconomy. While its impact on free trade is evident, its microeconomic effects\nremain open to debate. This study explores the influence of trade policy\nuncertainty on corporate ESG performance and its underlying mechanisms, using\ndata from A-share listed companies in China from 2010 to 2020. The findings\nreveal that increased trade policy uncertainty significantly and robustly\nenhances corporate ESG performance. Heterogeneity analysis indicates that\nhigh-tech enterprises are better equipped to improve their ESG performance in\nresponse to trade policy uncertainty. Furthermore, strengthening internal\ncontrols and appointing CEOs with environmental backgrounds also help firms\nseize the opportunities arising from trade policy uncertainty. In terms of\nmechanisms, trade policy uncertainty intensifies industry competition,\ncompelling firms to enhance their ESG performance to gain market share.\nAdditionally, it stimulates green technological innovation, further optimizing\nESG outcomes. Therefore, efforts should focus on improving the ESG standards\nsystem, establishing ESG incentive policies, increasing the transparency and\npredictability of trade policies, and promoting corporate green development to\nadvance national sustainable development goals."
    }
  ],
  [
    {
      "paper_id": "2407.07395v1",
      "title": "Standard compliant video coding using low complexity, switchable neural\n  wrappers",
      "subject": [
        "eess.IV"
      ],
      "abstract": "The proliferation of high resolution videos posts great storage and bandwidth\npressure on cloud video services, driving the development of next-generation\nvideo codecs. Despite great progress made in neural video coding, existing\napproaches are still far from economical deployment considering the complexity\nand rate-distortion performance tradeoff. To clear the roadblocks for neural\nvideo coding, in this paper we propose a new framework featuring standard\ncompatibility, high performance, and low decoding complexity. We employ a set\nof jointly optimized neural pre- and post-processors, wrapping a standard video\ncodec, to encode videos at different resolutions. The rate-distorion optimal\ndownsampling ratio is signaled to the decoder at the per-sequence level for\neach target rate. We design a low complexity neural post-processor architecture\nthat can handle different upsampling ratios. The change of resolution exploits\nthe spatial redundancy in high-resolution videos, while the neural wrapper\nfurther achieves rate-distortion performance improvement through end-to-end\noptimization with a codec proxy. Our light-weight post-processor architecture\nhas a complexity of 516 MACs / pixel, and achieves 9.3% BD-Rate reduction over\nVVC on the UVG dataset, and 6.4% on AOM CTC Class A1. Our approach has the\npotential to further advance the performance of the latest video coding\nstandards using neural processing with minimal added complexity."
    },
    {
      "paper_id": "1707.04179v1",
      "title": "Cost-Effective Cache Deployment in Mobile Heterogeneous Networks",
      "subject": [
        "cs.NI",
        "cs.IT"
      ],
      "abstract": "This paper investigates one of the fundamental issues in cache-enabled\nheterogeneous networks (HetNets): how many cache instances should be deployed\nat different base stations, in order to provide guaranteed service in a\ncost-effective manner. Specifically, we consider two-tier HetNets with\nhierarchical caching, where the most popular files are cached at small cell\nbase stations (SBSs) while the less popular ones are cached at macro base\nstations (MBSs). For a given network cache deployment budget, the cache sizes\nfor MBSs and SBSs are optimized to maximize network capacity while satisfying\nthe file transmission rate requirements. As cache sizes of MBSs and SBSs affect\nthe traffic load distribution, inter-tier traffic steering is also employed for\nload balancing. Based on stochastic geometry analysis, the optimal cache sizes\nfor MBSs and SBSs are obtained, which are threshold-based with respect to cache\nbudget in the networks constrained by SBS backhauls. Simulation results are\nprovided to evaluate the proposed schemes and demonstrate the applications in\ncost-effective network deployment."
    }
  ]
]