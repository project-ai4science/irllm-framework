[
  {
    "id":"neg-d21-0",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18058"
    ],
    "b_title":[
      "On the Classification of Isoparametric Hypersurfaces with Constant\n  Principal Curvatures in Compact 3-Manifolds"
    ],
    "b_abstract":[
      "Establishing detailed relationships between transnormal systems of different\ntypes and their behaviors under covering maps, this paper presents a\nclassification of transnormal systems on compact 3-manifolds in the sense of\nequivalence. For CPC transnormal systems, we show that the ambient manifolds\nmust be locally isometric to one of six standard geometries up to equivalence.\nWe also find some equivalence classes containing no CPC transnormal system,\nhighlighting a critical distinction between isoparametric foliations and CPC\ntransnormal systems, which has not been previously addressed in the literature."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.10906"
    ],
    "c_title":[
      "Explainable Adversarial Attacks on Coarse-to-Fine Classifiers"
    ],
    "c_abstract":[
      "Traditional adversarial attacks typically aim to alter the predicted labels\nof input images by generating perturbations that are imperceptible to the human\neye. However, these approaches often lack explainability. Moreover, most\nexisting work on adversarial attacks focuses on single-stage classifiers, but\nmulti-stage classifiers are largely unexplored. In this paper, we introduce\ninstance-based adversarial attacks for multi-stage classifiers, leveraging\nLayer-wise Relevance Propagation (LRP), which assigns relevance scores to\npixels based on their influence on classification outcomes. Our approach\ngenerates explainable adversarial perturbations by utilizing LRP to identify\nand target key features critical for both coarse and fine-grained\nclassifications. Unlike conventional attacks, our method not only induces\nmisclassification but also enhances the interpretability of the model's\nbehavior across classification stages, as demonstrated by experimental results."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-1",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08479"
    ],
    "b_title":[
      "Skyrise: Exploiting Serverless Cloud Infrastructure for Elastic Data\n  Processing"
    ],
    "b_abstract":[
      "Serverless computing offers elasticity unmatched by conventional server-based\ncloud infrastructure. Although modern data processing systems embrace\nserverless storage, such as Amazon S3, they continue to manage their compute\nresources as servers. This is challenging for unpredictable workloads, leaving\nclusters often underutilized. Recent research shows the potential of serverless\ncompute resources, such as cloud functions, for elastic data processing, but\nalso sees limitations in performance robustness and cost efficiency for long\nrunning workloads. These challenges require holistic approaches across the\nsystem stack. However, to the best of our knowledge, there is no end-to-end\ndata processing system built entirely on serverless infrastructure. In this\npaper, we present Skyrise, our effort towards building the first fully\nserverless SQL query processor. Skyrise exploits the elasticity of its\nunderlying infrastructure, while alleviating the inherent limitations with a\nnumber of adaptive and cost-aware techniques. We show that both Skyrise's\nperformance and cost are competitive to other cloud data systems for\nterabyte-scale queries of the analytical TPC-H benchmark."
    ],
    "b_categories":[
      [
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15447"
    ],
    "c_title":[
      "Ultra-high-energy $\\gamma$-ray emission associated with the tail of a\n  bow-shock pulsar wind nebula"
    ],
    "c_abstract":[
      "In this study, we present a comprehensive analysis of an unidentified\npoint-like ultra-high-energy (UHE) $\\gamma$-ray source, designated as 1LHAASO\nJ1740+0948u, situated in the vicinity of the middle-aged pulsar PSR J1740+1000.\nThe detection significance reached 17.1$\\sigma$ (9.4$\\sigma$) above 25$\\,$TeV\n(100$\\,$TeV). The source energy spectrum extended up to 300$\\,$TeV, which was\nwell fitted by a log-parabola function with $N0 = (1.93\\pm0.23) \\times 10^{-16}\n\\rm{TeV^{-1}\\,cm^{-2}\\,s^{-2}}$, $\\alpha = 2.14\\pm0.27$, and $\\beta =\n1.20\\pm0.41$ at E0 = 30$\\,$TeV. The associated pulsar, PSR J1740+1000, resides\nat a high galactic latitude and powers a bow-shock pulsar wind nebula (BSPWN)\nwith an extended X-ray tail. The best-fit position of the gamma-ray source\nappeared to be shifted by $0.2^{\\circ}$ with respect to the pulsar position. As\nthe (i) currently identified pulsar halos do not demonstrate such offsets, and\n(ii) centroid of the gamma-ray emission is approximately located at the\nextension of the X-ray tail, we speculate that the UHE $\\gamma$-ray emission\nmay originate from re-accelerated electron\/positron pairs that are advected\naway in the bow-shock tail."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-2",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17489"
    ],
    "b_title":[
      "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding"
    ],
    "b_abstract":[
      "Brain-computer interfaces (BCIs) present a promising avenue by translating\nneural activity directly into text, eliminating the need for physical actions.\nHowever, existing non-invasive BCI systems have not successfully covered the\nentire alphabet, limiting their practicality. In this paper, we propose a novel\nnon-invasive EEG-based BCI system with Curriculum-based Neural Spelling\nFramework, which recognizes all 26 alphabet letters by decoding neural signals\nassociated with handwriting first, and then apply a Generative AI (GenAI) to\nenhance spell-based neural language decoding tasks. Our approach combines the\nease of handwriting with the accessibility of EEG technology, utilizing\nadvanced neural decoding algorithms and pre-trained large language models\n(LLMs) to translate EEG patterns into text with high accuracy. This system show\nhow GenAI can improve the performance of typical spelling-based neural language\ndecoding task, and addresses the limitations of previous methods, offering a\nscalable and user-friendly solution for individuals with communication\nimpairments, thereby enhancing inclusive communication options."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03216"
    ],
    "c_title":[
      "A note on improved bounds for hypergraph rainbow matching problems"
    ],
    "c_abstract":[
      "A natural question, inspired by the famous Ryser-Brualdi-Stein Conjecture, is\nto determine the largest positive integer $g(r,n)$ such that every collection\nof $n$ matchings, each of size $n$, in an $r$-partite $r$-uniform hypergraph\ncontains a rainbow matching of size $g(r,n)$. The parameter $g'(r,n)$ is\ndefined identically with the exception that the host hypergraph is not required\nto be $r$-partite.\n  In this note, we improve the best known lower bounds on $g'(r,n)$ for all $r\n\\geq 4$ and the upper bounds on $g(r,n)$ for all $r \\geq 3$, provided $n$ is\nsufficiently large. More precisely, we show that if $r\\ge3$ then\n$$\\frac{2n}{r+1}-\\Theta_r(1)\\le g'(r,n)\\le g(r,n)\\le\nn-\\Theta_r(n^{1-\\frac{1}{r}}).$$ Interestingly, while it has been conjectured\nthat $g(2,n)=g'(2,n)=n-1$, our results show that if $r\\ge3$ then $g(r,n)$ and\n$g'(r,n)$ are bounded away from $n$ by a function which grows in $n$.\n  We also prove analogous bounds for the related problem where we are\ninterested in the smallest size $s$ for which any collection of $n$ matchings\nof size $s$ in an ($r$-partite) $r$-uniform hypergraph contains a rainbow\nmatching of size $n$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-3",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14901"
    ],
    "b_title":[
      "Oscillatory Line-Driven Winds: The Role of Atmospheric Stratification"
    ],
    "b_abstract":[
      "In a recent study, Dannen et al. surveyed a large parameter space to study\nthe transition from efficient to inefficient line driving. They found that when\nthe line force significantly weakens due to ionization, the winds are variable,\nwith a characteristic frequency comparable to the Lamb cut-off frequency of a\nstratified atmosphere, {\\omega}c. In this work, we present a set of simulations\nand perturbation analyses that elucidate the variability source and\ncharacteristics. We found that the line force adds wave energy and amplifies\nperturbations with frequencies near {\\omega}c. This selective amplification\nresults from the coupling between the natural tendency of velocity\nperturbations to grow in a stratified atmosphere and the dependence of the line\nforce on the velocity gradient, per the Castor-Abbott-Klein line-driven wind\ntheory. We also found that the variability stems from self-excitation that\noccurs in the exponential atmosphere due to the non-linearity introduced by the\nabsolute value of the velocity gradient in the line force prescription. We\nconclude that self-consistently calculating ionization is insufficient for\nmodeling the dynamics in the subsonic atmosphere. Instead future wind models\nshould relax the Sobolev approximation, or model the radiative transfer to\ncapture the dynamics and instabilities at the base of the wind."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05104"
    ],
    "c_title":[
      "An exponential integrator multicontinuum homogenization method for\n  fractional diffusion problem with multiscale coefficients"
    ],
    "c_abstract":[
      "In this paper, we present a robust and fully discretized method for solving\nthe time fractional diffusion equation with high-contrast multiscale\ncoefficients. We establish the homogenized equation in a coarse mesh using a\nmulticontinuum approach and employ the exponential integrator method for time\ndiscretization. The multicontinuum upscaled model captures the physical\ncharacteristics of the solution for the high-contrast multiscale problem,\nincluding averages and gradient effects in each continuum at the coarse scale.\nWe use the exponential integration method to address the nonlocality induced by\nthe time fractional derivative and the stiffness from the multiscale\ncoefficients in the semi-discretized problem. Convergence analysis of the\nnumerical scheme is provided, along with illustrative numerical examples. Our\nresults demonstrate the accuracy, efficiency, and improved stability for\nvarying order of fractional derivatives."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-4",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04612"
    ],
    "b_title":[
      "On the distribution of the angle between Oseledets spaces"
    ],
    "b_abstract":[
      "This note is concerned with the distribution of the angles between Oseledets\nsubspaces for linear cocycles driven by an ergodic transformation. We restrict\nourselves to dimension $2$, and give particular attention to the question of\nlog-integrability of those angles. In the setting of random i.i.d.\\ products of\nmatrices, we construct examples of probability measures on \\(\\GL_2(\\R)\\) with\nfinite first moment, for which the angle between Oseledets directions of the\nassociated cocycle is not log-integrable. Building on work for the totally\nirreducible case by Benoist and Quint, we show that for probability measures\nwith finite second moment the angle between Oseledets subspaces is always\nlog-integrable. Then we pivot to general measurable \\(\\GL_2(\\R)\\)-cocycles over\nan arbitrary ergodic automorphism of a non-atomic Lebesgue space. We show that\nno integrability condition on the distribution of the matrices is sufficient to\nguarantee log-integrability of the angle between Oseledets spaces. In fact, in\nthis context we show that the joint distribution of the Oseledets spaces may be\nchosen arbitrarily. We also obtain a similar flexibility result for bounded\ncocycles under the proper condition on the distribution of angles."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.16324"
    ],
    "c_title":[
      "Type I X-ray Burst Emission Reflected into the Eclipses of EXO 0748-676"
    ],
    "c_abstract":[
      "The neutron star X-ray binary, EXO 0748--676, was observed regularly by the\nRossi X-ray Timing Explorer (RXTE) and XMM-Newton during its first detected\noutburst (1985 - 2008). These observations captured hundreds of asymmetric,\nenergy-dependent X-ray eclipses, influenced by the ongoing ablation of the\ncompanion star and numerous Type I thermonuclear X-ray bursts. Here, we present\nthe light curves of 22 Type I X-ray bursts observed by RXTE that coincide,\nfully or partially, with an X-ray eclipse. We identify nine instances where the\nburst occurs entirely within totality, seven bursts split across an egress, and\nsix cases interrupted by an ingress. All in-eclipse bursts and split bursts\noccurred while the source was in the hard spectral state. We establish that we\nare not observing direct burst emission during eclipses since the companion\nstar and the ablated outflow entirely obscure our view of the X-ray emitting\nregion. We determine that the reflected flux from the outer accretion disc,\neven if maximally flared, is insufficient to explain all observations of\nin-eclipse X-ray bursts and instead explore scenarios whereby the emission\narising from the X-ray bursts is scattered, either by a burst-induced rise in\n$N_{\\rm{H}}$ that provides extra material, an accretion disc wind or the\nablated outflow into our line of sight. However, the rarity of a burst and\neclipse overlap makes it challenging to determine their origin."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-5",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05710"
    ],
    "b_title":[
      "EmotiCrafter: Text-to-Emotional-Image Generation based on\n  Valence-Arousal Model"
    ],
    "b_abstract":[
      "Recent research shows that emotions can enhance users' cognition and\ninfluence information communication. While research on visual emotion analysis\nis extensive, limited work has been done on helping users generate emotionally\nrich image content. Existing work on emotional image generation relies on\ndiscrete emotion categories, making it challenging to capture complex and\nsubtle emotional nuances accurately. Additionally, these methods struggle to\ncontrol the specific content of generated images based on text prompts. In this\nwork, we introduce the new task of continuous emotional image content\ngeneration (C-EICG) and present EmotiCrafter, an emotional image generation\nmodel that generates images based on text prompts and Valence-Arousal values.\nSpecifically, we propose a novel emotion-embedding mapping network that embeds\nValence-Arousal values into textual features, enabling the capture of specific\nemotions in alignment with intended input prompts. Additionally, we introduce a\nloss function to enhance emotion expression. The experimental results show that\nour method effectively generates images representing specific emotions with the\ndesired content and outperforms existing techniques."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05834"
    ],
    "c_title":[
      "Census of Ly$\\alpha$ Emission from $\\sim 600$ Galaxies at $z=5-14$:\n  Evolution of the Ly$\\alpha$ Luminosity Function and a Late Sharp Cosmic\n  Reionization"
    ],
    "c_abstract":[
      "We present the statistical properties of Ly$\\alpha$ emission in 586 galaxies\nat $z=4.5-14.2$, observed by multiple JWST\/NIRSpec spectroscopy projects,\nincluding JADES, GLASS, CEERS, and GO\/DDT programs. We obtain Ly$\\alpha$\nequivalent width (EW), Ly$\\alpha$ escape fraction, and ionizing photon\nproduction efficiency measurements or upper limits for these galaxies, and\nconfirm that the Ly$\\alpha$ emitting galaxy fraction decreases towards higher\nredshifts. We derive Ly$\\alpha$ luminosity functions from $z\\sim 5$ to $z\\sim\n10-14$ with the observed Ly$\\alpha$ EW distributions and galaxy UV luminosity\nfunctions, and find a $\\sim3$ dex decrease in number density at\n$L_\\mathrm{Ly\\alpha}=10^{42}-10^{43}$ erg s$^{-1}$ over the redshift range.\nNotably, this study presents the first constraints on the Ly$\\alpha$ luminosity\nfunction at $z\\sim 8-14$. We obtain the neutral hydrogen fractions of\n$x_\\mathrm{HI}=0.17_{-0.16}^{+0.23}$, $0.63_{-0.28}^{+0.18}$,\n$0.79_{-0.21}^{+0.13}$, and $0.88_{-0.13}^{+0.11}$ at $z\\sim6$, $7$, $8-9$, and\n$10-14$, respectively, via comparisons of the reionization models developed by\nsemi-numerical simulations with 21cmFAST explaining the observations of\nLy$\\alpha$, UV continuum, and Planck electron optical depth. The high\n$x_\\mathrm{HI}$ values over $z\\sim 7-14$ suggest a late and sharp reionization,\nwith the primary reionization process occurring at $z\\sim 6-7$. Such a late and\nsharp reionization is not easily explained by either a clumpy inter-galactic\nmedium or sources of reionization in a classical faint-galaxy or a\nbright-galaxy\/AGN scenario, unless a very high escape fraction or AGN duty\ncycle is assumed at $z\\sim 6-7$."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-6",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09389"
    ],
    "b_title":[
      "Canonical equilibrium of mean-field $O(n)$~models in presence of random\n  fields"
    ],
    "b_abstract":[
      "We study canonical-equilibrium properties of Random Field $O(n)$ Models\ninvolving classical continuous vector spins of $n$ components with mean-field\ninteractions and subject to disordered fields acting on individual spins. To\nthis end, we employ two complementary approaches: the mean-field approximation,\nvalid for any disorder distribution, and the replica trick, applicable when the\ndisordered fields are sampled from a Gaussian distribution. On the basis of an\nexact analysis, we demonstrate that when replica symmetry holds, both the\napproaches yield identical expression for the free energy per spin of the\nsystem. As consequences, we study the case of $n=2$ ($XY$ spins) and that of\n$n=3$ (Heisenberg spins) for two representative choices of the disorder\ndistribution, namely, a Gaussian and a symmetric bimodal distribution. For both\n$n=2$ and $n=3$, we demonstrate that while the magnetization exhibits a\ncontinuous phase transition as a function of temperature for the Gaussian case,\nthe transition could be either continuous or first-order with an emergent\ntricriticality when the disorder distribution is bimodal. We also discuss in\nthe context of our models the issue of self-averaging of extensive variables\nnear the critical point of a continuous phase transition."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15104"
    ],
    "c_title":[
      "Finite Gr\\\"obner bases for quantum symmetric groups"
    ],
    "c_abstract":[
      "Non-commutative Gr\\\"obner bases of two-sided ideals are not necessarily\nfinite. Motivated by this, we provide a closed-form description of a finite and\nreduced Gr\\\"obner bases for the two-sided ideal used in the construction of\nWangs quantum symmetric group. In particular, this proves that the word problem\nfor quantum symmetric groups is decidable."
    ],
    "c_categories":[
      [
        "math.QA",
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-7",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20450"
    ],
    "b_title":[
      "Universal electronic structure of layered nickelates via oxygen-centered\n  planar orbitals"
    ],
    "b_abstract":[
      "Superconductivity has recently been demonstrated in La$_3$Ni$_2$O$_7$ up to\n91K under moderate pressure in bulk crystals, and up to 48K at ambient pressure\nin thin films grown under compressive strain. Key questions remain open\nregarding the crystal structure and low-energy electronic states that support\nsuperconductivity in these compounds. Here we take advantage of the natural\npolymorphism between bilayer (2222) or alternating monolayer-trilayer (1313)\nstacking sequences that arises in bulk La$_3$Ni$_2$O$_7$ crystals to identify\nuniversal features in this family of materials. Employing angle-resolved\nphotoemission spectroscopy (ARPES) we observe the fingerprint of a spin-density\nwave (SDW) instability, strong and coherent enough to modify the electronic\nstructure. We demonstrate that this feature is a `translated' $\\beta$ Fermi\nsurface associated with a scattering vector $Q_{t\\beta}$ which matches the\n$Q_{SDW}$ detected by neutron and x-ray scattering experiments. This\nobservation provides an important link between surface and bulk probes, and\ndemonstrates a universal connection between magnetism and fermiology in\nLa$_3$Ni$_2$O$_7$ as well as La$_4$Ni$_3$O$_{10}$. We simulate the spectral\nweight distribution observed in our ARPES dichroism experiments and establish\nthat the low-energy electronic phenomenology is dominated by oxygen-centered\nplanar orbitals, which -- upon moving along the Fermi surface away from the\nNi-O-Ni bond directions -- evolve from the $d_{3x^2-r^2}$ and $d_{3y^2-r^2}$\nsymmetry characteristic of 3-spin polarons to the familiar $d_{x^2-y^2}$\nZhang-Rice singlets that support high-temperature superconductivity in\ncuprates. Despite the multiorbital nature of the nickelates, our work\nestablishes an empirical correspondence between the low-energy electronic\nstructure of cuprates and nickelates, thus suggesting a common origin for their\nunconventional superconductivity."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.16467"
    ],
    "c_title":[
      "Enhancing Explainability with Multimodal Context Representations for\n  Smarter Robots"
    ],
    "c_abstract":[
      "Artificial Intelligence (AI) has significantly advanced in recent years,\ndriving innovation across various fields, especially in robotics. Even though\nrobots can perform complex tasks with increasing autonomy, challenges remain in\nensuring explainability and user-centered design for effective interaction. A\nkey issue in Human-Robot Interaction (HRI) is enabling robots to effectively\nperceive and reason over multimodal inputs, such as audio and vision, to foster\ntrust and seamless collaboration. In this paper, we propose a generalized and\nexplainable multimodal framework for context representation, designed to\nimprove the fusion of speech and vision modalities. We introduce a use case on\nassessing 'Relevance' between verbal utterances from the user and visual scene\nperception of the robot. We present our methodology with a Multimodal Joint\nRepresentation module and a Temporal Alignment module, which can allow robots\nto evaluate relevance by temporally aligning multimodal inputs. Finally, we\ndiscuss how the proposed framework for context representation can help with\nvarious aspects of explainability in HRI."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-8",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01185"
    ],
    "b_title":[
      "Deep Active Speech Cancellation with Multi-Band Mamba Network"
    ],
    "b_abstract":[
      "We present a novel deep learning network for Active Speech Cancellation\n(ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively\ncanceling both noise and speech signals. The proposed Multi-Band Mamba\narchitecture segments input audio into distinct frequency bands, enabling\nprecise anti-signal generation and improved phase alignment across frequencies.\nAdditionally, we introduce an optimization-driven loss function that provides\nnear-optimal supervisory signals for anti-signal generation. Experimental\nresults demonstrate substantial performance gains, achieving up to 7.2dB\nimprovement in ANC scenarios and 6.2dB in ASC, significantly outperforming\nexisting methods. Audio samples are available at\nhttps:\/\/mishalydev.github.io\/DeepASC-Demo"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15464"
    ],
    "c_title":[
      "The 200 Gbps Challenge: Imagining HL-LHC analysis facilities"
    ],
    "c_abstract":[
      "The IRIS-HEP software institute, as a contributor to the broader HEP Python\necosystem, is developing scalable analysis infrastructure and software tools to\naddress the upcoming HL-LHC computing challenges with new approaches and\nparadigms, driven by our vision of what HL-LHC analysis will require. The\ninstitute uses a \"Grand Challenge\" format, constructing a series of\nincreasingly large, complex, and realistic exercises to show the vision of\nHL-LHC analysis. Recently, the focus has been demonstrating the IRIS-HEP\nanalysis infrastructure at scale and evaluating technology readiness for\nproduction.\n  As a part of the Analysis Grand Challenge activities, the institute executed\na \"200 Gbps Challenge\", aiming to show sustained data rates into the event\nprocessing of multiple analysis pipelines. The challenge integrated teams\ninternal and external to the institute, including operations and facilities,\nanalysis software tools, innovative data delivery and management services, and\nscalable analysis infrastructure. The challenge showcases the prototypes -\nincluding software, services, and facilities - built to process around 200 TB\nof data in both the CMS NanoAOD and ATLAS PHYSLITE data formats with test\npipelines.\n  The teams were able to sustain the 200 Gbps target across multiple pipelines.\nThe pipelines focusing on event rate were able to process at over 30 MHz. These\ntarget rates are demanding; the activity revealed considerations for future\ntesting at this scale and changes necessary for physicists to work at this\nscale in the future. The 200 Gbps Challenge has established a baseline on\ntoday's facilities, setting the stage for the next exercise at twice the scale."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-9",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04442"
    ],
    "b_title":[
      "A Survey on Path Planning Problem of Rolling Contacts: Approaches,\n  Applications and Future Challenges"
    ],
    "b_abstract":[
      "This paper explores an eclectic range of path-planning methodologies\nengineered for rolling surfaces. Our focus is on the kinematic intricacies of\nrolling contact systems, which are investigated through a motion planning lens.\nBeyond summarizing the approaches to single-contact rotational surfaces, we\nexplore the challenging domain of spin-rolling multi-contact systems. Our work\nproposes solutions for the higher-dimensional problem of multiple rotating\nobjects in contact. Venturing beyond kinematics, these methodologies find\napplication across a spectrum of domains, including rolling robots,\nreconfigurable swarm robotics, micro\/nano manipulation, and nonprehensile\nmanipulations. Through meticulously examining established planning strategies,\nwe unveil their practical implementations in various real-world scenarios, from\nintricate dexterous manipulation tasks to the nimble manoeuvring of rolling\nrobots and even shape planning of multi-contact swarms of particles. This study\nintroduces the persistent challenges and unexplored frontiers of robotics,\nintricately linked to both path planning and mechanism design. As we illuminate\nexisting solutions, we also set the stage for future breakthroughs in this\ndynamic and rapidly evolving field by highlighting the critical importance of\naddressing rolling contact problems."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02340"
    ],
    "c_title":[
      "Sharp stability for critical points of the Sobolev inequality in the\n  absence of bubbling"
    ],
    "c_abstract":[
      "When $u$ is close to a single Talenti bubble $v$ of the $p$-Sobolev\ninequality, we show that\n  \\begin{equation*}\n  \\|Du-Dv\\|_{L^p(\\mathbb{R}^n)}^{\\max\\{1,p-1\\}}\\le C \\|-{\\rm\ndiv}(|Du|^{p-2}Du)-|u|^{p^*-2}u\\|_{W^{-1,q}(\\mathbb{R}^n)}, \\end{equation*}\nwhere $C=C(n,p)>0$. This estimate provides a sharp stability estimate for the\nStruwe-type decomposition in the single bubble case, generalizing the result of\nCiraolo, Figalli, and Maggi \\cite{CFM2018} (focusing on the case $p=2$) to the\narbitrary $p$. Also, in the Sobolev setting, this answers an open problem\nraised by Zhou and Zou in \\cite[Remark 1.17]{ZZ2023}."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-10",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06079"
    ],
    "b_title":[
      "Set-valued evenly convex functions: characterizations and c-conjugacy"
    ],
    "b_abstract":[
      "In this work we deal with set-valued functions with values in the power set\nof a separated locally convex space where a nontrivial pointed convex cone\ninduces a partial order relation. A set-valued function is evenly convex if its\nepigraph is an evenly convex set, i.e., it is the intersection of an arbitrary\nfamily of open half-spaces. In this paper we characterize evenly convex\nset-valued functions as the pointwise supremum of its set-valued e-affine\nminorants. Moreover, a suitable conjugation pattern will be developed for these\nfunctions, as well as the counterpart of the biconjugation Fenchel-Moreau\ntheorem."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.17465"
    ],
    "c_title":[
      "Energetics and dynamics of membrane necks in particle wrapping"
    ],
    "c_abstract":[
      "Transport of microscopic objects across biological membranes usually involves\nmembrane deformation to enclose the object followed by detachment of the\nengulfed particle. However, in artificial membranes, this last topological\nremodelling step is in many cases not spontaneous due to the elastic stability\nof the neck structure formed upon complete particle wrapping. In this work, we\nuse optical trapping to induce the wrapping of a non-adhesive microsphere by\nthe membrane of a giant lipid vesicle and investigate the energetics and\ndynamics of the resulting neck structure. We find that neck formation occurs as\na result of membrane shape energy minimization under the application of\nexternal force. Remarkably, increasing membrane tension could reopen the neck\nand reverse the wrapping process. This process shows a clear hysteresis and a\ndegree of reversibility. Neck cleavage and particle detachment into the\nvesicle's interior could not be triggered in the range of our optical forces.\nSystematic studies on the thermal dynamics of wrapped particles allowed to\nestablish that diffusion properties of the system are in agreement with a\ncoupling of the particle motion with the neck structure, modeled as a solid\ninclusion within the membrane. Interestingly, the wrapped particle dynamics\nexhibited a tension dependency, which can be described as the sum of several\ndrag contributions."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-11",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09802"
    ],
    "b_title":[
      "Batch List-Decodable Linear Regression via Higher Moments"
    ],
    "b_abstract":[
      "We study the task of list-decodable linear regression using batches. A batch\nis called clean if it consists of i.i.d. samples from an unknown linear\nregression distribution. For a parameter $\\alpha \\in (0, 1\/2)$, an unknown\n$\\alpha$-fraction of the batches are clean and no assumptions are made on the\nremaining ones. The goal is to output a small list of vectors at least one of\nwhich is close to the true regressor vector in $\\ell_2$-norm. [DJKS23] gave an\nefficient algorithm, under natural distributional assumptions, with the\nfollowing guarantee. Assuming that the batch size $n$ satisfies $n \\geq\n\\tilde{\\Omega}(\\alpha^{-1})$ and the number of batches is $m = \\mathrm{poly}(d,\nn, 1\/\\alpha)$, their algorithm runs in polynomial time and outputs a list of\n$O(1\/\\alpha^2)$ vectors at least one of which is\n$\\tilde{O}(\\alpha^{-1\/2}\/\\sqrt{n})$ close to the target regressor. Here we\ndesign a new polynomial time algorithm with significantly stronger guarantees\nunder the assumption that the low-degree moments of the covariates distribution\nare Sum-of-Squares (SoS) certifiably bounded. Specifically, for any constant\n$\\delta>0$, as long as the batch size is $n \\geq\n\\Omega_{\\delta}(\\alpha^{-\\delta})$ and the degree-$\\Theta(1\/\\delta)$ moments of\nthe covariates are SoS certifiably bounded, our algorithm uses $m =\n\\mathrm{poly}((dn)^{1\/\\delta}, 1\/\\alpha)$ batches, runs in polynomial-time, and\noutputs an $O(1\/\\alpha)$-sized list of vectors one of which is\n$O(\\alpha^{-\\delta\/2}\/\\sqrt{n})$ close to the target. That is, our algorithm\nachieves substantially smaller minimum batch size and final error, while\nachieving the optimal list size. Our approach uses higher-order moment\ninformation by carefully combining the SoS paradigm interleaved with an\niterative method and a novel list pruning procedure. In the process, we give an\nSoS proof of the Marcinkiewicz-Zygmund inequality that may be of broader\napplicability."
    ],
    "b_categories":[
      [
        "cs.DS",
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06643"
    ],
    "c_title":[
      "Orthosymplectic modules of cohomological Hall algebras"
    ],
    "c_abstract":[
      "We study modules and comodules for cohomological Hall algebras equipped with\ntheir vertex coproducts arising as objects with classical type stabilizer\ngroups. Specifically we consider how classical type parabolic induction gives\nrise to actions of CoHAs of quivers with potential, of preprojective algberas,\nand of dimension zero sheaves on a smooth proper surface. In all cases the CoHA\naction is compatible with a localised (and vertex) coaction making the module a\ntwisted Yetter-Drinfeld module over the CoHA with its localised braided\nbialgebra structure. In the case of dimension zero sheaves on a surface the\naction is related to an approach to the AGT conjecture in classical type using\nmoduli stacks of orthosymplectic perverse coherent sheaves, a compactification\nof the stack of classical type bundles on a surface."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-12",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08062"
    ],
    "b_title":[
      "How Does CP Length Affect the Sensing Range for OFDM-ISAC?"
    ],
    "b_abstract":[
      "Orthogonal frequency division multiplexing (OFDM), which has been the\ndominating waveform for contemporary wireless communications, is also regarded\nas a competitive candidate for future integrated sensing and communication\n(ISAC) systems. Existing works on OFDM-ISAC usually assume that the maximum\nsensing range should be limited by the cyclic prefix (CP) length since\ninter-symbol interference (ISI) and inter-carrier interference (ICI) should be\navoided. However, in this paper, we provide rigorous analysis to reveal that\nthe random data embedded in OFDM-ISAC signal can actually act as a free ``mask\"\nfor ISI, which makes ISI\/ICI random and hence greatly attenuated after radar\nsignal processing. The derived signal-to-interference-plus-noise ratio (SINR)\nin the range profile demonstrates that the maximum sensing range of OFDM-ISAC\ncan greatly exceed the ISI-free distance that is limited by the CP length,\nwhich is validated by simulation results. To further mitigate power degradation\nfor long-range targets, a novel sliding window sensing method is proposed,\nwhich iteratively detects and cancels short-range targets before shifting the\ndetection window. The shifted detection window can effectively compensate the\npower degradation due to insufficient CP length for long-range targets. Such\nresults provide valuable guidance for the CP length design in OFDM-ISAC\nsystems."
    ],
    "b_categories":[
      [
        "cs.ET",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18947"
    ],
    "c_title":[
      "Synthesis of spherical mesoporous silica beads with tunable size,\n  stiffness and porosity"
    ],
    "c_abstract":[
      "We present an innovative template-free water-based sol-gel method to produce\nuniform mesoporous silica beads of millimeter size, which have tunable size,\nstiffness and porosity, and could be used for adsorption applications. Our\nprotocol exploits an in-situ enzymatic reaction to produce spherical beads of\nhydrogel from a charge-stabilized suspension of silica nanoparticles confined\nin a millimetric drop suspended in a non-miscible oil. Once the gelation step\nis complete, the spherical bead of gel is cleaned from oil and deposited onto a\nhydrophobic surface and let dry. Separating the gelation to the drying steps\nensures a spatially uniform gel and allows us to perform a solvent exchange\nbefore drying. For all beads, we observe a crack-free drying process leading to\nthe formation of stiff quasi-spherical beads with diameter in the range 1 to 5\nmm and Young modulus in the range $(0.1-2)$ GPa and narrow pore size\ndistribution, centered around $10$ to $25$ nm depending on the experimental\nconditions. Finally, to demonstrate the potentiality of these materials, we\ngraft on the bead surface aminosilane molecules, and quantify their CO$_2$\nadsorption efficiency. Overall, the production method we have developed is\nsimple, readily adaptable, and offers promising materials for adsorption,\nstorage, catalysis and chromatography."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-13",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05055"
    ],
    "b_title":[
      "Charge transport limited by nonlocal electron-phonon interaction. II.\n  Numerically exact quantum dynamics in the slow-phonon regime"
    ],
    "b_abstract":[
      "Transport of charge carriers in mechanically soft semiconductors is mainly\nlimited by their interaction with slow intermolecular phonons. Carrier motion\nexhibits a crossover from superdiffusive to subdiffusive, producing a distinct\nlow-frequency peak in the dynamical-mobility profile. These features can be\nunderstood within approaches relying on the timescale separation between\ncarrier and phonon dynamics, such as the transient localization scenario (TLS).\nHowever, recovering them from fully quantum dynamics has proved elusive. Using\nthe hierarchical equations of motion (HEOM)-based approach exposed in a\ncompanion paper (arXiv:2501.05054), we study carrier transport in the\none-dimensional Peierls model near the adiabatic limit. We find that the TLS\napproximates HEOM dynamics very well at higher temperatures and for stronger\ninteractions. Then, the transport is predominantly phonon-assisted, and turns\ndiffusive from the subdiffusive side well before one phonon period. In\ncontrast, the band current dominates at moderate temperatures and interactions,\nrelevant for transport in realistic materials. We then conclude that the\nsuper-to-subdiffusive crossover is transient, so that the diffusive motion sets\nin from the superdiffusive side after a couple of phonon periods. The\nlow-frequency dynamical mobility then additionally exhibits a dip at\napproximately one phonon frequency, and the zero-frequency peak. Our findings\nin this moderate regime show limitations of the TLS, and support the results of\nthe most advanced quantum-classical simulations. We expect that the qualitative\ndifferences between HEOM and TLS dynamics would diminish for a more realistic\nphonon density of states."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "physics.chem-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.19670"
    ],
    "c_title":[
      "Training Robust Graph Neural Networks by Modeling Noise Dependencies"
    ],
    "c_abstract":[
      "In real-world applications, node features in graphs often contain noise from\nvarious sources, leading to significant performance degradation in GNNs.\nAlthough several methods have been developed to enhance robustness, they rely\non the unrealistic assumption that noise in node features is independent of the\ngraph structure and node labels, thereby limiting their applicability. To this\nend, we introduce a more realistic noise scenario, dependency-aware noise on\ngraphs (DANG), where noise in node features create a chain of noise\ndependencies that propagates to the graph structure and node labels. We propose\na novel robust GNN, DA-GNN, which captures the causal relationships among\nvariables in the data generating process (DGP) of DANG using variational\ninference. In addition, we present new benchmark datasets that simulate DANG in\nreal-world applications, enabling more practical research on robust GNNs.\nExtensive experiments demonstrate that DA-GNN consistently outperforms existing\nbaselines across various noise scenarios, including both DANG and conventional\nnoise models commonly considered in this field."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-14",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02844"
    ],
    "b_title":[
      "Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text\n  Classification"
    ],
    "b_abstract":[
      "Text classification is a fundamental task in data mining, pivotal to various\napplications such as tabular understanding and recommendation. Although neural\nnetwork-based models, such as CNN and BERT, have demonstrated remarkable\nperformance in text classification, their effectiveness heavily relies on\nabundant labeled training data. This dependency makes these models less\neffective in dynamic few-shot text classification, where labeled data is\nscarce, and new target labels frequently appear based on application needs.\nRecently, large language models (LLMs) have shown promise due to their\nextensive pretraining and contextual understanding ability. Current approaches\nprovide LLMs with text inputs, candidate labels, and additional side\ninformation (e.g., descriptions) to classify texts. However, their\neffectiveness is hindered by the increased input size and the noise introduced\nthrough side information processing. To address these limitations, we propose a\ngraph-based online retrieval-augmented generation framework, namely GORAG, for\ndynamic few-shot text classification. Rather than treating each input\nindependently, GORAG constructs and maintains a weighted graph by extracting\nside information across all target texts. In this graph, text keywords and\nlabels are represented as nodes, with edges indicating the correlations between\nthem. To model these correlations, GORAG employs an edge weighting mechanism to\nprioritize the importance and reliability of extracted information and\ndynamically retrieves relevant context using a minimum-cost spanning tree\ntailored for each text input. Empirical evaluations demonstrate that GORAG\noutperforms existing approaches by providing more comprehensive and precise\ncontextual information."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05970"
    ],
    "c_title":[
      "Known Unknowns: Out-of-Distribution Property Prediction in Materials and\n  Molecules"
    ],
    "c_abstract":[
      "Discovery of high-performance materials and molecules requires identifying\nextremes with property values that fall outside the known distribution.\nTherefore, the ability to extrapolate to out-of-distribution (OOD) property\nvalues is critical for both solid-state materials and molecular design. Our\nobjective is to train predictor models that extrapolate zero-shot to higher\nranges than in the training data, given the chemical compositions of solids or\nmolecular graphs and their property values. We propose using a transductive\napproach to OOD property prediction, achieving improvements in prediction\naccuracy. In particular, the True Positive Rate (TPR) of OOD classification of\nmaterials and molecules improved by 3x and 2.5x, respectively, and precision\nimproved by 2x and 1.5x compared to non-transductive baselines. Our method\nleverages analogical input-target relations in the training and test sets,\nenabling generalization beyond the training target support, and can be applied\nto any other material and molecular tasks."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cs.CE",
        "cs.LG",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-15",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01922"
    ],
    "b_title":[
      "LAST SToP For Modeling Asynchronous Time Series"
    ],
    "b_abstract":[
      "We present a novel prompt design for Large Language Models (LLMs) tailored to\nAsynchronous Time Series. Unlike regular time series, which assume values at\nevenly spaced time points, asynchronous time series consist of timestamped\nevents occurring at irregular intervals, each described in natural language.\nOur approach effectively utilizes the rich natural language of event\ndescriptions, allowing LLMs to benefit from their broad world knowledge for\nreasoning across different domains and tasks. This allows us to extend the\nscope of asynchronous time series analysis beyond forecasting to include tasks\nlike anomaly detection and data imputation. We further introduce Stochastic\nSoft Prompting, a novel prompt-tuning mechanism that significantly improves\nmodel performance, outperforming existing fine-tuning methods such as QLoRA.\nThrough extensive experiments on real world datasets, we demonstrate that our\napproach achieves state-of-the-art performance across different tasks and\ndatasets."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18611"
    ],
    "c_title":[
      "Tight Bounds on the Binomial CDF, and the Minimum of i.i.d Binomials, in\n  terms of KL-Divergence"
    ],
    "c_abstract":[
      "We provide finite sample upper and lower bounds on the Binomial tail\nprobability which are a direct application of Sanov's theorem. We then use\nthese to obtain high probability upper and lower bounds on the minimum of\ni.i.d. Binomial random variables. Both bounds are finite sample, asymptotically\ntight, and expressed in terms of the KL-divergence."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.PR",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-16",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17882"
    ],
    "b_title":[
      "Science Across Languages: Assessing LLM Multilingual Translation of\n  Scientific Papers"
    ],
    "b_abstract":[
      "Scientific research is inherently global. However, the vast majority of\nacademic journals are published exclusively in English, creating barriers for\nnon-native-English-speaking researchers. In this study, we leverage large\nlanguage models (LLMs) to translate published scientific articles while\npreserving their native JATS XML formatting, thereby developing a practical,\nautomated approach for implementation by academic journals. Using our approach,\nwe translate articles across multiple scientific disciplines into 28 languages.\nTo evaluate translation accuracy, we introduce a novel question-and-answer (QA)\nbenchmarking method, in which an LLM generates comprehension-based questions\nfrom the original text and then answers them based on the translated text. Our\nbenchmark results show an average performance of 95.9%, showing that the key\nscientific details are accurately conveyed. In a user study, we translate the\nscientific papers of 15 researchers into their native languages, finding that\nthe authors consistently found the translations to accurately capture the\noriginal information in their articles. Interestingly, a third of the authors\nfound many technical terms \"overtranslated,\" expressing a preference to keep\nterminology more familiar in English untranslated. Finally, we demonstrate how\nin-context learning techniques can be used to align translations with\ndomain-specific preferences such as mitigating overtranslation, highlighting\nthe adaptability and utility of LLM-driven scientific translation. The code and\ntranslated articles are available at https:\/\/hankleid.github.io\/ProjectMundo."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14578"
    ],
    "c_title":[
      "Introduction of the G$_2$-Ricci Flow: Geometric Implications for\n  Spontaneous Symmetry Breaking and Gauge Boson Masses"
    ],
    "c_abstract":[
      "This work introduces the G$_2$-Ricci flow on seven-dimensional manifolds with\nnon-zero torsion and explores its physical implications. By extending the Ricci\nflow to manifolds with G$_2$ structures, we study the evolution of solitonic\nsolutions and their role in spontaneous symmetry breaking in gauge theories. In\nparticular, this model proposes that the masses of the W and Z bosons are\ndetermined not by an external scalar field, as in the Higgs mechanism, but by\nthe intrinsic geometric torsion of the manifold. Furthermore, a possible\nconnection between the geometry of extra dimensions and the curvature of our\nspacetime is explored, with implications for the experimentally observed\npositive cosmological constant. This approach provides an innovative\ninterpretation of fundamental interactions in theoretical physics, opening new\npossibilities for studying extra dimensions and the geometry of\nG$_2$-manifolds."
    ],
    "c_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-17",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03870"
    ],
    "b_title":[
      "Add Noise, Tasks, or Layers? MaiNLP at the VarDial 2025 Shared Task on\n  Norwegian Dialectal Slot and Intent Detection"
    ],
    "b_abstract":[
      "Slot and intent detection (SID) is a classic natural language understanding\ntask. Despite this, research has only more recently begun focusing on SID for\ndialectal and colloquial varieties. Many approaches for low-resource scenarios\nhave not yet been applied to dialectal SID data, or compared to each other on\nthe same datasets. We participate in the VarDial 2025 shared task on slot and\nintent detection in Norwegian varieties, and compare multiple set-ups: varying\nthe training data (English, Norwegian, or dialectal Norwegian), injecting\ncharacter-level noise, training on auxiliary tasks, and applying Layer\nSwapping, a technique in which layers of models fine-tuned on different\ndatasets are assembled into a model. We find noise injection to be beneficial\nwhile the effects of auxiliary tasks are mixed. Though some experimentation was\nrequired to successfully assemble a model from layers, it worked surprisingly\nwell; a combination of models trained on English and small amounts of dialectal\ndata produced the most robust slot predictions. Our best models achieve 97.6%\nintent accuracy and 85.6% slot F1 in the shared task."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08984"
    ],
    "c_title":[
      "Centre-of-momentum Variables in $\\nu_\\mu$CC1p1$\\pi$"
    ],
    "c_abstract":[
      "This study introduces a novel set of variables, namely the centre-of-momentum\nvariables, $\\theta_{\\textrm{COM}}$ and $E_{\\textrm{COM}}$, designed to isolate\nfinal-state interactions (FSI) from other aspects of neutrino-nucleus\ninteractions. Through detailed simulation studies, this work demonstrates the\nability of these variables to distinguish FSI contributions with minimal\ndependence on the nuclear initial state and, practically, on the neutrino flux,\nhighlighting their potential for advancing FSI modelling. With high-purity\nneutrino-hydrogen interaction selections, $\\theta_{\\textrm{COM}}$ offers the\nfirst opportunity for a direct cross-comparison among different neutrino\ncross-section experiments."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-18",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12300"
    ],
    "b_title":[
      "On the Chermak-Delgado lattice of a finite group"
    ],
    "b_abstract":[
      "By imposing conditions upon the index of a self-centralizing subgroup of a\ngroup, and upon the index of the center of the group, we are able to classify\nthe Chermak-Delgado lattice of the group. This is our main result. We use this\nresult to classify the Chermak-Delgado lattices of dicyclic groups and of\nmetabelian $p$-groups of maximal class."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.11471"
    ],
    "c_title":[
      "A Supersymmetric $w_{1+\\infty}$ Symmetry, the Extended Supergravity and\n  the Celestial Holography"
    ],
    "c_abstract":[
      "We determine the ${\\cal N}=4$ supersymmetric\n$W_{1+\\infty}^{2,2}[\\lambda=\\frac{1}{4}]$ algebra which is an extension of\n${\\cal N}=4$ $SO(4)$ superconformal algebra with vanishing central charge. We\nidentify the soft current algebra between the graviton, the gravitinos, the\nvectors, the Majorana fermions, the scalar or the pseudoscalar, equivalent to\n${\\cal N}=4$ supersymmetric $w_{1+\\infty}^{2,2}[\\lambda=\\frac{1}{4}]$ algebra,\nin two dimensions with the ${\\cal N}=4$ supergravity theory with $SO(4)$ global\nsymmetry in four dimensions found by Das (at Stony Brook in 1977), via\ncelestial holography. Furthermore, the truncations of ${\\cal N}=4$\nsupersymmetric $w_{1+\\infty}^{2,2}[\\lambda=\\frac{1}{4}]$ algebra provide the\nsoft current algebras for the ${\\cal N}=2,3$ supergravity theories, the ${\\cal\nN}=2$ supergravity coupled to its Abelian vector multiplet and the ${\\cal N}=1$\nsupersymmetric Maxwell Einstein theory. For the ${\\cal N}=2$ supergravity\ntheory, the soft current algebra can be also realized by the ${\\cal N}=2$\nsupersymmetric $w_{1+\\infty}^{K,K}[\\lambda=0]$ algebra."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-19",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20008"
    ],
    "b_title":[
      "Joint Fusion and Encoding: Advancing Multimodal Retrieval from the\n  Ground Up"
    ],
    "b_abstract":[
      "Information retrieval is indispensable for today's Internet applications, yet\ntraditional semantic matching techniques often fall short in capturing the\nfine-grained cross-modal interactions required for complex queries. Although\nlate-fusion two-tower architectures attempt to bridge this gap by independently\nencoding visual and textual data before merging them at a high level, they\nfrequently overlook the subtle interplay essential for comprehensive\nunderstanding. In this work, we rigorously assess these limitations and\nintroduce a unified retrieval framework that fuses visual and textual cues from\nthe ground up, enabling early cross-modal interactions for enhancing context\ninterpretation. Through a two-stage training process--comprising post-training\nadaptation followed by instruction tuning--we adapt MLLMs as retrievers using a\nsimple one-tower architecture. Our approach outperforms conventional methods\nacross diverse retrieval scenarios, particularly when processing complex\nmulti-modal inputs. Notably, the joint fusion encoder yields greater\nimprovements on tasks that require modality fusion compared to those that do\nnot, underscoring the transformative potential of early integration strategies\nand pointing toward a promising direction for contextually aware and effective\ninformation retrieval."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02272"
    ],
    "c_title":[
      "Mantra: Rewriting Quantum Programs to Minimize Trap-Movements for Zoned\n  Rydberg Atom Arrays"
    ],
    "c_abstract":[
      "A zoned neutral atom architecture achieves exceptional fidelity by\nsegregating the execution spaces of 1- and 2-qubit gates, being a promising\ncandidate for high-accuracy quantum systems. Unfortunately, naively applying\nprograms designed for static qubit topologies to zoned architectures may result\nin most execution time being consumed by inter-zone travels of atoms. To\naddress this, we introduce Mantra (Minimizing trAp movemeNts for aTom aRray\nArchitectures), which rewrites quantum programs to reduce the interleaving of\nsingle- and two-qubit gates. Mantra incorporates three strategies: (i) a\nfountain-shaped controlled-Z (CZ) chain, (ii) ZZ-interaction protocol without a\n1-qubit gate, and (iii) preemptive gate scheduling. Mantra reduces inter-zone\nmovements by 68%, physical gate counts by 35%, and improves circuit fidelities\nby 17% compared to the standard executions."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-20",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02520"
    ],
    "b_title":[
      "Predicting IoT Device Vulnerability Fix Times with Survival and Failure\n  Time Models"
    ],
    "b_abstract":[
      "The rapid integration of Internet of Things (IoT) devices into enterprise\nenvironments presents significant security challenges. Many IoT devices are\nreleased to the market with minimal security measures, often harbouring an\naverage of 25 vulnerabilities per device. To enhance cybersecurity measures and\naid system administrators in managing IoT patches more effectively, we propose\nan innovative framework that predicts the time it will take for a vulnerable\nIoT device to receive a fix or patch. We developed a survival analysis model\nbased on the Accelerated Failure Time (AFT) approach, implemented using the\nXGBoost ensemble regression model, to predict when vulnerable IoT devices will\nreceive fixes or patches. By constructing a comprehensive IoT vulnerabilities\ndatabase that combines public and private sources, we provide insights into\naffected devices, vulnerability detection dates, published CVEs, patch release\ndates, and associated Twitter activity trends. We conducted thorough\nexperiments evaluating different combinations of features, including\nfundamental device and vulnerability data, National Vulnerability Database\n(NVD) information such as CVE, CWE, and CVSS scores, transformed textual\ndescriptions into sentence vectors, and the frequency of Twitter trends related\nto CVEs. Our experiments demonstrate that the proposed model accurately\npredicts the time to fix for IoT vulnerabilities, with data from VulDB and NVD\nproving particularly effective. Incorporating Twitter trend data offered\nminimal additional benefit. This framework provides a practical tool for\norganisations to anticipate vulnerability resolutions, improve IoT patch\nmanagement, and strengthen their cybersecurity posture against potential\nthreats."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.16434"
    ],
    "c_title":[
      "Optically Detected Magnetic Resonance Imaging and Sensing Within\n  Functionalized Additively Manufactured Microporous Structures"
    ],
    "c_abstract":[
      "Quantum sensing with nitrogen-vacancy centers in diamond has emerged as a\npowerful tool for measuring diverse physical parameters, yet the versatility of\nthese measurement approaches is often limited by the achievable layout and\ndimensionality of bulk-crystal platforms. Here, we demonstrate a versatile\napproach to creating designer quantum sensors by surface-functionalizing\nmultiphoton lithography microstructures with NV-containing nanodiamonds. We\nshowcase this capability by fabricating a 150 $\\mu$m x 150 $\\mu$m x 150 $\\mu$m\ntriply periodic minimal surface gyroid structure with millions of attached\nnanodiamonds. We demonstrate a means to volumetrically image these structures\nusing a refractive index matching confocal imaging technique, and extract ODMR\nspectra from 1.86 $\\mu$m x 1.86 $\\mu$m areas of highly concentrated\nnanodiamonds across a cross section of the gyroid. Furthermore, the high\ndensity of sensing elements enables ensemble temperature measurements with\nsensitivity of 0.548 {\\deg}K\/$\\sqrt{Hz}$ at 5 mW excitation power. This\napproach to creating quantum-enabled microarchitectures opens new possibilities\nfor multimodal sensing in complex three-dimensional environments."
    ],
    "c_categories":[
      [
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-21",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02196"
    ],
    "b_title":[
      "CPTuning: Contrastive Prompt Tuning for Generative Relation Extraction"
    ],
    "b_abstract":[
      "Generative relation extraction (RE) commonly involves first reformulating RE\nas a linguistic modeling problem easily tackled with pre-trained language\nmodels (PLM) and then fine-tuning a PLM with supervised cross-entropy loss.\nAlthough having achieved promising performance, existing approaches assume only\none deterministic relation between each pair of entities without considering\nreal scenarios where multiple relations may be valid, i.e., entity pair\noverlap, causing their limited applications. To address this problem, we\nintroduce a novel contrastive prompt tuning method for RE, CPTuning, which\nlearns to associate a candidate relation between two in-context entities with a\nprobability mass above or below a threshold, corresponding to whether the\nrelation exists. Beyond learning schema, CPTuning also organizes RE as a\nverbalized relation generation task and uses Trie-constrained decoding to\nensure a model generates valid relations. It adaptively picks out the generated\ncandidate relations with a high estimated likelihood in inference, thereby\nachieving multi-relation extraction. We conduct extensive experiments on four\nwidely used datasets to validate our method. Results show that T5-large\nfine-tuned with CPTuning significantly outperforms previous methods, regardless\nof single or multiple relations extraction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03679"
    ],
    "c_title":[
      "The relationship between galaxy size and halo properties: Insights from\n  the IllustrisTNG simulations and differential clustering"
    ],
    "c_abstract":[
      "The physical origin of the radial sizes of galaxies and how galaxy sizes are\ncorrelated with the properties of their host dark matter halos is an open\nquestion in galaxy formation. In observations, the large-scale clustering of\ngalaxies selected by stellar mass is significantly different for large and\nsmall galaxies, and Behroozi et al. (2022) showed that these results are in\ntension with some of the correlations between galaxy size and halo properties\nin the literature. We analyze the IllustrisTNG suite of large volume\ncosmological hydrodynamic simulations along with dark matter only simulations\nwith matched initial conditions. We investigate correlations between the ratio\nof galaxy size to halo virial radius ($r_{\\rm gal}\/R_{\\rm vir}$) and halo spin,\nconcentration, and formation time at redshift 0-3. We find a significant\ncorrelation between $r_{\\rm gal}\/R_{\\rm vir}$ and concentration, but only above\na critical value $c \\simeq 16$, and we also find a correlation between $r_{\\rm\ngal}\/R_{\\rm vir}$ and halo formation time. We suggest that galaxy formation\nhistory and environment, in addition to halo properties at a given output time,\nplay an important role in shaping galaxy size. In addition, we directly measure\nsize-based differential clustering in the TNG300 simulation and compare\ndirectly with the observational results. We find significant scale-dependent\nsize-based differential clustering in TNG, in qualitative agreement with\nobservations. However, correlations between $r_{\\rm gal}\/R_{\\rm vir}$ and\nsecondary halo properties are not the drivers of the differential clustering in\nthe simulations; instead, we find that most of this signal in TNG arises from\nsatellite galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-22",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18013"
    ],
    "b_title":[
      "Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models\n  via Vision-Guided Reinforcement Learning"
    ],
    "b_abstract":[
      "Large Vision-Language Models (LVLMs) typically follow a two-stage training\nparadigm-pretraining and supervised fine-tuning. Recently, preference\noptimization, derived from the language domain, has emerged as an effective\npost-training reinforcement strategy to enhance capabilities of LVLMs. However,\nconstructing high-quality human-annotated preference data and developing robust\nreward models to mimic these preferences are both costly and challenging.\nMotivated by this observation, we propose Vision-R1, a novel vision-guided\nR1-like reinforcement learning algorithm for LVLMs that rewards models with\ndefinitive vision feedback. It only leverages curated instruction data,\neliminating the need for specialized reward models and handcrafted preference\ndatasets. We incorporate a criterion-driven reward function that further\nintegrates multi-dimensional feedback to evaluate model completions\ncomprehensively based on the vision task logic. Furthermore, we introduce a\nprogressive rule refinement strategy that dynamically adjusts the reward\ncriteria during training, enabling continuous model improvement and mitigating\nreward hacking. Extensive experiments on both in-distribution and\nout-of-distribution benchmarks demonstrate that fine-tuning the 7B LVLMs with\nVision-R1 achieves consistent performance gains, with even up to 50%\nimprovement and surpassing the state-of-the-art 10x size model."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18554"
    ],
    "c_title":[
      "Counterexample to Winkler's conjecture on Venn diagrams"
    ],
    "c_abstract":[
      "In 1984, Peter Winkler conjectured that every simple Venn diagram with $n$\ncurves can be extended to a simple Venn diagram with $n+1$ curves. We present a\ncounterexample to his conjecture for $n=7$, which is obtained by combining\ntheoretical ideas with computer assistance from state-of-the-art SAT solvers."
    ],
    "c_categories":[
      [
        "cs.DM",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-23",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06813"
    ],
    "b_title":[
      "Pareto Optimization with Robust Evaluation for Noisy Subset Selection"
    ],
    "b_abstract":[
      "Subset selection is a fundamental problem in combinatorial optimization,\nwhich has a wide range of applications such as influence maximization and\nsparse regression. The goal is to select a subset of limited size from a ground\nset in order to maximize a given objective function. However, the evaluation of\nthe objective function in real-world scenarios is often noisy. Previous\nalgorithms, including the greedy algorithm and multi-objective evolutionary\nalgorithms POSS and PONSS, either struggle in noisy environments or consume\nexcessive computational resources. In this paper, we focus on the noisy subset\nselection problem with a cardinality constraint, where the evaluation of a\nsubset is noisy. We propose a novel approach based on Pareto Optimization with\nRobust Evaluation for noisy subset selection (PORE), which maximizes a robust\nevaluation function and minimizes the subset size simultaneously. PORE can\nefficiently identify well-structured solutions and handle computational\nresources, addressing the limitations observed in PONSS. Our experiments,\nconducted on real-world datasets for influence maximization and sparse\nregression, demonstrate that PORE significantly outperforms previous methods,\nincluding the classical greedy algorithm, POSS, and PONSS. Further validation\nthrough ablation studies confirms the effectiveness of our robust evaluation\nfunction."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10030"
    ],
    "c_title":[
      "Quantum Spin Correlation Amplification Enables Macroscopic Detection of\n  Atomic-Level Fatigue in Ferromagnetic Metals"
    ],
    "c_abstract":[
      "Structural fatigue failures account for most of catastrophic metal component\nfailures, annually causing thousands of accidents, tens of thousands of\ncasualties, and $100 billion in global economic losses. Current detection\nmethods struggle to identify early-stage fatigue damage characterized by\nsub-nanometer atomic displacements and localized bond rupture. Here we present\na quantum-enhanced monitoring framework leveraging the fundamental symbiosis\nbetween metallic bonding forces and magnetic interactions. Through magnetic\nexcitation of quantum spin correlation in metallic structures, we establish a\nmacroscopic quantum spin correlation amplification technology that visualizes\nfatigue-induced magnetic flux variations corresponding to bond strength\ndegradation. Our multi-scale analysis integrates fatigue life prediction with\nquantum mechanical parameters (bonding force constants, crystal orbital overlap\npopulation) and ferromagnetic element dynamics, achieving unprecedented\nprediction accuracy (R^2>0.9, p<0.0001). In comprehensive fatigue trials\nencompassing 193 ferromagnetic metal specimens across 3,700 testing hours, this\nquantum magnetic signature consistently provided macroscopic fracture warnings\nprior to failure - a critical advance enabling 100% early detection success.\nThis transformative framework establishes the first operational platform for\npreemptive fatigue mitigation in critical infrastructure, offering a paradigm\nshift from post-failure analysis to quantum-enabled predictive maintenance."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-24",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00372"
    ],
    "b_title":[
      "Nucleolus Credit Assignment for Effective Coalitions in Multi-agent\n  Reinforcement Learning"
    ],
    "b_abstract":[
      "In cooperative multi-agent reinforcement learning (MARL), agents typically\nform a single grand coalition based on credit assignment to tackle a composite\ntask, often resulting in suboptimal performance. This paper proposed a\nnucleolus-based credit assignment grounded in cooperative game theory, enabling\nthe autonomous partitioning of agents into multiple small coalitions that can\neffectively identify and complete subtasks within a larger composite task.\nSpecifically, our designed nucleolus Q-learning could assign fair credits to\neach agent, and the nucleolus Q-operator provides theoretical guarantees with\ninterpretability for both learning convergence and the stability of the formed\nsmall coalitions. Through experiments on Predator-Prey and StarCraft scenarios\nacross varying difficulty levels, our approach demonstrated the emergence of\nmultiple effective coalitions during MARL training, leading to faster learning\nand superior performance in terms of win rate and cumulative rewards especially\nin hard and super-hard environments, compared to four baseline methods. Our\nnucleolus-based credit assignment showed the promise for complex composite\ntasks requiring effective subteams of agents."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14100"
    ],
    "c_title":[
      "Beamfocusing and Power Allocation for AN-Based PLS in Multiuser XL-MIMO\n  with Multiple Eavesdroppers"
    ],
    "c_abstract":[
      "This paper investigates the downlink (DL) physical layer security (PLS) in a\nnear-field (NF) extra-large multiple-input multiple-output MIMO (XL-MIMO)\nsystem. To enhance the secrecy rate (SR), null-space artificial noise (AN) is\ntransmitted alongside the confidential message, ensuring orthogonality with\nlegitimate user equipment (LUE) channels. The objective is to maximize the\nminimum SR by optimizing the NF beamfocusing matrix and power allocation\nbetween the signal and AN, considering various channel state information (CSI)\nconditions and transmit power constraints. The proposed approach uses\nsuccessive convex approximation (SCA) for beamfocusing optimization and golden\nsection search (GSS) for power allocation. The following open questions are\naddressed: (i) Can AN transmission further enhance SR for multiple LUEs in the\npresence of multiple eavesdropping user equipment (EUEs)? (ii) Can null-space\nAN transmission achieve attractive SR performance even without CSI availability\nfor EUEs? Both questions are affirmatively answered and explored in detail,\nwith an algorithm presented for joint beamfocusing design and AN-aided power\nallocation. The proposed method outperforms state-of-the-art approaches that\neither omit AN transmission or rely on maximal-ratio transmission (MRT) for\nbeamfocusing."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-25",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17180"
    ],
    "b_title":[
      "Bound Domains"
    ],
    "b_abstract":[
      "How much energy is required to unbind baryons from the cosmological\nstructures that originally bind them? This tutorial article explains why trying\nto answer this question using just a halo model can be misleading. Instead, it\nrecommends parsing the universe into ``bound domains,'' which are the\ngravitationally bound structures that ultimately become widely separated\nislands as the universe evolves. It explains why a bound domain's potential\nwell was about as deep ~1 Gyr after the Big Bang as it is now, and it outlines\nhow future research might take advantage of a bound-domain approach to make\nprogress on some open questions about the baryon distributions in and around\ngalaxy groups and clusters."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.11874"
    ],
    "c_title":[
      "Large Deviations for Slow-Fast Mean-Field Diffusions"
    ],
    "c_abstract":[
      "The aim of this paper is to investigate the large deviations for a class of\nslow-fast mean-field diffusions, which extends some existing results to the\ncase where the laws of fast process are also involved in the slow component.\nDue to the perturbations of fast process and its time marginal law, one cannot\nprove the large deviations based on verifying the powerful weak convergence\ncriterion directly. To overcome this problem, we employ the functional\noccupation measure, which combined with the notion of the viable pair and the\ncontrols of feedback form to characterize the limits of controlled sequences\nand justify the upper and lower bounds of Laplace principle. As a consequence,\nthe explicit representation formula of the rate function for large deviations\nis also presented."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-26",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13793"
    ],
    "b_title":[
      "The link between Microstructural Heterogeneity, Diffusivity, and\n  Hydrogen Embrittlement"
    ],
    "b_abstract":[
      "Green hydrogen is likely to play a major role in decarbonising the aviation\nindustry. It is crucial to understand the effects of microstructure on hydrogen\nredistribution, which may be implicated in the embrittlement of candidate fuel\nsystem metals. We have developed a stochastic multiscale finite element\nmodelling framework that integrates micromechanical and hydrogen transport\nmodels, such that the dominant microstructural effects can be efficiently\naccounted for at millimetre length scales. Our results show that microstructure\nhas a significant effect on hydrogen localisation in elastically anisotropic\nmaterials, which exhibit an interesting interplay between microstructure and\nmillimetre-scale hydrogen redistribution at various loading rates. Considering\n316L stainless steel and nickel, a direct comparison of model predictions\nagainst experimental hydrogen embrittlement data reveals that the reported\nsensitivity to loading rate is strongly linked with rate-dependent grain scale\ndiffusion. These findings highlight the need to incorporate microstructural\ncharacteristics in the design of hydrogen resistant materials."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.11411"
    ],
    "c_title":[
      "Beyond the Hype: Benchmarking LLM-Evolved Heuristics for Bin Packing"
    ],
    "c_abstract":[
      "Coupling Large Language Models (LLMs) with Evolutionary Algorithms has\nrecently shown significant promise as a technique to design new heuristics that\noutperform existing methods, particularly in the field of combinatorial\noptimisation. An escalating arms race is both rapidly producing new heuristics\nand improving the efficiency of the processes evolving them. However, driven by\nthe desire to quickly demonstrate the superiority of new approaches, evaluation\nof the new heuristics produced for a specific domain is often cursory: testing\non very few datasets in which instances all belong to a specific class from the\ndomain, and on few instances per class. Taking bin-packing as an example, to\nthe best of our knowledge we conduct the first rigorous benchmarking study of\nnew LLM-generated heuristics, comparing them to well-known existing heuristics\nacross a large suite of benchmark instances using three performance metrics.\nFor each heuristic, we then evolve new instances won by the heuristic and\nperform an instance space analysis to understand where in the feature space\neach heuristic performs well. We show that most of the LLM heuristics do not\ngeneralise well when evaluated across a broad range of benchmarks in contrast\nto existing simple heuristics, and suggest that any gains from generating very\nspecialist heuristics that only work in small areas of the instance space need\nto be weighed carefully against the considerable cost of generating these\nheuristics."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-27",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05488"
    ],
    "b_title":[
      "KIEval: Evaluation Metric for Document Key Information Extraction"
    ],
    "b_abstract":[
      "Document Key Information Extraction (KIE) is a technology that transforms\nvaluable information in document images into structured data, and it has become\nan essential function in industrial settings. However, current evaluation\nmetrics of this technology do not accurately reflect the critical attributes of\nits industrial applications. In this paper, we present KIEval, a novel\napplication-centric evaluation metric for Document KIE models. Unlike prior\nmetrics, KIEval assesses Document KIE models not just on the extraction of\nindividual information (entity) but also of the structured information\n(grouping). Evaluation of structured information provides assessment of\nDocument KIE models that are more reflective of extracting grouped information\nfrom documents in industrial settings. Designed with industrial application in\nmind, we believe that KIEval can become a standard evaluation metric for\ndeveloping or applying Document KIE models in practice. The code will be\npublicly available."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19368"
    ],
    "c_title":[
      "Qmod: Expressive High-Level Quantum Modeling"
    ],
    "c_abstract":[
      "Quantum computing hardware is advancing at a rapid pace, yet the lack of\nhigh-level programming abstractions remains a serious bottleneck in the\ndevelopment of new applications. Widely used frameworks still rely on\ngate-level circuit descriptions, causing the algorithm's functional intent to\nbecome lost in low-level implementation details, and hindering flexibility and\nreuse. While various high-level quantum programming languages have emerged in\nrecent years - offering a significant step toward higher abstraction - many\nstill lack support for classical-like expression syntax, and native constructs\nfor useful quantum algorithmic idioms. This paper presents Qmod, a high-level\nquantum programming language designed to capture algorithmic intent in natural\nterms while delegating implementation decisions to automation. Qmod introduces\nquantum numeric variables and expressions, including digital fixed-point\narithmetic tuned for compact representations and optimal resource usage. Beyond\ndigital encoding, Qmod also supports non-digital expression modes - phase and\namplitude encoding - frequently exploited by quantum algorithms to achieve\ncomputational advantages. We describe the language's constructs, demonstrate\npractical usage examples, and outline future work on evaluating Qmod across a\nbroader set of use cases."
    ],
    "c_categories":[
      [
        "cs.PL",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-28",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14064"
    ],
    "b_title":[
      "AIGVE-Tool: AI-Generated Video Evaluation Toolkit with Multifaceted\n  Benchmark"
    ],
    "b_abstract":[
      "The rapid advancement in AI-generated video synthesis has led to a growth\ndemand for standardized and effective evaluation metrics. Existing metrics lack\na unified framework for systematically categorizing methodologies, limiting a\nholistic understanding of the evaluation landscape. Additionally, fragmented\nimplementations and the absence of standardized interfaces lead to redundant\nprocessing overhead. Furthermore, many prior approaches are constrained by\ndataset-specific dependencies, limiting their applicability across diverse\nvideo domains. To address these challenges, we introduce AIGVE-Tool\n(AI-Generated Video Evaluation Toolkit), a unified framework that provides a\nstructured and extensible evaluation pipeline for a comprehensive AI-generated\nvideo evaluation. Organized within a novel five-category taxonomy, AIGVE-Tool\nintegrates multiple evaluation methodologies while allowing flexible\ncustomization through a modular configuration system. Additionally, we propose\nAIGVE-Bench, a large-scale benchmark dataset created with five SOTA video\ngeneration models based on hand-crafted instructions and prompts. This dataset\nsystematically evaluates various video generation models across nine critical\nquality dimensions. Extensive experiments demonstrate the effectiveness of\nAIGVE-Tool in providing standardized and reliable evaluation results,\nhighlighting specific strengths and limitations of current models and\nfacilitating the advancements of next-generation AI-generated video techniques."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18647"
    ],
    "c_title":[
      "Magnetic field evolution of X-ray emitting radio-quiet pulsars"
    ],
    "c_abstract":[
      "The intense magnetic fields present in neutron stars are closely linked to\ntheir observed temperature and spectral characteristics, timing properties,\nincluding spin period and its derivatives. Therefore, a comprehensive\ntheoretical analysis of magnetic field evolution is essential for understanding\nhow the strength of the magnetic field change over time. The decay rate of\nmagnetic field in isolated, non-accreting neutron stars can be assessed by\nevaluating the second derivative of the spin frequency. Another method to\nestimate this rate involves monitoring an increase in thermal emission beyond\nwhat is expected from standard cooling processes, assuming no additional\nheating mechanisms are present. Our findings indicate that for X-ray emitting\nisolated neutron stars, the evolution rate of spin period derivative aligns\nwith the dissipation rate of magnetic energy from the dipolar field, provided\nthat a substantial portion of the released energy is emitted as X-rays. The\ntime scale of magnetic field decay is found to be much shorter than typical age\nof radio pulsars."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-29",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01515"
    ],
    "b_title":[
      "DiagrammaticLearning: A Graphical Language for Compositional Training\n  Regimes"
    ],
    "b_abstract":[
      "Motivated by deep learning regimes with multiple interacting yet distinct\nmodel components, we introduce learning diagrams, graphical depictions of\ntraining setups that capture parameterized learning as data rather than code. A\nlearning diagram compiles to a unique loss function on which component models\nare trained. The result of training on this loss is a collection of models\nwhose predictions ``agree\" with one another. We show that a number of popular\nlearning setups such as few-shot multi-task learning, knowledge distillation,\nand multi-modal learning can be depicted as learning diagrams. We further\nimplement learning diagrams in a library that allows users to build diagrams of\nPyTorch and Flux.jl models. By implementing some classic machine learning use\ncases, we demonstrate how learning diagrams allow practitioners to build\ncomplicated models as compositions of smaller components, identify\nrelationships between workflows, and manipulate models during or after\ntraining. Leveraging a category theoretic framework, we introduce a rigorous\nsemantics for learning diagrams that puts such operations on a firm\nmathematical foundation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.00957"
    ],
    "c_title":[
      "Generative AI and LLMs in Industry: A text-mining Analysis and Critical\n  Evaluation of Guidelines and Policy Statements Across Fourteen Industrial\n  Sectors"
    ],
    "c_abstract":[
      "The rise of Generative AI (GAI) and Large Language Models (LLMs) has\ntransformed industrial landscapes, offering unprecedented opportunities for\nefficiency and innovation while raising critical ethical, regulatory, and\noperational challenges. This study conducts a text-based analysis of 160\nguidelines and policy statements across fourteen industrial sectors, utilizing\nsystematic methods and text-mining techniques to evaluate the governance of\nthese technologies. By examining global directives, industry practices, and\nsector-specific policies, the paper highlights the complexities of balancing\ninnovation with ethical accountability and equitable access. The findings\nprovide actionable insights and recommendations for fostering responsible,\ntransparent, and safe integration of GAI and LLMs in diverse industry contexts."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-30",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11482"
    ],
    "b_title":[
      "DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free\n  Continual Learning"
    ],
    "b_abstract":[
      "Continual learning (CL) is essential for Large Language Models (LLMs) to\nadapt to evolving real-world demands, yet they are susceptible to catastrophic\nforgetting (CF). While traditional CF solutions rely on expensive data\nrehearsal, recent rehearsal-free methods employ model-based and\nregularization-based strategies to address this issue. However, these\napproaches often neglect the model's plasticity, which is crucial to achieving\noptimal performance on newly learned tasks. Consequently, a key challenge in CL\nis striking a balance between preserving plasticity and mitigating CF. To\ntackle this challenge, we propose the $\\textbf{D}$ecomposed\n$\\textbf{A}$ttention-based $\\textbf{T}$ask $\\textbf{A}$daptation (DATA), which\nexplicitly decouples and learns both task-specific and task-shared knowledge\nusing high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA\ndynamically adjusts the weights of adapters of different ranks based on their\nrelevance and distinction from previous tasks, allowing the model to acquire\nnew task-specific skills while effectively retaining previously learned\nknowledge. Specifically, we implement a decomposed component weighting strategy\ncomprising learnable components that collectively generate attention-based\nweights, allowing the model to integrate and utilize diverse knowledge from\neach DATA. Extensive experiments on three widely used benchmarks demonstrate\nthat our proposed method achieves state-of-the-art performance. Notably, our\napproach significantly enhances model plasticity and mitigates CF by extending\nlearnable components and employing stochastic restoration during training\niterations."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.00870"
    ],
    "c_title":[
      "An intriguing coincidence between the majority of vast polar structure\n  dwarfs and a recent major merger at the M31 position"
    ],
    "c_abstract":[
      "A significant part of the Milky Way (MW) dwarf galaxies orbit within a Vast\nPOlar Structure (VPOS), which is perpendicular to the Galactic disc and whose\norigin has not yet been identified. It includes the Large Magellanic Cloud\n(LMC) and its six dynamically associated dwarf galaxies. Andromeda Galaxy (M31)\nexperienced a major merger two to three billion years ago, and its accurate\nmodelling predicts that an associated tidal tail is pointing towards the\nGalaxy. Here, we tested a possible association between M31 tidal tail particles\nand MW dwarf galaxies, focusing first on the LMC and its associated dwarfs\nsince they are less affected by ram pressure. We traced back these dwarf galaxy\norbits by one billion years and calculated their association with the tidal\ntail particles in the 6D phase space, based on their proper motion from\n\\textit{Gaia} DR3. We find that for low-mass MW models (total mass less than 5\n$\\times 10^{11} M_{\\odot}$), the separation in the 6D space can be less than\n1$\\sigma$ for most of the M31 modelling, albeit with a significant degree of\nfreedom due to the still unknown proper motion of M31. We further discover that\nmany other dwarfs could also be associated with the M31 tidal tails if their\nmotions had been radially slowed, as expected from the ram pressure exerted by\nthe MW corona. This intriguing coincidence could explain the origin of the\nVPOS, which resulted from a matter exchange between M31 and MW."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-31",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00868"
    ],
    "b_title":[
      "Gorenstein analogues of a projectivity criterion over group algebras"
    ],
    "b_abstract":[
      "We formulate and answer Gorenstein projective, flat, and injective analogues\nof a classical projectivity question for group rings under some mild additional\nassumptions. Although the original question, that was proposed by Jang-Hyun Jo\nin 2007, was for integral group rings, in this article, we deal with more\ngeneral commutative base rings. We make use of the vast developments that have\nhappened in the field of Gorenstein homological algebra over group rings in\nrecent years, and we also improve and generalize several existing results from\nthis area along the way."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.10187"
    ],
    "c_title":[
      "Nuclear matter in relativistic Brueckner-Hartree-Fock theory with local\n  and nonlocal covariant chiral interactions at leading order"
    ],
    "c_abstract":[
      "The simultaneous description for nuclear matter and finite nuclei has been a\nlong-standing challenge in nuclear ab initio theory. With the success for\nnuclear matter, the relativistic Brueckner-Hartree-Fock (RBHF) theory with\ncovariant chiral interactions is a promising ab initio approach to describe\nboth nuclear matter and finite nuclei. In the description of the finite nuclei\nwith the current RBHF theory, the covariant chiral interactions have to be\nlocalized to make calculations feasible. In order to examine the reliability\nand validity, in this letter, the RBHF theory with local and nonlocal covariant\nchiral interactions at leading order are applied for nuclear matter. The\nlow-energy constants in the covariant chiral interactions determined with the\nlocal regularization are close to those with the nonlocal regularization.\nMoreover, the RBHF theory with local and nonlocal covariant chiral interactions\nprovide equally well description of the saturation properties of nuclear\nmatter. The present work paves the way for the implementation of covariant\nchiral interactions in RBHF theory for finite nuclei."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-32",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13728"
    ],
    "b_title":[
      "Secure Federated Data Distillation"
    ],
    "b_abstract":[
      "Dataset Distillation (DD) is a powerful technique for reducing large datasets\ninto compact, representative synthetic datasets, accelerating Machine Learning\ntraining. However, traditional DD methods operate in a centralized manner,\nwhich poses significant privacy threats and reduces its applicability. To\nmitigate these risks, we propose a Secure Federated Data Distillation (SFDD)\nframework to decentralize the distillation process while preserving privacy.\nUnlike existing Federated Distillation techniques that focus on training global\nmodels with distilled knowledge, our approach aims to produce a distilled\ndataset without exposing local contributions. We leverage the\ngradient-matching-based distillation method, adapting it for a distributed\nsetting where clients contribute to the distillation process without sharing\nraw data. The central aggregator iteratively refines a synthetic dataset by\nintegrating client-side updates while ensuring data confidentiality. To make\nour approach resilient to inference attacks perpetrated by the server that\ncould exploit gradient updates to reconstruct private data, we create an\noptimized Local Differential Privacy approach, called LDPO-RLD. Furthermore, we\nassess the framework's resilience against malicious clients executing backdoor\nattacks (such as Doorping) and demonstrate robustness under the assumption of a\nsufficient number of participating clients. Our experimental results\ndemonstrate the effectiveness of SFDD and that the proposed defense concretely\nmitigates the identified vulnerabilities, with minimal impact on the\nperformance of the distilled dataset. By addressing the interplay between\nprivacy and federation in dataset distillation, this work advances the field of\nprivacy-preserving Machine Learning making our SFDD framework a viable solution\nfor sensitive data-sharing applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.06049"
    ],
    "c_title":[
      "The Role of Affective States in Computational Psychiatry"
    ],
    "c_abstract":[
      "Studying psychiatric illness has often been limited by difficulties in\nconnecting symptoms and behavior to neurobiology. Computational psychiatry\napproaches promise to bridge this gap by providing formal accounts of the\nlatent information processing changes that underlie the development and\nmaintenance of psychiatric phenomena. Models based on these theories generate\nindividual-level parameter estimates which can then be tested for relationships\nto neurobiology. In this review, we explore computational modelling approaches\nto one key aspect of health and illness: affect. We discuss strengths and\nlimitations of key approaches to modelling affect, with a focus on\nreinforcement learning, active inference, the hierarchical gaussian filter, and\ndrift-diffusion models. We find that, in this literature, affect is an\nimportant source of modulation in decision making, and has a bidirectional\ninfluence on how individuals infer both internal and external states.\nHighlighting the potential role of affect in information processing changes\nunderlying symptom development, we extend an existing model of psychosis, where\naffective changes are influenced by increasing cortical noise and consequent\nincreases in either perceived environmental instability or expected noise in\nsensory input, becoming part of a self-reinforcing process generating\nnegatively valenced, over-weighted priors underlying positive symptom\ndevelopment. We then provide testable predictions from this model at\ncomputational, neurobiological, and phenomenological levels of description."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-33",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19176"
    ],
    "b_title":[
      "Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer\n  Using Generative Artificial Intelligence"
    ],
    "b_abstract":[
      "Full-Field Digital Mammography (FFDM) is the primary imaging modality for\nroutine breast cancer screening; however, its effectiveness is limited in\npatients with dense breast tissue or fibrocystic conditions. Contrast-Enhanced\nSpectral Mammography (CESM), a second-level imaging technique, offers enhanced\naccuracy in tumor detection. Nonetheless, its application is restricted due to\nhigher radiation exposure, the use of contrast agents, and limited\naccessibility. As a result, CESM is typically reserved for select cases,\nleaving many patients to rely solely on FFDM despite the superior diagnostic\nperformance of CESM. While biopsy remains the gold standard for definitive\ndiagnosis, it is an invasive procedure that can cause discomfort for patients.\nWe introduce a multimodal, multi-view deep learning approach for virtual\nbiopsy, integrating FFDM and CESM modalities in craniocaudal and mediolateral\noblique views to classify lesions as malignant or benign. To address the\nchallenge of missing CESM data, we leverage generative artificial intelligence\nto impute CESM images from FFDM scans. Experimental results demonstrate that\nincorporating the CESM modality is crucial to enhance the performance of\nvirtual biopsy. When real CESM data is missing, synthetic CESM images proved\neffective, outperforming the use of FFDM alone, particularly in multimodal\nconfigurations that combine FFDM and CESM modalities. The proposed approach has\nthe potential to improve diagnostic workflows, providing clinicians with\naugmented intelligence tools to improve diagnostic accuracy and patient care.\nAdditionally, as a contribution to the research community, we publicly release\nthe dataset used in our experiments, facilitating further advancements in this\nfield."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11978"
    ],
    "c_title":[
      "Weight Distribution of the Weighted Coordinates Poset Block Space and\n  Singleton Bound"
    ],
    "c_abstract":[
      "In this paper, we determine the complete weight distribution of the space $\n\\mathbb{F}_q^N $ endowed by the weighted coordinates poset block metric\n($(P,w,\\pi)$-metric), also known as the $(P,w,\\pi)$-space, thereby obtaining it\nfor $(P,w)$-space, $(P,\\pi)$-space, $\\pi$-space, and $P$-space as special\ncases. Further, when $P$ is a chain, the resulting space is called as\nNiederreiter-Rosenbloom-Tsfasman (NRT) weighted block space and when $P$ is\nhierarchical, the resulting space is called as weighted coordinates\nhierarchical poset block space. The complete weight distribution of both the\nspaces are deduced from the main result. Moreover, we define an $I$-ball for an\nideal $I$ in $P$ and study the characteristics of it in $(P,w,\\pi)$-space.\n  We investigate the relationship between the $I$-perfect codes and $t$-perfect\ncodes in $(P,w,\\pi)$-space. Given an ideal $I$, we investigate how the maximum\ndistance separability (MDS) is related with $I$-perfect codes and $t$-perfect\ncodes in $(P,w,\\pi)$-space. Duality theorem is derived for an MDS\n$(P,w,\\pi)$-code when all the blocks are of same length. Finally, the\ndistribution of codewords among $r$-balls is analyzed in the case of chain\nposet, when all the blocks are of same length."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.CO",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-34",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04970"
    ],
    "b_title":[
      "Gradient-based Explanations for Deep Learning Survival Models"
    ],
    "b_abstract":[
      "Deep learning survival models often outperform classical methods in\ntime-to-event predictions, particularly in personalized medicine, but their\n\"black box\" nature hinders broader adoption. We propose a framework for\ngradient-based explanation methods tailored to survival neural networks,\nextending their use beyond regression and classification. We analyze the\nimplications of their theoretical assumptions for time-dependent explanations\nin the survival setting and propose effective visualizations incorporating the\ntemporal dimension. Experiments on synthetic data show that gradient-based\nmethods capture the magnitude and direction of local and global feature\neffects, including time dependencies. We introduce GradSHAP(t), a\ngradient-based counterpart to SurvSHAP(t), which outperforms SurvSHAP(t) and\nSurvLIME in a computational speed vs. accuracy trade-off. Finally, we apply\nthese methods to medical data with multi-modal inputs, revealing relevant\ntabular features and visual patterns, as well as their temporal dynamics."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09313"
    ],
    "c_title":[
      "Delay Performance Analysis with Short Packets in Intelligent Machine\n  Network"
    ],
    "c_abstract":[
      "With the rapid development of delay-sensitive services happened in industrial\nmanufacturing, Internet of Vehicles, and smart logistics, more stringent delay\nrequirements are put forward for the intelligent machine (IM) network. Short\npacket transmissions are widely adopted to reduce delay in IM networks.\nHowever, the delay performance of an IM network has not been sufficiently\nanalyzed. This paper applies queuing theory and stochastic geometry to\nconstruct network model and transmission model for downlink communication,\nrespectively, proposes and derives the following three metrics, e.g., the\ntransmission success probability (with delay as the threshold), expected delay,\nand delay jitter. To accurately characterize the transmission delay with short\npackets, the finite blocklength capacity is used to measure the channel\ntransmission rate. Simulation results show that the increase of packet length\nand IM density significantly deteriorates the three metrics. Short packets are\nneeded to improve the three metrics, especially in high IM density scenarios.\nThe outcomes of this paper provide an important theoretical basis for the\noptimization design and performance improvement of IM networks."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-35",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11362"
    ],
    "b_title":[
      "On the exact order of the discrepancy of low discrepancy digital van der\n  Corput--Kronecker sequences"
    ],
    "b_abstract":[
      "In this paper we give the exact order of the discrepancy of the digital van\nder Corput--Kronecker sequences that are based on recent counterexamples of the\n$X$-adic Littlewood conjecture in positive characteristics. Our result supports\nonce again the well-established conjecture in the theory of uniform\ndistribution which states that $D^*_N\\leq c \\frac{\\log^s N}{N},\\,c>0$ is the\nbest possible upper bound for the star discrepancy $D^*_N$ of a sequence in\n$[0,1)^s$ or in other words for every sequence in $[0,1)^s$\n$\\limsup_{N\\to\\infty}ND^*_N\/\\log^s N>0$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.16562"
    ],
    "c_title":[
      "Bezier Distillation"
    ],
    "c_abstract":[
      "In Rectified Flow, by obtaining the rectified flow several times, the mapping\nrelationship between distributions can be distilled into a neural network, and\nthe target distribution can be directly predicted by the straight lines of the\nflow. However, during the pairing process of the mapping relationship, a large\namount of error accumulation will occur, resulting in a decrease in performance\nafter multiple rectifications. In the field of flow models, knowledge\ndistillation of multi - teacher diffusion models is also a problem worthy of\ndiscussion in accelerating sampling. I intend to combine multi - teacher\nknowledge distillation with Bezier curves to solve the problem of error\naccumulation. Currently, the related paper is being written by myself."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-36",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04228"
    ],
    "b_title":[
      "Totally bounded ultrametric spaces and locally finite trees"
    ],
    "b_abstract":[
      "We investigate the interrelations between the metric properties, order\nproperties and combinatorial properties of the set of balls in totally bounded\nultrametric space. In particular, the Gurvich-Vyalyi representation of finite,\nultrametric spaces by monotone rooted trees is generalized to the case of\ntotally bounded ultrametric spaces. It is shown that such spaces have isometric\ncompletions if and only if their labeled representing trees are isomorphic. We\ncharacterize up to isomorphism the representing trees of these spaces and, up\nto order isomorphism, the posets of open balls in such spaces."
    ],
    "b_categories":[
      [
        "math.GN"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.12442"
    ],
    "c_title":[
      "HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented\n  Generation"
    ],
    "c_abstract":[
      "Retrieval-Augmented Generation (RAG) systems often struggle with imperfect\nretrieval, as traditional retrievers focus on lexical or semantic similarity\nrather than logical relevance. To address this, we propose HopRAG, a novel RAG\nframework that augments retrieval with logical reasoning through\ngraph-structured knowledge exploration. During indexing, HopRAG constructs a\npassage graph, with text chunks as vertices and logical connections established\nvia LLM-generated pseudo-queries as edges. During retrieval, it employs a\nretrieve-reason-prune mechanism: starting with lexically or semantically\nsimilar passages, the system explores multi-hop neighbors guided by\npseudo-queries and LLM reasoning to identify truly relevant ones. Extensive\nexperiments demonstrate HopRAG's superiority, achieving 76.78\\% higher answer\naccuracy and 65.07\\% improved retrieval F1 score compared to conventional\nmethods. The repository is available at https:\/\/github.com\/LIU-Hao-2002\/HopRAG."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-37",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18276"
    ],
    "b_title":[
      "Learning Orientation Field for OSM-Guided Autonomous Navigation"
    ],
    "b_abstract":[
      "OpenStreetMap (OSM) has gained popularity recently in autonomous navigation\ndue to its public accessibility, lower maintenance costs, and broader\ngeographical coverage. However, existing methods often struggle with noisy OSM\ndata and incomplete sensor observations, leading to inaccuracies in trajectory\nplanning. These challenges are particularly evident in complex driving\nscenarios, such as at intersections or facing occlusions. To address these\nchallenges, we propose a robust and explainable two-stage framework to learn an\nOrientation Field (OrField) for robot navigation by integrating LiDAR scans and\nOSM routes. In the first stage, we introduce the novel representation, OrField,\nwhich can provide orientations for each grid on the map, reasoning jointly from\nnoisy LiDAR scans and OSM routes. To generate a robust OrField, we train a deep\nneural network by encoding a versatile initial OrField and output an optimized\nOrField. Based on OrField, we propose two trajectory planners for OSM-guided\nrobot navigation, called Field-RRT* and Field-Bezier, respectively, in the\nsecond stage by improving the Rapidly Exploring Random Tree (RRT) algorithm and\nBezier curve to estimate the trajectories. Thanks to the robustness of OrField\nwhich captures both global and local information, Field-RRT* and Field-Bezier\ncan generate accurate and reliable trajectories even in challenging conditions.\nWe validate our approach through experiments on the SemanticKITTI dataset and\nour own campus dataset. The results demonstrate the effectiveness of our\nmethod, achieving superior performance in complex and noisy conditions. Our\ncode for network training and real-world deployment is available at\nhttps:\/\/github.com\/IMRL\/OriField."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12237"
    ],
    "c_title":[
      "Investigating Evolving Wormholes in $f(R,T)$ Gravity"
    ],
    "c_abstract":[
      "The present work examines whether evolving wormhole solution is possible or\nnot in $f(R,T)$ modified gravity theory. In the background of inhomogeneous\nFLRW type wormhole configuration the field equations are investigated for\ndifferent choices of scale factors and shape functions. For the power law and\nexponential choice of the scale factor from cosmological context and decoupled\npower law of $f(R,T)$ in each variable, wormhole configuration has been\nexamined for two viable choices of shape function. Energy conditions are\nexamined graphically for a range of values of the parameters involved. Finally,\nthe possibility of emergent scenario at early cosmic evolution has been\nexamined."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-38",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19680"
    ],
    "b_title":[
      "M-LLM Based Video Frame Selection for Efficient Video Understanding"
    ],
    "b_abstract":[
      "Recent advances in Multi-Modal Large Language Models (M-LLMs) show promising\nresults in video reasoning. Popular Multi-Modal Large Language Model (M-LLM)\nframeworks usually apply naive uniform sampling to reduce the number of video\nframes that are fed into an M-LLM, particularly for long context videos.\nHowever, it could lose crucial context in certain periods of a video, so that\nthe downstream M-LLM may not have sufficient visual information to answer a\nquestion. To attack this pain point, we propose a light-weight M-LLM -based\nframe selection method that adaptively select frames that are more relevant to\nusers' queries. In order to train the proposed frame selector, we introduce two\nsupervision signals (i) Spatial signal, where single frame importance score by\nprompting a M-LLM; (ii) Temporal signal, in which multiple frames selection by\nprompting Large Language Model (LLM) using the captions of all frame\ncandidates. The selected frames are then digested by a frozen downstream video\nM-LLM for visual reasoning and question answering. Empirical results show that\nthe proposed M-LLM video frame selector improves the performances various\ndownstream video Large Language Model (video-LLM) across medium (ActivityNet,\nNExT-QA) and long (EgoSchema, LongVideoBench) context video question answering\nbenchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14460"
    ],
    "c_title":[
      "Signless Laplacian State Transfer on Vertex Complemented Coronae"
    ],
    "c_abstract":[
      "Given a graph $G$ with vertex set $V(G)=\\{v_1,v_2,\\ldots,v_{n_1}\\}$ and a\ngraph $H$ of order $n_2$, the vertex complemented corona, denoted by\n$G\\tilde{\\circ}{H}$, is the graph produced by copying $H$ $n_1$ times, with the\n$i$-th copy of $H$ corresponding to the vertex $v_i$, and then adding edges\nbetween any vertex in $V(G)\\setminus\\{v_{i}\\}$ and any vertex of the $i$-th\ncopy of $H$. The present article deals with quantum state transfer of vertex\ncomplemented coronae concerning signless Laplacian matrix. Our research\ninvestigates conditions in which signless Laplacian perfect state transfer\nexists or not on vertex complemented coronae. Additionally, we also provide\nsome mild conditions for the class of graphs under consideration that allow\nsignless Laplacian pretty good state transfer."
    ],
    "c_categories":[
      [
        "math.CO",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-39",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12504"
    ],
    "b_title":[
      "Shapes of unit lattices in $D_p$-number fields"
    ],
    "b_abstract":[
      "The unit group of the ring of integers of a number field, modulo torsion, is\na lattice via the logarithmic Minkowski embedding. We examine the shape of this\nlattice, which we call the unit shape, within the family of prime degree $p$\nnumber fields whose Galois closure has dihedral Galois group $D_p$ and a unique\nreal embedding. In the case $p = 5$, we prove that the unit shapes lie on a\nsingle hypercycle on the modular surface (in this case, the modular surface is\nthe space of shapes of rank $2$ lattices). For general $p$, we show that the\nunit shapes are contained in a finite union of translates of periodic torus\norbits in the space of shapes."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.13619"
    ],
    "c_title":[
      "Complex Ontology Matching with Large Language Model Embeddings"
    ],
    "c_abstract":[
      "Ontology, and more broadly, Knowledge Graph Matching is a challenging task in\nwhich expressiveness has not been fully addressed. Despite the increasing use\nof embeddings and language models for this task, approaches for generating\nexpressive correspondences still do not take full advantage of these models, in\nparticular, large language models (LLMs). This paper proposes to integrate LLMs\ninto an approach for generating expressive correspondences based on alignment\nneed and ABox-based relation discovery. The generation of correspondences is\nperformed by matching similar surroundings of instance sub-graphs. The\nintegration of LLMs results in different architectural modifications, including\nlabel similarity, sub-graph matching, and entity matching. The performance word\nembeddings, sentence embeddings, and LLM-based embeddings, was compared. The\nresults demonstrate that integrating LLMs surpasses all other models, enhancing\nthe baseline version of the approach with a 45\\% increase in F-measure."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-40",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03763"
    ],
    "b_title":[
      "3D Printable Gradient Lattice Design for Multi-Stiffness Robotic Fingers"
    ],
    "b_abstract":[
      "Human fingers achieve exceptional dexterity and adaptability by combining\nstructures with varying stiffness levels, from soft tissues (low) to tendons\nand cartilage (medium) to bones (high). This paper explores developing a\nrobotic finger with similar multi-stiffness characteristics. Specifically, we\npropose using a lattice configuration, parameterized by voxel size and unit\ncell geometry, to optimize and achieve fine-tuned stiffness properties with\nhigh granularity. A significant advantage of this approach is the feasibility\nof 3D printing the designs in a single process, eliminating the need for manual\nassembly of elements with differing stiffness. Based on this method, we present\na novel, human-like finger, and a soft gripper. We integrate the latter with a\nrigid manipulator and demonstrate the effectiveness in pick and place tasks."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03536"
    ],
    "c_title":[
      "Randomized measurements for multi-parameter quantum metrology"
    ],
    "c_abstract":[
      "The optimal quantum measurements for estimating different unknown parameters\nin a parameterized quantum state are usually incompatible with each other.\nTraditional approaches to addressing the measurement incompatibility issue,\nsuch as the Holevo Cram\\'{e}r--Rao bound, suffer from multiple difficulties\ntowards practical applicability, as the optimal measurement strategies are\nusually state-dependent, difficult to implement and also take complex analyses\nto determine. Here we study randomized measurements as a new approach for\nmulti-parameter quantum metrology. We show quantum measurements on single\ncopies of quantum states given by 3-design perform near-optimally when\nestimating an arbitrary number of parameters in pure states and more generally,\napproximately low-rank states, whose metrological information is largely\nconcentrated in a low-dimensional subspace. The near-optimality is also shown\nin estimating the maximal number of parameters for three types of mixed states\nthat are well-conditioned on its support. Examples of fidelity estimation and\nHamiltonian estimation are explicitly provided to demonstrate the power and\nlimitation of randomized measurements in multi-parameter quantum metrology."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-41",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01847"
    ],
    "b_title":[
      "Complete function space for planar two-loop six-particle scattering\n  amplitudes"
    ],
    "b_abstract":[
      "We derive the full system of canonical differential equations for all planar\ntwo-loop massless six-particle master integrals, and determine analytically the\nboundary conditions. This fully specifies the solutions, which may be written\nas Chen iterated integrals. We argue that this is sufficient information for\nevaluating any scattering amplitude in four dimensions up to the finite part.\nWe support this claim by reducing, for the most complicated integral\ntopologies, integrals with typical Yang-Mills numerators. We use the analytic\nsolutions to the differential equations, together with dihedral symmetry, to\nprovide the full solution space relevant for two-loop six-particle\ncomputations. This includes the relevant function alphabet, as well as the\nindependent set of iterated integrals up to weight four. We also provide the\nanswer for all master integrals in terms of iterated integrals that can be\nreadily evaluated numerically. As a proof of concept, we provide a numerical\nimplementation that evaluates the integrals in part of the Euclidean region,\nand validate this against numerical evaluation of the Feynman integrals. Our\nresult removes the bottleneck of Feynman integral evaluation, paving the way to\nfuture analytic evaluations of six-particle scattering amplitudes."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17421"
    ],
    "c_title":[
      "LongSpec: Long-Context Speculative Decoding with Efficient Drafting and\n  Verification"
    ],
    "c_abstract":[
      "Speculative decoding has become a promising technique to mitigate the high\ninference latency of autoregressive decoding in Large Language Models (LLMs).\nDespite its promise, the effective application of speculative decoding in LLMs\nstill confronts three key challenges: the increasing memory demands of the\ndraft model, the distribution shift between the short-training corpora and\nlong-context inference, and inefficiencies in attention implementation. In this\nwork, we enhance the performance of speculative decoding in long-context\nsettings by addressing these challenges. First, we propose a memory-efficient\ndraft model with a constant-sized Key-Value (KV) cache. Second, we introduce\nnovel position indices for short-training data, enabling seamless adaptation\nfrom short-context training to long-context inference. Finally, we present an\ninnovative attention aggregation method that combines fast implementations for\nprefix computation with standard attention for tree mask handling, effectively\nresolving the latency and memory inefficiencies of tree decoding. Our approach\nachieves strong results on various long-context tasks, including\nrepository-level code completion, long-context summarization, and o1-like long\nreasoning tasks, demonstrating significant improvements in latency reduction.\nThe code is available at https:\/\/github.com\/sail-sg\/LongSpec."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-42",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14873"
    ],
    "b_title":[
      "Refining local-type primordial non-Gaussianity: Sharpened $b_\\phi$\n  constraints through bias expansion"
    ],
    "b_abstract":[
      "Local-type primordial non-Gaussianity (PNG), predicted by many non-minimal\nmodels of inflation, creates a scale-dependent contribution to the power\nspectrum of large-scale structure (LSS) tracers. Its amplitude is characterized\nby the product $b_\\phi f_{\\rm NL}^{\\rm loc}$, where $b_\\phi$ is an\nastrophysical parameter dependent on the properties of the tracer. However,\n$b_\\phi$ exhibits significant secondary dependence on halo concentration and\nother astrophysical properties, which may bias and weaken the constraints on\n$f_{\\rm NL}^{\\rm loc}$. In this work, we demonstrate that incorporating\nknowledge of the relation between Lagrangian bias parameters and $b_\\phi$ can\nsignificantly enhance PNG constraints. We employ the Hybrid Effective Field\nTheory (HEFT) approach at the field-level and a linear regression model to seek\na connection between the bias parameters and $b_{\\phi}$ for halo and galaxy\nsamples, constructed using the \\textsc{AbacusSummit} simulation suite and\nmimicking the luminous red galaxies (LRGs) and quasi-stellar objects (QSOs) of\nthe Dark Energy Spectroscopic Instrument (DESI) survey. For the fixed-mass halo\nsamples, our full bias model reduces the uncertainty by more than 70\\%, with\nmost of that improvement coming from $b_\\nabla$, which we find to be an\nexcellent proxy for concentration. For the galaxy samples, our model reduces\nthe uncertainty on $b_\\phi$ by 80\\% for all tracers. By adopting\nLagrangian-bias informed priors on the parameter $b_\\phi$, future analyses can\nthus constrain $f_{\\rm NL}^{\\rm loc}$ with less bias and smaller errors."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.06557"
    ],
    "c_title":[
      "LiveForesighter: Generating Future Information for Live-Streaming\n  Recommendations at Kuaishou"
    ],
    "c_abstract":[
      "Live-streaming, as a new-generation media to connect users and authors, has\nattracted a lot of attention and experienced rapid growth in recent years.\nCompared with the content-static short-video recommendation, the live-streaming\nrecommendation faces more challenges in giving our users a satisfactory\nexperience: (1) Live-streaming content is dynamically ever-changing along time.\n(2) valuable behaviors (e.g., send digital-gift, buy products) always require\nusers to watch for a long-time (>10 min). Combining the two attributes, here\nraising a challenging question for live-streaming recommendation: How to\ndiscover the live-streamings that the content user is interested in at the\ncurrent moment, and further a period in the future?"
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-43",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16955"
    ],
    "b_title":[
      "HEART: A New X-Ray Tracing Code for Mosaic Crystal Spectrometers"
    ],
    "b_abstract":[
      "We introduce a new open-source Python x-ray tracing code for modelling Bragg\ndiffracting mosaic crystal spectrometers: High Energy Applications Ray Tracer\n(HEART). HEART's high modularity enables customizable workflows as well as\nefficient development of novel features. Utilizing Numba's just-in-time (JIT)\ncompiler and the message-passing interface (MPI) allows running HEART in\nparallel leading to excellent performance. HEART is intended to be used for\nmodelling x-ray spectra as they would be seen in experiments that measure x-ray\nspectroscopy with a mosaic crystal spectrometer. This enables the user to, for\nexample, make predictions about what will be seen on a detector in experiment,\nperform optimizations on the design of the spectrometer setup, or to study the\neffect of the spectrometer on measured spectra. However, the code certainly has\nfurther uses beyond these example use cases. Here, we discuss the physical\nmodel used in the code, and explore a number of different mosaic distribution\nfunctions, intrinsic rocking curves, and sampling approaches which are\navailable to the user. Finally, we demonstrate its strong predictive capability\nin comparison to spectroscopic data collected at the European XFEL in Germany."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.01531"
    ],
    "c_title":[
      "A Global Games-Inspired Approach to Multi-Robot Task Allocation for\n  Heterogeneous Teams"
    ],
    "c_abstract":[
      "In this article we propose a game-theoretic approach to the multi-robot task\nallocation problem using the framework of global games. Each task is associated\nwith a global signal, a real-valued number that captures the task execution\nprogress and\/or urgency. We propose a linear objective function for each robot\nin the system, which, for each task, increases with global signal and decreases\nwith the number assigned robots. We provide conditions on the objective\nfunction hyperparameters to induce a mixed Nash equilibrium, i.e., solutions\nwhere all robots are not assigned to a single task. The resulting algorithm\nonly requires the inversion of a matrix to determine a probability distribution\nover the robot assignments. We demonstrate the performance of our algorithm in\nsimulation and provide direction for applications and future work."
    ],
    "c_categories":[
      [
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-44",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12146"
    ],
    "b_title":[
      "Divisors of an Integer in a Short Interval"
    ],
    "b_abstract":[
      "Let $\\mathcal{D}_{n} \\subset \\mathbb{N}$ denote the set of the $\\tau(n)$\ndivisors of $n$. We study the function $$ D_{n}(X,Y):=|\\{d \\in\n\\mathcal{D}_{n}:\\ X \\le d \\le X+Y\\}| $$ for $Y \\le X$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.08660"
    ],
    "c_title":[
      "Semantic Role Labeling: A Systematical Survey"
    ],
    "c_abstract":[
      "Semantic role labeling (SRL) is a central natural language processing (NLP)\ntask aiming to understand the semantic roles within texts, facilitating a wide\nrange of downstream applications. While SRL has garnered extensive and enduring\nresearch, there is currently a lack of a comprehensive survey that thoroughly\norganizes and synthesizes the field. This paper aims to review the entire\nresearch trajectory of the SRL community over the past two decades. We begin by\nproviding a complete definition of SRL. To offer a comprehensive taxonomy, we\ncategorize SRL methodologies into four key perspectives: model architectures,\nsyntax feature modeling, application scenarios, and multi-modal extensions.\nFurther, we discuss SRL benchmarks, evaluation metrics, and paradigm modeling\napproaches, while also exploring practical applications across various domains.\nFinally, we analyze future research directions in SRL, addressing the evolving\nrole of SRL in the age of large language models (LLMs) and its potential impact\non the broader NLP landscape. We maintain a public repository and consistently\nupdate related resources at: https:\/\/github.com\/DreamH1gh\/Awesome-SRL"
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-45",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04737"
    ],
    "b_title":[
      "Network and Kinetics-based Biosignatures: Implications for the Putative\n  Habitable World Observatory Design"
    ],
    "b_abstract":[
      "The proposed Habitable Worlds Observatory is intended to observe the\natmospheres of nearby terrestrial exoplanets with a resolution greater than\nthat of any previous instrument. While these observations present a substantial\nopportunity for astrobiology, they also incur the risk of false positives and\nfalse negatives. Here, we explore the use of systems science (in the form of\nnetwork theory and thermochemical kinetics) to mitigate these risks, and\nbriefly describe the technical specifications HWO would require in order to use\nthese methodologies."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15517"
    ],
    "c_title":[
      "Analysis of AI Effectiveness in Reducing Human Errors in Processing\n  Transportation Requests"
    ],
    "c_abstract":[
      "This article examines the characteristics of human errors in processing\ntransportation requests. The role of artificial intelligence (AI) in maritime\ntransportation is explored. The main methods and technologies used for\nautomating and optimizing the handling of transportation requests are analyzed,\nalong with their impact on reducing the number of errors. Examples of\nsuccessful AI implementation in large companies are provided, confirming the\npositive influence of these technologies on overall operational efficiency and\ncustomer service levels."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-46",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15988"
    ],
    "b_title":[
      "Rovibrational Overtone and Combination Bands of the HCNH+ Ion"
    ],
    "b_abstract":[
      "Spectra of vibrational overtone and combination bands from vibrational ground\nstate of HCNH+ were measured using an action spectroscopy technique with active\nbackground suppression in a cryogenic 22 pole radio frequency ion trap\napparatus. Spectroscopic constants for the upper vibrational levels of the\ntransitions were determined with vibrational band origins being 6846.77981(90)\n$\\text{cm}^{-1}$ ($2\\nu_1$ , NH stretch), 6640.47624(43) $\\text{cm}^{-1}$\n($\\nu_1 + \\nu_2$), 6282.03578(63) $\\text{cm}^{-1}$ ($2\\nu_2$, CH stretch), and\n6588.4894(20) $\\text{cm}^{-1}$ ($\\nu_2 + \\nu_3 + 2\\nu_5^0$). State of the art\nab initio VCI calculations up to 10000 $\\text{cm}^{-1}$ complement the\nexperimental data."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.16504"
    ],
    "c_title":[
      "Open-Source Tool for Evaluating Human-Generated vs. AI-Generated Medical\n  Notes Using the PDQI-9 Framework"
    ],
    "c_abstract":[
      "Background: The increasing use of artificial intelligence (AI) in healthcare\ndocumentation necessitates robust methods for evaluating the quality of\nAI-generated medical notes compared to those written by humans. This paper\nintroduces an open-source tool, the Human Notes Evaluator, designed to assess\nclinical note quality and differentiate between human and AI authorship.\nMethods: The Human Notes Evaluator is a Flask-based web application implemented\non Hugging Face Spaces. It employs the Physician Documentation Quality\nInstrument (PDQI-9), a validated 9-item rubric, to evaluate notes across\ndimensions such as accuracy, thoroughness, clarity, and more. The tool allows\nusers to upload clinical notes in CSV format and systematically score each note\nagainst the PDQI-9 criteria, as well as assess the perceived origin (human, AI,\nor undetermined). Results: The Human Notes Evaluator provides a user-friendly\ninterface for standardized note assessment. It outputs comprehensive results,\nincluding individual PDQI-9 scores for each criterion, origin assessments, and\noverall quality metrics. Exportable data facilitates comparative analyses\nbetween human and AI-generated notes, identification of quality trends, and\nareas for documentation improvement. The tool is available online at\nhttps:\/\/huggingface.co\/spaces\/iyadsultan\/human_evaluator . Discussion: This\nopen-source tool offers a valuable resource for researchers, healthcare\nprofessionals, and AI developers to rigorously evaluate and compare the quality\nof medical notes. By leveraging the PDQI-9 framework, it provides a structured\nand reliable approach to assess clinical documentation, contributing to the\nresponsible integration of AI in healthcare. The tool's availability on Hugging\nFace promotes accessibility and collaborative development in the field of\nAI-driven medical documentation."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-47",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08398"
    ],
    "b_title":[
      "Physically motivated analytic model of energy efficiency for EUV-driven\n  atmospheric escape of close-in exoplanets"
    ],
    "b_abstract":[
      "Extreme Ultraviolet (EUV) driven atmospheric escape is a key process in the\natmospheric evolution of close-in exoplanets. In many evolutionary models, the\nenergy-limited mass-loss rate with a constant efficiency (typically $\\sim10\\%$)\nis assumed for calculating the mass-loss rate. However, hydrodynamic\nsimulations have demonstrated that this efficiency depends on various stellar\nand planetary parameters. Comprehending the underlying physics of the\nefficiency is essential for understanding planetary atmospheric evolution and\nrecent observations of the upper atmosphere of close-in exoplanets. We\nintroduce relevant temperatures and timescales derived from physical principles\nto elucidate the mass-loss process. Our analytical mass-loss model is based on\nphenomenology and consistent across a range of planetary parameters. We compare\nour mass-loss efficiency and the radiation hydrodynamic simulations. The model\ncan predict efficiency in both energy-limited and recombination-limited\nregimes. We further apply our model to exoplanets observed with hydrogen\nabsorption (Ly$\\alpha$ and H$\\alpha$). Our findings suggest that Ly$\\alpha$\nabsorption is detectable in planets subjected to intermediate EUV flux; under\nthese conditions, the escaping outflow is insufficient in low-EUV environments,\nwhile the photoionization timescale remains short in high-EUV ranges.\nConversely, H$\\alpha$ absorption is detectable under high EUV flux conditions,\nfacilitated by the intense Ly$\\alpha$ flux exciting hydrogen atoms. According\nto our model, the non-detection of neutral hydrogen can be explained by a low\nmass-loss rate and is not necessarily due to stellar wind confinement or the\nabsence of a hydrogen-dominated atmosphere in many cases. This model assists in\nidentifying future observational targets and explicates the unusual absorption\ndetection\/non-detection patterns observed in recent studies."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02328"
    ],
    "c_title":[
      "Limited Effectiveness of LLM-based Data Augmentation for COVID-19\n  Misinformation Stance Detection"
    ],
    "c_abstract":[
      "Misinformation surrounding emerging outbreaks poses a serious societal\nthreat, making robust countermeasures essential. One promising approach is\nstance detection (SD), which identifies whether social media posts support or\noppose misleading claims. In this work, we finetune classifiers on COVID-19\nmisinformation SD datasets consisting of claims and corresponding tweets.\nSpecifically, we test controllable misinformation generation (CMG) using large\nlanguage models (LLMs) as a method for data augmentation. While CMG\ndemonstrates the potential for expanding training datasets, our experiments\nreveal that performance gains over traditional augmentation methods are often\nminimal and inconsistent, primarily due to built-in safeguards within LLMs. We\nrelease our code and datasets to facilitate further research on misinformation\ndetection and generation."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.HC",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-48",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08834"
    ],
    "b_title":[
      "Smart Contract Fuzzing Towards Profitable Vulnerabilities"
    ],
    "b_abstract":[
      "Billions of dollars are transacted through smart contracts, making\nvulnerabilities a major financial risk. One focus in the security arms race is\non profitable vulnerabilities that attackers can exploit. Fuzzing is a key\nmethod for identifying these vulnerabilities. However, current solutions face\ntwo main limitations: a lack of profit-centric techniques for expediting\ndetection, and insufficient automation in maximizing the profitability of\ndiscovered vulnerabilities, leaving the analysis to human experts. To address\nthese gaps, we have developed VERITE, a profit-centric smart contract fuzzing\nframework that not only effectively detects those profitable vulnerabilities\nbut also maximizes the exploited profits.\n  VERITE has three key features: 1) DeFi action-based mutators for boosting the\nexploration of transactions with different fund flows; 2) potentially\nprofitable candidates identification criteria, which checks whether the input\nhas caused abnormal fund flow properties during testing; 3) a gradient\ndescent-based profit maximization strategy for these identified candidates.\n  VERITE is fully developed from scratch and evaluated on a dataset consisting\nof 61 exploited real-world DeFi projects with an average of over 1.1 million\ndollars loss. The results show that VERITE can automatically extract more than\n18 million dollars in total and is significantly better than state-of-the-art\nfuzzer ITYFUZZ in both detection (29\/10) and exploitation (134 times more\nprofits gained on average). Remarkably, in 12 targets, it gains more profits\nthan real-world attacking exploits (1.01 to 11.45 times more). VERITE is also\napplied by auditors in contract auditing, where 6 (5 high severity) zero-day\nvulnerabilities are found with over $2,500 bounty rewards."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03076"
    ],
    "c_title":[
      "Non-Affine Extensions of the Raychaudhuri Equation in the K-essence\n  Framework"
    ],
    "c_abstract":[
      "The Raychaudhuri equation (RE) governs the evolution of geodesic congruences\nin curved spacetime. Here, we extend the classical RE by incorporating\nnon-affine parametrization within the framework of k-essence scalar field\ndynamics. The non-affine parametrization introduces deviations from purely\ngeodesic congruences (motion), allowing investigation of non-gravitational\ninteractions and external forces. Using a DBI-type k-essence Lagrangian, we\nanalyze the behavior of non-geodesic flow curves in the background FLRW metric,\nelucidating their role in cosmic acceleration and structure formation. The\nemergent metric formalism is used to derive a modified RE, revealing new\ngeometric and dynamical features induced by the k-essence field. The\ncosmological implications of our model are studied by constraining key\nparameters using observational data from the PANTHEON+SHOES+BAO and Hubble\ndatasets. Our results suggest that non-affine parametrization, coupled with\nk-essence dynamics, can provide a viable explanation for late-time cosmic\nacceleration while addressing the Hubble tension. Further, we reinterpret the\nmodified RE as an anti-damped harmonic oscillator, revealing quantum-like\neffects in cosmic expansion. These results suggest a deep connection between\nscalar field dynamics and modified gravity, offering new perspectives on the\nnature of the universe's expansion history."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-49",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05340"
    ],
    "b_title":[
      "Robust valuation and optimal harvesting of forestry resources in the\n  presence of catastrophe risk and parameter uncertainty"
    ],
    "b_abstract":[
      "We determine forest lease value and optimal harvesting strategies under model\nparameter uncertainty within stochastic bio-economic models that account for\ncatastrophe risk. Catastrophic events are modeled as a Poisson point process,\nwith a two-factor stochastic convenience yield model capturing the lumber spot\nprice dynamics. Using lumber futures and US wildfire data, we estimate model\nparameters through a Kalman filter and maximum likelihood estimation and define\nthe model parameter uncertainty set as the 95% confidence region. We\nnumerically determine the forest lease value under catastrophe risk and\nparameter uncertainty using reflected backward stochastic differential\nequations (RBSDEs) and establish conservative and optimistic bounds for lease\nvalues and optimal stopping boundaries for harvesting, facilitating Monte Carlo\nsimulations. Numerical experiments further explore how parameter uncertainty,\ncatastrophe intensity, and carbon sequestration impact the lease valuation and\nharvesting decision. In particular, we explore the costs arising from this form\nof uncertainty in the form of a reduction of the lease value. These are\nimplicit costs that can be attributed to climate risk and will be emphasized\nthrough the importance of forestry resources in the energy transition process.\nWe conclude that in the presence of parameter uncertainty, it is better to lean\ntoward a conservative strategy reflecting, to some extent, the worst case than\nbeing overly optimistic. Our results also highlight the critical role of\nconvenience yield in determining optimal harvesting strategies."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC",
        "q-fin.MF"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2503.05584"
    ],
    "c_title":[
      "QArtSR: Quantization via Reverse-Module and Timestep-Retraining in\n  One-Step Diffusion based Image Super-Resolution"
    ],
    "c_abstract":[
      "One-step diffusion-based image super-resolution (OSDSR) models are showing\nincreasingly superior performance nowadays. However, although their denoising\nsteps are reduced to one and they can be quantized to 8-bit to reduce the costs\nfurther, there is still significant potential for OSDSR to quantize to lower\nbits. To explore more possibilities of quantized OSDSR, we propose an efficient\nmethod, Quantization via reverse-module and timestep-retraining for OSDSR,\nnamed QArtSR. Firstly, we investigate the influence of timestep value on the\nperformance of quantized models. Then, we propose Timestep Retraining\nQuantization (TRQ) and Reversed Per-module Quantization (RPQ) strategies to\ncalibrate the quantized model. Meanwhile, we adopt the module and image losses\nto update all quantized modules. We only update the parameters in quantization\nfinetuning components, excluding the original weights. To ensure that all\nmodules are fully finetuned, we add extended end-to-end training after\nper-module stage. Our 4-bit and 2-bit quantization experimental results\nindicate that QArtSR obtains superior effects against the recent leading\ncomparison methods. The performance of 4-bit QArtSR is close to the\nfull-precision one. Our code will be released at\nhttps:\/\/github.com\/libozhu03\/QArtSR."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-50",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12882"
    ],
    "b_title":[
      "Efficient classical algorithms for linear optical circuits"
    ],
    "b_abstract":[
      "We present efficient classical algorithms to approximate expectation values\nand probability amplitudes in linear optical circuits. Specifically, our\nclassical algorithm efficiently approximates the expectation values of\nobservables in linear optical circuits for arbitrary product input states\nwithin an additive error under a mild condition. This result suggests that\ncertain applications of linear optical circuits relying on expectation value\nestimation, such as photonic variational algorithms, may face challenges in\nachieving quantum advantage. In addition, the (marginal) output probabilities\nof boson sampling with arbitrary product input states can be efficiently\napproximated using our algorithm, implying that boson sampling can be\nefficiently simulated if its output probability distribution is polynomially\nsparse. Moreover, our method generalizes Gurvits's algorithm, originally\ndesigned to approximate the permanent, to also approximate the hafnian of\ncomplex symmetric matrices with an additive error. The algorithm also solves a\nmolecular vibronic spectra problem for arbitrary product input states as\nprecisely as boson samplers. Finally, our method extends to near-Clifford\ncircuits, enabling the classical approximation of their expectation values of\nany observables and (marginal) output probabilities."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02692"
    ],
    "c_title":[
      "Dynamical localization and eigenvalue asymptotics: long-range hopping\n  lattice operators with electric field"
    ],
    "c_abstract":[
      "We prove that for polynomial long-range hopping lattice operators with\nuniform electric field under any bounded perturbation, the semi-uniform\npolynomial decay of the eigenfunctions is determined by the asymptotic behavior\nof the eigenvalues, and conversely. Consequently, we recover and refine recent\nresults on power-law dynamical localization for this model. In this paper, to\nprove these results, we develop new arguments to deal with singularities in\nobtaining the semi-uniform polynomial decay of eigenfunctions, prove an\nindependent result on the asymptotic behavior of eigenvalues for discrete\noperators, revisit a notion of Power-Law SULE, and utilize a known perturbation\nresult on localization, proved through the KAM method. Unlike existing results\nin the literature, our approach does not rely on the specific form of the\neigenfunctions, but rather the asymptotic behavior of the eigenvalues and the\npotential. It is worth underlining that our general results can be applied to\nother models such as Maryland-type potentials."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.CA",
        "math.FA",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-51",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07547"
    ],
    "b_title":[
      "Instance-dependent Early Stopping"
    ],
    "b_abstract":[
      "In machine learning practice, early stopping has been widely used to\nregularize models and can save computational costs by halting the training\nprocess when the model's performance on a validation set stops improving.\nHowever, conventional early stopping applies the same stopping criterion to all\ninstances without considering their individual learning statuses, which leads\nto redundant computations on instances that are already well-learned. To\nfurther improve the efficiency, we propose an Instance-dependent Early Stopping\n(IES) method that adapts the early stopping mechanism from the entire training\nset to the instance level, based on the core principle that once the model has\nmastered an instance, the training on it should stop. IES considers an instance\nas mastered if the second-order differences of its loss value remain within a\nsmall range around zero. This offers a more consistent measure of an instance's\nlearning status compared with directly using the loss value, and thus allows\nfor a unified threshold to determine when an instance can be excluded from\nfurther backpropagation. We show that excluding mastered instances from\nbackpropagation can increase the gradient norms, thereby accelerating the\ndecrease of the training loss and speeding up the training process. Extensive\nexperiments on benchmarks demonstrate that IES method can reduce\nbackpropagation instances by 10%-50% while maintaining or even slightly\nimproving the test accuracy and transfer learning performance of a model."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13244"
    ],
    "c_title":[
      "Applying a star formation model calibrated on high-resolution\n  interstellar medium simulations to cosmological simulations of galaxy\n  formation"
    ],
    "c_abstract":[
      "Modern high-resolution simulations of the interstellar medium (ISM) have\nshown that key factors in governing star formation are the competing influences\nof radiative dissipation, pressure support driven by stellar feedback, and the\nrelentless pull of gravity. Cosmological simulations of galaxy formation, such\nas IllustrisTNG or ASTRID, are however not able to resolve this physics in\ndetail and therefore need to rely on approximate treatments. These have often\ntaken the form of empirical subgrid models of the ISM expressed in terms of an\neffective equation of state (EOS) that relates the mean ISM pressure to the\nmean gas density. Here we seek to improve these heuristic models by directly\nfitting their key ingredients to results of the high-resolution TIGRESS\nsimulations, which have shown that the dynamical equilibrium of the ISM can be\nunderstood in terms of a pressure-regulated, feedback modulated (PRFM) model\nfor star formation. Here we explore a simple subgrid model that draws on the\nPRFM concept but uses only local quantities. It accurately reproduces PRFM for\npure gas disks, while it predicts slightly less star formation than PRFM in the\npresence of an additional thin stellar disk. We compare the properties of this\nmodel with the older Springel and Hernquist and TNG prescriptions, and apply\nall three to isolated simulations of disk galaxies as well as to a set of\nhigh-resolution zoom-in simulations carried out with a novel 'multi-zoom'\ntechnique that we introduce in this study. The softer EOS implied by TIGRESS\nproduces substantially thinner disk galaxies, which has important ramifications\nfor disk stability and galaxy morphology. The total stellar mass of galaxies is\nhowever hardly modified at low redshift, reflecting the dominating influence of\nlarge-scale gaseous inflows and outflows to galaxies, which are not sensitive\nto the EOS itself"
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-52",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15786"
    ],
    "b_title":[
      "Chocolate Games with a Pass"
    ],
    "b_abstract":[
      "The authors present their research on chocolate games with a pass-move.\nChocolate games are generalizations of Nim. In this work, we modify the\nstandard rules of the game to allow a one-time pass; that is, a pass-move may\nbe used at most once in the game, but not from a terminal position. Once the\npass has been used by either player, it is no longer available. In the case of\nthe classical three-pile nim with $x,y,z$ for the number of stones of each\npile, the previous player wins when the ``exclusive or'' of $x,y,z$ is $0$, and\nits Grundy number is calculated as ``exclusive or'' of $x,y,z$. However, no\nmathematical formula is known for the previous player's winning position when a\npass-move is allowed. In this study, we show a theorem to determine the Grundy\nnumber of a position with a pass where the position can be considered as a\ndisjunctive sum of two positions which have a special property. By using the\ntheorem, we show closed formulas for positions which have Grundy numbers $0,\n1,$ and $2$ for some chocolate games with a pass."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.06093"
    ],
    "c_title":[
      "DeepMill: Neural Accessibility Learning for Subtractive Manufacturing"
    ],
    "c_abstract":[
      "Manufacturability is vital for product design and production, with\naccessibility being a key element, especially in subtractive manufacturing.\nTraditional methods for geometric accessibility analysis are time-consuming and\nstruggle with scalability, while existing deep learning approaches in\nmanufacturability analysis often neglect geometric challenges in accessibility\nand are limited to specific model types. In this paper, we introduce DeepMill,\nthe first neural framework designed to accurately and efficiently predict\ninaccessible and occlusion regions under varying machining tool parameters,\napplicable to both CAD and freeform models. To address the challenges posed by\ncutter collisions and the lack of extensive training datasets, we construct a\ncutter-aware dual-head octree-based convolutional neural network (O-CNN) and\ngenerate an inaccessible and occlusion regions analysis dataset with a variety\nof cutter sizes for network training. Experiments demonstrate that DeepMill\nachieves 94.7% accuracy in predicting inaccessible regions and 88.7% accuracy\nin identifying occlusion regions, with an average processing time of 0.04\nseconds for complex geometries. Based on the outcomes, DeepMill implicitly\ncaptures both local and global geometric features, as well as the complex\ninteractions between cutters and intricate 3D models."
    ],
    "c_categories":[
      [
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-53",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11159"
    ],
    "b_title":[
      "Contributions of $\\rho(770,1450)\\to \\omega\\pi$ for the Cabibbo-favored\n  $D \\to h\\omega\\pi$ decays"
    ],
    "b_abstract":[
      "Recently, the BESIII Collaboration has observed three-body decays $D_s^+\\to\n\\eta \\omega\\pi^+$, $D^+\\to K^0_S\\pi^+\\omega$ and $D^0\\to K^-\\pi^+\\omega$. In\nthis work, we investigate the contributions of the subprocesses $\\rho^+\\to\n\\omega\\pi^+$ in these Cabibbo-favored decays $D \\to h\\omega\\pi$, with $\\rho^+=\n\\{\\rho(770)^+, \\rho(1450)^+, \\rho(770)^+\\&\\rho(1450)^+\\}$ and $h=\\{ \\eta,\nK^0_S, K^-\\}$, by introducing these subprocesses into the decay amplitudes of\nthe relevant decay processes via the vector form factor $F_{\\omega\\pi}$\nmeasured in the related $\\tau$ and $e^+e^-$ processes; we provide the first\ntheoretical predictions for the branching fractions of the quasi-two-body\ndecays $D_s^+\\to\\eta[\\rho^+\\to]\\omega\\pi^+$, $D^+\\to\nK^0_S[\\rho^+\\to]\\omega\\pi^+$ and $D^0\\to K^-[\\rho^+\\to]\\omega\\pi^+$. Our\nfindings reveal that the contributions from the subprocess\n$\\rho(770)^+\\to\\omega\\pi^+$ are significant in these observed three-body decays\n$D_s^+\\to\\eta \\omega\\pi^+$, $D^+\\to K^0_S \\omega\\pi^+$ and $D^0\\to K^-\n\\omega\\pi^+$, notwithstanding the contributions originating from the\nBreit-Wigner tail effect of $\\rho(770)^+$. The numerical results of this study\nsuggest that these Cabibbo-favored three-body decays are dominated by the\ncontributions come from the $P$-wave intermediate states $\\rho(770)^+$,\n$\\rho(1450)^+$ and their interference effects."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08092"
    ],
    "c_title":[
      "Chromatic Higher Semiadditivity by Height Induction"
    ],
    "c_abstract":[
      "We give a new proof of the $\\infty$-semiadditivity of $K(n)$-local spectra.\nThe proof proceeds by induction on the height via algebraic K-theory, utilizing\nrecent advances in chromatic homotopy theory and the redshift conjecture,\ninstead of using the Ravenel-Wilson computation of the Morava K-theory of\nEilenberg-MacLane spaces."
    ],
    "c_categories":[
      [
        "math.AT",
        "math.KT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-54",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14312"
    ],
    "b_title":[
      "Modelling Capillary Rise with a Slip Boundary Condition: Well-posedness\n  and Long-time Dynamics of Solutions to Washburn's Equation"
    ],
    "b_abstract":[
      "The aim of this paper is to extend Washburn's capillary rise equation by\nincorporating a slip condition at the pipe wall. The governing equation is\nderived using fundamental principles from continuum mechanics. A new scaling is\nintroduced, allowing for a systematic analysis of different flow regimes. We\nprove the global-in-time existence and uniqueness of a bounded positive\nsolution to Washburn's equation that includes the slip parameter, as well as\nthe continuous dependence of the solution in the maximum norm on the initial\ndata. Thus, the initial-value problem for Washburn's equation is shown to be\nwell-posed in the sense of Hadamard. Additionally, we show that the unique\nequilibrium solution may be reached either monotonically or in an oscillatory\nfashion, similarly to the no-slip case. Finally, we determine the basin of\nattraction for the system, ensuring that the equilibrium state will be reached\nfrom the initial data we impose. These results hold for any positive value of\nthe nondimensional slip parameter in the model, and for all values of the ratio\n$h_0\/h_e$ in the range $[0,3\/2]$, where $h_0$ is the initial height of the\nfluid column and $h_e$ is its equilibrium height."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.AP",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.12608"
    ],
    "c_title":[
      "UniBERTs: Adversarial Training for Language-Universal Representations"
    ],
    "c_abstract":[
      "This paper presents UniBERT, a compact multilingual language model that\nleverages an innovative training framework integrating three components: masked\nlanguage modeling, adversarial training, and knowledge distillation.\nPre-trained on a meticulously curated Wikipedia corpus spanning 107 languages,\nUniBERT is designed to reduce the computational demands of large-scale models\nwhile maintaining competitive performance across various natural language\nprocessing tasks. Comprehensive evaluations on four tasks -- named entity\nrecognition, natural language inference, question answering, and semantic\ntextual similarity -- demonstrate that our multilingual training strategy\nenhanced by an adversarial objective significantly improves cross-lingual\ngeneralization. Specifically, UniBERT models show an average relative\nimprovement of 7.72% over traditional baselines, which achieved an average\nrelative improvement of only 1.17%, with statistical analysis confirming the\nsignificance of these gains (p-value = 0.0181). This work highlights the\nbenefits of combining adversarial training and knowledge distillation to build\nscalable and robust language models, thereby advancing the field of\nmultilingual and cross-lingual natural language processing."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-55",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19238"
    ],
    "b_title":[
      "Correlations drive the attosecond response of strongly-correlated\n  insulators"
    ],
    "b_abstract":[
      "Attosecond spectroscopy of materials has provided invaluable insight into\nlight-driven coherent electron dynamics. However, attosecond spectroscopies\nhave so far been focused on weakly-correlated materials. As a result, the\nbehavior of strongly-correlated systems is largely unknown at sub- to\nfew-femtosecond timescales, even though it is typically the realm at which\nelectron-electron interactions operate. Here we conduct attosecond-resolved\nexperiments on the correlated insulator nickel oxide, and compare its response\nto a common band insulator, revealing fundamentally different behaviors. The\nresults, together with state-of-the art time-dependent $\\textit{ab initio}$\ncalculations, show that the correlated system response is governed by a\nlaser-driven quench of electron correlations. The evolution of the on-site\nelectronic interaction is measured here at its natural timescale, marking the\nfirst direct measurement of Hubbard $U$ renormalization in NiO. It is found to\ntake place within a few femtoseconds, after which structural changes slowly\nstart to take place. The resulting picture sheds light on the entire\nlight-induced response of a strongly-correlated system, from attosecond to\nlong-lived effects."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12842"
    ],
    "c_title":[
      "Heavy-tailed random vectros: theory and applications"
    ],
    "c_abstract":[
      "In this paper we introduce and study several multivariate, heavy-tailed\ndistribution classes, and we explore their closure properties and their\napplications. We consider the class of multivariate, positively decreasing\ndistributions, and its intersection with other multivariate distribution\nclasses."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-56",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03476"
    ],
    "b_title":[
      "Achieve equilibrium outside the contact angle hysteresis"
    ],
    "b_abstract":[
      "It is common belief that the equilibrium contact angle, corresponding to the\nminimum system energy state, lies between advancing and receding contact\nangles. Here, we derive advancing and receding contact angles considering the\nmicro contacting processes on ideal rough 2D surfaces. Equilibrium contact\nangles obtained via energy minimization can be smaller than the receding\ncontact angle and reach 0 degrees, at which hysteresis diminishes on the\nsuper-hydrophilic surface. Gibbs free energy analyses, numerical simulations\nand physical experiments all confirm these new findings."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03121"
    ],
    "c_title":[
      "Distributed and heterogeneous tensor-vector contraction algorithms for\n  high performance computing"
    ],
    "c_abstract":[
      "The tensor-vector contraction (TVC) is the most memory-bound operation of its\nclass and a core component of the higher-order power method (HOPM). This paper\nbrings distributed-memory parallelization to a native TVC algorithm for dense\ntensors that overall remains oblivious to contraction mode, tensor splitting\nand tensor order. Similarly, we propose a novel distributed HOPM, namely\ndHOPM3, that can save up to one order of magnitude of streamed memory and is\nabout twice as costly in terms of data movement as a distributed TVC operation\n(dTVC) when using task-based parallelization. The numerical experiments carried\nout in this work on three different architectures featuring multi-core and\naccelerators confirm that the performances of dTVC and dHOPM3 remain relatively\nclose to the peak system memory bandwidth (50%-80%, depending on the\narchitecture) and on par with STREAM benchmark figures. On strong scalability\nscenarios, our native multi-core implementations of these two algorithms can\nachieve similar and sometimes even greater performance figures than those based\nupon state-of-the-art CUDA batched kernels. Finally, we demonstrate that both\ncomputation and communication can benefit from mixed precision arithmetic also\nin cases where the hardware does not support low precision data types natively."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-57",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14665"
    ],
    "b_title":[
      "These Magic Moments: Differentiable Uncertainty Quantification of\n  Radiance Field Models"
    ],
    "b_abstract":[
      "This paper introduces a novel approach to uncertainty quantification for\nradiance fields by leveraging higher-order moments of the rendering equation.\nUncertainty quantification is crucial for downstream tasks including view\nplanning and scene understanding, where safety and robustness are paramount.\nHowever, the high dimensionality and complexity of radiance fields pose\nsignificant challenges for uncertainty quantification, limiting the use of\nthese uncertainty quantification methods in high-speed decision-making. We\ndemonstrate that the probabilistic nature of the rendering process enables\nefficient and differentiable computation of higher-order moments for radiance\nfield outputs, including color, depth, and semantic predictions. Our method\noutperforms existing radiance field uncertainty estimation techniques while\noffering a more direct, computationally efficient, and differentiable\nformulation without the need for post-processing. Beyond uncertainty\nquantification, we also illustrate the utility of our approach in downstream\napplications such as next-best-view (NBV) selection and active ray sampling for\nneural radiance field training. Extensive experiments on synthetic and\nreal-world scenes confirm the efficacy of our approach, which achieves\nstate-of-the-art performance while maintaining simplicity."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17189"
    ],
    "c_title":[
      "Bayesian optimisation of poloidal field coil positions in tokamaks"
    ],
    "c_abstract":[
      "The tokamak is a world-leading concept for producing sustainable energy via\nmagnetically-confined nuclear fusion. Identifying where to position the magnets\nwithin a tokamak, specifically the poloidal field (PF) coils, is a design\nproblem which requires balancing a number of competing economic, physical, and\nengineering objectives and constraints. In this paper, we show that\nmulti-objective Bayesian optimisation (BO), an iterative optimisation technique\nutilising probabilistic machine learning models, can effectively explore this\ncomplex design space and return several optimal PF coil sets. These solutions\nspan the Pareto front, a subset of the objective space that optimally satisfies\nthe specified objective functions. We outline an easy-to-use BO framework and\ndemonstrate that it outperforms alternative optimisation techniques while using\nsignificantly fewer computational resources. Our results show that BO is a\npromising technique for fusion design problems that rely on computationally\ndemanding high-fidelity simulations."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-58",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03974"
    ],
    "b_title":[
      "Cryptographic Verifiability for Voter Registration Systems"
    ],
    "b_abstract":[
      "Voter registration systems are a critical - and surprisingly understudied -\nelement of most high-stakes elections. Despite a history of targeting by\nadversaries, relatively little academic work has been done to increase\nvisibility into how voter registration systems keep voters' data secure,\naccurate, and up to date. Enhancing transparency and verifiability could help\nelection officials and the public detect and mitigate risks to this essential\ncomponent of electoral processes worldwide.\n  This work introduces cryptographic verifiability for voter registration\nsystems. Based on consultation with diverse expert stakeholders that support\nelections systems, we precisely define the requirements for cryptographic\nverifiability in voter registration and systematize the practical challenges\nthat must be overcome for near-term deployment.\n  We then introduce VRLog, the first system to bring strong verifiability to\nvoter registration. VRLog enables election officials to provide a transparent\nlog that (1) allows voters to verify that their registration data has not been\ntampered with and (2) allows the public to monitor update patterns and database\nconsistency. We also introduce VRLog$^x$, an enhancement to VRLog that offers\ncryptographic privacy to voter deduplication between jurisdictions - a common\nmaintenance task currently performed in plaintext or using trusted third\nparties. Our designs rely on standard, efficient cryptographic primitives, and\nare backward compatible with existing voter registration systems. Finally, we\nprovide an open-source implementation of VRLog and benchmarks to demonstrate\nthat the system is practical - capable of running on low-cost commodity\nhardware and scaling to support databases the size of the largest U.S. state\nvoter registration systems."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12243"
    ],
    "c_title":[
      "FOCUS: First Order Concentrated Updating Scheme"
    ],
    "c_abstract":[
      "Large language models (LLMs) demonstrate remarkable performance, and\nimproving their pre-training process appears to be key to enhancing their\ncapabilities further. Based on the documented success of Adam, learning rate\ndecay, and weight decay, we hypothesize that the pre-training loss landscape\nfeatures a narrowing valley structure. Through experiments with synthetic loss\nfunctions, we discover that when gradient query noise is high relative to the\nvalley's sharpness, Adam's performance falls behind that of Signum because Adam\nreduces the effective step size too drastically. This observation led us to\ndevelop FOCUS, an optimizer that enhances Signum by incorporating attraction\ntoward moving averaged parameters, allowing it to handle noise better while\nmaintaining larger step sizes. In training GPT-2, FOCUS proves to be more\nstable than Signum and faster than Adam. These results suggest that gradient\nnoise may be an underappreciated limiting factor in LLM training, and FOCUS\noffers promising solutions."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-59",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07036"
    ],
    "b_title":[
      "Automated Consistency Analysis of LLMs"
    ],
    "b_abstract":[
      "Generative AI (Gen AI) with large language models (LLMs) are being widely\nadopted across the industry, academia and government. Cybersecurity is one of\nthe key sectors where LLMs can be and\/or are already being used. There are a\nnumber of problems that inhibit the adoption of trustworthy Gen AI and LLMs in\ncybersecurity and such other critical areas. One of the key challenge to the\ntrustworthiness and reliability of LLMs is: how consistent an LLM is in its\nresponses? In this paper, we have analyzed and developed a formal definition of\nconsistency of responses of LLMs. We have formally defined what is consistency\nof responses and then develop a framework for consistency evaluation. The paper\nproposes two approaches to validate consistency: self-validation, and\nvalidation across multiple LLMs. We have carried out extensive experiments for\nseveral LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a\nsecurity benchmark consisting of several cybersecurity questions: informational\nand situational. Our experiments corroborate the fact that even though these\nLLMs are being considered and\/or already being used for several cybersecurity\ntasks today, they are often inconsistent in their responses, and thus are\nuntrustworthy and unreliable for cybersecurity."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15956"
    ],
    "c_title":[
      "Solutions of first passage times problems: a biscaling approach"
    ],
    "c_abstract":[
      "We study the first-passage time (FPT) problem for widespread recurrent\nprocesses in confined though large systems and present a comprehensive\nframework for characterizing the FPT distribution over many time scales. We\nfind that the FPT statistics can be described by two scaling functions: one\ncorresponds to the solution for an infinite system, and the other describes a\nscaling that depends on system size. We find a universal scaling relationship\nfor the FPT moments $\\langle t^q \\rangle$ with respect to the domain size and\nthe source-target distance. This scaling exhibits a transition at $q_c=\\theta$,\nwhere $\\theta$ is the persistence exponent. For low-order moments with $q<q_c$,\nconvergence occurs towards the moments of an infinite system. In contrast, the\nhigh-order moments, $q>q_c$, can be derived from an infinite density function.\nThe presented uniform approximation, connecting the two scaling functions,\nprovides a description of the first-passage time statistics across all time\nscales. We extend the results to include diffusion in a confining potential in\nthe high-temperature limit, where the potential strength takes the place of the\nsystem's size as the relevant scale. This study has been applied to various\nmediums, including a particle in a box, two-dimensional wedge, fractal\ngeometries, non-Markovian processes and the non-equilibrium process of\nresetting."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-60",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08397"
    ],
    "b_title":[
      "Strong bounds for large-scale Minimum Sum-of-Squares Clustering"
    ],
    "b_abstract":[
      "Clustering is a fundamental technique in data analysis and machine learning,\nused to group similar data points together. Among various clustering methods,\nthe Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used.\nMSSC aims to minimize the total squared Euclidean distance between data points\nand their corresponding cluster centroids. Due to the unsupervised nature of\nclustering, achieving global optimality is crucial, yet computationally\nchallenging. The complexity of finding the global solution increases\nexponentially with the number of data points, making exact methods impractical\nfor large-scale datasets. Even obtaining strong lower bounds on the optimal\nMSSC objective value is computationally prohibitive, making it difficult to\nassess the quality of heuristic solutions. We address this challenge by\nintroducing a novel method to validate heuristic MSSC solutions through\noptimality gaps. Our approach employs a divide-and-conquer strategy,\ndecomposing the problem into smaller instances that can be handled by an exact\nsolver. The decomposition is guided by an auxiliary optimization problem, the\n\"anticlustering problem\", for which we design an efficient heuristic.\nComputational experiments demonstrate the effectiveness of the method for\nlarge-scale instances, achieving optimality gaps below 3% in most cases while\nmaintaining reasonable computational times. These results highlight the\npracticality of our approach in assessing feasible clustering solutions for\nlarge datasets, bridging a critical gap in MSSC evaluation."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16293"
    ],
    "c_title":[
      "Lepton number violating\/conserving heavy baryons four-body decays, in\n  presence of two almost degenerated heavy neutrinos"
    ],
    "c_abstract":[
      "We study the four-body heavy baryon decay, including two leptons in the final\nstate, of the form $B_A \\to B_B P \\ell_\\alpha \\ell_\\beta$, which can be either\na lepton number conserving (LNC) or a lepton number violating (LNV) process\n(where $B$, $P$ and $\\ell$ are baryons, pseudoscalar mesons and leptons,\nrespectively), including all kinematic allowed lepton pair possibilities. We\nwork beyond the simplified assumption of a single heavy Majorana neutrino\nmixing with the active sector, considering potential interference effects when\nincluding two nearly degenerate heavy Majorana neutrinos. Particularly, we\nprovide a first estimate of the decay channels involving different flavors for\nthe external leptons (e.g., muon-tau), and elaborate on the interference\npattern due to leptons exchange. We show that the results for the two heavy\nalmost degenerate neutrinos can be recast into a single Majorana neutrino, and\nexhibit the features for both the LNC and LNV scenarios. We determine the\npotential exclusion region for the mass and heavy-light mixing parameters, of\nthe neutrinos driving the decay, including finite size detector effects. We\nalso obtain the Branching ratio as a function of the heavy neutrino mass for\nthe current upper limit of the heavy-light mixings."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-61",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05712"
    ],
    "b_title":[
      "Multi-Step Reasoning in Korean and the Emergent Mirage"
    ],
    "b_abstract":[
      "We introduce HRMCR (HAE-RAE Multi-Step Commonsense Reasoning), a benchmark\ndesigned to evaluate large language models' ability to perform multi-step\nreasoning in culturally specific contexts, focusing on Korean. The questions\nare automatically generated via templates and algorithms, requiring LLMs to\nintegrate Korean cultural knowledge into sequential reasoning steps. Consistent\nwith prior observations on emergent abilities, our experiments reveal that\nmodels trained on fewer than \\(2 \\cdot 10^{25}\\) training FLOPs struggle to\nsolve any questions, showing near-zero performance. Beyond this threshold,\nperformance improves sharply. State-of-the-art models (e.g., O1) still score\nunder 50\\%, underscoring the difficulty of our tasks. Notably, stepwise\nanalysis suggests the observed emergent behavior may stem from compounding\nerrors across multiple steps rather than reflecting a genuinely new capability.\nWe publicly release the benchmark and commit to regularly updating the dataset\nto prevent contamination."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14982"
    ],
    "c_title":[
      "The connective KO theory of the Eilenberg-MacLane space K(Z\/2,2)"
    ],
    "c_abstract":[
      "We compute ko_*(K(Z\/2,2)) and ko^*(K(Z\/2,2)), the connective KO-homology and\n-cohomology of the mod 2 Eilenberg-MacLane space K(Z\/2,2), using the Adams\nspectral sequence. The work relies heavily on work done several years earlier\nfor the (complex) ku groups by the author and W.S.Wilson. We illustrate an\ninteresting duality relation between the ko-homology and -cohomology groups. We\ndeduce a new result about Stiefel-Whitney classes in Spin manifolds."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-62",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05469"
    ],
    "b_title":[
      "The largest subcritical component in inhomogeneous random graphs of\n  preferential attachment type"
    ],
    "b_abstract":[
      "We identify the size of the largest connected component in a subcritical\ninhomogeneous random graph with a kernel of preferential attachment type. The\ncomponent is polynomial in the graph size with an explicitly given exponent,\nwhich is strictly larger than the exponent for the largest degree in the graph.\nThis is in stark contrast to the behaviour of inhomogeneous random graphs with\na kernel of rank one. Our proof uses local approximation by branching random\nwalks going well beyond the weak local limit and novel results on subcritical\nkilled branching random walks."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20492"
    ],
    "c_title":[
      "Neuromorphic Circuits with Spiking Astrocytes for Increased Energy\n  Efficiency, Fault Tolerance, and Memory Capacitance"
    ],
    "c_abstract":[
      "In the rapidly advancing field of neuromorphic computing, integrating\nbiologically-inspired models like the Leaky Integrate-and-Fire Astrocyte (LIFA)\ninto spiking neural networks (SNNs) enhances system robustness and performance.\nThis paper introduces the LIFA model in SNNs, addressing energy efficiency,\nmemory management, routing mechanisms, and fault tolerance. Our core\narchitecture consists of neurons, synapses, and astrocyte circuits, with each\nastrocyte supporting multiple neurons for self-repair. This clustered model\nimproves fault tolerance and operational efficiency, especially under adverse\nconditions. We developed a routing methodology to map the LIFA model onto a\nfault-tolerant, many-core design, optimizing network functionality and\nefficiency. Our model features a fault tolerance rate of 81.10\\% and a\nresilience improvement rate of 18.90\\%, significantly surpassing other\nimplementations. The results validate our approach in memory management,\nhighlighting its potential as a robust solution for advanced neuromorphic\ncomputing applications. The integration of astrocytes represents a significant\nadvancement, setting the stage for more resilient and adaptable neuromorphic\nsystems."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-63",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05114"
    ],
    "b_title":[
      "The ESO SupJup Survey V: Exploring Atmospheric Variability and Orbit of\n  the Super-Jupiter AB Pictoris b with CRIRES+"
    ],
    "b_abstract":[
      "A growing number of directly-imaged companions have been recently\ncharacterised, with robust constraints on carbon-to-oxygen ratios and even\nisotopic ratios. Many companions and isolated targets have also shown spectral\nvariability. In this work we observed the super-Jupiter AB~Pictoris~b across\nfour consecutive nights using VLT\/CRIRES+ as part of the ESO SupJup survey,\nexploring how the constraints on chemical composition and temperature profile\nchange over time using spectral line shape variations between nights. We\nperformed atmospheric retrievals of the high-resolution observations and found\nbroadly consistent results across all four nights, but there were differences\nfor some parameters. We clearly detect H$_2$O, $^{12}$CO and $^{13}$CO in each\nnight, but abundances varied by $\\sim2\\sigma$, which was correlated to the deep\natmosphere temperature profiles. We also found differences in the\n$^{12}$C$\/^{13}$C ratios in each night by up to $\\sim3\\sigma$, which seemed to\nbe correlated with the cloud deck pressure. Our combined retrieval\nsimultaneously analysing all nights together constrained broadly the average of\neach night individually, with the C\/O$=0.59\\pm0.01$, consistent with solar\ncomposition, and $^{12}$C$\/^{13}$C~$ = 102\\pm8$, slightly higher than the ISM\nand Solar System values. We also find a low projected rotational velocity,\nsuggesting that AB~Pictoris~b is either intrinsically a slow rotator due to its\nyoung age or that the spin axis is observed pole-on with a $\\sim90^\\circ$\nmisalignment with its orbit inclination. Future observations will be able to\nfurther explore the variability and orbit of AB~Pictoris~b as well as for other\ncompanions."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.07197"
    ],
    "c_title":[
      "Effective and Efficient Masked Image Generation Models"
    ],
    "c_abstract":[
      "Although masked image generation models and masked diffusion models are\ndesigned with different motivations and objectives, we observe that they can be\nunified within a single framework. Building upon this insight, we carefully\nexplore the design space of training and sampling, identifying key factors that\ncontribute to both performance and efficiency. Based on the improvements\nobserved during this exploration, we develop our model, referred to as eMIGM.\nEmpirically, eMIGM demonstrates strong performance on ImageNet generation, as\nmeasured by Fr\\'echet Inception Distance (FID). In particular, on ImageNet\n256x256, with similar number of function evaluations (NFEs) and model\nparameters, eMIGM outperforms the seminal VAR. Moreover, as NFE and model\nparameters increase, eMIGM achieves performance comparable to the\nstate-of-the-art continuous diffusion models while requiring less than 40% of\nthe NFE. Additionally, on ImageNet 512x512, with only about 60% of the NFE,\neMIGM outperforms the state-of-the-art continuous diffusion models. Code is\navailable at https:\/\/github.com\/ML-GSAI\/eMIGM."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-64",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12995"
    ],
    "b_title":[
      "Frobenius method for Mahler equations"
    ],
    "b_abstract":[
      "Using Hahn series, one can attach to any linear Mahler equation a basis of\nsolutions at 0 reminiscent of the solutions of linear differential equations at\na regular singularity. We show that such a basis of solutions can be produced\nby using a variant of Frobenius method."
    ],
    "b_categories":[
      [
        "cs.SC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06846"
    ],
    "c_title":[
      "On the eternal non-Markovianity of qubit maps"
    ],
    "c_abstract":[
      "As is well known, unital Pauli maps can be eternally non-CP-divisible. In\ncontrast, here we show that in the case of non-unital maps, eternal\nnon-Markovianity in the non-unital part is ruled out. In the unital case, the\neternal non-Markovianity can be obtained by a convex combination of two\ndephasing semigroups, but not all three of them. We study these results and the\nramifications arising from them."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-65",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04364"
    ],
    "b_title":[
      "Lost in Edits? A $\\lambda$-Compass for AIGC Provenance"
    ],
    "b_abstract":[
      "Recent advancements in diffusion models have driven the growth of text-guided\nimage editing tools, enabling precise and iterative modifications of\nsynthesized content. However, as these tools become increasingly accessible,\nthey also introduce significant risks of misuse, emphasizing the critical need\nfor robust attribution methods to ensure content authenticity and traceability.\nDespite the creative potential of such tools, they pose significant challenges\nfor attribution, particularly in adversarial settings where edits can be\nlayered to obscure an image's origins. We propose LambdaTracer, a novel\nlatent-space attribution method that robustly identifies and differentiates\nauthentic outputs from manipulated ones without requiring any modifications to\ngenerative or editing pipelines. By adaptively calibrating reconstruction\nlosses, LambdaTracer remains effective across diverse iterative editing\nprocesses, whether automated through text-guided editing tools such as\nInstructPix2Pix and ControlNet or performed manually with editing software such\nas Adobe Photoshop. Extensive experiments reveal that our method consistently\noutperforms baseline approaches in distinguishing maliciously edited images,\nproviding a practical solution to safeguard ownership, creativity, and\ncredibility in the open, fast-evolving AI ecosystems."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20206"
    ],
    "c_title":[
      "On the Glivenko-Cantelli theorem for real-valued empirical functions of\n  stationary $\\alpha$-mixing and $\\beta$-mixing sequences"
    ],
    "c_abstract":[
      "In this paper we extend the classical Glivenko-Cantelli theorem to\nreal-valued empirical functions under dependence structures characterised by\n$\\alpha$-mixing and $\\beta$-mixing conditions. We investigate sufficient\nconditions ensuring that families of real-valued functions exhibit the\nGlivenko-Cantelli (GC) property in these dependence settings. Our analysis\nfocuses on function classes satisfying uniform entropy conditions and\nestablishes deviation bounds under mixing coefficients that decay at\nappropriate rates. Our results refine the existing literature by relaxing the\nindependence assumptions and highlighting the role of dependence in empirical\nprocess convergence."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-66",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03145"
    ],
    "b_title":[
      "Geometry Restoration and Dewarping of Camera-Captured Document Images"
    ],
    "b_abstract":[
      "This research focuses on developing a method for restoring the topology of\ndigital images of paper documents captured by a camera, using algorithms for\ndetection, segmentation, geometry restoration, and dewarping. Our methodology\nemploys deep learning (DL) for document outline detection, followed by computer\nvision (CV) to create a topological 2D grid using cubic polynomial\ninterpolation and correct nonlinear distortions by remapping the image. Using\nclassical CV methods makes the document topology restoration process more\nefficient and faster, as it requires significantly fewer computational\nresources and memory. We developed a new pipeline for automatic document\ndewarping and reconstruction, along with a framework and annotated dataset to\ndemonstrate its efficiency. Our experiments confirm the promise of our\nmethodology and its superiority over existing benchmarks (including mobile apps\nand popular DL solutions, such as RectiNet, DocGeoNet, and DocTr++) both\nvisually and in terms of document readability via Optical Character Recognition\n(OCR) and geometry restoration metrics. This paves the way for creating\nhigh-quality digital copies of paper documents and enhancing the efficiency of\nOCR systems. Project page: https:\/\/github.com\/HorizonParadox\/DRCCBI"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07206"
    ],
    "c_title":[
      "Einstein-Maxwell-Dilaton Wormholes that meet the Energy Conditions"
    ],
    "c_abstract":[
      "One of the latest predictions of Einstein's theory is the existence of\nWormholes (WH). In this work, we present exact solutions of the\nEinstein-Maxwell-Dilaton equations representing traversable Wormholes. These\nsolutions satisfy the energy conditions and have a ring singularity satisfying\nthe cosmic censorship of WHs, i.e. we show that, as in previous solutions,\ngeodesics cannot touch the singularity. We find that the most optimal input\nregions for the first class of solutions traversing these wormholes are near\nthe poles and near the equatorial plane for the second class. We also find that\nthe solution associated with the first class is physically feasible, while for\nthe second class it presents the problem of not being asymptotically flat when\nconsidering a dilatonic-type scalar field. Finally, we give examples of\nrealistic astrophysical objects that could fulfill these conditions."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-67",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07260"
    ],
    "b_title":[
      "Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion"
    ],
    "b_abstract":[
      "3D semantic scene completion is critical for multiple downstream tasks in\nautonomous systems. It estimates missing geometric and semantic information in\nthe acquired scene data. Due to the challenging real-world conditions, this\ntask usually demands complex models that process multi-modal data to achieve\nacceptable performance. We propose a unique neural model, leveraging advances\nfrom the state space and diffusion generative modeling to achieve remarkable 3D\nsemantic scene completion performance with monocular image input. Our technique\nprocesses the data in the conditioned latent space of a variational autoencoder\nwhere diffusion modeling is carried out with an innovative state space\ntechnique. A key component of our neural network is the proposed Skimba (Skip\nMamba) denoiser, which is adept at efficiently processing long-sequence data.\nThe Skimba diffusion model is integral to our 3D scene completion network,\nincorporating a triple Mamba structure, dimensional decomposition residuals and\nvarying dilations along three directions. We also adopt a variant of this\nnetwork for the subsequent semantic segmentation stage of our method. Extensive\nevaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show\nthat our approach not only outperforms other monocular techniques by a large\nmargin, it also achieves competitive performance against stereo methods. The\ncode is available at https:\/\/github.com\/xrkong\/skimba"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15419"
    ],
    "c_title":[
      "Mechanism of Shape Symmetry Breaking in Surfactant Mediated Crystal\n  Growth"
    ],
    "c_abstract":[
      "We present a dynamical model of crystal growth, in which it is possible to\nreliably achieve asymmetric products, beginning from symmetric initial\nconditions and growing within an isotropic environment. The asymmetric growth\nis the result of a positive feedback mechanism that amplifies the effect of\nthermal fluctuations in the coverage of surfactants on the growing crystalline\nfacets. Within our simple model, we are able to understand the kinetic and\nthermodynamic factors involved in both the onset of symmetry breaking and the\npersistence of anisotropic growth. We demonstrate that the mechanism is general\nby studying models with increasing complexity. We argue that this mechanism of\nsymmetry breaking underpins observations of colloidal, seed-mediated syntheses\nof single crystalline metal nanorods capped with strongly interacting\nsurfactants. The parameters within our model are related to experimental\nobservables such as the concentration, hydrophobicity, and binding strength of\nthe surfactants, which suggests a potential route to optimize the yield of\nasymmetric products in colloidal nanoparticle syntheses."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-68",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03756"
    ],
    "b_title":[
      "Conditions for radiative zones in the molecular hydrogen envelope of\n  Jupiter and Saturn: The role of alkali metals"
    ],
    "b_abstract":[
      "Interior models of gas giants in the Solar System traditionally assume a\nfully convective molecular hydrogen envelope. However, recent observations from\nthe Juno mission suggest a possible depletion of alkali metals in Jupiter's\nmolecular hydrogen envelope, indicating that a stable radiative layer could\nexist at the kilobar level. Recent studies propose that deep stable layers help\nreconcile various Jupiter observations, including its atmospheric water and CO\nabundances and the depth of its zonal winds. However, opacity tables used to\ninfer stable layers are often outdated and incomplete, leaving the precise\nmolecular hydrogen envelope composition required for a deep radiative zone\nuncertain. In this paper, we determine atmospheric compositions that can lead\nto the formation of a radiative zone at the kilobar level in Jupiter and Saturn\ntoday. We computed radiative opacity tables covering pressures up to $10^5$\nbar, including the most abundant molecules present in the gas giants of the\nSolar System, as well as contributions from free electrons, metal hydrides,\noxides, and atomic species, using the most up-to-date line lists published in\nthe literature. These tables were used to calculate Rosseland-mean opacities\nfor the molecular hydrogen envelopes of Jupiter and Saturn, which were then\ncompared to the critical mean opacity required to maintain convection. We find\nthat the presence of a radiative zone is controlled by the existence of K, Na,\nand NaH in the atmosphere of Jupiter and Saturn. For Jupiter, the elemental\nabundance of K and Na must be less than $\\sim 10^{-3}$ times solar to form a\nradiative zone. In contrast, for Saturn, the required abundance for K and Na is\nbelow $\\sim 10^{-4}$ times solar."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03292"
    ],
    "c_title":[
      "ALPET: Active Few-shot Learning for Citation Worthiness Detection in\n  Low-Resource Wikipedia Languages"
    ],
    "c_abstract":[
      "Citation Worthiness Detection (CWD) consists in determining which sentences,\nwithin an article or collection, should be backed up with a citation to\nvalidate the information it provides. This study, introduces ALPET, a framework\ncombining Active Learning (AL) and Pattern-Exploiting Training (PET), to\nenhance CWD for languages with limited data resources. Applied to Catalan,\nBasque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCW\nbaseline while reducing the amount of labeled data in some cases above 80\\%.\nALPET's performance plateaus after 300 labeled samples, showing it suitability\nfor low-resource scenarios where large, labeled datasets are not common. While\nspecific active learning query strategies, like those employing K-Means\nclustering, can offer advantages, their effectiveness is not universal and\noften yields marginal gains over random sampling, particularly with smaller\ndatasets. This suggests that random sampling, despite its simplicity, remains a\nstrong baseline for CWD in constraint resource environments. Overall, ALPET's\nability to achieve high performance with fewer labeled samples makes it a\npromising tool for enhancing the verifiability of online content in\nlow-resource language settings."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-69",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07090"
    ],
    "b_title":[
      "Generative Distribution Prediction: A Unified Approach to Multimodal\n  Learning"
    ],
    "b_abstract":[
      "Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07634"
    ],
    "c_title":[
      "A lower bound on the right-handed neutrino mass from wash-in\n  leptogenesis"
    ],
    "c_abstract":[
      "Leptogenesis is an attractive scenario for the generation of the baryon\nasymmetry of the Universe that relies on the dynamics of right-handed neutrinos\n(RHNs) in the seesaw extension of the Standard Model. In standard thermal\nleptogenesis, the RHN mass scale $M_N$ is subject to the Davidson--Ibarra\nbound, $M_N \\gtrsim 10^9\\,\\textrm{GeV}$, which builds on the assumption that\nRHN decays are responsible for the violation of both charge-parity invariance\n($CP$) and baryon-minus-lepton number ($B\\!-\\!L$). In this paper, we relax this\nassumption in the context of the more general framework of wash-in\nleptogenesis, in which $CP$ violation is encoded in the initial conditions and\nthe only remaining task of the RHN decays is to violate $B\\!-\\!L$. Solving the\nrelevant set of Boltzmann equations, we find that, in wash-in leptogenesis, the\nRHN mass scale can be as low as 7 TeV."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-70",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15467"
    ],
    "b_title":[
      "Bipartite expansion beyond biparticity"
    ],
    "b_abstract":[
      "The recently suggested bipartite analysis extends the Kauffman planar\ndecomposition to arbitrary $N$, i.e. extends it from the Jones polynomial to\nthe HOMFLY polynomial. This provides a generic and straightforward\nnon-perturbative calculus in an arbitrary Chern--Simons theory. Technically,\nthis approach is restricted to knots and links which possess bipartite\nrealizations, i.e. can be entirely glued from antiparallel lock (two-vertex)\ntangles rather than single-vertex $R$-matrices. However, we demonstrate that\nthe resulting positive decomposition (PD), i.e. the representation of the\nfundamental HOMFLY polynomials as positive integer polynomials of the three\nparameters $\\phi$, $\\bar\\phi$ and $D$, exists for arbitrary knots, not only\nbipartite ones. This poses new questions about the true significance of\nbipartite expansion, which appears to make sense far beyond its original scope,\nand its generalizations to higher representations. We have provided two\nexplanations for the existence of the PD for non-bipartite knots. An\ninteresting option is to resolve a particular bipartite vertex in a\nnot-fully-bipartite diagram and reduce the HOMFLY polynomial to a linear\ncombination of those for smaller diagrams. If the resulting diagrams correspond\nto bipartite links, this option provides a PD even to an initially\nnon-bipartite knot. Another possibility for a non-bipartite knot is to have a\nbipartite clone with the same HOMFLY polynomial providing this PD. We also\nsuggest a promising criterium for the existence of a bipartite realization\nbehind a given PD, which is based on the study of the precursor Jones\npolynomials."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.GT",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.17792"
    ],
    "c_title":[
      "Topology preserving Image segmentation using the iterative\n  convolution-thresholding method"
    ],
    "c_abstract":[
      "Variational models are widely used in image segmentation, with various models\ndesigned to address different types of images by optimizing specific objective\nfunctionals. However, traditional segmentation models primarily focus on the\nvisual attributes of the image, often neglecting the topological properties of\nthe target objects. This limitation can lead to segmentation results that\ndeviate from the ground truth, particularly in images with complex topological\nstructures. In this paper, we introduce a topology-preserving constraint into\nthe iterative convolution-thresholding method (ICTM), resulting in the\ntopology-preserving ICTM (TP-ICTM). Extensive experiments demonstrate that, by\nexplicitly preserving the topological properties of target objects-such as\nconnectivity-the proposed algorithm achieves enhanced accuracy and robustness,\nparticularly in images with intricate structures or noise."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-71",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02824"
    ],
    "b_title":[
      "Proteomic Learning of Gamma-Aminobutyric Acid (GABA) Receptor-Mediated\n  Anesthesia"
    ],
    "b_abstract":[
      "Anesthetics are crucial in surgical procedures and therapeutic interventions,\nbut they come with side effects and varying levels of effectiveness, calling\nfor novel anesthetic agents that offer more precise and controllable effects.\nTargeting Gamma-aminobutyric acid (GABA) receptors, the primary inhibitory\nreceptors in the central nervous system, could enhance their inhibitory action,\npotentially reducing side effects while improving the potency of anesthetics.\nIn this study, we introduce a proteomic learning of GABA receptor-mediated\nanesthesia based on 24 GABA receptor subtypes by considering over 4000 proteins\nin protein-protein interaction (PPI) networks and over 1.5 millions known\nbinding compounds. We develop a corresponding drug-target interaction network\nto identify potential lead compounds for novel anesthetic design. To ensure\nrobust proteomic learning predictions, we curated a dataset comprising 136\ntargets from a pool of 980 targets within the PPI networks. We employed three\nmachine learning algorithms, integrating advanced natural language processing\n(NLP) models such as pretrained transformer and autoencoder embeddings. Through\na comprehensive screening process, we evaluated the side effects and\nrepurposing potential of over 180,000 drug candidates targeting the GABRA5\nreceptor. Additionally, we assessed the ADMET (absorption, distribution,\nmetabolism, excretion, and toxicity) properties of these candidates to identify\nthose with near-optimal characteristics. This approach also involved optimizing\nthe structures of existing anesthetics. Our work presents an innovative\nstrategy for the development of new anesthetic drugs, optimization of\nanesthetic use, and deeper understanding of potential anesthesia-related side\neffects."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16356"
    ],
    "c_title":[
      "Evaluating Binary Decision Biases in Large Language Models: Implications\n  for Fair Agent-Based Financial Simulations"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) are increasingly being used to simulate\nhuman-like decision making in agent-based financial market models (ABMs). As\nmodels become more powerful and accessible, researchers can now incorporate\nindividual LLM decisions into ABM environments. However, integration may\nintroduce inherent biases that need careful evaluation. In this paper we test\nthree state-of-the-art GPT models for bias using two model sampling approaches:\none-shot and few-shot API queries. We observe significant variations in\ndistributions of outputs between specific models, and model sub versions, with\nGPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes\nresponses) compared to GPT-4-0125-preview's extreme bias (98-99% yes\nresponses). We show that sampling methods and model sub-versions significantly\nimpact results: repeated independent API calls produce different distributions\ncompared to batch sampling within a single call. While no current GPT model can\nsimultaneously achieve a uniform distribution and Markovian properties in\none-shot testing, few-shot sampling can approach uniform distributions under\ncertain conditions. We explore the Temperature parameter, providing a\ndefinition and comparative results. We further compare our results to true\nrandom binary series and test specifically for the common human bias of\nNegative Recency - finding LLMs have a mixed ability to 'beat' humans in this\none regard. These findings emphasise the critical importance of careful LLM\nintegration into ABMs for financial markets and more broadly."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-72",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06179"
    ],
    "b_title":[
      "Actual Achieved Gain and Optimal Perceived Gain: Modeling Human\n  Take-over Decisions Towards Automated Vehicles' Suggestions"
    ],
    "b_abstract":[
      "Driver decision quality in take-overs is critical for effective\nhuman-Autonomous Driving System (ADS) collaboration. However, current research\nlacks detailed analysis of its variations. This paper introduces two\nmetrics--Actual Achieved Gain (AAG) and Optimal Perceived Gain (OPG)--to assess\ndecision quality, with OPG representing optimal decisions and AAG reflecting\nactual outcomes. Both are calculated as weighted averages of perceived gains\nand losses, influenced by ADS accuracy. Study 1 (N=315) used a 21-point\nThurstone scale to measure perceived gains and losses-key components of AAG and\nOPG-across typical tasks: route selection, overtaking, and collision avoidance.\nStudies 2 (N=54) and 3 (N=54) modeled decision quality under varying ADS\naccuracy and decision time. Results show with sufficient time (>3.5s), AAG\nconverges towards OPG, indicating rational decision-making, while limited time\nleads to intuitive and deterministic choices. Study 3 also linked AAG-OPG\ndeviations to irrational behaviors. An intervention study (N=8) and a pilot\n(N=4) employing voice alarms and multi-modal alarms based on these deviations\ndemonstrated AAG's potential to improve decision quality."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12782"
    ],
    "c_title":[
      "Stability of 2-class groups in the $\\mathbb{Z}_2$-extension of certain\n  real biquadratic fields"
    ],
    "c_abstract":[
      "Greenberg's conjecture on the stability of $\\ell$-class groups in the\ncyclotomic $\\mathbb{Z}_{\\ell}$-extension of a real field has been proven for\nvarious infinite families of real quadratic fields for the prime $\\ell=2$. In\nthis work, we consider an infinite family of real biquadratic fields $K$. With\nsome extensive use of elementary group theoretic and class field theoretic\narguments, we investigate the $2$-class groups of the $n$-th layers $K_n$ of\nthe cyclotomic $\\mathbb{Z}_2$-extension of $K$ and verify Greenberg's\nconjecture. We also relate capitulation of ideal classes of certain\nsub-extensions of $K_n$ to the relative sizes of the $2$-class groups."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-73",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19259"
    ],
    "b_title":[
      "Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for\n  Autonomous Drone FlighT at the Edge"
    ],
    "b_abstract":[
      "The integration of human-intuitive interactions into autonomous systems has\nbeen limited. Traditional Natural Language Processing (NLP) systems struggle\nwith context and intent understanding, severely restricting human-robot\ninteraction. Recent advancements in Large Language Models (LLMs) have\ntransformed this dynamic, allowing for intuitive and high-level communication\nthrough speech and text, and bridging the gap between human commands and\nrobotic actions. Additionally, autonomous navigation has emerged as a central\nfocus in robotics research, with artificial intelligence (AI) increasingly\nbeing leveraged to enhance these systems. However, existing AI-based navigation\nalgorithms face significant challenges in latency-critical tasks where rapid\ndecision-making is critical. Traditional frame-based vision systems, while\neffective for high-level decision-making, suffer from high energy consumption\nand latency, limiting their applicability in real-time scenarios. Neuromorphic\nvision systems, combining event-based cameras and spiking neural networks\n(SNNs), offer a promising alternative by enabling energy-efficient, low-latency\nnavigation. Despite their potential, real-world implementations of these\nsystems, particularly on physical platforms such as drones, remain scarce. In\nthis work, we present Neuro-LIFT, a real-time neuromorphic navigation framework\nimplemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural\nlanguage processing, Neuro-LIFT translates human speech into high-level\nplanning commands which are then autonomously executed using event-based\nneuromorphic vision and physics-driven planning. Our framework demonstrates its\ncapabilities in navigating in a dynamic environment, avoiding obstacles, and\nadapting to human instructions in real-time."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15048"
    ],
    "c_title":[
      "On the test properties of the Frobenius endomorphism"
    ],
    "c_abstract":[
      "In this paper, we prove two theorems concerning the test properties of the\nFrobenius endomorphism over commutative Noetherian local rings of prime\ncharacteristic $p$. Our first theorem generalizes a result of Funk-Marley on\nthe vanishing of Ext and Tor modules, while our second theorem generalizes one\nof our previous results on maximal Cohen-Macaulay tensor products. In these\nearlier results, we replace $^{e}R$ with a more general module $^{e}M$, where\n$R$ is a Cohen-Macaulay ring, $M$ is a Cohen-Macaulay $R$-module with full\nsupport, and $^{e}M$ is the module viewed as an $R$-module via the $e$-th\niteration of the Frobenius endomorphism. We also provide examples and present\napplications of our results, yielding new characterizations of the regularity\nof local rings."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-74",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15704"
    ],
    "b_title":[
      "Uncertainties in the Hubble Constant from Peculiar Velocities"
    ],
    "b_abstract":[
      "Recent measurements of the Hubble constant using type Ia supernovae\nexplicitly correct for their estimated peculiar velocities using the 2M++\nreconstruction of the local density field. The amount of uncertainty from this\nreconstruction procedure has thus far been unquantified. To rectify this, we\nuse mock universe realisations of the 2M++ catalogue and generate predicted\npeculiar velocities using the same method as the predictions that are used to\ncorrect for the Pantheon+ catalogue. We find that the method yields\nuncertainties of 0.3 km\/s\/Mpc and hence subdominant to the total uncertainty in\nH0."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03067"
    ],
    "c_title":[
      "Design and implementation of tools to build an ontology of Security\n  Requirements for Internet of Medical Things"
    ],
    "c_abstract":[
      "When developing devices, architectures and services for the Internet of\nMedical Things (IoMT) world, manufacturers or integrators must be aware of the\nsecurity requirements expressed by both laws and specifications. To provide\ntools guiding through these requirements and to assure a third party of the\ncorrect compliance, an ontology charting the relevant laws and specifications\n(for the European context) is very useful. We here address the development of\nthis ontology. Due to the very high number and size of the considered\nspecification documents, we have put in place a methodology and tools to\nsimplify the transition from natural text to an ontology. The first step is a\nmanual highlighting of relevant concepts in the corpus, then a manual\ntranslation to XML\/XSD is operated. We have developed a tool allowing us to\nconvert this semi-structured data into an ontology. Because the different\nspecifications use similar but different wording, our approach favors the\ncreation of similar instances in the ontology. To improve the ontology\nsimplification through instance merging, we consider the use of LLMs. The\nresponses of the LLMs are compared against our manually defined correct\nresponses. The quality of the responses of the automated system does not prove\nto be good enough to be trusted blindly, and should only be used as a starting\npoint for a manual correction."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-75",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11972"
    ],
    "b_title":[
      "Waveguide QED Analysis of Quantum-Coherent Links for Modular Quantum\n  Computing"
    ],
    "b_abstract":[
      "Waveguides potentially offer an effective medium for interconnecting quantum\nprocessors within a modular framework, facilitating the coherent quantum state\ntransfer between the qubits across separate chips. In this work, we analyze a\nquantum communication scenario where two qubits are connected to a shared\nwaveguide, whose resonance frequency may match or not match that of the qubits.\nBoth configurations are simulated from the perspective of quantum\nelectrodynamics (QED) to assess the system behavior and key factors that\ninfluence reliable inter-chip communication. The primary performance metrics\nanalyzed are quantum state transfer fidelity and latency, considering the\nimpact of key system parameters such as the qubit-waveguide detuning, coupling\nstrength, waveguide decay rate, and qubit decay rate. We present the system\ndesign requirements that yield enhanced state transmission fidelity rates and\nlowered latency, and discuss the scalability of waveguide-mediated\ninterconnects considering various configurations of the system."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15877"
    ],
    "c_title":[
      "Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation"
    ],
    "c_abstract":[
      "Recent advances in text-to-image diffusion models have been driven by the\nincreasing availability of paired 2D data. However, the development of 3D\ndiffusion models has been hindered by the scarcity of high-quality 3D data,\nresulting in less competitive performance compared to their 2D counterparts. To\naddress this challenge, we propose repurposing pre-trained 2D diffusion models\nfor 3D object generation. We introduce Gaussian Atlas, a novel representation\nthat utilizes dense 2D grids, enabling the fine-tuning of 2D diffusion models\nto generate 3D Gaussians. Our approach demonstrates successful transfer\nlearning from a pre-trained 2D diffusion model to a 2D manifold flattened from\n3D structures. To support model training, we compile GaussianVerse, a\nlarge-scale dataset comprising 205K high-quality 3D Gaussian fittings of\nvarious 3D objects. Our experimental results show that text-to-image diffusion\nmodels can be effectively adapted for 3D content generation, bridging the gap\nbetween 2D and 3D modeling."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-76",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20382"
    ],
    "b_title":[
      "Physics-Driven Data Generation for Contact-Rich Manipulation via\n  Trajectory Optimization"
    ],
    "b_abstract":[
      "We present a low-cost data generation pipeline that integrates physics-based\nsimulation, human demonstrations, and model-based planning to efficiently\ngenerate large-scale, high-quality datasets for contact-rich robotic\nmanipulation tasks. Starting with a small number of embodiment-flexible human\ndemonstrations collected in a virtual reality simulation environment, the\npipeline refines these demonstrations using optimization-based kinematic\nretargeting and trajectory optimization to adapt them across various robot\nembodiments and physical parameters. This process yields a diverse, physically\nconsistent dataset that enables cross-embodiment data transfer, and offers the\npotential to reuse legacy datasets collected under different hardware\nconfigurations or physical parameters. We validate the pipeline's effectiveness\nby training diffusion policies from the generated datasets for challenging\ncontact-rich manipulation tasks across multiple robot embodiments, including a\nfloating Allegro hand and bimanual robot arms. The trained policies are\ndeployed zero-shot on hardware for bimanual iiwa arms, achieving high success\nrates with minimal human input. Project website:\nhttps:\/\/lujieyang.github.io\/physicsgen\/."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02027"
    ],
    "c_title":[
      "Existence of optimal controls for stochastic partial differential\n  equations with fully local monotone coefficients"
    ],
    "c_abstract":[
      "This paper deals with a stochastic optimal feedback control problem for the\ncontrolled stochastic partial differential equations. More precisely, we\nestablish the existence of stochastic optimal feedback control for the\ncontrolled stochastic partial differential equations with fully monotone\ncoefficients by a minimizing sequence for the control problem. Using the\nFaedo-Galerkin approximations, the uniform estimates and the tightness in some\nappropriate space for the Faedo-Galerkin approximating solution can be obtain\nto prove the well-posedness of the controlled stochastic partial differential\nequations with fully monotone coefficients. The results obtained in the present\npaper may be applied to various types of controlled stochastic partial\ndifferential equations, such as the controlled stochastic convection diffusion\nequation."
    ],
    "c_categories":[
      [
        "math.OC",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-77",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13469"
    ],
    "b_title":[
      "Conditional Electrocardiogram Generation Using Hierarchical Variational\n  Autoencoders"
    ],
    "b_abstract":[
      "Cardiovascular diseases (CVDs) are disorders impacting the heart and\ncirculatory system. These disorders are the foremost and continuously\nescalating cause of mortality worldwide. One of the main tasks when working\nwith CVDs is analyzing and identifying pathologies on a 12-lead\nelectrocardiogram (ECG) with a standard 10-second duration. Using machine\nlearning (ML) in automatic ECG analysis increases CVD diagnostics'\navailability, speed, and accuracy. However, the most significant difficulty in\ndeveloping ML models is obtaining a sufficient training dataset. Due to the\nlimitations of medical data usage, such as expensiveness, errors, the ambiguity\nof labels, imbalance of classes, and privacy issues, utilizing synthetic\nsamples depending on specific pathologies bypasses these restrictions and\nimproves algorithm quality. Existing solutions for the conditional generation\nof ECG signals are mainly built on Generative Adversarial Networks (GANs), and\nonly a few papers consider the architectures based on Variational Autoencoders\n(VAEs), showing comparable results in recent works. This paper proposes the\npublicly available conditional Nouveau VAE model for ECG signal generation\n(cNVAE-ECG), which produces high-resolution ECGs with multiple pathologies. We\nprovide an extensive comparison of the proposed model on various practical\ndownstream tasks, including transfer learning scenarios showing an area under\nthe receiver operating characteristic (AUROC) increase up to 2% surpassing\nGAN-like competitors."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10329"
    ],
    "c_title":[
      "Strong law of large numbers for a branching random walk among Bernoulli\n  traps"
    ],
    "c_abstract":[
      "We study a $d$-dimensional branching random walk (BRW) in an i.i.d. random\nenvironment on $\\mathbb{Z}^d$ in discrete time. A Bernoulli trap field is\nattached to $\\mathbb{Z}^d$, where each site, independently of the others, is a\ntrap with a fixed probability. The interaction between the BRW and the trap\nfield is given by the hard killing rule. Given a realization of the\nenvironment, over each time step, each particle first moves according to a\nsimple symmetric random walk to a nearest neighbor, and immediately afterwards,\nsplits into two particles if the new site is not a trap or is killed instantly\nif the new site is a trap. Conditional on the ultimate survival of the BRW, we\nprove a strong law of large numbers for the total mass of the process. Our\nresult is quenched, that is, it holds in almost every environment in which the\nstarting point of the BRW is inside the infinite connected component of\ntrap-free sites."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-78",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12202"
    ],
    "b_title":[
      "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D\n  Assets Generation"
    ],
    "b_abstract":[
      "We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for\ngenerating high-resolution textured 3D assets. This system includes two\nfoundation components: a large-scale shape generation model -- Hunyuan3D-DiT,\nand a large-scale texture synthesis model -- Hunyuan3D-Paint. The shape\ngenerative model, built on a scalable flow-based diffusion transformer, aims to\ncreate geometry that properly aligns with a given condition image, laying a\nsolid foundation for downstream applications. The texture synthesis model,\nbenefiting from strong geometric and diffusion priors, produces high-resolution\nand vibrant texture maps for either generated or hand-crafted meshes.\nFurthermore, we build Hunyuan3D-Studio -- a versatile, user-friendly production\nplatform that simplifies the re-creation process of 3D assets. It allows both\nprofessional and amateur users to manipulate or even animate their meshes\nefficiently. We systematically evaluate our models, showing that Hunyuan3D 2.0\noutperforms previous state-of-the-art models, including the open-source models\nand closed-source models in geometry details, condition alignment, texture\nquality, and etc. Hunyuan3D 2.0 is publicly released in order to fill the gaps\nin the open-source 3D community for large-scale foundation generative models.\nThe code and pre-trained weights of our models are available at:\nhttps:\/\/github.com\/Tencent\/Hunyuan3D-2"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20185"
    ],
    "c_title":[
      "Love numbers beyond GR from the modified Teukolsky equation"
    ],
    "c_abstract":[
      "We obtain the full set of tidal Love numbers of non-rotating black holes in\nan effective field theory extension of general relativity. We achieve our\nresults using a recently introduced modified Teukolsky equation that describes\nthe perturbations of black holes in this theory. We show how to identify the\nLove numbers and their beta functions in a systematic and gauge invariant way,\napplying analytic continuation on the angular number $\\ell$ when necessary. We\nobserve that there are three types of Love numbers: electric, magnetic, and a\n``mixing'' type, associated to parity-breaking theories, that we identify here\nfor the first time. The modified Teukolsky equation proves to be very useful as\nit allows us to obtain all the different Love numbers in a unified framework.\nWe compare our results with previous literature that utilized the\nRegge-Wheeler-Zerilli equations to compute Love numbers, finding perfect\nagreement. The method introduced here paves the way towards the computation of\nLove numbers of rotating black holes beyond general relativity."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-79",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07841"
    ],
    "b_title":[
      "Fingerprints of triaxiality in the charge radii of neutron-rich\n  Ruthenium"
    ],
    "b_abstract":[
      "We present the first measurements with a new collinear laser spectroscopy\nsetup at the Argonne Tandem Linac Accelerator System utilizing its unique\ncapability to deliver neutron-rich refractory metal isotopes produced by the\nspontaneous fission of 252Cf. We measured isotope shifts from optical spectra\nfor nine radioactive ruthenium isotopes 106-114Ru, reaching deep into the\nmid-shell region. The extracted charge radii are in excellent agreement with\npredictions from the Brussels-Skyrme-on-a-Grid models that account for the\ntriaxial deformation of nuclear ground states in this region. We show that\ntriaxial deformation impacts charge radii in models that feature shell effects,\nin contrast to what could be concluded from a liquid drop analysis. This\nindicates that this exotic type of deformation should not be neglected in\nregions where it is known to occur, even if its presence cannot be\nunambiguously inferred through laser spectroscopy."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.05887"
    ],
    "c_title":[
      "Miyaoka-Yau equality and uniformization of log Fano pairs"
    ],
    "c_abstract":[
      "Let $(X, \\Delta)$ be a log Fano pair with standard coefficients. We show that\nif it satisfies the equality case in the Miyaoka-Yau inequality, then its\norbifold universal cover is a projective space."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-80",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11293"
    ],
    "b_title":[
      "Growth of Cosmic Strings beyond Kination"
    ],
    "b_abstract":[
      "A novel mechanism for the production of a cosmic network of fundamental\nsuperstrings based on a time-varying string tension has been recently proposed\nin the context of a kinating background driven by the volume modulus of string\ncompactifications. In this paper, we generalise the analysis of this growth\nmechanism by using dynamical system techniques. We first study the cosmological\ngrowth of strings in a spatially-flat Universe filled with a perfect fluid and\na field-dependent tension, finding the fixed points of the phase space of this\nsystem. We then apply this analysis to fundamental strings and EFT strings\nobtained from wrapping $p$-branes on $(p-1)$-cycles. We find a cosmological\ngrowth for fundamental strings even without kination, as in scaling fixed\npoints, and for EFT strings arising from D3- and NS5-branes wrapped around\nfibration cycles."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00319"
    ],
    "c_title":[
      "Physics-Inspired Distributed Radio Map Estimation"
    ],
    "c_abstract":[
      "To gain panoramic awareness of spectrum coverage in complex wireless\nenvironments, data-driven learning approaches have recently been introduced for\nradio map estimation (RME). While existing deep learning based methods conduct\nRME given spectrum measurements gathered from dispersed sensors in the region\nof interest, they rely on centralized data at a fusion center, which however\nraises critical concerns on data privacy leakages and high communication\noverloads. Federated learning (FL) enhance data security and communication\nefficiency in RME by allowing multiple clients to collaborate in model training\nwithout directly sharing local data. However, the performance of the FL-based\nRME can be hindered by the problem of task heterogeneity across clients due to\ntheir unavailable or inaccurate landscaping information. To fill this gap, in\nthis paper, we propose a physics-inspired distributed RME solution in the\nabsence of landscaping information. The main idea is to develop a novel\ndistributed RME framework empowered by leveraging the domain knowledge of radio\npropagation models, and by designing a new distributed learning approach that\nsplits the entire RME model into two modules. A global autoencoder module is\nshared among clients to capture the common pathloss influence on radio\npropagation pattern, while a client-specific autoencoder module focuses on\nlearning the individual features produced by local shadowing effects from the\nunique building distributions in local environment. Simulation results show\nthat our proposed method outperforms the benchmarks in achieving higher\nperformance."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-81",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01005"
    ],
    "b_title":[
      "Noise-resilient solid host for electron qubits above 100 mK"
    ],
    "b_abstract":[
      "Cryogenic solid neon has recently emerged as a pristine solid host for single\nelectron qubits. At ~10 mK temperatures, electron-on-solid-neon (eNe) charge\nqubits have exhibited exceptionally long coherence times and high operation\nfidelities. To advance this platform towards a scalable quantum information\narchitecture, systematic characterization of its noise feature is imperative.\nHere, we show the remarkable resilience of solid neon against charge and\nthermal noises when eNe qubits are operated away from the charge-insensitive\nsweet-spot and at elevated temperatures. Without optimizing neon growth, the\nmeasured charge (voltage) noise on solid neon is already orders of magnitude\nlower than that in most stringently grown semiconductors, rivaling the best\nrecords to date. Up to 400 mK, the eNe charge qubits operated at ~5 GHz can\nmaintain their echo coherence times over 1 microsecond. These observations\nhighlight solid neon as an ideal host for quantum information processing at\nhigher temperatures and larger scales."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11085"
    ],
    "c_title":[
      "Towards Data-Efficient Pretraining for Atomic Property Prediction"
    ],
    "c_abstract":[
      "This paper challenges the recent paradigm in atomic property prediction that\nlinks progress to growing dataset sizes and computational resources. We show\nthat pretraining on a carefully selected, task-relevant dataset can match or\neven surpass large-scale pretraining, while using as little as 1\/24th of the\ncomputational cost. We introduce the Chemical Similarity Index (CSI), a novel\nmetric inspired by computer vision's Fr\\'echet Inception Distance, for\nmolecular graphs which quantifies the alignment between upstream pretraining\ndatasets and downstream tasks. By selecting the most relevant dataset with\nminimal CSI distance, we show that models pretrained on a smaller, focused\ndataset consistently outperform those pretrained on massive, mixed datasets\nsuch as JMP, even when those larger datasets include the relevant dataset.\nCounterintuitively, we also find that indiscriminately adding more data can\ndegrade model performance when the additional data poorly aligns with the task\nat hand. Our findings highlight that quality often outperforms quantity in\npretraining for atomic property prediction."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-82",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14946"
    ],
    "b_title":[
      "Has the Paris Agreement Shaped Emission Trends? A Panel VECM Analysis of\n  Energy, Growth, and CO$_2$ in 106 Middle-Income Countries"
    ],
    "b_abstract":[
      "Rising CO$_2$ emissions remain a critical global challenge, particularly in\nmiddle-income countries where economic growth drives environmental degradation.\nThis study examines the long-run and short-run relationships between CO$_2$\nemissions, energy use, GDP per capita, and population across 106 middle-income\ncountries from 1980 to 2023. Using a Panel Vector Error Correction Model\n(VECM), we assess the impact of the Paris Agreement (2015) on emissions while\nconducting cointegration tests to confirm long-run equilibrium relationships.\nThe findings reveal a strong long-run relationship among the variables, with\nenergy use as the dominant driver of emissions, while GDP per capita has a\nmoderate impact. However, the Paris Agreement has not significantly altered\nemissions trends in middle-income economies. Granger causality tests indicate\nthat energy use strongly causes emissions, but GDP per capita and population do\nnot exhibit significant short-run causal effects. Variance decomposition\nconfirms that energy shocks have the most persistent effects, and impulse\nresponse functions (IRFs) show emissions trajectories are primarily shaped by\neconomic activity rather than climate agreements. Robustness checks, including\nautocorrelation tests, polynomial root stability, and Yamagata-Pesaran slope\nhomogeneity tests, validate model consistency. These results suggest that while\nglobal agreements set emissions reduction goals, their effectiveness remains\nlimited without stronger national climate policies, sectoral energy reforms,\nand financial incentives for clean energy adoption to ensure sustainable\neconomic growth."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.14614"
    ],
    "c_title":[
      "FIND: Fine-grained Information Density Guided Adaptive\n  Retrieval-Augmented Generation for Disease Diagnosis"
    ],
    "c_abstract":[
      "Retrieval-Augmented Large Language Models (LLMs), which integrate external\nknowledge into LLMs, have shown remarkable performance in various medical\ndomains, including clinical diagnosis. However, existing RAG methods struggle\nto effectively assess task difficulty to make retrieval decisions, thereby\nfailing to meet the clinical requirements for balancing efficiency and\naccuracy. So in this paper, we propose FIND (\\textbf{F}ine-grained\n\\textbf{In}formation \\textbf{D}ensity Guided Adaptive RAG), a novel framework\nthat improves the reliability of RAG in disease diagnosis scenarios. FIND\nincorporates a fine-grained adaptive control module to determine whether\nretrieval is necessary based on the information density of the input. By\noptimizing the retrieval process and implementing a knowledge filtering module,\nFIND ensures that the retrieval is better suited to clinical scenarios.\nExperiments on three Chinese electronic medical record datasets demonstrate\nthat FIND significantly outperforms various baseline methods, highlighting its\neffectiveness in clinical diagnosis tasks."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-83",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01983"
    ],
    "b_title":[
      "Diagrammatics of information"
    ],
    "b_abstract":[
      "We introduce a diagrammatic perspective for Shannon entropy created by the\nfirst author and Mikhail Khovanov and connect it to information theory and\nmutual information. We also give two complete proofs that the $5$-term\ndilogarithm deforms to the $4$-term infinitesimal dilogarithm."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math-ph",
        "math.IT",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13312"
    ],
    "c_title":[
      "High Power Fast Frequency Modulation"
    ],
    "c_abstract":[
      "A fast and highly efficient frequency modulation at a high power level is\ndescribed. The system incorporates ferroelectric phase shifters and a magic-T\nor a circulator. A magnetron may be considered as a potential application. The\nmagnetron output may be converted to a selected reference frequency with\nnegligible insertion loss. The method also allows simultaneous amplitude and\nphase control."
    ],
    "c_categories":[
      [
        "physics.acc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-84",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.00873"
    ],
    "b_title":[
      "Exploring Structured Semantic Priors Underlying Diffusion Score for\n  Test-time Adaptation"
    ],
    "b_abstract":[
      "Capitalizing on the complementary advantages of generative and discriminative\nmodels has always been a compelling vision in machine learning, backed by a\ngrowing body of research. This work discloses the hidden semantic structure\nwithin score-based generative models, unveiling their potential as effective\ndiscriminative priors. Inspired by our theoretical findings, we propose DUSA to\nexploit the structured semantic priors underlying diffusion score to facilitate\nthe test-time adaptation of image classifiers or dense predictors. Notably,\nDUSA extracts knowledge from a single timestep of denoising diffusion, lifting\nthe curse of Monte Carlo-based likelihood estimation over timesteps. We\ndemonstrate the efficacy of our DUSA in adapting a wide variety of competitive\npre-trained discriminative models on diverse test-time scenarios. Additionally,\na thorough ablation study is conducted to dissect the pivotal elements in DUSA.\nCode is publicly available at https:\/\/github.com\/BIT-DA\/DUSA."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.19362"
    ],
    "c_title":[
      "On the Ising Phase Transition in the Infrared-Divergent Spin Boson Model"
    ],
    "c_abstract":[
      "We prove absence of ground states in the infrared-divergent spin boson model\nat large coupling. Our key argument reduces the proof to verifying long range\norder in the dual one-dimensional continuum Ising model, i.e., to showing that\nthe respective two point function is lower bounded by a strictly positive\nconstant. We can then use known results from percolation theory to establish\nlong range order at large coupling. Combined with the known existence of ground\nstates at small coupling, our result proves that the spin boson model undergoes\na phase transition with respect to the coupling strength. We also present an\nexpansion for the vacuum overlap of the spin boson ground state in terms of the\nIsing $n$-point functions, which implies that the phase transition is unique,\ni.e., that there is a critical coupling constant below which a ground state\nexists and above which none can exist."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-85",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13911"
    ],
    "b_title":[
      "Application of autoresonance in rapid beam extraction of synchrotrons"
    ],
    "b_abstract":[
      "In recent years, ultra-high dose rate (FLASH) radiotherapy has become a novel\ncancer treatment technique because of its similar tumor-killing efficacy as\nconventional particle therapy while significantly protecting normal tissues.\nHowever, due to the limitation of particle number, achieving FLASH condition in\na compact heavy-ion synchrotron requires a short extraction time of tens of\nmilliseconds, which is challenging for the conventional RF-KO method. To tackle\nthis challenge, we introduce autoresonance into the third-order resonant\nextraction for the first time, offering an alternative to the conventional\napproach of merely increasing the excitation strength. By leveraging a strong\ndetuning effect, a frequency sweeping excitation with small amplitude can drive\nthe entire beam into the autoresonant state, thus enabling rapid beam\nextraction within a single sweeping period. Compared with the conventional\nmethod, this innovative method requires only the addition of an octupole\nmagnet. At the same time, it shows that the conventional RF-KO method has a\nhigh autoresonance threshold, so that only a small number of particles that\nmeet the threshold can be excited to large amplitude and be extracted in each\nsweeping period. In this paper, the autoresonance threshold of a particle in\nthe presence of sextupole and octupole magnetic fields is analyzed, and the\nsingle particle simulation shows good agreement with the theoretical formula.\nFurthermore, the autoresonance based rapid extraction process is simulated and\nstudied, revealing the possibility of millisecond scale beam extraction."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08593"
    ],
    "c_title":[
      "Image-to-Force Estimation for Soft Tissue Interaction in\n  Robotic-Assisted Surgery Using Structured Light"
    ],
    "c_abstract":[
      "For Minimally Invasive Surgical (MIS) robots, accurate haptic interaction\nforce feedback is essential for ensuring the safety of interacting with soft\ntissue. However, most existing MIS robotic systems cannot facilitate direct\nmeasurement of the interaction force with hardware sensors due to space\nlimitations. This letter introduces an effective vision-based scheme that\nutilizes a One-Shot structured light projection with a designed pattern on soft\ntissue coupled with haptic information processing through a trained\nimage-to-force neural network. The images captured from the endoscopic stereo\ncamera are analyzed to reconstruct high-resolution 3D point clouds for soft\ntissue deformation. Based on this, a modified PointNet-based force estimation\nmethod is proposed, which excels in representing the complex mechanical\nproperties of soft tissue. Numerical force interaction experiments are\nconducted on three silicon materials with different stiffness. The results\nvalidate the effectiveness of the proposed scheme."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-86",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05214"
    ],
    "b_title":[
      "Gaussian Random Fields as an Abstract Representation of Patient Metadata\n  for Multimodal Medical Image Segmentation"
    ],
    "b_abstract":[
      "The growing rate of chronic wound occurrence, especially in patients with\ndiabetes, has become a concerning trend in recent years. Chronic wounds are\ndifficult and costly to treat, and have become a serious burden on health care\nsystems worldwide. Chronic wounds can have devastating consequences for the\npatient, with infection often leading to reduced quality of life and increased\nmortality risk. Innovative deep learning methods for the detection and\nmonitoring of such wounds have the potential to reduce the impact to both\npatient and clinician. We present a novel multimodal segmentation method which\nallows for the introduction of patient metadata into the training workflow\nwhereby the patient data are expressed as Gaussian random fields. Our results\nindicate that the proposed method improved performance when utilising multiple\nmodels, each trained on different metadata categories. Using the Diabetic Foot\nUlcer Challenge 2022 test set, when compared to the baseline results\n(intersection over union = 0.4670, Dice similarity coefficient = 0.5908) we\ndemonstrate improvements of +0.0220 and +0.0229 for intersection over union and\nDice similarity coefficient respectively. This paper presents the first study\nto focus on integrating patient data into a chronic wound segmentation\nworkflow. Our results show significant performance gains when training\nindividual models using specific metadata categories, followed by average\nmerging of prediction masks using distance transforms. All source code for this\nstudy is available at:\nhttps:\/\/github.com\/mmu-dermatology-research\/multimodal-grf"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.04897"
    ],
    "c_title":[
      "Iterative phase retrieval algorithm for space-variant PSF in optical\n  systems with aberrations"
    ],
    "c_abstract":[
      "Iterative phase retrieval algorithms are widely used in digital optics for\ntheir efficiency and simplicity. Conventionally, these algorithms do not\nconsider aberrations as they assume an ideal, aberration-free optical system.\nHere, we propose modified iterative phase retrieval algorithms that take into\naccount the space-invariant and space-variant point spread function of the\noptical system."
    ],
    "c_categories":[
      [
        "physics.comp-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-87",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15633"
    ],
    "b_title":[
      "RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes"
    ],
    "b_abstract":[
      "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can\nproduce high-fidelity novel views. However, previous GS-based methods primarily\ntarget indoor scenes and rely on RGB-D sensors or pre-trained depth estimation\nmodels, hence underperforming in outdoor scenarios. To address this issue, we\npropose a RGB-only gaussian splatting SLAM method for unbounded outdoor\nscenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network\nto generate consistent pointmaps between frames for pose estimation. Compared\nto commonly used depth maps, pointmaps include spatial relationships and scene\ngeometry across multiple views, enabling robust camera pose estimation. Then,\nwe propose integrating the estimated camera poses with 3DGS rendering as an\nend-to-end differentiable pipeline. Our method achieves simultaneous\noptimization of camera poses and 3DGS scene parameters, significantly enhancing\nsystem tracking accuracy. Specifically, we also design an adaptive scale mapper\nfor the pointmap regression network, which provides more accurate pointmap\nmapping to the 3DGS map representation. Our experiments on the Waymo dataset\ndemonstrate that OpenGS-SLAM reduces tracking error to 9.8\\% of previous 3DGS\nmethods, and achieves state-of-the-art results in novel view synthesis. Project\nPage: https:\/\/3dagentworld.github.io\/opengs-slam\/"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02929"
    ],
    "c_title":[
      "Reducing Circuit Depth in Quantum State Preparation for Quantum\n  Simulation Using Measurements and Feedforward"
    ],
    "c_abstract":[
      "Reducing circuit depth and identifying an optimal trade-off between circuit\ndepth and width is crucial for successful quantum computation. In this context,\nmid-circuit measurement and feedforward have been shown to significantly reduce\nthe depth of quantum circuits, particularly in implementing logical gates. By\nleveraging these techniques, we propose several parallelization strategies that\nreduce quantum circuit depth at the expense of increasing width in preparing\nvarious quantum states relevant to quantum simulation. With measurements and\nfeedforward, we demonstrate that utilizing unary encoding as a bridge between\ntwo quantum states substantially reduces the circuit depth required for\npreparing quantum states, such as sparse quantum states and sums of Slater\ndeterminants within the first quantization framework, while maintaining an\nefficient circuit width. Additionally, we show that a coordinate Bethe ansatz,\ncharacterized by its high degree of freedom in its phase, can be\nprobabilistically prepared in a constant-depth quantum circuit using\nmeasurements and feedforward. We anticipate that our study will contribute to\nthe reduction of circuit depth in initial state preparation, particularly for\nquantum simulation, which is a critical step toward achieving quantum\nadvantage."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-88",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03864"
    ],
    "b_title":[
      "Temporal regularity for the stochastic heat equation with rough\n  dependence in space"
    ],
    "b_abstract":[
      "Consider the nonlinear stochastic heat equation $$\n  \\frac{\\partial u (t,x)}{\\partial t}=\\frac{\\partial^2 u (t,x)}{\\partial x^2}+\n\\sigma(u (t,x))\\dot{W}(t,x),\\quad t> 0,\\,\n  x\\in \\mathbb{R}, $$ where $\\dot W$ is a Gaussian noise which is white in time\nand has the covariance of a fractional Brownian motion with Hurst parameter\n$H\\in(\\frac 14,\\frac 12)$ in the space variable. When $\\sigma(0)=0$, the\nwell-posedness of the solution and its H\\\"older continuity have been proved by\nHu et al. \\cite{HHLNT2017}. In this paper, we study the asymptotic properties\nof the temporal gradient $u(t+\\varepsilon, x)-u(t, x)$ at any fixed $t \\ge 0$\nand $x\\in \\mathbb R$, as $\\varepsilon\\downarrow 0$. As applications, we deduce\nKhintchine's law of iterated logarithm, Chung's law of iterated logarithm, and\na result on the $q$-variations of the temporal process $\\{u(t, x)\\}_{t \\ge 0}$,\nwhere $x\\in \\mathbb R$ is fixed."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07030"
    ],
    "c_title":[
      "Sensitivity of Online Feedback Optimization to time-varying parameters"
    ],
    "c_abstract":[
      "Online Feedback Optimization uses optimization algorithms as dynamic systems\nto design optimal control inputs. The results obtained from Online Feedback\nOptimization depend on the setup of the chosen optimization algorithm. In this\nwork we analyse the sensitivity of Online Feedback Optimization to the\nparameters of projected gradient descent as the algorithm of choice. We derive\nclosed-form expressions for sensitivities of the objective function with\nrespect to the parameters of the projected gradient and to time-varying model\nmismatch. The formulas are then used for analysis of model mismatch in a gas\nlift optimization problem. The results of the case study indicate that the\nsensitivity of Online Feedback Optimization to the model mismatch depends on\nhow long the controller has been running, with decreasing sensitivity to\nmismatch in individual timesteps for long operation times."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-89",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06678"
    ],
    "b_title":[
      "Quantile Multi-Armed Bandits with 1-bit Feedback"
    ],
    "b_abstract":[
      "In this paper, we study a variant of best-arm identification involving\nelements of risk sensitivity and communication constraints. Specifically, the\ngoal of the learner is to identify the arm with the highest quantile reward,\nwhile the communication from an agent (who observes rewards) and the learner\n(who chooses actions) is restricted to only one bit of feedback per arm pull.\nWe propose an algorithm that utilizes noisy binary search as a subroutine,\nallowing the learner to estimate quantile rewards through 1-bit feedback. We\nderive an instance-dependent upper bound on the sample complexity of our\nalgorithm and provide an algorithm-independent lower bound for specific\ninstances, with the two matching to within logarithmic factors under mild\nconditions, or even to within constant factors in certain low error probability\nscaling regimes. The lower bound is applicable even in the absence of\ncommunication constraints, and thus we conclude that restricting to 1-bit\nfeedback has a minimal impact on the scaling of the sample complexity."
    ],
    "b_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.04739"
    ],
    "c_title":[
      "Universal thermodynamic topological classes of black holes in perfect\n  fluid dark matter background"
    ],
    "c_abstract":[
      "In this paper, we study the universal thermodynamic topological classes of a\nfamily of black holes in a perfect fluid dark matter (PFDM) background. Recent\nresearch on black hole thermodynamics suggests that all black holes can be\nclassified into four universal thermodynamic classes, denoted by $W^{1-}$,\n$W^{0+}$, $W^{0-}$, and $W^{1+}$. Our study reveals that the Schwarzschild\nblack hole in PFDM belongs to the $W^{1-}$ class, and independence of black\nhole size thermodynamically unstable at both low- and high-temperature limits.\nThe Reissner-Nordstr\\\"om, Kerr, and Kerr-Newman black holes in the PFDM\nbackground belong to the same universal thermodynamic class, $W^{0+}$, which\nrepresents small, stable black holes and large, unstable black holes at\nlow-temperature limits, whereas no black hole state exists at high\ntemperatures. The AdS black holes behave differently compared to their\ncounterparts in PFDM. The Schwarzschild-AdS black hole belongs to the $W^{0-}$\nclass, indicating no black hole state at low temperatures, but small, unstable\nand large, stable black hole states at high temperatures. Furthermore, the\nKerr-AdS black hole belongs to the $W^{1+}$ class, characterized by small,\nstable black holes at low temperatures, large, stable black holes at high\ntemperatures, and unstable, intermediate-sized black holes at both low and high\ntemperatures. These findings uncover the universal topological classifications\nunderlying black hole thermodynamics, offering profound insights into the\nfundamental principles of quantum gravity."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-90",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09690"
    ],
    "b_title":[
      "Operator models and analytic subordination for operator-valued free\n  convolution powers"
    ],
    "b_abstract":[
      "We revisit the theory of operator-valued free convolution powers given by a\ncompletely positive map $\\eta$. We first give a general result, with a new\nanalytic proof, that the $\\eta$-convolution power of the law of $X$ is realized\nby $V^*XV$ for any operator $V$ satisfying certain conditions, which unifies\nNica and Speicher's construction in the scalar-valued setting and\nShlyakhtenko's construction in the operator-valued setting. Second, we provide\nan analog, for the setting of $\\eta$-valued convolution powers, of the analytic\nsubordination for conditional expectations that holds for additive free\nconvolution. Finally, we describe a Hilbert-space manipulation that explains\nthe equivalence between the $n$-fold additive free convolution and the\nconvolution power with respect to $\\eta = n \\operatorname{id}$."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.01721"
    ],
    "c_title":[
      "Uncovering the Iceberg in the Sea: Fundamentals of Pulse Shaping and\n  Modulation Design for Random ISAC Signals"
    ],
    "c_abstract":[
      "Integrated Sensing and Communications (ISAC) is expected to play a pivotal\nrole in future 6G networks. To maximize time-frequency resource utilization, 6G\nISAC systems must exploit data payload signals, that are inherently random, for\nboth communication and sensing tasks. This paper provides a comprehensive\nanalysis of the sensing performance of such communication-centric ISAC signals,\nwith a focus on modulation and pulse shaping design to reshape the statistical\nproperties of their auto-correlation functions (ACFs), thereby improving the\ntarget ranging performance. We derive a closed-form expression for the\nexpectation of the squared ACF of random ISAC signals, considering arbitrary\nmodulation bases and constellation mappings within the Nyquist pulse shaping\nframework. The structure is metaphorically described as an ``iceberg hidden in\nthe sea\", where the ``iceberg'' represents the squared mean of the ACF of\nrandom ISAC signals, that is determined by the pulse shaping filter, and the\n``sea level'' characterizes the corresponding variance, caused by the\nrandomness of the data payload. Our analysis shows that, for QAM\/PSK\nconstellations with Nyquist pulse shaping, Orthogonal Frequency Division\nMultiplexing (OFDM) achieves the lowest ranging sidelobe level across all lags.\nBuilding on these insights, we propose a novel Nyquist pulse shaping design to\nenhance the sensing performance of random ISAC signals. Numerical results\nvalidate our theoretical findings, showing that the proposed pulse shaping\nsignificantly reduces ranging sidelobes compared to conventional root-raised\ncosine (RRC) pulse shaping, thereby improving the ranging performance."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-91",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08689"
    ],
    "b_title":[
      "Mining Diamonds in labeled Transition Systems"
    ],
    "b_abstract":[
      "Labeled transition systems can be a great way to visualize the complex\nbehavior of parallel and communicating systems. However, if, during a\nparticular timeframe, no synchronization or communication between processes\noccurs, then multiple parallel sequences of actions are able to interleave\narbitrarily, and the resulting graph quickly becomes too complex for the human\neye to understand easily. With that in mind, we propose an exact formalization\nof these arbitrary interleavings, and an algorithm to find all said\ninterleavings in deterministic LTSs, to reduce the visual complexity of labeled\ntransition systems."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00842"
    ],
    "c_title":[
      "Adiabatic Index in Fluid Models of Collisionless Black Hole Accretion"
    ],
    "c_abstract":[
      "Models of highly sub-Eddington accretion onto black holes commonly use a\nsingle fluid model for the collisionless, near-horizon plasma. These models\nmust specify an equation of state. It is common to use an ideal gas with $p =\n(\\gamma - 1) u$ and $\\gamma = 4\/3, 13\/9,$ or $5\/3$, but these produce\nsignificantly different outcomes. We discuss the origins of this discrepancy\nand the assumptions underlying the single fluid model. The main result of this\ninvestigation is that under conditions relevant to low luminosity black hole\naccretion the best choice of single fluid adiabatic index is close to but\nslightly less than $5\/3$. Along the way we provide a simple equilibrium model\nfor the relation between the ion-to-electron dissipation ratio and the ion to\nelectron temperature ratio and explore the implications for electron\ntemperature fluctuations in Event Horizon Telescope sources."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-92",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06135"
    ],
    "b_title":[
      "Phase structure analysis of CP(1) model with $\\theta$ term by tensor\n  renormalization group"
    ],
    "b_abstract":[
      "We analyze the phase structure of 2d lattice CP(1) model with $\\theta$ term\nby using the bond-weighted tensor renormalization group method. We propose a\nnew tensor network representation for the model using the quadrature scheme and\nconfirm that its accuracy is better than that of the conventional\ncharacter-like expansion. As a probe to study the phase structure, we adopt the\ncentral charge and the scaling dimensions. The numerical results indicate an\nexistence of critical point at $\\theta=\\pi$, which is consistent with the\nHaldane's conjecture."
    ],
    "b_categories":[
      [
        "hep-lat"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.18460"
    ],
    "c_title":[
      "DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense\n  Retrievers"
    ],
    "c_abstract":[
      "Large language models (LLMs) have demonstrated strong effectiveness and\nrobustness while fine-tuned as dense retrievers. However, their large parameter\nsize brings significant inference time computational challenges, including high\nencoding costs for large-scale corpora and increased query latency, limiting\ntheir practical deployment. While smaller retrievers offer better efficiency,\nthey often fail to generalize effectively with limited supervised fine-tuning\ndata. In this work, we introduce DRAMA, a training framework that leverages\nLLMs to train smaller generalizable dense retrievers. In particular, we adopt\npruned LLMs as the backbone and train on diverse LLM-augmented data in a\nsingle-stage contrastive learning setup. Experiments show that DRAMA offers\nbetter multilingual and long-context capabilities than traditional\nencoder-based retrievers, and achieves strong performance across multiple tasks\nand languages. These highlight the potential of connecting the training of\nsmaller retrievers with the growing advancements in LLMs, bridging the gap\nbetween efficiency and generalization."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-93",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03361"
    ],
    "b_title":[
      "Strong Lensing analysis of SPT-CLJ2325$-$4111 and SPT-CLJ0049$-$2440,\n  two Powerful Cosmic Telescopes ($R_E > 40''$) from the SPT Clusters Sample"
    ],
    "b_abstract":[
      "We report the results from a study of two massive ($M_{500c} > 6.0 \\times\n10^{14} M_{\\odot}$) strong lensing clusters selected from the South Pole\nTelescope cluster survey for their high Einstein radius ($R_E > 40''$),\nSPT-CLJ2325$-$4111 and SPT-CLJ0049$-$2440. Ground-based and shallow HST imaging\nindicated extensive strong lensing evidence in these fields, with giant arcs\nspanning 18\\arcsec\\ and 31\\arcsec, respectively, motivating further space-based\nimaging followup. Here, we present multiband HST imaging and ground-based\nMagellan spectroscopy of the fields, from which we compile detailed strong\nlensing models. The lens models of SPT-CL\\,J2325$-$4111 and\nSPT-CL\\,J0049$-$2440 were optimized using 9, and 8 secure multiple-imaged\nsystems with a final image-plane rms of 0\\farcs63 and 0\\farcs73, respectively.\nFrom the lensing analysis, we measure the projected mass density within 500~kpc\nof $M(<500 ~{\\rm kpc}) = 7.30\\pm0.07 \\times 10^{14}$$M_{\\odot}$, and $M(<500\n~{\\rm kpc})=7.12^{+0.16}_{-0.19}\\times 10^{14}$ $M_{\\odot}$ for these two\nclusters, and a sub-halos mass ratio of $0.12\\pm{0.01}$ and\n$0.21^{+0.07}_{-0.05}$, respectively. Both clusters produce a large area with\nhigh magnification ($\\mu\\geq 3$) for a source at $z=9$, $A^{lens}_{| \\mu | \\geq\n3 }=4.93^{+0.03}_{-0.04} arcmin^2$, and $A^{lens}_{| \\mu | \\geq 3\n}=3.64^{+0.14}_{-0.10} arcmin^2$ respectively, placing them in the top tier of\nstrong lensing clusters. We conclude that these clusters are spectacular\nsightlines for further observations that will reduce the systematic\nuncertainties due to cosmic variance. This paper provides the community with\ntwo additional well-calibrated cosmic telescopes, as strong as the Frontier\nFields, suitable for studies of the highly magnified background Universe."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.04294"
    ],
    "c_title":[
      "A shadowable chain recurrent set with an attached hyperbolic singularity"
    ],
    "c_abstract":[
      "We construct a $C^\\infty$-flow on the four-dimensional sphere whose\nnonwandering set contains an attached hyperbolic singularity yet possesses the\nstandard shadowing property. This gives a counterexample to a conjecture given\nby Arbieto, L\\'{o}pez, Rego and S\\'{a}nchez (Math. Annalen 390:417-437)."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-94",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11761"
    ],
    "b_title":[
      "Strong and weak dynamo regimes in Taylor-Couette flows"
    ],
    "b_abstract":[
      "We reveal a nonlinear magnetic dynamo in a Taylor-Couette flow at small\nmagnetic Prandtl numbers $Pm\\leq 1$, which has been previously believed to\nexist only at higher $Pm\\gtrsim 10$ in this flow. Both the amplitude of initial\nperturbations and $Pm$ play a critical role in its onset and evolution. It is\nshown that this dynamo exists in two main states -- a weak state dominated by\nlarge-scale modes and a strong, more turbulent state with higher amplitude\ndominated by small-scale modes. These findings can be important for dynamo\nprocesses in many astrophysical settings with small $Pm$."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.flu-dyn",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08763"
    ],
    "c_title":[
      "Evaluating Decision Rules Across Many Weak Experiments"
    ],
    "c_abstract":[
      "Technology firms conduct randomized controlled experiments (\"A\/B tests\") to\nlearn which actions to take to improve business outcomes. In firms with mature\nexperimentation platforms, experimentation programs can consist of many\nthousands of tests. To scale experimentation effectively, firms rely on\ndecision rules: standard operating procedures for mapping the results of an\nexperiment to a choice of treatment arm to launch to the general user\npopulation. Despite the critical role of decision rules in translating\nexperimentation into business decisions, rigorous guidance on how to evaluate\nand choose decision rules is scarce. This paper proposes to evaluate decision\nrules based on their cumulative returns to business north star metrics.\nAlthough this quantity is intuitive and easy to explain to decision-makers,\nestimating it can be non-trivial, especially when experiments have weak\nsignal-to-noise ratios. We develop a cross-validation estimator that is much\nless biased than the naive plug-in estimator under conditions realistic to\ndigital experimentation. We demonstrate the efficacy of our approach via a case\nstudy of 123 historical A\/B tests at Netflix, where we used it to show that a\nnew decision rule would increase cumulative returns to the north star metric by\nan estimated 33%, leading directly to the adoption of the new rule."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-95",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15299"
    ],
    "b_title":[
      "On type 1 active galactic nuclei with double-peaked [O~{\\sc iii}]. I.\n  data sample and basic results"
    ],
    "b_abstract":[
      "Double-peaked narrow emission lines (DPNELs) might be evidence for the\nexistence of kpc-scale dual AGNs. There are so far large samples of objects\nwith DPNELs in narrow emission line galaxies. Here, a systematic search is made\nto build a sample of type 1 AGNs with double-peaked [O~{\\sc~iii}] from Data\nRelease 16 of the Sloan Digital Sky Survey (SDSS). Through visually inspecting\nand fitting [O~{\\sc~iii}], fitting broad H$\\alpha$ emission lines, performing\nF-test for [O~{\\sc~iii}] profiles, and checking broad H$\\beta$ and\n[O~{\\sc~iii}] emission lines, we select 62 type 1 AGNs with reliable\ndouble-peaked [O~{\\sc~iii}] from 11557 QSOs with z < 0.3. After visually\nchecking the 62 SDSS multi-color images, we find only seven objects with signs\nof merging. Four possible models for the double-peaked [O~{\\sc~iii}] observed\nin our sample are discussed: the superposition model, AGN outflow model, dual\nAGN model, and rotating disk model. However, the current results can not\nprovide any one explanation conclusively, and additional observational data are\nneeded to provide the details of narrow line regions. But at least 22 objects\nwith different velocity offsets between double-peaked [O~{\\sc~iii}] and narrow\nH$\\alpha$ emission lines could be excluded as dual AGN candidates. The relative\nvelocity offsets of the [O~{\\sc~iii}] blue-shifted\/red-shifted components are\nnegative to their line flux ratios, which is consistent with dual AGN model.\nThis work provides a new sample of 62 type 1 AGNs with double-peaked\n[O~{\\sc~iii}] for further study."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14619"
    ],
    "c_title":[
      "Reward Models Identify Consistency, Not Causality"
    ],
    "c_abstract":[
      "Reward models (RMs) play a crucial role in aligning large language models\n(LLMs) with human preferences and enhancing reasoning quality. Traditionally,\nRMs are trained to rank candidate outputs based on their correctness and\ncoherence. However, in this work, we present several surprising findings that\nchallenge common assumptions about RM behavior. Our analysis reveals that\nstate-of-the-art reward models prioritize structural consistency over causal\ncorrectness. Specifically, removing the problem statement has minimal impact on\nreward scores, whereas altering numerical values or disrupting the reasoning\nflow significantly affects RM outputs. Furthermore, RMs exhibit a strong\ndependence on complete reasoning trajectories truncated or incomplete steps\nlead to significant variations in reward assignments, indicating that RMs\nprimarily rely on learned reasoning patterns rather than explicit problem\ncomprehension. These findings hold across multiple architectures, datasets, and\ntasks, leading to three key insights: (1) RMs primarily assess coherence rather\nthan true reasoning quality; (2) The role of explicit problem comprehension in\nreward assignment is overstated; (3) Current RMs may be more effective at\nranking responses than verifying logical validity. Our results suggest a\nfundamental limitation in existing reward modeling approaches, emphasizing the\nneed for a shift toward causality-aware reward models that go beyond\nconsistency-driven evaluation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-96",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05241"
    ],
    "b_title":[
      "Contrast-Free Myocardial Scar Segmentation in Cine MRI using Motion and\n  Texture Fusion"
    ],
    "b_abstract":[
      "Late gadolinium enhancement MRI (LGE MRI) is the gold standard for the\ndetection of myocardial scars for post myocardial infarction (MI). LGE MRI\nrequires the injection of a contrast agent, which carries potential side\neffects and increases scanning time and patient discomfort. To address these\nissues, we propose a novel framework that combines cardiac motion observed in\ncine MRI with image texture information to segment the myocardium and scar\ntissue in the left ventricle. Cardiac motion tracking can be formulated as a\nfull cardiac image cycle registration problem, which can be solved via deep\nneural networks. Experimental results prove that the proposed method can\nachieve scar segmentation based on non-contrasted cine images with comparable\naccuracy to LGE MRI. This demonstrates its potential as an alternative to\ncontrast-enhanced techniques for scar detection."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20210"
    ],
    "c_title":[
      "Decay of resolvent kernels and Schr\\\"odinger eigenstates for L\\'evy\n  operators"
    ],
    "c_abstract":[
      "We study the spatial decay behaviour of resolvent kernels for a large class\nof non-local L\\'evy operators and bound states of the corresponding\nSchr\\\"odinger operators. Our findings naturally lead us to proving results for\nL\\'evy measures, which have subexponential or exponential decay, respectively.\nThis leads to sharp transitions in the the decay rates of the resolvent\nkernels. We obtain estimates that allow us to describe and understand the\nintricate decay behaviour of the resolvent kernels and the bound states in\neither regime, extending findings by Carmona, Masters and Simon for fractional\nLaplacians (the subexponential regime) and classical relativistic operators\n(the exponential regime). Our proofs are mainly based on methods from the\ntheory of operator semigroups."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.FA",
        "math.MP",
        "math.PR",
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-97",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04879"
    ],
    "b_title":[
      "Statistical Collusion by Collectives on Learning Platforms"
    ],
    "b_abstract":[
      "As platforms increasingly rely on learning algorithms, collectives may form\nand seek ways to influence these platforms to align with their own interests.\nThis can be achieved by coordinated submission of altered data. To evaluate the\npotential impact of such behavior, it is essential to understand the\ncomputations that collectives must perform to impact platforms in this way. In\nparticular, collectives need to make a priori assessments of the effect of the\ncollective before taking action, as they may face potential risks when\nmodifying their data. Moreover they need to develop implementable coordination\nalgorithms based on quantities that can be inferred from observed data. We\ndevelop a framework that provides a theoretical and algorithmic treatment of\nthese issues and present experimental results in a product evaluation domain."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.10565"
    ],
    "c_title":[
      "Conical Targets for Enhanced High-Current Positron Sources"
    ],
    "c_abstract":[
      "Previous pair-production-driven positron source designs have assumed that the\ntransverse dimension of the target is significantly greater than the secondary\nbeam it generates. This paper explores the use of targets with different\ntransverse profiles with the aim of enhancing positron production. The starting\npoint of this research is the concept of wire targets, proposed by M. James et\nal. in 1991 for the former SLC positron source. Building on this foundation,\nthis study takes this concept a step further by introducing conical-shaped\ntargets, which can substantially improve the yield by reducing the reabsorption\nof positrons by the target--an issue that is worsened by the high-field\nsolenoid lenses commonly used for positron capture. Using Geant4 simulations,\nwe propose new conical targets adapted for the parameters of the future\ncollider FCC-ee and its positron source test facility P-cubed (PSI Positron\nProduction experiment) at the Paul Scherrer Institute. We find that conical\ntargets can nearly double the positron production at the target and enhance the\nbaseline positron yield of FCC-ee by around 60%. Additionally, we present the\nthermo-mechanical studies for the conical targets based on the FCC-ee primary\nbeam power requirements and outline the mechanical implementation for a future\nproof-of-principle demonstration at the P-cubed facility."
    ],
    "c_categories":[
      [
        "hep-ex",
        "physics.acc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-98",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14368"
    ],
    "b_title":[
      "Langevin model for soliton molecules in ultrafast fiber ring laser\n  cavity: investigating experimentally the interplay between noise and inertia"
    ],
    "b_abstract":[
      "The dynamics of soliton molecules in ultrafast fiber ring laser cavity is\nstrongly influenced by noise. We show how a parsimonious Langevin model can be\nconstructed from experimental data, resulting in a mathematical description\nthat encompasses both the deterministic and stochastic properties of the\nevolution of the soliton molecules. In particular, we were able to probe the\nresponse dynamics of the soliton molecule to an external kick in a sub-critical\napproach, namely without the need to actually disturb the systems under\ninvestigation. Moreover, the noise experienced by the dissipative solitonic\nsystem, including its distribution and correlation, can now be also analyzed in\ndetails. Our strategy can be applied to any systems where the individual motion\nof its constitutive particles can be traced; the case of optical\nsolitonic-system laser presented here serving as a proof-of-principle\ndemonstration."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.04378"
    ],
    "c_title":[
      "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\n  Open-Ended General-Domain Tasks"
    ],
    "c_abstract":[
      "Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-99",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17484"
    ],
    "b_title":[
      "Capacity Expansion Planning under Uncertainty subject to Expected Energy\n  Not Served Constraints"
    ],
    "b_abstract":[
      "We present a method for solving a large-scale stochastic capacity expansion\nproblem which explicitly considers reliability constraints, in particular\nconstraints on expected energy not served. Our method tackles this problem by a\nLagrange relaxation of the expected energy not served constraints. We solve the\nrelaxed formulation in an iterative manner, using a subgradient-based method.\nEach iteration requires the solution of a stochastic capacity expansion\nproblem, for which we implement a subgradient decomposition scheme in a\nhigh-performance computing infrastructure. We apply the proposed methodology on\nthe Economic Viability Assessment model that is used by ENTSO-E in the annual\nEuropean Resource Adequacy Assessment, extended to include explicit reliability\nconstraints. The approach is able to solve this model achieving a 1.3%\noptimality gap. We compare our approach against accounting for reliability\nthrough penalizing load shedding at VOLL, and find that the former results in\n1.6% savings in total cost. We are also able to quantify the cost savings from\nallowing some load curtailment in the capacity planning process, which ranges\nfrom 1.6 to 6% in the cases analyzed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11443"
    ],
    "c_title":[
      "On the hierarchy of plate models for a singularly perturbed multi-well\n  nonlinear elastic energy"
    ],
    "c_abstract":[
      "In the celebrated work of Friesecke, James and M\\\"uller '06 the authors\nderive a hierarchy of models for plates by carefully analyzing the\n$\\Gamma$-convergence of the rescaled nonlinear elastic energy. The key\ningredient of their proofs is the rigidity estimate proved in an earlier work\nof theirs. Here we consider the case in which the elastic energy has a\nmulti-well structure: this type of functional arises, for example, in the study\nof solid-solid phase transitions. Since the rigidity estimate fails in the case\nof compatible wells, we follow Alicandro, Dal Maso, Lazzaroni and Palombaro '18\nand add a regularization term to the energy that penalizes jumps from one well\nto another, leading to good compactness properties. In this setting we recover\nthe full hierarchy of plate models with an explicit dependence on the wells.\nFinally, we study the convergence of energy minimizers with suitable external\nforces and full Neumann boundary conditions. To do so, we adapt the definition\nof optimal rotations introduced by Maor, Mora '21."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-100",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12568"
    ],
    "b_title":[
      "A Cognitive Writing Perspective for Constrained Long-Form Text\n  Generation"
    ],
    "b_abstract":[
      "Like humans, Large Language Models (LLMs) struggle to generate high-quality\nlong-form text that adheres to strict requirements in a single pass. This\nchallenge is unsurprising, as successful human writing, according to the\nCognitive Writing Theory, is a complex cognitive process involving iterative\nplanning, translating, reviewing, and monitoring. Motivated by these cognitive\nprinciples, we aim to equip LLMs with human-like cognitive writing capabilities\nthrough CogWriter, a novel training-free framework that transforms LLM\nconstrained long-form text generation into a systematic cognitive writing\nparadigm. Our framework consists of two key modules: (1) a Planning Agent that\nperforms hierarchical planning to decompose the task, and (2) multiple\nGeneration Agents that execute these plans in parallel. The system maintains\nquality via continuous monitoring and reviewing mechanisms, which evaluate\noutputs against specified requirements and trigger necessary revisions.\nCogWriter demonstrates exceptional performance on LongGenBench, a benchmark for\ncomplex constrained long-form text generation. Even when using Qwen-2.5-14B as\nits backbone, CogWriter surpasses GPT-4o by 22% in complex instruction\ncompletion accuracy while reliably generating texts exceeding 10,000 words. We\nhope this cognitive science-inspired approach provides a paradigm for LLM\nwriting advancements:\n\\href{https:\/\/github.com\/KaiyangWan\/CogWriter}{CogWriter}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05860"
    ],
    "c_title":[
      "Multidimensional moment problem and Stieltjes transform"
    ],
    "c_abstract":[
      "The truncated multidimensional moment problem is studied in terms of the\nStieltjes transform as the interpolation problem. A step-by-step algorithm is\nconstructed for the multidimensional moment problem and the set of solutions is\nfound in terms of continued fractions."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-101",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12233"
    ],
    "b_title":[
      "Robust Full-Space Physical Layer Security for STAR-RIS-Aided Wireless\n  Networks: Eavesdropper with Uncertain Location and Channel"
    ],
    "b_abstract":[
      "A robust full-space physical layer security (PLS) transmission scheme is\nproposed in this paper considering the full-space wiretapping challenge of\nwireless networks supported by simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS). Different from the existing\nschemes, the proposed PLS scheme takes account of the uncertainty on the\neavesdropper's position within the 360$^\\circ$ service area offered by the\nSTAR-RIS. Specifically, the large system analytical method is utilized to\nderive the asymptotic expression of the average security rate achieved by the\nsecurity user, considering that the base station (BS) only has the statistical\ninformation of the eavesdropper's channel state information (CSI) and the\nuncertainty of its location. To evaluate the effectiveness of the proposed PLS\nscheme, we first formulate an optimization problem aimed at maximizing the\nweighted sum rate of the security user and the public user. This optimization\nis conducted under the power allocation constraint, and some practical\nlimitations for STAR-RIS implementation, through jointly designing the active\nand passive beamforming variables. A novel iterative algorithm based on the\nminimum mean-square error (MMSE) and cross-entropy optimization (CEO) methods\nis proposed to effectively address the established non-convex optimization\nproblem with discrete variables. Simulation results indicate that the proposed\nrobust PLS scheme can effectively mitigate the information leakage across the\nentire coverage area of the STAR-RIS-assisted system, leading to superior\nperformance gain when compared to benchmark schemes encompassing traditional\nRIS-aided scheme."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01500"
    ],
    "c_title":[
      "Gamma\/hadron separation in the TAIGA experiment with neural network\n  methods"
    ],
    "c_abstract":[
      "In this work, the ability of rare VHE gamma ray selection with neural network\nmethods is investigated in the case when cosmic radiation flux strongly\nprevails (ratio up to {10^4} over the gamma radiation flux from a point\nsource). This ratio is valid for the Crab Nebula in the TeV energy range, since\nthe Crab is a well-studied source for calibration and test of various methods\nand installations in gamma astronomy. The part of TAIGA experiment which\nincludes three Imaging Atmospheric Cherenkov Telescopes observes this\ngamma-source too. Cherenkov telescopes obtain images of Extensive Air Showers.\nHillas parameters can be used to analyse images in standard processing method,\nor images can be processed with convolutional neural networks. In this work we\nwould like to describe the main steps and results obtained in the gamma\/hadron\nseparation task from the Crab Nebula with neural network methods. The results\nobtained are compared with standard processing method applied in the TAIGA\ncollaboration and using Hillas parameter cuts. It is demonstrated that a signal\nwas received at the level of higher than 5.5{\\sigma} in 21 hours of Crab Nebula\nobservations after processing the experimental data with the neural network\nmethod."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.IM",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-102",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07687"
    ],
    "b_title":[
      "The PLATO field selection process. II. Characterization of LOPS2, the\n  first long-pointing field"
    ],
    "b_abstract":[
      "PLAnetary Transits and Oscillations of stars (PLATO) is an ESA M-class\nmission to be launched by the end of 2026 to discover and characterize\ntransiting planets around bright and nearby stars, and in particular habitable\nrocky planets hosted by solar-like stars. Over the mission lifetime, an average\nof 8% of the science data rate will be allocated to Guest Observer programs\n(GOs) selected by ESA through public calls, hence it is essential for the\ncommunity to know in advance where the observing fields will be located. In a\nprevious paper, we identified two preliminary long-pointing fields (LOPN1 and\nLOPS1) for PLATO, respectively in the northern and southern hemisphere. Here we\npresent LOPS2, a slightly adjusted version of the southern field that has\nrecently been selected by the PLATO Science Working Team as the first field to\nbe observed by PLATO for at least two continuous years, following the\nscientific requirements. In this paper, we describe the astrophysical content\nof LOPS2 in detail, including known planetary systems, bright\/variable\/binary\nstars, clusters and synergies with other current and future facilities."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.14764"
    ],
    "c_title":[
      "A shape-optimization approach for inverse diffusion problems using a\n  single boundary measurement"
    ],
    "c_abstract":[
      "This paper explores the reconstruction of a space-dependent parameter in\ninverse diffusion problems, proposing a shape-optimization-based approach. The\nmain objective is to recover the absorption coefficient from a single boundary\nmeasurement. While conventional gradient-based methods rely on the Fr\\'{e}chet\nderivative of a cost functional with respect to the unknown parameter, we also\nutilize its shape derivative with respect to the unknown boundary interface for\nrecovery. This non-conventional approach addresses the problem of parameter\nrecovery from a single measurement, which represents the key innovation of this\nwork. Numerical experiments confirm the effectiveness of the proposed method,\neven for intricate and non-convex boundary interfaces."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-103",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01626"
    ],
    "b_title":[
      "Treatment of Thermal Non-Equilibrium Dissociation Rates: Application to\n  $\\rm H_2$"
    ],
    "b_abstract":[
      "This work presents a detailed description of the thermochemical\nnon-equilibrium dissociation of diatomic molecules, and applies this theory to\nthe case of $\\rm H_2$ dissociation. The master equations are used to derive\ncorresponding aggregate rate constant expressions that hold for any degree of\nthermochemical non-equilibrium. These general expressions are analyzed in three\nkey limits\/ regimes: the thermal equilibrium limit, the quasi-steady-state\n(QSS) regime, and the pre-QSS regime. Under several simplifying assumptions, an\nanalytical source term expression that holds in all of these regimes, and is\nonly a function of the translational temperature, $T_{\\rm t}$, and the fraction\nof dissociation, $\\phi_{\\rm A}$, is proposed. This expression has two input\nparameters: the QSS dissociation rate constant in the absence of recombination,\n$k_{\\rm d,nr}(T_{\\rm t})$, and a pre-QSS correction factor, $\\eta(T_{\\rm t})$.\nThe value of $\\eta(T_{\\rm t})$ is evaluated by comparing the predictions of the\nproposed expression against existing master equation simulations of a 0-D\nisothermal and isochoric reactor for the case of $\\rm H_2$ dissociation with\nthe third-bodies $\\rm H_2$, $\\rm H$, and $\\rm He$. Despite its simple\nfunctional form, the proposed expression is able to reproduce the master\nequation results for the majority of the tested conditions. The best fit of\n$k_{\\rm d,nr}(T_{\\rm t})$ is then evaluated by conducting a detailed literature\nreview. Data from a wide range of experimental and computational studies are\nconsidered for the third-bodies $\\rm H_2$, $\\rm H$, and inert gases, and fits\nthat are valid from 200 to 20,000 K are proposed. From this review, the\nuncertainty of the proposed fits are estimated to be less than a factor of two."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17194"
    ],
    "c_title":[
      "Curriculum RL meets Monte Carlo Planning: Optimization of a Real World\n  Container Management Problem"
    ],
    "c_abstract":[
      "In this work, we augment reinforcement learning with an inference-time\ncollision model to ensure safe and efficient container management in a\nwaste-sorting facility with limited processing capacity. Each container has two\noptimal emptying volumes that trade off higher throughput against overflow\nrisk. Conventional reinforcement learning (RL) approaches struggle under\ndelayed rewards, sparse critical events, and high-dimensional uncertainty --\nfailing to consistently balance higher-volume empties with the risk of\nsafety-limit violations. To address these challenges, we propose a hybrid\nmethod comprising: (1) a curriculum-learning pipeline that incrementally trains\na PPO agent to handle delayed rewards and class imbalance, and (2) an offline\npairwise collision model used at inference time to proactively avert collisions\nwith minimal online cost. Experimental results show that our targeted\ninference-time collision checks significantly improve collision avoidance,\nreduce safety-limit violations, maintain high throughput, and scale effectively\nacross varying container-to-PU ratios. These findings offer actionable\nguidelines for designing safe and efficient container-management systems in\nreal-world facilities."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-104",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16185"
    ],
    "b_title":[
      "On the equation of state of U(1) lattice gauge theory in three\n  dimensions"
    ],
    "b_abstract":[
      "We study the equation of state of three-dimensional compact U(1) gauge theory\non the lattice by means of numerical simulations, and discuss the implications\nof our results for the spectrum of the theory, in connection with previous\nresults from the literature. We also compare our findings to the case of\nnon-Abelian gauge theories and comment on the continuum limit."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11811"
    ],
    "c_title":[
      "Topological edge states of continuous Hamiltonians"
    ],
    "c_abstract":[
      "This paper concerns the topological classification of continuous Hamiltonians\nthat find applications in biased cold plasmas and photonics. Besides a magnetic\nbias, the Hamiltonians are parametrized by a plasma frequency and a fixed\nvertical wavenumber. Eight distinct phases of matter are identified as these\nparameters vary. When insulating gaps are shared by two such phases, asymmetric\nedge modes propagate along interfaces separating the two phases. Here we apply\nthe notion of a bulk difference invariant (BDI) to this Hamiltonian, and show\nby numerical diagonalizations of interface Hamiltonians that after an\nappropriate regularization our BDI correctly predicts edge transport as\ndescribed by a bulk edge correspondence. We also derive theoretical tools to\ncompute the BDI and show the limitations of the bulk edge correspondence (BEC)\nwhen the phase transition is too singular."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-105",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13142"
    ],
    "b_title":[
      "Computational modelling of biological systems now and then: revisiting\n  tools and visions from the beginning of the century"
    ],
    "b_abstract":[
      "Since the turn of the millennium, computational modelling of biological\nsystems has evolved remarkably and sees matured use spanning basic and clinical\nresearch. While the topic of the peri-millennial debate about the virtues and\nlimitations of 'reductionism and integrationism' seems less controversial\ntoday, a new apparent dichotomy dominates discussions: mechanistic vs.\ndata-driven modelling. In light of this distinction, we provide an overview of\nrecent achievements and new challenges with a focus on the cardiovascular\nsystem. Attention has shifted from generating a universal model of the human to\neither models of individual humans (digital twins) or entire cohorts of models\nrepresentative of clinical populations to enable in silico clinical trials.\nDisease-specific parameterisation, inter-individual and intra-individual\nvariability, uncertainty quantification as well as interoperable, standardised,\nand quality-controlled data are important issues today, which call for open\ntools, data and metadata standards, as well as strong community interactions.\nThe quantitative, biophysical, and highly controlled approach provided by in\nsilico methods has become an integral part of physiological and medical\nresearch. In silico methods have the potential to accelerate future progress\nalso in the fields of integrated multi-physics modelling, multi-scale models,\nvirtual cohort studies, and machine learning beyond what is feasible today. In\nfact, mechanistic and data-driven modelling can complement each other\nsynergistically and fuel tomorrow's artificial intelligence applications to\nfurther our understanding of physiology and disease mechanisms, to generate new\nhypotheses and assess their plausibility, and thus to contribute to the\nevolution of preventive, diagnostic, and therapeutic approaches."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2502.13892"
    ],
    "c_title":[
      "Intrinsic Donaldson-Thomas theory. I. Component lattices of stacks"
    ],
    "c_abstract":[
      "This is the first paper in a series on intrinsic Donaldson-Thomas theory, a\ngeneralization of Donaldson-Thomas theory from the linear case, or the case of\nmoduli stacks of objects in $3$-Calabi-Yau abelian categories, to the\nnon-linear case of general $(-1)$-shifted symplectic stacks. This is done by\ndeveloping a new framework for studying the enumerative geometry of general\nalgebraic stacks, and we expect that this framework can also be applied to\nextending other types of enumerative theories for linear stacks to the\nnon-linear case.\n  In this paper, we establish the foundations of our framework. We introduce\nthe component lattice of an algebraic stack, which is the key combinatorial\nobject in our theory. It generalizes and globalizes the cocharacter lattice and\nthe Weyl group of an algebraic group, and is defined as the set of connected\ncomponents of the stack of graded points of the original stack.\n  We prove several results on the structure of graded and filtered points of a\nstack using the component lattice. The first is the constancy theorem, which\nstates that there is a wall-and-chamber structure on the component lattice,\nsuch that the isomorphism types of connected components of the stacks of graded\nand filtered points stay constant within each chamber. The second is the\nfiniteness theorem, providing a criterion for the finiteness of the number of\npossible isomorphism types of these components. The third is the associativity\ntheorem, generalizing the structure of Hall algebras from linear stacks to\ngeneral stacks, involving a notion of Hall categories.\n  Finally, we discuss some applications of these results outside\nDonaldson-Thomas theory, including a construction of stacks of real-weighted\nfiltrations, and a generalization of the semistable reduction theorem to\nreal-weighted filtrations."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-106",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07095"
    ],
    "b_title":[
      "The devasting economic impact of Callinectes sapidus on the clam fishing\n  in the Po Delta (Italy): Striking evidence from novel field data"
    ],
    "b_abstract":[
      "Invasive species are a growing threat to marine ecosystems, and the recent\nproliferation of the Atlantic blue crab (Callinectes sapidus) in the Po Delta\n(Italy) has had significant ecological and economic impacts, particularly on\nclam farming. This study explores the influence of C. sapidus on clam\nproduction in the Po Delta, combining biological and ecological data with\nsocio-economic analysis. Field data collected between August and December 2023\nfrom the Canarin and Scardovari Lagoons revealed seasonal fluctuations in crab\nabundance, with a peak in captures during the warmer months. The predatory\nbehaviour of C. sapidus has led to a sharp decline in clam production, reaching\nnear-zero levels in early 2024. Statistical analysis confirmed a strong\ncorrelation between the increase of the invasive crab population and the\ndecrease in clam yields. This study also explores potential management\nstrategies, including the economic valorisation of C. sapidus as a commercial\nresource, turning an ecological challenge into an opportunity. These findings\nhighlight the urgent need for targeted management interventions to mitigate the\nimpact of this invasive species on local fisheries and ecosystems."
    ],
    "b_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2501.16495"
    ],
    "c_title":[
      "Explaining GitHub Actions Failures with Large Language Models:\n  Challenges, Insights, and Limitations"
    ],
    "c_abstract":[
      "GitHub Actions (GA) has become the de facto tool that developers use to\nautomate software workflows, seamlessly building, testing, and deploying code.\nYet when GA fails, it disrupts development, causing delays and driving up\ncosts. Diagnosing failures becomes especially challenging because error logs\nare often long, complex and unstructured. Given these difficulties, this study\nexplores the potential of large language models (LLMs) to generate correct,\nclear, concise, and actionable contextual descriptions (or summaries) for GA\nfailures, focusing on developers' perceptions of their feasibility and\nusefulness. Our results show that over 80\\% of developers rated LLM\nexplanations positively in terms of correctness for simpler\/small logs.\nOverall, our findings suggest that LLMs can feasibly assist developers in\nunderstanding common GA errors, thus, potentially reducing manual analysis.\nHowever, we also found that improved reasoning abilities are needed to support\nmore complex CI\/CD scenarios. For instance, less experienced developers tend to\nbe more positive on the described context, while seasoned developers prefer\nconcise summaries. Overall, our work offers key insights for researchers\nenhancing LLM reasoning, particularly in adapting explanations to user\nexpertise."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-107",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17275"
    ],
    "b_title":[
      "Time-dependent global sensitivity analysis of the Doyle-Fuller-Newman\n  model"
    ],
    "b_abstract":[
      "The Doyle-Fuller-Newman model is arguably the most ubiquitous electrochemical\nmodel in lithium-ion battery research. Since it is a highly nonlinear model,\nits input-output relations are still poorly understood. Researchers therefore\noften employ sensitivity analyses to elucidate relative parametric importance\nfor certain use cases. However, some methods are ill-suited for the complexity\nof the model and appropriate methods often face the downside of only being\napplicable to scalar quantities of interest. We implement a novel framework for\nglobal sensitivity analysis of time-dependent model outputs and apply it to a\ndrive cycle simulation. We conduct a full and a subgroup sensitivity analysis\nto resolve lowly sensitive parameters and explore the model error when\nunimportant parameters are set to arbitrary values. Our findings suggest that\nthe method identifies insensitive parameters whose variations cause only small\ndeviations in the voltage response of the model. By providing the methodology,\nwe hope research questions related to parametric sensitivity for time-dependent\nquantities of interest, such as voltage responses, can be addressed more easily\nand adequately in simulative battery research and beyond."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.10943"
    ],
    "c_title":[
      "InsQABench: Benchmarking Chinese Insurance Domain Question Answering\n  with Large Language Models"
    ],
    "c_abstract":[
      "The application of large language models (LLMs) has achieved remarkable\nsuccess in various fields, but their effectiveness in specialized domains like\nthe Chinese insurance industry remains underexplored. The complexity of\ninsurance knowledge, encompassing specialized terminology and diverse data\ntypes, poses significant challenges for both models and users. To address this,\nwe introduce InsQABench, a benchmark dataset for the Chinese insurance sector,\nstructured into three categories: Insurance Commonsense Knowledge, Insurance\nStructured Database, and Insurance Unstructured Documents, reflecting\nreal-world insurance question-answering tasks.We also propose two methods,\nSQL-ReAct and RAG-ReAct, to tackle challenges in structured and unstructured\ndata tasks. Evaluations show that while LLMs struggle with domain-specific\nterminology and nuanced clause texts, fine-tuning on InsQABench significantly\nimproves performance. Our benchmark establishes a solid foundation for\nadvancing LLM applications in the insurance domain, with data and code\navailable at https:\/\/github.com\/HaileyFamo\/InsQABench.git."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-108",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08434"
    ],
    "b_title":[
      "One loop analysis of the cubic action for gravity"
    ],
    "b_abstract":[
      "We analyze some aspects of the cubic action for gravity recently proposed by\nCheung and Remmen, which is a particular instance of a first order (Palatini)\naction. In this approach both the spacetime metric and the connection are\ntreated as independent fields. We discuss its BRST invariance and compute\nexplicitly the one-loop contribution of quantum fluctuations around flat space,\nchecking that the corresponding Slavnov-Taylor identities are fulfilled.\nFinally, our results on a first order action are compared with the existing\nones corresponding to a second order action."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.18096"
    ],
    "c_title":[
      "On the Jucys-Murphy method and fusion procedure for the Sergeev\n  superalgebra"
    ],
    "c_abstract":[
      "We use the Jucys-Murphy elements to construct a complete set of primitive\nidempotents for the Sergeev superalgebra ${\\mathcal S}_n$. We produce\nseminormal forms for the simple modules over ${\\mathcal S}_n$ and over the spin\nsymmetric group algebra with explicit constructions of basis vectors. We show\nthat the idempotents can also be obtained from a new version of the fusion\nprocedure."
    ],
    "c_categories":[
      [
        "math.RA",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-109",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05497"
    ],
    "b_title":[
      "$t$+$t$ cluster states in $^{6}$He"
    ],
    "b_abstract":[
      "The study of $t$+$t$ cluster states in $^{6}$He provides valuable insights\ninto exotic nuclear structures and the behavior of fermionic cluster systems.\nThis study shows rich cluster resonant state structures above the threshold,\nidentified by experimental reconstruction and theoretical calculations. The\nexcitation energy spectrum above the $t$+$t$ threshold in $^{6}$He is measured\nvia the fragmentation excitation process during the breakup reaction of\n$^{9}$Li on a $^{208}$Pb target at an incident energy of 32.7 MeV\/nucleon. The\nresonant states are reconstructed from the final state coincident particles\n$t$+$t$ using the invariant mass method, while the non-resonant background is\nestimated using the event mixing method. The two new states of energy level\npeaks at $17.016\\pm0.002$ and $19.4\\pm0.6$ MeV are observed in addition to the\npreviously observed energy level peaks at $13.9\\pm0.3$ and $15.0\\pm0.3$ MeV.\nMicroscopic cluster model calculations exploring the $t+t$ resonance states in\n$^6\\mathrm{He}$ yield theoretical energy spectra which are then compared with\nthe current experimental results. The calculated reduced width amplitudes (RWA)\nof the $t+t$ channels further confirm the clustering structure of the\nidentified $t+t$ resonance states."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.18970"
    ],
    "c_title":[
      "Empirical likelihood approach for high-dimensional moment restrictions\n  with dependent data"
    ],
    "c_abstract":[
      "Economic and financial models -- such as vector autoregressions, local\nprojections, and multivariate volatility models -- feature complex dynamic\ninteractions and spillovers across many time series. These models can be\nintegrated into a unified framework, with high-dimensional parameters\nidentified by moment conditions. As the number of parameters and moment\nconditions may surpass the sample size, we propose adding a double penalty to\nthe empirical likelihood criterion to induce sparsity and facilitate dimension\nreduction. Notably, we utilize a marginal empirical likelihood approach despite\ntemporal dependence in the data. Under regularity conditions, we provide\nasymptotic guarantees for our method, making it an attractive option for\nestimating large-scale multivariate time series models. We demonstrate the\nversatility of our procedure through extensive Monte Carlo simulations and\nthree empirical applications, including analyses of US sectoral inflation\nrates, fiscal multipliers, and volatility spillover in China's banking sector."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-110",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03879"
    ],
    "b_title":[
      "First-order CP phase transition in two-flavor QCD at $\\theta = \\pi$\n  under electromagnetic scale anomaly via a Nambu-Jona-Lasinio description"
    ],
    "b_abstract":[
      "We discuss the thermal CP phase transition in QCD at $\\theta=\\pi$ under a\nweak magnetic field background, where the electromagnetic scale anomaly gets\nsignificant. To explicitize, we work on a two-flavor Nambu-Jona-Lasinio model\nat $\\theta=\\pi$ in the mean field approximation, including the\nelectromagnetic-scale anomaly term. We find that the thermal CP phase\ntransition becomes first order and the strength of the first order gets more\nprominent as the magnetic field increases. The associated potential barrier is\nthermally created by the electromagnetic scale anomaly and gives rise to\ncriticality due to the induced potential of a non-perturbative form $\\sim\n\\frac{|eB|^3}{f_\\pi} \\frac{|P|}{P^2 + m_0^2}$, where $eB$ denotes the magnetic\nfield strength; $P$ the CP order parameter, and $m_0$ the isospin-symmetric\ncurrent-quark mass."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.20758"
    ],
    "c_title":[
      "Collective Reasoning Among LLMs A Framework for Answer Validation\n  Without Ground Truth"
    ],
    "c_abstract":[
      "We present a collaborative framework where multiple large language models,\nnamely GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash, work together to generate and respond to complex PhD-level\nprobability questions in the absence of definitive ground truth. This study\nexplores how inter-model consensus enhances response reliability and serves as\na proxy for assessing the quality of generated questions. To quantify agreement\nand consistency, we employ statistical methods including chi-square tests,\nFleiss' Kappa, and confidence interval analysis, measuring both response\nprecision and question clarity. Our findings highlight that Claude and Gemini\ngenerate well-structured and less ambiguous questions, leading to higher\ninter-model agreement. This is reflected in their narrower confidence intervals\nand stronger alignment with answering models. Conversely, LLaMA demonstrates\nincreased variability and lower reliability in question formulation, as\nindicated by broader confidence intervals and reduced consensus rates. These\nresults suggest that multi-model collaboration not only enhances the\nreliability of responses but also provides a valuable framework for assessing\nand improving question quality in the absence of explicit ground truth. This\nresearch offers meaningful insights into optimizing AI-driven reasoning through\ncollaborative large-language model interactions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-111",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15270"
    ],
    "b_title":[
      "Automating Comment Generation for Smart Contract from Bytecode"
    ],
    "b_abstract":[
      "Recently, smart contracts have played a vital role in automatic financial and\nbusiness transactions. To help end users without programming background to\nbetter understand the logic of smart contracts, previous studies have proposed\nmodels for automatically translating smart contract source code into their\ncorresponding code summaries. However, in practice, only 13% of smart contracts\ndeployed on the Ethereum blockchain are associated with source code. The\npractical usage of these existing tools is significantly restricted.\nConsidering that bytecode is always necessary when deploying smart contracts,\nin this paper, we first introduce the task of automatically generating smart\ncontract code summaries from bytecode. We propose a novel approach, named\nSmartBT (Smart contract Bytecode Translator) for automatically translating\nsmart contract bytecode into fine-grained natural language description\ndirectly. Two key challenges are posed for this task: structural code logic\nhidden in bytecode and the huge semantic gap between bytecode and natural\nlanguage descriptions. To address the first challenge, we transform bytecode\ninto CFG (Control-Flow Graph) to learn code structural and logic details.\nRegarding the second challenge, we introduce an information retrieval component\nto fetch similar comments for filling the semantic gap. Then the structural\ninput and semantic input are used to build an attentional sequence-to-sequence\nneural network model. The copy mechanism is employed to copy rare words\ndirectly from similar comments and the coverage mechanism is employed to\neliminate repetitive outputs. The automatic evaluation results show that\nSmartBT outperforms a set of baselines by a large margin, and the human\nevaluation results show the effectiveness and potential of SmartBT in producing\nmeaningful and accurate comments for smart contract code from bytecode\ndirectly."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08766"
    ],
    "c_title":[
      "Integrating UX Design in Astronomical Software Development: A Case Study"
    ],
    "c_abstract":[
      "In 2023, ASTRON took the step of incorporating a dedicated User Experience\n(UX) designer into its software development process. This decision aimed to\nenhance the accessibility and usability of services providing access to the\ndata holdings from the telescopes we are developing.\n  The field of astronomical software development has historically under\nemphasized UX design. ASTRON's initiative not only improves our own tools, but\ncan also be used to demonstrate to the broader community the value of\nintegrating UX expertise into development teams.\n  We discuss how we integrate the UX designer at the start of our software\ndevelopment lifecycle. We end with providing some considerations on how other\nprojects could make use of UX knowledge in their development process."
    ],
    "c_categories":[
      [
        "astro-ph.IM",
        "cs.HC",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-112",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01694"
    ],
    "b_title":[
      "Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of\n  Search, RL and Distillation"
    ],
    "b_abstract":[
      "A key paradigm to improve the reasoning capabilities of large language models\n(LLMs) is to allocate more inference-time compute to search against a verifier\nor reward model. This process can then be utilized to refine the pretrained\nmodel or distill its reasoning patterns into more efficient models. In this\npaper, we study inference-time compute by viewing chain-of-thought (CoT)\ngeneration as a metastable Markov process: easy reasoning steps (e.g.,\nalgebraic manipulations) form densely connected clusters, while hard reasoning\nsteps (e.g., applying a relevant theorem) create sparse, low-probability edges\nbetween clusters, leading to phase transitions at longer timescales. Under this\nframework, we prove that implementing a search protocol that rewards sparse\nedges improves CoT by decreasing the expected number of steps to reach\ndifferent clusters. In contrast, we establish a limit on reasoning capability\nwhen the model is restricted to local information of the pretrained graph. We\nalso show that the information gained by search can be utilized to obtain a\nbetter reasoning model: (1) the pretrained model can be directly finetuned to\nfavor sparse edges via policy gradient methods, and moreover (2) a compressed\nmetastable representation of the reasoning dynamics can be distilled into a\nsmaller, more efficient model."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14829"
    ],
    "c_title":[
      "Validation of satellite and reanalysis rainfall products against rain\n  gauge observations in Ghana and Zambia"
    ],
    "c_abstract":[
      "Accurate rainfall data are crucial for effective climate services, especially\nin Sub-Saharan Africa, where agriculture depends heavily on rain-fed systems.\nThe sparse distribution of rain-gauge networks necessitates reliance on\nsatellite and reanalysis rainfall products (REs). This study evaluated eight\nREs -- CHIRPS, TAMSAT, CHIRP, ENACTS, ERA5, AgERA5, PERSIANN-CDR, and\nPERSIANN-CCS-CDR -- in Zambia and Ghana using a point-to-pixel validation\napproach. The analysis covered spatial consistency, annual rainfall summaries,\nseasonal patterns, and rainfall intensity detection across 38 ground stations.\nResults showed no single product performed optimally across all contexts,\nhighlighting the need for application-specific recommendations. All products\nexhibited a high probability of detection (POD) for dry days in Zambia and\nnorthern Ghana (70% < POD < 100%, and 60% < POD < 85%, respectively),\nsuggesting their utility for drought-related studies. However, all products\nshowed limited skill in detecting heavy and violent rains (POD close to 0%),\nmaking them unsuitable for analyzing such events (e.g., floods) in their\ncurrent form. Products integrated with station data (ENACTS, CHIRPS, and\nTAMSAT) outperformed others in many contexts, emphasizing the importance of\nlocal observation calibration. Bias correction is strongly recommended due to\nvarying bias levels across rainfall summaries. A critical area for improvement\nis the detection of heavy and violent rains, with which REs currently struggle.\nFuture research should focus on this aspect."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-113",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07383"
    ],
    "b_title":[
      "Diagnostic-free onboard battery health assessment"
    ],
    "b_abstract":[
      "Diverse usage patterns induce complex and variable aging behaviors in\nlithium-ion batteries, complicating accurate health diagnosis and prognosis.\nSeparate diagnostic cycles are often used to untangle the battery's current\nstate of health from prior complex aging patterns. However, these same\ndiagnostic cycles alter the battery's degradation trajectory, are\ntime-intensive, and cannot be practically performed in onboard applications. In\nthis work, we leverage portions of operational measurements in combination with\nan interpretable machine learning model to enable rapid, onboard battery health\ndiagnostics and prognostics without offline diagnostic testing and the\nrequirement of historical data. We integrate mechanistic constraints within an\nencoder-decoder architecture to extract electrode states in a physically\ninterpretable latent space and enable improved reconstruction of the\ndegradation path. The health diagnosis model framework can be flexibly applied\nacross diverse application interests with slight fine-tuning. We demonstrate\nthe versatility of this model framework by applying it to three battery-cycling\ndatasets consisting of 422 cells under different operating conditions,\nhighlighting the utility of an interpretable diagnostic-free, onboard battery\ndiagnosis and prognosis model."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14571"
    ],
    "c_title":[
      "Anomalous Dynamics of a Liquid Corner Film"
    ],
    "c_abstract":[
      "Measuring the rheology of liquids typically requires precise control over\nshear rates and stresses. However, we demonstrate that the features of a\npower-law fluid can be predicted by simply observing the capillary spreading\ndynamics of viscous droplets within a wedge-shaped geometry. By considering the\ninfluence of capillary and viscous forces within this geometry, we show that\nthe spreading dynamics can be described by a nonlinear diffusion equation.\nAnalytical predictions indicate subdiffusive behavior, establishing a direct\nrelationship between the diffusion exponent and the rheological exponent, which\nis also corroborated by experimental results. Since this relationship is\nindependent of flow details, it provides robust predictions for the rheological\nproperties of power-law fluids."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-114",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01187"
    ],
    "b_title":[
      "Skewed Memorization in Large Language Models: Quantification and\n  Decomposition"
    ],
    "b_abstract":[
      "Memorization in Large Language Models (LLMs) poses privacy and security\nrisks, as models may unintentionally reproduce sensitive or copyrighted data.\nExisting analyses focus on average-case scenarios, often neglecting the highly\nskewed distribution of memorization. This paper examines memorization in LLM\nsupervised fine-tuning (SFT), exploring its relationships with training\nduration, dataset size, and inter-sample similarity. By analyzing memorization\nprobabilities over sequence lengths, we link this skewness to the token\ngeneration process, offering insights for estimating memorization and comparing\nit to established metrics. Through theoretical analysis and empirical\nevaluation, we provide a comprehensive understanding of memorization behaviors\nand propose strategies to detect and mitigate risks, contributing to more\nprivacy-preserving LLMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05973"
    ],
    "c_title":[
      "Complete heteroclinic networks derived from graphs consisting of two\n  cycles"
    ],
    "c_abstract":[
      "We address the question how a given connection structure (directed graph) can\nbe realised as a heteroclinic network that is complete in the sense that it\ncontains all unstable manifolds of its equilibria. For a directed graph\nconsisting of two cycles we provide a constructive method to achieve this: (i)\nenlarge the graph by adding some edges and (ii) apply the simplex method to\nobtain a network in phase space. Depending on the length of the cycles we\nderive the minimal number of required new edges. In the resulting network each\nadded edge leads to a positive transverse eigenvalue at the respective\nequilibrium. We discuss the total number of such positive eigenvalues in an\nindividual cycle and some implications for the stability of this cycle."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-115",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10636"
    ],
    "b_title":[
      "Efficient and Safe Trajectory Planning for Autonomous Agricultural\n  Vehicle Headland Turning in Cluttered Orchard Environments"
    ],
    "b_abstract":[
      "Autonomous agricultural vehicles (AAVs), including field robots and\nautonomous tractors, are becoming essential in modern farming by improving\nefficiency and reducing labor costs. A critical task in AAV operations is\nheadland turning between crop rows. This task is challenging in orchards with\nlimited headland space, irregular boundaries, operational constraints, and\nstatic obstacles. While traditional trajectory planning methods work well in\narable farming, they often fail in cluttered orchard environments. This letter\npresents a novel trajectory planner that enhances the safety and efficiency of\nAAV headland maneuvers, leveraging advancements in autonomous driving. Our\napproach includes an efficient front-end algorithm and a high-performance\nback-end optimization. Applied to vehicles with various implements, it\noutperforms state-of-the-art methods in both standard and challenging orchard\nfields. This work bridges agricultural and autonomous driving technologies,\nfacilitating a broader adoption of AAVs in complex orchards."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01927"
    ],
    "c_title":[
      "Short Paths in the Planar Graph Product Structure Theorem"
    ],
    "c_abstract":[
      "The Planar Graph Product Structure Theorem of Dujmovi\\'c et al. [J. ACM '20]\nsays that every planar graph $G$ is contained in $H\\boxtimes P\\boxtimes K_3$\nfor some planar graph $H$ with treewidth at most 3 and some path $P$. This\nresult has been the key to solving several old open problems. Several people\nhave asked whether the Planar Graph Product Structure Theorem can be proved\nwith good upper bounds on the length of $P$. No $o(n)$ upper bound was\npreviously known for $n$-vertex planar graphs. We answer this question in the\naffirmative, by proving that for any $\\epsilon\\in (0,1)$ every $n$-vertex\nplanar graph is contained in $H\\boxtimes P\\boxtimes K_{O(1\/\\epsilon)}$, for\nsome planar graph $H$ with treewidth 3 and for some path $P$ of length\n$O(\\frac{1}{\\epsilon}n^{(1+\\epsilon)\/2})$. This bound is almost tight since\nthere is a lower bound of $\\Omega(n^{1\/2})$ for certain $n$-vertex planar\ngraphs. In fact, we prove a stronger result with $P$ of length\n$O(\\frac{1}{\\epsilon}\\,\\textrm{tw}(G)\\,n^{\\epsilon})$, which is tight up to the\n$O(\\frac{1}{\\epsilon}\\,n^{\\epsilon})$ factor for every $n$-vertex planar graph\n$G$. Finally, taking $\\epsilon=\\frac{1}{\\log n}$, we show that every $n$-vertex\nplanar graph $G$ is contained in $H\\boxtimes P\\boxtimes K_{O(\\log n)}$ for some\nplanar graph $H$ with treewidth at most 3 and some path $P$ of length\n$O(\\textrm{tw}(G)\\,\\log n)$. This result is particularly attractive since the\ntreewidth of the product $H\\boxtimes P\\boxtimes K_{O(\\log n)}$ is within a\n$O(\\log^2n)$ factor of the treewidth of $G$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-116",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01924"
    ],
    "b_title":[
      "TAET: Two-Stage Adversarial Equalization Training on Long-Tailed\n  Distributions"
    ],
    "b_abstract":[
      "Adversarial robustness is a critical challenge in deploying deep neural\nnetworks for real-world applications. While adversarial training is a widely\nrecognized defense strategy, most existing studies focus on balanced datasets,\noverlooking the prevalence of long-tailed distributions in real-world data,\nwhich significantly complicates robustness. This paper provides a comprehensive\nanalysis of adversarial training under long-tailed distributions and identifies\nlimitations in the current state-of-the-art method, AT-BSL, in achieving robust\nperformance under such conditions. To address these challenges, we propose a\nnovel training framework, TAET, which integrates an initial stabilization phase\nfollowed by a stratified equalization adversarial training phase. Additionally,\nprior work on long-tailed robustness has largely ignored the crucial evaluation\nmetric of balanced accuracy. To bridge this gap, we introduce the concept of\nbalanced robustness, a comprehensive metric tailored for assessing robustness\nunder long-tailed distributions. Extensive experiments demonstrate that our\nmethod surpasses existing advanced defenses, achieving significant improvements\nin both memory and computational efficiency. This work represents a substantial\nadvancement in addressing robustness challenges in real-world applications. Our\ncode is available at:\nhttps:\/\/github.com\/BuhuiOK\/TAET-Two-Stage-Adversarial-Equalization-Training-on-Long-Tailed-Distributions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13014"
    ],
    "c_title":[
      "On the electrons really contributing to dc conductivity of warm dense\n  matter"
    ],
    "c_abstract":[
      "Atomic properties of warm dense matter is an active field of research.\nUnderstanding transport properties of these states is essential for providing\ncoefficients needed by magneto-radiative hydrodynamics codes for many studies,\nincluding hydrodynamic instabilities, energy balances or heating in fusion\nplasmas, difficult to investigate by experimental means. In this paper, we\npresent an average-atom approach for the calculation of direct-current electric\nconductivity within Ziman's theory. The mean ion charge $Z^*$, commonly called\nionization, is an important input of the Ziman formula, but is not clearly\ndefined within average-atom models. Our study spans a wide range of\nthermodynamical conditions, i.e., for the densities, from a few $10^{-2}$ to\nabout 4 times the solid's density, and, for the temperatures, typically from\n0.1 eV to 700 eV, favorable to large differences in the mean ion charge $Z^*$\naccording to its definition. We compare and discuss different ways of defining\n$Z^*$ while trying to figure out which electrons really contribute to electric\nconduction. We compare our results with experimental data and published\ntheoretical values, in particular from the second transport code comparison\nworkshop, which was held in July 2023 at Lawrence Livermore National\nLaboratory. These comparisons lead us to propose indicators for the relevance\nof including different charges predicted by our average-atom model in the\ndefinition of $Z^*$."
    ],
    "c_categories":[
      [
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-117",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05503"
    ],
    "b_title":[
      "Steady bubbles and drops in inviscid fluids"
    ],
    "b_abstract":[
      "We construct steady non-spherical bubbles and drops, which are traveling wave\nsolutions to the axisymmetric two-phase Euler equations with surface tension,\nwhose inner phase is a bounded connected domain. The solutions have a uniform\nvorticity distribution in this inner phase and they have a vortex sheet on its\nsurface.\n  Our construction relies on a perturbative approach around an explicit\nspherical solution, given by Hill's vortex enclosed by a spherical vortex\nsheet. The construction is sensitive to the Weber numbers describing the flow.\nAt critical Weber numbers, we perform a bifurcation analysis utilizing the\nCrandall-Rabinowitz theorem in Sobolev spaces on the 2-sphere. Away from these\ncritical numbers, our construction relies on the implicit function theorem.\n  Our results imply that the model containing surface tension is richer than\nthe ordinary one-phase Euler equations, in the sense that for the latter,\nHill's spherical vortex is unique (modulo translations) among all axisymmetric\nsimply connected uniform vortices of a given circulation."
    ],
    "b_categories":[
      [
        "math.AP",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.09032"
    ],
    "c_title":[
      "Teaching LLMs How to Learn with Contextual Fine-Tuning"
    ],
    "c_abstract":[
      "Prompting Large Language Models (LLMs), or providing context on the expected\nmodel of operation, is an effective way to steer the outputs of such models to\nsatisfy human desiderata after they have been trained. But in rapidly evolving\ndomains, there is often need to fine-tune LLMs to improve either the kind of\nknowledge in their memory or their abilities to perform open ended reasoning in\nnew domains. When human's learn new concepts, we often do so by linking the new\nmaterial that we are studying to concepts we have already learned before. To\nthat end, we ask, \"can prompting help us teach LLMs how to learn\". In this\nwork, we study a novel generalization of instruction tuning, called contextual\nfine-tuning, to fine-tune LLMs. Our method leverages instructional prompts\ndesigned to mimic human cognitive strategies in learning and problem-solving to\nguide the learning process during training, aiming to improve the model's\ninterpretation and understanding of domain-specific knowledge. We empirically\ndemonstrate that this simple yet effective modification improves the ability of\nLLMs to be fine-tuned rapidly on new datasets both within the medical and\nfinancial domains."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-118",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19632"
    ],
    "b_title":[
      "The Non-Uniform Expansion of the Crab Nebula"
    ],
    "b_abstract":[
      "We present extensive proper motion measurements of the Crab Nebula made from\nCanada-France-Hawaii Telescope MegaPrime\/MegaCam images taken in 2007, 2016,\nand 2019. A total of 19974 proper motion vectors with uncertainty\n$<10$\\,mas\\,yr$^{-1}$ located over the majority of the Crab Nebula are used to\nmap the supernova remnant's two-dimensional expansion properties that reflect\nthe dynamics of the original explosion, acceleration of ejecta imparted by\nspin-down energy from the pulsar, and interaction between the ejecta and\nsurrounding cicumstellar material (CSM). The average convergence date we derive\nis 1105.5 $\\pm$ 0.5 CE, which is 15-35 yr earlier compared to most previous\nestimates. We find that it varies as a function of position angle around the\nnebula, with the earliest date and smallest proper motions measured along the\nequator defined by the east and west bays. The lower acceleration of material\nalong the equatorial plane may be indicative of the supernova's interaction\nwith a disk-like CSM geometry. Comparing our measurements to previous\nanalytical solutions of the Crab's expansion and our own numerical simulation\nusing the moving mesh hydrodynamics code \\texttt{Sprout}, we conclude that the\nejecta have relaxed closer to homologous expansion than expected for the\ncommonly adopted pulsar spindown age of $\\tau \\sim 700$ yr and a pulsar wind\nnebula (PWN) still evolving inside the flat part of the ejecta density profile.\nThese findings provide further evidence that the PWN has broken out of the\ninner flat part of the supernova ejecta density profile and has experienced\n``blowout''."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00241"
    ],
    "c_title":[
      "Mordal: Automated Pretrained Model Selection for Vision Language Models"
    ],
    "c_abstract":[
      "Incorporating multiple modalities into large language models (LLMs) is a\npowerful way to enhance their understanding of non-textual data, enabling them\nto perform multimodal tasks. Vision language models (VLMs) form the fastest\ngrowing category of multimodal models because of their many practical use\ncases, including in healthcare, robotics, and accessibility. Unfortunately,\neven though different VLMs in the literature demonstrate impressive visual\ncapabilities in different benchmarks, they are handcrafted by human experts;\nthere is no automated framework to create task-specific multimodal models.\n  We introduce Mordal, an automated multimodal model search framework that\nefficiently finds the best VLM for a user-defined task without manual\nintervention. Mordal achieves this both by reducing the number of candidates to\nconsider during the search process and by minimizing the time required to\nevaluate each remaining candidate. Our evaluation shows that Mordal can find\nthe best VLM for a given problem using up to $8.9\\times$--$11.6\\times$ lower\nGPU hours than grid search. In the process of our evaluation, we have also\ndiscovered new VLMs that outperform their state-of-the-art counterparts."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-119",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11989"
    ],
    "b_title":[
      "Nontrivial nonnegative weak solutions to fractional $p$-Laplace\n  inequalities and equations"
    ],
    "b_abstract":[
      "For the nonlocal quasilinear fractional $p$-Laplace operator $(-\\Delta)^s_p$\nwith $s\\in (0,1)$ and $p\\in(1,\\infty)$, we investigate the nonexistence and\nexistence of nontrivial nonnegative solutions $u$ in the local fractional\nSobolev space $W_{\\rm loc}^{s,p}(\\mathbb R^n)$ that satisfies the inequality\n$(-\\Delta)^s_p u\\ge u^q$ weakly in $\\mathbb R^n$, where $q\\in(0,\\infty)$. In\naddition, nonexistence of nontrivial nonnegative weak solutions in the global\nfractional Sobolev space $W^{s,p}(\\mathbb R^n)$ to the fractional $p$-Laplace\nequation $(-\\Delta)^s_p u= u^q$ are also investigated. The approach taken in\nthis paper is mainly based on some delicate analysis of the fundamental\nsolutions to the fractional $p$-Laplace operator $(-\\Delta)^s_p$."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.13816"
    ],
    "c_title":[
      "Large Language Model driven Policy Exploration for Recommender Systems"
    ],
    "c_abstract":[
      "Recent advancements in Recommender Systems (RS) have incorporated\nReinforcement Learning (RL), framing the recommendation as a Markov Decision\nProcess (MDP). However, offline RL policies trained on static user data are\nvulnerable to distribution shift when deployed in dynamic online environments.\nAdditionally, excessive focus on exploiting short-term relevant items can\nhinder exploration, leading to suboptimal recommendations and negatively\nimpacting long-term user gains. Online RL-based RS also face challenges in\nproduction deployment, due to the risks of exposing users to untrained or\nunstable policies. Large Language Models (LLMs) offer a promising solution to\nmimic user objectives and preferences for pre-training policies offline to\nenhance the initial recommendations in online settings. Effectively managing\ndistribution shift and balancing exploration are crucial for improving RL-based\nRS, especially when leveraging LLM-based pre-training. To address these\nchallenges, we propose an Interaction-Augmented Learned Policy (iALP) that\nutilizes user preferences distilled from an LLM. Our approach involves\nprompting the LLM with user states to extract item preferences, learning\nrewards based on feedback, and updating the RL policy using an actor-critic\nframework. Furthermore, to deploy iALP in an online scenario, we introduce an\nadaptive variant, A-iALP, that implements a simple fine-tuning strategy\n(A-iALP$_{ft}$), and an adaptive approach (A-iALP$_{ap}$) designed to mitigate\nissues with compromised policies and limited exploration. Experiments across\nthree simulated environments demonstrate that A-iALP introduces substantial\nperformance improvements"
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-120",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08782"
    ],
    "b_title":[
      "A comparative study of different TSO-DSO coordination in the reserve\n  market"
    ],
    "b_abstract":[
      "The increasing penetration of Distributed Energy Resources (DERs) in the\ndistribution system has led to the emergence of a new market actor - the\naggregator. The aggregator serves as a facilitator, enabling flexibility asset\nowners to get access to different markets. In which, EVs aggregators are\ngaining more attention due to their expanding use and potential to provide\nservices in various types of markets, particularly in the reserve market.\nCurrently, TSO indirectly utilizes these resources under the management of the\ndistribution system operators (DSO), which can negatively impact the\ndistribution grid. Conversely, adjustments from DSOs can impact service\nprovision to TSO due to the shortage of TSO usage information. These factors\nhighlight the importance of evaluating the service provision from aggregators\nunder different TSO-DSO coordination schemes. This paper focuses on the\nprovision of flexibility from electric vehicles (EVs) aggregators for balancing\nservice in the TSO-DSO hybrid-managed and compares it with the DSO-managed\ncoordination schemes. The behavior of aggregators reacting to price\nfluctuations and TSO requests under different coordination schemes and\nsimulation scenarios is thoroughly evaluated. Additionally, their impact on the\ngrid is analyzed through the DSO's congestion management process and validated\nusing data from a real part of the Dutch distribution network. Results find\nthat the hybrid-managed coordination scheme gives more benefit to the\naggregator than the DSO-managed scheme and the EVs aggregator will gain more\nprofit in winter than summer due to more upward regulation service is needed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08760"
    ],
    "c_title":[
      "Modular Forms and Certain ${}_2F_1(1)$ Hypergeometric Series"
    ],
    "c_abstract":[
      "Using the framework relating hypergeometric motives to modular forms, we\ndefine an explicit family of weight 2 Hecke eigenforms with complex\nmultiplication. We use the theory of ${}_2F_1(1)$ hypergeometric series and\nRamanujan's theory of alternative bases to compute the exact central $L$-value\nof these Hecke eigenforms in terms of special beta values. We also show the\nintegral Fourier coefficients can be written in terms of Jacobi sums,\nreflecting a motivic relation between the hypergeometric series and the modular\nforms."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-121",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06296"
    ],
    "b_title":[
      "MoEMoE: Question Guided Dense and Scalable Sparse Mixture-of-Expert for\n  Multi-source Multi-modal Answering"
    ],
    "b_abstract":[
      "Question Answering (QA) and Visual Question Answering (VQA) are well-studied\nproblems in the language and vision domain. One challenging scenario involves\nmultiple sources of information, each of a different modality, where the answer\nto the question may exist in one or more sources. This scenario contains richer\ninformation but is highly complex to handle. In this work, we formulate a novel\nquestion-answer generation (QAG) framework in an environment containing\nmulti-source, multimodal information. The answer may belong to any or all\nsources; therefore, selecting the most prominent answer source or an optimal\ncombination of all sources for a given question is challenging. To address this\nissue, we propose a question-guided attention mechanism that learns attention\nacross multiple sources and decodes this information for robust and unbiased\nanswer generation. To learn attention within each source, we introduce an\nexplicit alignment between questions and various information sources, which\nfacilitates identifying the most pertinent parts of the source information\nrelative to the question. Scalability in handling diverse questions poses a\nchallenge. We address this by extending our model to a sparse\nmixture-of-experts (sparse-MoE) framework, enabling it to handle thousands of\nquestion types. Experiments on T5 and Flan-T5 using three datasets demonstrate\nthe model's efficacy, supported by ablation studies."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.04473"
    ],
    "c_title":[
      "Fermions and the Renormalisation Group at Large N"
    ],
    "c_abstract":[
      "We investigate fermionic quantum field theories using functional\nrenormalisation. In the limit of many fermion flavours $N$, we demonstrate that\ntheories have exact solutions for their quantum effective actions given by\nquasi-local interaction functionals of fermion bilinears. The structure implies\nthat local potential approximations are exact, exactly solvable, and that field\nanomalous dimensions vanish. Theories with non-trivial anomalous dimensions may\nalso arise under conditions that are identified. We further demonstrate that\nhigher derivative interactions are inevitably induced by point-like ones,\nincluding at large-$N$. The local potential flows for fermionic theories with\nthe most general $U(N)$ symmetric interactions are provided. For sample\ntheories with scalar, pseudo-scalar, vector, or axial-vector interactions, we\nidentify conformal fixed points, scaling dimensions, conformal manifolds, and\nquantum-induced shifts in scaling dimensions of higher derivative interactions.\nWe also study fermion mass generation, and subleading modifications due to\nfinite $N$ corrections. Implications for conformal field theories, and\napplications in condensed matter and particle physics are indicated."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-122",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14006"
    ],
    "b_title":[
      "Asymmetrical Latent Representation for Individual Treatment Effect\n  Modeling"
    ],
    "b_abstract":[
      "Conditional Average Treatment Effect (CATE) estimation, at the heart of\ncounterfactual reasoning, is a crucial challenge for causal modeling both\ntheoretically and applicatively, in domains such as healthcare, sociology, or\nadvertising. Borrowing domain adaptation principles, a popular design maps the\nsample representation to a latent space that balances control and treated\npopulations while enabling the prediction of the potential outcomes. This paper\npresents a new CATE estimation approach based on the asymmetrical search for\ntwo latent spaces called Asymmetrical Latent Representation for Individual\nTreatment Effect (ALRITE), where the two latent spaces are respectively\nintended to optimize the counterfactual prediction accuracy on the control and\nthe treated samples. Under moderate assumptions, ALRITE admits an upper bound\non the precision of the estimation of heterogeneous effects (PEHE), and the\napproach is empirically successfully validated compared to the state-of-the-art"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03038"
    ],
    "c_title":[
      "Generative assimilation and prediction for weather and climate"
    ],
    "c_abstract":[
      "Machine learning models have shown great success in predicting weather up to\ntwo weeks ahead, outperforming process-based benchmarks. However, existing\napproaches mostly focus on the prediction task, and do not incorporate the\nnecessary data assimilation. Moreover, these models suffer from error\naccumulation in long roll-outs, limiting their applicability to seasonal\npredictions or climate projections. Here, we introduce Generative Assimilation\nand Prediction (GAP), a unified deep generative framework for assimilation and\nprediction of both weather and climate. By learning to quantify the\nprobabilistic distribution of atmospheric states under observational,\npredictive, and external forcing constraints, GAP excels in a broad range of\nweather-climate related tasks, including data assimilation, seamless\nprediction, and climate simulation. In particular, GAP is competitive with\nstate-of-the-art ensemble assimilation, probabilistic weather forecast and\nseasonal prediction, yields stable millennial simulations, and reproduces\nclimate variability from daily to decadal time scales."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-123",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05638"
    ],
    "b_title":[
      "Mim-Width is paraNP-complete"
    ],
    "b_abstract":[
      "We show that it is NP-hard to distinguish graphs of linear mim-width at most\n1211 from graphs of sim-width at least 1216. This implies that Mim-Width,\nSim-Width, One-Sided Mim-Width, and their linear counterparts are all\nparaNP-complete, i.e., NP-complete to compute even when upper bounded by a\nconstant."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.DM",
        "cs.DS",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12238"
    ],
    "c_title":[
      "Generalized transition uncertainties in constrained Markov decision\n  processes"
    ],
    "c_abstract":[
      "We examine a constrained Markov decision process under uncertain transition\nprobabilities, with the uncertainty modeled as deviations from observed\ntransition probabilities. We construct the uncertainty set associated with the\ndeviations using polyhedral and second-order cone constraints and employ a\nrobust optimization framework. We demonstrate that each inner optimization\nproblem of the robust model can be equivalently transformed into a second-order\ncone programming problem. Using strong duality arguments, we show that the\nresulting robust problem can be equivalently reformulated into a non-convex\nprogramming problem that includes bilinear and second-order cone constraints.\nIn the numerical experiments, we study a machine replacement problem and\nexplore potential sources of uncertainty in the transition probabilities. We\nexamine how the optimal values and solutions differ as we vary the feasible\nregion of the uncertainty set, considering only polyhedral constraints and a\ncombination of polyhedral and second-order cone constraints. Furthermore, we\nanalyze the impact of the number of states, the discount factor, and variations\nin the feasible region of the uncertainty set on the optimal values."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-124",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14714"
    ],
    "b_title":[
      "Authenticity as Aesthetics: Enabling the Client to Dominate\n  Decision-making in Co-design"
    ],
    "b_abstract":[
      "This paper revises aesthetics theory through the lens of authenticity and\ninvestigates practical applications using a co-design approach. We encourage\ndesigners to include ordinary clients as co-creators in the co-design process,\nguiding them in expressing their aesthetics, values, and preferences while\nstimulating their creativity. This paper proposes a bespoke design process\nframework for authenticity aesthetics that incorporates empathy, defining,\nideating, prototyping, and testing. This framework delineates the roles and\nresponsibilities of clients and designers at different phases and highlights\nevolving material mediums that enable their communication. The paper concludes\nby reflecting on consumerist aesthetics, advocating for designers to focus on\nthe insights of ordinary clients, design for their authentic uniqueness, and\nrecognize the broad prospects of bespoke design methods."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14067"
    ],
    "c_title":[
      "Towards a global phase diagram of Ce-based dipolar-octupolar pyrochlore\n  magnets under magnetic fields"
    ],
    "c_abstract":[
      "Recent experiments have established a strong case for Ce$_2$(Zr, Sn,\nHf)$_2$O$_7$ to host $\\pi$-flux quantum spin ice (QSI). However, an irrefutable\nconclusion still requires strong, multifaceted evidence. In dipolar-octupolar\n(DO) compounds, external magnetic fields only strongly couple with the dipolar\ncomponent $\\tau_z$ along its local z-axis in contrast to octupolar components\n$\\tau^{x,y}$. This gives rise to the unique ways magnetic fields interact with\nthe system and, in turn, provides us with a variety of tuning knobs to generate\ncomprehensive experimental results. In this work, we focus on magnetic fields\nalong the (110), (111), and (001) directions and present a plethora of\nremarkable experimental signatures to probe the underlying physics of\n$\\pi$-flux QSI using gauge mean field theory (GMFT) and Monte Carlo\nsimulations. In particular, we present unique signatures in magnetic\nfield-dependent phase diagrams, equal-time and dynamical structure factors, and\nmagnetostriction."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-125",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12179"
    ],
    "b_title":[
      "Fitting regular point patterns with a hyperuniform perturbed lattice"
    ],
    "b_abstract":[
      "We introduce a new methodology for modeling regular spatial data using\nhyperuniform point processes. We show that, under some mixing conditions on the\nperturbations, perturbed lattices in general dimension are hyperuniform. Due to\ntheir inherent repulsive structure, they serve as an effective baseline model\nfor data sets in which points exhibit repulsiveness. Specifically, we derive an\nexplicit formula for the $K$-function of lattices perturbed by a Gaussian\nrandom field, which proves particularly useful in conjunction with the minimal\ncontrast method. We apply this approach to a data set representing the grain\ncenters of a polycrystalline metallic material composed of nickel and titanium."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20891"
    ],
    "c_title":[
      "Application of fragmentation function to the indirect production of\n  fully charmed tetraquark"
    ],
    "c_abstract":[
      "The indirect production mechanisms of fully charmed tetraquark are analyzed\nusing the NRQCD factorization and Suzuki approach, respectively. The process\nfirst produces a heavy charm quark through Higgs, $W^+$, or $Z^0$ decay, and\nthen the resulting charm quark evolves into an $S$-wave fully charmed\ntetraquark state with quantum number $J^{PC}$, including $0^{++}$, $1^{+-}$,\nand $2^{++}$, via the fragmentation function. While the transverse momentum\n$\\langle \\vec{q}_T^2\\rangle$ in Suzuki approach ranges from 2.01 to 299.04\nGeV$^2$, the numerical results obtained from these two approaches are\nconsistent with each other. The decay widths, branching ratios, and produced\nevents would be predicted at LHC and CEPC, respectively. The corresponding\ntheoretical uncertainty of heavy quark mass $m_c$ and distribution of energy\nfraction are also presented. The results show that the contribution for the\nproduction of $T_{4c}$ through $W^+$ decay channel at LHC is relatively large.\nAt CEPC, a sufficient number of $T_{4c}$ events are produced through $Z^0$\ndecays, which is likely to be detected in future experiments."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-126",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12270"
    ],
    "b_title":[
      "A Bayesian location-scale joint model for time-to-event and multivariate\n  longitudinal data with association based on within-individual variability"
    ],
    "b_abstract":[
      "Within-individual variability of health indicators measured over time is\nbecoming commonly used to inform about disease progression. Simple summary\nstatistics (e.g. the standard deviation for each individual) are often used but\nthey are not suited to account for time changes. In addition, when these\nsummary statistics are used as covariates in a regression model for\ntime-to-event outcomes, the estimates of the hazard ratios are subject to\nregression dilution. To overcome these issues, a joint model is built where the\nassociation between the time-to-event outcome and multivariate longitudinal\nmarkers is specified in terms of the within-individual variability of the\nlatter. A mixed-effect location-scale model is used to analyse the longitudinal\nbiomarkers, their within-individual variability and their correlation. The time\nto event is modelled using a proportional hazard regression model, with a\nflexible specification of the baseline hazard, and the information from the\nlongitudinal biomarkers is shared as a function of the random effects. The\nmodel can be used to quantify within-individual variability for the\nlongitudinal markers and their association with the time-to-event outcome. We\nshow through a simulation study the performance of the model in comparison with\nthe standard joint model with constant variance. The model is applied on a\ndataset of adult women from the UK cystic fibrosis registry, to evaluate the\nassociation between lung function, malnutrition and mortality."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.12862"
    ],
    "c_title":[
      "RobotIQ: Empowering Mobile Robots with Human-Level Planning for\n  Real-World Execution"
    ],
    "c_abstract":[
      "This paper introduces RobotIQ, a framework that empowers mobile robots with\nhuman-level planning capabilities, enabling seamless communication via natural\nlanguage instructions through any Large Language Model. The proposed framework\nis designed in the ROS architecture and aims to bridge the gap between humans\nand robots, enabling robots to comprehend and execute user-expressed text or\nvoice commands. Our research encompasses a wide spectrum of robotic tasks,\nranging from fundamental logical, mathematical, and learning reasoning for\ntransferring knowledge in domains like navigation, manipulation, and object\nlocalization, enabling the application of learned behaviors from simulated\nenvironments to real-world operations. All encapsulated within a modular\ncrafted robot library suite of API-wise control functions, RobotIQ offers a\nfully functional AI-ROS-based toolset that allows researchers to design and\ndevelop their own robotic actions tailored to specific applications and robot\nconfigurations. The effectiveness of the proposed system was tested and\nvalidated both in simulated and real-world experiments focusing on a home\nservice scenario that included an assistive application designed for elderly\npeople. RobotIQ with an open-source, easy-to-use, and adaptable robotic library\nsuite for any robot can be found at https:\/\/github.com\/emmarapt\/RobotIQ."
    ],
    "c_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-127",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01261"
    ],
    "b_title":[
      "Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical\n  Codebook-Text Alignment with Long Text"
    ],
    "b_abstract":[
      "Image quantization is a crucial technique in image generation, aimed at\nlearning a codebook that encodes an image into a discrete token sequence.\nRecent advancements have seen researchers exploring learning multi-modal\ncodebook (i.e., text-aligned codebook) by utilizing image caption semantics,\naiming to enhance codebook performance in cross-modal tasks. However, existing\nimage-text paired datasets exhibit a notable flaw in that the text descriptions\ntend to be overly concise, failing to adequately describe the images and\nprovide sufficient semantic knowledge, resulting in limited alignment of text\nand codebook at a fine-grained level. In this paper, we propose a novel\nText-Augmented Codebook Learning framework, named TA-VQ, which generates longer\ntext for each image using the visual-language model for improved text-aligned\ncodebook learning. However, the long text presents two key challenges: how to\nencode text and how to align codebook and text. To tackle two challenges, we\npropose to split the long text into multiple granularities for encoding, i.e.,\nword, phrase, and sentence, so that the long text can be fully encoded without\nlosing any key semantic knowledge. Following this, a hierarchical encoder and\nnovel sampling-based alignment strategy are designed to achieve fine-grained\ncodebook-text alignment. Additionally, our method can be seamlessly integrated\ninto existing VQ models. Extensive experiments in reconstruction and various\ndownstream tasks demonstrate its effectiveness compared to previous\nstate-of-the-art approaches."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17204"
    ],
    "c_title":[
      "Dual phase transitions in a 1D lattice with PT-symmetric Floquet defect"
    ],
    "c_abstract":[
      "Systems with non-Hermitian potential or Floquet modulation often result in\nphase transition related phenomena. In this paper, we study the dual phase\ntransitions in a one-dimensional lattice by introducing a defect containing\nboth Floquet modulation and PT-symmetric potential. In such a configuration, we\ndemonstrate how the gain-loss from PT-symmetry and the control parameters in\nFloquet modulation adjust the wave dynamic behaviors. When these parameters\nchange, the system will undergo dual phase transitions from an\nenergy-delocalized phase to a localized phase where energy oscillates with\ntime, and then to a PT-symmetry broken phase with energy boost. In particular,\nwe find that the energy oscillations in the second phase is resulted from the\nbeating of two energy oscillations: one is introduced by the PT-symmetric\npotential and the other is introduced by the Floquet modulation, rather than\nthe field interference of the defect modes. Furthermore, we find that the first\nphase transition can be non-exist and the second phase transition is affected\nby the Floquet parameters. Our results reveal the underlying physics of dual\nphase transitions that occur in simple lattice systems with PT-symmetric\nFloquet defect, which extends the study of non-Hermitian Floquet systems."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-128",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13217"
    ],
    "b_title":[
      "Complexity and Algorithm for the Matching vertex-cutset Problem"
    ],
    "b_abstract":[
      "In 1985, Chv\\'{a}tal introduced the concept of star cutsets as a means to\ninvestigate the properties of perfect graphs, which inspired many researchers\nto study cutsets with some specific structures, for example, star cutsets,\nclique cutsets, stable cutsets. In recent years, approximation algorithms have\ndeveloped rapidly, the computational complexity associated with determining the\nminimum vertex cut possessing a particular structural property have attracted\nconsiderable academic attention.\n  In this paper, we demonstrate that determining whether there is a matching\nvertex-cutset in $H$ with size at most $k$, is $\\mathbf{NP}$-complete, where\n$k$ is a given positive integer and $H$ is a connected graph. Furthermore, we\ndemonstrate that for a connected graph $H$, there exists a $2$-approximation\nalgorithm in $O(nm^2)$ for us to find a minimum matching vertex-cutset.\nFinally, we show that every plane graph $H$ satisfying $H\\not\\in\\{K_2, K_4\\}$\ncontains a matching vertex-cutset with size at most three, and this bound is\ntight."
    ],
    "b_categories":[
      [
        "cs.DS",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11376"
    ],
    "c_title":[
      "Annotating Scientific Uncertainty: A comprehensive model using\n  linguistic patterns and comparison with existing approaches"
    ],
    "c_abstract":[
      "UnScientify, a system designed to detect scientific uncertainty in scholarly\nfull text. The system utilizes a weakly supervised technique to identify\nverbally expressed uncertainty in scientific texts and their authorial\nreferences. The core methodology of UnScientify is based on a multi-faceted\npipeline that integrates span pattern matching, complex sentence analysis and\nauthor reference checking. This approach streamlines the labeling and\nannotation processes essential for identifying scientific uncertainty, covering\na variety of uncertainty expression types to support diverse applications\nincluding information retrieval, text mining and scientific document\nprocessing. The evaluation results highlight the trade-offs between modern\nlarge language models (LLMs) and the UnScientify system. UnScientify, which\nemploys more traditional techniques, achieved superior performance in the\nscientific uncertainty detection task, attaining an accuracy score of 0.808.\nThis finding underscores the continued relevance and efficiency of\nUnScientify's simple rule-based and pattern matching strategy for this specific\napplication. The results demonstrate that in scenarios where resource\nefficiency, interpretability, and domain-specific adaptability are critical,\ntraditional methods can still offer significant advantages."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-129",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02077"
    ],
    "b_title":[
      "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback\n  of Mixed Quality"
    ],
    "b_abstract":[
      "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality (M3HF),\na novel framework that integrates multi-phase human feedback of mixed quality\ninto the MARL training process. By involving humans with diverse expertise\nlevels to provide iterative guidance, M3HF leverages both expert and non-expert\nfeedback to continuously refine agents' policies. During training, we\nstrategically pause agent learning for human evaluation, parse feedback using\nlarge language models to assign it appropriately and update reward functions\nthrough predefined templates and adaptive weight by using weight decay and\nperformance-based adjustments. Our approach enables the integration of nuanced\nhuman insights across various levels of quality, enhancing the interpretability\nand robustness of multi-agent cooperation. Empirical results in challenging\nenvironments demonstrate that M3HF significantly outperforms state-of-the-art\nmethods, effectively addressing the complexities of reward design in MARL and\nenabling broader human participation in the training process."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03819"
    ],
    "c_title":[
      "Interpolation and inverse problems in spectral Barron spaces"
    ],
    "c_abstract":[
      "Spectral Barron spaces, which quantify the absolute value of weighted Fourier\ncoefficients of a function, have gained considerable attention due to their\ncapability for universal approximation across certain function classes. By\nestablishing a connection between these spaces and a specific positive linear\noperator, we investigate the interpolation and scaling relationships among\ndiverse spectral Barron spaces. Furthermore, we introduce a link condition by\nrelating the spectral Barron space to inverse problems, illustrating this with\nthree exemplary cases. We revisit the notion of universal approximation within\nthe context of spectral Barron spaces and validate an error bound for Tikhonov\nregularization, penalized by the spectral Barron norm."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.FA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-130",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10786"
    ],
    "b_title":[
      "Epidemic-guided deep learning for spatiotemporal forecasting of\n  Tuberculosis outbreak"
    ],
    "b_abstract":[
      "Tuberculosis (TB) remains a formidable global health challenge, driven by\ncomplex spatiotemporal transmission dynamics and influenced by factors such as\npopulation mobility and behavioral changes. We propose an Epidemic-Guided Deep\nLearning (EGDL) approach that fuses mechanistic epidemiological principles with\nadvanced deep learning techniques to enhance early warning systems and\nintervention strategies for TB outbreaks. Our framework is built upon a\nnetworked Susceptible-Infectious-Recovered (SIR) model augmented with a\nsaturated incidence rate and graph Laplacian diffusion, capturing both\nlong-term transmission dynamics and region-specific population mobility\npatterns. Compartmental model parameters are rigorously estimated using\nBayesian inference via the Markov Chain Monte Carlo (MCMC) approach.\nTheoretical analysis leveraging the comparison principle and Green's formula\nestablishes global stability properties of the disease-free and endemic\nequilibria. Building on these epidemiological insights, we design two\nforecasting architectures, EGDL-Parallel and EGDL-Series, that integrate the\nmechanistic outputs of the networked SIR model within deep neural networks.\nThis integration mitigates the overfitting risks commonly encountered in\ndata-driven methods and filters out noise inherent in surveillance data,\nresulting in reliable forecasts of real-world epidemic trends. Experiments\nconducted on TB incidence data from 47 prefectures in Japan demonstrate that\nour approach delivers robust and accurate predictions across multiple time\nhorizons (short to medium-term forecasts). Additionally, incorporating\nuncertainty quantification through conformal prediction enhances the model's\npractical utility for guiding targeted public health interventions."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07255"
    ],
    "c_title":[
      "GazeGrasp: DNN-Driven Robotic Grasping with Wearable Eye-Gaze Interface"
    ],
    "c_abstract":[
      "We present GazeGrasp, a gaze-based manipulation system enabling individuals\nwith motor impairments to control collaborative robots using eye-gaze. The\nsystem employs an ESP32 CAM for eye tracking, MediaPipe for gaze detection, and\nYOLOv8 for object localization, integrated with a Universal Robot UR10 for\nmanipulation tasks. After user-specific calibration, the system allows\nintuitive object selection with a magnetic snapping effect and robot control\nvia eye gestures. Experimental evaluation involving 13 participants\ndemonstrated that the magnetic snapping effect significantly reduced gaze\nalignment time, improving task efficiency by 31%. GazeGrasp provides a robust,\nhands-free interface for assistive robotics, enhancing accessibility and\nautonomy for users."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-131",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10561"
    ],
    "b_title":[
      "VisiMark: Characterizing and Augmenting Landmarks for People with Low\n  Vision in Augmented Reality to Support Indoor Navigation"
    ],
    "b_abstract":[
      "Landmarks are critical in navigation, supporting self-orientation and mental\nmodel development. Similar to sighted people, people with low vision (PLV)\nfrequently look for landmarks via visual cues but face difficulties identifying\nsome important landmarks due to vision loss. We first conducted a formative\nstudy with six PLV to characterize their challenges and strategies in landmark\nselection, identifying their unique landmark categories (e.g., area\nsilhouettes, accessibility-related objects) and preferred landmark\naugmentations. We then designed VisiMark, an AR interface that supports\nlandmark perception for PLV by providing both overviews of space structures and\nin-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found\nthat VisiMark enabled PLV to perceive landmarks they preferred but could not\neasily perceive before, and changed PLV's landmark selection from only\nvisually-salient objects to cognitive landmarks that are more important and\nmeaningful. We further derive design considerations for AR-based landmark\naugmentation systems for PLV."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11847"
    ],
    "c_title":[
      "A Spiral Bicycle Track that Can Be Traced by a Unicycle"
    ],
    "c_abstract":[
      "A unibike curve is a track that can be made by either a bicycle or a\nunicycle. More precisely, the end of a unit tangent vector at any point on a\nunibike curve lies on the curve (so the bike's front wheel always lies on the\ntrack made by the rear wheel). David Finn found such a curve in 2002, but it\nloops around itself in an extremely complicated way with many twists and\nself-intersections. Starting with the polar square root curve r = sqrt[t\/(2\npi)] and iterating a simple construction involving a differential equation\napparently leads in the limit to a unibike curve having a spiral shape. The\niteration gets each curve as a rear track of its predecessor. Solving hundreds\nof differential equations numerically, where each depends on the preceding one,\nleads to error buildup, but with some care one can get a curve having unibike\nerror less than 10^-7. The evidence is strong for the conjecture that the limit\nof the iteration exists and is a unibike curve."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-132",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06971"
    ],
    "b_title":[
      "Fluorescent Biomolecules Detectable in Near-Surface Ice on Europa"
    ],
    "b_abstract":[
      "Europa, Jupiter's second Galilean moon, is believed to host a subsurface\nocean in contact with a rocky mantle, where hydrothermal activity may drive the\nsynthesis of organic molecules. Of these molecules, abiotic synthesis of\naromatic amino acids is unlikely, and their detection on Europa could be\nconsidered a biosignature. Fluorescence from aromatic amino acids, with\ncharacteristic emissions in the 200-400 nanometer wavelength range, can be\ninduced by a laser and may be detectable where ocean material has been\nrelatively recently emplaced on Europa's surface, as indicated by geologically\nyoung terrain and surface features. However, surface bombardment by charged\nparticles from the Jovian magnetosphere and solar ultraviolet (UV) radiation\ndegrades organic molecules, limiting their longevity. We model radiolysis and\nphotolysis of aromatic amino acids embedded in ice, showing dependencies on\nhemispheric and latitudinal patterns of charged particle bombardment and ice\nphase. We demonstrate that biosignatures contained within freshly deposited ice\nin high-latitude regions on the surface of Europa are detectable using\nlaser-induced UV fluorescence, even from an orbiting spacecraft."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05484"
    ],
    "c_title":[
      "DecoupledGaussian: Object-Scene Decoupling for Physics-Based Interaction"
    ],
    "c_abstract":[
      "We present DecoupledGaussian, a novel system that decouples static objects\nfrom their contacted surfaces captured in-the-wild videos, a key prerequisite\nfor realistic Newtonian-based physical simulations. Unlike prior methods\nfocused on synthetic data or elastic jittering along the contact surface, which\nprevent objects from fully detaching or moving independently, DecoupledGaussian\nallows for significant positional changes without being constrained by the\ninitial contacted surface. Recognizing the limitations of current 2D inpainting\ntools for restoring 3D locations, our approach proposes joint Poisson fields to\nrepair and expand the Gaussians of both objects and contacted scenes after\nseparation. This is complemented by a multi-carve strategy to refine the\nobject's geometry. Our system enables realistic simulations of decoupling\nmotions, collisions, and fractures driven by user-specified impulses,\nsupporting complex interactions within and across multiple scenes. We validate\nDecoupledGaussian through a comprehensive user study and quantitative\nbenchmarks. This system enhances digital interaction with objects and scenes in\nreal-world environments, benefiting industries such as VR, robotics, and\nautonomous driving. Our project page is at:\nhttps:\/\/wangmiaowei.github.io\/DecoupledGaussian.github.io\/."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-133",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02945"
    ],
    "b_title":[
      "The Tabular Foundation Model TabPFN Outperforms Specialized Time Series\n  Forecasting Models Based on Simple Features"
    ],
    "b_abstract":[
      "Foundation models have become popular in forecasting due to their ability to\nmake accurate predictions, even with minimal fine-tuning on specific datasets.\nIn this paper, we demonstrate how the newly released regression variant of\nTabPFN, a general tabular foundation model, can be applied to time series\nforecasting. We propose a straightforward approach, TabPFN-TS, which pairs\nTabPFN with simple feature engineering to achieve strong forecasting\nperformance. Despite its simplicity and with only 11M parameters, TabPFN-TS\noutperforms Chronos-Mini, a model of similar size, and matches or even slightly\noutperforms Chronos-Large, which has 65-fold more parameters. A key strength of\nour method lies in its reliance solely on artificial data during pre-training,\navoiding the need for large training datasets and eliminating the risk of\nbenchmark contamination."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01509"
    ],
    "c_title":[
      "Proposal and Evaluation of a Practical CBCT Dose Optimization Method"
    ],
    "c_abstract":[
      "Objective: To propose a CBCT dose optimization method using readily available\nmeasurement equipment in radiation oncology departments.\n  Approach: A 0.6cc air kerma (Kair) calibrated Farmer chamber measured Kair at\nisocenter for five default CBCT protocols (HEAD, PELVIS, LARGE PELVIS, THORAX,\nSPOTLIGHT) on a Varian TrueBeam linac. Imaging parameters were modified to\nreduce cumulative exposure by reducing projections (by 25%, 50%, 75%) in FDK\nreconstruction, or lowering single frame exposure by 25%, 50%, 70 to 75%. Cone\nBeam Dose Index (CBDI) and weighted CBDI (CBDI_w) were measured in CTDI\nphantoms to correlate with Kair. Image quality was assessed quantitatively (HU\nlinearity, uniformity, low-contrast visibility, high-contrast resolution,\nspatial integrity) using Catphan604, and qualitatively via anthropomorphic\nphantoms.\n  Results: A linear relationship between Kair, CTDI, and CBDI_w was\nestablished. High-contrast resolution and spatial integrity were unaffected by\ndose reduction (R < 0.5), while low-contrast visibility strongly correlated\nwith exposure (R > 0.75). HU uniformity and linearity remained stable (<40 HU\ndeviation), except for LARGE PELVIS at <50% single-frame exposure. 80 to 50%\ndose reduction retained clinically acceptable image quality with minimal\nartifacts or noise.\n  Significance: CBCT protocols on TrueBeam linacs were optimized for dose\nreduction. The method enables easy implementation by radiotherapy physicists\nwithout diagnostic physics equipment or expertise."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-134",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16731"
    ],
    "b_title":[
      "On the acceleration of gradient methods: the triangle steepest descent\n  method"
    ],
    "b_abstract":[
      "The gradient type of methods has been a competitive choice in solving large\nscale problems arising from various applications such as machine learning.\nHowever, there is still space to accelerate the gradient methods. To this end,\nin this paper, we pay attention to the cyclic steepest descent method (CSD),\nand prove that the CSD method has a gradient subsequence that is\nR-superlinearly convergent for the 2-dimensional strictly convex quadratic\ncase. Moreover, we propose a new gradient method called triangle steepest\ndescent method (TSD) which has a parameter $j$ to control the number of cycles.\nThis method is motivated by utilizing a geometric property of the steepest\ndescent method (SD) method to get around the zigzag behavior. We show that the\nTSD method is at least R-linearly convergent for strictly convex quadratic\nproblems. The advantage of the TSD method is that it is not sensitive to the\ncondition number of a strictly convex quadratic problem. For example, it\nperforms better than other competitive gradient methods when the condition\nnumber reaches 1e20 or 1e100 for some strictly convex quadratic problems.\nExtensive numerical results verify the efficiency of the TSD method compared to\nother types of gradient methods."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.02691"
    ],
    "c_title":[
      "Memory Efficient Continual Learning for Edge-Based Visual Anomaly\n  Detection"
    ],
    "c_abstract":[
      "Visual Anomaly Detection (VAD) is a critical task in computer vision with\nnumerous real-world applications. However, deploying these models on edge\ndevices presents significant challenges, such as constrained computational and\nmemory resources. Additionally, dynamic data distributions in real-world\nsettings necessitate continuous model adaptation, further complicating\ndeployment under limited resources. To address these challenges, we present a\nnovel investigation into the problem of Continual Learning for Visual Anomaly\nDetection (CLAD) on edge devices. We evaluate the STFPM approach, given its low\nmemory footprint on edge devices, which demonstrates good performance when\ncombined with the Replay approach. Furthermore, we propose to study the\nbehavior of a recently proposed approach, PaSTe, specifically designed for the\nedge but not yet explored in the Continual Learning context. Our results show\nthat PaSTe is not only a lighter version of STPFM, but it also achieves\nsuperior anomaly detection performance, improving the f1 pixel performance by\n10% with the Replay technique. In particular, the structure of PaSTe allows us\nto test it using a series of Compressed Replay techniques, reducing memory\noverhead by a maximum of 91.5% compared to the traditional Replay for STFPM.\nOur study proves the feasibility of deploying VAD models that adapt and learn\nincrementally on CLAD scenarios on resource-constrained edge devices."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-135",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08257"
    ],
    "b_title":[
      "DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with\n  Physics Awareness"
    ],
    "b_abstract":[
      "A dexterous hand capable of grasping any object is essential for the\ndevelopment of general-purpose embodied intelligent robots. However, due to the\nhigh degree of freedom in dexterous hands and the vast diversity of objects,\ngenerating high-quality, usable grasping poses in a robust manner is a\nsignificant challenge. In this paper, we introduce DexGrasp Anything, a method\nthat effectively integrates physical constraints into both the training and\nsampling phases of a diffusion-based generative model, achieving\nstate-of-the-art performance across nearly all open datasets. Additionally, we\npresent a new dexterous grasping dataset containing over 3.4 million diverse\ngrasping poses for more than 15k different objects, demonstrating its potential\nto advance universal dexterous grasping. The code of our method and our dataset\nwill be publicly released soon."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15965"
    ],
    "c_title":[
      "Practical Portfolio Optimization with Metaheuristics:Pre-assignment\n  Constraint and Margin Trading"
    ],
    "c_abstract":[
      "Portfolio optimization is a critical area in finance, aiming to maximize\nreturns while minimizing risk. Metaheuristic algorithms were shown to solve\ncomplex optimization problems efficiently, with Genetic Algorithms and Particle\nSwarm Optimization being among the most popular methods. This paper introduces\nan innovative approach to portfolio optimization that incorporates\npre-assignment to limit the search space for investor preferences and better\nresults. Additionally, taking margin trading strategies in account and using a\nrare performance ratio to evaluate portfolio efficiency. Through an\nillustrative example, this paper demonstrates that the metaheuristic-based\nmethodology yields superior risk-adjusted returns compared to traditional\nbenchmarks. The results highlight the potential of metaheuristics with help of\nassets filtering in enhancing portfolio performance in terms of risk adjusted\nreturn."
    ],
    "c_categories":[
      [
        "cs.CE",
        "q-fin.PM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-136",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18033"
    ],
    "b_title":[
      "OmnimatteZero: Training-free Real-time Omnimatte with Pre-trained Video\n  Diffusion Models"
    ],
    "b_abstract":[
      "Omnimatte aims to decompose a given video into semantically meaningful\nlayers, including the background and individual objects along with their\nassociated effects, such as shadows and reflections. Existing methods often\nrequire extensive training or costly self-supervised optimization. In this\npaper, we present OmnimatteZero, a training-free approach that leverages\noff-the-shelf pre-trained video diffusion models for omnimatte. It can remove\nobjects from videos, extract individual object layers along with their effects,\nand composite those objects onto new videos. We accomplish this by adapting\nzero-shot image inpainting techniques for video object removal, a task they\nfail to handle effectively out-of-the-box. We then show that self-attention\nmaps capture information about the object and its footprints and use them to\ninpaint the object's effects, leaving a clean background. Additionally, through\nsimple latent arithmetic, object layers can be isolated and recombined\nseamlessly with new video layers to produce new videos. Evaluations show that\nOmnimatteZero not only achieves superior performance in terms of background\nreconstruction but also sets a new record for the fastest Omnimatte approach,\nachieving real-time performance with minimal frame runtime."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12504"
    ],
    "c_title":[
      "Shapes of unit lattices in $D_p$-number fields"
    ],
    "c_abstract":[
      "The unit group of the ring of integers of a number field, modulo torsion, is\na lattice via the logarithmic Minkowski embedding. We examine the shape of this\nlattice, which we call the unit shape, within the family of prime degree $p$\nnumber fields whose Galois closure has dihedral Galois group $D_p$ and a unique\nreal embedding. In the case $p = 5$, we prove that the unit shapes lie on a\nsingle hypercycle on the modular surface (in this case, the modular surface is\nthe space of shapes of rank $2$ lattices). For general $p$, we show that the\nunit shapes are contained in a finite union of translates of periodic torus\norbits in the space of shapes."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-137",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03872"
    ],
    "b_title":[
      "Universal self-gravitating skyrmions"
    ],
    "b_abstract":[
      "The self-gravitating skyrmion is an exact solution of the Einstein\n$SU(2)$-Skyrme model describing a topological soliton with baryon number $B=1$,\nliving in a $4$-dimensional space-time in the presence of a cosmological\nconstant. Here we show that, using the maximal embedding Ansatz of $SU(2)$ into\n$SU(N)$ in the Euler angles parametrization, this solution can be generalized\nto include arbitrary values of the flavor number and, consequently, allowing\nhigher values of the topological charge. Also, we show that higher-order\ncorrections in the 't Hooft expansion can be considered while still preserving\nthe analytical nature of the solutions. Finally we will show that from the\ngravitational solutions it is possible to construct skyrmions in flat\nspace-time at a finite volume."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16079"
    ],
    "c_title":[
      "Together We Rise: Optimizing Real-Time Multi-Robot Task Allocation using\n  Coordinated Heterogeneous Plays"
    ],
    "c_abstract":[
      "Efficient task allocation among multiple robots is crucial for optimizing\nproductivity in modern warehouses, particularly in response to the increasing\ndemands of online order fulfillment. This paper addresses the real-time\nmulti-robot task allocation (MRTA) problem in dynamic warehouse environments,\nwhere tasks emerge with specified start and end locations. The objective is to\nminimize both the total travel distance of robots and delays in task\ncompletion, while also considering practical constraints such as battery\nmanagement and collision avoidance. We introduce MRTAgent, a dual-agent\nReinforcement Learning (RL) framework inspired by self-play, designed to\noptimize task assignments and robot selection to ensure timely task execution.\nFor safe navigation, a modified linear quadratic controller (LQR) approach is\nemployed. To the best of our knowledge, MRTAgent is the first framework to\naddress all critical aspects of practical MRTA problems while supporting\ncontinuous robot movements."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-138",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09614"
    ],
    "b_title":[
      "Reversing the Computing Research Workforce Shortfall: Bolstering\n  Domestic Student Pathways to PhDs"
    ],
    "b_abstract":[
      "To sustain innovation and safeguard national security, the U.S. must\nstrengthen domestic pathways to computing PhDs by engaging talented\nundergraduates early - before they are committed to industry - with research\nexperiences, mentorship, and financial support for graduate studies."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01411"
    ],
    "c_title":[
      "Maximally Extendable Product Codes are Good Coboundary Expanders"
    ],
    "c_abstract":[
      "We investigate the coboundary expansion property of product codes called\nproduct expansion, which plays an important role in the recent constructions of\ngood quantum LDPC codes and classical locally testable codes. Prior research\nrevealed that this property is equivalent to agreement testability and robust\ntestability for products of two codes of linear distance. However, for products\nof more than two codes, product expansion is a strictly stronger property. In\nthis paper, we prove that the collection of random codes over a sufficiently\nlarge field has good product expansion. We believe that in the case of four\ncodes, these ideas can be used to construct good quantum locally testable codes\nin a way similar to the current constructions using only products of two codes."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-139",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20563"
    ],
    "b_title":[
      "Mean-field approximation and phase transitions in an Ising-voter model\n  on directed regular random graphs"
    ],
    "b_abstract":[
      "It is known that on directed graphs, the correlations between neighbours of a\ngiven site vanish and thus simple mean-field-like arguments can be used to\ndescribe exactly the behaviour of Ising-like systems. We analyse heterogeneous\nmodifications of such models where a fraction of agents is driven by the voter\nor the antivoter dynamics. It turns out that voter agents do not affect the\ndynamics of the model and it behaves like a pure Ising model. Antivoter agents\nhave a stronger impact since they act as a kind of noise, which weakens a\nferromagnetic ordering. Only when Ising spins are driven by the heat-bath\ndynamics, the behaviour of the model is correctly described by the mean-field\napproximation. The Metropolis dynamics generates some additional correlations\nthat render the mean-field approach approximate. Simulations on annealed\nnetworks agree with the mean-field approximation but for the model with\nantivoters and with the Metropolis dynamics only its heterogeneous version\nprovides such an agreement. Calculation of the Binder cumulant confirms that\ncritical points in our models with the heat-bath dynamics belong to the Ising\nmean-field universality class. For the Metropolis dynamics, the phase\ntransition is most likely discontinuous, at least for not too many antivoters."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.18482"
    ],
    "c_title":[
      "MixLLM: Dynamic Routing in Mixed Large Language Models"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) exhibit potential artificial generic\nintelligence recently, however, their usage is costly with high response\nlatency. Given mixed LLMs with their own strengths and weaknesses, LLM routing\naims to identify the most suitable model for each query in the stream to\nmaximize response quality and minimize cost and latency. However, the\nchallenges involve: (1) dynamic trade-offs among quality, cost, and latency;\n(2) enabling continual learning in deployed systems; and (3) navigating a\nvarying (e.g., new LLM addition or old LLM removal) set of LLM candidates over\ntime. To bridge these gaps, we develop MixLLM, a dynamic\ncontextual-bandit-based routing system for query-LLM assignment. Specifically,\nwe first leverage query tags to enhance query embeddings for the routing task.\nNext, we design lightweight prediction models to estimate the response\nqualities and costs of queries over LLMs. We then devise a meta-decision maker\nto choose the query-LLM assignments to best tradeoff response quality, cost,\nand latency. Finally, the system benefits from continual training, allowing it\nto adapt to evolving queries and user feedback over time. Our extensive\nexperiments show that MixLLM achieves the best trade-offs in response quality,\ncost, and latency (97.25% of GPT-4's quality at 24.18% of the cost under the\ntime constraint)."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-140",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08334"
    ],
    "b_title":[
      "Navier-Stokes\/Allen-Cahn system with moving contact line"
    ],
    "b_abstract":[
      "In this paper, we study a diffuse interface model for two-phase immiscible\nflows coupled by Navier-Stokes equations and mass-conserving Allen-Cahn\nequations. The contact line (the intersection of the fluid-fluid interface with\nthe solid wall) moves along the wall when one fluid replaces the other, such as\nin liquid spreading or oil-water displacement. The system is equipped with the\ngeneralized Navier boundary conditions (GNBC) for the fluid velocity\n${\\boldsymbol u}$, and dynamic boundary condition or relaxation boundary\ncondition for the phase field variable $\\phi$. We first obtain the\nlocal-in-time existence of unique strong solutions to the 2D and 3D\nNavier-Stokes\/Allen-Cahn (NSAC) system with generalized Navier boundary\nconditions and dynamic boundary condition. For the 2D case in channels, we\nfurther show these solutions can be extended to any large time $T$.\nAdditionally, we prove the local-in-time strong solutions for systems with\ngeneralized Navier boundary conditions and relaxation boundary condition in 3D\nchannels. Finally, we establish a global unique strong solution accompany with\nsome exponential decay estimates when the fluids are near phase separation\nstates and the contact angle closes to 90 degrees or the fluid-fluid interface\ntension constant is small."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.03473"
    ],
    "c_title":[
      "Critical-like phenomenon in scraping of jamming systems"
    ],
    "c_abstract":[
      "In jamming systems like colloids, emulsions, foams, and biological tissues,\nsignificant deformation is essential for processes such as material scraping or\nwound self-healing. To adequately spread a foam or cream over a surface,\nexternal force must be applied to artificially scrape it. The scraping of foam\nusing a rigid plate has been observed to exhibit complex behavior distinct from\nthat of simple liquids. In this study, we quantitatively analyzed the\ntransition between partial and slender scraping regimes by examining changes in\ninternal structure and partial spreading lengths. Our findings reveal that the\nsequential propagation of bubble rearrangement in the foam's internal structure\nleads to the partial scraping. Moreover, the scraping length in the partial\nscraping regime shows divergence near the transition point, characterized by a\ncritical exponent of approximately 0.61. These results imply that foam scraping\nis governed by directional percolation theory, supported by the agreement\nbetween the experimentally observed critical exponent and theoretical\npredictions. This research significantly advances the understanding of\nmacroscopic kinetics and rheological behavior in jamming systems, including\nfoams, colloids, emulsions, and biological tissues."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-141",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07190"
    ],
    "b_title":[
      "Epitaxial thin films of pyrochlore iridates: a forward looking approach"
    ],
    "b_abstract":[
      "Topological quantum materials that show strongly correlated electrons as well\nas topological order, for which spin-orbit coupling is a key ingredient,\nexhibit novel states of matter. One such example is the family of pyrochlore\niridates, featuring strong spin-orbital coupling, strong electron interactions\nas well as geometric frustration, making them an ideal platform to study novel\ntopological phases. High-quality epitaxial pyrochlore iridate films, although\nchallenging to produce, provide a pathway to explore unconventional behaviours\nand unravel the intrinsic properties of these largely unexplored materials.\nAdditionally, designing interfaces with specific properties is crucial to\ncreate multilayered devices that can achieve significant technological\nbreakthroughs using topological states of these materials. This article reviews\nexperimental work on epitaxial pyrochlore iridate thin films, discussing\nevidence of topological phases found in them. Future research directions are\noutlined, which include exploring the rich tunability offered by chemical\ndoping, especially when combined with the design of epitaxial heterostructures."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.07943"
    ],
    "c_title":[
      "CREDAL: Close Reading of Data Models"
    ],
    "c_abstract":[
      "Data models are necessary for the birth of data and of any data-driven\nsystem. Indeed, every algorithm, every machine learning model, every\nstatistical model, and every database has an underlying data model without\nwhich the system would not be usable. Hence, data models are excellent sites\nfor interrogating the (material, social, political, ...) conditions giving rise\nto a data system. Towards this, drawing inspiration from literary criticism, we\npropose to closely read data models in the same spirit as we closely read\nliterary artifacts. Close readings of data models reconnect us with, among\nother things, the materiality, the genealogies, the techne, the closed nature,\nand the design of technical systems.\n  While recognizing from literary theory that there is no one correct way to\nread, it is nonetheless critical to have systematic guidance for those\nunfamiliar with close readings. This is especially true for those trained in\nthe computing and data sciences, who too often are enculturated to set aside\nthe socio-political aspects of data work. A systematic methodology for reading\ndata models currently does not exist. To fill this gap, we present the CREDAL\nmethodology for close readings of data models. We detail our iterative\ndevelopment process and present results of a qualitative evaluation of CREDAL\ndemonstrating its usability, usefulness, and effectiveness in the critical\nstudy of data."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-142",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12966"
    ],
    "b_title":[
      "Optimal Denoising in Score-Based Generative Models: The Role of Data\n  Regularity"
    ],
    "b_abstract":[
      "Score-based generative models achieve state-of-the-art sampling performance\nby denoising a distribution perturbed by Gaussian noise. In this paper, we\nfocus on a single deterministic denoising step, and compare the optimal\ndenoiser for the quadratic loss, we name ''full-denoising'', to the alternative\n''half-denoising'' introduced by Hyv{\\\"a}rinen (2024). We show that looking at\nthe performances in term of distance between distribution tells a more nuanced\nstory, with different assumptions on the data leading to very different\nconclusions. We prove that half-denoising is better than full-denoising for\nregular enough densities, while full-denoising is better for singular densities\nsuch as mixtures of Dirac measures or densities supported on a low-dimensional\nsubspace. In the latter case, we prove that full-denoising can alleviate the\ncurse of dimensionality under a linear manifold hypothesis."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.19068"
    ],
    "c_title":[
      "When a forest, narrowed to an atom of subset algebra, turns out to be a\n  tree"
    ],
    "c_abstract":[
      "It is proved that the restriction of a $k$ and $(k-1)$-component directed\nspanning forest of minimal weight to an atom of the subset algebra generated by\nthe sets of vertices of trees of $k$-component minimal spanning forests is a\ntree. For spanning minimal forests consisting of fewer components, this\nproperty, generally speaking, does not exist."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-143",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12683"
    ],
    "b_title":[
      "AC nuclear Stark effect in H-atom via super-intense laser-atom\n  interaction"
    ],
    "b_abstract":[
      "We investigate the nuclear Stark effect induced in hydrogen-like atomic\nnuclei under super-intense laser fields. Since laser wavelengths are generally\nlarger than nuclear dimensions, direct laser-nucleus interaction is unfeasible.\nInstead, this effect is induced indirectly through electron oscillations in the\nlaser field, which produce a periodic electric field that shifts the nuclear\nenergy levels. Using perturbation theory, we derive an expression for the\nenergy shift and dynamic polarizability of the nucleus as a function of laser\nparameters. Our findings reveal that the Nuclear Stark effect can be controlled\nby adjusting the laser frequency and intensity, potentially enabling\napplications in nuclear and quantum optical systems."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10726"
    ],
    "c_title":[
      "Prototype-Guided Cross-Modal Knowledge Enhancement for Adaptive Survival\n  Prediction"
    ],
    "c_abstract":[
      "Histo-genomic multimodal survival prediction has garnered growing attention\nfor its remarkable model performance and potential contributions to precision\nmedicine. However, a significant challenge in clinical practice arises when\nonly unimodal data is available, limiting the usability of these advanced\nmultimodal methods. To address this issue, this study proposes a\nprototype-guided cross-modal knowledge enhancement (ProSurv) framework, which\neliminates the dependency on paired data and enables robust learning and\nadaptive survival prediction. Specifically, we first introduce an intra-modal\nupdating mechanism to construct modality-specific prototype banks that\nencapsulate the statistics of the whole training set and preserve the\nmodality-specific risk-relevant features\/prototypes across intervals.\nSubsequently, the proposed cross-modal translation module utilizes the learned\nprototypes to enhance knowledge representation for multimodal inputs and\ngenerate features for missing modalities, ensuring robust and adaptive survival\nprediction across diverse scenarios. Extensive experiments on four public\ndatasets demonstrate the superiority of ProSurv over state-of-the-art methods\nusing either unimodal or multimodal input, and the ablation study underscores\nits feasibility for broad applicability. Overall, this study addresses a\ncritical practical challenge in computational pathology, offering substantial\nsignificance and potential impact in the field."
    ],
    "c_categories":[
      [
        "cs.LG",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-144",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04889"
    ],
    "b_title":[
      "Exceptional Topology on Nonorientable Manifolds"
    ],
    "b_abstract":[
      "We classify gapped and gapless phases of non-Hermitian band structures on\ntwo-dimensional nonorientable parameter spaces. Such spaces arise in a wide\nrange of physical systems in the presence of non-symmorphic parameter space\nsymmetries. For gapped phases, we find that nonorientable spaces provide a\nnatural setting for exploring fundamental structural problems in braid group\ntheory, such as torsion and conjugacy. Gapless phases, which host exceptional\npoints (EPs), explicitly violate the fermion doubling theorem, even in two-band\nmodels. We demonstrate that EPs traversing the nonorientable parameter space\nexhibit non-Abelian charge inversion. These braided phases and their\ntransitions leave distinct signatures in the form of bulk Fermi arc\ndegeneracies, offering a concrete route toward experimental realization and\nverification."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "math-ph",
        "math.MP",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.14792"
    ],
    "c_title":[
      "From anomalous diffusion in polygons to a transport locking relation"
    ],
    "c_abstract":[
      "We study particle transport in a class of open channels of finite length,\nmade of identical cells of connected open polygonal billiards with parallel\nboundaries. In these systems the Mean Square Displacement (MSD) grows in time\nfaster than linearly. We show that irrespective of the geometry of these\nchannels, the distribution of the first return times decays algebraically with\ntwo different exponents, separated by a crossover region that is determined by\nthe MSD. We find that the distribution of first return times satisfies a simple\nscaling form. In turn, the transmission coefficient, defined as the fraction of\ntrajectories that starting at the cell at the origin escape the channel through\nthe other boundary, decays algebraically with the size of the system, and, as a\nsignature of non-recurrent transport, sometimes slower. From these two\nprocesses we derive a locking relation among the scaling exponents for the\nasymptotic behavior of the MSD, the times of first return to the origin and the\nway transmission decays with the system size, showing that these three\nprocesses are interdependent. The locking relation holds for diffusive\nprocesses, as well as for fractional Brownian motion with arbitrary Hurst\nexponent. We argue that the locking relation may be valid for many other\ntransport processes, Markovian or not, with finite MSD."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "nlin.CD"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-145",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04071"
    ],
    "b_title":[
      "The vertexing challenge at FCC-ee"
    ],
    "b_abstract":[
      "Following in the footsteps of the LHC, the Future Circular Collider (FCC)\nplans to be the next multi-generational collider project. In the first stage,\nFCC-ee will collide intense beams of electrons and positrons at centre of mass\nenergies between 88 and 365 GeV, making it an electroweak, flavour, Higgs and\ntop factory. The unprecedented statistical precision requires FCC-ee\nexperiments to limit their systematic uncertainties to the very minimum.\n  The precise reconstruction of the interaction vertices is central to most\nmeasurements at FCC-ee, such as rare flavour physics processes and the\nmeasurement of Higgs and Z decays to bottom and charm quarks and taus. This\ncontribution will discuss the requirements of FCC-ee vertex detectors, from the\nnecessary impact parameter resolution via the challenging collision environment\nat the Z pole to the tight requirement on the material budget, which should be\nkept below 0.3% of a radiation length per detection layer. Next, the proposed\nvertex detector designs for FCC-ee are shortly presented, and an outlook is\ngiven on novel detector designs and features.\n  The requirements for the vertexing performance translate into requirements\nfor the sensors used for the vertex detector. As discussed in this\ncontribution, they need to feature a spatial resolution of about 3 $\\mu$m and\nprovide timing information of O($\\mu$s-ns) while keeping power consumption\nminimal to allow for air-cooling of the detector - minimising the detector\nmaterial budget.\n  The only type of sensor capable of aiming to fulfil such requirements are\nCMOS Monolithic Active Pixel Sensors (MAPS), which combine signal generation,\namplification and readout into a single silicon die. Therefore, the rest of\nthis contribution will present an overview of existing and planned MAPS\ntechnologies and prototypes aiming to fulfil the stringent FCC-ee vertex\ndetector requirements."
    ],
    "b_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11937"
    ],
    "c_title":[
      "FitLight: Federated Imitation Learning for Plug-and-Play Autonomous\n  Traffic Signal Control"
    ],
    "c_abstract":[
      "Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC)\nmethods have been extensively studied, their practical applications still raise\nsome serious issues such as high learning cost and poor generalizability. This\nis because the ``trial-and-error'' training style makes RL agents extremely\ndependent on the specific traffic environment, which also requires a long\nconvergence time. To address these issues, we propose a novel Federated\nImitation Learning (FIL)-based framework for multi-intersection TSC, named\nFitLight, which allows RL agents to plug-and-play for any traffic environment\nwithout additional pre-training cost. Unlike existing imitation learning\napproaches that rely on pre-training RL agents with demonstrations, FitLight\nallows real-time imitation learning and seamless transition to reinforcement\nlearning. Due to our proposed knowledge-sharing mechanism and novel hybrid\npressure-based agent design, RL agents can quickly find a best control policy\nwith only a few episodes. Moreover, for resource-constrained TSC scenarios,\nFitLight supports model pruning and heterogeneous model aggregation, such that\nRL agents can work on a micro-controller with merely 16{\\it KB} RAM and 32{\\it\nKB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art\nmethods, FitLight not only provides a superior starting point but also\nconverges to a better final solution on both real-world and synthetic datasets,\neven under extreme resource limitations."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-146",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12378"
    ],
    "b_title":[
      "Identification and estimation of structural vector autoregressive models\n  via LU decomposition"
    ],
    "b_abstract":[
      "Structural vector autoregressive (SVAR) models are widely used to analyze the\nsimultaneous relationships between multiple time-dependent data. Various\nstatistical inference methods have been studied to overcome the identification\nproblems of SVAR models. However, most of these methods impose strong\nassumptions for innovation processes such as the uncorrelation of components.\nIn this study, we relax the assumptions for innovation processes and propose an\nidentification method for SVAR models under the zero-restrictions on the\ncoefficient matrices, which correspond to sufficient conditions for LU\ndecomposition of the coefficient matrices of the reduced form of the SVAR\nmodels. Moreover, we establish asymptotically normal estimators for the\ncoefficient matrices and impulse responses, which enable us to construct test\nstatistics for the simultaneous relationships of time-dependent data. The\nfinite-sample performance of the proposed method is elucidated by numerical\nsimulations. We also present an example of an empirical study that analyzes the\nimpact of policy rates on unemployment and prices."
    ],
    "b_categories":[
      [
        "econ.EM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.01312"
    ],
    "c_title":[
      "CleanPose: Category-Level Object Pose Estimation via Causal Learning and\n  Knowledge Distillation"
    ],
    "c_abstract":[
      "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be released."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-147",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06374"
    ],
    "b_title":[
      "AFRIDOC-MT: Document-level MT Corpus for African Languages"
    ],
    "b_abstract":[
      "This paper introduces AFRIDOC-MT, a document-level multi-parallel translation\ndataset covering English and five African languages: Amharic, Hausa, Swahili,\nYor\\`ub\\'a, and Zulu. The dataset comprises 334 health and 271 information\ntechnology news documents, all human-translated from English to these\nlanguages. We conduct document-level translation benchmark experiments by\nevaluating neural machine translation (NMT) models and large language models\n(LLMs) for translations between English and these languages, at both the\nsentence and pseudo-document levels. These outputs are realigned to form\ncomplete documents for evaluation. Our results indicate that NLLB-200 achieved\nthe best average performance among the standard NMT models, while GPT-4o\noutperformed general-purpose LLMs. Fine-tuning selected models led to\nsubstantial performance gains, but models trained on sentences struggled to\ngeneralize effectively to longer documents. Furthermore, our analysis reveals\nthat some LLMs exhibit issues such as under-generation, repetition of words or\nphrases, and off-target translations, especially for African languages."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05504"
    ],
    "c_title":[
      "Piezoelectric Bulk Acoustic Resonators For Dark Photon Detection"
    ],
    "c_abstract":[
      "The kinetically mixed dark photon is a simple, testable dark matter candidate\nwith strong theoretical motivation. Detecting the feeble electric field dark\nphoton dark matter produces requires extremely sensitive detectors. Bulk\nacoustic resonators (BARs), with their exceptionally high-quality phonon modes,\nare capable of achieving incredible sensitivity to gravitational waves in the\nMHz to GHz frequency range. The BAR phonons are typically read out by detecting\nthe electric field generated by the BAR materials' piezoelectricity. Here we\nshow that this piezoelectricity also rewards such detectors sensitivity to dark\nphoton dark matter, as the dark electric field can resonantly excite BAR\nphonons. A single 10 g piezoelectric BAR in a large, cold, environment can be\norders of magnitude more sensitive to the kinetic mixing parameter than any\ncurrent experiment, with only a month-long exposure and thermally-limited\nbackgrounds."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-148",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08019"
    ],
    "b_title":[
      "An AI-driven framework for rapid and localized optimizations of urban\n  open spaces"
    ],
    "b_abstract":[
      "As urbanization accelerates, open spaces are increasingly recognized for\ntheir role in enhancing sustainability and well-being, yet they remain\nunderexplored compared to built spaces. This study introduces an AI-driven\nframework that integrates machine learning models (MLMs) and explainable AI\ntechniques to optimize Sky View Factor (SVF) and visibility, key spatial\nmetrics influencing thermal comfort and perceived safety in urban spaces.\nUnlike global optimization methods, which are computationally intensive and\nimpractical for localized adjustments, this framework supports incremental\ndesign improvements with lower computational costs and greater flexibility. The\nframework employs SHapley Adaptive Explanations (SHAP) to analyze feature\nimportance and Counterfactual Explanations (CFXs) to propose minimal design\nchanges. Simulations tested five MLMs, identifying XGBoost as the most\naccurate, with building width, park area, and heights of surrounding buildings\nas critical for SVF, and distances from southern buildings as key for\nvisibility. Compared to Genetic Algorithms, which required approximately 15\/30\nminutes across 3\/4 generations to converge, the tested CFX approach achieved\noptimized results in 1 minute with a 5% RMSE error, demonstrating significantly\nfaster performance and suitability for scalable retrofitting strategies. This\ninterpretable and computationally efficient framework advances urban\nperformance optimization, providing data-driven insights and practical\nretrofitting solutions for enhancing usability and environmental quality across\ndiverse urban contexts."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09365"
    ],
    "c_title":[
      "On reflected L\\'evy processes with collapse"
    ],
    "c_abstract":[
      "We consider a L\\'evy process reflected at the origin with additional i.i.d.\ncollapses that occur at Poisson epochs, where a collapse is a jump downward to\na state which is a random fraction of the state just before the jump. We first\nstudy the general case, then specialize to the case where the L\\'evy process is\nspectrally positive and finally we specialize further to the two cases where\nthe L\\'evy process is a Brownian motion and a compound Poisson process with\nexponential jumps minus a linear slope."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-149",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03434"
    ],
    "b_title":[
      "RASD: Retrieval-Augmented Speculative Decoding"
    ],
    "b_abstract":[
      "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09939"
    ],
    "c_title":[
      "Infrared Behavior of Induced Gravitational Waves from Isocurvature\n  Perturbations"
    ],
    "c_abstract":[
      "Induced gravitational waves provide a powerful probe of primordial\nperturbations in the early universe through their distinctive spectral\nproperties. We analyze the spectral energy density $\\Omega_{\\text{GW}}$ of\ngravitational waves induced by isocurvature scalar perturbations. In the\ninfrared regime, we find that the spectral slope $n_{\\text{GW}} \\equiv \\text{d}\n\\ln\\Omega_\\mathrm{GW}\/\\text{d}\\ln k$ takes the log-dependent form $3-4\/ \\ln\n(\\tilde{k}_*^2 \/ 6k^2)$, where $\\tilde{k}_*$ represents the effective peak\nscale of the primordial scalar power spectrum. This characteristic behavior\ndiffers markedly from that of adiabatic-induced gravitational waves,\nestablishing a robust observational discriminant between isocurvature and\nadiabatic primordial perturbation modes."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-150",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14381"
    ],
    "b_title":[
      "dtaianomaly: A Python library for time series anomaly detection"
    ],
    "b_abstract":[
      "dtaianomaly is an open-source Python library for time series anomaly\ndetection, designed to bridge the gap between academic research and real-world\napplications. Our goal is to (1) accelerate the development of novel\nstate-of-the-art anomaly detection techniques through simple extensibility; (2)\noffer functionality for large-scale experimental validation; and thereby (3)\nbring cutting-edge research to business and industry through a standardized\nAPI, similar to scikit-learn to lower the entry barrier for both new and\nexperienced users. Besides these key features, dtaianomaly offers (1) a broad\nrange of built-in anomaly detectors, (2) support for time series preprocessing,\n(3) tools for visual analysis, (4) confidence prediction of anomaly scores, (5)\nruntime and memory profiling, (6) comprehensive documentation, and (7)\ncross-platform unit testing.\n  The source code of dtaianomaly, documentation, code examples and installation\nguides are publicly available at https:\/\/github.com\/ML-KULeuven\/dtaianomaly."
    ],
    "b_categories":[
      [
        "cs.DB",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16174"
    ],
    "c_title":[
      "Exciton Binding Energies in 2D Materials: Insights from Braneworld\n  Physics"
    ],
    "c_abstract":[
      "In the present work, we introduce a new interpretation of exciton binding\nenergies in two-dimensional (2D) materials using concepts from brane physics.\nWe adapt the Dvali-Gabadadze-Porrati-Shifman mechanism to a (2+1)-dimensional\nbrane in a (3+1)-D spacetime, deriving an effective electromagnetic potential\non the brane. Using this potential, we develop a hydrogenic model for exciton\nbinding energies in 2D materials, applying it to s-type excitons and comparing\ntheoretical predictions with experimental results on WS$_{2}$ monolayers. This\ninterdisciplinary approach bridges high-energy and condensed matter physics,\noffering a new didactic representation of excitons in low-dimensional systems."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-151",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13320"
    ],
    "b_title":[
      "Toward Ethical AI: A Qualitative Analysis of Stakeholder Perspectives"
    ],
    "b_abstract":[
      "As Artificial Intelligence (AI) systems become increasingly integrated into\nvarious aspects of daily life, concerns about privacy and ethical\naccountability are gaining prominence. This study explores stakeholder\nperspectives on privacy in AI systems, focusing on educators, parents, and AI\nprofessionals. Using qualitative analysis of survey responses from 227\nparticipants, the research identifies key privacy risks, including data\nbreaches, ethical misuse, and excessive data collection, alongside perceived\nbenefits such as personalized services, enhanced efficiency, and educational\nadvancements. Stakeholders emphasized the need for transparency,\nprivacy-by-design, user empowerment, and ethical oversight to address privacy\nconcerns effectively. The findings provide actionable insights into balancing\nthe benefits of AI with robust privacy protections, catering to the diverse\nneeds of stakeholders. Recommendations include implementing selective data use,\nfostering transparency, promoting user autonomy, and integrating ethical\nprinciples into AI development. This study contributes to the ongoing discourse\non ethical AI, offering guidance for designing privacy-centric systems that\nalign with societal values and build trust among users. By addressing privacy\nchallenges, this research underscores the importance of developing AI\ntechnologies that are not only innovative but also ethically sound and\nresponsive to the concerns of all stakeholders."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02548"
    ],
    "c_title":[
      "Investigating (Non)-Integrability and Pulsating String in D3-Brane\n  Background"
    ],
    "c_abstract":[
      "This work explores the (non)-integrability and chaotic dynamics of classical\nstrings in the background of a D3-brane with a non-commutative parameter,\nwithin the framework of the AdS\/CFT correspondence. Using the Polyakov action,\nwe derive the equations of motion and constraints for pulsating strings and\nanalyze their stability through perturbation theory. In the large energy limit,\nthe first-order perturbed equation simplifies to the P\\\"oschl-Teller equation,\nsolvable via associated Legendre or hypergeometric functions, while numerical\nmethods are employed for generic energy values. We demonstrate that the\nnon-commutative parameter enhances chaotic behavior, as evidenced by the\nLargest Lyapunov Exponent (LLE). Furthermore, we investigate the integrability\nof geodesic motion and identify two distinct string modes: capture and escape\nto infinity. Finally, we study pulsating strings in the deformed $(AdS_{3}\n\\times S^{2})_{\\varkappa}$ background, deriving dispersion relations for both\nshort and long strings."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-152",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05023"
    ],
    "b_title":[
      "Euclid: Detecting Solar System objects in Euclid images and classifying\n  them using Kohonen self-organising maps"
    ],
    "b_abstract":[
      "The ESA Euclid mission will survey more than 14,000 deg$^2$ of the sky in\nvisible and near-infrared wavelengths, mapping the extra-galactic sky to\nconstrain our cosmological model of the Universe. Although the survey focusses\non regions further than 15 deg from the ecliptic, it should allow for the\ndetection of more than about $10^5$ Solar System objects (SSOs). After\nsimulating the expected signal from SSOs in Euclid images acquired with the\nvisible camera (VIS), we describe an automated pipeline developed to detect\nmoving objects with an apparent velocity in the range of 0.1-10 arcsec\/h,\ntypically corresponding to sources in the outer Solar System (from Centaurs to\nKuiper-belt objects). In particular, the proposed detection scheme is based on\nSourcextractor software and on applying a new algorithm capable of associating\nmoving objects amongst different catalogues. After applying a suite of filters\nto improve the detection quality, we study the expected purity and completeness\nof the SSO detections. We also show how a Kohonen self-organising neural\nnetwork can be successfully trained (in an unsupervised fashion) to classify\nstars, galaxies, and SSOs. By implementing an early-stopping method in the\ntraining scheme, we show that the network can be used in a predictive way,\nallowing one to assign the probability of each detected object being a member\nof each considered class."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.13903"
    ],
    "c_title":[
      "A Criterion for the Algebraic Density Property of Affine\n  $SL_2$-Manifolds"
    ],
    "c_abstract":[
      "Let $B$ be an affine $k$-domain which admits a nontrivial fundamental pair\n$(D,U)$ of locally nilpotent derivations, i.e., if $E=[D,U]$ then $(D,U,E)$ is\nan $\\mathfrak{sl}_2$-triple. We prove an algebraic criterion, characterizing\nunder which conditions the fundamental pair $(D,U)$ resp. the triple $(D,U,E)$\nis compatible in a technical sense that allows us to construct many vector\nfields on the spectrum of $B$ from the complete ones. This criterion enables us\nto prove the algebraic density property for the following widely studied\nclasses of $\\mathrm{SL}_2$-varieties arising in physics: Classical\nCalogero--Moser spaces, Calogero--Moser spaces with \"inner degrees of freedom''\nand smooth cyclic quiver varieties."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.AG",
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-153",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09700"
    ],
    "b_title":[
      "The bright, dusty aftermath of giant eruptions & H-rich supernovae. Late\n  interaction of supernova shocks & dusty circumstellar shells"
    ],
    "b_abstract":[
      "The late-stage evolution of massive stars is marked by intense instability as\nthey approach core-collapse. During these phases, giant stellar eruptions lead\nto exceptionally high mass-loss rates, forming significant amounts of dust.\nHowever, the survival of these dust grains is challenged by the powerful shock\nwaves generated when the progenitor explodes as a supernova (SN). We explore\nthe impact of hydrogen-rich SN explosions from 45, 50, and 60 M$_\\odot$\nprogenitors on dust formed after these eruptions, focusing on interactions with\ncircumstellar shells occurring from a few years to centuries after the event.\nUsing 3D hydrodynamical simulations, we track the evolution of dust particles\nin a scenario that includes the progenitor's stellar wind, a giant eruption,\nand the subsequent SN explosion, following the mass budgets predicted by\nstellar evolution models. For a standard SN ejecta mass of 10 M$_\\odot$ and\nkinetic energy of $10^{51}$ erg, only 25% of the dust mass survives 250 years\npost-explosion in a spherical circumstellar medium (CSM), while merely 2%\nremains a century after the explosion in a bipolar CSM. If the SN follows the\neruption within a dozen years, 75% of the dust survives for a standard\nexplosion, dropping to 20% for more massive ejecta (15-20 M$_\\odot$) with\nkinetic energy of $5 \\times 10^{51}$ erg. The geometry of the CSM and the early\ntransition of the SN remnant into a radiative phase significantly influence\ndust survival. As the shock wave weakens and efficiently converts kinetic\nenergy into thermal radiation (up to half of the injected kinetic energy) the\nlikelihood of dust survival increases, affecting not only pre-existing dust in\nthe CSM but also SN-condensed dust and ambient interstellar dust. Contrary to\nexpectations, a larger fraction of the dust mass can survive if the SN occurs\nonly a few years after the eruption."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.13670"
    ],
    "c_title":[
      "Strichartz estimates for the half Klein-Gordon equation on\n  asymptotically flat backgrounds and applications to cubic Dirac equations"
    ],
    "c_abstract":[
      "The aim of this paper is to establish the $L^2_t$-endpoint Strichartz\nestimate for (half) Klein-Gordon equations on a weakly asymptotically flat\nspace-time. As an application we prove small data global well-posedness and\nscattering for massive cubic Dirac equations in the full subcritical range in\nthis setting.\n  Crucial ingredient is a parametrix contruction following the work of\nMetcalfe-Tataru and Xue and complements Strichartz estimates obtained by\nZheng-Zhang. The proof of the global result for the cubic Dirac equation\nfollows the strategy developed by Machihara-Nakanishi-Ozawa in the Euclidean\nsetting."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-154",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10708"
    ],
    "b_title":[
      "Exploration of Hepatitis B Virus Infection Dynamics through\n  Virology-Informed Neural Network: A Novel Artificial Intelligence Approach"
    ],
    "b_abstract":[
      "In this work, we introduce Virology-Informed Neural Networks (VINNs), a\npowerful tool for capturing the intricate dynamics of viral infection when data\nof some compartments of the model are not available. VINNs, an extension of the\nwidely known Physics-Informed Neural Networks (PINNs), offer an alternative\napproach to traditional numerical methods for solving system of differential\nequations. We apply this VINN technique on a recently proposed hepatitis B\nvirus (HBV) infection dynamics model to predict the transmission of the\ninfection within the liver more accurately. This model consists of four\ncompartments, namely uninfected and infected hepatocytes, rcDNA-containing\ncapsids, and free viruses, along with the consideration of capsid recycling.\nLeveraging the power of VINNs, we study the impacts of variations in parameter\nrange, experimental noise, data variability, network architecture, and learning\nrate in this work. In order to demonstrate the robustness and effectiveness of\nVINNs, we employ this approach on the data collected from nine HBV-infceted\nchimpanzees, and it is observed that VINNs can effectively estimate the model\nparameters. VINNs reliably capture the dynamics of infection spread and\naccurately predict their future progression using real-world data. Furthermore,\nVINNs efficiently identify the most influential parameters in HBV dynamics\nbased solely on experimental data from the capsid component. It is also\nexpected that this framework can be extended beyond viral dynamics, providing a\npowerful tool for uncovering hidden patterns and complex interactions across\nvarious scientific and engineering domains."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02029"
    ],
    "c_title":[
      "Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large\n  Vision-Language Models"
    ],
    "c_abstract":[
      "With the integration of an additional modality, large vision-language models\n(LVLMs) exhibit greater vulnerability to safety risks (e.g., jailbreaking)\ncompared to their language-only predecessors. Although recent studies have\ndevoted considerable effort to the post-hoc alignment of LVLMs, the inner\nsafety mechanisms remain largely unexplored. In this paper, we discover that\ninternal activations of LVLMs during the first token generation can effectively\nidentify malicious prompts across different attacks. This inherent safety\nperception is governed by sparse attention heads, which we term ``safety\nheads.\" Further analysis reveals that these heads act as specialized shields\nagainst malicious prompts; ablating them leads to higher attack success rates,\nwhile the model's utility remains unaffected. By locating these safety heads\nand concatenating their activations, we construct a straightforward but\npowerful malicious prompt detector that integrates seamlessly into the\ngeneration process with minimal extra inference overhead. Despite its simple\nstructure of a logistic regression model, the detector surprisingly exhibits\nstrong zero-shot generalization capabilities. Experiments across various\nprompt-based attacks confirm the effectiveness of leveraging safety heads to\nprotect LVLMs. Code is available at \\url{https:\/\/github.com\/Ziwei-Zheng\/SAHs}."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-155",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14989"
    ],
    "b_title":[
      "Morphology and kinematics of the gas in M51: How interaction with\n  NGC5195 has moulded the structure of its arms"
    ],
    "b_abstract":[
      "The Whirlpool Galaxy is a well studied grand design galaxy with two major\nspiral arms, and a large satellite NGC 5195. The arms both show long uniform\nsections with perturbations ('kinks' or sharp turns) in specific regions.\nComparing the two arms shows a small radial offset between the main kinked\nregions. We analysed the morphology and also the velocity field in the disk of\nM51 using kinematic maps based on H$\\alpha$ and CO line emission. These sample\ncomplementary radial ranges, with the CO map covering the central zone and the\nH$\\alpha$ map extending to cover the outer zone. We looked for indicators of\ndensity wave resonance, zones where radial flows of gas in the disk plane\nreverse their sign. These were present in both velocity maps; their\ntwo-dimensional localization placed them along or closely parallel to the\nspiral arms, at a set of well defined galactocentric radii, and notably more\nconcentrated along the southern, stronger arm. The results can be well\ninterpreted quantitatively, using a numerical model of the interaction of M51\nand NGC5195 in which the satellite has made two relatively recent passes\nthrough the disk plane of M51. During the first pass the pair of dominant\nspiral arms was stimulated, and during the second pass the strong kinks in both\narms were formed at about the same time. The second interaction is particularly\nwell characterised, because the timescale corresponding to the production of\nthe kinks and the recovery of the original pitch angle is identical for the two\narms."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.17475"
    ],
    "c_title":[
      "EMD-Fuzzy: An Empirical Mode Decomposition Based Fuzzy Model for\n  Cross-Stimulus Transfer Learning of SSVEP"
    ],
    "c_abstract":[
      "The Brain-Computer Interface (BCI) enables direct brain-to-device\ncommunication, with the Steady-State Visual Evoked Potential (SSVEP) paradigm\nfavored for its stability and high accuracy across various fields. In SSVEP BCI\nsystems, supervised learning models significantly enhance performance over\nunsupervised models, achieving higher accuracy in less time. However, prolonged\ndata collection can cause user fatigue and even trigger photosensitive\nepilepsy, creating a negative user experience. Thus, reducing calibration time\nis crucial. To address this, Cross-Stimulus transfer learning (CSTL) can\nshorten calibration by utilizing only partial frequencies. Traditional CSTL\nmethods, affected by time-domain impulse response variations, are suitable only\nfor adjacent frequency transfers, limiting their general applicability. We\nintroduce an Empirical Mode Decomposition (EMD) Based Fuzzy Model (EMD-Fuzzy),\nwhich employs EMD to extract crucial frequency information and achieves\nstimulus transfer in the frequency domain through Fast Fourier Transform (FFT)\nto mitigate time-domain differences. Combined with a Fuzzy Decoder that uses\nfuzzy logic for representation learning, our approach delivers promising\npreliminary results in offline tests and state-of-the-art performance. With\nonly 4 frequencies, our method achieved an accuracy of 82.75% (16.30%) and an\ninformation transfer rate (ITR) of 186.56 (52.09) bits\/min on the 40-target\nBenchmark dataset. In online tests, our method demonstrates robust efficacy,\nachieving an averaged accuracy of 86.30% (6.18%) across 7 subjects. This\nperformance underscores the effectiveness of integrating EMD and fuzzy logic\ninto EEG decoding for CSTL and highlights our method's potential in real-time\napplications where consistent and reliable decoding is crucial."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-156",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10171"
    ],
    "b_title":[
      "Area estimates for capillary cmc hypersurfaces with nonpositive Yamabe\n  invariant"
    ],
    "b_abstract":[
      "We prove area estimates for stable capillary $cmc$ (minimal) hypersurfaces\n$\\Sigma$ with nonpositive Yamabe invariant that are properly immersed in a\nRiemannian $n$-dimensional manifold $M$ with scalar curvature $R^M$ and mean\ncurvature of the boundary $H^{\\partial M}$ bounded from below. We also prove a\nlocal rigidity result in the case $\\Sigma$ is embedded and\n$\\mathcal{J}$-energy-minimizing. In this case, we show that $M$ locally splits\nalong $\\Sigma$ and is isometric to $(-\\varepsilon,\\varepsilon)\\times \\Sigma,\ndt^2 + e^{-2Ht}g)$, where $g$ is Einstein, or Ricci flat, $H\\geq 0$ and\n$\\partial\\Sigma$ is totally geodesic."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.03285"
    ],
    "c_title":[
      "Modelling noise in gravitational-wave observatories with\n  transdimensional models"
    ],
    "c_abstract":[
      "Modelling noise in gravitational-wave observatories is crucial for accurately\ninferring the properties of gravitational-wave sources. We introduce a\ntransdimensional Bayesian approach to characterise the noise in ground-based\ngravitational-wave observatories using the Bayesian inference software\n$\\texttt{Bilby}$. The algorithm models broadband noise with a combination of\npower laws; narrowband features with Lorentzians; and shapelets to capture any\nadditional features in the data. We show that our noise model provides a\nsignificantly improved fit of the LIGO and Virgo noise amplitude spectral\ndensities compared to currently available noise fits obtained with on-source\ndata segments. We perform astrophysical inference on well-known events in the\nthird Gravitational-Wave Transient Catalog using our noise model and observe\nshifts of up to $7\\%$ in the $90\\%$ boundaries of credible intervals for some\nparameters. We discuss plans to deploy this framework systematically for\ngravitational-wave inference along with possible areas of improvement."
    ],
    "c_categories":[
      [
        "astro-ph.IM",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-157",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20332"
    ],
    "b_title":[
      "Emergent Symbolic Mechanisms Support Abstract Reasoning in Large\n  Language Models"
    ],
    "b_abstract":[
      "Many recent studies have found evidence for emergent reasoning capabilities\nin large language models, but debate persists concerning the robustness of\nthese capabilities, and the extent to which they depend on structured reasoning\nmechanisms. To shed light on these issues, we perform a comprehensive study of\nthe internal mechanisms that support abstract rule induction in an open-source\nlanguage model (Llama3-70B). We identify an emergent symbolic architecture that\nimplements abstract reasoning via a series of three computations. In early\nlayers, symbol abstraction heads convert input tokens to abstract variables\nbased on the relations between those tokens. In intermediate layers, symbolic\ninduction heads perform sequence induction over these abstract variables.\nFinally, in later layers, retrieval heads predict the next token by retrieving\nthe value associated with the predicted abstract variable. These results point\ntoward a resolution of the longstanding debate between symbolic and neural\nnetwork approaches, suggesting that emergent reasoning in neural networks\ndepends on the emergence of symbolic mechanisms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.04090"
    ],
    "c_title":[
      "Dissipation and particle acceleration in astrophysical jets with\n  velocity and magnetic shear: Interaction of Kelvin-Helmholtz and Drift-Kink\n  Instabilities"
    ],
    "c_abstract":[
      "We present 2D particle-in-cell simulations of a magnetized, collisionless,\nrelativistic pair plasma subjected to combined velocity and magnetic-field\nshear, a scenario typical for astrophysical black-hole jet-wind boundaries. We\ncreate conditions where only the Kelvin-Helmholtz (KH) and Drift-Kink (DK)\ninstabilities can develop, while tearing modes are forbidden. We find that DKI\ncan effectively disrupt the cats-eye vortices generated by KHI, creating a\nturbulent shear layer on the DK timescale. This interplay leads to a\nsignificant enhancement of dissipation over cases with only velocity shear or\nonly magnetic shear. Moreover, we observe efficient nonthermal particle\nacceleration caused by the alignment of the instability-driven electric fields\nwith Speiser-like motion of particles close to the shear interface. This study\nhighlights the sensitivity of dissipation to multiple simultaneous\ninstabilities, thus providing a strong motivation for further studies of their\nnonlinear interaction at the kinetic level."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-158",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16637"
    ],
    "b_title":[
      "On the Li\\'enard's type equation: an icon of the Nonlinear Analysis"
    ],
    "b_abstract":[
      "In this note, we review the latest qualitative results, referring to the\nLi\\'enard Equation, in the framework of non-conformable, generalized and\nfractional differential operators."
    ],
    "b_categories":[
      [
        "math.GM"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.05065"
    ],
    "c_title":[
      "Multicenter higher-derivative BPS black holes"
    ],
    "c_abstract":[
      "We consider the reduction of four-derivative heterotic supergravity on a\ntorus and construct two-charge multicenter BPS black hole solutions. In $d=5$,\nthe three-form field can be dualized to a gauge field and we correspondingly\nconstruct three-charge multicenter BPS black hole solutions to the dualized\nBergshoeff-de Roo action. This makes precise the embedding of known solutions\ninto five-dimensional $\\alpha'$-corrected STU supergravity."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-159",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18848"
    ],
    "b_title":[
      "Reinforcement Learning of Flexible Policies for Symbolic Instructions\n  with Adjustable Mapping Specifications"
    ],
    "b_abstract":[
      "Symbolic task representation is a powerful tool for encoding human\ninstructions and domain knowledge. Such instructions guide robots to accomplish\ndiverse objectives and meet constraints through reinforcement learning (RL).\nMost existing methods are based on fixed mappings from environmental states to\nsymbols. However, in inspection tasks, where equipment conditions must be\nevaluated from multiple perspectives to avoid errors of oversight, robots must\nfulfill the same symbol from different states. To help robots respond to\nflexible symbol mapping, we propose representing symbols and their mapping\nspecifications separately within an RL policy. This approach imposes on RL\npolicy to learn combinations of symbolic instructions and mapping\nspecifications, requiring an efficient learning framework. To cope with this\nissue, we introduce an approach for learning flexible policies called Symbolic\nInstructions with Adjustable Mapping Specifications (SIAMS). This paper\nrepresents symbolic instructions using linear temporal logic (LTL), a formal\nlanguage that can be easily integrated into RL. Our method addresses the\ndiversified completion patterns of instructions by (1) a specification-aware\nstate modulation, which embeds differences in mapping specifications in state\nfeatures, and (2) a symbol-number-based task curriculum, which gradually\nprovides tasks according to the learning's progress. Evaluations in 3D\nsimulations with discrete and continuous action spaces demonstrate that our\nmethod outperforms context-aware multitask RL comparisons."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10951"
    ],
    "c_title":[
      "Energy rates due to Fe isotopes during presupernova evolution of massive\n  stars"
    ],
    "c_abstract":[
      "This work presents the microscopic calculation of energy rates ({\\gamma} ray\nheating and (anti)neutrino cooling rates) due to weak decay of selected Fe\nisotopes. The isotopes have astrophysical significance during the presupernova\nevolution of massive stars. The energy rates are calculated using the pn QRPA\nmodel and compared with the independent particle model (IPM), large scale shell\nmodel (LSSM) and recent shell model calculation (GXPF1J). The reported\n(anti)neutrino cooling rates are smaller by up to two orders of magnitude at\nlow core temperature values than the IPM rates. The two calculations compare\nwell at T = 30 GK. The comparison of cooling rates with the LSSM is\ninteresting. The pn QRPA cooling rates due to even even Fe isotopes are smaller\n(up to 2 orders of magnitude). For the odd A isotopes, the reported rates are\nbigger up to an order of magnitude. The pn QRPA computed cooling rates are, up\nto 2 orders of magnitude, bigger when compared with the GXPF1J calculation. The\n{\\gamma} ray heating rates due to electron capture rates rise with the\ntemperature and density values of the stellar core. On the other hand, the\n{\\gamma} ray heating due to \\b{eta} decay increases with the core temperature\nvalues but decreases by orders of magnitude when the stellar core stiffens. The\npn QRPA computed {\\gamma} heating rates are bigger (up to 3 orders of\nmagnitude) at high temperatures and densities (for the case of 55 56Fe) when\ncompared with the recent shell model results. Owing to the importance of energy\nrates, this study may contribute to a realistic simulation of presupernova\nevolution of massive stars."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-160",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01891"
    ],
    "b_title":[
      "Training and Evaluating with Human Label Variation: An Empirical Study"
    ],
    "b_abstract":[
      "Human label variation (HLV) challenges the standard assumption that a\nlabelled instance has a single ground truth, instead embracing the natural\nvariation in human annotation to train and evaluate models. While various\ntraining methods and metrics for HLV have been proposed, it is still unclear\nwhich methods and metrics perform best in what settings. We propose new\nevaluation metrics for HLV leveraging fuzzy set theory. Since these new\nproposed metrics are differentiable, we then in turn experiment with employing\nthese metrics as training objectives. We conduct an extensive study over 6 HLV\ndatasets testing 14 training methods and 6 evaluation metrics. We find that\ntraining on either disaggregated annotations or soft labels performs best\nacross metrics, outperforming training using the proposed training objectives\nwith differentiable metrics. We also show that our proposed soft metric is more\ninterpretable and correlates best with human preference."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00051"
    ],
    "c_title":[
      "A two-stage dual-task learning strategy for early prediction of\n  pathological complete response to neoadjuvant chemotherapy for breast cancer\n  using dynamic contrast-enhanced magnetic resonance images"
    ],
    "c_abstract":[
      "Rationale and Objectives: Early prediction of pathological complete response\n(pCR) can facilitate personalized treatment for breast cancer patients. To\nimprove prediction accuracy at the early time point of neoadjuvant\nchemotherapy, we proposed a two-stage dual-task learning strategy to train a\ndeep neural network for early prediction of pCR using early-treatment magnetic\nresonance images. Methods: We developed and validated the two-stage dual-task\nlearning strategy using the dataset from the national-wide, multi-institutional\nI-SPY2 clinical trial, which included dynamic contrast-enhanced magnetic\nresonance images acquired at three time points: pretreatment (T0), after 3\nweeks (T1), and after 12 weeks of treatment (T2). First, we trained a\nconvolutional long short-term memory network to predict pCR and extract the\nlatent space image features at T2. At the second stage, we trained a dual-task\nnetwork to simultaneously predict pCR and the image features at T2 using images\nfrom T0 and T1. This allowed us to predict pCR earlier without using images\nfrom T2. Results: The conventional single-stage single-task strategy gave an\narea under the receiver operating characteristic curve (AUROC) of 0.799 for pCR\nprediction using all the data at time points T0 and T1. By using the proposed\ntwo-stage dual-task learning strategy, the AUROC was improved to 0.820.\nConclusions: The proposed two-stage dual-task learning strategy can improve\nmodel performance significantly (p=0.0025) for predicting pCR at the early\nstage (3rd week) of neoadjuvant chemotherapy. The early prediction model can\npotentially help physicians to intervene early and develop personalized plans\nat the early stage of chemotherapy."
    ],
    "c_categories":[
      [
        "cs.CV",
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-161",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17217"
    ],
    "b_title":[
      "Supersymmetric Grey Galaxies, Dual Dressed Black Holes and the\n  Superconformal Index"
    ],
    "b_abstract":[
      "Motivated by the recent construction of grey galaxy and Dual Dressed Black\nHole solutions in $AdS_5\\times S^5$, we present two conjectures relating to the\nlarge $N$ entropy of supersymmetric states in ${\\cal N}=4$ Yang-Mills theory.\nOur first conjecture asserts the existence of a large number of supersymmetric\nstates which can be thought of as a non interacting mix of supersymmetric black\nholes and supersymmetric `gravitons'. It predicts a microcanonical phase\ndiagram of supersymmetric states with eleven distinct phases, and makes a sharp\nprediction for the supersymmetric entropy (as a function of 5 charges) in each\nof these phases. The microcanonical version of the superconformal index\ninvolves a sum over states - with alternating signs - over a line in 5\nparameter charge space. Our second conjecture asserts that this sum is\ndominated by the point on the line that has the largest supersymmetric entropy.\nThis conjecture predicts a large $N$ formula for the superconformal index as a\nfunction of indicial charges, and predicts a microcanonical indicial phase\ndiagram with nine distinct phases. It predicts agreement between the\nsuperconformal index and black hole entropy in one phase (so over one range of\ncharges), but disagreement in other phases (and so at other values of charges).\nWe compare our predictions against numerically evaluated superconformal index\nat $N\\leq10$, and find qualitative agreement."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11176"
    ],
    "c_title":[
      "LogiDynamics: Unraveling the Dynamics of Logical Inference in Large\n  Language Model Reasoning"
    ],
    "c_abstract":[
      "Modern large language models (LLMs) employ various forms of logical\ninference, both implicitly and explicitly, when addressing reasoning tasks.\nUnderstanding how to optimally leverage these inference paradigms is critical\nfor advancing LLMs' reasoning capabilities. This paper adopts an exploratory\napproach by introducing a controlled evaluation environment for analogical\nreasoning -- a fundamental cognitive task -- that is systematically\nparameterized across three dimensions: modality (textual, visual, symbolic),\ndifficulty (easy, medium, hard), and task format (multiple-choice or free-text\ngeneration). We analyze the comparative dynamics of inductive, abductive, and\ndeductive inference pipelines across these dimensions, and demonstrate that our\nfindings generalize to broader in-context learning tasks. Additionally, we\ninvestigate advanced paradigms such as hypothesis selection, verification, and\nrefinement, revealing their potential to scale up logical inference in LLM\nreasoning. This exploratory study provides a foundation for future research in\nenhancing LLM reasoning through systematic logical inference strategies."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-162",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11843"
    ],
    "b_title":[
      "Can LLM Agents Maintain a Persona in Discourse?"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are widely used as conversational agents,\nexploiting their capabilities in various sectors such as education, law,\nmedicine, and more. However, LLMs are often subjected to context-shifting\nbehaviour, resulting in a lack of consistent and interpretable\npersonality-aligned interactions. Adherence to psychological traits lacks\ncomprehensive analysis, especially in the case of dyadic (pairwise)\nconversations. We examine this challenge from two viewpoints, initially using\ntwo conversation agents to generate a discourse on a certain topic with an\nassigned personality from the OCEAN framework (Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism) as High\/Low for each trait. This\nis followed by using multiple judge agents to infer the original traits\nassigned to explore prediction consistency, inter-model agreement, and\nalignment with the assigned personality. Our findings indicate that while LLMs\ncan be guided toward personality-driven dialogue, their ability to maintain\npersonality traits varies significantly depending on the combination of models\nand discourse settings. These inconsistencies emphasise the challenges in\nachieving stable and interpretable personality-aligned interactions in LLMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.04587"
    ],
    "c_title":[
      "Noise sensitivity for stochastic heat and Schr\\\"odinger equation"
    ],
    "c_abstract":[
      "In this note, we consider the stochastic heat and Schr\\\"odinger equation, and\nshow that, at time $t$, the onset of the chaos occurs on the scale of $1\/t$,\nand the Fourier spectrum of the solution is asymptotically Gaussian after\ncentering and rescaling."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-163",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12289"
    ],
    "b_title":[
      "Evaluating Step-by-step Reasoning Traces: A Survey"
    ],
    "b_abstract":[
      "Step-by-step reasoning is widely used to enhance the reasoning ability of\nlarge language models (LLMs) in complex problems. Evaluating the quality of\nreasoning traces is crucial for understanding and improving LLM reasoning.\nHowever, the evaluation criteria remain highly unstandardized, leading to\nfragmented efforts in developing metrics and meta-evaluation benchmarks. To\naddress this gap, this survey provides a comprehensive overview of step-by-step\nreasoning evaluation, proposing a taxonomy of evaluation criteria with four\ntop-level categories (groundedness, validity, coherence, and utility). We then\ncategorize metrics based on their implementations, survey which metrics are\nused for assessing each criterion, and explore whether evaluator models can\ntransfer across different criteria. Finally, we identify key directions for\nfuture research."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16017"
    ],
    "c_title":[
      "On weakly amenable groupoids"
    ],
    "c_abstract":[
      "In this work, we study groupoids and their approximation properties,\ngeneralizing both the definitions and some known results for the group case.\nMore precisely, we introduce weak amenability for groupoids using the\ndefinition of the Fourier algebra given by Renault. We prove that weakly\namenable groupoids are inner exact. We also generalize its algebraic\ncounterpart, the CBAP. To do this we introduce the notion of a quasi Cartan\npair $(B,A)$ and see that $(C_r^*(G),C_0(G^0))$ can be viewed as such. We then\ndefine what it means for a pair $(B,A)$ to have the CBAP. We introduce the\nCowling-Haagerup constants associated to these approximation properties and\nprove that $\\Lambda_{\\text{cb}}(C_r^*(G),C_0(G^0)) \\leq\n\\Lambda_{\\text{cb}}(G)$. We then study some classes of groupoids where we could\nachieve equality, that is, $\\Lambda_{\\text{cb}}(G) =\n\\Lambda_{\\text{cb}}(C_r^*(G),C_0(G^0))$. They are discrete groupoids and\ngroupoids arising from partial actions of a discrete group $\\Gamma$ on a\nlocally compact Hausdorff space $X$."
    ],
    "c_categories":[
      [
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-164",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17547"
    ],
    "b_title":[
      "Learning Multi-Level Features with Matryoshka Sparse Autoencoders"
    ],
    "b_abstract":[
      "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nneural networks by extracting the concepts represented in their activations.\nHowever, choosing the size of the SAE dictionary (i.e. number of learned\nconcepts) creates a tension: as dictionary size increases to capture more\nrelevant concepts, sparsity incentivizes features to be split or absorbed into\nmore specific features, leaving high-level features missing or warped. We\nintroduce Matryoshka SAEs, a novel variant that addresses these issues by\nsimultaneously training multiple nested dictionaries of increasing size,\nforcing the smaller dictionaries to independently reconstruct the inputs\nwithout using the larger dictionaries. This organizes features hierarchically -\nthe smaller dictionaries learn general concepts, while the larger dictionaries\nlearn more specific concepts, without incentive to absorb the high-level\nfeatures. We train Matryoshka SAEs on Gemma-2-2B and TinyStories and find\nsuperior performance on sparse probing and targeted concept erasure tasks, more\ndisentangled concept representations, and reduced feature absorption. While\nthere is a minor tradeoff with reconstruction performance, we believe\nMatryoshka SAEs are a superior alternative for practical tasks, as they enable\ntraining arbitrarily large SAEs while retaining interpretable features at\ndifferent levels of abstraction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03344"
    ],
    "c_title":[
      "Ferrers bar response models: a grid calculation for Galactic models"
    ],
    "c_abstract":[
      "This study numerically investigates the dynamics of barred spiral galaxies\nusing 3D Ferrers bar response models. A total of 708 models were analyzed,\nincorporating variations in the axisymmetric potential (nucleus, bulge, disk,\nhalo), bar length, mass, angular velocity, and disk stellar velocity\ndispersion. Model evaluation employed the Spearman correlation (to assess\ninput-output relationships) and permutation feature importance in a Random\nForest Regressor (to measure input variable impacts). Orbital configurations of\ntest particles reveal the critical role of bar dynamics in shaping galaxies'\nmorphological and kinematic properties. Key findings emphasize how bar\npotential influences major orbital families, affecting barred galaxies'\nlong-term structure. These results provide deeper insights into galactic\ncomponent interactions and a robust framework for understanding bar properties."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-165",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15959"
    ],
    "b_title":[
      "A Knowledge Distillation-Based Approach to Enhance Transparency of\n  Classifier Models"
    ],
    "b_abstract":[
      "With the rapid development of artificial intelligence (AI), especially in the\nmedical field, the need for its explainability has grown. In medical image\nanalysis, a high degree of transparency and model interpretability can help\nclinicians better understand and trust the decision-making process of AI\nmodels. In this study, we propose a Knowledge Distillation (KD)-based approach\nthat aims to enhance the transparency of the AI model in medical image\nanalysis. The initial step is to use traditional CNN to obtain a teacher model\nand then use KD to simplify the CNN architecture, retain most of the features\nof the data set, and reduce the number of network layers. It also uses the\nfeature map of the student model to perform hierarchical analysis to identify\nkey features and decision-making processes. This leads to intuitive visual\nexplanations. We selected three public medical data sets (brain tumor, eye\ndisease, and Alzheimer's disease) to test our method. It shows that even when\nthe number of layers is reduced, our model provides a remarkable result in the\ntest set and reduces the time required for the interpretability analysis."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10257"
    ],
    "c_title":[
      "Orthogonal projections of hypercubes"
    ],
    "c_abstract":[
      "Projections of hypercubes have been applied to visualize high-dimensional\nbinary state spaces in various scientific fields. Conventional methods for\nprojecting hypercubes, however, face practical difficulties. Manual methods\nrequire nontrivial adjustments of the projection basis, while\noptimization-based algorithms limit the interpretability and reproducibility of\nthe resulting plots. These limitations motivate us to explore theoretically\nanalyzable projection algorithms such as principal component analysis (PCA).\nHere, we investigate the mathematical properties of PCA-projected hypercubes.\nOur numerical and analytical results show that PCA effectively captures\npolarized distributions within the hypercubic state space. This property\nenables the assessment of the asymptotic distribution of projected vertices and\nerror bounds, which characterize the performance of PCA in the projected space.\nWe demonstrate the application of PCA to visualize the hypercubic energy\nlandscapes of Ising spin systems. By adding projected hypercubic edges, these\nvisualizations reveal pathways of correlated spin flips. Our work provides a\nbetter understanding of how PCA discovers hidden patterns in high-dimensional\nbinary data."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-166",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11951"
    ],
    "b_title":[
      "Qubit-Based Framework for Quantum Machine Learning: Bridging Classical\n  Data and Quantum Algorithms"
    ],
    "b_abstract":[
      "This paper dives into the exciting and rapidly growing field of quantum\ncomputing, explaining its core ideas, current progress, and how it could\nrevolutionize the way we solve complex problems. It starts by breaking down the\nbasics, like qubits, quantum circuits, and how principles like superposition\nand entanglement make quantum computers fundamentally different-and far more\npowerful for certain tasks-than the classical computers we use today. We also\nexplore how quantum computing deals with complex problems and why it is\nuniquely suited for challenges classical systems struggle to handle. A big part\nof this paper focuses on Quantum Machine Learning (QML), where the strengths of\nquantum computing meet the world of artificial intelligence. By processing\nmassive datasets and optimizing intricate algorithms, quantum systems offer new\npossibilities for machine learning. We highlight different approaches to\ncombining quantum and classical computing, showing how they can work together\nto produce faster and more accurate results. Additionally, we explore the tools\nand platforms available-like TensorFlow Quantum, Qiskit and PennyLane-that are\nhelping researchers and developers bring these theories to life. Of course,\nquantum computing has its hurdles. Challenges like scaling up hardware,\ncorrecting errors, and keeping qubits stable are significant roadblocks. Yet,\nwith rapid advancements in cloud-based platforms and innovative technologies,\nthe potential of quantum computing feels closer than ever. This paper aims to\noffer readers a clear and comprehensive introduction to quantum computing, its\nrole in machine learning, and the immense possibilities it holds for the future\nof technology."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07831"
    ],
    "c_title":[
      "Directional Locking and Hysteresis in Stripe and Bubble Forming Systems\n  on One-Dimensional Periodic Substrates with a Rotating Drive"
    ],
    "c_abstract":[
      "We examine the dynamics of a two-dimensional stripe, bubble, and crystal\nforming system interacting with a periodic one-dimensional substrate under an\napplied drive that is rotated with respect to the substrate periodicity\ndirection $x$. We find that the stripes remain strongly directionally locked to\nthe $x$ direction for an extended range of drives before undergoing motion\nparallel to the drive. In some cases, the stripes break apart at the unlocking\ntransition, but can dynamically reform into stripes aligned perpendicular to\nthe $x$ direction, producing hysteresis in the directional locking and\nunlocking transitions. In contrast, moving anisotropic crystal and bubble\nphases exhibit weaker directional locking and reduced or no hysteresis. The\nhysteresis occurs in regimes where the particle rearrangements occur and is\nmost pronounced near the stripe phase. We also show that for varied substrate\nstrength, substrate spacing, and particle density, a number of novel dynamical\npatterns can form that include a combination of stripe, bubble, and crystal\nmorphologies."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-167",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19693"
    ],
    "b_title":[
      "Accurate and Scalable Graph Neural Networks via Message Invariance"
    ],
    "b_abstract":[
      "Message passing-based graph neural networks (GNNs) have achieved great\nsuccess in many real-world applications. For a sampled mini-batch of target\nnodes, the message passing process is divided into two parts: message passing\nbetween nodes within the batch (MP-IB) and message passing from nodes outside\nthe batch to those within it (MP-OB). However, MP-OB recursively relies on\nhigher-order out-of-batch neighbors, leading to an exponentially growing\ncomputational cost with respect to the number of layers. Due to the neighbor\nexplosion, the whole message passing stores most nodes and edges on the GPU\nsuch that many GNNs are infeasible to large-scale graphs. To address this\nchallenge, we propose an accurate and fast mini-batch approach for large graph\ntransductive learning, namely topological compensation (TOP), which obtains the\noutputs of the whole message passing solely through MP-IB, without the costly\nMP-OB. The major pillar of TOP is a novel concept of message invariance, which\ndefines message-invariant transformations to convert costly MP-OB into fast\nMP-IB. This ensures that the modified MP-IB has the same output as the whole\nmessage passing. Experiments demonstrate that TOP is significantly faster than\nexisting mini-batch methods by order of magnitude on vast graphs (millions of\nnodes and billions of edges) with limited accuracy degradation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03937"
    ],
    "c_title":[
      "A universal scaling of condensation temperature in quantum fluids"
    ],
    "c_abstract":[
      "The phenomena of superconductivity and superfluidity are believed to\noriginate from the same underlying physics, namely the condensation of either\nbosons or pairs of fermions (Cooper pairs). In this work I complied and\nanalyzed literature data for a number of quantum fluids and showed that indeed\nthey all follow the same simple scaling law. The critical temperature for\ncondensation T$_c$ is found to scale with the condensate coherence length $\\xi$\nand the effective mass of condensing particles m$^{\\ast}$. The scaling plot\nincludes members of most known classes of superconductors, as well as a number\nof superfluids and condensates, such as $^3$He, $^4$He, dilute Bose and Fermi\ngases, excitons, polaritons, neutron superfluid and proton superconductor in\nneutron stars, nuclear pairing, quark--antiquark condensate and Higgs\ncondensate. The scaling plot spans more that 24 orders of magnitude of critical\ntemperatures, albeit the scaling exponent is not the one predicted by theory.\nThe plot might help the search for a dark matter particle."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.supr-con",
        "gr-qc",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-168",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15654"
    ],
    "b_title":[
      "Machine-generated text detection prevents language model collapse"
    ],
    "b_abstract":[
      "As Large Language Models (LLMs) become increasingly prevalent, their\ngenerated outputs are proliferating across the web, risking a future where\nmachine-generated content dilutes human-authored text. Since online data is the\nprimary resource for LLM pre-training, subsequent models could be trained on an\nunknown portion of synthetic samples. This will lead to model collapse, a\ndegenerative process whereby LLMs reinforce their own errors, and ultimately\nyield a declining performance. In this study, we investigate the impact of\ndecoding strategy on model collapse, analysing the characteristics of text at\neach model generation, the similarity to human references, and the resulting\nmodel performance. Using the decoding strategies that lead to the most\nsignificant degradation, we evaluate model collapse in more realistic scenarios\nwhere the origin of the data (human or synthetic) is unknown. We train a\nmachine-generated text detector and propose an importance sampling approach to\nalleviate model collapse. Our method is validated on two LLM variants (GPT-2\nand SmolLM2) on the open-ended text generation task. We demonstrate that it can\nnot only prevent model collapse but also improve performance when sufficient\nhuman-authored samples are present."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00016"
    ],
    "c_title":[
      "Time-Irreversible Quantum-Classical Dynamics of Molecular Models in the\n  Brain"
    ],
    "c_abstract":[
      "This manuscript aims to illustrate a quantum-classical dissipative theory\n(suited to be converted to effective algorithms for numerical simulations)\nwithin the long-term project of studying molecular processes in the brain.\nOther approaches, briefly sketched in the text, have advocated the need to deal\nwith both quantum and classical dynamic variables when studying the brain. At\nvariance with these other frameworks, the manuscript's formalism allows us to\nexplicitly treat the classical dynamical variables. The theory must be\ndissipative not because of formal requirements but because brain processes\nappear to be dissipative at the molecular, physiological, and high functional\nlevels. We discuss theoretically that using Brownian dynamics or the\nNos\\`e-Hoover-Chain thermostat to perform computer simulations provides an\neffective way to introduce an arrow of time for open quantum systems in a\nclassical environment. In the future, We plan to study classical models of\nneurons and astrocytes, as well as their networks, coupled to quantum dynamical\nvariables describing, e.g., nuclear and electron spins, HOMO and LUMO orbitals\nof phenyl and indole rings, ion channels, and tunneling protons."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.other",
        "physics.bio-ph",
        "q-bio.NC",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-169",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16494"
    ],
    "b_title":[
      "The impact of artificial intelligence: from cognitive costs to global\n  inequality"
    ],
    "b_abstract":[
      "In this paper, we examine the wide-ranging impact of artificial intelligence\non society, focusing on its potential to both help and harm global equity,\ncognitive abilities, and economic stability. We argue that while artificial\nintelligence offers significant opportunities for progress in areas like\nhealthcare, education, and scientific research, its rapid growth -- mainly\ndriven by private companies -- may worsen global inequalities, increase\ndependence on automated systems for cognitive tasks, and disrupt established\neconomic paradigms. We emphasize the critical need for strong governance and\nethical guidelines to tackle these issues, urging the academic community to\nactively participate in creating policies that ensure the benefits of\nartificial intelligence are shared fairly and its risks are managed\neffectively."
    ],
    "b_categories":[
      [
        "cs.CY",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05932"
    ],
    "c_title":[
      "Small symplectic $4$-manifolds via contact gluing and some applications"
    ],
    "c_abstract":[
      "In this paper, we introduce a streamlined procedure for constructing small\nsymplectic 4-manifolds via contact gluing, based on a technique invented by\nDavid Gay around 2000. We also give a few applications, ranging from embeddings\nof singular Lagrangian RP^2s to realizing an infinite family of lens spaces as\nhypersurfaces of contact type in a symplectic Hirzebruch surface. Furthermore,\nour investigation on S^1-invariant contact structures also suggests there\nshould be a universal upper bound for the self-intersection of a rational\nunicuspidal curve with one Puiseux pair in any algebraic surface (the bound\ndepends only on the singularity)."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.GT",
        "math.SG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-170",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03123"
    ],
    "b_title":[
      "Disentanglement in Difference: Directly Learning Semantically\n  Disentangled Representations by Maximizing Inter-Factor Differences"
    ],
    "b_abstract":[
      "In this study, Disentanglement in Difference(DiD) is proposed to address the\ninherent inconsistency between the statistical independence of latent variables\nand the goal of semantic disentanglement in disentanglement representation\nlearning. Conventional disentanglement methods achieve disentanglement\nrepresentation by improving statistical independence among latent variables.\nHowever, the statistical independence of latent variables does not necessarily\nimply that they are semantically unrelated, thus, improving statistical\nindependence does not always enhance disentanglement performance. To address\nthe above issue, DiD is proposed to directly learn semantic differences rather\nthan the statistical independence of latent variables. In the DiD, a Difference\nEncoder is designed to measure the semantic differences; a contrastive loss\nfunction is established to facilitate inter-dimensional comparison. Both of\nthem allow the model to directly differentiate and disentangle distinct\nsemantic factors, thereby resolving the inconsistency between statistical\nindependence and semantic disentanglement. Experimental results on the dSprites\nand 3DShapes datasets demonstrate that the proposed DiD outperforms existing\nmainstream methods across various disentanglement metrics."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10338"
    ],
    "c_title":[
      "The quantum non-Markovianity for a special class of generalized Weyl\n  channel"
    ],
    "c_abstract":[
      "A quantum channel is usually represented as a sum of Kraus operators. The\nrecent study [Phys. Rev. A 98, 032328 (2018)] has shown that applying a\nperturbation to the Kraus operators in qubit Pauli channels, the dynamical maps\nexhibit interesting properties, such as non-Markovianity, singularity. This has\nsparked our interest in studying the properties of other quantum channels. In\nthis work, we study a special class of generalized Weyl channel where the Kraus\noperators are proportional to the Weyl diagonal matrices and the rest are\nvanishing. We use the Choi matrix of intermediate map to study quantum\nnon-Markovianity. The crossover point of the eigenvalues of Choi matrix is a\nsingularity of the decoherence rates in the canonical form of the master\nequation. Moreover, we identify the non-Markovianity based on the methods of CP\ndivisibility and distinguishability. We also quantify the non-Markovianity in\nterms of the Hall-Cresser-Li-Andersson (HCLA) measure and the\nBreuer-Laine-Piilo (BLP) measure, respectively. In particular, we choose\nmutually unbiased bases as a pair of orthogonal initial states to quantify the\nnon-Markovianity based on the BLP measure."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-171",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10337"
    ],
    "b_title":[
      "Bifurcation of global energy minimizers for a diffusion-aggregation\n  model on sphere"
    ],
    "b_abstract":[
      "We consider a free energy functional defined on probability densities on the\nunit sphere $\\mathbb{S}^d$, and investigate its global minimizers. The energy\nconsists of two components: an entropy and a nonlocal interaction energy, which\nfavour spreading and aggregation behaviour, respectively. We find a threshold\nvalue for the size of the attractive interactions, and establish the global\nenergy minimizers in each case. The bifurcation at this threshold value is\ninvestigated. We also generalize the results to spaces consisting of an\narbitrary number of spheres (e.g., the flat torus $\\mathbb{S}^1 \\times\n\\mathbb{S}^1$)."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.09181"
    ],
    "c_title":[
      "Dynamic Feature Selection from Variable Feature Sets Using Features of\n  Features"
    ],
    "c_abstract":[
      "Machine learning models usually assume that a set of feature values used to\nobtain an output is fixed in advance. However, in many real-world problems, a\ncost is associated with measuring these features. To address the issue of\nreducing measurement costs, various methods have been proposed to dynamically\nselect which features to measure, but existing methods assume that the set of\nmeasurable features remains constant, which makes them unsuitable for cases\nwhere the set of measurable features varies from instance to instance. To\novercome this limitation, we define a new problem setting for Dynamic Feature\nSelection (DFS) with variable feature sets and propose a deep learning method\nthat utilizes prior information about each feature, referred to as ''features\nof features''. Experimental results on several datasets demonstrate that the\nproposed method effectively selects features based on the prior information,\neven when the set of measurable features changes from instance to instance."
    ],
    "c_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-172",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02958"
    ],
    "b_title":[
      "Position: Editing Large Language Models Poses Serious Safety Risks"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) contain large amounts of facts about the world.\nThese facts can become outdated over time, which has led to the development of\nknowledge editing methods (KEs) that can change specific facts in LLMs with\nlimited side effects. This position paper argues that editing LLMs poses\nserious safety risks that have been largely overlooked. First, we note the fact\nthat KEs are widely available, computationally inexpensive, highly performant,\nand stealthy makes them an attractive tool for malicious actors. Second, we\ndiscuss malicious use cases of KEs, showing how KEs can be easily adapted for a\nvariety of malicious purposes. Third, we highlight vulnerabilities in the AI\necosystem that allow unrestricted uploading and downloading of updated models\nwithout verification. Fourth, we argue that a lack of social and institutional\nawareness exacerbates this risk, and discuss the implications for different\nstakeholders. We call on the community to (i) research tamper-resistant models\nand countermeasures against malicious model editing, and (ii) actively engage\nin securing the AI ecosystem."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16053"
    ],
    "c_title":[
      "Hierarchical Recording Architecture for Three-Dimensional Magnetic\n  Recording"
    ],
    "c_abstract":[
      "Three-dimensional magnetic recording (3DMR) is a highly promising approach to\nachieving ultra-large data storage capacity in hard disk drives. One of the\ngreatest challenges for 3DMR lies in performing sequential and correct writing\nof bits into the multi-layer recording medium. In this work, we have proposed a\nhierarchical recording architecture based on layered heat-assisted writing with\na multi-head array. The feasibility of the architecture is validated in a\ndual-layer 3DMR system with FePt-based thin films via micromagnetic simulation.\nOur results reveal the magnetization reversal mechanism of the grains,\nultimately attaining appreciable switching probability and medium\nsignal-to-noise ratio (SNR) for each layer. In particular, an optimal\nhead-to-head distance is identified as the one that maximizes the medium SNR.\nOptimizing the system's noise resistance will improve the overall SNR and allow\nfor a smaller optimal head-to-head distance, which can pave the way for scaling\n3DMR to more recording layers."
    ],
    "c_categories":[
      [
        "cs.AR",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-173",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17498"
    ],
    "b_title":[
      "Improving Value-based Process Verifier via Structural Prior Injection"
    ],
    "b_abstract":[
      "In the Large Language Model(LLM) reasoning scenario, people often estimate\nstate value via Monte Carlo sampling. Though Monte Carlo estimation is an\nelegant method with less inductive bias, noise and errors are inevitably\nintroduced due to the limited sampling. To handle the problem, we inject the\nstructural prior into the value representation and transfer the scalar value\ninto the expectation of a pre-defined categorical distribution, representing\nthe noise and errors from a distribution perspective. Specifically, by treating\nthe result of Monte Carlo sampling as a single sample from the prior\nground-truth Binomial distribution, we quantify the sampling error as the\nmismatch between posterior estimated distribution and ground-truth\ndistribution, which is thus optimized via distribution selection optimization.\nWe test the performance of value-based process verifiers on Best-of-N task and\nBeam search task. Compared with the scalar value representation, we show that\nreasonable structural prior injection induced by different objective functions\nor optimization methods can improve the performance of value-based process\nverifiers for about 1$\\sim$2 points at little-to-no cost. We also show that\nunder different structural prior, the verifiers' performances vary greatly\ndespite having the same optimal solution, indicating the importance of\nreasonable structural prior injection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05866"
    ],
    "c_title":[
      "Spin alignment of quarkonia in vortical quark-gluon plasma"
    ],
    "c_abstract":[
      "The spin alignment of $J\/\\psi$ with respect to event plane in relativistic\nheavy ion collisions exhibits a significant signal. We propose a possible\nmechanism for spin alignment through spin dependent dissociation of quarkonia\nin a vortical quark-gluon plasma. The spin dependent dissociation is realized\nthrough inelastic scattering between constituents of quarkonium and those of\nquark-gluon plasma polarized by the vorticity. The spin dependent dissociation\nrate is found to depend on the directions of vorticity, quantization axis, and\nquark momentum. We implement our results in a dissociation dominated evolution\nmodel for quarkonia in the Bjorken flow, finding the spin $0$ state is slightly\nsuppressed compared to the average of the other two, which is consistent with\nthe sign found in experiments. We also find absence of logarithmic enhancement\nin binding energy in the vortical correction to dissociation rate, which is\nunderstood from the requirement that a spin dependent dissociation can only\ncome from quark coupling to a pair of chromomagnetic and chromoelectric field."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-174",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08401"
    ],
    "b_title":[
      "Mean resolvent analysis of periodic flows"
    ],
    "b_abstract":[
      "The mean resolvent operator predicts, in the frequency domain, the mean\nlinear response to forcing, and, as such, it provides the optimal LTI\napproximation of the input-output dynamics of flows in the statistically steady\nregime (Leclercq & Sipp 2023). In this paper, we aim at providing numerical\nframeworks to extract optimal forcings and responses of the mean resolvent,\nalso known as mean resolvent modes. For periodic flows, we rewrite the mean\nresolvent operator in terms of a harmonic resolvent operator (Wereley & Hall\n1990; Padovan & Rowley 2022) to obtain reference mean resolvent modes.\nSuccessively, we propose a projection algorithm approximating those modes\nwithin a subspace of mean-flow resolvent modes. The projected problem is\ndirectly solved in the frequency domain, but we also discuss a time-stepper\nversion that can bypass the explicit construction of the operator without\nrecurring to direct-adjoint looping. We evaluate the algorithms on an\nincompressible axisymmetric laminar jet periodically forced at the inlet. For a\nweakly unsteady case, the mean-flow resolvent correctly approximates the main\nreceptivity peak of the mean resolvent, but completely fails to capture a\nsecondary receptivity peak. For a strongly unsteady case, even the main\nreceptivity peak of the mean resolvent is incorrectly captured by the mean-flow\nresolvent. Although the present algorithms are currently restricted to periodic\nflows, input projection may be a key ingredient to extend mean resolvent\nanalysis to more complex statistically steady flows."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.02165"
    ],
    "c_title":[
      "Optimal Broadcast on Congested Random Graphs"
    ],
    "c_abstract":[
      "We study the problem of broadcasting multiple messages in the CONGEST model.\nIn this problem, a dedicated node $s$ possesses a set $M$ of messages with\nevery message being of the size $O(\\log n)$ where $n$ is the total number of\nnodes. The objective is to ensure that every node in the network learns all\nmessages in $M$. The execution of an algorithm progresses in rounds and we\nfocus on optimizing the round complexity of broadcasting multiple messages.\n  Our primary contribution is a randomized algorithm designed for networks\nmodeled as random graphs. The algorithm succeeds with high probability and\nachieves round complexity that is optimal up to a polylogarithmic factor. It\nleverages a multi-COBRA primitive, which uses multiple branching random walks\nrunning in parallel. To the best of our knowledge, this approach has not been\napplied in distributed algorithms before. A crucial aspect of our method is the\nuse of these branching random walks to construct an optimal (up to a\npolylogarithmic factor) tree packing of a random graph, which is then used for\nefficient broadcasting. This result is of independent interest.\n  We also prove the problem to be NP-hard in a centralized setting and provide\ninsights into why straightforward lower bounds, namely graph diameter and\n$\\frac{|M|}{minCut}$, can not be tight."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-175",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20594"
    ],
    "b_title":[
      "Kinematical Modeling of the Resolved Stellar Outskirts of M32:\n  Constraints on Tidal Stripping Scenarios"
    ],
    "b_abstract":[
      "As the only compact elliptical close enough to resolve into individual stars,\nthe satellite dwarf galaxy M32 provides a unique opportunity for exploring the\norigins of such rare galaxies. In this work, we combined archival and novel\nKeck\/DEIMOS spectroscopy from a southern extension of the Spectroscopic and\nPhotometric Landscape of Andromeda's Stellar Halo (SPLASH) survey with optical\nHST imaging from the Panchromatic Hubble Andromeda Southern Treasury (PHAST)\nsurvey. The resulting sample of 2525 giant stars is unprecedented both in size\nand spatial coverage (0.9-15.5 arcmin, or out to $\\sim$23$r_{\\rm eff}$ and\n$\\sim$30$r_{\\rm eff}$ along M32's major and minor axes) for probing the\nresolved stellar outskirts of M32. Given the structurally complex region near\nM32 on the sky, we modeled M32's line-of-sight kinematics simultaneously\nalongside M31's rotating stellar disk and potential outliers corresponding to\nM31's kinematically hot stellar halo and\/or tidal substructure. Inside the\nradius corresponding to the observed twisting of isophotal contours in M32's\nsurface brightness profile ($R_{\\rm iso} \\sim$ 5$r_{\\rm eff}$ $\\sim$ 150'' or\n0.56 kpc), M32 exhibits a line-of-sight velocity distribution characteristic of\nordered rotation, transitioning to a distribution with heavier outliers beyond\nthis radius. Within $R_{\\rm iso}$, the rotational direction is aligned with\nM32's major-axis rotation, but shifts to become roughly aligned with M32's\nminor axis beyond $R_{\\rm iso}$. We interpret these kinematical signatures in\nthe stellar outskirts of M32 as evidence of tidal distortion from interactions\nwith M31 and discuss their implications for M32 formation pathways."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.14116"
    ],
    "c_title":[
      "Domain-Factored Untrained Deep Prior for Spectrum Cartography"
    ],
    "c_abstract":[
      "Spectrum cartography (SC) focuses on estimating the radio power propagation\nmap of multiple emitters across space and frequency using limited sensor\nmeasurements. Recent advances in SC have shown that leveraging learned deep\ngenerative models (DGMs) as structural constraints yields state-of-the-art\nperformance. By harnessing the expressive power of neural networks, these\nstructural \"priors\" capture intricate patterns in radio maps. However, training\nDGMs requires substantial data, which is not always available, and distribution\nshifts between training and testing data can further degrade performance. To\naddress these challenges, this work proposes using untrained neural networks\n(UNNs) for SC. UNNs, commonly applied in vision tasks to represent complex data\nwithout training, encode structural information of data in neural\narchitectures. In our approach, a custom-designed UNN represents radio maps\nunder a spatio-spectral domain factorization model, leveraging physical\ncharacteristics to reduce sample complexity of SC. Experiments show that the\nmethod achieves performance comparable to learned DGM-based SC, without\nrequiring training data."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-176",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08106"
    ],
    "b_title":[
      "Photodetachment of negative hydrogen ion beam"
    ],
    "b_abstract":[
      "The method of H- photoionization is interesting for laser assisted charge\nexchange injection. In this paper, the model and computation of photoionization\nof negative hydrogen ion by using strong lasers is considered. The development\nof this work is motivated by using pure lasers for photodetachment of electron\nfrom negative hydrogen ion when it is not convenient or not possible to use\nstripping magnet. Herein we develop a method of calculation of high efficiency\nphotoionization using time dependent wave equation with application of powerful\nlasers. We compare this precise method of calculation with simplified method of\ncalculation through linear model of cross section interaction. Another\nmechanism of photodetachment through excitation of the Feshbach resonance is\nalso considered."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05494"
    ],
    "c_title":[
      "Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection"
    ],
    "c_abstract":[
      "Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing\ncardiovascular conditions, yet anomaly detection in ECG signals remains\nchallenging due to their inherent complexity and variability. We propose\nMulti-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel\nend-to-end framework that effectively captures both global and local\ndependencies in ECG data. Unlike state-of-the-art methods that rely on\nheartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for\nsuch pre-processing steps, enhancing its suitability for clinical deployment.\nMMAE-ECG partitions ECG signals into non-overlapping segments, with each\nsegment assigned learnable positional embeddings. A novel multi-scale masking\nstrategy and multi-scale attention mechanism, along with distinct positional\nembeddings, enable a lightweight Transformer encoder to effectively capture\nboth local and global dependencies. The masked segments are then reconstructed\nusing a single-layer Transformer block, with an aggregation strategy employed\nduring inference to refine the outputs. Experimental results demonstrate that\nour method achieves performance comparable to state-of-the-art approaches while\nsignificantly reducing computational complexity-approximately 1\/78 of the\nfloating-point operations (FLOPs) required for inference. Ablation studies\nfurther validate the effectiveness of each component, highlighting the\npotential of multi-scale masked autoencoders for anomaly detection."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-177",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08085"
    ],
    "b_title":[
      "Interactive Holographic Visualization for 3D Facial Avatar"
    ],
    "b_abstract":[
      "Traditional methods for visualizing dynamic human expressions, particularly\nin medical training, often rely on flat-screen displays or static mannequins,\nwhich have proven inefficient for realistic simulation. In response, we propose\na platform that leverages a 3D interactive facial avatar capable of displaying\nnon-verbal feedback, including pain signals. This avatar is projected onto a\nstereoscopic, view-dependent 3D display, offering a more immersive and\nrealistic simulated patient experience for pain assessment practice. However,\nthere is no existing solution that dynamically predicts and projects\ninteractive 3D facial avatars in real-time. To overcome this, we emphasize the\nneed for a 3D display projection system that can project the facial avatar\nholographically, allowing users to interact with the avatar from any viewpoint.\nBy incorporating 3D Gaussian Splatting (3DGS) and real-time view-dependent\ncalibration, we significantly improve the training environment for accurate\npain recognition and assessment."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12980"
    ],
    "c_title":[
      "Quantitative, Data-driven Network Model for Global Cascading Financial\n  Failure"
    ],
    "c_abstract":[
      "Global catastrophic risk events, such as nuclear war, pose a severe threat to\nthe stability of international financial systems. As evidenced by even less\nsevere scenarios like the Great Recession, an economic failure can propagate\nthrough the world trade network, wreaking havoc on the global economy. While\nthe contemporary literature on cascading failure models addresses this issue\nqualitatively, a simple and intuitive quantitative estimation that could be\nused in integrated assessment frameworks is missing. In this study, we\nintroduce a quantitative network model of global financial cascading failure.\nOur proposal is a fast, efficient, single free parameter model, following a\nstraightforward logic of propagating failures. We fit the model to the Great\nRecession and test it against historical examples and commercial analysis. We\nalso provide predictions for a hypothetical armed conflict between India and\nPakistan. Our aim is to introduce a quantitative approach that could inform\npolicy decisions by contextualising global catastrophic scenarios regarding\nfinancial losses and assessing the effectiveness of resilience strategies,\ncomplementing existing models and frameworks for broader risk assessment."
    ],
    "c_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-178",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14509"
    ],
    "b_title":[
      "MultiSlav: Using Cross-Lingual Knowledge Transfer to Combat the Curse of\n  Multilinguality"
    ],
    "b_abstract":[
      "Does multilingual Neural Machine Translation (NMT) lead to The Curse of the\nMultlinguality or provides the Cross-lingual Knowledge Transfer within a\nlanguage family? In this study, we explore multiple approaches for extending\nthe available data-regime in NMT and we prove cross-lingual benefits even in\n0-shot translation regime for low-resource languages. With this paper, we\nprovide state-of-the-art open-source NMT models for translating between\nselected Slavic languages. We released our models on the HuggingFace Hub\n(https:\/\/hf.co\/collections\/allegro\/multislav-6793d6b6419e5963e759a683) under\nthe CC BY 4.0 license. Slavic language family comprises morphologically rich\nCentral and Eastern European languages. Although counting hundreds of millions\nof native speakers, Slavic Neural Machine Translation is under-studied in our\nopinion. Recently, most NMT research focuses either on: high-resource languages\nlike English, Spanish, and German - in WMT23 General Translation Task 7 out of\n8 task directions are from or to English; massively multilingual models\ncovering multiple language groups; or evaluation techniques."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11235"
    ],
    "c_title":[
      "Ergodic exploration of dynamic distribution"
    ],
    "c_abstract":[
      "This research addresses the challenge of performing search missions in\ndynamic environments, particularly for drifting targets whose movement is\ndictated by a flow field. This is accomplished through a dynamical system that\nintegrates two partial differential equations: one governing the dynamics and\nuncertainty of the probability distribution, and the other regulating the\npotential field for ergodic multi-agent search. The target probability field\nevolves in response to the target dynamics imposed by the environment and\naccomplished sensing efforts, while being explored by multiple robot agents\nguided by the potential field gradient. The proposed methodology was tested on\ntwo simulated search scenarios, one of which features a synthetically generated\ndomain and showcases better performance when compared to the baseline method\nwith static target probability over a range of agent to flow field velocity\nratios. The second search scenario represents a realistic sea search and rescue\nmission where the search start is delayed, the search is performed in multiple\nrobot flight missions, and the procedure for target drift uncertainty\ncompensation is demonstrated. Furthermore, the proposed method provides an\naccurate survey completion metric, based on the known detection\/sensing\nparameters, that correlates with the actual number of targets found\nindependently."
    ],
    "c_categories":[
      [
        "cs.RO",
        "math.DS",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-179",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17875"
    ],
    "b_title":[
      "5G Direct Position Estimation for Precise Localization in Dense Urban\n  Area"
    ],
    "b_abstract":[
      "In recent years, the fifth-generation (5G) new radio (NR) signals have\nemerged as a promising supplementary resource for urban navigation. However, a\nmajor challenge in utilizing 5G signals lies in their vulnerability to\nnon-line-of-sight (NLoS) propagation effects, which are especially prevalent in\nurban street canyons. This paper applies the direct position estimation (DPE)\nmethod to 5G cellular signals to mitigate the NLoS bias as well as the\nmultipath effects, thereby enabling precise localization in urbanized\nenvironments. The feasibility of applying the DPE method to NR positioning is\nanalyzed, followed by a discussion of the tapped delay line (TDL) channel\npropagation model provided by the 3rd Generation Partnership Project (3GPP).\nThe positioning performance is then evaluated through large-scale system-level\nsimulations. The simulation results demonstrate that 5G DPE achieves\nsatisfactory positioning accuracy in a 10 dB noisy channel, with an overall\nroot mean square error (RMSE) constrained within 6 m. In addition, 5G DPE\noutperforms the observed time difference of arrival (OTDoA) method by 95.24% in\nterms of positioning accuracy in an NLoS-dominated propagation environment."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15217"
    ],
    "c_title":[
      "Radio Science Investigations for the Heavy Metal Mission to Asteroid\n  (216) Kleopatra"
    ],
    "c_abstract":[
      "This work presents the simulation results of the radio science experiment\nonboard the proposed Heavy Metal mission to the M-type asteroid (216)\nKleopatra. Earth-based radiometric measurements (range and range-rate),\ncomplemented by images from the onboard optical camera and by measurements from\nthe inter-satellite link between the maincraft and a secondary subcraft, are\nused in an orbit determination process to assess the attainable accuracy for\nthe mass of Kleopatra and its extended gravity field. Preliminary results\nindicate that the asteroid mass can be retrieved with a relative accuracy up to\n$10^{-7}$, while the extended gravity field can be estimated up to degree 10\nwith sufficient accuracy to discriminate between internal structure models,\nsatisfying the scientific goals of the mission."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-180",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13101"
    ],
    "b_title":[
      "AI and the Transformation of Accountability and Discretion in Urban\n  Governance"
    ],
    "b_abstract":[
      "The integration of Artificial Intelligence (AI) in urban governance presents\nsignificant opportunities to transform decision-making and enhance\naccountability. The paper highlights AI's potential to reposition human\ndiscretion and reshape specific types of accountability, elevating the\ndecision-making capabilities of both frontline bureaucrats and managers while\nensuring ethical standards and public trust are maintained. While AI can\nenhance bureaucratic flexibility and efficiency, its integration will also\nnecessitate new governance frameworks to mitigate risks associated with uneven\ncapacity distribution, ethical concerns, and public trust. Following the\nliterature review and theoretical discussion, this study introduces a set of\nguiding principles for AI-assisted urban governance, emphasizing equitable AI\ndeployment, adaptive administrative structures, robust data governance,\ntransparent human-AI collaboration, and citizen engagement in oversight\nmechanisms. By critically evaluating AI's dual role in expanding discretion and\nreinforcing accountability, this paper advances a framework for responsible AI\nadoption, ensuring that urban governance remains adaptive, transparent, and\naligned with public values."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02124"
    ],
    "c_title":[
      "Semiconductor Laser with Electrically Modulated Frequency"
    ],
    "c_abstract":[
      "We propose a novel method to control the frequency of semiconductor lasers.\nThe new technique allows fabricating three-terminal lasers with fast frequency\ntuning and the possibility to implement intrinsically the linearization of\nlaser frequency sweep. The electrical contact located between the lower undoped\ncladding and the waveguide together with the upper laser contact enable pumping\nfor optical gain. A voltage applied between the same contact and the contact\nlocated under the lower cladding induces space charge limited current (SCLC)\nacross the lower cladding. Electrons driven into this layer create the space\ncharge. The charge affects the refractive index of the layer and\ncorrespondingly the laser frequency. The proposed technique is applicable to\nany semiconductor lasers. Critical requirements are that free carrier\nconcentration in the lower cladding must be small enough not to affect the SCLC\nand the laser gain must be high enough to overcome losses introduced by\ninteractivity contact. As an example, we present the calculated characteristics\nof the QCL operated at 10$\\mu$m wavelength. Our calculations show that the\nlaser frequency shift can reach GHz range and the laser tuning speed will be\nlimited by external electronics. Calculations demonstrate that within the range\nof the selected parameters, the device possesses intrinsically linear relation\nbetween the optical frequency and the tuning voltage."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-181",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06187"
    ],
    "b_title":[
      "MSConv: Multiplicative and Subtractive Convolution for Face Recognition"
    ],
    "b_abstract":[
      "In Neural Networks, there are various methods of feature fusion. Different\nstrategies can significantly affect the effectiveness of feature\nrepresentation, consequently influencing the ability of model to extract\nrepresentative and discriminative features. In the field of face recognition,\ntraditional feature fusion methods include feature concatenation and feature\naddition. Recently, various attention mechanism-based fusion strategies have\nemerged. However, we found that these methods primarily focus on the important\nfeatures in the image, referred to as salient features in this paper, while\nneglecting another equally important set of features for image recognition\ntasks, which we term differential features. This may cause the model to\noverlook critical local differences when dealing with complex facial samples.\nTherefore, in this paper, we propose an efficient convolution module called\nMSConv (Multiplicative and Subtractive Convolution), designed to balance the\nlearning of model about salient and differential features. Specifically, we\nemploy multi-scale mixed convolution to capture both local and broader\ncontextual information from face images, and then utilize Multiplication\nOperation (MO) and Subtraction Operation (SO) to extract salient and\ndifferential features, respectively. Experimental results demonstrate that by\nintegrating both salient and differential features, MSConv outperforms models\nthat only focus on salient features."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19022"
    ],
    "c_title":[
      "A BV-Category of Spacetime Interventions"
    ],
    "c_abstract":[
      "We use the Chu construction to functorially build BV-categories from duoidal\ncategories, demonstrating that candidate models of BV-logic can be cofreely\nconstructed from a fragment of a model of Retor\\'e's sequencing operator. By\nusing this construction to show that the strong Hyland envelope is a\nBV-category, we find a way to build a canonical model of spatio-temporal\nrelationships between agents in spacetime from any symmetric monoidal category.\nThe concrete physical interpretation of spacetime events in this model as\nintervention-context pairs resolves deficiencies in previous attempts to give a\ngeneral categorical semantics to quantum supermaps."
    ],
    "c_categories":[
      [
        "cs.LO",
        "math.CT",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-182",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04112"
    ],
    "b_title":[
      "A Class of Non-Contracting Branch Groups with Non-Torsion Rigid Kernels"
    ],
    "b_abstract":[
      "In this work, we provide the first example of an infinite family of branch\ngroups in the class of non-contracting self-similar groups. We show that these\ngroups are very strongly fractal, not regular branch, and of exponential\ngrowth. Further, we prove that these groups do not have the congruence subgroup\nproperty by explicitly calculating the structure of their rigid kernels. This\nclass of groups is also the first example of branch groups with non-torsion\nrigid kernels. As a consequence of these results, we also determine the\nHausdorff dimension of these groups."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.13350"
    ],
    "c_title":[
      "DoMINO: A Decomposable Multi-scale Iterative Neural Operator for\n  Modeling Large Scale Engineering Simulations"
    ],
    "c_abstract":[
      "Numerical simulations play a critical role in design and development of\nengineering products and processes. Traditional computational methods, such as\nCFD, can provide accurate predictions but are computationally expensive,\nparticularly for complex geometries. Several machine learning (ML) models have\nbeen proposed in the literature to significantly reduce computation time while\nmaintaining acceptable accuracy. However, ML models often face limitations in\nterms of accuracy and scalability and depend on significant mesh downsampling,\nwhich can negatively affect prediction accuracy and generalization. In this\nwork, we propose a novel ML model architecture, DoMINO (Decomposable\nMulti-scale Iterative Neural Operator) developed in NVIDIA Modulus to address\nthe various challenges of machine learning based surrogate modeling of\nengineering simulations. DoMINO is a point cloudbased ML model that uses local\ngeometric information to predict flow fields on discrete points. The DoMINO\nmodel is validated for the automotive aerodynamics use case using the DrivAerML\ndataset. Through our experiments we demonstrate the scalability, performance,\naccuracy and generalization of our model to both in-distribution and\nout-of-distribution testing samples. Moreover, the results are analyzed using a\nrange of engineering specific metrics important for validating numerical\nsimulations."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-183",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01940"
    ],
    "b_title":[
      "Spin-period variations in the intermediate polar RX J2133.7+5107"
    ],
    "b_abstract":[
      "We report the results of long-term time series photometry on RX J2133.7+5107\n(also known as 1RXS J213344.1+510725) obtained at several observatories. Using\ndata taken during 17 years, we determined the current value of the spin period\nof $570.811470$ seconds with the formal accuracy of $0.000006$ seconds and a\nspin-up of the white dwarf with a characteristic time of $1.483(1)\\times10^5$\nyears. This is even faster than that reported previously and, if confirmed,\nmakes this object have one of the fastest spin-up timescales of all known\nintermediate polars. We derived an improved value of the superhump period of\nthe system to be $0^d.280130(1)$. Superhump maxima timings are moving on the\nphase curve from season to season, showing non-monotonic changes, without a\nchange in superhump period."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14428"
    ],
    "c_title":[
      "Risk-mediated dynamic regulation of effective contacts de-synchronizes\n  outbreaks in metapopulation epidemic models"
    ],
    "c_abstract":[
      "Metapopulation epidemic models help capture the spatial dimension of\ninfectious disease spread by dividing heterogeneous populations into separate\nbut interconnected communities, represented by nodes in a network. In the event\nof an epidemic, an important research question is, to what degree spatial\ninformation (i.e., regional or national) is relevant for mitigation and (local)\npolicymakers. This study investigates the impact of different levels of\ninformation on nationwide epidemic outcomes, modeling the reaction to the\nmeasured hazard as a feedback loop reducing contact rates in a metapopulation\nmodel based on ordinary differential equations (ODEs). Using COVID-19 and\nhigh-resolution mobility data for Germany of 2020 as a case study, we found two\nmarkedly different regimes depending on the maximum contact reduction\n$\\psi_{\\rm max}$: mitigation and suppression. In the regime of (modest)\nmitigation, gradually increasing $\\psi_{\\rm max}$ from zero to moderate levels\ndelayed and spread out the onset of infection waves while gradually reducing\nthe peak values. This effect was more pronounced when the contribution of\nregional information was low relative to national data. In the suppression\nregime, the feedback-induced contact reduction is strong enough to extinguish\nlocal outbreaks and decrease the mean and variance of the peak day\ndistribution, thus regional information was more important. When suppression or\nelimination is impossible, ensuring local epidemics are desynchronized helps to\navoid hospitalization or intensive care bottlenecks by reallocating resources\nfrom less-affected areas."
    ],
    "c_categories":[
      [
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-184",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15576"
    ],
    "b_title":[
      "Interpreting and Steering LLMs with Mutual Information-based\n  Explanations on Sparse Autoencoders"
    ],
    "b_abstract":[
      "Large language models (LLMs) excel at handling human queries, but they can\noccasionally generate flawed or unexpected responses. Understanding their\ninternal states is crucial for understanding their successes, diagnosing their\nfailures, and refining their capabilities. Although sparse autoencoders (SAEs)\nhave shown promise for interpreting LLM internal representations, limited\nresearch has explored how to better explain SAE features, i.e., understanding\nthe semantic meaning of features learned by SAE. Our theoretical analysis\nreveals that existing explanation methods suffer from the frequency bias issue,\nwhere they emphasize linguistic patterns over semantic concepts, while the\nlatter is more critical to steer LLM behaviors. To address this, we propose\nusing a fixed vocabulary set for feature interpretations and designing a mutual\ninformation-based objective, aiming to better capture the semantic meaning\nbehind these features. We further propose two runtime steering strategies that\nadjust the learned feature activations based on their corresponding\nexplanations. Empirical results show that, compared to baselines, our method\nprovides more discourse-level explanations and effectively steers LLM behaviors\nto defend against jailbreak attacks. These findings highlight the value of\nexplanations for steering LLM behaviors in downstream applications. We will\nrelease our code and data once accepted."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17801"
    ],
    "c_title":[
      "A uniform construction of Chevalley normal forms for automorphic Lie\n  algebras on the Riemann sphere"
    ],
    "c_abstract":[
      "For a finite subgroup $G$ of $SU(2)$ and one of its ground forms\n$P\\in\\mathbb{C}[X,Y]$, we show that the space of invariants\n$\\mathbb{C}[X,Y,P^{-1}]^{G}_k$ of degree $k\\in2\\mathbb{Z}$ is a cyclic module\nover the algebra of invariants of degree zero. We find a generator for this\nmodule, uniformly for all finite subgroups of $SU(2)$. Then we construct a\nuniform intertwiner sending the scalar invariants to vector-valued invariants.\nWith these tools we construct all automorphic Lie algebras\n$\\mathfrak{g}[X,Y,P^{-1}]^{G}_0$ defined by a homomorphism from the symmetry\ngroup $G$ into the automorphism group of a finite dimensional Lie algebra\n$\\mathfrak g$, which factors through $SU(2)$. When the Lie algebra $\\mathfrak\ng$ is simple, we present a set of generators for the automorphic Lie algebra\nwhich is analogous to the Chevalley basis for $\\mathfrak g$. Previous\nobservations of isomorphisms between automorphic Lie algebras with distinct\nsymmetry groups $G$ are explained in terms of the Coxeter number of $\\mathfrak\ng$ and the orders appearing in $G$. Finally, we compute the structure constants\nfor automorphic Lie algebras of all exceptional Lie types."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-185",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00700"
    ],
    "b_title":[
      "S2CFormer: Revisiting the RD-Latency Trade-off in Transformer-based\n  Learned Image Compression"
    ],
    "b_abstract":[
      "Transformer-based Learned Image Compression (LIC) suffers from a suboptimal\ntrade-off between decoding latency and rate-distortion (R-D) performance.\nMoreover, the critical role of the FeedForward Network (FFN)-based channel\naggregation module has been largely overlooked. Our research reveals that\nefficient channel aggregation-rather than complex and time-consuming spatial\noperations-is the key to achieving competitive LIC models. Based on this\ninsight, we initiate the ``S2CFormer'' paradigm, a general architecture that\nsimplifies spatial operations and enhances channel operations to overcome the\nprevious trade-off. We present two instances of the S2CFormer: S2C-Conv, and\nS2C-Attention. Both models demonstrate state-of-the-art (SOTA) R-D performance\nand significantly faster decoding speed. Furthermore, we introduce S2C-Hybrid,\nan enhanced variant that maximizes the strengths of different S2CFormer\ninstances to achieve a better performance-latency trade-off. This model\noutperforms all the existing methods on the Kodak, Tecnick, and CLIC\nProfessional Validation datasets, setting a new benchmark for efficient and\nhigh-performance LIC. The code is at\n\\href{https:\/\/github.com\/YunuoChen\/S2CFormer}{https:\/\/github.com\/YunuoChen\/S2CFormer}."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13003"
    ],
    "c_title":[
      "Fluorescent molecular rotor-based polymer materials for local\n  microviscosity mapping in microfluidic channels"
    ],
    "c_abstract":[
      "A viscosity-sensitive monomer consisting of a methacrylate-functionalized\njulolidone-based molecular rotor (MECVJ) was synthesized and used to obtain\nviscosity-sensitive polymers (poly(DMA-\\textit{s}-MECVJ)). The qualitative\nproperties of the molecular rotor were preserved after its inclusion in the new\npolymer, in particular the effect of the viscosity of the surrounding medium on\nthe fluorescence lifetime of the rotor. By grafting these polymers onto glass\nslides, viscosity-sensitive surfaces were obtained, showing good robustness in\ntime after successive use and washing. As proof of concept, these surfaces were\nused to assemble a microfluidic chip capable of mapping viscosity of fluids\nflowing inside the channel."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.app-ph",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-186",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17295"
    ],
    "b_title":[
      "Mitigating Hallucinated Translations in Large Language Models with\n  Hallucination-focused Preference Optimization"
    ],
    "b_abstract":[
      "Machine Translation (MT) is undergoing a paradigm shift, with systems based\non fine-tuned large language models (LLM) becoming increasingly competitive\nwith traditional encoder-decoder models trained specifically for translation\ntasks. However, LLM-based systems are at a higher risk of generating\nhallucinations, which can severely undermine user's trust and safety. Most\nprior research on hallucination mitigation focuses on traditional MT models,\nwith solutions that involve post-hoc mitigation - detecting hallucinated\ntranslations and re-translating them. While effective, this approach introduces\nadditional complexity in deploying extra tools in production and also increases\nlatency. To address these limitations, we propose a method that intrinsically\nlearns to mitigate hallucinations during the model training phase.\nSpecifically, we introduce a data creation framework to generate hallucination\nfocused preference datasets. Fine-tuning LLMs on these preference datasets\nreduces the hallucination rate by an average of 96% across five language pairs,\nwhile preserving overall translation quality. In a zero-shot setting our\napproach reduces hallucinations by 89% on an average across three unseen target\nlanguages."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.09912"
    ],
    "c_title":[
      "Beta-Generalized Lindley Distribution: A Novel Probability Model for\n  Wind Speed"
    ],
    "c_abstract":[
      "Wind speed distribution has many applications, such as the assessment of wind\nenergy and building design. Applying an appropriate statistical distribution to\nfit the wind speed data, especially on its heavy right tail, is of great\ninterest. In this study, we introduce a novel four-parameter class of\ngeneralized Lindley distribution, called the beta-generalized Lindley (BGL)\ndistribution, to fit the wind speed data, which are derived from the annual and\nlong-term measurements of the Flatirons M2 meteorological tower from the years\n2010 to 2020 at heights of 10, 20, 50, and 80 meters. In terms of the density\nfit and various goodness-of-fit metrics, the BGL model outperforms its\nsubmodels (beta-Lindley, generalized Lindley, and Lindley) and other reference\ndistributions, such as gamma, beta-Weibull, Weibull, beta-exponential, and\nLog-Normal. Furthermore, the BGL distribution is more accurate at modeling the\nlong right tail of wind speed, including the $95^{th}$ and $99^{th}$\npercentiles and Anderson-Darling statistics at different heights. Therefore, we\nconclude that the BGL distribution is a strong alternative model for the wind\nspeed distribution."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-187",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17881"
    ],
    "b_title":[
      "RayLoc: Wireless Indoor Localization via Fully Differentiable\n  Ray-tracing"
    ],
    "b_abstract":[
      "Wireless indoor localization has been a pivotal area of research over the\nlast two decades, becoming a cornerstone for numerous sensing applications.\nHowever, conventional wireless localization methods rely on channel state\ninformation to perform blind modelling and estimation of a limited set of\nlocalization parameters. This oversimplification neglects many sensing scene\ndetails, resulting in suboptimal localization accuracy. To address this\nlimitation, this paper presents a novel approach to wireless indoor\nlocalization by reformulating it as an inverse problem of wireless ray-tracing,\ninferring scene parameters that generates the measured CSI. At the core of our\nsolution is a fully differentiable ray-tracing simulator that enables\nbackpropagation to comprehensive parameters of the sensing scene, allowing for\nprecise localization. To establish a robust localization context, RayLoc\nconstructs a high-fidelity sensing scene by refining coarse-grained background\nmodel. Furthermore, RayLoc overcomes the challenges of sparse gradient and\nlocal minima by convolving the signal generation process with a Gaussian\nkernel. Extensive experiments showcase that RayLoc outperforms traditional\nlocalization baselines and is able to generalize to different sensing\nenvironments."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21125"
    ],
    "c_title":[
      "Eukaryotes evade information storage-replication rate trade-off with\n  endosymbiont assistance leading to larger genomes"
    ],
    "c_abstract":[
      "Genome length varies widely among organisms, from compact genomes of\nprokaryotes to vast and complex genomes of eukaryotes. In this study, we\ntheoretically identify the evolutionary pressures that may have driven this\ndivergence in genome length. We use a parameter-free model to study genome\nlength evolution under selection pressure to minimize replication time and\nmaximize information storage capacity. We show that prokaryotes tend to reduce\ngenome length, constrained by a single replication origin, while eukaryotes\nexpand their genomes by incorporating multiple replication origins. We propose\na connection between genome length and cellular energetics, suggesting that\nendosymbiotic organelles, mitochondria and chloroplasts, evolutionarily\nregulate the number of replication origins, thereby influencing genome length\nin eukaryotes. We show that the above two selection pressures also lead to\nstrict equalization of the number of purines and their corresponding\nbase-pairing pyrimidines within a single DNA strand, known as Chagraff's second\nparity rule, a hitherto unexplained observation in genomes of nearly all known\nspecies. This arises from the symmetrization of replichore length, another\nobservation that has been shown to hold across species, which our model\nreproduces. The model also reproduces other experimentally observed phenomena,\nsuch as a general preference for deletions over insertions, and elongation and\nhigh variance of genome lengths under reduced selection pressure for\nreplication rate, termed the C-value paradox. We highlight the possibility of\nregulation of the firing of latent replication origins in response to cues from\nthe extracellular environment leading to the regulation of cell cycle rates in\nmulticellular eukaryotes."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-188",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09137"
    ],
    "b_title":[
      "Gradient Descent Converges Linearly to Flatter Minima than Gradient Flow\n  in Shallow Linear Networks"
    ],
    "b_abstract":[
      "We study the gradient descent (GD) dynamics of a depth-2 linear neural\nnetwork with a single input and output. We show that GD converges at an\nexplicit linear rate to a global minimum of the training loss, even with a\nlarge stepsize -- about $2\/\\textrm{sharpness}$. It still converges for even\nlarger stepsizes, but may do so very slowly. We also characterize the solution\nto which GD converges, which has lower norm and sharpness than the gradient\nflow solution. Our analysis reveals a trade off between the speed of\nconvergence and the magnitude of implicit regularization. This sheds light on\nthe benefits of training at the ``Edge of Stability'', which induces additional\nregularization by delaying convergence and may have implications for training\nmore complex models."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11161"
    ],
    "c_title":[
      "BFA: Best-Feature-Aware Fusion for Multi-View Fine-grained Manipulation"
    ],
    "c_abstract":[
      "In real-world scenarios, multi-view cameras are typically employed for\nfine-grained manipulation tasks. Existing approaches (e.g., ACT) tend to treat\nmulti-view features equally and directly concatenate them for policy learning.\nHowever, it will introduce redundant visual information and bring higher\ncomputational costs, leading to ineffective manipulation. For a fine-grained\nmanipulation task, it tends to involve multiple stages while the most\ncontributed view for different stages is varied over time. In this paper, we\npropose a plug-and-play best-feature-aware (BFA) fusion strategy for multi-view\nmanipulation tasks, which is adaptable to various policies. Built upon the\nvisual backbone of the policy network, we design a lightweight network to\npredict the importance score of each view. Based on the predicted importance\nscores, the reweighted multi-view features are subsequently fused and input\ninto the end-to-end policy network, enabling seamless integration. Notably, our\nmethod demonstrates outstanding performance in fine-grained manipulations.\nExperimental results show that our approach outperforms multiple baselines by\n22-46% success rate on different tasks. Our work provides new insights and\ninspiration for tackling key challenges in fine-grained manipulations."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-189",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13297"
    ],
    "b_title":[
      "RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question\n  Answering"
    ],
    "b_abstract":[
      "Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text\nand images, has gained significant attention in information retrieval (IR) and\nnatural language processing (NLP). Traditional ranking methods rely on small\nencoder-based language models, which are incompatible with modern decoder-based\ngenerative large language models (LLMs) that have advanced various NLP tasks.\nTo bridge this gap, we propose RAMQA, a unified framework combining\nlearning-to-rank methods with generative permutation-enhanced ranking\ntechniques. We first train a pointwise multi-modal ranker using LLaVA as the\nbackbone. Then, we apply instruction tuning to train a LLaMA model for\nre-ranking the top-k documents using an innovative autoregressive multi-task\nlearning approach. Our generative ranking model generates re-ranked document\nIDs and specific answers from document candidates in various permutations.\nExperiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant\nimprovements over strong baselines, highlighting the effectiveness of our\napproach. Code and data are available at: https:\/\/github.com\/TonyBY\/RAMQA"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21160"
    ],
    "c_title":[
      "Imperfect preparation and Trojan attack on the phase modulator in the\n  decoy-state BB84 protocol"
    ],
    "c_abstract":[
      "Quantum key distribution (QKD) provides a theoretically secure method for\ncryptographic key exchange by leveraging quantum mechanics, but practical\nimplementations face vulnerabilities such as Trojan horse attack on phase\nmodulators. This work analyzes the security of QKD systems under such attacks,\nconsidering both ideal and imperfect state preparation scenarios. The Trojan\nattack model is generalized to arbitrary states of probing pulses and\nconservative bounds of information leakage through side-channel of special form\nare introduced. The quantum coin imbalance, a critical security parameter,\nremains low (on the order of $10^{-7}$ for ideal state preparation and\n$10^{-5}$ for imperfect preparation) with this new approach and presence\nadditional hardware passive countermeasures. Numerical simulations confirm\nnonzero secure key rate at distances over 100 km through optical fiber channel."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-190",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15775"
    ],
    "b_title":[
      "Fast Calculation of Nonuniform Plane Waves at Arbitrarily Oriented and\n  Charged Planar Interfaces of Isotropic Lossy Media"
    ],
    "b_abstract":[
      "A fast method for calculating the reflected and transmitted waves for a given\nnonuniform plane wave incident on an arbitrarily oriented and charged planar\ninterface between two isotropic and possibly lossy media is proposed based on\nthe decomposition of the complex wave vector and complex wave numbers with\nrespect to the unit normal vector of the interface. According to the complex\nvector analysis, the exact definition of the complex angles of incidence,\nreflection and refraction are presented and applied in the complex forms of\nSnell's law and Fresnel equations to quickly and correctly calculate the\ncomplex wave vectors and the complex electric fields of the reflected and\nrefracted waves at a charged interface where the surface charge and current\ndensities are considered. The calculation procedure and two practical examples\nare also given to demonstrate the validity and powerfulness of the proposed\nmethodology."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.07613"
    ],
    "c_title":[
      "A general form of Newton-Maclaurin type inequalities"
    ],
    "c_abstract":[
      "In this paper, we extend the classical Newton-Maclaurin inequalities to\nfunctions $S_{k;s}(x)=E_k(x)+\\dsum_{i=1}^s \\al_i E_{k-i}(x)$, which are formed\nby linear combinations of multiple basic symmetric mean. We proved that when\nthe coefficients $\\al_1,\\al_2,\\cdots,\\al_s$ satisfy the condition that the\npolynomial $$t^s+\\al_1 t^{s-1}+\\al_2 t^{s-2}+\\cdots+\\al_s $$ has only real\nroots, the Newton-Maclaurin type inequalities hold for $S_{k;s}(x)$."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-191",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08051"
    ],
    "b_title":[
      "Screening rho-meson mass in the presence of strong magnetic fields"
    ],
    "b_abstract":[
      "We study the screening mass of the neutral rho-meson in the presence of\nstrong magnetic fields using the Kroll-Lee-Zumino (KLZ) model. The rho-meson\nself-energy is computed at one-loop order within the lowest Landau level (LLL)\napproximation, considering the magnetic field as the dominant energy scale. Due\nto Lorentz symmetry breaking induced by the external field, we decompose the\nself-energy into three independent tensor structures, which give rise to three\ndistinct modes. Additionally, the four-momentum splits into parallel and\nperpendicular components, leading to two types of screening masses: the\nparallel screening mass ( $p_0=0$ and $p_\\perp \\to 0$ ) and the perpendicular\nscreening mass ( $p_0=0$ and $p_\\parallel \\to 0$ ). Our results show that the\nzero and perpendicular modes exhibit a monotonically increasing behavior with\nthe magnetic field strength, whereas the parallel mode remains essentially\nconstant. These findings provide new insights into the behavior of vector\nmesons in strongly magnetized media, with implications for QCD under extreme\nconditions."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.13863"
    ],
    "c_title":[
      "Recovering All Coefficients in the Schr\\\"{o}dinger Equation With Finite\n  Sets of Boundary Measurements"
    ],
    "c_abstract":[
      "We consider an inverse problem of recovering all spatial dependent\ncoefficients in the time dependent Schr\\\"odinger equation defined on an open\nbounded domain in $\\mathbb{R}^n$, $n\\geq 2$, with smooth enough boundary. We\nshow that by appropriately selecting a finite number of initial conditions and\na fixed Dirichlet boundary condition, we may recover all the coefficients in a\nLipschitz stable fashion from the corresponding finitely many boundary\nmeasurements made on a portion of the boundary. The proof is based on a direct\napproach, which was introduced in \\cite{HIY2020}, to derive the stability\nestimate directly from the Carleman estimates without any cut-off procedure or\ncompactness-uniqueness argument."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-192",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09522"
    ],
    "b_title":[
      "Quantum Synchronizing Words: Resetting and Preparing Qutrit States"
    ],
    "b_abstract":[
      "Synchronizing words in classical automata theory provide a mechanism to reset\nany state of a deterministic automaton to a specific target state via a\ncarefully chosen finite sequence of transition rules. In this work, we extend\nthe concept of synchronizing words to quantum information theory. Specifically,\nwe show that with only two quantum channels, it is possible to bring an\narbitrary qutrit state close to a designated target state. Furthermore, we\ndemonstrate that following this reset, any pure real qutrit state can be\nclosely approximated using the same two channels. These findings establish a\nquantum analogue of synchronizing words, highlighting their potential\napplications in constructing minimal sets of universal quantum gates capable of\nboth resetting and preparing arbitrary states."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.04179"
    ],
    "c_title":[
      "Generation from Noisy Examples"
    ],
    "c_abstract":[
      "We continue to study the learning-theoretic foundations of generation by\nextending the results from Kleinberg and Mullainathan [2024] and Li et al.\n[2024] to account for noisy example streams. In the noiseless setting of\nKleinberg and Mullainathan [2024] and Li et al. [2024], an adversary picks a\nhypothesis from a binary hypothesis class and provides a generator with a\nsequence of its positive examples. The goal of the generator is to eventually\noutput new, unseen positive examples. In the noisy setting, an adversary still\npicks a hypothesis and a sequence of its positive examples. But, before\npresenting the stream to the generator, the adversary inserts a finite number\nof negative examples. Unaware of which examples are noisy, the goal of the\ngenerator is to still eventually output new, unseen positive examples. In this\npaper, we provide necessary and sufficient conditions for when a binary\nhypothesis class can be noisily generatable. We provide such conditions with\nrespect to various constraints on the number of distinct examples that need to\nbe seen before perfect generation of positive examples. Interestingly, for\nfinite and countable classes we show that generatability is largely unaffected\nby the presence of a finite number of noisy examples."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-193",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12751"
    ],
    "b_title":[
      "R3-Avatar: Record and Retrieve Temporal Codebook for Reconstructing\n  Photorealistic Human Avatars"
    ],
    "b_abstract":[
      "We present R3-Avatar, incorporating a temporal codebook, to overcome the\ninability of human avatars to be both animatable and of high-fidelity rendering\nquality. Existing video-based reconstruction of 3D human avatars either focuses\nsolely on rendering, lacking animation support, or learns a pose-appearance\nmapping for animating, which degrades under limited training poses or complex\nclothing. In this paper, we adopt a \"record-retrieve-reconstruct\" strategy that\nensures high-quality rendering from novel views while mitigating degradation in\nnovel poses. Specifically, disambiguating timestamps record temporal appearance\nvariations in a codebook, ensuring high-fidelity novel-view rendering, while\nnovel poses retrieve corresponding timestamps by matching the most similar\ntraining poses for augmented appearance. Our R3-Avatar outperforms cutting-edge\nvideo-based human avatar reconstruction, particularly in overcoming visual\nquality degradation in extreme scenarios with limited training human poses and\ncomplex clothing."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08647"
    ],
    "c_title":[
      "JWST's First View of Tidal Disruption Events: Compact, Accretion-Driven\n  Emission Lines & Strong Silicate Emission in an Infrared-selected Sample"
    ],
    "c_abstract":[
      "Mid-infrared (MIR) emission from tidal disruption events (TDEs) is a powerful\nprobe of the circumnuclear environment around dormant supermassive black holes.\nThis emission arises from the reprocessing of intrinsic emission into thermal\nMIR emission by circumnuclear dust. While the majority of optical- and\nX-ray-selected TDEs show only weak dust echoes consistent with primarily\nunobscured sight lines, there have been growing efforts aimed at finding TDEs\nin obscured environments using MIR selection methods. In this work, we present\nthe first JWST observations of 4 MIR-selected TDEs with JWST Mid-Infrared\nInstrument (MIRI) Medium-Resolution Spectrometer (MRS). Two of these sources\nshow flares in other wavelength bands (one in optical, one in X-ray), while the\nother two are MIR-only transients. None of these TDEs showed pre-outburst\nnuclear activity, but all of the MIRI\/MRS observations reveal emission lines\nassociated with highly ionized gas, implying ionization from TDE accretion.\nAdditionally, all four sources show silicate emission features around 10 and 18\n$\\mu$m that are much stronger than the features seen in active galactic nuclei\n(AGN). We suggest that the emitting dust is optically thin to its own emission\nand show that the MIR spectrum is consistent with emission from optically thin\ndust along an isodelay surface. All four sources show an excess at short\nwavelengths ($\\lambda < 8\\, \\mu$m), which could arise from a late-time plateau\nin the intrinsic flare, akin to what is seen in late-time UV observations of\nunobscured TDEs, although self-consistent dust modeling is required to fully\nassess the strength of this late-time plateau."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-194",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09765"
    ],
    "b_title":[
      "Pooling Liquidity Pools in AMMs"
    ],
    "b_abstract":[
      "Market fragmentation across multiple Automated Market Makers (AMMs) creates\ninefficiencies such as costly arbitrage, unnecessarily high slippage and\ndelayed incorporation of new information into prices. These inefficiencies\nraise trading costs, reduce liquidity provider profits, and degrade overall\nmarket efficiency. To address these issues, we propose a modification of the\nConstant Product Market Maker (CPMM) pricing mechanism, called the Global\nMarket Maker (GMM), which aggregates liquidity information from all AMMs to\nmitigate these inefficiencies. Through theoretical and numerical analyses, we\ndemonstrate that the GMM enhances profits for both AMMs and traders by\neliminating arbitrage opportunities. Additionally, it reduces the profitability\nof sandwich attacks and minimizes impermanent losses."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2503.08299"
    ],
    "c_title":[
      "Distillation-PPO: A Novel Two-Stage Reinforcement Learning Framework for\n  Humanoid Robot Perceptive Locomotion"
    ],
    "c_abstract":[
      "In recent years, humanoid robots have garnered significant attention from\nboth academia and industry due to their high adaptability to environments and\nhuman-like characteristics. With the rapid advancement of reinforcement\nlearning, substantial progress has been made in the walking control of humanoid\nrobots. However, existing methods still face challenges when dealing with\ncomplex environments and irregular terrains. In the field of perceptive\nlocomotion, existing approaches are generally divided into two-stage methods\nand end-to-end methods. Two-stage methods first train a teacher policy in a\nsimulated environment and then use distillation techniques, such as DAgger, to\ntransfer the privileged information learned as latent features or actions to\nthe student policy. End-to-end methods, on the other hand, forgo the learning\nof privileged information and directly learn policies from a partially\nobservable Markov decision process (POMDP) through reinforcement learning.\nHowever, due to the lack of supervision from a teacher policy, end-to-end\nmethods often face difficulties in training and exhibit unstable performance in\nreal-world applications. This paper proposes an innovative two-stage perceptive\nlocomotion framework that combines the advantages of teacher policies learned\nin a fully observable Markov decision process (MDP) to regularize and supervise\nthe student policy. At the same time, it leverages the characteristics of\nreinforcement learning to ensure that the student policy can continue to learn\nin a POMDP, thereby enhancing the model's upper bound. Our experimental results\ndemonstrate that our two-stage training framework achieves higher training\nefficiency and stability in simulated environments, while also exhibiting\nbetter robustness and generalization capabilities in real-world applications."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-195",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18399"
    ],
    "b_title":[
      "T3ST code: Turbulent Transport in Tokamaks via Stochastic Trajectories"
    ],
    "b_abstract":[
      "We introduce the Turbulent Transport in Tokamaks via Stochastic Trajectories\n(T3ST) code, designed to address the problem of turbulent transport using a\nstatistical approach complementary to gyrokinetics. The code employs\ntest-particle methods to track the dynamics of charged particles in\naxisymmetric magnetic equilibria, accounting for both turbulence and Coulomb\ncollisions. The turbulence is decoupled from plasma dynamics and represented\nthrough a statistical ensemble of synthetic random fields with specified\nspectral properties. This approach enables T3ST to compute transport\ncoefficients as Lagrangian correlations - orders of magnitude faster than\ngyrokinetic codes."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02018"
    ],
    "c_title":[
      "Advancing Obfuscation Strategies to Counter China's Great Firewall: A\n  Technical and Policy Perspective"
    ],
    "c_abstract":[
      "China's Great Firewall (GFW) exemplifies one of the most extensive and\ntechnologically sophisticated internet censorship frameworks worldwide. Serving\nas a cornerstone of state-directed digital governance, it integrates a\nmultitude of methods - ranging from DNS manipulation and IP blocking to keyword\nfiltering and active surveillance - to control online information flows. These\nmeasures, underpinned by both technical proficiency and administrative\noversight, form a formidable obstacle to open communication and data privacy.\nThis paper critically examines the GFW's principal detection techniques,\nincluding Deep Packet Inspection (DPI), domain name tampering, and traffic\nfingerprinting, and analyzes how they align with broader governmental\nmechanisms. In parallel, we evaluate emerging countermeasures that leverage\nobfuscation, encryption, and routing innovations to circumvent these\nrestrictions. By situating technical strategies within the broader context of\ngovernance and human rights, this work underscores the ongoing and evolving\ncontest between state-imposed internet controls and individual efforts to\nmaintain unrestricted access to digital resources."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-196",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09533"
    ],
    "b_title":[
      "Large Language Models for Multi-Facility Location Mechanism Design"
    ],
    "b_abstract":[
      "Designing strategyproof mechanisms for multi-facility location that optimize\nsocial costs based on agent preferences had been challenging due to the\nextensive domain knowledge required and poor worst-case guarantees. Recently,\ndeep learning models have been proposed as alternatives. However, these models\nrequire some domain knowledge and extensive hyperparameter tuning as well as\nlacking interpretability, which is crucial in practice when transparency of the\nlearned mechanisms is mandatory. In this paper, we introduce a novel approach,\nnamed LLMMech, that addresses these limitations by incorporating large language\nmodels (LLMs) into an evolutionary framework for generating interpretable,\nhyperparameter-free, empirically strategyproof, and nearly optimal mechanisms.\nOur experimental results, evaluated on various problem settings where the\nsocial cost is arbitrarily weighted across agents and the agent preferences may\nnot be uniformly distributed, demonstrate that the LLM-generated mechanisms\ngenerally outperform existing handcrafted baselines and deep learning models.\nFurthermore, the mechanisms exhibit impressive generalizability to\nout-of-distribution agent preferences and to larger instances with more agents."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10471"
    ],
    "c_title":[
      "Siamese Foundation Models for Crystal Structure Prediction"
    ],
    "c_abstract":[
      "Crystal Structure Prediction (CSP), which aims to generate stable crystal\nstructures from compositions, represents a critical pathway for discovering\nnovel materials. While structure prediction tasks in other domains, such as\nproteins, have seen remarkable progress, CSP remains a relatively underexplored\narea due to the more complex geometries inherent in crystal structures. In this\npaper, we propose Siamese foundation models specifically designed to address\nCSP. Our pretrain-finetune framework, named DAO, comprises two complementary\nfoundation models: DAO-G for structure generation and DAO-P for energy\nprediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that\nour DAO-G significantly surpasses state-of-the-art (SOTA) methods across all\nmetrics. Extensive ablation studies further confirm that DAO-G excels in\ngenerating diverse polymorphic structures, and the dataset relaxation and\nenergy guidance provided by DAO-P are essential for enhancing DAO-G's\nperformance. When applied to three real-world superconductors\n($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and\n$\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to\nanalyze, our foundation models achieve accurate critical temperature\npredictions and structure generations. For instance, on\n$\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the\nexperimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with\nhigh accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast,\nconventional DFT calculators like Quantum Espresso only successfully derive the\nstructure of the first superconductor within an acceptable time, while the RMSE\nis nearly 8 times larger, and the computation speed is more than 1000 times\nslower. These compelling results collectively highlight the potential of our\napproach for advancing materials science research and development."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-197",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18295"
    ],
    "b_title":[
      "Quantization of the Momentum Map via $\\frak{g}$-adapted Formalities"
    ],
    "b_abstract":[
      "In this note, we provide a proof of the existence and complete classification\nof $G$-invariant star products with quantum momentum maps on Poisson manifolds\nby means of an equivariant version of the formality theorem."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.QA",
        "math.SG"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.01091"
    ],
    "c_title":[
      "Projected Spread Models"
    ],
    "c_abstract":[
      "We present a disease transmission model that considers both explicit and\nnon-explicit factors. This approach is crucial for accurate prediction and\ncontrol of infectious disease spread. In this paper, we extend the spread model\nfrom our previous works \\cite{ban2021mathematical,ban2023randomspread,\nban2023mathematical, ban2023spread} to a projected spread model that considers\nboth hidden and explicit types. Additionally, we provide the spread rate for\nthe projected spread model corresponding to the topological and random models.\nFurthermore, examples and numerical results are provided to illustrate the\ntheory."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-198",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03859"
    ],
    "b_title":[
      "A Synergistic Framework for Learning Shape Estimation and Shape-Aware\n  Whole-Body Control Policy for Continuum Robots"
    ],
    "b_abstract":[
      "In this paper, we present a novel synergistic framework for learning shape\nestimation and a shape-aware whole-body control policy for tendon-driven\ncontinuum robots. Our approach leverages the interaction between two Augmented\nNeural Ordinary Differential Equations (ANODEs) -- the Shape-NODE and\nControl-NODE -- to achieve continuous shape estimation and shape-aware control.\nThe Shape-NODE integrates prior knowledge from Cosserat rod theory, allowing it\nto adapt and account for model mismatches, while the Control-NODE uses this\nshape information to optimize a whole-body control policy, trained in a Model\nPredictive Control (MPC) fashion. This unified framework effectively overcomes\nlimitations of existing data-driven methods, such as poor shape awareness and\nchallenges in capturing complex nonlinear dynamics. Extensive evaluations in\nboth simulation and real-world environments demonstrate the framework's robust\nperformance in shape estimation, trajectory tracking, and obstacle avoidance.\nThe proposed method consistently outperforms state-of-the-art end-to-end,\nNeural-ODE, and Recurrent Neural Network (RNN) models, particularly in terms of\ntracking accuracy and generalization capabilities."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01259"
    ],
    "c_title":[
      "Description of nucleon transfer reactions at intermediate energies\n  within the impulse picture"
    ],
    "c_abstract":[
      "Background:\n  At intermediate energies, transfer reactions hardly occur because the\nmomentum-matching condition is difficult to satisfy. In the standard\ndistorted-wave Born approximation, a particle to be transferred must have a\nmomentum being similar to the momentum transfer.\n  Purpose:\n  We propose a new reaction framework based on the distorted-wave impulse\napproximation for transfer reactions at intermediate energies, aiming to ease\nthe momentum-matching condition.\n  Methods:\n  The $(p,d)$ reaction is described as a $p$-$d$ elastic scattering for\nbackward-angle scattering in the target nucleus and the proton that formed a\n$pn$ pair is left and bound in the residual nucleus in the final channel. The\nmomentum transfer is shared by the deuteron in the target nucleus and the\nproton in the residual nucleus.\n  Results:\n  The new framework is applied to the $^{16}$O($p,d$)$^{15}$O reaction at\n200~MeV and compared with experimental data. The angular distribution is\nsatisfactorily well described, whereas an anomalously large scaling factor is\nneeded to reproduce the absolute value. The transition matrix is analyzed in\ndetail and the mechanism of the momentum sharing is clarified.\n  Conclusions:\n  The new reaction framework for transfer reactions at intermediate energies\nseems to be promising for describing the reaction mechanism but fails to\nexplain the absolute value of the cross section. The use of the $p$-$d$\ntransition amplitude instead of its cross section will be necessary to draw a\nconclusion on the applicability of the present framework."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-199",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16389"
    ],
    "b_title":[
      "Attentional Triple-Encoder Network in Spatiospectral Domains for Medical\n  Image Segmentation"
    ],
    "b_abstract":[
      "Retinal Optical Coherence Tomography (OCT) segmentation is essential for\ndiagnosing pathology. Traditional methods focus on either spatial or spectral\ndomains, overlooking their combined dependencies. We propose a triple-encoder\nnetwork that integrates CNNs for spatial features, Fast Fourier Convolution\n(FFC) for spectral features, and attention mechanisms to capture global\nrelationships across both domains. Attention fusion modules integrate\nconvolution and cross-attention to further enhance features. Our method\nachieves an average Dice score improvement from 0.855 to 0.864, outperforming\nprior work."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15075"
    ],
    "c_title":[
      "Abelian and monopole dominance in SU(3) gluodynamics and Gribov copy\n  effects"
    ],
    "c_abstract":[
      "We continue our study of the Gribov copies effrcts in the Maximal Abelian\ngauge in lattice $SU(3)$ gluodynamics. Our computations were completed for four\nvalues of the lattice spacing with physical lattice size $L \\approx 2$ fm. It\nis demonstrated that when one uses the effective simulated annealing algorithm\nto fix the gauge the obtained Gribov copies produce low abelian string tension\nwhich is below 90% of the physical value independent of the lattice spacing.\nThese Gribov copies produce also low value (about 86%) for the monopole string\ntension. It is further shown that in case of less effective relaxation\nalgorithm it is possible to obtain Gribov copies which produce both Abelian and\nmonopole string tension in good agreement with the physical one."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-200",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02496"
    ],
    "b_title":[
      "To Hedge or Not to Hedge: Optimal Strategies for Stochastic Trade Flow\n  Management"
    ],
    "b_abstract":[
      "This paper addresses the trade-off between internalisation and\nexternalisation in the management of stochastic trade flows. We consider agents\nwho must absorb flows and manage risk by deciding whether to warehouse it or\nhedge in the market, thereby incurring transaction costs and market impact.\nUnlike market makers, these agents cannot skew their quotes to attract\noffsetting flows and deter risk-increasing ones, leading to a fundamentally\ndifferent problem. Within the Almgren-Chriss framework, we derive\nalmost-closed-form solutions in the case of quadratic execution costs, while\nmore general cases require numerical methods. In particular, we discuss the\nchallenges posed by artificial boundary conditions when using classical\ngrid-based numerical PDE techniques and propose reinforcement learning methods\nas an alternative."
    ],
    "b_categories":[
      [
        "q-fin.TR"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2503.13681"
    ],
    "c_title":[
      "Single Sparse Graph Enhanced Expectation Propagation Algorithm Design\n  for Uplink MIMO-SCMA"
    ],
    "c_abstract":[
      "Sparse code multiple access (SCMA) and multiple input multiple output (MIMO)\nare considered as two efficient techniques to provide both massive connectivity\nand high spectrum efficiency for future machine-type wireless networks. This\npaper proposes a single sparse graph (SSG) enhanced expectation propagation\nalgorithm (EPA) receiver, referred to as SSG-EPA, for uplink MIMO-SCMA systems.\nFirstly, we reformulate the sparse codebook mapping process using a linear\nencoding model, which transforms the variable nodes (VNs) of SCMA from\nsymbol-level to bit-level VNs. Such transformation facilitates the integration\nof the VNs of SCMA and low-density parity-check (LDPC), thereby emerging the\nSCMA and LDPC graphs into a SSG. Subsequently, to further reduce the detection\ncomplexity, the message propagation between SCMA VNs and function nodes (FNs)\nare designed based on EPA principles. Different from the existing iterative\ndetection and decoding (IDD) structure, the proposed EPA-SSG allows a\nsimultaneously detection and decoding at each iteration, and eliminates the use\nof interleavers, de-interleavers, symbol-to-bit, and bit-to-symbol LLR\ntransformations. Simulation results show that the proposed SSG-EPA achieves\nbetter error rate performance compared to the state-of-the-art schemes."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-201",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08949"
    ],
    "b_title":[
      "Self-Supervised Graph Contrastive Pretraining for Device-level\n  Integrated Circuits"
    ],
    "b_abstract":[
      "Self-supervised graph representation learning has driven significant\nadvancements in domains such as social network analysis, molecular design, and\nelectronics design automation (EDA). However, prior works in EDA have mainly\nfocused on the representation of gate-level digital circuits, failing to\ncapture analog and mixed-signal circuits. To address this gap, we introduce\nDICE: Device-level Integrated Circuits Encoder, the first self-supervised\npretrained graph neural network (GNN) model for any circuit expressed at the\ndevice level. DICE is a message-passing neural network (MPNN) trained through\ngraph contrastive learning, and its pretraining process is simulation-free,\nincorporating two novel data augmentation techniques. Experimental results\ndemonstrate that DICE achieves substantial performance gains across three\ndownstream tasks, underscoring its effectiveness for both analog and digital\ncircuits."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03184"
    ],
    "c_title":[
      "PAC Learning with Improvements"
    ],
    "c_abstract":[
      "One of the most basic lower bounds in machine learning is that in nearly any\nnontrivial setting, it takes $\\textit{at least}$ $1\/\\epsilon$ samples to learn\nto error $\\epsilon$ (and more, if the classifier being learned is complex).\nHowever, suppose that data points are agents who have the ability to improve by\na small amount if doing so will allow them to receive a (desired) positive\nclassification. In that case, we may actually be able to achieve\n$\\textit{zero}$ error by just being \"close enough\". For example, imagine a\nhiring test used to measure an agent's skill at some job such that for some\nthreshold $\\theta$, agents who score above $\\theta$ will be successful and\nthose who score below $\\theta$ will not (i.e., learning a threshold on the\nline). Suppose also that by putting in effort, agents can improve their skill\nlevel by some small amount $r$. In that case, if we learn an approximation\n$\\hat{\\theta}$ of $\\theta$ such that $\\theta \\leq \\hat{\\theta} \\leq \\theta + r$\nand use it for hiring, we can actually achieve error zero, in the sense that\n(a) any agent classified as positive is truly qualified, and (b) any agent who\ntruly is qualified can be classified as positive by putting in effort. Thus,\nthe ability for agents to improve has the potential to allow for a goal one\ncould not hope to achieve in standard models, namely zero error.\n  In this paper, we explore this phenomenon more broadly, giving general\nresults and examining under what conditions the ability of agents to improve\ncan allow for a reduction in the sample complexity of learning, or\nalternatively, can make learning harder. We also examine both theoretically and\nempirically what kinds of improvement-aware algorithms can take into account\nagents who have the ability to improve to a limited extent when it is in their\ninterest to do so."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-202",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19720"
    ],
    "b_title":[
      "Analysis of Linear Consensus Algorithm on Strongly Connected Graph Using\n  Effective Resistance"
    ],
    "b_abstract":[
      "We study the performance of the linear consensus algorithm on strongly\nconnected graphs using the linear quadratic (LQ) cost as a performance measure.\n  In particular, we derive bounds on the LQ cost by leveraging effective\nresistance. Our results extend previous analyses -- which were limited to\nreversible cases -- to the nonreversible setting. To facilitate this\ngeneralization, we introduce novel concepts, termed the back-and-forth path and\nthe pivot node, which serve as effective alternatives to traditional techniques\nthat require reversibility. Moreover, we apply our approach to geometric graphs\nto estimate the LQ cost without the reversibility assumption. The proposed\napproach provides a framework that can be adapted to other contexts where\nreversibility is typically assumed."
    ],
    "b_categories":[
      [
        "cs.MA",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07347"
    ],
    "c_title":[
      "A multi-wavelength view of the isolated neutron star eRASSU\n  J065715.3+260428"
    ],
    "c_abstract":[
      "The X-ray source eRASSU J065715.3+260428 was identified as a likely thermally\nemitting isolated neutron star in a search in the SRG\/eROSITA All-Sky Survey.\nWe investigated the nature and evolutionary state of the source through a\ndedicated multi-wavelength follow-up campaign with XMM-Newton, NICER, FAST, and\nESO-VLT, complemented by the analysis of archival Fermi-LAT observations. The\nX-ray observations unveiled the rotation period, $P=261.085400(4)$ ms, and\nspin-down rate, $\\dot{P}=6^{+11}_{-4}\\times10^{-15}$ s s$^{-1}$, of the source.\nNo optical counterparts are detected down to 27.3 mag ($5\\sigma$, R band),\nimplying a large X-ray-to-optical flux ratio above 5200. The X-ray spectrum of\nthe source is best described by a composite phenomenological model consisting\nof two thermal components, either a double blackbody continuum with\ntemperatures 90 eV and 220 eV or a hydrogen neutron star atmosphere of\ntemperature $\\log(T\/\\mathrm{K})\\sim 5.8$ combined with a hot blackbody of 250\neV, in both cases modified by an absorption feature at low energies ($\\sim0.3$\nkeV). The presence of faint non-thermal hard X-ray tails is ruled out above\n$(2.1\\pm1.8)$% of the source unabsorbed flux. Radio searches at $1-1.5$ GHz\nwith FAST yielded negative results, with a deep upper limit on the pulsed flux\nof 1.4 $\\mu$Jy ($10\\sigma$). Similarly, no significant spatial or pulsed\nsignals were detected in sixteen years of Fermi-LAT observations. The source is\nmost likely a middle-aged spin-powered pulsar and can also be identified as PSR\nJ0657+2604. The absence of non-thermal X-ray, radio, or gamma-ray emission\nwithin current limits suggests either an unfavourable viewing geometry or\nunusual magnetospheric properties. Additional observations are needed to check\nfor faint hard X-ray tails, investigate the presence of diffuse emission from a\npulsar-wind nebula, and obtain a more accurately sampled timing solution."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-203",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03705"
    ],
    "b_title":[
      "Correlation time in extremal self-organized critical models"
    ],
    "b_abstract":[
      "We investigate correlation time numerically in extremal self-organized\ncritical models, namely, the Bak-Sneppen evolution and the Robin Hood dynamics.\nThe (fitness) correlation time is the duration required for the extinction or\nmutation of species over the entire spatial region in the critical state. We\napply the methods of finite-size scaling and extreme value theory to understand\nthe statistics of the correlation time. We find power-law system size scaling\nbehaviors for the mean, the variance, the mode, and the peak probability of the\ncorrelation time. We obtain data collapse for the correlation time cumulative\nprobability distribution, and the scaling function follows the generalized\nextreme value density close to the Gumbel function."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08129"
    ],
    "c_title":[
      "Automatic Live Music Song Identification Using Multi-level Deep Sequence\n  Similarity Learning"
    ],
    "c_abstract":[
      "This paper studies the novel problem of automatic live music song\nidentification, where the goal is, given a live recording of a song, to\nretrieve the corresponding studio version of the song from a music database. We\npropose a system based on similarity learning and a Siamese convolutional\nneural network-based model. The model uses cross-similarity matrices of\nmulti-level deep sequences to measure musical similarity between different\naudio tracks. A manually collected custom live music dataset is used to test\nthe performance of the system with live music. The results of the experiments\nshow that the system is able to identify 87.4% of the given live music queries."
    ],
    "c_categories":[
      [
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-204",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07515"
    ],
    "b_title":[
      "The Paradox of Success in Evolutionary and Bioinspired Optimization:\n  Revisiting Critical Issues, Key Studies, and Methodological Pathways"
    ],
    "b_abstract":[
      "Evolutionary and bioinspired computation are crucial for efficiently\naddressing complex optimization problems across diverse application domains. By\nmimicking processes observed in nature, like evolution itself, these algorithms\noffer innovative solutions beyond the reach of traditional optimization\nmethods. They excel at finding near-optimal solutions in large, complex search\nspaces, making them invaluable in numerous fields. However, both areas are\nplagued by challenges at their core, including inadequate benchmarking,\nproblem-specific overfitting, insufficient theoretical grounding, and\nsuperfluous proposals justified only by their biological metaphor. This\noverview recapitulates and analyzes in depth the criticisms concerning the lack\nof innovation and rigor in experimental studies within the field. To this end,\nwe examine the judgmental positions of the existing literature in an informed\nattempt to guide the research community toward directions of solid contribution\nand advancement in these areas. We summarize guidelines for the design of\nevolutionary and bioinspired optimizers, the development of experimental\ncomparisons, and the derivation of novel proposals that take a step further in\nthe field. We provide a brief note on automating the process of creating these\nalgorithms, which may help align metaheuristic optimization research with its\nprimary objective (solving real-world problems), provided that our identified\npathways are followed. Our conclusions underscore the need for a sustained push\ntowards innovation and the enforcement of methodological rigor in prospective\nstudies to fully realize the potential of these advanced computational\ntechniques."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09245"
    ],
    "c_title":[
      "On the kissing number of the cross-polytope"
    ],
    "c_abstract":[
      "A new upper bound $\\kappa_T(K_n)\\leq 2.9162^{(1+o(1))n}$ for the translative\nkissing number of the $n$-dimensional cross-polytope $K_n$ is proved, improving\non Hadwiger's bound $\\kappa_T(K_n)\\leq 3^n-1$ from 1957. Furthermore, it is\nshown that there exist kissing configurations satisfying $\\kappa_T(K_n)\\geq\n1.1637^{(1-o(1))n}$, which improves on the previous best lower bound $\n\\kappa_T(K_n)\\geq 1.1348^{(1-o(1))n}$ by Talata. It is also shown that the\nlattice kissing number satisfies $\\kappa_L(K_n)< 12(2^n-1)$ for all $n\\geq 1$,\nand that the lattice $D_4^+$ is the unique lattice, up to signed permutations\nof coordinates, attaining the maximum lattice kissing number $\\kappa_L(K_4)=40$\nin four dimensions."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-205",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07150"
    ],
    "b_title":[
      "Simulating programmable morphing of shape memory polymer beam systems\n  with complex geometry and topology"
    ],
    "b_abstract":[
      "We propose a novel approach to the analysis of programmable geometrically\nexact shear deformable beam systems made of shape memory polymers. The proposed\nmethod combines the viscoelastic Generalized Maxwell model with the Williams,\nLandel and Ferry relaxation principle, enabling the reproduction of the shape\nmemory effect of structural systems featuring complex geometry and topology.\nVery high efficiency is pursued by discretizing the differential problem in\nspace through the isogeometric collocation (IGA-C) method. The method, in\naddition to the desirable attributes of isogeometric analysis (IGA), such as\nexactness of the geometric reconstruction of complex shapes and high-order\naccuracy, circumvents the need for numerical integration since it discretizes\nthe problem in the strong form. Other distinguishing features of the proposed\nformulation are: i) ${\\rm SO}(3)$-consistency for the linearization of the\nproblem and for the time stepping; ii) minimal (finite) rotation\nparametrization, that means only three rotational unknowns are used; iii) no\nadditional unknowns are needed to account for the rate-dependent material\ncompared to the purely elastic case. Through different numerical applications\ninvolving challenging initial geometries, we show that the proposed formulation\npossesses all the sought attributes in terms of programmability of complex\nsystems, geometric flexibility, and high order accuracy."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03373"
    ],
    "c_title":[
      "W-class states-identification and quantification of Bell-CHSH\n  inequalities' violation"
    ],
    "c_abstract":[
      "We discuss a family of W-class states describing three-qubit systems. For\nsuch systems, we analyze the relations between the entanglement measures and\nthe nonlocality parameter for a two-mode mixed state related to the two-qubit\nsubsystem. We find the conditions determining the boundary values of the\nnegativity, parameterized by concurrence, for violating the Bell-CHSH\ninequality. Additionally, we derive the value ranges of the mixedness measure,\nparameterized by concurrence and negativity for the qubit--qubit mixed state,\nguaranteeing the violation and non-violation of the Bell-CHSH inequality."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-206",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02267"
    ],
    "b_title":[
      "A unified framework for pointwise convergence to the initial data of\n  heat equations in metric measure spaces"
    ],
    "b_abstract":[
      "Given a metric measure space $(\\mathcal{X}, d, \\mu)$ satisfying the volume\ndoubling condition, we consider a semigroup $\\{S_t\\}$ and the associated heat\noperator. We propose general conditions on the heat kernel so that the\nsolutions of the associated heat equations attain the initial data pointwise.\nWe demonstrate that these conditions are satisfied by a broad class of\noperators, including the Laplace operators perturbed by a gradient, fractional\nLaplacian, mixed local-nonlocal operators, Laplacian on Riemannian manifolds,\nDunkl Laplacian and many more. In addition, we consider the Laplace operator in\n$\\mathbb{R}^n$ with the Hardy potential and establish a characterization for\nthe pointwise convergence to the initial data. We also prove similar results\nfor the nonhomogeneous equations and showcase an application for the power-type\nnonlinearities."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.17915"
    ],
    "c_title":[
      "A strong-driving toolkit for topological Floquet energy pumps with\n  superconducting circuits"
    ],
    "c_abstract":[
      "Topological Floquet energy pumps -- which use periodic driving to create a\ntopologically protected quantized energy current -- have been proposed and\nstudied theoretically, but have never been observed directly. Previous work\nproposed that such a pump could be realized with a strongly-driven\nsuperconducting qubit coupled to a cavity. Here, we experimentally demonstrate\nthat the proposed hierarchy of energy scales and drive frequencies can be\nrealized using a transmon qubit. We develop an experimental toolkit to realize\nthe adiabatic driving field required for energy pumping using coordinated\nfrequency modulation of the transmon and amplitude modulation of an applied\nresonant microwave drive. With this toolkit, we measure adiabatic evolution of\nthe qubit under the applied field for times comparable to $T_1$, which far\nexceed the bare qubit dephasing time. This result paves the way for direct\nexperimental observation of topological energy pumping."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-207",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04949"
    ],
    "b_title":[
      "Charge sensing of few-electron ZnO double quantum dots probed by\n  radio-frequency reflectometry"
    ],
    "b_abstract":[
      "Zinc oxide (ZnO) has garnered much attention as a promising material for\nquantum devices due to its unique characteristics. To utilize the potential of\nZnO for quantum devices, the development of fundamental technological elements\nsuch as high-speed readout and charge sensing capabilities has become\nessential. In this study, we address these challenges by demonstrating\nradio-frequency (rf) reflectometry and charge sensing in ZnO quantum dots, thus\nadvancing the potential for qubit applications. A device is fabricated on a\nhigh-quality ZnO heterostructure, featuring gate-defined target and sensor\nquantum dots. The sensor dot, integrated into an rf resonator circuit, enables\nthe detection of single-electron charges in the target dots. Using this setup,\nthe formation of few-electron double quantum dots is observed by obtaining\ntheir charge stability diagram. Also, a charge stability diagram with a gate\npulse sequence is measured. We discuss the strong electron correlation in ZnO,\nwhich leads to nearly degenerate spin-singlet and -triplet two-electron states\nin the (0, 2) charge state, and the perspectives on spin-state readout."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14888"
    ],
    "c_title":[
      "The Multi-Faceted Monosemanticity in Multimodal Representations"
    ],
    "c_abstract":[
      "In this paper, we leverage recent advancements in feature monosemanticity to\nextract interpretable features from deep multimodal models, offering a\ndata-driven understanding of modality gaps. Specifically, we investigate CLIP\n(Contrastive Language-Image Pretraining), a prominent visual-language\nrepresentation model trained on extensive image-text pairs. Building upon\ninterpretability tools developed for single-modal models, we extend these\nmethodologies to assess multi-modal interpretability of CLIP features.\nAdditionally, we introduce the Modality Dominance Score (MDS) to attribute the\ninterpretability of each feature to its respective modality. Next, we transform\nCLIP features into a more interpretable space, enabling us to categorize them\ninto three distinct classes: vision features (single-modal), language features\n(single-modal), and visual-language features (cross-modal). Our findings reveal\nthat this categorization aligns closely with human cognitive understandings of\ndifferent modalities. We also demonstrate significant use cases of this\nmodality-specific features including detecting gender bias, adversarial attack\ndefense and text-to-image model editing. These results indicate that\nlarge-scale multimodal models, equipped with task-agnostic interpretability\ntools, offer valuable insights into key connections and distinctions between\ndifferent modalities."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-208",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10221"
    ],
    "b_title":[
      "Modelling Activity Scheduling Behaviour with Deep Generative Machine\n  Learning"
    ],
    "b_abstract":[
      "We model human activity scheduling behaviour using a deep generative machine\nlearning approach. Activity schedules, which represent the activities and\nassociated travel behaviours of individuals, are a core component of many\napplied models in the transport, energy and epidemiology domains. Our data\ndriven approach learns human preferences and scheduling logic without the need\nfor complex interacting combinations of sub-models and custom-rules, this makes\nour approach significantly faster and simpler to operate that existing\napproaches. We find activity schedule data combines aspects of both continuous\nimage data and also discrete text data, requiring novel approaches. We\nadditionally contribute a novel schedule representation and comprehensive\nevaluation framework for generated schedules. Evaluation shows our approach is\nable to rapidly generate large, diverse and realistic synthetic samples of\nactivity schedules."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12942"
    ],
    "c_title":[
      "Predicting the Stability of Geopolymer Activator Solutions for Optimised\n  Synthesis through Thermodynamic Modelling"
    ],
    "c_abstract":[
      "Geopolymers are an emerging class of binding materials used in sustainable\ncements, concretes, and composites. However, despite growing research, the lack\nof standardised processes and stability analyses for formulating activator\nsolutions - a crucial component of geopolymer systems - remains a barrier to\nquality control and research advancement. This study presents an experimentally\nvalidated energy balance with thermodynamic phenomenon mathematically modelled\nfor synthesising consistent geopolymer activator solutions. The model's general\napplicability enables dynamic assessments of user-specified systems, offering\nstability metrics for quality control in laboratory and industrial settings.\nFundamentally, the mathematical model can be used towards batching optimisation\nunder user-defined conditions where dissolution of geopolymer precursors can be\nmaximised via solution preparation and batching optimisation. The model results\nquantify experimentally validated temperature dynamics, thermodynamic\nstability, and process design\/batching optimisation, challenging traditional\npractices in the literature that rely on undefined equilibration periods. Key\nfindings demonstrate that stable, ready-to-use activator solutions can be\nachieved in as little as 1 minute, compared to the typically used 24-hour\nbatching periods. This research paves the way towards standardised activator\nsolution preparation and supports the development of Standard Operating\nProcedures (SOPs) for geopolymer synthesis, promoting consistency and\nscalability in geopolymer technology."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "math.DS",
        "physics.app-ph",
        "physics.chem-ph",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-209",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10417"
    ],
    "b_title":[
      "Simultaneous extension of generalized BT-inverses and core-EP inverses"
    ],
    "b_abstract":[
      "In this paper we introduce the generalized inverse of complex square matrix\nwith respect to other matrix having same size. Some of its representations,\nproperties and characterizations are obtained. Also some new representation\nmatrices of W-weighted BT-inverse and W-weighted core-EP inverse are determined\nas well as characterizations of generalized inverses A A^\\odagger,\nA^{odagger,W}, A^\\diamond, A^{\\diamond,W}."
    ],
    "b_categories":[
      [
        "math.FA",
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.16059"
    ],
    "c_title":[
      "Irreversible thermodynamics and Glansdorff-Prigogine principle derived\n  from stochastic thermodynamics"
    ],
    "c_abstract":[
      "We derive the main equations of irreversible thermodynamic including the\nexpression for the Glansdorff-Prigogine extremal principle from stochastic\nthermodynamics. To this end, we analyze a system that is subject to gradients\nof temperature and external forces that induce the appearance of fluxes of\nseveral sorts and the creation of entropy. We show that the rate of entropy\nproduction is a convex function of the fluxes, from which follows that the\nexcess entropy production is nonnegative, which is an expression of the\nGlansdorff-Prigogine principle. We show that the Lyapunov function associated\nwith the excess entropy production can be identified with a thermodynamic\npotential in the special case where the gradients of temperature are absent."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-210",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09507"
    ],
    "b_title":[
      "When and How Does CLIP Enable Domain and Compositional Generalization?"
    ],
    "b_abstract":[
      "The remarkable generalization performance of contrastive vision-language\nmodels like CLIP is often attributed to the diversity of their training\ndistributions. However, key questions remain unanswered: Can CLIP generalize to\nan entirely unseen domain when trained on a diverse mixture of domains (domain\ngeneralization)? Can it generalize to unseen classes within partially seen\ndomains (compositional generalization)? What factors affect such\ngeneralization? To answer these questions, we trained CLIP models on\nsystematically constructed training distributions with controlled domain\ndiversity and object class exposure. Our experiments show that domain diversity\nis essential for both domain and compositional generalization, yet\ncompositional generalization can be surprisingly weaker than domain\ngeneralization when the training distribution contains a suboptimal subset of\nthe test domain. Through data-centric and mechanistic analyses, we find that\nsuccessful generalization requires learning of shared representations already\nin intermediate layers and shared circuitry."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.13611"
    ],
    "c_title":[
      "Quantum Error Correction and $Z(2)$ Lattice Gauge Theories"
    ],
    "c_abstract":[
      "$Z(2)$ lattice gauge theory plays an important role in the study of the\nthreshold probability of Quantum Error Correction (QEC) for a quantum code. For\ncertain QEC codes, such as the well-known Kitaev's toric\/surface code, one can\nfind a mapping of the QEC decoding problem onto a statistical mechanics model\nfor a given noise model. The investigation of the threshold probability then\ncorresponds to that of the phase diagram of the mapped statistical mechanics\nmodel. This can be studied by Monte Carlo simulation of the statistical\nmechanics model. In~\\cite{Rispler}, we investigate the effects of realistic\nnoise models on the toric\/surface code in two dimensions together with syndrome\nmeasurement noise and introduce the random coupled-plaquette gauge model,\n3-dimensional $Z(2) \\times Z(2)$ lattice gauge theory. This new Z(2) gauge\ntheory model captures main aspects of toric\/surface code under depolarizing and\nsyndrome noise. In these proceedings, we mainly focus on the aspects of Mont\nCarlo simulation and discuss preliminary results from Monte Carlo simulations\nof mapped classes of Z(2) lattice theories."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-211",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13154"
    ],
    "b_title":[
      "Evolution of a trait distributed over a large fragmented population:\n  Propagation of chaos meets adaptive dynamics"
    ],
    "b_abstract":[
      "We consider a metapopulation made up of $K$ demes, each containing $N$\nindividuals bearing a heritable quantitative trait. Demes are connected by\nmigration and undergo independent Moran processes with mutation and selection\nbased on trait values. Mutation and migration rates are tuned so that each deme\nreceives a migrant or a mutant in the same slow timescale and is thus\nessentially monomorphic at all times for the trait (adaptive dynamics). In the\ntimescale of mutation\/migration, the metapopulation can then be seen as a giant\nspatial Moran model with size $K$ that we characterize. As $K\\to \\infty$ and\nphysical space becomes continuous, the empirical distribution of the trait\n(over the physical and trait spaces) evolves deterministically according to an\nintegro-differential evolution equation. In this limit, the trait of every\nmigrant is drawn from this global distribution, so that conditional on its\ninitial state, traits from finitely many demes evolve independently\n(propagation of chaos). Under mean-field dispersal, the value $X_t$ of the\ntrait at time $t$ and at any given location has a law denoted $\\mu_t$ and a\njump kernel with two terms: a mutation-fixation term and a migration-fixation\nterm involving $\\mu_{t-}$ (McKean-Vlasov equation). In the limit where\nmutations have small effects and migration is further slowed down accordingly,\nwe obtain the convergence of $X$, in the new migration timescale, to the\nsolution of a stochastic differential equation which can be referred to as a\nnew canonical equation of adaptive dynamics. This equation includes an\nadvection term representing selection, a diffusive term due to genetic drift,\nand a jump term, representing the effect of migration, to a state distributed\naccording to its own law."
    ],
    "b_categories":[
      [
        "math.PR",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2502.17318"
    ],
    "c_title":[
      "Modelling conductive thermal transport in three-dimensional fibrous\n  media with fiber-to-fiber contacts"
    ],
    "c_abstract":[
      "Understanding heat transfers in fibrous materials, particularly conduction,\nis a major challenge due to their heterogeneous and multiscale nature, and the\nunknown contribution of fiber-to-fiber contacts. In most previous modelling\nstudies, the existence of thermal contact resistance is not considered, and the\ncomputational complexity often limits the size of simulated samples, which\nleads to imprecise of inaccurate predictions. The same problem arises when\nconsidering electrical conduction through fibrous materials. In this work, we\ndescribe a computationally efficient simulation approach based on multi-nodal\nrepresentation to analyze the steady-state heat conduction through the solid\nstructure in numerically generated 3D nanofiber networks, including contact\nresistance. We show that the solid conductivity in these networks is governed\nby a master curve that depends on a single parameter: a characteristic ratio\nrepresenting the interplay between fiber intrinsic conductivity and contact\nresistance as well as the influence of other geometric parameters, which\nnumerically validates previous theoretical studies. However, we observe a\ndeviation to this established theory for poorly-connected networks. We derive\nan expression for a correction factor, considering the influence of\ncorrelations between fiber temperatures, and we find then good agreement with\nour simulation data. Our results demonstrate that the solid conductivity can be\nfully predicted based on geometric quantities, regardless of the extent of\nnetwork connectivity, thus generalizing previous studies on this topic. This\nwork, contributing to improve our understanding of conductive heat transport in\nfibrous media, may prove useful in the development of accurate predictive\nmodels and optimization strategies for fibrous insulation materials."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-212",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12698"
    ],
    "b_title":[
      "A Continual Learning-driven Model for Accurate and Generalizable\n  Segmentation of Clinically Comprehensive and Fine-grained Whole-body\n  Anatomies in CT"
    ],
    "b_abstract":[
      "Precision medicine in the quantitative management of chronic diseases and\noncology would be greatly improved if the Computed Tomography (CT) scan of any\npatient could be segmented, parsed and analyzed in a precise and detailed way.\nHowever, there is no such fully annotated CT dataset with all anatomies\ndelineated for training because of the exceptionally high manual cost, the need\nfor specialized clinical expertise, and the time required to finish the task.\nTo this end, we proposed a novel continual learning-driven CT model that can\nsegment complete anatomies presented using dozens of previously partially\nlabeled datasets, dynamically expanding its capacity to segment new ones\nwithout compromising previously learned organ knowledge. Existing multi-dataset\napproaches are not able to dynamically segment new anatomies without\ncatastrophic forgetting and would encounter optimization difficulty or\ninfeasibility when segmenting hundreds of anatomies across the whole range of\nbody regions. Our single unified CT segmentation model, CL-Net, can highly\naccurately segment a clinically comprehensive set of 235 fine-grained\nwhole-body anatomies. Composed of a universal encoder, multiple optimized and\npruned decoders, CL-Net is developed using 13,952 CT scans from 20 public and\n16 private high-quality partially labeled CT datasets of various vendors,\ndifferent contrast phases, and pathologies. Extensive evaluation demonstrates\nthat CL-Net consistently outperforms the upper limit of an ensemble of 36\nspecialist nnUNets trained per dataset with the complexity of 5% model size and\nsignificantly surpasses the segmentation accuracy of recent leading Segment\nAnything-style medical image foundation models by large margins. Our continual\nlearning-driven CL-Net model would lay a solid foundation to facilitate many\ndownstream tasks of oncology and chronic diseases using the most widely adopted\nCT imaging."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13673"
    ],
    "c_title":[
      "Fault-tolerant Preparation of Distant Logical Bell Pair -- with\n  application in the magic square game"
    ],
    "c_abstract":[
      "Measures of quantum nonlocality traditionally assume perfect local\ncomputation. In real experiments, however, each computational primitive is\nimperfect. Fault-tolerant techniques enable arbitrarily accurate quantum\ncomputation but do not necessarily preserve optimized measures of nonlocality.\nWe examine the impact of low noise on quantum nonlocality in nonlocal games,\nwhere even small imperfections can disproportionately increase entanglement\nconsumption. Focusing on the fault-tolerant magic square game, we optimize the\ntradeoff between noisy entanglement consumption and deficit in the game value.\nWe introduce an interface circuit and logical entanglement purification\nprotocol (EPP) to efficiently translate states between physical and logical\nqubits and purify noisy logical Bell pair, reducing Bell pair consumption. Our\nanalytical and numerical results, particularly for the $[[7^k,1,3^k]]$\nconcatenated Steane code, demonstrate exponential Bell pair savings and a\nhigher noise threshold. We establish theoretical lower bounds for local noise\nthreshold of $4.70\\times10^{-4}$ and an initial Bell pair infidelity threshold\nof $18.3\\%$. Our framework is adaptable to various quantum error-correcting\ncodes (QECCs) and experimental platforms. This work not only advances\nfault-tolerant nonlocal games but also inspires further research on interfacing\ndifferent QECCs, fostering modular quantum architectures and the quantum\ninternet."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-213",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12047"
    ],
    "b_title":[
      "Quantum Byzantine Multiple Access Channels"
    ],
    "b_abstract":[
      "In communication theory, attacks like eavesdropping or jamming are typically\nassumed to occur at the channel level, while communication parties are expected\nto follow established protocols. But what happens if one of the parties turns\nmalicious? In this work, we investigate a compelling scenario: a\nmultiple-access channel with two transmitters and one receiver, where one\ntransmitter deviates from the protocol and acts dishonestly. To address this\nchallenge, we introduce the Byzantine multiple-access classical-quantum channel\nand derive an achievable communication rate for this adversarial setting."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16990"
    ],
    "c_title":[
      "Preserving Lefschetz properties after extension of variables"
    ],
    "c_abstract":[
      "Consider a standard graded artinian $k$-algebra $B$ and an extension of $B$\nby a new variable, $A=B\\otimes_k k[x]\/(x^d)$ for some $d\\geq 1$. We will show\nhow maximal rank properties for powers of a general linear form on $A$ can be\ndetermined by maximal rank properties for different powers of general linear\nforms on $B$. This is then used to study Lefschetz properties of algebras that\ncan be obtained via such extensions. In particular, it allows for a new proof\nthat monomial complete intersections have the strong Lefschetz property over a\nfield of characteristic zero. Moreover, it gives a recursive formula for the\ndeterminants that show up in that case. Finally, for algebras over a field of\ncharacteristic zero, we give a classification for what properties $B$ must have\nfor all extensions $B\\otimes_k k[x]\/(x^d)$ to have the weak or the strong\nLefschetz property."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-214",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06314"
    ],
    "b_title":[
      "Observation of Two Cascading Screening Processes in an Iron-based\n  Superconductor"
    ],
    "b_abstract":[
      "Understanding how renormalized quasiparticles emerge in strongly correlated\nelectron materials provides a challenge for both experiment and theory. It has\nbeen predicted that distinctive spin and orbital screening mechanisms drive\nthis process in multiorbital materials with strong Coulomb and Hund's\ninteractions. Here, we provide the experimental evidence of both mechanisms\nfrom angle-resolved photoemission spectroscopy on RbFe$_2$As$_2$. We observe\nthat the emergence of low-energy Fe 3$d_{xy}$ quasiparticles below 90K is tied\nto spin screening. A second process changes the spectral weight at high\nenergies up to room temperature. Supported by theoretical calculations we\nattribute it to orbital screening of Fe 3d atomic excitations. These two\ncascading screening processes drive the temperature evolution from a bad metal\nto a correlated Fermi liquid."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.07117"
    ],
    "c_title":[
      "Optimal convergence of the arbitrary Lagrangian-Eulerian interface\n  tracking method for two-phase Navier--Stokes flow without surface tension"
    ],
    "c_abstract":[
      "Optimal-order convergence in the $H^1$ norm is proved for an arbitrary\nLagrangian-Eulerian interface tracking finite element method for the sharp\ninterface model of two-phase Navier-Stokes flow without surface tension, using\nhigh-order curved evolving mesh. In this method, the interfacial mesh points\nmove with the fluid's velocity to track the sharp interface between two phases\nof the fluid, and the interior mesh points move according to a harmonic\nextension of the interface velocity. The error of the semidiscrete arbitrary\nLagrangian-Eulerian interface tracking finite element method is shown to be\n$O(h^k)$ in the $L^\\infty(0, T; H^1(\\Omega))$ norm for the Taylor-Hood finite\nelements of degree $k \\ge 2$. This high-order convergence is achieved by\nutilizing the piecewise smoothness of the solution on each subdomain occupied\nby one phase of the fluid, relying on a low global regularity on the entire\nmoving domain. Numerical experiments illustrate and complement the theoretical\nresults."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-215",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07358"
    ],
    "b_title":[
      "Deep Generative Clustering with VAEs and Expectation-Maximization"
    ],
    "b_abstract":[
      "We propose a novel deep clustering method that integrates Variational\nAutoencoders (VAEs) into the Expectation-Maximization (EM) framework. Our\napproach models the probability distribution of each cluster with a VAE and\nalternates between updating model parameters by maximizing the Evidence Lower\nBound (ELBO) of the log-likelihood and refining cluster assignments based on\nthe learned distributions. This enables effective clustering and generation of\nnew samples from each cluster. Unlike existing VAE-based methods, our approach\neliminates the need for a Gaussian Mixture Model (GMM) prior or additional\nregularization techniques. Experiments on MNIST and FashionMNIST demonstrate\nsuperior clustering performance compared to state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01360"
    ],
    "c_title":[
      "Groups with a covering condition on commutators"
    ],
    "c_abstract":[
      "Given a group G and positive integers k,n, we let B_n=B_n(G) denote the set\nof all elements x in G such that |x^G|\\leq n, and we say that G satisfies the\n(k,n)-covering condition for commutators if there is a subset S in G such that\n|S|\\leq k and all commutators of G are contained in the product SB_n. The\nimportance of groups satisfying this condition was revealed in the recent study\nof probabilistically nilpotent finite groups of class two. The main result\nobtained in this paper is the following theorem.\n  Let G be a group satisfying the (k,n)-covering condition for commutators.\nThen G' contains a characteristic subgroup B such that [G':B] and |B'| are both\n(k,n)-bounded.\n  This extends several earlier results of similar flavour."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-216",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00392"
    ],
    "b_title":[
      "RefDrone: A Challenging Benchmark for Referring Expression Comprehension\n  in Drone Scenes"
    ],
    "b_abstract":[
      "Drones have become prevalent robotic platforms with diverse applications,\nshowing significant potential in Embodied Artificial Intelligence (Embodied\nAI). Referring Expression Comprehension (REC) enables drones to locate objects\nbased on natural language expressions, a crucial capability for Embodied AI.\nDespite advances in REC for ground-level scenes, aerial views introduce unique\nchallenges including varying viewpoints, occlusions and scale variations. To\naddress this gap, we introduce RefDrone, a REC benchmark for drone scenes.\nRefDrone reveals three key challenges in REC: 1) multi-scale and small-scale\ntarget detection; 2) multi-target and no-target samples; 3) complex environment\nwith rich contextual expressions. To efficiently construct this dataset, we\ndevelop RDAgent (referring drone annotation framework with multi-agent system),\na semi-automated annotation tool for REC tasks. RDAgent ensures high-quality\ncontextual expressions and reduces annotation cost. Furthermore, we propose\nNumber GroundingDINO (NGDINO), a novel method designed to handle multi-target\nand no-target cases. NGDINO explicitly learns and utilizes the number of\nobjects referred to in the expression. Comprehensive experiments with\nstate-of-the-art REC methods demonstrate that NGDINO achieves superior\nperformance on both the proposed RefDrone and the existing gRefCOCO datasets.\nThe dataset and code will be publicly at\nhttps:\/\/github.com\/sunzc-sunny\/refdrone."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12041"
    ],
    "c_title":[
      "A strongly polynomial-time algorithm for the general linear programming\n  problem"
    ],
    "c_abstract":[
      "This article presents a strongly polynomial-time algorithm for the general\nlinear programming problem. This algorithm is an implicit reduction procedure\nthat works as follows. Primal and dual problems are combined into a special\nsystem of linear equations constrained by complementarity relations and\nnon-negative variables. Each iteration of the algorithm consists of applying a\npair of complementary Gauss-Jordan pivoting operations, guided by a\nnecessary-condition lemma. The algorithm requires no more than k+n iterations,\nas there are only k+n complementary pairs of columns to compare\none-pair-at-a-time, where k is the number of constraints and n is the number of\nvariables of given general linear programming problem. Numerical illustration\nis given that includes an instance of a classical problem of Klee and Minty and\na problem of Beale."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-217",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03656"
    ],
    "b_title":[
      "A Study in Dataset Distillation for Image Super-Resolution"
    ],
    "b_abstract":[
      "Dataset distillation is the concept of condensing large datasets into smaller\nbut highly representative synthetic samples. While previous research has\nprimarily focused on image classification, its application to image\nSuper-Resolution (SR) remains underexplored. This exploratory work studies\nmultiple dataset distillation techniques applied to SR, including pixel- and\nlatent-space approaches under different aspects. Our experiments demonstrate\nthat a 91.12% dataset size reduction can be achieved while maintaining\ncomparable SR performance to the full dataset. We further analyze\ninitialization strategies and distillation methods to optimize memory\nefficiency and computational costs. Our findings provide new insights into\ndataset distillation for SR and set the stage for future advancements."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13287"
    ],
    "c_title":[
      "A convexity preserving nonconvex regularization for inverse problems\n  under non-Gaussian noise"
    ],
    "c_abstract":[
      "We propose a nonconvexly regularized convex model for linear regression\nproblems under non-Gaussian noise. The cost function of the proposed model is\ndesigned with a possibly non-quadratic data fidelity term and a nonconvex\nregularizer via the generalized Moreau enhancement of a seed convex\nregularizer. We present sufficient conditions (i) for the cost function of the\nproposed model to be convex over the entire space, and (ii) for the existence\nof a minimizer of the proposed model. Under such conditions, we propose a\nproximal splitting type algorithm with guaranteed convergence to a global\nminimizer of the proposed model. As an application, we enhance nonconvexly a\nconvex sparsity-promoting regularizer in a scenario of simultaneous declipping\nand denoising."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-218",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15246"
    ],
    "b_title":[
      "Variational Message Passing-based Multiobject Tracking for MIMO-Radars\n  using Raw Sensor Signals"
    ],
    "b_abstract":[
      "In this paper, we propose a direct multiobject tracking (MOT) approach for\nMIMO-radar signals that operates on raw sensor data via variational message\npassing (VMP). Unlike classical track-before-detect (TBD) methods, which often\nrely on simplified likelihood models and exclude nuisance parameters (e.g.,\nobject amplitudes, noise variance), our method adopts a superimposed signal\nmodel and employs a mean-field approximation to jointly estimate both object\nexistence and object states. By considering correlations within in the radar\nsignal due to closely spaced objects and jointly estimating nuisance\nparameters, the proposed method achieves robust performance for close-by\nobjects and in low-signal-to-noise ratio (SNR) regimes. Our numerical\nevaluation based on MIMO-radar signals demonstrate that our VMP-based\ndirect-MOT method outperforms a detect-then-track (DTT) pipeline comprising a\nsuper-resolution sparse Bayesian learning (SBL)-based estimation stage followed\nby classical MOT using global nearest neighbour data association and a Kalman\nfilter."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14646"
    ],
    "c_title":[
      "Determining a credit transition matrix from cumulative default\n  probabilities"
    ],
    "c_abstract":[
      "To quantify the changes in the credit rating of a bond is an important\nmathematical problem for the credit rating industry. To think of the credit\nrating as the state a Markov chain is an interesting proposal leading to\nchallenges in mathematical modeling. Since cumulative default rates are more\nreadily measurable than credit migrations, a natural question is whether the\ncredit transition matrix (CTM) can be determined from the knowledge of the\ncumulative default probabilities.\n  Here we use a connection between the CTM and the cumulative default\nprobabilities to setup an ill-posed, linear inverse problem with box\nconstraints, which we solve by an entropy minimization procedure. This approach\nis interesting on several counts. On the one hand, we may have less data that\nunknowns, and on the other hand, even when we have as much data as unknowns,\nthe matrix connecting them may not be invertible, which makes the problem\nill-posed.\n  Besides developing the tools to solve the problem, we apply it to several\ntest cases to check the performance of the method. The results are quite\nsatisfactory."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-219",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13806"
    ],
    "b_title":[
      "Organ-aware Multi-scale Medical Image Segmentation Using Text Prompt\n  Engineering"
    ],
    "b_abstract":[
      "Accurate segmentation is essential for effective treatment planning and\ndisease monitoring. Existing medical image segmentation methods predominantly\nrely on uni-modal visual inputs, such as images or videos, requiring\nlabor-intensive manual annotations. Additionally, medical imaging techniques\ncapture multiple intertwined organs within a single scan, further complicating\nsegmentation accuracy. To address these challenges, MedSAM, a large-scale\nmedical segmentation model based on the Segment Anything Model (SAM), was\ndeveloped to enhance segmentation accuracy by integrating image features with\nuser-provided prompts. While MedSAM has demonstrated strong performance across\nvarious medical segmentation tasks, it primarily relies on geometric prompts\n(e.g., points and bounding boxes) and lacks support for text-based prompts,\nwhich could help specify subtle or ambiguous anatomical structures. To overcome\nthese limitations, we propose the Organ-aware Multi-scale Text-guided Medical\nImage Segmentation Model (OMT-SAM) for multi-organ segmentation. Our approach\nintroduces CLIP encoders as a novel image-text prompt encoder, operating with\nthe geometric prompt encoder to provide informative contextual guidance. We\npair descriptive textual prompts with corresponding images, processing them\nthrough pre-trained CLIP encoders and a cross-attention mechanism to generate\nfused image-text embeddings. Additionally, we extract multi-scale visual\nfeatures from MedSAM, capturing fine-grained anatomical details at different\nlevels of granularity. We evaluate OMT-SAM on the FLARE 2021 dataset,\nbenchmarking its performance against existing segmentation methods. Empirical\nresults demonstrate that OMT-SAM achieves a mean Dice Similarity Coefficient of\n0.937, outperforming MedSAM (0.893) and other segmentation models, highlighting\nits superior capability in handling complex medical image segmentation tasks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12116"
    ],
    "c_title":[
      "Efficient PINNs: Multi-Head Unimodular Regularization of the Solutions\n  Space"
    ],
    "c_abstract":[
      "We present a machine learning framework to facilitate the solution of\nnonlinear multiscale differential equations and, especially, inverse problems\nusing Physics-Informed Neural Networks (PINNs). This framework is based on what\nis called multihead (MH) training, which involves training the network to learn\na general space of all solutions for a given set of equations with certain\nvariability, rather than learning a specific solution of the system. This setup\nis used with a second novel technique that we call Unimodular Regularization\n(UR) of the latent space of solutions. We show that the multihead approach,\ncombined with the regularization, significantly improves the efficiency of\nPINNs by facilitating the transfer learning process thereby enabling the\nfinding of solutions for nonlinear, coupled, and multiscale differential\nequations."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "hep-th",
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-220",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04164"
    ],
    "b_title":[
      "Efficient Distributed Optimization under Heavy-Tailed Noise"
    ],
    "b_abstract":[
      "Distributed optimization has become the default training paradigm in modern\nmachine learning due to the growing scale of models and datasets. To mitigate\ncommunication overhead, local updates are often applied before global\naggregation, resulting in a nested optimization approach with inner and outer\nsteps. However, heavy-tailed stochastic gradient noise remains a significant\nchallenge, particularly in attention-based models, hindering effective\ntraining. In this work, we propose TailOPT, an efficient framework designed to\naddress heavy-tailed noise by leveraging adaptive optimization or clipping\ntechniques. We establish convergence guarantees for the TailOPT framework under\nheavy-tailed noise with potentially unbounded gradient variance and local\nupdates. Among its variants, we highlight a memory and communication efficient\ninstantiation which we call $Bi^2Clip$, which performs coordinate-wise clipping\nat both the inner and outer optimizers, achieving adaptive-like performance\n(e.g., Adam) without the cost of maintaining or transmitting additional\ngradient statistics. Empirically, TailOPT, including $Bi^2Clip$, demonstrates\nsuperior performance on several language tasks and models, outperforming\nstate-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19574"
    ],
    "c_title":[
      "Leveraging Retrieval-Augmented Generation and Large Language Models to\n  Predict SERCA-Binding Protein Fragments from Cardiac Proteomics Data"
    ],
    "c_abstract":[
      "Large language models (LLMs) have shown promise in various natural language\nprocessing tasks, including their application to proteomics data to classify\nprotein fragments. In this study, we curated a limited mass spectrometry\ndataset with 1000s of protein fragments, consisting of proteins that appear to\nbe attached to the endoplasmic reticulum in cardiac cells, of which a fraction\nwas cloned and characterized for their impact on SERCA, an ER calcium pump.\nWith this limited dataset, we sought to determine whether LLMs could correctly\npredict whether a new protein fragment could bind SERCA, based only on its\nsequence and a few biophysical characteristics, such as hydrophobicity,\ndetermined from that sequence. To do so, we generated random sequences based on\ncloned fragments, embedded the fragments into a retrieval augmented generation\n(RAG) database to group them by similarity, then fine-tuned large language\nmodel (LLM) prompts to predict whether a novel sequence could bind SERCA. We\nbenchmarked this approach using multiple open-source LLMs, namely the\nMeta\/llama series, and embedding functions commonly available on the\nHuggingface repository. We then assessed the generalizability of this approach\nin classifying novel protein fragments from mass spectrometry that were not\ninitially cloned for functional characterization. By further tuning the prompt\nto account for motifs, such as ER retention sequences, we improved the\nclassification accuracy by and identified several proteins predicted to\nlocalize to the endoplasmic reticulum and bind SERCA, including Ribosomal\nProtein L2 and selenoprotein S. Although our results were based on proteomics\ndata from cardiac cells, our approach demonstrates the potential of LLMs in\nidentifying novel protein interactions and functions with very limited\nproteomic data."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-221",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16639"
    ],
    "b_title":[
      "Whenever, Wherever: Towards Orchestrating Crowd Simulations with\n  Spatio-Temporal Spawn Dynamics"
    ],
    "b_abstract":[
      "Realistic crowd simulations are essential for immersive virtual environments,\nrelying on both individual behaviors (microscopic dynamics) and overall crowd\npatterns (macroscopic characteristics). While recent data-driven methods like\ndeep reinforcement learning improve microscopic realism, they often overlook\ncritical macroscopic features such as crowd density and flow, which are\ngoverned by spatio-temporal spawn dynamics, namely, when and where agents enter\na scene. Traditional methods, like random spawn rates, stochastic processes, or\nfixed schedules, are not guaranteed to capture the underlying complexity or\nlack diversity and realism. To address this issue, we propose a novel approach\ncalled nTPP-GMM that models spatio-temporal spawn dynamics using Neural\nTemporal Point Processes (nTPPs) that are coupled with a spawn-conditional\nGaussian Mixture Model (GMM) for agent spawn and goal positions. We evaluate\nour approach by orchestrating crowd simulations of three diverse real-world\ndatasets with nTPP-GMM. Our experiments demonstrate the orchestration with\nnTPP-GMM leads to realistic simulations that reflect real-world crowd scenarios\nand allow crowd analysis."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01853"
    ],
    "c_title":[
      "A self-learning magnetic Hopfield neural network with intrinsic gradient\n  descent adaption"
    ],
    "c_abstract":[
      "Physical neural networks using physical materials and devices to mimic\nsynapses and neurons offer an energy-efficient way to implement artificial\nneural networks. Yet, training physical neural networks are difficult and\nheavily relies on external computing resources. An emerging concept to solve\nthis issue is called physical self-learning that uses intrinsic physical\nparameters as trainable weights. Under external inputs (i.e. training data),\ntraining is achieved by the natural evolution of physical parameters that\nintrinsically adapt modern learning rules via autonomous physical process,\neliminating the requirements on external computation resources.Here, we\ndemonstrate a real spintronic system that mimics Hopfield neural networks (HNN)\nand unsupervised learning is intrinsically performed via the evolution of\nphysical process. Using magnetic texture defined conductance matrix as\ntrainable weights, we illustrate that under external voltage inputs, the\nconductance matrix naturally evolves and adapts Oja's learning algorithm in a\ngradient descent manner. The self-learning HNN is scalable and can achieve\nassociative memories on patterns with high similarities. The fast spin dynamics\nand reconfigurability of magnetic textures offer an advantageous platform\ntowards efficient autonomous training directly in materials."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-222",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12624"
    ],
    "b_title":[
      "Implicit Repair with Reinforcement Learning in Emergent Communication"
    ],
    "b_abstract":[
      "Conversational repair is a mechanism used to detect and resolve\nmiscommunication and misinformation problems when two or more agents interact.\nOne particular and underexplored form of repair in emergent communication is\nthe implicit repair mechanism, where the interlocutor purposely conveys the\ndesired information in such a way as to prevent misinformation from any other\ninterlocutor. This work explores how redundancy can modify the emergent\ncommunication protocol to continue conveying the necessary information to\ncomplete the underlying task, even with additional external environmental\npressures such as noise. We focus on extending the signaling game, called the\nLewis Game, by adding noise in the communication channel and inputs received by\nthe agents. Our analysis shows that agents add redundancy to the transmitted\nmessages as an outcome to prevent the negative impact of noise on the task\nsuccess. Additionally, we observe that the emerging communication protocol's\ngeneralization capabilities remain equivalent to architectures employed in\nsimpler games that are entirely deterministic. Additionally, our method is the\nonly one suitable for producing robust communication protocols that can handle\ncases with and without noise while maintaining increased generalization\nperformance levels."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18391"
    ],
    "c_title":[
      "New insights into the distribution of the topmost gap in random walks\n  and L\\'evy flights"
    ],
    "c_abstract":[
      "Building upon the knowledge of the distribution of the first positive\nposition reached by a random walker starting from the origin, one can derive\nnew results on the statistics of the gap between the largest and second-largest\npositions of the walk, and recover known ones in a more direct manner."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-223",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09559"
    ],
    "b_title":[
      "Threshold Quantum Secret Sharing"
    ],
    "b_abstract":[
      "One crucial and basic method for disclosing a secret to every participant in\nquantum cryptography is quantum secret sharing. Numerous intricate protocols,\nincluding secure multiparty summation, multiplication, sorting, voting, and\nmore, can be designed with it. A quantum secret sharing protocol with a $(t,n)$\nthreshold approach and modulo d, where t and n represent the threshold number\nof participants and the total number of participants, respectively was recently\ndiscussed by Song et al. Kao et al. notes that without the information of other\nparticipants, the secret in Song {\\em et al.'s}protocol cannot be\nreconstructed. We address a protocol that solves this issue in this paper."
    ],
    "b_categories":[
      [
        "cs.CR",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07109"
    ],
    "c_title":[
      "The Quest for Visual Understanding: A Journey Through the Evolution of\n  Visual Question Answering"
    ],
    "c_abstract":[
      "Visual Question Answering (VQA) is an interdisciplinary field that bridges\nthe gap between computer vision (CV) and natural language processing(NLP),\nenabling Artificial Intelligence(AI) systems to answer questions about images.\nSince its inception in 2015, VQA has rapidly evolved, driven by advances in\ndeep learning, attention mechanisms, and transformer-based models. This survey\ntraces the journey of VQA from its early days, through major breakthroughs,\nsuch as attention mechanisms, compositional reasoning, and the rise of\nvision-language pre-training methods. We highlight key models, datasets, and\ntechniques that shaped the development of VQA systems, emphasizing the pivotal\nrole of transformer architectures and multimodal pre-training in driving recent\nprogress. Additionally, we explore specialized applications of VQA in domains\nlike healthcare and discuss ongoing challenges, such as dataset bias, model\ninterpretability, and the need for common-sense reasoning. Lastly, we discuss\nthe emerging trends in large multimodal language models and the integration of\nexternal knowledge, offering insights into the future directions of VQA. This\npaper aims to provide a comprehensive overview of the evolution of VQA,\nhighlighting both its current state and potential advancements."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-224",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13606"
    ],
    "b_title":[
      "LaVCa: LLM-assisted Visual Cortex Captioning"
    ],
    "b_abstract":[
      "Understanding the property of neural populations (or voxels) in the human\nbrain can advance our comprehension of human perceptual and cognitive\nprocessing capabilities and contribute to developing brain-inspired computer\nmodels. Recent encoding models using deep neural networks (DNNs) have\nsuccessfully predicted voxel-wise activity. However, interpreting the\nproperties that explain voxel responses remains challenging because of the\nblack-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex\nCaptioning (LaVCa), a data-driven approach that uses large language models\n(LLMs) to generate natural-language captions for images to which voxels are\nselective. By applying LaVCa for image-evoked brain activity, we demonstrate\nthat LaVCa generates captions that describe voxel selectivity more accurately\nthan the previously proposed method. Furthermore, the captions generated by\nLaVCa quantitatively capture more detailed properties than the existing method\nat both the inter-voxel and intra-voxel levels. Furthermore, a more detailed\nanalysis of the voxel-specific properties generated by LaVCa reveals\nfine-grained functional differentiation within regions of interest (ROIs) in\nthe visual cortex and voxels that simultaneously represent multiple distinct\nconcepts. These findings offer profound insights into human visual\nrepresentations by assigning detailed captions throughout the visual cortex\nwhile highlighting the potential of LLM-based methods in understanding brain\nrepresentations. Please check out our webpage at\nhttps:\/\/sites.google.com\/view\/lavca-llm\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.06498"
    ],
    "c_title":[
      "Simplices in $t$-intersecting families for vector spaces"
    ],
    "c_abstract":[
      "Let $V$ be an $n$-dimensional vector space over the finite field\n$\\mathbb{F}_q$ and ${V\\brack k}$ denote the family of all $k$-dimensional\nsubspaces of $V$. A family $\\mathcal{F}\\subseteq {V\\brack k}$ is called\n$k$-uniform $r$-wise $t$-intersecting if for any $F_1, F_2, \\dots, F_r \\in\n\\mathcal{F}$, we have $\\dim\\left(\\bigcap_{i=1}^r F_i \\right) \\geq t$. An\n$r$-wise $t$-intersecting family $\\{X_1, X_2, \\dots, X_{r+1}\\}$ is called a\n$(r+1,t)$-simplex if $\\dim\\left(\\bigcap_{i=1}^{r+1} X_i \\right) < t$, denoted\nby $\\Delta_{r+1,t}$. Notice that it is usually called triangle when $r=2$ and\n$t=1$. For $k \\geq t \\geq 1$, $r \\geq 2$ and $n \\geq 3kr^2 + 3krt$, we prove\nthat the maximal number of $\\Delta_{r+1,t}$ in a $k$-uniform $r$-wise\n$t$-intersecting subspace family of $V$ is at most $n_{t+r,k}$, and we describe\nall the extreme families. Furthermore, we have the extremal structure of\n$k$-uniform intersecting families maximizing the number of triangles for $n\\geq\n2k+9$ as a corollary."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-225",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03618"
    ],
    "b_title":[
      "The Logical Implication Steering Method for Conditional Interventions on\n  Transformer Generation"
    ],
    "b_abstract":[
      "The field of mechanistic interpretability in pre-trained transformer models\nhas demonstrated substantial evidence supporting the ''linear representation\nhypothesis'', which is the idea that high level concepts are encoded as vectors\nin the space of activations of a model. Studies also show that model generation\nbehavior can be steered toward a given concept by adding the concept's vector\nto the corresponding activations. We show how to leverage these properties to\nbuild a form of logical implication into models, enabling transparent and\ninterpretable adjustments that induce a chosen generation behavior in response\nto the presence of any given concept. Our method, Logical Implication Model\nSteering (LIMS), unlocks new hand engineered reasoning capabilities by\nintegrating neuro-symbolic logic into pre-trained transformer models."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01254"
    ],
    "c_title":[
      "Heitler effect and resonance fluorescence in quantum magnonics"
    ],
    "c_abstract":[
      "We consider a coupled system of a qubit and a magnon mode in which the qubit\nis weakly driven. We demonstrate that the spectral steady-state responses of\nboth the qubit and the magnon show, in addition to two sidebands split by the\ncoupling, also a peak at the driving frequency with virtually zero linewidth.\nThis phenomenon, which persists at both strong and weak coupling, is an analog\nof the Heitler effect in atomic physics, and shows the path towards building of\ncoherent magnon sources."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-226",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09905"
    ],
    "b_title":[
      "Towards personalised assessment of abdominal aortic aneurysm structural\n  integrity"
    ],
    "b_abstract":[
      "Abdominal aortic aneurysm (AAA) is a life-threatening condition involving the\npermanent dilation of the aorta, often detected incidentally through imaging\nfor some other condition. The standard clinical approach to managing AAA\nfollows a one-size-fits-all model based on aneurysm size and growth rate,\nleading to underestimation or overestimation of rupture risk in individual\npatients. The widely studied stress-based rupture risk estimation using\ncomputational biomechanics requires wall strength information. However,\nnon-invasive methods for local patient-specific wall strength measurement have\nnot yet been developed. Recently, we introduced an image-based approach for\npatient-specific, in vivo, non-invasive AAA kinematic analysis using\ntime-resolved 3D computed tomography angiography (4D-CTA) images to measure\nwall strain throughout the cardiac cycle. In the present study, we integrated\nwall tension computation and strain measurement to develop a novel measure of\nlocal structural integrity of AAA wall - Relative Structural Integrity Index\n(RSII), independent of material properties and thickness of the wall and\nconditions of blood pressure measurement. Our methods provide a visual map of\nAAA wall structural integrity for individual patients using only their medical\nimages and blood pressure data. We applied our methods to twelve patients.\nAdditionally, we compared our measure of structural integrity of aneurysmal and\nnon-aneurysmal aortas. Our results show similar values of the wall structural\nintegrity measure across the patients, indicating the reliability of our\nmethods. In line with experimental observations reported in the literature, our\nanalysis revealed that localized low stiffness areas are primarily found in the\nmost dilated AAA regions. Our results clearly demonstrate that the AAA wall is\nstiffer than the non-aneurysmal aorta."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.10748"
    ],
    "c_title":[
      "Noncommutative Deformation of Optical States"
    ],
    "c_abstract":[
      "In this paper, we study the noncommutative deformation of different optical\nstates. We\n  develop the deformed coherent state by using the raising and lowering\noperators of the\n  quantum harmonic oscillator. This helps us to investigate the noncommutative\ndeformation\n  of a squeezed state in terms of noncommutative parameter, which in turn leads\nto the\n  noncommutative deformation of a photon-added coherent state. This\nnoncommutative\n  deformation has an overall effect on the non-classicality of such states.\nThis is done by\n  investigating the impact of noncommutative deformation of the Mandal\nparameter for such\n  states."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-227",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07019"
    ],
    "b_title":[
      "Coupled poro-elastic behavior of hyper-elastic membranes"
    ],
    "b_abstract":[
      "This study investigates the coupled deformation and flow behavior through\nthin, hyper-elastic, porous membranes subjected to pressure loading. Using\nbulge test experiments, optical deformation measurements, and flow rate\ncharacterization, we analyze the structural and fluid dynamic responses of\nmembranes with varying material stiffness and porosity patterns. A\ntwo-parameter Gent model captures the hyper-elastic deformation, while local\nstretch analyses reveal the evolution of pore sizes across the membrane. We\nfind that membrane stretch is primarily governed by material stiffness and\napplied pressure, independent of porosity. A gradient of increasing pore size\ntoward the membrane center emerges due to higher local stretch, while the total\nopen pore area remains approximately constant across radial layers of the\nmembrane. Flow rate scaling is characterized using a discharge coefficient that\naccounts for pore area expansion and pressure losses. While the initial scaling\ncompares well in most cases, it breaks down for scenarios with significantly\ndifferent pore Reynolds numbers, driven by large variations in initial\nporosity. To address this, we introduce a Reynolds-dependent correction term\nthat unifies discharge coefficient predictions across diverse porosity and flow\nvelocity conditions. These findings enhance the understanding of poro-elastic\nsystems and provide robust scaling relationships for designing thin, flexible,\nporous structures in applications such as bio-inspired aerodynamic systems and\nadaptive flow regulation devices."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12269"
    ],
    "c_title":[
      "Cracking the PUMA Challenge in 24 Hours with CellViT++ and nnU-Net"
    ],
    "c_abstract":[
      "Automatic tissue segmentation and nuclei detection is an important task in\npathology, aiding in biomarker extraction and discovery. The panoptic\nsegmentation of nuclei and tissue in advanced melanoma (PUMA) challenge aims to\nimprove tissue segmentation and nuclei detection in melanoma histopathology.\nUnlike many challenge submissions focusing on extensive model tuning, our\napproach emphasizes delivering a deployable solution within a 24-hour\ndevelopment timeframe, using out-of-the-box frameworks. The pipeline combines\ntwo models, namely CellViT++ for nuclei detection and nnU-Net for tissue\nsegmentation. Our results demonstrate a significant improvement in tissue\nsegmentation, achieving a Dice score of 0.750, surpassing the baseline score of\n0.629. For nuclei detection, we obtained results comparable to the baseline in\nboth challenge tracks. The code is publicly available at\nhttps:\/\/github.com\/TIO-IKIM\/PUMA."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-228",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07126"
    ],
    "b_title":[
      "Decision theory and the \"almost implies near\" phenomenon"
    ],
    "b_abstract":[
      "We propose to relax traditional axioms in decision theory by incorporating a\nmeasurement, or degree, of satisfaction. For example, if the independence axiom\nof expected utility theory is violated, we can measure the size of the\nviolation. This measure allows us to derive an approximation guarantee for a\nutility representation that aligns with the unmodified version of the axiom.\nAlmost satisfying the axiom implies, then, a utility that is near a utility\nrepresentation. We develop specific examples drawn from expected utility theory\nunder risk and uncertainty."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.03539"
    ],
    "c_title":[
      "No \"chaos\" in bosonic string massive scalar amplitudes"
    ],
    "c_abstract":[
      "We compute directly in covariant formalism a variety of four point massive\nscalar amplitudes in bosonic string with scalars up to level 10 and at least\none tachyon.\n  All computed amplitudes are perfectly regular and show no sign of erratic\nbehavior.\n  We give a naive argument based on a very simple model of why this can\nreasonably be expected and we check on the explicit examples that the intuition\nderived from the model is sensible.\n  Furthermore we discuss the complications due to null states (BRST exact\nstates) in actually computing the covariant bosonic string spectrum and how\nthese can be overcome by using a ``$\\Pi$ gauge'' which makes manifest that the\ndegeneration of any spin at any mass level is independent on the spacetime\ndimension."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-229",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04162"
    ],
    "b_title":[
      "The Eisenstein ideal at prime-square level has constant rank"
    ],
    "b_abstract":[
      "Let $N$ and $p$ be prime numbers with $p \\geq 5$ such that $p || (N + 1)$. In\na previous paper, we showed that there is a cuspform $f$ of weight 2 and level\n$\\Gamma_0(N^2)$ whose $\\ell$-th Fourier coefficient is congruent to $\\ell + 1$\nmodulo a prime above $p$ for all primes $\\ell$. In this paper, we prove that\nthis form $f$ is unique up to Galois conjugacy, and the extension of\n$\\mathbb{Z}_p$ generated by the coefficients of $f$ is exactly\n$\\mathbb{Z}_p[\\zeta_p + \\zeta_p^{-1}]$. We also prove similar results when a\nhigher power of $p$ divides $N + 1$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.15502"
    ],
    "c_title":[
      "MapColorAI: Designing Contextually Relevant Choropleth Map Color Schemes\n  Using a Large Language Model"
    ],
    "c_abstract":[
      "Choropleth maps, which utilize color schemes to visualize spatial patterns\nand trends, are simple yet effective tools for geographic data analysis. As\nsuch, color scheme design is a critical aspect of choropleth map creation. The\ntraditional coloring methods offered by GIS tools such as ArcGIS and QGIS are\nnot user-friendly for non-professionals. On the one hand, these tools provide\nnumerous color schemes, making it hard to decide which one best matches the\ntheme. On the other hand, it is difficult to fulfill some ambiguous and\npersonalized coloring needs of users, such as requests for 'summer-like' map\ncolors. To address these shortcomings, we develop a novel system that leverages\na large language model and map color design principles to generate contextually\nrelevant and user-aligned choropleth map color schemes. The system follows a\nthree-stage process: Data processing, which provides an overview of the data\nand classifies the data into meaningful classes; Color Concept Design, where\nthe color theme and color mode are conceptualized based on data characteristics\nand user intentions; and Color Scheme Design, where specific colors are\nassigned to classes based on generated color theme, color mode, and user\nrequirements. Our system incorporates an interactive interface, providing\nnecessary visualization for choropleth map color design and allowing users to\ncustomize and refine color choices flexibly. Through user studies and\nevaluations, the system demonstrates acceptable usability, accuracy, and\nflexibility, with users highlighting the tool's efficiency and ease of use."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-230",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13568"
    ],
    "b_title":[
      "WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot\n  Positioning"
    ],
    "b_abstract":[
      "Autonomous mobile robots are widely used for navigation, transportation, and\ninspection tasks indoors and outdoors. In practical situations of limited\nsatellite signals or poor lighting conditions, navigation depends only on\ninertial sensors. In such cases, the navigation solution rapidly drifts due to\ninertial measurement errors. In this work, we propose WMINet a wheel-mounted\ninertial deep learning approach to estimate the mobile robot's position based\nonly on its inertial sensors. To that end, we merge two common practical\nmethods to reduce inertial drift: a wheel-mounted approach and driving the\nmobile robot in periodic trajectories. Additionally, we enforce a wheelbase\nconstraint to further improve positioning performance. To evaluate our proposed\napproach we recorded using the Rosbot-XL a wheel-mounted initial dataset\ntotaling 190 minutes, which is made publicly available. Our approach\ndemonstrated a 66\\% improvement over state-of-the-art approaches. As a\nconsequence, our approach enables navigation in challenging environments and\nbridges the pure inertial gap. This enables seamless robot navigation using\nonly inertial sensors for short periods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12286"
    ],
    "c_title":[
      "A Linear Programming Approach to Private Information Retrieval"
    ],
    "c_abstract":[
      "This work presents an algorithmic framework that uses linear programming to\nconstruct \\emph{addition-based Private Information Retrieval (AB-PIR)} schemes,\nwhere retrieval is performed by downloading only linear combinations of message\nsymbols with coefficients set to 0 or 1. The AB-PIR schemes generalize several\nexisting capacity-achieving PIR schemes and are of practical interest because\nthey use only addition operations -- avoiding multiplication and other complex\noperations -- and are compatible with any finite field, including binary. Our\nframework broadens the search space to include all feasible solutions and can\nbe used to construct optimal AB-PIR schemes for the entire range of problem\nparameters, including the number of servers, the total number of messages, and\nthe number of messages that need to be retrieved. The framework enables us to\nidentify schemes that outperform the previously proposed PIR schemes in certain\ncases and, in other cases, achieve performance on par with the best-known\nAB-PIR solutions. Additionally, the schemes generated by our framework can be\nintegrated into existing solutions for several related PIR scenarios, improving\ntheir overall performance."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-231",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01854"
    ],
    "b_title":[
      "On extending the class of convex functions"
    ],
    "b_abstract":[
      "In this brief note, it is shown that the function p^TW log(p) is convex in p\nif W is a diagonally dominant positive definite M-matrix. The techniques used\nto prove convexity are well-known in linear algebra and essentially involves\nfactoring the Hessian in a way that is amenable to martix analysis. Using\nsimilar techniques, two classes of convex homogeneous polynomials is derived -\nnamely, p^TW p2 and (p^k)^TW p^k - the latter also happen to be SOS-convex.\nLastly, usign the same techniques, it is also shown that the function p^TW ep\nis convex over the positive reals only if W is a non-negative diagonal matrix.\nDiscussions regarding the utility of these functions and examples accompany the\nresults presented."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.01269"
    ],
    "c_title":[
      "Exploratory Utility Maximization Problem with Tsallis Entropy"
    ],
    "c_abstract":[
      "We study expected utility maximization problem with constant relative risk\naversion utility function in a complete market under the reinforcement learning\nframework. To induce exploration, we introduce the Tsallis entropy regularizer,\nwhich generalizes the commonly used Shannon entropy. Unlike the classical\nMerton's problem, which is always well-posed and admits closed-form solutions,\nwe find that the utility maximization exploratory problem is ill-posed in\ncertain cases, due to over-exploration. With a carefully selected primary\ntemperature function, we investigate two specific examples, for which we fully\ncharacterize their well-posedness and provide semi-closed-form solutions. It is\ninteresting to find that one example has the well-known Gaussian distribution\nas the optimal strategy, while the other features the rare Wigner semicircle\ndistribution, which is equivalent to a scaled Beta distribution. The means of\nthe two optimal exploratory policies coincide with that of the classical\ncounterpart. In addition, we examine the convergence of the value function and\noptimal exploratory strategy as the exploration vanishes. Finally, we design a\nreinforcement learning algorithm and conduct numerical experiments to\ndemonstrate the advantages of reinforcement learning."
    ],
    "c_categories":[
      [
        "cs.LG",
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-232",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06103"
    ],
    "b_title":[
      "Several combinatorial results generalized from one large subset of\n  semigroups to infinitely many"
    ],
    "b_abstract":[
      "In 2015, Phulara established a generalization of the famous central set\ntheorem by an original idea. Roughly speaking, this idea extends a\ncombinatorial result from one large subset of the given semigroup to countably\nmany. In this paper, we apply this idea to other combinatorial results to\nobtain corresponding generalizations, and do some further investigation.\nMoreover, we find that Phulara's generalization can be generalized further that\ncan deal with uncountably many C-sets."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.01511"
    ],
    "c_title":[
      "TreeLUT: An Efficient Alternative to Deep Neural Networks for Inference\n  Acceleration Using Gradient Boosted Decision Trees"
    ],
    "c_abstract":[
      "Accelerating machine learning inference has been an active research area in\nrecent years. In this context, field-programmable gate arrays (FPGAs) have\ndemonstrated compelling performance by providing massive parallelism in deep\nneural networks (DNNs). Neural networks (NNs) are computationally intensive\nduring inference, as they require massive amounts of multiplication and\naddition, which makes their implementations costly. Numerous studies have\nrecently addressed this challenge to some extent using a combination of\nsparsity induction, quantization, and transformation of neurons or sub-networks\ninto lookup tables (LUTs) on FPGAs. Gradient boosted decision trees (GBDTs) are\na high-accuracy alternative to DNNs in a wide range of regression and\nclassification tasks, particularly for tabular datasets. The basic building\nblock of GBDTs is a decision tree, which resembles the structure of binary\ndecision diagrams. FPGA design flows are heavily optimized to implement such a\nstructure efficiently. In addition to decision trees, GBDTs perform simple\noperations during inference, including comparison and addition. We present\nTreeLUT as an open-source tool for implementing GBDTs using an efficient\nquantization scheme, hardware architecture, and pipelining strategy. It\nprimarily utilizes LUTs with no BRAMs or DSPs on FPGAs, resulting in high\nefficiency. We show the effectiveness of TreeLUT using multiple classification\ndatasets, commonly used to evaluate ultra-low area and latency architectures.\nUsing these benchmarks, we compare our implementation results with existing DNN\nand GBDT methods, such as DWN, PolyLUT-Add, NeuraLUT, LogicNets, FINN, hls4ml,\nand others. Our results show that TreeLUT significantly improves hardware\nutilization, latency, and throughput at competitive accuracy compared to\nprevious works."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-233",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11283"
    ],
    "b_title":[
      "Set-Based Position Ambiguity Reduction Method for Zonotope Shadow\n  Matching in Urban Areas Using Estimated Multipath Errors"
    ],
    "b_abstract":[
      "In urban areas, the quality of global navigation satellite system (GNSS)\nsignals deteriorates, leading to reduced positioning accuracy. To address this\nissue, 3D-mapping-aided (3DMA) techniques, such as shadow matching and zonotope\nshadow matching (ZSM), have been proposed. However, these methods can introduce\na problem known as multi-modal position ambiguity, making it challenging to\nselect the exact mode in which the receiver is located. Accurately selecting\nthe correct mode is essential for improving positioning accuracy. A previous\nstudy proposed a method that uses satellite-pseudorange consistency (SPC),\ncalculated from pseudorange measurements, to select the mode containing the\nreceiver. This method achieved a mode selection accuracy of approximately 78%.\nTo further enhance accuracy, the study utilized pseudorange measurements\ncollected at multiple timesteps from a fixed location and a trained\nline-of-sight (LOS) classifier. However, in practice, collecting data at\nmultiple timesteps from the same location in dynamic environments is\nchallenging. Moreover, the performance of the trained LOS classifier heavily\ndepends on the surrounding environment, leading to low reliability. In this\nstudy, we propose a method that estimates and corrects multipath errors based\non the mode distribution obtained from the output of ZSM and extract an\nenhanced SPC using the corrected pseudorange measurements. This enables high\nmode selection accuracy using only single-timestep pseudorange measurements,\nwithout requiring a trained LOS classifier."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18648"
    ],
    "c_title":[
      "No-scale Brans-Dicke Gravity -- ultralight scalar boson & heavy inflaton"
    ],
    "c_abstract":[
      "It is very much intriguing if the Planck scale $M_{\\rm{Pl}}$ is not a\nfundamental parameter. The Brans-Dicke gravity is nothing but the theory where\nthe Planck scale $M_{\\rm{Pl}}$ is indeed an illusional parameter. The theory\npredicts a massless scalar boson whose exchanges between matters induce\nunwanted long range forces. We solve this problem imposing there is no\ndimensionful parameter in the theory, even at the quantum level. We further\nextend the theory by including a $R^2$ term and a non-minimal coupling of the\nStandard Model Higgs to gravity, as their coefficients are dimensionless. This\nextension provides a heavy inflaton field that is consistent with all\ncosmological observations, with a potential very similar to that of the\nStarobinsky model. The inflaton necessarily decays into the massless scalar\nbosons, resulting in a non-negligible amount of dark radiation in the present\nuniverse. We demonstrate that the inflation model yields a sufficiently high\nreheating temperature for successful leptogenesis, and we also discuss a\npossible candidate for dark matter."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-234",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10148"
    ],
    "b_title":[
      "Leptogenesis in the presence of density perturbations"
    ],
    "b_abstract":[
      "We point out a new effect on the freeze-out process of heavy particles\ninduced by density perturbations in the early universe, which we call\n``acoustically driven freeze-out.'' This beyond-linear effect is caused by the\nexponential decoupling of heavy particles from the thermal bath in the presence\nof density perturbations, and already at moderately large values $\\delta T \/\n\\bar{T} = O (10^{-2})$ it cannot be captured by linear perturbation theory. We\nillustrate this effect with leptogenesis taking the decay and inverse decay of\nheavy neutrinos into account, and discuss its phenomenological implications. We\nfound that perturbations always enhance the (spatially averaged) values of the\nfinal lepton asymmetry, and as a result, constraints on the mass of heavy\nneutrinos are found to be relaxed in the presence of perturbations."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.15435"
    ],
    "c_title":[
      "Making Sense Of Distributed Representations With Activation Spectroscopy"
    ],
    "c_abstract":[
      "In the study of neural network interpretability, there is growing evidence to\nsuggest that relevant features are encoded across many neurons in a distributed\nfashion. Making sense of these distributed representations without knowledge of\nthe network's encoding strategy is a combinatorial task that is not guaranteed\nto be tractable. This work explores one feasible path to both detecting and\ntracing the joint influence of neurons in a distributed representation. We term\nthis approach Activation Spectroscopy (ActSpec), owing to its analysis of the\npseudo-Boolean Fourier spectrum defined over the activation patterns of a\nnetwork layer. The sub-network defined between a given layer and an output\nlogit is cast as a special class of pseudo-Boolean function. The contributions\nof each subset of neurons in the specified layer can be quantified through the\nfunction's Fourier coefficients. We propose a combinatorial optimization\nprocedure to search for Fourier coefficients that are simultaneously\nhigh-valued, and non-redundant. This procedure can be viewed as an extension of\nthe Goldreich-Levin algorithm which incorporates additional problem-specific\nconstraints. The resulting coefficients specify a collection of subsets, which\nare used to test the degree to which a representation is distributed. We verify\nour approach in a number of synthetic settings and compare against existing\ninterpretability benchmarks. We conclude with a number of experimental\nevaluations on an MNIST classifier, and a transformer-based network for\nsentiment analysis."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-235",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01708"
    ],
    "b_title":[
      "Aspects of Artificial Intelligence: Transforming Machine Learning\n  Systems Naturally"
    ],
    "b_abstract":[
      "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.DB",
        "cs.DM",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17277"
    ],
    "c_title":[
      "Fourier decay of measures supported on sets of numbers with consecutive\n  partial quotients belonging to a given set"
    ],
    "c_abstract":[
      "We consider measures supported on sets of irrational numbers possessing many\nconsecutive partial quotients satisfying a condition based on the previous\npartial quotients. We show that under mild assumptions, such sets will always\nsupport measures whose Fourier transform decays to zero."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-236",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08430"
    ],
    "b_title":[
      "Fully numerical Hartree-Fock Calculations with Quantized Tensor Trains"
    ],
    "b_abstract":[
      "We present a fully numerical framework for the optimization of\nmolecule-specific quantum chemical basis functions within the quantics tensor\ntrain format using a finite-difference scheme. The optimization is driven by\nsolving the Hartree-Fock equations (HF) with the density-matrix renormalization\ngroup (DMRG) algorithm on Cartesian grids that are iteratively refined. In\ncontrast to the standard way of tackling the mean-field problem by expressing\nthe molecular orbitals as linear combinations of atomic orbitals (LCAO) our\nmethod only requires as much basis functions as there are electrons within the\nsystem. Benchmark calculations for atoms and molecules with up to ten electrons\nshow excellent agreement with LCAO calculations with large basis sets\nsupporting the validity of the tensor network approach. Our work therefore\noffers a promising alternative to well-established HF-solvers and could pave\nthe way to define highly accurate, fully numerical, molecule-adaptive basis\nsets, which, in the future, could lead to benefits for post-HF calculations."
    ],
    "b_categories":[
      [
        "physics.chem-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.18989"
    ],
    "c_title":[
      "Extension of Optimal Locally Repairable codes"
    ],
    "c_abstract":[
      "Recent studies have delved into the construction of locally repairable codes\n(LRCs) with optimal minimum distance from function fields. In this paper, we\npresent several novel constructions by extending the findings of optimally\ndesigned locally repairable codes documented in the literature. Let $C$ denote\nan optimal LRC of locality $r$, implying that every repairable block of $C$ is\na $[r+1, r]$ MDS code, and $C$ maximizes its minimum distance. By extending a\nsingle coordinate of one of these blocks, we demonstrate that the resulting\ncode remains an optimally designed locally repairable code. This suggests that\nthe maximal length of an optimal LRC from rational function fields can be\nextended up to $q+2$ over a finite field $\\mathbb{F}_q$. In addition, we give a\nnew construction of optimal $(r, 3)$-LRC by extending one coordinate in each\nblock within $C$. Furthermore, we propose a novel family of LRCs with\nRoth-Lempel type that are optimal under certain conditions. Finally, we explore\noptimal LRCs derived from elliptic function fields and extend a single\ncoordinate of such codes. This approach leads us to confirm that the new codes\nare also optimal, thereby allowing their lengths to reach $q + 2\\sqrt{q} - 2r -\n2$ with locality $r$. We also consider the construction of optimal $(r, 3)$-LRC\nin elliptic function fields, with exploring one more condition."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-237",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01945"
    ],
    "b_title":[
      "Cryogenic Thermal Modeling of Microwave High Density Signaling"
    ],
    "b_abstract":[
      "Superconducting quantum computers require microwave control lines running\nfrom room temperature to the mixing chamber of a dilution refrigerator. Adding\nmore lines without preliminary thermal modeling to make predictions risks\noverwhelming the cooling power at each thermal stage. In this paper, we\ninvestigate the thermal load of SC-086\/50-SCN-CN semi-rigid coaxial cable,\nwhich is commonly used for the control and readout lines of a superconducting\nquantum computer, as we increase the number of lines to a quantum processor. We\ninvestigate the makeup of the coaxial cables, verify the materials and\ndimensions, and experimentally measure the total thermal conductivity of a\nsingle cable as a function of the temperature from cryogenic to room\ntemperature values. We also measure the cryogenic DC electrical resistance of\nthe inner conductor as a function of temperature, allowing for the calculation\nof active thermal loads due to Ohmic heating. Fitting this data produces a\nnumerical thermal conductivity function used to calculate the static heat loads\ndue to thermal transfer within the wires resulting from a temperature gradient.\nThe resistivity data is used to calculate active heat loads, and we use these\nfits in a cryogenic model of a superconducting quantum processor in a typical\nBluefors XLD1000-SL dilution refrigerator, investigating how the thermal load\nincreases with processor sizes ranging from 100 to 225 qubits. We conclude that\nthe theoretical upper limit of the described architecture is approximately 200\nqubits. However, including an engineering margin in the cooling power and the\navailable space for microwave readout circuitry at the mixing chamber, the\npractical limit will be approximately 140 qubits."
    ],
    "b_categories":[
      [
        "physics.ins-det",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.09138"
    ],
    "c_title":[
      "Few-Shot Adaptation of Training-Free Foundation Model for 3D Medical\n  Image Segmentation"
    ],
    "c_abstract":[
      "Vision foundation models have achieved remarkable progress across various\nimage analysis tasks. In the image segmentation task, foundation models like\nthe Segment Anything Model (SAM) enable generalizable zero-shot segmentation\nthrough user-provided prompts. However, SAM primarily trained on natural\nimages, lacks the domain-specific expertise of medical imaging. This limitation\nposes challenges when applying SAM to medical image segmentation, including the\nneed for extensive fine-tuning on specialized medical datasets and a dependency\non manual prompts, which are both labor-intensive and require intervention from\nmedical experts.\n  This work introduces the Few-shot Adaptation of Training-frEe SAM (FATE-SAM),\na novel method designed to adapt the advanced Segment Anything Model 2 (SAM2)\nfor 3D medical image segmentation. FATE-SAM reassembles pre-trained modules of\nSAM2 to enable few-shot adaptation, leveraging a small number of support\nexamples to capture anatomical knowledge and perform prompt-free segmentation,\nwithout requiring model fine-tuning. To handle the volumetric nature of medical\nimages, we incorporate a Volumetric Consistency mechanism that enhances spatial\ncoherence across 3D slices. We evaluate FATE-SAM on multiple medical imaging\ndatasets and compare it with supervised learning methods, zero-shot SAM\napproaches, and fine-tuned medical SAM methods. Results show that FATE-SAM\ndelivers robust and accurate segmentation while eliminating the need for large\nannotated datasets and expert intervention. FATE-SAM provides a practical,\nefficient solution for medical image segmentation, making it more accessible\nfor clinical applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-238",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09013"
    ],
    "b_title":[
      "Prompt to Restore, Restore to Prompt: Cyclic Prompting for Universal\n  Adverse Weather Removal"
    ],
    "b_abstract":[
      "Universal adverse weather removal (UAWR) seeks to address various weather\ndegradations within a unified framework. Recent methods are inspired by prompt\nlearning using pre-trained vision-language models (e.g., CLIP), leveraging\ndegradation-aware prompts to facilitate weather-free image restoration,\nyielding significant improvements. In this work, we propose CyclicPrompt, an\ninnovative cyclic prompt approach designed to enhance the effectiveness,\nadaptability, and generalizability of UAWR. CyclicPrompt Comprises two key\ncomponents: 1) a composite context prompt that integrates weather-related\ninformation and context-aware representations into the network to guide\nrestoration. This prompt differs from previous methods by marrying learnable\ninput-conditional vectors with weather-specific knowledge, thereby improving\nadaptability across various degradations. 2) The erase-and-paste mechanism,\nafter the initial guided restoration, substitutes weather-specific knowledge\nwith constrained restoration priors, inducing high-quality weather-free\nconcepts into the composite prompt to further fine-tune the restoration\nprocess. Therefore, we can form a cyclic \"Prompt-Restore-Prompt\" pipeline that\nadeptly harnesses weather-specific knowledge, textual contexts, and reliable\ntextures. Extensive experiments on synthetic and real-world datasets validate\nthe superior performance of CyclicPrompt. The code is available at:\nhttps:\/\/github.com\/RongxinL\/CyclicPrompt."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13272"
    ],
    "c_title":[
      "Uniaxial Pressure Effects, Phase Diagram, and Tricritical Point in the\n  Centrosymmetric Skyrmion Lattice Magnet GdRu$_2$Si$_2$"
    ],
    "c_abstract":[
      "The magnetic phase diagram, magnetoelastic coupling, and uniaxial pressure\neffects of centrosymmetric magnetic skyrmion-hosting GdRu$_2$Si$_2$ are\ninvestigated by means of high-resolution capacitance dilatometry in fields up\nto 15\\,T supported by specific heat and magnetisation studies. In addition to\nthe previously reported phases in the $H$-$T$ phase diagram, we observe a third\nantiferromagnetic phase in zero magnetic field. We present the magnetic phase\ndiagram and find two unreported phases, one of which features a comparably\ngiant uniaxial pressure dependence. Our dilatometric measurements show\nmagnetoelastic effects associated with the various magnetic ordering phenomena.\nWe determine the uniaxial pressure dependencies of the various phases, in\nparticular of the skyrmion lattice phase which is enhanced at higher fields and\ntemperatures and also widens at a rate of 0.07~T\/GPa when uniaxial pressure is\napplied along the $c$ axis. The relevance of fluctuations is further\nhighlighted by the presence of tricritical point indicated by our thermodynamic\ndata at the phase boundary separating two double-\\textit{Q} magnetic\nconfigurations between which the skyrmion pocket phase evolves upon further\ncooling."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-239",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15433"
    ],
    "b_title":[
      "Testing strong-field QED to second-order in the highly correlated atomic\n  system berylliumlike Pb78+ by electron-ion recombination spectroscopy"
    ],
    "b_abstract":[
      "A low-energy storage ring with an ultracold electron cooler has been coupled\nwith a heavy-ion accelerator facilitating high-resolution electron-ion\ncollision spectroscopy of the heaviest few-electron ions. In the present work\nresonant electron-ion recombination of berylliumlike Pb$^{78+}$ ions was\nmeasured in the collision-energy range 9.3-16.5eV and a value of 244.937(30) eV\nis derived for the Pb$^{78+}$($2s^2\\;^1S_0 - 2s\\,2p\\;^3P_1$) excitation energy.\nThis result agrees with the most recent (less accurate) theoretical value of\n244.942(52) eV [Malyshev et al., Physical Review A 110, 062824 (2024)], which\nhas been calculated by applying strong-field QED rigorously up to the second\norder. The present investigation suggests that further technical improvements\ncan potentially increase the experimental accuracy by an order of magnitude."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11870"
    ],
    "c_title":[
      "Counterfactual Realizability"
    ],
    "c_abstract":[
      "It is commonly believed that, in a real-world environment, samples can only\nbe drawn from observational and interventional distributions, corresponding to\nLayers 1 and 2 of the Pearl Causal Hierarchy. Layer 3, representing\ncounterfactual distributions, is believed to be inaccessible by definition.\nHowever, Bareinboim, Forney, and Pearl (2015) introduced a procedure that\nallows an agent to sample directly from a counterfactual distribution, leaving\nopen the question of what other counterfactual quantities can be estimated\ndirectly via physical experimentation. We resolve this by introducing a formal\ndefinition of realizability, the ability to draw samples from a distribution,\nand then developing a complete algorithm to determine whether an arbitrary\ncounterfactual distribution is realizable given fundamental physical\nconstraints, such as the inability to go back in time and subject the same unit\nto a different experimental condition. We illustrate the implications of this\nnew framework for counterfactual data collection using motivating examples from\ncausal fairness and causal reinforcement learning. While the baseline approach\nin these motivating settings typically follows an interventional or\nobservational strategy, we show that a counterfactual strategy provably\ndominates both."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-240",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10160"
    ],
    "b_title":[
      "Coupling and Acceleration of Externally Injected Electron Beams in\n  Laser-Driven Plasma Wakefields"
    ],
    "b_abstract":[
      "The multi-stage method of laser wakefield acceleration (LWFA) presents a\npromising approach for developing stable, full-optical, high-energy electron\naccelerators. By segmenting the acceleration process into several booster\nstages, each powered by independent laser drivers, this technique effectively\nmitigates challenges such as electron dephasing, pump depletion, and laser\ndiffraction. A critical aspect of multi-stage LWFA is the nonlinear interaction\nbetween the injected electron beam and the laser-driven wakefields in the\nbooster stage. This study investigates the injection and acceleration of\nexternal electron beams within wakefields in the booster stage using\nmulti-dimensional Particle-In-Cell (PIC) simulations. We provide both\nqualitative and quantitative descriptions of the observed physical processes.\nKey parameters influencing charge coupling process and the resultant beam\nquality have been identified. Furthermore, we have examined how off-axis\ninjection relative to the driver laser influences the acceleration process and\nbeam quality. Our findings provide valuable insights for advancing and\noptimizing multi-stage plasma-based accelerators."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02335"
    ],
    "c_title":[
      "Connecting the Unconnectable through Feedback"
    ],
    "c_abstract":[
      "Reliable uplink connectivity remains a persistent challenge for IoT devices,\nparticularly those at the cell edge, due to their limited transmit power and\nsingle-antenna configurations. This paper introduces a novel framework aimed at\nconnecting the unconnectable, leveraging real-time feedback from access points\n(APs) to enhance uplink coverage without increasing the energy consumption of\nIoT devices. At the core of this approach are feedback channel codes, which\nenable IoT devices to dynamically adapt their transmission strategies based on\nAP decoding feedback, thereby reducing the critical uplink SNR required for\nsuccessful communication. Analytical models are developed to quantify the\ncoverage probability and the number of connectable APs, providing a\ncomprehensive understanding of the system's performance. Numerical results\nvalidate the proposed method, demonstrating substantial improvements in\ncoverage range and connectivity, particularly for devices at the cell edge,\nwith up to a 51% boost in connectable APs. Our approach offers a robust and\nenergy-efficient solution to overcoming uplink coverage limitations, enabling\nIoT networks to connect devices in challenging environments."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-241",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11955"
    ],
    "b_title":[
      "Simultaneously decoding the unknown stationary state and function\n  parameters for mean field games"
    ],
    "b_abstract":[
      "Mean field games (MFGs) offer a versatile framework for modeling large-scale\ninteractive systems across multiple domains. This paper builds upon a previous\nwork, by developing a state-of-the-art unified approach to decode or design the\nunknown stationary state of MFGs, in addition to the underlying parameter\nfunctions governing their behavior. This result is novel, even in the general\nrealm of inverse problems for nonlinear PDEs. By enabling agents to distill\ncrucial insights from observed data and unveil intricate hidden structures and\nunknown states within MFG systems, our approach surmounts a significant\nobstacle, enhancing the applicability of MFGs in real-world scenarios. This\nadvancement not only enriches our understanding of MFG dynamics but also\nbroadens the scope for their practical deployment in various contexts."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.07381"
    ],
    "c_title":[
      "Feedforward Cancellation of High-Frequency Phase Noise in\n  Frequency-Doubled Lasers"
    ],
    "c_abstract":[
      "The cancellation of high-frequency laser phase noise using feedforward\ntechniques, as opposed to feedback methods, has achieved significant\nadvancements in recent years. However, directly applying existing feedforward\ntechniques to laser systems based on nonlinear conversion still faces\nsubstantial challenges. Here, we propose and demonstrate a feedforward scheme\nthat suppresses phase noise in frequency-doubled light by utilizing phase noise\ninformation of its fundamental pump. This scheme is enabled by the fact that\nthe phase jitter of the frequency-doubled light is simply twice that of the\npump, except for a first-order low-pass filtering effect introduced by the SHG\nenhancement cavity. Testing this method on a 420-nm frequency-doubled laser\nsystem, we realize a 25-dB suppression of the servo noise bump near 1 MHz on\nthe 420-nm light, and an average suppression of 30 dB for strong injected noise\nranging from 100 kHz to 20 MHz. This scheme shows promising potential for\napplications requiring blue or ultraviolet light with minimal high-frequency\nphase noise, such as precision control of atoms and molecules."
    ],
    "c_categories":[
      [
        "physics.atom-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-242",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06509"
    ],
    "b_title":[
      "Crossover from BKT to first-order transition induced by higher-order\n  terms in 2D XY models"
    ],
    "b_abstract":[
      "We study phase transitions in $XY$ models, generalized by inclusion of $n$\nhigher-order pairwise interactions of equal strength, by Monte Carlo\nsimulation. It is found that by adding new terms the\nBerezinskii-Kosterlitz-Thouless (BKT) transition, observed in the standard $XY$\nmodel, gradually changes to the first-order phase transition. We determine the\ncritical number of terms for which the first-order transition appears as\n$n_c=6$. It is also found that for $n=5$ the transition is pseudo-first-order\nbut it becomes true first-order if the couplings are allowed to increase. In\ngeneral, a more rapid increase of the coupling intensity supports the\nfirst-order transition, however, a too fast increase may result in splitting of\nthe single transition to multiple transitions. Consequently, the minimal number\nof the terms required for the change of the BKT phase transition to first order\nin the present model with arbitrary couplings is estimated to be $2 < n_c \\leq\n5$."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.17610"
    ],
    "c_title":[
      "FeedSign: Robust Full-parameter Federated Fine-tuning of Large Models\n  with Extremely Low Communication Overhead of One Bit"
    ],
    "c_abstract":[
      "Federated fine-tuning (FFT) attempts to fine-tune a pre-trained model with\nprivate data from distributed clients by exchanging models rather than data\nunder the orchestration of a parameter server (PS). To overcome the bottleneck\nforged by the growing communication and memory overhead for clients in such\nsystems due to the growing model sizes, we propose \\textit{FeedSign}, an FFT\nalgorithm in which the upload and download payload for an aggregation step is\nexactly $1$ bit per step, while the memory overhead is squeezed to the amount\nneeded for inference. This is realized by utilizing zeroth-order (ZO)\noptimizers on large models and shared pseudo-random number generators (PRNG)\nacross devices to represent the gradient estimates as seed-sign pairs. We\nconduct theoretical analysis on FeedSign and show that it converges at an\nexponential rate $\\mathcal{O}(e^{-t})$, where $t$ is the number of elapsed\nsteps under widely used assumptions. Moreover, FeedSign is found to be robust\nagainst data heterogeneity and Byzantine attacks. We conducted extensive\nexperiments on models across different structures and sizes (11M to 13B) and\nfound that the proposed method performs better or closely, depending on\nscenarios, compared to its ZO and FO counterparts, albeit with an\norders-of-magnitude lower communication overhead. We also discuss some\ninteresting advantages as byproducts guaranteed by the minimalistic design of\n\\textit{FeedSign}."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-243",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17132"
    ],
    "b_title":[
      "Applications of Large Models in Medicine"
    ],
    "b_abstract":[
      "This paper explores the advancements and applications of large-scale models\nin the medical field, with a particular focus on Medical Large Models (MedLMs).\nThese models, encompassing Large Language Models (LLMs), Vision Models, 3D\nLarge Models, and Multimodal Models, are revolutionizing healthcare by\nenhancing disease prediction, diagnostic assistance, personalized treatment\nplanning, and drug discovery. The integration of graph neural networks in\nmedical knowledge graphs and drug discovery highlights the potential of Large\nGraph Models (LGMs) in understanding complex biomedical relationships. The\nstudy also emphasizes the transformative role of Vision-Language Models (VLMs)\nand 3D Large Models in medical image analysis, anatomical modeling, and\nprosthetic design. Despite the challenges, these technologies are setting new\nbenchmarks in medical innovation, improving diagnostic accuracy, and paving the\nway for personalized healthcare solutions. This paper aims to provide a\ncomprehensive overview of the current state and future directions of large\nmodels in medicine, underscoring their significance in advancing global health."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15905"
    ],
    "c_title":[
      "Ergodicity of cocyles over 2-dimensional rotations"
    ],
    "c_abstract":[
      "We study recurrence and ergodicity of cocycles with values in R d , d $\\ge$\n1, over rotations by badly approximable irrational numbers on T $\\rho$ , $\\rho$\n\\&gt; 1. The discontinuities of the functions generating the cocycles also\nsatisfy a Diophantine condition. For simplicity of notation we mainly consider\nthe cases $\\rho$ = 2, d = 1 and 2."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-244",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01888"
    ],
    "b_title":[
      "Enhancing Transformer with GNN Structural Knowledge via Distillation: A\n  Novel Approach"
    ],
    "b_abstract":[
      "Integrating the structural inductive biases of Graph Neural Networks (GNNs)\nwith the global contextual modeling capabilities of Transformers represents a\npivotal challenge in graph representation learning. While GNNs excel at\ncapturing localized topological patterns through message-passing mechanisms,\ntheir inherent limitations in modeling long-range dependencies and\nparallelizability hinder their deployment in large-scale scenarios. Conversely,\nTransformers leverage self-attention mechanisms to achieve global receptive\nfields but struggle to inherit the intrinsic graph structural priors of GNNs.\nThis paper proposes a novel knowledge distillation framework that\nsystematically transfers multiscale structural knowledge from GNN teacher\nmodels to Transformer student models, offering a new perspective on addressing\nthe critical challenges in cross-architectural distillation. The framework\neffectively bridges the architectural gap between GNNs and Transformers through\nmicro-macro distillation losses and multiscale feature alignment. This work\nestablishes a new paradigm for inheriting graph structural biases in\nTransformer architectures, with broad application prospects."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07272"
    ],
    "c_title":[
      "A Large-Scale Reconfigurable Multiplexed Quantum Photonic Network"
    ],
    "c_abstract":[
      "Entanglement distribution in quantum networks will enable next-generation\ntechnologies for quantum-secured communications, distributed quantum computing\nand sensing. Future quantum networks will require dense connectivity, allowing\nmultiple users to share entanglement in a reconfigurable and multiplexed\nmanner, while long-distance connections are established through the\nteleportation of entanglement, or entanglement swapping. While several recent\nworks have demonstrated fully connected, local multi-user networks based on\nmultiplexing, extending this to a global network architecture of interconnected\nlocal networks remains an outstanding challenge. Here we demonstrate the next\nstage in the evolution of multiplexed quantum networks: a prototype global\nreconfigurable network where entanglement is routed and teleported in a\nflexible and multiplexed manner between two local multi-user networks composed\nof four users each. At the heart of our network is a programmable\n8x8-dimensional multi-port circuit that harnesses the natural mode-mixing\nprocess inside a multi-mode fibre to implement on-demand high-dimensional\noperations on two independent photons carrying eight transverse-spatial modes.\nOur circuit design allows us to break away from the limited planar geometry and\nbypass the control and fabrication challenges of conventional integrated\nphotonic platforms. Our demonstration showcases the potential of this\narchitecture for enabling large-scale, global quantum networks that offer\nversatile connectivity while being fully compatible with an existing\ncommunications infrastructure."
    ],
    "c_categories":[
      [
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-245",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19075"
    ],
    "b_title":[
      "Incomplete Information Robustness"
    ],
    "b_abstract":[
      "Consider an analyst who models a strategic situation using an incomplete\ninformation game. The true game may involve correlated, duplicated belief\nhierarchies, but the analyst lacks knowledge of the correlation structure and\ncan only approximate each belief hierarchy. To make predictions in this\nsetting, the analyst uses belief-invariant Bayes correlated equilibria (BIBCE)\nand seeks to determine which one is justifiable. We address this question by\nintroducing the notion of robustness: a BIBCE is robust if, for every nearby\nincomplete information game, there exists a BIBCE close to it. Our main result\nprovides a sufficient condition for robustness using a generalized potential\nfunction. In a supermodular potential game, a robust BIBCE is a Bayes Nash\nequilibrium, whereas this need not hold in other classes of games."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.06970"
    ],
    "c_title":[
      "Model Diffusion for Certifiable Few-shot Transfer Learning"
    ],
    "c_abstract":[
      "In modern large-scale deep learning, a prevalent and effective workflow for\nsolving low-data problems is adapting powerful pre-trained foundation models\n(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while\nempirically effective, the resulting solutions lack generalisation guarantees\nto certify their accuracy - which may be required for ethical or legal reasons\nprior to deployment in high-importance applications. In this paper we develop a\nnovel transfer learning approach that is designed to facilitate non-vacuous\nlearning theoretic generalisation guarantees for downstream tasks, even in the\nlow-shot regime. Specifically, we first use upstream tasks to train a\ndistribution over PEFT parameters. We then learn the downstream task by a\nsample-and-evaluate procedure -- sampling plausible PEFTs from the trained\ndiffusion model and selecting the one with the highest likelihood on the\ndownstream data. Crucially, this confines our model hypothesis to a finite set\nof PEFT samples. In contrast to learning in the typical continuous hypothesis\nspaces of neural network weights, this facilitates tighter risk certificates.\nWe instantiate our bound and show non-trivial generalization guarantees\ncompared to existing learning approaches which lead to vacuous bounds in the\nlow-shot regime."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-246",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01623"
    ],
    "b_title":[
      "Instrumental Variables with Time-Varying Exposure: New Estimates of\n  Revascularization Effects on Quality of Life"
    ],
    "b_abstract":[
      "The ISCHEMIA Trial randomly assigned patients with ischemic heart disease to\nan invasive treatment strategy centered on revascularization with a control\ngroup assigned non-invasive medical therapy. As is common in such ``strategy\ntrials,'' many participants assigned to treatment remained untreated while many\nassigned to control crossed over into treatment. Intention-to-treat (ITT)\nanalyses of strategy trials preserve randomization-based comparisons, but ITT\neffects are diluted by non-compliance. Conventional per-protocol analyses that\ncondition on treatment received are likely biased by discarding random\nassignment. In trials where compliance choices are made shortly after\nassignment, instrumental variables (IV) methods solve both problems --\nrecovering an undiluted average causal effect of treatment for treated subjects\nwho comply with trial protocol. In ISCHEMIA, however, some controls were\nrevascularized as long as five years after random assignment. This paper\nextends the IV framework for strategy trials, allowing for such dynamic\nnon-random compliance behavior. IV estimates of long-run revascularization\neffects on quality of life are markedly larger than previously reported ITT and\nper-protocol estimates. We also show how to estimate complier characteristics\nin a dynamic-treatment setting. These estimates reveal increasing selection\nbias in naive time-varying per-protocol estimates of revascularization effects.\nCompliers have baseline health similar to that of the study population, while\ncontrol-group crossovers are far sicker."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2503.16758"
    ],
    "c_title":[
      "Nonlinear stability of compressible vortex sheets in three-dimensional\n  elastodynamics"
    ],
    "c_abstract":[
      "We investigate the nonlinear stability of compressible vortex sheet solutions\nfor three-dimensional (3D) isentropic elastic flows. Building upon previous\nresults on the weakly linear stability of elastic vortex sheets [19], we\nperform a detailed study of the roots of the Lopatinskii determinant and\nidentify a geometric stability condition associated with the deformation\ngradient. We employ an upper triangularization technique that isolates the\noutgoing modes into a closed system, where they appear only at the leading\norder. This enables us to derive energy estimates despite derivative loss. The\nmajor novelty of our approach includes the following two key aspects: (1) For\nthe 3D compressible Euler vortex sheets, the front symbol exhibits degenerate\nellipticity in certain frequency directions, which makes it challenging to\nensure the front's regularity using standard energy estimates. Our analysis\nreveals that the non-parallel structure of the deformation gradient tensor\nplays a crucial role in recovering ellipticity in the front symbol, thereby\nenhancing the regularity of the free interface. (2) Another significant\nchallenge in 3D arises from the strong degeneracy caused by the collision of\nrepeated roots and poles. Unlike in 2D, where such interactions are absent, we\nencounter a co-dimension one set in frequency space where a double root\ncoincides with a double pole. To resolve this, we refine Coulombel's\ndiagonalization framework [21] and construct a suitable transformation that\nreduces the degeneracy order of the Lopatinskii matrix, enabling the use of\nlocalized Garding-type estimates to control the characteristic components.\nFinally, we employ a Nash-Moser iteration scheme to establish the local\nexistence and nonlinear stability of vortex sheets under small initial\nperturbations, showing stability within a subsonic regime."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-247",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.00986"
    ],
    "b_title":[
      "Photometric Objects Around Cosmic Webs (PAC). VII. Disentangling Mass\n  and Environment Quenching with the Aid of Galaxy-halo Connection in\n  Simulations"
    ],
    "b_abstract":[
      "Star formation quenching in galaxies is a critical process in galaxy\nformation. It is widely believed that the quenching process is dominated by the\nmass of galaxies and\/or their environment. In Paper V, we addressed the\nchallenge to disentangle the effects of mass and environment by employing the\nPAC method, which combines spectroscopic and deep photometric surveys. This\napproach enabled us to measure the excess surface density of blue and red\ngalaxies around massive central galaxies down to $10^{9.0}M_{\\odot}$. However,\nit is not straightforward to completely separate the two effects. To address\nthis issue, in this paper, we derive the average quenched fraction of central\n(isolated) galaxies, $\\bar{f}_{\\mathrm{q}}^{\\mathrm{cen}}(M_{*})$, by combining\nthe 3D quenched fraction distribution $f^{\\mathrm{sat}}_{\\mathrm{q}}(r;\nM_{*,\\mathrm{cen}}, M_{*,\\mathrm{sat}})$, reconstructed from the\n$\\bar{n}_2w_{\\mathrm{p}}(r_{\\mathrm{p}})$ measurements, with the stellar\nmass-halo mass relation in N-body simulations from Paper IV, and the observed\ntotal quenched fraction, $\\bar{f}_{\\mathrm{q}}^{\\mathrm{all}}(M_{*})$. Using\n$f^{\\mathrm{sat}}_{\\mathrm{q}}(r;M_{*,\\mathrm{cen}},M_{*,\\mathrm{sat}})$,\n$\\bar{f}_{\\mathrm{q}}^{\\mathrm{cen}}(M_{*})$, and the galaxy-halo connection,\nwe assign a quenched probability to each (sub)halo in the simulation, enabling\na comprehensive study of galaxy quenching. We find that the mass-quenched\nfraction increases from 0.3 to 0.87 across the stellar mass range $[10^{9.5},\n10^{11.0}]M_{\\odot}$, while the environmental quenched fraction decreases from\n0.17 to 0.03. The mass effect dominates galaxy quenching across the entire\nstellar mass range we studied. Moreover, more massive host halos are more\neffective at quenching their satellite galaxies, while satellite stellar mass\nhas minimal influence on environmental quenching."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.06244"
    ],
    "c_title":[
      "Hate in the Time of Algorithms: Evidence on Online Behavior from a\n  Large-Scale Experiment"
    ],
    "c_abstract":[
      "Social media algorithms are thought to amplify variation in user beliefs,\nthus contributing to radicalization. However, quantitative evidence on how\nalgorithms and user preferences jointly shape harmful online engagement is\nlimited. I conduct an individually randomized experiment with 8 million users\nof an Indian TikTok-like platform, replacing algorithmic ranking with random\ncontent delivery. Exposure to \"toxic\" posts decreases by 27%, mainly due to\nreduced platform usage by users with higher interest in such content.\nStrikingly, these users increase engagement with toxic posts they find. Survey\nevidence indicates shifts to other platforms. Model-based counterfactuals\nhighlight the limitations of blanket algorithmic regulation."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-248",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17868"
    ],
    "b_title":[
      "Hybrid Near-field and Far-field Localization with Holographic MIMO"
    ],
    "b_abstract":[
      "Due to its ability to precisely control wireless beams, holographic\nmultiple-input multiple-output (HMIMO) is expected to be a promising solution\nto achieve high-accuracy localization. However, as the scale of HMIMO increases\nto improve beam control capability, the corresponding near-field (NF) region\nexpands, indicating that users may exist in both NF and far-field (FF) regions\nwith different electromagnetic transmission characteristics. As a result,\nexisting methods for pure NF or FF localization are no longer applicable. We\nconsider a hybrid NF and FF localization scenario in this paper, where a base\nstation (BS) locates multiple users in both NF and FF regions with the aid of a\nreconfigurable intelligent surface (RIS), which is a low-cost implementation of\nHMIMO. In such a scenario, it is difficult to locate the users and optimize the\nRIS phase shifts because whether the location of the user is in the NF or FF\nregion is unknown, and the channels of different users are coupled. To tackle\nthis challenge, we propose a RIS-enabled localization method that searches the\nusers in both NF and FF regions and tackles the coupling issue by jointly\nestimating all user locations. We derive the localization error bound by\nconsidering the channel coupling and propose an RIS phase shift optimization\nalgorithm that minimizes the derived bound. Simulations show the effectiveness\nof the proposed method and demonstrate the performance gain compared to pure NF\nand FF techniques."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08024"
    ],
    "c_title":[
      "Global boundedness in the higher-dimensional fully parabolic chemotaxis\n  with weak singular sensitivity and logistic source"
    ],
    "c_abstract":[
      "We consider the following chemotaxis system under homogeneous Neumann\nboundary conditions in a smooth, open, bounded domain $\\Omega \\subset\n\\mathbb{R}^n$ with $n \\geq 3$: \\begin{equation*}\n  \\begin{cases}\n  u_t = \\Delta u - \\chi \\nabla \\cdot \\left( \\frac{u}{v^k} \\nabla v \\right) + ru\n- \\mu u^2, & \\text{in } \\Omega \\times (0,T_{\\rm max}),\n  v_t = \\Delta v - \\alpha v + \\beta u, & \\text{in } \\Omega \\times (0,T_{\\rm\nmax}),\n  \\end{cases} \\end{equation*} where $k \\in (0,1)$, and $\\chi, r, \\mu, \\alpha,\n\\beta$ are positive parameters. In this paper, we demonstrate that for suitably\nsmooth initial data, the problem admits a unique nonnegative classical solution\nthat remains globally bounded in time when $\\mu$ is sufficiently large."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-249",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11962"
    ],
    "b_title":[
      "HInter: Exposing Hidden Intersectional Bias in Large Language Models"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) may portray discrimination towards certain\nindividuals, especially those characterized by multiple attributes (aka\nintersectional bias). Discovering intersectional bias in LLMs is challenging,\nas it involves complex inputs on multiple attributes (e.g. race and gender). To\naddress this challenge, we propose HInter, a test technique that\nsynergistically combines mutation analysis, dependency parsing and metamorphic\noracles to automatically detect intersectional bias in LLMs. HInter generates\ntest inputs by systematically mutating sentences using multiple mutations,\nvalidates inputs via a dependency invariant and detects biases by checking the\nLLM response on the original and mutated sentences. We evaluate HInter using\nsix LLM architectures and 18 LLM models (GPT3.5, Llama2, BERT, etc) and find\nthat 14.61% of the inputs generated by HInter expose intersectional bias.\nResults also show that our dependency invariant reduces false positives\n(incorrect test inputs) by an order of magnitude. Finally, we observed that\n16.62% of intersectional bias errors are hidden, meaning that their\ncorresponding atomic cases do not trigger biases. Overall, this work emphasize\nthe importance of testing LLMs for intersectional bias."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12459"
    ],
    "c_title":[
      "A Universal Raman Spectroscopic Framework for Defect Quantification in\n  Mono-to-Multilayer Graphenic Materials: The Graphene Atlas"
    ],
    "c_abstract":[
      "Point defects, though atomically small, significantly influence the\nproperties of 2D materials. A general method for characterizing point defect\ndensity ($n_{ D }$) in graphenic materials with arbitrary layer number ($n_{ L\n}$) is currently lacking. Here, we introduce the Graphene Atlas, a\nnon-destructive Raman spectroscopy-based framework for defect quantification in\ndiverse graphenic systems. We demonstrate that the relative fractions of the\ndouble-resonance D and 2D Raman bands, which arise from competing scattering\nprocesses, exhibit a universal relationship with $n_{ D }$, independent of $n_{\nL }$. Plotting Raman data on a plane defined by defect-related and layer\nnumber-related parameters enables a direct and quantitative determination of\n$n_{ D }$ and $n_{ L }$. This Graphene Atlas provides a transformative tool for\nreal-time defect quantification in scalable manufacturing of graphenic\nmaterials, bridging fundamental research and industrial applications. This\nframework establishes a new standard for defect characterization of graphenic\nsystems, facilitating their optimization for advanced technological\napplications."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-250",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12647"
    ],
    "b_title":[
      "Absence of superconductivity and density-wave transition in\n  ambient-pressure tetragonal La$_4$Ni$_3$O$_{10}$"
    ],
    "b_abstract":[
      "The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ and\nLa$_4$Ni$_3$O$_{10}$ under high pressure stimulates intensive research\ninterests. These nickelates crystallize in an orthogonal\/monoclinic structure\nwith tilted NiO$_6$ octahedra at ambient pressure and enter a density-wave-like\nphase at low temperatures. The application of pressure suppresses the\noctahedral tilting and triggers a transition to tetragonal structure (I4\/mmm),\nwhich is believed to be a key prerequisite for the emergence of superconducting\nstate. Here, by developing a high oxidative environment growth technology, we\nreport the first tetragonal nickelates La$_4$Ni$_3$O$_{10}$ microcrystals\nwithout octahedral tilting at ambient pressure. In tetragonal\nLa$_4$Ni$_3$O$_{10}$, transport measurements find that both density-wave and\nsuperconducting transitions are absent up to 160 GPa, indicating a robust\ntetragonal metallic ground state. Density functional theory calculations reveal\nthat the band structure of ambient-pressure tetragonal La$_4$Ni$_3$O$_{10}$\ninvolves more $d_{z2}$ orbital contribution to the Fermi surface, compared to\nthe monoclinic phase or the high-pressure superconducting tetragonal phase. The\nconcurrent absence of density-wave state and high-pressure superconductivity in\nour ambient-pressure tetragonal crystals of La$_4$Ni$_3$O$_{10}$ suggests an\nunderlying correlation between these two orders. It suggests that the\ntetragonal structure is not necessary, while the density-wave state is crucial\nfor the superconductivity in nickelates. Our findings impose important\nconstraints on the mechanism of pressure-induced superconductivity in\nnickelates and sheds new light on exploring ambient pressure high-temperature\nNi-based superconductors."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10066"
    ],
    "c_title":[
      "Augmenting Plane Straight-Line Graphs to Meet Parity Constraints"
    ],
    "c_abstract":[
      "Given a plane geometric graph $G$ on $n$ vertices, we want to augment it so\nthat given parity constraints of the vertex degrees are met. In other words,\ngiven a subset $R$ of the vertices, we are interested in a plane geometric\nsupergraph $G'$ such that exactly the vertices of $R$ have odd degree in\n$G'\\setminus G$. We show that the question whether such a supergraph exists can\nbe decided in polynomial time for two interesting cases. First, when the\nvertices are in convex position, we present a linear-time algorithm. Building\non this insight, we solve the case when $G$ is a plane geometric path in $O(n\n\\log n)$ time. This solves an open problem posed by Catana, Olaverri, Tejel,\nand Urrutia (Appl. Math. Comput. 2020)."
    ],
    "c_categories":[
      [
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-251",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02564"
    ],
    "b_title":[
      "Balanced Multi-view Clustering"
    ],
    "b_abstract":[
      "Multi-view clustering (MvC) aims to integrate information from different\nviews to enhance the capability of the model in capturing the underlying data\nstructures. The widely used joint training paradigm in MvC is potentially not\nfully leverage the multi-view information, since the imbalanced and\nunder-optimized view-specific features caused by the uniform learning objective\nfor all views. For instance, particular views with more discriminative\ninformation could dominate the learning process in the joint training paradigm,\nleading to other views being under-optimized. To alleviate this issue, we first\nanalyze the imbalanced phenomenon in the joint-training paradigm of multi-view\nclustering from the perspective of gradient descent for each view-specific\nfeature extractor. Then, we propose a novel balanced multi-view clustering\n(BMvC) method, which introduces a view-specific contrastive regularization\n(VCR) to modulate the optimization of each view. Concretely, VCR preserves the\nsample similarities captured from the joint features and view-specific ones\ninto the clustering distributions corresponding to view-specific features to\nenhance the learning process of view-specific feature extractors. Additionally,\na theoretical analysis is provided to illustrate that VCR adaptively modulates\nthe magnitudes of gradients for updating the parameters of view-specific\nfeature extractors to achieve a balanced multi-view learning procedure. In such\na manner, BMvC achieves a better trade-off between the exploitation of\nview-specific patterns and the exploration of view-invariance patterns to fully\nlearn the multi-view information for the clustering task. Finally, a set of\nexperiments are conducted to verify the superiority of the proposed method\ncompared with state-of-the-art approaches on eight benchmark MvC datasets."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15455"
    ],
    "c_title":[
      "A Precision Trial Case Study for Heterogeneous Treatment Effects in\n  Obstructive Sleep Apnea"
    ],
    "c_abstract":[
      "Precision medicine tailors treatments to individual patient characteristics,\nwhich is especially valuable for conditions like obstructive sleep apnea (OSA),\nwhere treatment responses vary widely. Traditional trials often overlook\nsubgroup differences, leading to suboptimal recommendations. Current approaches\nrely on pre-specified thresholds with inherent uncertainty, assuming these\nthresholds are correct-a flawed assumption. This case study compares\npre-specified thresholds to two advanced Bayesian methods: the established\nFK-BMA method and its novel variant, FK. The FK approach retains the\nflexibility of free-knot splines but omits variable selection, providing\nstable, interpretable models. Using biomarker data from large studies, this\ndesign identifies subgroups dynamically, allowing early trial termination or\nenrollment adjustments. Simulations in this specific context show FK improves\nprecision, efficiency, and subgroup detection, offering practical benefits over\nFK-BMA and advancing precision medicine for OSA."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-252",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18709"
    ],
    "b_title":[
      "Beamforming with Oversampled Time-Modulated Arrays"
    ],
    "b_abstract":[
      "The time-modulated array (TMA) is a simple array architecture in which each\nantenna is connected via a multi-throw switch. The switch acts as a modulator\nswitching state faster than the symbol rate. The phase shifting and beamforming\nis achieved by a cyclic shift of the periodical modulating signal across\nantennas. In this paper, the TMA mode of operation is proposed to improve the\nresolution of a conventional phase shifter. The TMAs are analyzed under\nconstrained switching frequency being a small multiple of the symbol rate. The\npresented generic signal model gives insight into the magnitude, phase and\nspacing of the harmonic components generated by the quantized modulating\nsequence. It is shown that the effective phase-shifting resolution can be\nimproved multiplicatively by the oversampling factor ($O$) at the cost of\nintroducing harmonics. Finally, the array tapering with an oversampled\nmodulating signal is proposed. The oversampling provides $O+1$ uniformly\ndistributed tapering amplitudes."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05977"
    ],
    "c_title":[
      "Comment on \"Galvano-rotational effect induced by electroweak\n  interactions in pulsars\""
    ],
    "c_abstract":[
      "In this comment, we obtain the corrected energy spectrum for Dvornikov's\npaper, that is, a spectrum in which the matter term, given by $V_L$, is\n''tied'' in both the radial and angular quantum numbers, given by $N$ and\n$J_z$. In particular, the error committed by Dvornikov arose from an\nincorrectly solved second-order differential equation. Besides, such an\nequation also had another error, i.e. since Dvornikov considered\nultrarelativistic particles where $m\\to 0$, it implies that all terms of this\nequation containing $m$ should vanish; however, that is not what happened.\nTherefore, solving in detail the corrected Dvornikov equation, we obtain the\ncorrected spectrum, where we verified that for $J_z>0$ (positive angular\nmomentum), $\\sigma=+1$ (upper component of the spinor) and $V_L>0$, or $J_z<0$\n(negative angular momentum), $\\sigma=-1$ (lower component of the spinor) and\n$V_L<0$, we recover the particular spectrum of Dvornikov's paper with $m^2=0$\n(as it should be)."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-253",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11994"
    ],
    "b_title":[
      "Power Amplifier-Aware Transmit Power Optimization for OFDM and SC-FDMA\n  Systems"
    ],
    "b_abstract":[
      "The Single Carrier-Frequency Division Multiple Access (SC-FDMA) is a\ntransmission technique used in the uplink of Long Term Evolution (LTE) and 5G\nsystems, as it is characterized by reduced transmitted signal envelope\nfluctuations in comparison to Orthogonal Frequency Division Multiplexing (OFDM)\ntechnique used in the downlink. This allows for higher energy efficiency of\nUser Equipments (UEs) while maintaining sufficient signal quality, measured by\nError Vector Magnitude (EVM), at the transmitter. This paper proposes to model\na nonlinear Power Amplifier (PA) influence while optimizing the transmit power\nin order to maximize the Signal to Noise and Distortion power Ratio (SNDR) at\nthe receiver, removing the transmitter-based EVM constraint. An analytic model\nof SNDR for the OFDM system and a semi-analytical model for the SC-FDMA system\nare provided. Numerical investigations show that the proposed transmit power\noptimization allows for improved signal quality at the receiver for both OFDM\nand SC-FDMA systems. However, SC-FDMA still outperforms OFDM in this matter.\nSuch a power amplifier-aware wireless transmitter optimization should be\nconsidered to boost the performance and sustainability of next-generation\nwireless systems, including Internet of Things (IoT) ones."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03295"
    ],
    "c_title":[
      "Investigating the exclusive toponium production at the LHC and FCC"
    ],
    "c_abstract":[
      "An exploratory study of the exclusive toponium production in $pp$, $pPb$ and\n$PbPb$ collisions at the center - of - mass energies of the Large Hadron\nCollider (LHC) and Future Circular Collider (FCC) is performed. Assuming that\nthe toponium is a pseudoscalar $t\\bar{t}$ bound state, we consider its\nproduction by photon and gluon - induced interactions. Results for the total\ncross - sections and associated rapidity distributions are presented, and the\nobservability of the toponium in exclusive processes is discussed."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-254",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11558"
    ],
    "b_title":[
      "A performance analysis of VM-based Trusted Execution Environments for\n  Confidential Federated Learning"
    ],
    "b_abstract":[
      "Federated Learning (FL) is a distributed machine learning approach that has\nemerged as an effective way to address recent privacy concerns. However, FL\nintroduces the need for additional security measures as FL alone is still\nsubject to vulnerabilities such as model and data poisoning and inference\nattacks. Confidential Computing (CC) is a paradigm that, by leveraging\nhardware-based trusted execution environments (TEEs), protects the\nconfidentiality and integrity of ML models and data, thus resulting in a\npowerful ally of FL applications. Typical TEEs offer an application-isolation\nlevel but suffer many drawbacks, such as limited available memory and debugging\nand coding difficulties. The new generation of TEEs offers a virtual machine\n(VM)-based isolation level, thus reducing the porting effort for existing\napplications. In this work, we compare the performance of VM-based and\napplication-isolation level TEEs for confidential FL (CFL) applications. In\nparticular, we evaluate the impact of TEEs and additional security mechanisms\nsuch as TLS (for securing the communication channel). The results, obtained\nacross three datasets and two deep learning models, demonstrate that the new\nVM-based TEEs introduce a limited overhead (at most 1.5x), thus paving the way\nto leverage public and untrusted computing environments, such as HPC facilities\nor public cloud, without detriment to performance."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.PF"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05913"
    ],
    "c_title":[
      "Tensor Learning and Compression of N-phonon Interactions"
    ],
    "c_abstract":[
      "Phonon interactions from lattice anharmonicity govern thermal properties and\nheat transport in materials. These interactions are described by n-th order\ninteratomic force constants (n-IFCs), which can be viewed as high-dimensional\ntensors correlating the motion of n atoms, or equivalently encoding n-phonon\nscattering processes in momentum space. Here, we introduce a tensor\ndecomposition to efficiently compress n-IFCs for arbitrary order n. Using\ntensor learning, we find optimal low-rank approximations of n-IFCs by solving\nthe resulting optimization problem. Our approach reveals the inherent low\ndimensionality of phonon-phonon interactions and allows compression of the 3\nand 4-IFC tensors by factors of up to $10^3-10^4$ while retaining high accuracy\nin calculations of phonon scattering rates and thermal conductivity.\nCalculations of thermal conductivity using the compressed n-IFCs achieve a\nspeed-up by nearly three orders of magnitude with >98% accuracy relative to the\nreference uncompressed solution. These calculations include both 3- and\n4-phonon scattering and are shown for a diverse range of materials (Si, HgTe,\nMgO, and TiNiSn). In addition to accelerating state-of-the-art thermal\ntransport calculations, the method shown here paves the way for modeling\nstrongly anharmonic materials and higher-order phonon interactions."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-255",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09113"
    ],
    "b_title":[
      "Constraint-Guided Learning of Data-driven Health Indicator Models: An\n  Application on the Pronostia Bearing Dataset"
    ],
    "b_abstract":[
      "This paper presents a constraint-guided deep learning framework for\ndeveloping physically consistent health indicators in bearing prognostics and\nhealth management. Conventional data-driven methods often lack physical\nplausibility, while physics-based models are limited by incomplete system\nknowledge. To address this, we integrate domain knowledge into deep learning\nusing constraints to enforce monotonicity, bound output values between 1 and 0\n(representing healthy to failed states), and ensure consistency between signal\nenergy trends and health indicator estimates. This eliminates the need for\ncomplex loss term balancing. We implement constraint-guided gradient descent\nwithin an autoencoder architecture, creating a constrained autoencoder.\nHowever, the framework is adaptable to other architectures. Using\ntime-frequency representations of accelerometer signals from the Pronostia\ndataset, our constrained model generates smoother, more reliable degradation\nprofiles compared to conventional methods, aligning with expected physical\nbehavior. Performance is assessed using three metrics: trendability,\nrobustness, and consistency. Compared to a conventional baseline, the\nconstrained model improves all three. Another baseline, incorporating\nmonotonicity via a soft-ranking loss function, outperforms in trendability but\nfalls short in robustness and consistency. An ablation study confirms that the\nmonotonicity constraint enhances trendability, the boundary constraint ensures\nconsistency, and the energy-health consistency constraint improves robustness.\nThese findings highlight the effectiveness of constraint-guided deep learning\nin producing reliable, physically meaningful health indicators, offering a\npromising direction for future prognostic applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10287"
    ],
    "c_title":[
      "Beyond-Hubbard pairing in a cuprate ladder"
    ],
    "c_abstract":[
      "The Hubbard model is believed to capture the essential physics of cuprate\nsuperconductors. However, recent theoretical studies suggest that it fails to\nreproduce a robust and homogeneous superconducting ground state. Here, using\nresonant inelastic x-ray scattering and density matrix renormalization group\ncalculations, we show that magnetic excitations in the prototypical cuprate\nladder Sr$_{14}$Cu$_{24}$O$_{41}$ are inconsistent with those of a simple\nHubbard model. The magnetic response of hole carriers, contributing to an\nemergent branch of spin excitations, is strongly suppressed. This effect is the\nconsequence of d-wave-like pairing, enhanced by nearly an order of magnitude\nthrough a large nearest-neighbor attractive interaction. The similarity between\ncuprate ladders and the two-dimensional compounds suggests that such an\nenhanced hole pairing may be a universal feature of superconducting cuprates."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-256",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05555"
    ],
    "b_title":[
      "Improving Zero-Shot Object-Level Change Detection by Incorporating\n  Visual Correspondence"
    ],
    "b_abstract":[
      "Detecting object-level changes between two images across possibly different\nviews is a core task in many applications that involve visual inspection or\ncamera surveillance. Existing change-detection approaches suffer from three\nmajor limitations: (1) lack of evaluation on image pairs that contain no\nchanges, leading to unreported false positive rates; (2) lack of\ncorrespondences (i.e., localizing the regions before and after a change); and\n(3) poor zero-shot generalization across different domains. To address these\nissues, we introduce a novel method that leverages change correspondences (a)\nduring training to improve change detection accuracy, and (b) at test time, to\nminimize false positives. That is, we harness the supervision labels of where\nan object is added or removed to supervise change detectors, improving their\naccuracy over previous work by a large margin. Our work is also the first to\npredict correspondences between pairs of detected changes using estimated\nhomography and the Hungarian algorithm. Our model demonstrates superior\nperformance over existing methods, achieving state-of-the-art results in change\ndetection and change correspondence accuracy across both in-distribution and\nzero-shot benchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11642"
    ],
    "c_title":[
      "Initial data for a black string and a Kaluza-Klein bubble:\n  Space-dependent compactification radius"
    ],
    "c_abstract":[
      "As the first step to explore the nonlinear dynamics of an extra dimension in\nthe Kaluza-Klein (KK) spacetime with black objects through numerical\nrelativity, we generate time-symmetric initial data of a black string and\/or a\nKK bubble with space-dependent compactification radius. The initial data\ndeveloped in this paper are classified into three types. First, we present\nanalytic initial data with SO(3) symmetry whose three-dimensional section is\nspherically symmetric. These initial data include a black string without a KK\nbubble, a black string trapping a KK bubble, and a naked KK bubble. Second, we\npresent analytic initial data for multiple black strings with varying\ncompactification radius, which is a natural generalization of the\nBrill-Lindquist initial data for four-dimensional general relativity. Finally,\nwe develop a numerical method for generating the initial data with a black\nstring and a KK bubble located at different positions, which would be useful in\nsimulating what happens when an expanding KK bubble meets black objects in\ndynamical context."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-257",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06795"
    ],
    "b_title":[
      "Robotic Ultrasound-Guided Femoral Artery Reconstruction of\n  Anatomically-Representative Phantoms"
    ],
    "b_abstract":[
      "Femoral artery access is essential for numerous clinical procedures,\nincluding diagnostic angiography, therapeutic catheterization, and emergency\ninterventions. Despite its critical role, successful vascular access remains\nchallenging due to anatomical variability, overlying adipose tissue, and the\nneed for precise ultrasound (US) guidance. Errors in needle placement can lead\nto severe complications, restricting the procedure to highly skilled clinicians\nin controlled hospital settings. While robotic systems have shown promise in\naddressing these challenges through autonomous scanning and vessel\nreconstruction, clinical translation remains limited due to reliance on\nsimplified phantom models that fail to capture human anatomical complexity. In\nthis work, we present a method for autonomous robotic US scanning of bifurcated\nfemoral arteries, and validate it on five vascular phantoms created from real\npatient computed tomography (CT) data. Additionally, we introduce a video-based\ndeep learning US segmentation network tailored for vascular imaging, enabling\nimproved 3D arterial reconstruction. The proposed network achieves a Dice score\nof 89.21% and an Intersection over Union of 80.54% on a newly developed\nvascular dataset. The quality of the reconstructed artery centerline is\nevaluated against ground truth CT data, demonstrating an average L2 deviation\nof 0.91+\/-0.70 mm, with an average Hausdorff distance of 4.36+\/-1.11mm. This\nstudy is the first to validate an autonomous robotic system for US scanning of\nthe femoral artery on a diverse set of patient-specific phantoms, introducing a\nmore advanced framework for evaluating robotic performance in vascular imaging\nand intervention."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18272"
    ],
    "c_title":[
      "The Periodic Table and the Group SO(4,4)"
    ],
    "c_abstract":[
      "The periodic system of chemical elements is represented within the framework\nof the weight diagram of the Lie algebra of the fourth rank of the rotation\ngroup of an eight-dimensional pseudo-Euclidean space. The hydrogen realization\nof the Cartan subalgebra and Weyl generators of the group algebra is studied.\nThe root structure of the subalgebras of the group algebra of a conformal group\nin the framework of a twofold covering is analyzed. Based on the analysis, the\nCartan-Weyl basis of the group algebra is determined. The root and weight\ndiagrams are constructed. A mass formula associated with each node of the\nweight diagram is introduced. Spin is interpreted as the fourth generator of\nthe Cartan subalgebra, whose two eigenvalues correspond to two\nthree-dimensional projections of the weight diagram containing elements of the\nperiodic system from hydrogen to moscovium (the first projection) and from\nhelium to oganesson (the second projection). One of the main advantages of the\nproposed group-theoretic construction of the periodic system is the natural\ninclusion of antimatter in the general scheme."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-258",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16394"
    ],
    "b_title":[
      "Propagation Performance of Terahertz Channels in Lunar Dust"
    ],
    "b_abstract":[
      "The growing momentum in lunar exploration programs and urgent need for robust\ncommunication systems capable of operating in dust-laden lunar environments\nnecessitate comprehensive understanding of channel propagation characteristics\nin lunar conditions. In this article, we present a comprehensive analysis of\nterahertz (THz) channel propagation characteristics through lunar dust\nenvironments, critical for establishing reliable communication and sensing\ninfrastructure on the Moon. We develop an extended Mie scattering model\nincorporating the unique properties of lunar dust particles (Apollo 11 sample\n10084, Apollo 14 sample 14003, and Apollo 17 sample 70051), including their\nirregular morphology, dielectric characteristics, and charge-dependent\nbehavior. Through theoretical analysis and experimental verification, we\nexamine both power and bit error rate (BER) performance across varying dust\nconditions. Our results reveal distinct relationships between particle charge\nlevels, morphological characteristics, and channel performance with power loss\npatterns and BER evolution. Our findings provide essential guidelines for\ndeveloping robust lunar communication systems that integrate sensing\ncapabilities, contributing to the establishment of sustainable lunar\ninfrastructure."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.18209"
    ],
    "c_title":[
      "Hyers-Ulam stability of homomorphisms and *-homomorphisms on Hilbert\n  C*-modules"
    ],
    "c_abstract":[
      "In this paper, we introduce the idea of $\\ast$-homomorphism on a Hilbert\n$C^{*}$-module. Furthermore, we prove the Hyers-Ulam stability of homomorphisms\nand $\\ast$-homomorphisms on Hilbert $C^{*}$-modules using the fixed point\nmethod."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-259",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03732"
    ],
    "b_title":[
      "More Modality, More AI: Exploring Design Opportunities of AI-Based\n  Multi-modal Remote Monitoring Technologies for Early Detection of Mental\n  Health Sequelae in Youth Concussion Patients"
    ],
    "b_abstract":[
      "Anxiety, depression, and suicidality are common mental health sequelae\nfollowing concussion in youth patients, often exacerbating concussion symptoms\nand prolonging recovery. Despite the critical need for early detection of these\nmental health symptoms, clinicians often face challenges in accurately\ncollecting patients' mental health data and making clinical decision-making in\na timely manner. Today's remote patient monitoring (RPM) technologies offer\nopportunities to objectively monitor patients' activities, but they were not\nspecifically designed for youth concussion patients; moreover, the large amount\nof data collected by RPM technologies may also impose significant workloads on\nclinicians to keep up with and use the data. To address these gaps, we employed\na three-stage study consisting of a formative study, interface design, and\ndesign evaluation. We first conducted a formative study through semi-structured\ninterviews with six highly professional concussion clinicians and identified\nclinicians' key challenges in remotely collecting patient information and\naccessing patient treatment compliance. Subsequently, we proposed preliminary\nclinician-facing interface designs with the integration of AI-based RPM\ntechnologies (AI-RPM), followed by design evaluation sessions with highly\nprofessional concussion clinicians. Clinicians underscored the value of\nintegrating multi-modal AI-RPM technologies to support clinicians'\ndecision-making while emphasizing the importance of customizable interfaces\nwith explainability and multiple responsible design considerations."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.13602"
    ],
    "c_title":[
      "Room temperature observation of the anomalous in-plane Hall effect in\n  epitaxial thin films of a Weyl ferromagnet"
    ],
    "c_abstract":[
      "Topologically nontrivial electronic states can give rise to novel anomalous\nHall effects. The potential appearance of these effects at room temperature\nholds promise for their application in magnetic sensing, spintronics, and\nenergy harvesting technology. The anomalous in-plane Hall effect (IPHE) is\npredicted to arise in topological magnetic materials when an external magnetic\nfield is applied within the sample plane. Because of stringent symmetry\nrequirements, the conclusive detection of the anomalous IPHE induced by\ntopological electronic states remains challenging, and the study of anomalous\nHall effects is often confined to cryogenic conditions. Combining molecular\nbeam epitaxy of the kagome metal Fe$_3$Sn with measurements of the electric\nHall effect and theoretical calculations, we propose and experimentally\ndemonstrate that the interplay of the kagome lattice motif with spin-orbit\ncoupling and canted ferromagnetism with large exchange interactions gives rise\nto the anomalous IPHE at room temperature that is induced by topological Weyl\npoints in the electronic band structure. Synthesizing a topological\nheterostructure including layers of Fe$_3$Sn and ferromagnetic CoFeB, we\nfurther show the enhancement of the anomalous IPHE through the magnetic stray\nfield of the CoFeB layer. Our work establishes a design paradigm for\ntopological magnets and heterostructures to discover and control novel\nanomalous Hall effects toward their use in technological applications."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-260",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01679"
    ],
    "b_title":[
      "LIBRA: Measuring Bias of Large Language Model from a Local Context"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have significantly advanced natural language\nprocessing applications, yet their widespread use raises concerns regarding\ninherent biases that may reduce utility or harm for particular social groups.\nDespite the advancement in addressing LLM bias, existing research has two major\nlimitations. First, existing LLM bias evaluation focuses on the U.S. cultural\ncontext, making it challenging to reveal stereotypical biases of LLMs toward\nother cultures, leading to unfair development and use of LLMs. Second, current\nbias evaluation often assumes models are familiar with the target social\ngroups. When LLMs encounter words beyond their knowledge boundaries that are\nunfamiliar in their training data, they produce irrelevant results in the local\ncontext due to hallucinations and overconfidence, which are not necessarily\nindicative of inherent bias. This research addresses these limitations with a\nLocal Integrated Bias Recognition and Assessment Framework (LIBRA) for\nmeasuring bias using datasets sourced from local corpora without crowdsourcing.\nImplementing this framework, we develop a dataset comprising over 360,000 test\ncases in the New Zealand context. Furthermore, we propose the Enhanced\nIdealized CAT Score (EiCAT), integrating the iCAT score with a beyond knowledge\nboundary score (bbs) and a distribution divergence-based bias measurement to\ntackle the challenge of LLMs encountering words beyond knowledge boundaries.\nOur results show that the BERT family, GPT-2, and Llama-3 models seldom\nunderstand local words in different contexts. While Llama-3 exhibits larger\nbias, it responds better to different cultural contexts. The code and dataset\nare available at: https:\/\/github.com\/ipangbo\/LIBRA."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05614"
    ],
    "c_title":[
      "Resolvent bounds for repulsive potentials"
    ],
    "c_abstract":[
      "We prove limiting absorption resolvent bounds for the semiclassical\nSchr\\\"odinger operator with a repulsive potential in dimension $n\\ge 3$, which\nmay have a singularity at the origin. As an application, we obtain time decay\nfor the weighted energy of the solution to the associated wave equation with a\nshort range repulsive potential and compactly supported initial data."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-261",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08813"
    ],
    "b_title":[
      "Structure theorems for Gorenstein ideals of codimension four with small\n  number of generators"
    ],
    "b_abstract":[
      "In this article we study minimal free resolutions of Gorenstein ideals of\ncodimension four, using methods coming from representation theory. We introduce\nfamilies of higher structure maps associated with such resolution, defined\nsimilarly to the codimension three case. As our main application, we prove that\nevery Gorenstein ideal of codimension four minimally generated by six elements\nis a hyperplane section of a Gorenstein ideal of codimension three,\nstrengthening a result by Herzog-Miller and Vasconcelos-Villarreal. We state\nanalogous conjectural results for ideals minimally generated by seven and eight\nelements."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16315"
    ],
    "c_title":[
      "Accretion with Back-Reaction onto Cylindrically Symmetric Black Hole\n  with Energy Conditions Analysis"
    ],
    "c_abstract":[
      "This paper is devoted to study back-reaction effects from matter accretion\nonto a cylindrically symmetric black hole using a perturbative scheme, focusing\non cases where accretion reaches a quasi-steady state. We examine three\ndistinct models by deriving corrections to the metric coefficients and\nobtaining expressions for the mass function. We analyze energy conditions, the\nself-consistency of the corrected solution and present formulas for the\ncorrected apparent horizon and discussed thermodynamic properties. Our results\nalign with the Vaidya form near the apparent horizon, regardless of the\nenergy-momentum tensor's form. Furthermore, we show that for a charged\ncylindrically symmetric black hole, the corrected mass term resembles that of\nthe static case, indicating that charge does not alter the corrected metric\nform in this perturbative approach."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-262",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02262"
    ],
    "b_title":[
      "Analyses of features of magnetic cycles at different amounts of dynamo\n  supercriticality: Solar dynamo is about two times critical"
    ],
    "b_abstract":[
      "The growth of a large-scale magnetic field in the Sun and stars is usually\npossible when the dynamo number (D) is above a critical value Dc. As the star\nages, its rotation rate and thus D decrease. Hence, the question is how far the\nsolar dynamo is from the critical dynamo transition. To answer this question,\nwe have performed a set of simulations using Babcock-Leighton type dynamo\nmodels at different values of dynamo supercriticality and analyzed various\nfeatures of magnetic cycle. By comparing the recovery rates of the dynamo from\nthe Maunder minimum and statistics (numbers and durations) of the grand minima\nand maxima with that of observations and we show that the solar dynamo is only\nabout two times critical and thus not highly supercritical. The observed\ncorrelation between the polar field proxy and the following cycle amplitudes\nand Gnevyshev-Ohl rule are also compatible with this conclusion."
    ],
    "b_categories":[
      [
        "astro-ph.SR",
        "physics.plasm-ph",
        "physics.space-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.16610"
    ],
    "c_title":[
      "Embracing Reconfigurable Antennas in the Tri-hybrid MIMO Architecture\n  for 6G and Beyond"
    ],
    "c_abstract":[
      "Multiple-input multiple-output (MIMO) communication has led to immense\nenhancements in data rates and efficient spectrum management. The evolution of\nMIMO, though, has been accompanied by increased hardware complexity and array\nsizes, causing the system power consumption to increase. Despite past advances\nin power-efficient hybrid architectures, new solutions are needed to enable\nextremely large-scale MIMO deployments for 6G and beyond. In this paper, we\nintroduce a novel architecture that integrates low-power reconfigurable\nantennas with both digital and analog precoding. This \\emph{tri-hybrid}\napproach addresses key limitations in traditional and hybrid MIMO systems by\nimproving power consumption and adds a new layer for signal processing. We\nprovide an analysis of the proposed architecture and compare its performance\nwith existing solutions, including fully-digital and hybrid MIMO systems. The\nresults demonstrate significant improvements in energy efficiency, highlighting\nthe potential of the tri-hybrid system to meet the growing demands of future\nwireless networks. We conclude the paper with a summary of design and\nimplementation challenges, including the need for technological advancements in\nreconfigurable array hardware and tunable antenna parameters."
    ],
    "c_categories":[
      [
        "cs.ET",
        "cs.IT",
        "cs.NI",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-263",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10865"
    ],
    "b_title":[
      "A theory of ecological invasions and its implications for\n  eco-evolutionary dynamics"
    ],
    "b_abstract":[
      "Predicting the outcomes of species invasions is a central goal of ecology, a\ntask made especially challenging due to ecological feedbacks. To address this,\nwe develop a general theory of ecological invasions applicable to a wide\nvariety of ecological models: including Lotka-Volterra models, consumer\nresource models, and models with cross feeding. Importantly, our framework\nremains valid even when invading evolved (non-random) communities and accounts\nfor invasion-driven species extinctions. We derive analytical expressions\nrelating invasion fitness to invader abundance, shifts in the community, and\nextinction probabilities. These results can be understood through a new\nquantity we term ``dressed invasion fitness'', which augments the traditional\nnotion of invasion fitness by incorporating ecological feedbacks. We apply our\ntheory to analyze short-term evolutionary dynamics through a series of\ninvasions by mutants whose traits are correlated with an existing parent. We\ndemonstrate that, generically, mutants and parents can coexist, often by\ndriving the extinction of low-abundance species. We validate theoretical\npredictions against experimental datasets spanning ecosystems from plants to\nmicrobial protists. Our work highlights the central role of ecological\nfeedbacks in shaping community responses to invasions and mutations, suggesting\nthat parent-mutant coexistence is widespread in eco-evolutionary dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2503.03490"
    ],
    "c_title":[
      "On the construction of polynomial Poisson algebras: a novel grading\n  approach"
    ],
    "c_abstract":[
      "In this work, we refine recent results on the explicit construction of\npolynomial algebras associated with commutants of subalgebras in enveloping\nalgebras of Lie algebras by considering an additional grading with respect to\nthe subalgebra. It is shown that such an approach simplifies and systematizes\nthe explicit derivation of the Lie--Poisson brackets of elements in the\ncommutant, and several fundamental properties of the grading are given. The\nprocedure is illustrated by revisiting three relevant reduction chains\nassociated with the rank-two complex simple Lie algebra\n$\\mathfrak{sl}(3,\\mathbb{C})$. Specifically, we analyze the reduction chains\n$\\mathfrak{so}(3) \\subset \\mathfrak{su}(3)$, corresponding to the Elliott model\nin nuclear physics, the chain $\\mathfrak{o}(3) \\subset\n\\mathfrak{sl}(3,\\mathbb{C})$ associated with the decomposition of the\nenveloping algebra of $\\mathfrak{sl}(3,\\mathbb{C})$ as a sum of modules, and\nthe reduction chain $\\mathfrak{h} \\subset \\mathfrak{sl}(3,\\mathbb{C})$\nconnected to the Racah algebra $R(3)$. In addition, a description of the\nclassification of the centralizer with respect to the Cartan subalgebra\n$\\mathfrak{h}$ associated with the classical series $A_n$ in connection with\nits root system is reconsidered. As an illustration of the procedure, the case\nof $S(A_3)^\\mathfrak{h}$ is considered in detail, which is connected with the\nrank-two Racah algebra for specific realizations of the generators as vector\nfields. This case has attracted interest with regard to orthogonal polynomials."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-264",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09156"
    ],
    "b_title":[
      "Absolute Risk Prediction for Cannabis Use Disorder Using Bayesian\n  Machine Learning"
    ],
    "b_abstract":[
      "Introduction: Substance use disorders (SUDs) have emerged as a pressing\npublic health crisis in the United States, with adolescent substance use often\nleading to SUDs in adulthood. Effective strategies are needed to prevent this\nprogression. To help in filling this need, we develop a novel and the\nfirst-ever absolute risk prediction model for cannabis use disorder (CUD) for\nadolescent or young adult cannabis users.\n  Methods: We train a Bayesian machine learning model that provides a\npersonalized CUD absolute risk for adolescent or young adult cannabis users\nusing data from the National Longitudinal Study of Adolescent to Adult Health.\nModel performance is assessed using 5-fold cross-validation (CV) with area\nunder the curve (AUC) and ratio of the expected to observed number of cases\n(E\/O). External validation of the final model is conducted using two\nindependent datasets.\n  Results: The proposed model has five risk factors: biological sex,\ndelinquency, and scores on personality traits of conscientiousness,\nneuroticism, and openness. For predicting CUD risk within five years of first\ncannabis use, AUC and E\/O, computed via 5-fold CV, were 0.68 and 0.95,\nrespectively. For the same type of prediction in external validation, AUC\nvalues were 0.64 and 0.75, with E\/O values of 0.98 and 1, indicating good\ndiscrimination and calibration performances of the model.\n  Discussion and Conclusion: The proposed model is the first absolute risk\nprediction model for an SUD. It can aid clinicians in identifying\nadolescent\/youth substance users at a high risk of developing CUD in future for\nclinically appropriate interventions."
    ],
    "b_categories":[
      [
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.13116"
    ],
    "c_title":[
      "Linea alba 3D morphometric variability by CT scan exploration"
    ],
    "c_abstract":[
      "Purpose: The width of the Linea alba, which is often gauged by inter-rectus\ndistance, is a key risk factor for incisional hernia and recurrence. Previous\nstudies provided limited descriptions with no consideration for width, location\nvariability, or curvature. We aimed to offer a comprehensive 3D anatomical\nanalysis of the Linea alba, emphasizing its variations across diverse\ndemographics. Methods: Using open source software, 2D sagittal plane and 3D\nreconstructions were performed on 117 patients' CT scans. Linea alba length,\ncurvature assessed by the sagitta (the longest perpendicular segment between\nxipho-pubic line and the Linea alba), and continuous width along the height\nwere measured. Results: The Linea alba had a rhombus shape, with a maximum\nwidth at the umbilicus of 4.4$\\pm$1.9 cm and a larger width above the umbilicus\nthan below. Its length was 37.5$\\pm$3.6 cm, which increased with body mass\nindex (BMI) (p$\\leq$0.001), and was shorter in women (p$\\leq$0.001). The\nsagitta was 2.6$\\pm$2.2 cm, three times higher in the obese group\n(p$\\leq$0.001), majorated with age (p=0.009), but was independent of gender\n(p=0.212). Linea alba width increased with both age and BMI (p$\\leq$0.001,\np=0.002), being notably wider in women halfway between the umbilicus and pubis\n(p=0.007). Conclusion: This study provides an exhaustive 3D description of\nLinea alba's anatomical variability, presenting new considerations for\ncurvature. This method provides a patient-specific anatomy description of the\nLinea alba. Further studies are needed to determine whether 3D reconstruction\ncorrelates with pathologies, such as hernias and diastasis recti."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-265",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13597"
    ],
    "b_title":[
      "A Comprehensive Survey on Spectral Clustering with Graph Structure\n  Learning"
    ],
    "b_abstract":[
      "Spectral clustering is a powerful technique for clustering high-dimensional\ndata, utilizing graph-based representations to detect complex, non-linear\nstructures and non-convex clusters. The construction of a similarity graph is\nessential for ensuring accurate and effective clustering, making graph\nstructure learning (GSL) central for enhancing spectral clustering performance\nin response to the growing demand for scalable solutions. Despite advancements\nin GSL, there is a lack of comprehensive surveys specifically addressing its\nrole within spectral clustering. To bridge this gap, this survey presents a\ncomprehensive review of spectral clustering methods, emphasizing on the\ncritical role of GSL. We explore various graph construction techniques,\nincluding pairwise, anchor, and hypergraph-based methods, in both fixed and\nadaptive settings. Additionally, we categorize spectral clustering approaches\ninto single-view and multi-view frameworks, examining their applications within\none-step and two-step clustering processes. We also discuss multi-view\ninformation fusion techniques and their impact on clustering data. By\naddressing current challenges and proposing future research directions, this\nsurvey provides valuable insights for advancing spectral clustering\nmethodologies and highlights the pivotal role of GSL in tackling large-scale\nand high-dimensional data clustering tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08523"
    ],
    "c_title":[
      "Microscopic Origin of Reduced Magnetic Order in a Frustrated Metal"
    ],
    "c_abstract":[
      "Although magnetic frustration in metals provides a promising avenue for novel\nquantum phenomena, their microscopic interpretation is often challenging. Here\nwe use the face-centered cubic intermetallic HoInCu$_4$ as model material to\nshow that Hamiltonians neglecting the charge degree of freedom are appropriate\nfor frustrated metals possessing low density of states at the Fermi surface.\nThrough neutron scattering techniques we determine matching magnetic exchange\ninteractions in the paramagnetic and field-polarized states using an effective\nspin-1 Heisenberg Hamiltonian, for which we identify antiferromagnetic nearest\nand next-nearest neighbour interactions $J_1$ and $J_2$ that are close to the\ncritical ratio $J_2$\/$J_1$ = 1\/2. The study further provides evidence that\nspin-wave theory fails to predict the low-energy spin dynamics in the\nantiferromagnetic zero-field state, which is dominated by overdamped magnetic\nexcitations. We conclude that the low-energy fluctuations arise from quantum\nfluctuations, accounting for the missing moment of the strongly renormalized\nmagnetic long-range order."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-266",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07446"
    ],
    "b_title":[
      "EigenGS Representation: From Eigenspace to Gaussian Image Space"
    ],
    "b_abstract":[
      "Principal Component Analysis (PCA), a classical dimensionality reduction\ntechnique, and 2D Gaussian representation, an adaptation of 3D Gaussian\nSplatting for image representation, offer distinct approaches to modeling\nvisual data. We present EigenGS, a novel method that bridges these paradigms\nthrough an efficient transformation pipeline connecting eigenspace and\nimage-space Gaussian representations. Our approach enables instant\ninitialization of Gaussian parameters for new images without requiring\nper-image optimization from scratch, dramatically accelerating convergence.\nEigenGS introduces a frequency-aware learning mechanism that encourages\nGaussians to adapt to different scales, effectively modeling varied spatial\nfrequencies and preventing artifacts in high-resolution reconstruction.\nExtensive experiments demonstrate that EigenGS not only achieves superior\nreconstruction quality compared to direct 2D Gaussian fitting but also reduces\nnecessary parameter count and training time. The results highlight EigenGS's\neffectiveness and generalization ability across images with varying resolutions\nand diverse categories, making Gaussian-based image representation both\nhigh-quality and viable for real-time applications."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10797"
    ],
    "c_title":[
      "Phase-Amplitude Representation of Continuum States"
    ],
    "c_abstract":[
      "A numerical method of solving the one-dimensional Schrodinger equation for\nthe regular and irregular continuum states using the phase-amplitude\nrepresentation is presented. Our solution acquires the correct Dirac-delta\nnormalization by wisely enforcing the amplitude and phase boundary values. Our\nnumerical test involving point-wise relative errors with the known Coulomb\nfunctions shows that the present method approximates both the regular and\nirregular wavefunctions with similar, excellent accuracy. This is done by using\nnew basis polynomials that, among other advantages, can elegantly enforce the\nderivative continuity of any order. The current phase-amplitude method is\nimplemented here to study the continuum states of Coulomb-screened potentials.\nWe discovered that, during the parametric transition from a Hydrogen atom to\nthe Yukawa potential, the electronic density at the origin exhibits surprising\noscillation -- a phenomenon apparently unique to the continuum states."
    ],
    "c_categories":[
      [
        "physics.atom-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-267",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12118"
    ],
    "b_title":[
      "Quantum Thermodynamics on a limit cycle"
    ],
    "b_abstract":[
      "We consider a periodic quantum clock based on cooperative resonance\nfluorescence at zero temperature.\n  In the quantum case, this system has an exact steady state and the limit\ncycle appears in conditional quantum dynamics under homodyne detection. We show\nthat the intrinsic quantum phase diffusion on the limit cycle leads to\nfluctuations in the period. By simulating the stochastic master equation for\nhomodyne detection, we extract the statistical properties of the clock period.\nWe show that the precision of the clock satisfies the quantum-thermodynamic\nkinetic uncertainty relations. As energy dissipation increases, the clock\nquality improves, fully validating, in a quantum stochastic system, the link\nbetween energy dissipation and clock precision."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.16368"
    ],
    "c_title":[
      "Foundation Models for CPS-IoT: Opportunities and Challenges"
    ],
    "c_abstract":[
      "Methods from machine learning (ML) have transformed the implementation of\nPerception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS)\nand the Internet of Things (IoT), replacing mechanistic and basic statistical\nmodels with those derived from data. However, the first generation of ML\napproaches, which depend on supervised learning with annotated data to create\ntask-specific models, faces significant limitations in scaling to the diverse\nsensor modalities, deployment configurations, application tasks, and operating\ndynamics characterizing real-world CPS-IoT systems. The success of\ntask-agnostic foundation models (FMs), including multimodal large language\nmodels (LLMs), in addressing similar challenges across natural language,\ncomputer vision, and human speech has generated considerable enthusiasm for and\nexploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics\npipelines, promising to reduce the need for costly task-specific engineering.\n  Nonetheless, a significant gap persists between the current capabilities of\nFMs and LLMs in the CPS-IoT domain and the requirements they must meet to be\nviable for CPS-IoT applications. In this paper, we analyze and characterize\nthis gap through a thorough examination of the state of the art and our\nresearch, which extends beyond it in various dimensions. Based on the results\nof our analysis and research, we identify essential desiderata that CPS-IoT\ndomain-specific FMs and LLMs must satisfy to bridge this gap. We also propose\nactions by CPS-IoT researchers to collaborate in developing key community\nresources necessary for establishing FMs and LLMs as foundational tools for the\nnext generation of CPS-IoT systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-268",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11721"
    ],
    "b_title":[
      "Identifying intermediate mass binary black hole mergers in AGN disks\n  using LISA"
    ],
    "b_abstract":[
      "We show that Laser Interferometer Space Antenna can uniquely identify the\nsites of intermediate-mass binary black hole (IMBBH) mergers if they occur in\nActive Galactic Nuclei (AGN) disks with a gas density $\\rho\\geq10^{-12} \\, {\\rm\ng\/cc}$ via measurement of dynamical friction effect in the gravitational\nwaveform. We find that even a single observation of a gravitational wave source\nwith a total mass of $10^3 M_{\\odot}$ and a mass ratio of 2 at a luminosity\ndistance of 3 Gpc is sufficient to confidently associate the merger to be in an\nAGN disk with a density $\\sim 10^{-12} \\, {\\rm g\/cc}$, as it allows estimation\nof the density with an error bar ${\\cal O}(100\\%)$. This provides a new way of\ninferring AGN disk densities that complement traditional X-ray observations.\nFurther, we find that neglecting the presence of environmental effects in the\nwaveform models used for parameter estimation can bias the chirp mass, mass\nratio and arrival time of a merger. If not corrected, this can significantly\nimpact our ability to carry out multiband data analysis of IMBBHs that combines\ninformation from LISA and the ground-based gravitational wave detectors."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.13407"
    ],
    "c_title":[
      "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust\n  Multi-Teacher Knowledge Distillation Framework"
    ],
    "c_abstract":[
      "Deep learning has achieved significant success in the field of remote sensing\nimage change detection (CD), yet two major challenges remain: the scarcity of\nsub-meter, all-inclusive open-source CD datasets, and the difficulty of\nachieving consistent and satisfactory detection results across images with\nvarying change areas. To address these issues, we introduce the JL1-CD dataset,\nwhich contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5\nto 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation\n(MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD\ndatasets demonstrate that the MTKD framework significantly improves the\nperformance of CD models with various network architectures and parameter\nsizes, achieving new state-of-the-art results. The code is available at\nhttps:\/\/github.com\/circleLZY\/MTKD-CD."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-269",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15896"
    ],
    "b_title":[
      "Modeling the emission lines from r-process elements in Supernova nebulae"
    ],
    "b_abstract":[
      "The origin of heavy r-process elements in the universe is still a matter of\ngreat debate, with a confirmed scenario being neutron star (NS) mergers.\nAdditional relevant sites could be specific classes of events, such as\ngamma-ray burst (GRB) Supernovae (SNe), where a central engine could push\nneutron-rich material outwards, contributing to the ejecta of the massive\nexploding star. Here, we investigate our ability to infer the production of\nheavy elements in such scenarios, on the basis of the observed nebular\nemission. We solve the steady-state ionization, level population, and thermal\nbalance, for optically thin ejecta in non-local thermodynamic equilibrium\n(NLTE), in order to explore the role of heavy elements in cooling the gas, and\ntheir imprint in the emergent spectrum a few hundreds days post-explosion. We\nfind that heavy elements would be relevant in the cooling process of the nebula\nonly if they account for at least $\\sim1\\%$ of the total ejected mass, at the\ntypical kinetic temperatures of a few thousands K. However, even in the absence\nof such amount, a few $0.1\\%$ of the total ejected mass could be instead\nsufficient to leave a detectable imprint around $\\sim1-10~\\mathrm{\\mu m}$. This\nwavelength range, which would be relatively clean from features due to light\nelements, would be instead robustly populated by lines from heavy elements\narising from forbidden transitions in their atomic fine structures. Hence, the\nnew generation of telescopes, represented by the James Webb Space Telescope\n(JWST), will most likely allow for their detection."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02514"
    ],
    "c_title":[
      "On the optimal stopping problem for diffusions and an approximation\n  result for stopping times"
    ],
    "c_abstract":[
      "In this article, we study the classical finite-horizon optimal stopping\nproblem for multidimensional diffusions through an approach that differs from\nwhat is typically found in the literature. More specifically, we first prove a\nkey equality for the value function from which a series of results easily\nfollow. This equality enables us to prove that the classical stopping time, at\nwhich the value function equals the terminal gain, is the smallest optimal\nstopping time, without resorting to the martingale approach and relying on the\nSnell envelope. Moreover, this equality allows us to rigorously demonstrate the\ndynamic programming principle, thus showing that the value function is the\nviscosity solution to the corresponding variational inequality. Such an\nequality also shows that the value function does not change when the class of\nstopping times varies. To prove this equality, we use an approximation result\nfor stopping times, which is of independent interest and can find application\nin other stochastic control problems involving stopping times, as switching or\nimpulsive problems, also of mean field type."
    ],
    "c_categories":[
      [
        "math.OC",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-270",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16451"
    ],
    "b_title":[
      "Think-Then-React: Towards Unconstrained Human Action-to-Reaction\n  Generation"
    ],
    "b_abstract":[
      "Modeling human-like action-to-reaction generation has significant real-world\napplications, like human-robot interaction and games. Despite recent\nadvancements in single-person motion generation, it is still challenging to\nwell handle action-to-reaction generation, due to the difficulty of directly\npredicting reaction from action sequence without prompts, and the absence of a\nunified representation that effectively encodes multi-person motion. To address\nthese challenges, we introduce Think-Then-React (TTR), a large\nlanguage-model-based framework designed to generate human-like reactions.\nFirst, with our fine-grained multimodal training strategy, TTR is capable to\nunify two processes during inference: a thinking process that explicitly infers\naction intentions and reasons corresponding reaction description, which serve\nas semantic prompts, and a reacting process that predicts reactions based on\ninput action and the inferred semantic prompts. Second, to effectively\nrepresent multi-person motion in language models, we propose a unified motion\ntokenizer by decoupling egocentric pose and absolute space features, which\neffectively represents action and reaction motion with same encoding. Extensive\nexperiments demonstrate that TTR outperforms existing baselines, achieving\nsignificant improvements in evaluation metrics, such as reducing FID from 3.988\nto 1.942."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11714"
    ],
    "c_title":[
      "Monotonicity of the jump set and jump amplitudes in one-dimensional TV\n  denoising"
    ],
    "c_abstract":[
      "We revisit the classical problem of denoising a one-dimensional scalar-valued\nfunction by minimizing the sum of an $L^2$ fidelity term and the total\nvariation, scaled by a regularization parameter. This study focuses on proving\nthat the jump set of solutions, corresponding to discontinuities or edges, as\nwell as the amplitude of the jumps are nonincreasing as the regularization\nparameter increases. Our results apply to input functions in $L^\\infty$ with\nleft and right approximate limits everywhere, extending beyond the traditional\nsetting of functions of bounded variation. The proof leverages competitor\nconstructions and convexity properties of the taut string problem, a well-known\nequivalent formulation of the TV model. Such a monotonicity property reflects\nthat the extent to which geometric and topological features of the original\nsignal are preserved is consistent with the amount of smoothing desired when\nformulating the denoising method."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-271",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11337"
    ],
    "b_title":[
      "A Comparison of Human and Machine Learning Errors in Face Recognition"
    ],
    "b_abstract":[
      "Machine learning applications in high-stakes scenarios should always operate\nunder human oversight. Developing an optimal combination of human and machine\nintelligence requires an understanding of their complementarities, particularly\nregarding the similarities and differences in the way they make mistakes. We\nperform extensive experiments in the area of face recognition and compare two\nautomated face recognition systems against human annotators through a\ndemographically balanced user study. Our research uncovers important ways in\nwhich machine learning errors and human errors differ from each other, and\nsuggests potential strategies in which human-machine collaboration can improve\naccuracy in face recognition."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.CY",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05344"
    ],
    "c_title":[
      "Higher rank prioritary bundles on ruled surfaces and their global\n  sections"
    ],
    "c_abstract":[
      "Let $X$ be a ruled surface over a nonsingular curve $C$ of genus $g\\geq0$.\nThe main goal of this paper is to construct simple prioritary vector bundles of\nany rank $r$ on $X$ and to give effective bounds for the dimension of their\nmodule of global sections."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-272",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01526"
    ],
    "b_title":[
      "On quivers, spectral networks and black holes"
    ],
    "b_abstract":[
      "It was recently found that connection coefficients of the Heun equation can\nbe derived in closed form using crossing symmetry in two-dimensional Liouville\ntheory via the Nekrasov-Shatashvili functions. In this work, we systematize\nthis approach to second-order linear ODEs of Fuchsian type, which arise in the\ndescription of N = 2, four-dimensional quiver gauge theories. After presenting\nthe general procedure, we focus on the specific case of Fuchsian equations with\nfive regular singularities and present some applications to black hole\nperturbation theory. First, we consider a massive scalar perturbation of the\nSchwarzschild black hole in AdS7. Next, we analyze vector type perturbations of\nthe Reissner-Nordstr\\\"om-AdS5 black hole. We also discuss the implications of\nour results in the context of the AdS\/CFT correspondence and present explicit\nresults in the large spin limit, where we make connection with the light-cone\nbootstrap. Furthermore, using the spectral network technology, we identify the\nregion of the moduli space in Seiberg-Witten theory that is relevant for the\nstudy of black hole quasinormal modes. Our results suggest that, in some cases,\nthis region corresponds to the strong-coupling regime, highlighting the\npotential applicability of the conformal GMN TBA framework to address scenarios\nwhere the gravitational dictionary implies that the instanton counting\nparameters are not parametrically small."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.11421"
    ],
    "c_title":[
      "Linear, decoupled and positivity-preserving staggered mesh schemes for\n  general dissipative systems with arbitrary energy distributions"
    ],
    "c_abstract":[
      "In this paper, we develop a novel staggered mesh (SM) approach for general\nnonlinear dissipative systems with arbitrary energy distributions (including\ncases with known or unknown energy lower bounds). Based on this framework, we\npropose several second-order semi-discrete schemes that maintain linearity,\ncomputational decoupling, and unconditional energy stability. Firstly, for\ndissipative systems with known energy lower bounds, we introduce a positive\nauxiliary variable $V(t)$ to substitute the total energy functional,\nsubsequently discretizing it on staggered temporal meshes to ensure that the\nenergy remains non-increasing regardless of the size of time step. The newly\ndeveloped schemes achieve full computational decoupling, maintaining\nessentially the same computational expense as conventional implicit-explicit\nmethods while demonstrating significantly improved accuracy. Furthermore, we\nrigorously establish the positivity preservation of the discrete variable\n$V^{n+1\/2}$ which is a crucial property ensuring numerical stability and\naccuracy. Theoretical analysis confirms second-order temporal convergence for\nthe proposed SM schemes. Secondly, for dissipative systems lacking well-defined\nenergy lower bounds, we devise an alternative auxiliary variable formulation\nand extend the SM framework to maintain unconditional energy stability while\npreserving numerical effectiveness and accuracy. Finally, comprehensive\nnumerical experiments, including benchmark problem simulations, validate the\nproposed schemes' efficacy and demonstrate their superior performance\ncharacteristics."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-273",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16237"
    ],
    "b_title":[
      "3D radio data visualisation in open science platforms for\n  next-generation observatories"
    ],
    "b_abstract":[
      "Next-generation telescopes will bring groundbreaking discoveries but they\nwill also present new technological challenges. The Square Kilometre Array\nObservatory (SKAO) will be one of the most demanding scientific\ninfrastructures, with a projected data output of 700 PB per year to be\ndistributed to a network of SKA Regional Centres. Current tools are not fully\nsuited to manage such massive data volumes, therefore, new research is required\nto transform science archives from data providers into service providers. In\nthis paper we examine how a science archive can deliver advanced visualisation\ncapabilities for the SKA science archive. In particular, we have conducted a\nthorough exploration of existing visualisation software for astronomy and other\nfields to identify tools capable of addressing Big Data requirements. Using\nselected technologies, we have developed a prototype archive that provides\naccess to interactive visualisations of 3D radio data through web-based\ninterfaces, adhering to International Virtual Observatory Alliance (IVOA)\nrecommendations to favour interoperability and Open Science practices. In\naddition, we discuss how current IVOA recommendations support these\nvisualisation capabilities and how they could be expanded. Our prototype\narchive includes a service to generate 3D models on the fly as a server\noperation, enabling remote visualisations in a flexible manner; for instance, a\nset of parameters can be used to customise the models and their visualisation.\nWe have used SKA precursor and pathfinder data to test its usability and\nscalability, concluding that remote visualisation is a viable solution for\nhandling high-volume data. However, our prototype is constrained by memory\nlimitations, requiring techniques to reduce memory usage."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11753"
    ],
    "c_title":[
      "HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real\n  and Synthetic Claims"
    ],
    "c_abstract":[
      "Misinformation can be countered with fact-checking, but the process is costly\nand slow. Identifying checkworthy claims is the first step, where automation\ncan help scale fact-checkers' efforts. However, detection methods struggle with\ncontent that is 1) multimodal, 2) from diverse domains, and 3) synthetic. We\nintroduce HintsOfTruth, a public dataset for multimodal checkworthiness\ndetection with $27$K real-world and synthetic image\/claim pairs. The mix of\nreal and synthetic data makes this dataset unique and ideal for benchmarking\ndetection methods. We compare fine-tuned and prompted Large Language Models\n(LLMs). We find that well-configured lightweight text-based encoders perform\ncomparably to multimodal models but the first only focus on identifying\nnon-claim-like content. Multimodal LLMs can be more accurate but come at a\nsignificant computational cost, making them impractical for large-scale\napplications. When faced with synthetic data, multimodal models perform more\nrobustly"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-274",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00110"
    ],
    "b_title":[
      "New constraints on the evolution of the MHI-M* scaling relation\n  combining CHILES and MIGHTEE-HI data"
    ],
    "b_abstract":[
      "The improved sensitivity of interferometric facilities to the 21-cm line of\natomic hydrogen (HI) enables studies of its properties in galaxies beyond the\nlocal Universe. In this work, we perform a 21 cm line spectral stacking\nanalysis combining the MIGHTEE and CHILES surveys in the COSMOS field to derive\na robust HI-stellar mass relation at z=0.36. In particular, by stacking\nthousands of star-forming galaxies subdivided into stellar mass bins, we\noptimize the signal-to-noise ratio of targets and derive mean HI masses in the\ndifferent stellar mass intervals for the investigated galaxy population. We\ncombine spectra from the two surveys, estimate HI masses, and derive the\nscaling relation log10(MHI) = (0.32 +- 0.04)log10(M*) + (6.65 +- 0.36). Our\nfindings indicate that galaxies at z=0.36 are HI richer than those at z=0, but\nHI poorer than those at z=1, with a slope consistent across redshift,\nsuggesting that stellar mass does not significantly affect HI exchange\nmechanisms. We also observe a slower growth rate HI relative to the molecular\ngas, supporting the idea that the accretion of cold gas is slower than the rate\nof consumption of molecular gas to form stars. This study contributes to\nunderstanding the role of atomic gas in galaxy evolution and sets the stage for\nfuture development of the field in the upcoming SKA era."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02268"
    ],
    "c_title":[
      "What Kind of Visual Tokens Do We Need? Training-free Visual Token\n  Pruning for Multi-modal Large Language Models from the Perspective of Graph"
    ],
    "c_abstract":[
      "Recent Multimodal Large Language Models(MLLMs) often use a large number of\nvisual tokens to compensate their visual shortcoming, leading to excessive\ncomputation and obvious visual redundancy. In this paper, we investigate what\nkind of visual tokens are needed for MLLMs, and reveal that both foreground and\nbackground tokens are critical for MLLMs given the varying difficulties of\nexamples. Based on this observation, we propose a graph-based method towards\ntraining-free visual token pruning, termed G-Prune.In particular, G-Prune\nregards visual tokens as nodes, and construct their connections based on their\nsemantic similarities. Afterwards, the information flow is propagated via\nweighted links, and the most important tokens after iterations are kept for\nMLLMs, which can be front or background.To validate G-Prune, we apply it to a\nrecent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of\nbenchmarks.The experiment results show that G-Prune can greatly reduce\ncomputation overhead while retaining high performance on both coarse- and\nfine-grained tasks. For instance, G-Prune can reduce 63.57\\% FLOPs of\nLLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\\% and 2.34\\% accuracy drops,\nrespectively."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-275",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10658"
    ],
    "b_title":[
      "LimTopic: LLM-based Topic Modeling and Text Summarization for Analyzing\n  Scientific Articles limitations"
    ],
    "b_abstract":[
      "The limitations sections of scientific articles play a crucial role in\nhighlighting the boundaries and shortcomings of research, thereby guiding\nfuture studies and improving research methods. Analyzing these limitations\nbenefits researchers, reviewers, funding agencies, and the broader academic\ncommunity. We introduce LimTopic, a strategy where Topic generation in\nLimitation sections in scientific articles with Large Language Models (LLMs).\nHere, each topic contains the title and Topic Summary. This study focuses on\neffectively extracting and understanding these limitations through topic\nmodeling and text summarization, utilizing the capabilities of LLMs. We\nextracted limitations from research articles and applied an LLM-based topic\nmodeling integrated with the BERtopic approach to generate a title for each\ntopic and Topic Sentences. To enhance comprehension and accessibility, we\nemployed LLM-based text summarization to create concise and generalizable\nsummaries for each topic Topic Sentences and produce a Topic Summary. Our\nexperimentation involved prompt engineering, fine-tuning LLM and BERTopic, and\nintegrating BERTopic with LLM to generate topics, titles, and a topic summary.\nWe also experimented with various LLMs with BERTopic for topic modeling and\nvarious LLMs for text summarization tasks. Our results showed that the\ncombination of BERTopic and GPT 4 performed the best in terms of silhouette and\ncoherence scores in topic modeling, and the GPT4 summary outperformed other LLM\ntasks as a text summarizer."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00415"
    ],
    "c_title":[
      "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents"
    ],
    "c_abstract":[
      "MarketSenseAI is a novel framework for holistic stock analysis which\nleverages Large Language Models (LLMs) to process financial news, historical\nprices, company fundamentals and the macroeconomic environment to support\ndecision making in stock analysis and selection. In this paper, we present the\nlatest advancements on MarketSenseAI, driven by rapid technological expansion\nin LLMs. Through a novel architecture combining Retrieval-Augmented Generation\nand LLM agents, the framework processes SEC filings and earnings calls, while\nenriching macroeconomic analysis through systematic processing of diverse\ninstitutional reports. We demonstrate a significant improvement in fundamental\nanalysis accuracy over the previous version. Empirical evaluation on S\\&P 100\nstocks over two years (2023-2024) shows MarketSenseAI achieving cumulative\nreturns of 125.9% compared to the index return of 73.5%, while maintaining\ncomparable risk profiles. Further validation on S\\&P 500 stocks during 2024\ndemonstrates the framework's scalability, delivering a 33.8% higher Sortino\nratio than the market. This work marks a significant advancement in applying\nLLM technology to financial analysis, offering insights into the robustness of\nLLM-driven investment strategies."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "q-fin.CP",
        "q-fin.PM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-276",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11524"
    ],
    "b_title":[
      "The Scaled Polarity transform and related inequalities"
    ],
    "b_abstract":[
      "In this paper we deal with generalizations of the Mahler volume product for\nlog-concave functions. We show that the polarity transform $\\mathcal A$ can be\nrescaled so that the Mahler product it induces has upper and lower bounds of\nthe same asymptotics. We discuss a similar result for the $\\mathcal J$\ntransform.\n  As an application, we extend the K\\\"onig-Milman duality of entropy result to\nthe class of geometric log-concave functions."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20387"
    ],
    "c_title":[
      "InsTaG: Learning Personalized 3D Talking Head from Few-Second Video"
    ],
    "c_abstract":[
      "Despite exhibiting impressive performance in synthesizing lifelike\npersonalized 3D talking heads, prevailing methods based on radiance fields\nsuffer from high demands for training data and time for each new identity. This\npaper introduces InsTaG, a 3D talking head synthesis framework that allows a\nfast learning of realistic personalized 3D talking head from few training data.\nBuilt upon a lightweight 3DGS person-specific synthesizer with universal motion\npriors, InsTaG achieves high-quality and fast adaptation while preserving\nhigh-level personalization and efficiency. As preparation, we first propose an\nIdentity-Free Pre-training strategy that enables the pre-training of the\nperson-specific model and encourages the collection of universal motion priors\nfrom long-video data corpus. To fully exploit the universal motion priors to\nlearn an unseen new identity, we then present a Motion-Aligned Adaptation\nstrategy to adaptively align the target head to the pre-trained field, and\nconstrain a robust dynamic head structure under few training data. Experiments\ndemonstrate our outstanding performance and efficiency under various data\nscenarios to render high-quality personalized talking heads."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-277",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09551"
    ],
    "b_title":[
      "Intra-day Solar and Power Forecast for Optimization of Intraday Market\n  Participation"
    ],
    "b_abstract":[
      "The prediction of solar irradiance enhances reliability in photovoltaic (PV)\nsolar plant generation and grid integration. In Colombia, PV plants face\npenalties if energy production deviates beyond governmental thresholds from\nintraday market offers. This research employs Long Short-Term Memory (LSTM) and\nBidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV\nplant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour\nhorizon and 10-minute resolution. While Bi-LSTM showed superior performance,\nthe LSTM model achieved comparable results with significantly reduced training\ntime (6 hours versus 18 hours), making it computationally advantageous. The\nLSTM predictions were averaged to create an hourly resolution model, evaluated\nusing Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square\nError, and Mean Absolute Percentage Error metrics. Comparison with the Global\nForecast System (GFS) revealed similar performance, with both models\neffectively capturing daily solar irradiance patterns. The forecast model\nintegrates with an Object-Oriented power production model, enabling accurate\nenergy offers in the intraday market while minimizing penalty costs."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09172"
    ],
    "c_title":[
      "LOB-Bench: Benchmarking Generative AI for Finance -- an Application to\n  Limit Order Book Data"
    ],
    "c_abstract":[
      "While financial data presents one of the most challenging and interesting\nsequence modelling tasks due to high noise, heavy tails, and strategic\ninteractions, progress in this area has been hindered by the lack of consensus\non quantitative evaluation paradigms. To address this, we present LOB-Bench, a\nbenchmark, implemented in python, designed to evaluate the quality and realism\nof generative message-by-order data for limit order books (LOB) in the LOBSTER\nformat. Our framework measures distributional differences in conditional and\nunconditional statistics between generated and real LOB data, supporting\nflexible multivariate statistical evaluation. The benchmark also includes\nfeatures commonly used LOB statistics such as spread, order book volumes, order\nimbalance, and message inter-arrival times, along with scores from a trained\ndiscriminator network. Lastly, LOB-Bench contains \"market impact metrics\", i.e.\nthe cross-correlations and price response functions for specific events in the\ndata. We benchmark generative autoregressive state-space models, a (C)GAN, as\nwell as a parametric LOB model and find that the autoregressive GenAI approach\nbeats traditional model classes."
    ],
    "c_categories":[
      [
        "cs.CE",
        "cs.LG",
        "q-fin.CP",
        "q-fin.TR"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-278",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16003"
    ],
    "b_title":[
      "Mechano-Bactericidal Surfaces Achieved by Epitaxial Growth of\n  Metal-Organic Frameworks"
    ],
    "b_abstract":[
      "Mechano-bactericidal (MB) surfaces have been proposed as an emerging strategy\nfor preventing biofilm formation. Unlike antibiotics and metal ions that\nchemically interfere with cellular processes, MB nanostructures cause physical\ndamage to the bacteria. The antibacterial performance of artificial MB surfaces\nrelies on rational control of surface features, which is difficult to achieve\nfor large surfaces in real-life applications. Herein, we report a facile and\nscalable method for fabricating MB surfaces based on metal-organic frameworks\n(MOFs) using epitaxial MOF-on-MOF hybrids as building blocks with nanopillars\nof less than 5 nm tip diameter, 200 nm base diameter, and 300 nm length. Two\nmethods of MOF surface assembly, in-situ growth and ex-situ dropcasting, result\nin surfaces with nanopillars in different orientations, both presenting MB\nactions (bactericidal efficiency of 83% for E. coli). Distinct MB mechanisms,\nincluding stretching, impaling, and apoptosis-like death induced by mechanical\ninjury are discussed with the observed bacterial morphology on the obtained MOF\nsurfaces."
    ],
    "b_categories":[
      [
        "physics.bio-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11905"
    ],
    "c_title":[
      "Upcycling Text-to-Image Diffusion Models for Multi-Task Capabilities"
    ],
    "c_abstract":[
      "Text-to-image synthesis has witnessed remarkable advancements in recent\nyears. Many attempts have been made to adopt text-to-image models to support\nmultiple tasks. However, existing approaches typically require\nresource-intensive re-training or additional parameters to accommodate for the\nnew tasks, which makes the model inefficient for on-device deployment. We\npropose Multi-Task Upcycling (MTU), a simple yet effective recipe that extends\nthe capabilities of a pre-trained text-to-image diffusion model to support a\nvariety of image-to-image generation tasks. MTU replaces Feed-Forward Network\n(FFN) layers in the diffusion model with smaller FFNs, referred to as experts,\nand combines them with a dynamic routing mechanism. To the best of our\nknowledge, MTU is the first multi-task diffusion modeling approach that\nseamlessly blends multi-tasking with on-device compatibility, by mitigating the\nissue of parameter inflation. We show that the performance of MTU is on par\nwith the single-task fine-tuned diffusion models across several tasks including\nimage editing, super-resolution, and inpainting, while maintaining similar\nlatency and computational load (GFLOPs) as the single-task fine-tuned models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-279",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19402"
    ],
    "b_title":[
      "A note on spontaneous symmetry breaking in the mean-field Bose gas"
    ],
    "b_abstract":[
      "We consider the homogeneous mean-field Bose gas at positive temperature. We\nshow that spontaneous $U(1)$ symmetry breaking occurs if and only if the system\ndisplays Bose-Einstein condensation in the sense that the one-particle density\nmatrix of the Gibbs state has a macroscopic eigenvalue."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.AP",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.02565"
    ],
    "c_title":[
      "Efficient Graph Condensation via Gaussian Process"
    ],
    "c_abstract":[
      "Graph condensation reduces the size of large graphs while preserving\nperformance, addressing the scalability challenges of Graph Neural Networks\ncaused by computational inefficiencies on large datasets. Existing methods\noften rely on bi-level optimization, requiring extensive GNN training and\nlimiting their scalability. To address these issues, this paper proposes Graph\nCondensation via Gaussian Process (GCGP), a novel and computationally efficient\napproach to graph condensation. GCGP utilizes a Gaussian Process (GP), with the\ncondensed graph serving as observations, to estimate the posterior distribution\nof predictions. This approach eliminates the need for the iterative and\nresource-intensive training typically required by GNNs. To enhance the\ncapability of the GCGP in capturing dependencies between function values, we\nderive a specialized covariance function that incorporates structural\ninformation. This covariance function broadens the receptive field of input\nnodes by local neighborhood aggregation, thereby facilitating the\nrepresentation of intricate dependencies within the nodes. To address the\nchallenge of optimizing binary structural information in condensed graphs,\nConcrete random variables are utilized to approximate the binary adjacency\nmatrix in a continuous counterpart. This relaxation process allows the\nadjacency matrix to be represented in a differentiable form, enabling the\napplication of gradient-based optimization techniques to discrete graph\nstructures. Experimental results show that the proposed GCGP method efficiently\ncondenses large-scale graph data while preserving predictive performance,\naddressing the scalability and efficiency challenges. The implementation of our\nmethod is publicly available at https:\/\/github.com\/WANGLin0126\/GCGP."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-280",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17894"
    ],
    "b_title":[
      "FetchBot: Object Fetching in Cluttered Shelves via Zero-Shot Sim2Real"
    ],
    "b_abstract":[
      "Object fetching from cluttered shelves is an important capability for robots\nto assist humans in real-world scenarios. Achieving this task demands robotic\nbehaviors that prioritize safety by minimizing disturbances to surrounding\nobjects, an essential but highly challenging requirement due to restricted\nmotion space, limited fields of view, and complex object dynamics. In this\npaper, we introduce FetchBot, a sim-to-real framework designed to enable\nzero-shot generalizable and safety-aware object fetching from cluttered shelves\nin real-world settings. To address data scarcity, we propose an efficient\nvoxel-based method for generating diverse simulated cluttered shelf scenes at\nscale and train a dynamics-aware reinforcement learning (RL) policy to generate\nobject fetching trajectories within these scenes. This RL policy, which\nleverages oracle information, is subsequently distilled into a vision-based\npolicy for real-world deployment. Considering that sim-to-real discrepancies\nstem from texture variations mostly while from geometric dimensions rarely, we\npropose to adopt depth information estimated by full-fledged depth foundation\nmodels as the input for the vision-based policy to mitigate sim-to-real gap. To\ntackle the challenge of limited views, we design a novel architecture for\nlearning multi-view representations, allowing for comprehensive encoding of\ncluttered shelf scenes. This enables FetchBot to effectively minimize\ncollisions while fetching objects from varying positions and depths, ensuring\nrobust and safety-aware operation. Both simulation and real-robot experiments\ndemonstrate FetchBot's superior generalization ability, particularly in\nhandling a broad range of real-world scenarios, includ"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09643"
    ],
    "c_title":[
      "On Cantor sets with arbitrary Hausdorff and packing measures"
    ],
    "c_abstract":[
      "For every couple of Hausdorff functions $\\psi, \\varphi$ verifying some mild\nassumptions, we construct a compact subset $ K $ of the Baire space such that\nthe $\\varphi$-Hausdorff measure and the $\\psi$-packing measure on $ K $ are\nboth finite and positive. We then embed such examples in any\ninfinite-dimensional Banach space to answer positively to a question of Fan on\nthe existence of metric spaces with arbitrary scales."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.FA",
        "math.MG",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-281",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.21220"
    ],
    "b_title":[
      "XAIxArts Manifesto: Explainable AI for the Arts"
    ],
    "b_abstract":[
      "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.02932"
    ],
    "c_title":[
      "Dominance Regions of Pursuit-evasion Games in Non-anticipative\n  Information Patterns"
    ],
    "c_abstract":[
      "The evader's dominance region is an important concept and the foundation of\ngeometric methods for pursuit-evasion games. This article mainly reveals the\nrelevant properties of the evader's dominance region, especially in\nnon-anticipative information patterns. We can use these properties to research\npursuit-evasion games in non-anticipative information patterns. The core\nproblem is under what condition the pursuer has a non-anticipative strategy to\nprevent the evader leaving its initial dominance region before being captured\nregardless of the evader's strategy. We first define the evader's dominance\nregion by the shortest path distance, and we rigorously prove for the first\ntime that the initial dominance region of the evader is the reachable region of\nthe evader in the open-loop sense. Subsequently, we prove that there exists a\nnon-anticipative strategy by which the pursuer can capture the evader before\nthe evader leaves its initial dominance region's closure in the absence of\nobstacles. For cases with obstacles, we provide a counter example to illustrate\nthat such a non-anticipative strategy does not always exist, and provide a\nnecessary condition for the existence of such strategy. Finally, we consider a\nscenario with a single corner obstacle and provide a sufficient condition for\nthe existence of such a non-anticipative strategy. At the end of this article,\nwe discuss the application of the evader's dominance region in target defense\ngames. This article has important reference significance for the design of\nnon-anticipative strategies in pursuit-evasion games with obstacles."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-282",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08768"
    ],
    "b_title":[
      "Instantaneous directional channel measurements at 14 GHz and 160 GHz via\n  a virtual circular array"
    ],
    "b_abstract":[
      "In this paper a novel frequency-scalable rotary platform design is introduced\nwhich allows for flexible directional channel measurements using different\ntypes of antennas, and which can also be used with frequency extenders for\nmeasurements up to the THz region. The measurement platform has been applied to\nmeasure the channel properties including the direction of arrival at the FR3\nfrequency 14 GHz and in the D-band at 160 GHz in a large hall indoor\nenvironment with LOS distances up to 40 m. The results show very good agreement\nof strong path components for both frequencies as well as interesting\ndependencies of delay spread, angular spread, and Ricean K- factor on distance\nand frequency and can be used to parameterize a path loss model."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15265"
    ],
    "c_title":[
      "Self-assembly of Dipolar Crystals from Magnetic Colloids"
    ],
    "c_abstract":[
      "We study the self-assembly of magnetic colloids using the Stockmayer (SM)\nmodel characterized by short-range Lennard-Jones interactions and long-range\ndipole-dipole interactions. Using molecular dynamics simulations, we design\ncooling protocols that yield perfectly assembled single-domain magnetic\ncrystals. We identify cooling rates at which the system transforms from an\namorphous glass to a crystal, where magnetic ordering promotes crystalline\norder. Remarkably, we observe that the latter develops via a spontaneous\ntransition rather than through the traditional nucleation and growth mechanism.\nFor a weakly dipolar fluid ($\\mu=1$), this self-assembly results in a\nface-centered cubic (FCC) colloidal crystal with dipole moments chained along\nthe (111) direction. For fluids with higher dipole moment ($\\mu = 2.5$), the\ncrystal structure shifts towards a body-centered orthorhombic (BCO) arrangement\ndue to the compression of chains from strong dipolar attractions. These results\nprovide valuable insights into the mechanisms driving crystallization in\nmagnetic fluids, opening new avenues for understanding the formation of\nmagnetically responsive colloidal magnetic crystals with promising\napplications."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-283",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10370"
    ],
    "b_title":[
      "Explicit Formulas for the Alexander Polynomial of Pretzel Knots"
    ],
    "b_abstract":[
      "We provide explicit formulas for the Alexander polynomial of Pretzel knots\nand establish several immediate corollaries, including the characterization of\nPretzel knots with a trivial Alexander polynomial."
    ],
    "b_categories":[
      [
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.01122"
    ],
    "c_title":[
      "ACCORD: Alleviating Concept Coupling through Dependence Regularization\n  for Text-to-Image Diffusion Personalization"
    ],
    "c_abstract":[
      "Image personalization has garnered attention for its ability to customize\nText-to-Image generation using only a few reference images. However, a key\nchallenge in image personalization is the issue of conceptual coupling, where\nthe limited number of reference images leads the model to form unwanted\nassociations between the personalization target and other concepts. Current\nmethods attempt to tackle this issue indirectly, leading to a suboptimal\nbalance between text control and personalization fidelity. In this paper, we\ntake a direct approach to the concept coupling problem through statistical\nanalysis, revealing that it stems from two distinct sources of dependence\ndiscrepancies. We therefore propose two complementary plug-and-play loss\nfunctions: Denoising Decouple Loss and Prior Decouple loss, each designed to\nminimize one type of dependence discrepancy. Extensive experiments demonstrate\nthat our approach achieves a superior trade-off between text control and\npersonalization fidelity."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-284",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17709"
    ],
    "b_title":[
      "GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration"
    ],
    "b_abstract":[
      "GUI agents hold significant potential to enhance the experience and\nefficiency of human-device interaction. However, current methods face\nchallenges in generalizing across applications (apps) and tasks, primarily due\nto two fundamental limitations in existing datasets. First, these datasets\noverlook developer-induced structural variations among apps, limiting the\ntransferability of knowledge across diverse software environments. Second, many\nof them focus solely on navigation tasks, which restricts their capacity to\nrepresent comprehensive software architectures and complex user interactions.\nTo address these challenges, we introduce GUI-Xplore, a dataset meticulously\ndesigned to enhance cross-application and cross-task generalization via an\nexploration-and-reasoning framework. GUI-Xplore integrates pre-recorded\nexploration videos providing contextual insights, alongside five hierarchically\nstructured downstream tasks designed to comprehensively evaluate GUI agent\ncapabilities. To fully exploit GUI-Xplore's unique features, we propose\nXplore-Agent, a GUI agent framework that combines Action-aware GUI Modeling\nwith Graph-Guided Environment Reasoning. Further experiments indicate that\nXplore-Agent achieves a 10% improvement over existing methods in unfamiliar\nenvironments, yet there remains significant potential for further enhancement\ntowards truly generalizable GUI agents."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17264"
    ],
    "c_title":[
      "Constructing Simultaneous Confidence Bands for Errors-in-variables\n  Curves with Application to the Lorenz Curve"
    ],
    "c_abstract":[
      "Errors-in-variables curves are curves where errors exist not only in the\nindependent variable but also in the dependent variable. We address the\nchallenge of constructing simultaneous confidence bands (SCBs) for such curves.\nOur method finds application in the Lorenz curve, which represents the\nconcentration of income or wealth. Unlike ordinary regression curves, the\nLorenz curve incorporates errors in its explanatory variable and requires a\nfundamentally different treatment. To the best of our knowledge, the\ndevelopment of SCBs for such curves has not been explored in previous research.\nUsing the Lorenz curve as a case study, this paper proposes a novel approach to\naddress this challenge."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-285",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13435"
    ],
    "b_title":[
      "WideRange4D: Enabling High-Quality 4D Reconstruction with Wide-Range\n  Movements and Scenes"
    ],
    "b_abstract":[
      "With the rapid development of 3D reconstruction technology, research in 4D\nreconstruction is also advancing, existing 4D reconstruction methods can\ngenerate high-quality 4D scenes. However, due to the challenges in acquiring\nmulti-view video data, the current 4D reconstruction benchmarks mainly display\nactions performed in place, such as dancing, within limited scenarios. In\npractical scenarios, many scenes involve wide-range spatial movements,\nhighlighting the limitations of existing 4D reconstruction datasets.\nAdditionally, existing 4D reconstruction methods rely on deformation fields to\nestimate the dynamics of 3D objects, but deformation fields struggle with\nwide-range spatial movements, which limits the ability to achieve high-quality\n4D scene reconstruction with wide-range spatial movements. In this paper, we\nfocus on 4D scene reconstruction with significant object spatial movements and\npropose a novel 4D reconstruction benchmark, WideRange4D. This benchmark\nincludes rich 4D scene data with large spatial variations, allowing for a more\ncomprehensive evaluation of the generation capabilities of 4D generation\nmethods. Furthermore, we introduce a new 4D reconstruction method, Progress4D,\nwhich generates stable and high-quality 4D results across various complex 4D\nscene reconstruction tasks. We conduct both quantitative and qualitative\ncomparison experiments on WideRange4D, showing that our Progress4D outperforms\nexisting state-of-the-art 4D reconstruction methods. Project:\nhttps:\/\/github.com\/Gen-Verse\/WideRange4D"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09193"
    ],
    "c_title":[
      "Transparent Correlated Metallic Perovskites with Conducive Chemical\n  Disorder"
    ],
    "c_abstract":[
      "This manuscript presents a working model linking chemical disorder and\ntransport properties in correlated-electron perovskites with high-entropy\nformulations and a framework to actively design them. We demonstrate this new\nlearning in epitaxial Sr$x$(Ti,Cr,Nb,Mo,W)O$3$ thin films that exhibit\nexceptional crystalline fidelity despite a diverse chemical formulation where\nmost B-site species are highly misfit with respect to valence and radius. X-ray\ndiffraction, X-ray photoelectron spectroscopy, and transmission electron\nmicroscopy confirm a unique combination of chemical disorder and structural\nperfection in thick epitaxial layers. This combination produces significant\nelectron correlation, low electrical resistivity, and an optical transparency\nwindow that surpasses that of constituent end-members, with a flattened\nfrequency- and temperature-dependent response. We address the computational\nchallenges of modeling such systems and investigate short-range ordering using\ncluster expansion. These results showcase that unusual d-metal combinations\naccess an expanded property design space that is predictable using end-member\ncharacteristics -- though unavailable to them -- thus offering performance\nadvances in optical, spintronic, and quantum devices."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-286",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02432"
    ],
    "b_title":[
      "Analysis of the $ q\\bar q\\to Z^* \\to hA \\to4\\tau$ process within the\n  lepton-specific 2HDM at the LHC"
    ],
    "b_abstract":[
      "We analyse light Higgs scalar and pseudoscalar associated hadro-production in\nthe 2-Higgs Doublet Model (2HDM) Type-X (or lepton-specific) within the\nparameter space allowed by theoretical self-consistency requirements as well as\nthe latest experimental constraints from the Large Hadron Collider (LHC),\nprecision data and $B$ physics. Over the viable regions of such a scenario, the\nStandard Model-like Higgs boson discovered at the LHC in 2012 is the heavier\nCP-even state $H$. Furthermore, in the Type-X scenario, due to large\n$\\tan\\beta$, the lighter Higgs scalar $h$ and the pseudoscalar $A$ mainly decay\ninto two $\\tau$ leptons. Therefore, we concentrate on analysing the signal\nprocess $pp\\to Z^{*} \\to hA\\to \\tau^{+}\\tau^{-}\\tau^{+}\\tau^{-}\\to \\ell\n\\nu_\\ell \\ell \\nu_\\ell \\tau_h \\tau_h$ (where $\\ell= e, \\mu$ whereas $\\tau_h$\nrepresents the hadronic decay of the $\\tau$) and explore the feasibility of\nconducting such a search at the LHC with a centre-of-mass energy of\n$\\sqrt{s}~=$ 14 TeV and a luminosity of $L~=~300~fb^{-1}$. To suppress the huge\nSM background, we confine ourselves to consider the fraction of signal events\nwith two same-sign $\\tau$ leptons further decaying into same-sign leptons while\nthe other two $\\tau$ leptons decay hadronically. We find that a combination of\nkinematical selection and machine learning (ML) analysis will yields\nsignificant sensitivity to this process at the end of the LHC Run 3."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.18500"
    ],
    "c_title":[
      "HSRMamba: Contextual Spatial-Spectral State Space Model for Single\n  Hyperspectral Super-Resolution"
    ],
    "c_abstract":[
      "Mamba has demonstrated exceptional performance in visual tasks due to its\npowerful global modeling capabilities and linear computational complexity,\noffering considerable potential in hyperspectral image super-resolution\n(HSISR). However, in HSISR, Mamba faces challenges as transforming images into\n1D sequences neglects the spatial-spectral structural relationships between\nlocally adjacent pixels, and its performance is highly sensitive to input\norder, which affects the restoration of both spatial and spectral details. In\nthis paper, we propose HSRMamba, a contextual spatial-spectral modeling state\nspace model for HSISR, to address these issues both locally and globally.\nSpecifically, a local spatial-spectral partitioning mechanism is designed to\nestablish patch-wise causal relationships among adjacent pixels in 3D features,\nmitigating the local forgetting issue. Furthermore, a global spectral\nreordering strategy based on spectral similarity is employed to enhance the\ncausal representation of similar pixels across both spatial and spectral\ndimensions. Finally, experimental results demonstrate our HSRMamba outperforms\nthe state-of-the-art methods in quantitative quality and visual results. Code\nwill be available soon."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-287",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10589"
    ],
    "b_title":[
      "Long Context Tuning for Video Generation"
    ],
    "b_abstract":[
      "Recent advances in video generation can produce realistic, minute-long\nsingle-shot videos with scalable diffusion transformers. However, real-world\nnarrative videos require multi-shot scenes with visual and dynamic consistency\nacross shots. In this work, we introduce Long Context Tuning (LCT), a training\nparadigm that expands the context window of pre-trained single-shot video\ndiffusion models to learn scene-level consistency directly from data. Our\nmethod expands full attention mechanisms from individual shots to encompass all\nshots within a scene, incorporating interleaved 3D position embedding and an\nasynchronous noise strategy, enabling both joint and auto-regressive shot\ngeneration without additional parameters. Models with bidirectional attention\nafter LCT can further be fine-tuned with context-causal attention, facilitating\nauto-regressive generation with efficient KV-cache. Experiments demonstrate\nsingle-shot models after LCT can produce coherent multi-shot scenes and exhibit\nemerging capabilities, including compositional generation and interactive shot\nextension, paving the way for more practical visual content creation. See\nhttps:\/\/guoyww.github.io\/projects\/long-context-video\/ for more details."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14049"
    ],
    "c_title":[
      "Rectifiability of the singular strata for harmonic maps to Euclidean\n  buildings"
    ],
    "c_abstract":[
      "We define a natural notion of the singular strata for harmonic maps into\n$F$-connected complexes (which include locally finite Euclidean buildings), and\nprove the rectifiability of these strata. We additionally establish bounds on\nthe Minkowski content for certain quantitative strata, following the\nrectifiable Reifenberg program of [NV17]. This builds on a result of the second\nauthor [D], which showed that the full singular set is $(n-2)$-rectifiable."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-288",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12915"
    ],
    "b_title":[
      "Minimal unit vector fields on oscillator groups"
    ],
    "b_abstract":[
      "In this paper, we treat minimal left-invariant unit vector fields on\noscillator group and their relations with the ones that define a harmonic map.\nParticularly, if all structure constants of the oscillator group are equal to\neach other, then all unit left invariant vector fields that define a harmonic\nmap into the unit tangent bundle with Sasaki metric are minimal."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.05309"
    ],
    "c_title":[
      "Private Selection with Heterogeneous Sensitivities"
    ],
    "c_abstract":[
      "Differentially private (DP) selection involves choosing a high-scoring\ncandidate from a finite candidate pool, where each score depends on a sensitive\ndataset. This problem arises naturally in a variety of contexts including model\nselection, hypothesis testing, and within many DP algorithms. Classical\nmethods, such as Report Noisy Max (RNM), assume all candidates' scores are\nequally sensitive to changes in a single individual's data, but this often\nisn't the case. To address this, algorithms like the Generalised Exponential\nMechanism (GEM) leverage variability in candidate sensitivities. However, we\nobserve that while these algorithms can outperform RNM in some situations, they\nmay underperform in others - they can even perform worse than random selection.\nIn this work, we explore how the distribution of scores and sensitivities\nimpacts DP selection mechanisms. In all settings we study, we find that there\nexists a mechanism that utilises heterogeneity in the candidate sensitivities\nthat outperforms standard mechanisms like RNM. However, no single mechanism\nuniformly outperforms RNM. We propose using the correlation between the scores\nand sensitivities as the basis for deciding which DP selection mechanism to\nuse. Further, we design a slight variant of GEM, modified GEM that generally\nperforms well whenever GEM performs poorly. Relying on the correlation\nheuristic we propose combined GEM, which adaptively chooses between GEM and\nmodified GEM and outperforms both in polarised settings."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.DS",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-289",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17776"
    ],
    "b_title":[
      "Tip of the Tongue Query Elicitation for Simulated Evaluation"
    ],
    "b_abstract":[
      "Tip-of-the-tongue (TOT) search occurs when a user struggles to recall a\nspecific identifier, such as a document title. While common, existing search\nsystems often fail to effectively support TOT scenarios. Research on TOT\nretrieval is further constrained by the challenge of collecting queries, as\ncurrent approaches rely heavily on community question-answering (CQA) websites,\nleading to labor-intensive evaluation and domain bias. To overcome these\nlimitations, we introduce two methods for eliciting TOT queries - leveraging\nlarge language models (LLMs) and human participants - to facilitate simulated\nevaluations of TOT retrieval systems. Our LLM-based TOT user simulator\ngenerates synthetic TOT queries at scale, achieving high correlations with how\nCQA-based TOT queries rank TOT retrieval systems when tested in the Movie\ndomain. Additionally, these synthetic queries exhibit high linguistic\nsimilarity to CQA-derived queries. For human-elicited queries, we developed an\ninterface that uses visual stimuli to place participants in a TOT state,\nenabling the collection of natural queries. In the Movie domain, system rank\ncorrelation and linguistic similarity analyses confirm that human-elicited\nqueries are both effective and closely resemble CQA-based queries. These\napproaches reduce reliance on CQA-based data collection while expanding\ncoverage to underrepresented domains, such as Landmark and Person. LLM-elicited\nqueries for the Movie, Landmark, and Person domains have been released as test\nqueries in the TREC 2024 TOT track, with human-elicited queries scheduled for\ninclusion in the TREC 2025 TOT track. Additionally, we provide source code for\nsynthetic query generation and the human query collection interface, along with\ncurated visual stimuli used for eliciting TOT queries."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.HC",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11340"
    ],
    "c_title":[
      "Toughness of double network hydrogels: the role of reduced stress\n  propagation"
    ],
    "c_abstract":[
      "Double network hydrogels show remarkable mechanical performance, combining\nhigh strength and fracture toughness with sufficient stiffness to bear load,\ndespite containing only a low density of cross-linked polymer molecules in\nwater. We introduce a simple mesoscale model of a double network material,\ndetailed enough to resolve the salient microphysics of local plastic bond\nbreakage, yet simple enough to address macroscopic cracking. Load sharing\nbetween the networks results in a delocalisation of stress such that the double\nnetwork inherits both the stiffness of its stiff-and-brittle sacrificial\nnetwork and the ductility of its soft-and-ductile matrix network. The\nunderlying mechanism is a reduction in the Eshelby stress propagator between\nsacrificial bonds, inhibiting the tendency for the plastic failure of one\nsacrificial bond to propagate stress to neighbouring sacrificial bonds and\ncause a follow-on cascade of breakages. The mechanism of brittle macroscopic\ncracking is thereby suppressed, giving instead ductile deformation via\ndiffusely distributed microcracking."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-290",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18100"
    ],
    "b_title":[
      "Realizing degree sequences with $\\mathcal S_3$-connected graphs"
    ],
    "b_abstract":[
      "A graph $G$ is $\\mathcal S_3$-connected if, for any mapping $\\beta : V (G)\n\\mapsto {\\mathbb Z}_3$ with $\\sum_{v\\in V(G)} \\beta(v)\\equiv 0\\pmod3$, there\nexists a strongly connected orientation $D$ satisfying\n$d^{+}_D(v)-d^{-}_D(v)\\equiv \\beta(v)\\pmod{3}$ for any $v \\in V(G)$. It is\nknown that $\\mathcal S_3$-connected graphs are contractible configurations for\nthe property of flow index strictly less than three. In this paper, we provide\na complete characterization of graphic sequences that have an\n$\\mathcal{S}_{3}$-connected realization: A graphic sequence $\\pi=(d_1,\\,\n\\ldots,\\, d_n )$ has an $\\mathcal S_3$-connected realization if and only if\n$\\min \\{d_1,\\, \\ldots,\\, d_n\\} \\ge 4$ and $\\sum^n_{i=1}d_i \\ge 6n - 4$.\nConsequently, every graphic sequence $\\pi=(d_1,\\, \\ldots,\\, d_n )$ with $\\min\n\\{d_1,\\, \\ldots,\\, d_n\\} \\ge 6$ has a realization $G$ with flow index strictly\nless than three. This supports a conjecture of Li, Thomassen, Wu and Zhang\n[European J. Combin., 70 (2018) 164-177] that every $6$-edge-connected graph\nhas flow index strictly less than three."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.08186"
    ],
    "c_title":[
      "Measuring the redshift-space distortions by cross-correlating the\n  density fields before and after reconstruction"
    ],
    "c_abstract":[
      "In this work, we develop a theoretical model for the cross-power spectrum of\nthe galaxy density field before and after standard baryonic acoustic\noscillation (BAO) reconstruction. Using this model, we extract the\nredshift-space distortion (RSD) parameter from the cross-power spectrum. The\nmodel is validated against a suite of high-resolution $N$-body simulations,\ndemonstrating its accuracy and robustness for cosmological analyses."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-291",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09748"
    ],
    "b_title":[
      "PyPLUTO: a data analysis Python package for the PLUTO code"
    ],
    "b_abstract":[
      "In recent years, numerical simulations have become indispensable for\naddressing complex astrophysical problems. The MagnetoHydroDynamics (MHD)\nframework represents a key tool for investigating the dynamical evolution of\nastrophysical plasmas, which are described as a set of partial differential\nequations that enforce the conservation of mass, momentum, and energy, along\nwith Maxwell's equation for the evolution of the electromagnetic fields. Due to\nthe high nonlinearity of the MHD equations (regardless of their specifications,\ne.g., classical\/relativistic or ideal\/resistive), a general analytical solution\nis precluded, making the numerical approach crucial. Numerical simulations\nusually end up producing large sets of data files and their scientific analysis\nleans on dedicated software designed for data visualization. However, in order\nto encompass all of the code output features, specialized tools focusing on the\nnumerical code may represent a more versatile and built-in tool. Here, we\npresent PyPLUTO, a Python package tailored for efficient loading, manipulation,\nand visualization of outputs produced with the PLUTO code (Mignone et al.,\n2007; Mignone et al., 2012). PyPLUTO uses memory mapping to optimize data\nloading and provides general routines for data manipulation and visualization.\nPyPLUTO also supports the particle modules of the PLUTO code, enabling users to\nload and visualize particles, such as cosmic rays (Mignone et al., 2018),\nLagrangian (Vaidya et al., 2018), or dust (Mignone et al., 2019) particles,\nfrom hybrid simulations. A dedicated Graphical User Interface (GUI) simplifies\nthe generation of single-subplot figures, making PyPLUTO a powerful yet\nuser-friendly toolkit for astrophysical data analysis."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03770"
    ],
    "c_title":[
      "The smoothness of the real projective deformation spaces of orderable\n  Coxeter 3-polytopes"
    ],
    "c_abstract":[
      "A Coxeter polytope is a convex polytope in a real projective space equipped\nwith linear reflections in its facets, such that the orbits of the polytope\nunder the action of the group generated by the linear reflections tessellate a\nconvex domain in the real projective space. Vinberg proved that the group\ngenerated by these reflections acts properly discontinuously on the interior of\nthe convex domain, thus inducing a natural orbifold structure on the polytope.\n  In this paper, we consider labeled combinatorial polytopes $\\mathcal{G}$\nassociated to such orbifolds, and study the deformation space $\\mathcal{C}\n(\\mathcal{G})$ of Coxeter polytopes realizing $\\mathcal{G}$. We prove that if\n$\\mathcal{G}$ is orderable and of normal type then the deformation space\n$\\mathcal{C}(\\mathcal{G})$ of real projective Coxeter 3-polytopes realizing\n$\\mathcal{G}$ is a smooth manifold. This result is achieved by analyzing a\nnatural map of $\\mathcal{C} (\\mathcal{G})$ into a smooth manifold called the\nrealization space."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-292",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03925"
    ],
    "b_title":[
      "The Small-Gain Condition for Infinite Networks"
    ],
    "b_abstract":[
      "In recent years, attempts have been made to extend ISS small-gain theorems\nfrom finite networks to countably infinite, locally finite networks. Under\nspecific assumptions about the interconnection gains and the ISS formulation,\ncorresponding infinite-dimensional small-gain results have been proven.\nHowever, concerning these assumptions, the results are still too narrow to be\nconsidered a full extension of the state-of-the-art for finite networks. We\ntake a step to closing this gap by a thorough investigation of various monotone\noperators associated with an infinite network and a specific ISS formulation.\nOur results shed more light on the theory of finite networks, yield complete\ncharacterizations of the small-gain condition for specific ISS formulations,\nand show which obstacles still have to be overcome to obtain a complete theory\nfor the most general case."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.11992"
    ],
    "c_title":[
      "Survey on Hand Gesture Recognition from Visual Input"
    ],
    "c_abstract":[
      "Hand gesture recognition has become an important research area, driven by the\ngrowing demand for human-computer interaction in fields such as sign language\nrecognition, virtual and augmented reality, and robotics. Despite the rapid\ngrowth of the field, there are few surveys that comprehensively cover recent\nresearch developments, available solutions, and benchmark datasets. This survey\naddresses this gap by examining the latest advancements in hand gesture and 3D\nhand pose recognition from various types of camera input data including RGB\nimages, depth images, and videos from monocular or multiview cameras, examining\nthe differing methodological requirements of each approach. Furthermore, an\noverview of widely used datasets is provided, detailing their main\ncharacteristics and application domains. Finally, open challenges such as\nachieving robust recognition in real-world environments, handling occlusions,\nensuring generalization across diverse users, and addressing computational\nefficiency for real-time applications are highlighted to guide future research\ndirections. By synthesizing the objectives, methodologies, and applications of\nrecent studies, this survey offers valuable insights into current trends,\nchallenges, and opportunities for future research in human hand gesture\nrecognition."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-293",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12982"
    ],
    "b_title":[
      "SparseAlign: A Fully Sparse Framework for Cooperative Object Detection"
    ],
    "b_abstract":[
      "Cooperative perception can increase the view field and decrease the occlusion\nof an ego vehicle, hence improving the perception performance and safety of\nautonomous driving. Despite the success of previous works on cooperative object\ndetection, they mostly operate on dense Bird's Eye View (BEV) feature maps,\nwhich are computationally demanding and can hardly be extended to long-range\ndetection problems. More efficient fully sparse frameworks are rarely explored.\nIn this work, we design a fully sparse framework, SparseAlign, with three key\nfeatures: an enhanced sparse 3D backbone, a query-based temporal context\nlearning module, and a robust detection head specially tailored for sparse\nfeatures. Extensive experimental results on both OPV2V and DairV2X datasets\nshow that our framework, despite its sparsity, outperforms the state of the art\nwith less communication bandwidth requirements. In addition, experiments on the\nOPV2Vt and DairV2Xt datasets for time-aligned cooperative object detection also\nshow a significant performance gain compared to the baseline works."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17079"
    ],
    "c_title":[
      "A Variational Principle for Extended Irreversible Thermodynamics: Heat\n  Conducting Viscous Fluids"
    ],
    "c_abstract":[
      "Extended irreversible thermodynamics is a theory that extends the classical\nframework of nonequilibrium thermodynamics by going beyond the\nlocal-equilibrium assumption. A notable example of this is the Maxwell-Cattaneo\nheat flux model, which introduces a time lag in the heat flux response to\ntemperature gradients. In this paper, we develop a variational formulation of\nthe equations of extended irreversible thermodynamics by introducing an action\nprinciple for a nonequilibrium Lagrangian that treats thermodynamic fluxes as\nindependent variables. A key feature of this approach is that it naturally\nextends both Hamilton's principle of reversible continuum mechanics and the\nearlier variational formulation of classical irreversible thermodynamics. The\nvariational principle is initially formulated in the material (Lagrangian)\ndescription, from which the Eulerian form is derived using material covariance\n(or relabeling symmetries). The tensorial structure of the thermodynamic fluxes\ndictates the choice of objective rate in the Eulerian description, leading to\nthe introduction of nonequilibrium stresses arising from both viscous and\nthermal effects to ensure thermodynamic consistency. This framework naturally\nresults in the Cattaneo-Christov model for heat flux. We also investigate the\nextension of the approach to accommodate higher-order fluxes and the general\nform of entropy fluxes. The variational framework presented in this paper has\npromising applications in the development of structure-preserving and\nthermodynamically consistent numerical methods. It is particularly relevant for\nmodeling systems where entropy production is a delicate issue that requires\ncareful treatment to ensure consistency with the laws of thermodynamics."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "math-ph",
        "math.MP",
        "physics.class-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-294",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12662"
    ],
    "b_title":[
      "TuneNSearch: a hybrid transfer learning and local search approach for\n  solving vehicle routing problems"
    ],
    "b_abstract":[
      "This paper introduces TuneNSearch, a hybrid transfer learning and local\nsearch approach for addressing different variants of vehicle routing problems\n(VRP). Recently, multi-task learning has gained much attention for solving VRP\nvariants. However, this adaptability often compromises the performance of the\nmodels. To address this challenge, we first pre-train a reinforcement learning\nmodel on the multi-depot VRP, followed by a short fine-tuning phase to adapt it\nto different variants. By leveraging the complexity of the multi-depot VRP, the\npre-trained model learns richer node representations and gains more\ntransferable knowledge compared to models trained on simpler routing problems,\nsuch as the traveling salesman problem. TuneNSearch employs, in the first\nstage, a Transformer-based architecture, augmented with a residual edge-graph\nattention network to capture the impact of edge distances and residual\nconnections between layers. This architecture allows for a more precise capture\nof graph-structured data, improving the encoding of VRP's features. After\ninference, our model is also coupled with a second stage composed of a local\nsearch algorithm, which yields substantial performance gains with minimal\ncomputational overhead added. Results show that TuneNSearch outperforms many\nexisting state-of-the-art models trained for each VRP variant, requiring only\none-fifth of the training epochs. Our approach demonstrates strong\ngeneralization, achieving high performance across different tasks,\ndistributions and problem sizes, thus addressing a long-standing gap in the\nliterature."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10886"
    ],
    "c_title":[
      "Linear scaling causal discovery from high-dimensional time series by\n  dynamical community detection"
    ],
    "c_abstract":[
      "Understanding which parts of a dynamical system cause each other is extremely\nrelevant in fundamental and applied sciences. However, inferring causal links\nfrom observational data, namely without direct manipulations of the system, is\nstill computationally challenging, especially if the data are high-dimensional.\nIn this study we introduce a framework for constructing causal graphs from\nhigh-dimensional time series, whose computational cost scales linearly with the\nnumber of variables. The approach is based on the automatic identification of\ndynamical communities, groups of variables which mutually influence each other\nand can therefore be described as a single node in a causal graph. These\ncommunities are efficiently identified by optimizing the Information Imbalance,\na statistical quantity that assigns a weight to each putative causal variable\nbased on its information content relative to a target variable. The communities\nare then ordered starting from the fully autonomous ones, whose evolution is\nindependent from all the others, to those that are progressively dependent on\nother communities, building in this manner a community causal graph. We\ndemonstrate the computational efficiency and the accuracy of our approach on\ntime-discrete and time-continuous dynamical systems including up to 80\nvariables."
    ],
    "c_categories":[
      [
        "physics.data-an",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-295",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04436"
    ],
    "b_title":[
      "Planet Masses, Radii, and Orbits from NASA's K2 Mission"
    ],
    "b_abstract":[
      "We report the masses, sizes, and orbital properties of 86 planets orbiting 55\nstars observed by NASA's K2 Mission with follow-up Doppler measurements by the\nHIRES spectrometer at the W. M. Keck Observatory and the Automated Planet\nFinder at Lick Observatory. Eighty-one of the planets were discovered from\ntheir transits in the K2 photometry, while five were found based on subsequent\nDoppler measurements of transiting planet host stars. The sizes of the\ntransiting planets range from Earth-size to larger than Jupiter (1-3 REarth is\ntypical), while the orbital periods range from less than a day to a few months.\nFor 32 of the planets, the Doppler signal was detected with significance\ngreater than 5-sigma (51 were detected with >3-sigma significance). An\nimportant characteristic of this catalog is the use of uniform analysis\nprocedures to determine stellar and planetary properties. This includes the\ntransit search and fitting procedures applied to the K2 photometry, the Doppler\nfitting techniques applied to the radial velocities, and the spectral modeling\nto determine bulk stellar parameters. Such a uniform treatment will make the\ncatalog useful for statistical studies of the masses, densities, and system\narchitectures of exoplanetary systems. This work also serves as a data release\nfor all previously unpublished RVs and associated stellar activity indicators\nobtained by our team for these systems, along with derived stellar and planet\nparameters."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.12378"
    ],
    "c_title":[
      "Pragmatics in the Era of Large Language Models: A Survey on Datasets,\n  Evaluation, Opportunities and Challenges"
    ],
    "c_abstract":[
      "Understanding pragmatics-the use of language in context-is crucial for\ndeveloping NLP systems capable of interpreting nuanced language use. Despite\nrecent advances in language technologies, including large language models,\nevaluating their ability to handle pragmatic phenomena such as implicatures and\nreferences remains challenging. To advance pragmatic abilities in models, it is\nessential to understand current evaluation trends and identify existing\nlimitations. In this survey, we provide a comprehensive review of resources\ndesigned for evaluating pragmatic capabilities in NLP, categorizing datasets by\nthe pragmatics phenomena they address. We analyze task designs, data collection\nmethods, evaluation approaches, and their relevance to real-world applications.\nBy examining these resources in the context of modern language models, we\nhighlight emerging trends, challenges, and gaps in existing benchmarks. Our\nsurvey aims to clarify the landscape of pragmatic evaluation and guide the\ndevelopment of more comprehensive and targeted benchmarks, ultimately\ncontributing to more nuanced and context-aware NLP models."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-296",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15879"
    ],
    "b_title":[
      "Typed-RAG: Type-aware Multi-Aspect Decomposition for Non-Factoid\n  Question Answering"
    ],
    "b_abstract":[
      "Non-factoid question-answering (NFQA) poses a significant challenge due to\nits open-ended nature, diverse intents, and the need for multi-aspect\nreasoning, which renders conventional factoid QA approaches, including\nretrieval-augmented generation (RAG), inadequate. Unlike factoid questions,\nnon-factoid questions (NFQs) lack definitive answers and require synthesizing\ninformation from multiple sources across various reasoning dimensions. To\naddress these limitations, we introduce Typed-RAG, a type-aware multi-aspect\ndecomposition framework within the RAG paradigm for NFQA. Typed-RAG classifies\nNFQs into distinct types -- such as debate, experience, and comparison -- and\napplies aspect-based decomposition to refine retrieval and generation\nstrategies. By decomposing multi-aspect NFQs into single-aspect sub-queries and\naggregating the results, Typed-RAG generates more informative and contextually\nrelevant responses. To evaluate Typed-RAG, we introduce Wiki-NFQA, a benchmark\ndataset covering diverse NFQ types. Experimental results demonstrate that\nTyped-RAG outperforms baselines, thereby highlighting the importance of\ntype-aware decomposition for effective retrieval and generation in NFQA. Our\ncode and dataset are available at https:\/\/github.com\/TeamNLP\/Typed-RAG."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08620"
    ],
    "c_title":[
      "Interplay of entanglement structures and stabilizer entropy in spin\n  models"
    ],
    "c_abstract":[
      "Understanding the interplay between nonstabilizerness and entanglement is\ncrucial for uncovering the fundamental origins of quantum complexity. Recent\nstudies have proposed entanglement spectral quantities, such as antiflatness of\nthe entanglement spectrum and entanglement capacity, as effective complexity\nmeasures, establishing direct connections to stabilizer R\\'enyi entropies. In\nthis work, we systematically investigate quantum complexity across a diverse\nrange of spin models, analyzing how entanglement structure and\nnonstabilizerness serve as distinctive signatures of quantum phases. By\nstudying entanglement spectra and stabilizer entropy measures, we demonstrate\nthat these quantities consistently differentiate between distinct phases of\nmatter. Specifically, we provide a detailed analysis of spin chains including\nthe XXZ model, the transverse-field XY model, its extension with\nDzyaloshinskii-Moriya interactions, as well as the Cluster Ising and Cluster XY\nmodels. Our findings reveal that entanglement spectral properties and\nmagic-based measures serve as intertwined, robust indicators of quantum phase\ntransitions, highlighting their significance in characterizing quantum\ncomplexity in many-body systems."
    ],
    "c_categories":[
      [
        "cond-mat.other",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-297",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06974"
    ],
    "b_title":[
      "Higher-rank GBS groups: non-positive curvature and biautomaticity"
    ],
    "b_abstract":[
      "We characterise when a rank $n$ generalised Baumslag-Solitar group is CAT(0)\nand when it is biautomatic."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.16167"
    ],
    "c_title":[
      "CodeReviewQA: The Code Review Comprehension Assessment for Large\n  Language Models"
    ],
    "c_abstract":[
      "State-of-the-art large language models (LLMs) have demonstrated impressive\ncode generation capabilities but struggle with real-world software engineering\ntasks, such as revising source code to address code reviews, hindering their\npractical use. Code review comments are often implicit, ambiguous, and\ncolloquial, requiring models to grasp both code and human intent. This\nchallenge calls for evaluating large language models' ability to bridge both\ntechnical and conversational contexts. While existing work has employed the\nautomated code refinement (ACR) task to resolve these comments, current\nevaluation methods fall short, relying on text matching metrics that provide\nlimited insight into model failures and remain susceptible to training data\ncontamination. To address these limitations, we introduce a novel evaluation\nbenchmark, $\\textbf{CodeReviewQA}$ that enables us to conduct fine-grained\nassessment of model capabilities and mitigate data contamination risks. In\nCodeReviewQA, we decompose the generation task of code refinement into\n$\\textbf{three essential reasoning steps}$: $\\textit{change type recognition}$\n(CTR), $\\textit{change localisation}$ (CL), and $\\textit{solution\nidentification}$ (SI). Each step is reformulated as multiple-choice questions\nwith varied difficulty levels, enabling precise assessment of model\ncapabilities, while mitigating data contamination risks. Our comprehensive\nevaluation spans 72 recently released large language models on $\\textbf{900\nmanually curated, high-quality examples}$ across nine programming languages.\nOur results show that CodeReviewQA is able to expose specific model weaknesses\nin code review comprehension, disentangled from their generative automated code\nrefinement results."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-298",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08533"
    ],
    "b_title":[
      "Practical parameter identifiability of respiratory mechanics in the\n  extremely preterm infant"
    ],
    "b_abstract":[
      "The complexity of mathematical models describing respiratory mechanics has\ngrown in recent years, however, parameter identifiability of such models has\nonly been studied in the last decade in the context of observable data. This\nstudy investigates parameter identifiability of a nonlinear respiratory\nmechanics model tuned to the physiology of an extremely preterm infant, using\nglobal Morris screening, local deterministic sensitivity analysis, and singular\nvalue decomposition-based subset selection. The model predicts airflow and\ndynamic pulmonary volumes and pressures under varying levels of continuous\npositive airway pressure, and a range of parameters characterizing both\nsurfactant-treated and surfactant-deficient lung. Sensitivity analyses\nindicated eleven parameters influence model outputs over the range of\ncontinuous positive airway pressure and lung health scenarios. The model was\nadapted to data from a spontaneously breathing 1 kg infant using gradient-based\noptimization to estimate the parameter subset characterizing the patient's\nstate of health."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2502.05890"
    ],
    "c_title":[
      "Uniqueness of generalized conformal restriction measures and\n  Malliavin-Kontsevich-Suhov measures for $c \\in (0,1]$"
    ],
    "c_abstract":[
      "In this paper, we present a unified approach to establish the uniqueness of\ngeneralized conformal restriction measures with central charge $c \\in (0, 1]$\nin both chordal and radial cases, by relating these measures to the Brownian\nloop soup. Our method also applies to the uniqueness of the\nMalliavin-Kontsevich-Suhov loop measures for $c \\in (0,1]$, which was recently\nobtained in [Baverez-Jego, arXiv:2407.09080] for all $c \\leq 1$ from a CFT\nframework of SLE loop measures. In contrast, though only valid for $c \\in\n(0,1]$, our approach provides additional probabilistic insights, as it directly\nlinks natural quantities of MKS measures to loop-soup observables."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-299",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12051"
    ],
    "b_title":[
      "TLUE: A Tibetan Language Understanding Evaluation Benchmark"
    ],
    "b_abstract":[
      "Large language models (LLMs) have made tremendous progress in recent years,\nbut low-resource languages, such as Tibetan, remain significantly\nunderrepresented in their evaluation. Despite Tibetan being spoken by over\nseven million people, it has largely been neglected in the development and\nassessment of LLMs. To address this gap, we present TLUE (A Tibetan Language\nUnderstanding Evaluation Benchmark), the first large-scale benchmark for\nassessing LLMs' capabilities in Tibetan. TLUE comprises two major components:\n(1) a comprehensive multi-task understanding benchmark spanning 5 domains and\n67 subdomains, and (2) a safety benchmark covering 7 subdomains. We evaluate a\ndiverse set of state-of-the-art LLMs. Experimental results demonstrate that\nmost LLMs perform below the random baseline, highlighting the considerable\nchallenges LLMs face in processing Tibetan, a low-resource language. TLUE\nprovides an essential foundation for driving future research and progress in\nTibetan language understanding and underscores the need for greater inclusivity\nin LLM development."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03000"
    ],
    "c_title":[
      "Determine the Order of Functional Data"
    ],
    "c_abstract":[
      "Dimension reduction is often necessary in functional data analysis, with\nfunctional principal component analysis being one of the most widely used\ntechniques. A key challenge in applying these methods is determining the number\nof eigen-pairs to retain, a problem known as order determination. When a\ncovariance function admits a finite representation, the challenge becomes\nestimating the rank of the associated covariance operator. While this problem\nis straightforward when the full trajectories of functional data are available,\nin practice, functional data are typically collected discretely and are subject\nto measurement error contamination. This contamination introduces a ridge to\nthe empirical covariance function, which obscures the true rank of the\ncovariance operator. We propose a novel procedure to identify the true rank of\nthe covariance operator by leveraging the information of eigenvalues and\neigenfunctions. By incorporating the nonparametric nature of functional data\nthrough smoothing techniques, the method is applicable to functional data\ncollected at random, subject-specific points. Extensive simulation studies\ndemonstrate the excellent performance of our approach across a wide range of\nsettings, outperforming commonly used information-criterion-based methods and\nmaintaining effectiveness even in high-noise scenarios. We further illustrate\nour method with two real-world data examples."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-300",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05015"
    ],
    "b_title":[
      "On Measuring Unnoticeability of Graph Adversarial Attacks: Observations,\n  New Measure, and Applications"
    ],
    "b_abstract":[
      "Adversarial attacks are allegedly unnoticeable. Prior studies have designed\nattack noticeability measures on graphs, primarily using statistical tests to\ncompare the topology of original and (possibly) attacked graphs. However, we\nobserve two critical limitations in the existing measures. First, because the\nmeasures rely on simple rules, attackers can readily enhance their attacks to\nbypass them, reducing their attack \"noticeability\" and, yet, maintaining their\nattack performance. Second, because the measures naively leverage global\nstatistics, such as degree distributions, they may entirely overlook attacks\nuntil severe perturbations occur, letting the attacks be almost \"totally\nunnoticeable.\" To address the limitations, we introduce HideNSeek, a learnable\nmeasure for graph attack noticeability. First, to mitigate the bypass problem,\nHideNSeek learns to distinguish the original and (potential) attack edges using\na learnable edge scorer (LEO), which scores each edge on its likelihood of\nbeing an attack. Second, to mitigate the overlooking problem, HideNSeek\nconducts imbalance-aware aggregation of all the edge scores to obtain the final\nnoticeability score. Using six real-world graphs, we empirically demonstrate\nthat HideNSeek effectively alleviates the observed limitations, and LEO (i.e.,\nour learnable edge scorer) outperforms eleven competitors in distinguishing\nattack edges under five different attack methods. For an additional\napplication, we show that LEO boost the performance of robust GNNs by removing\nattack-like edges."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12098"
    ],
    "c_title":[
      "Dzyaloshinskii-Moriya interaction chirality reversal with ferromagnetic\n  thickness"
    ],
    "c_abstract":[
      "In ultrathin ferromagnetic films sandwiched between two distinct heavy metal\nlayers or between a heavy metal and an oxide layer, the Dzyaloshinskii-Moriya\ninteraction (DMI) is recognized as being of interfacial origin. Its chirality\nand strength are determined by the properties of the adjacent heavy metals and\nthe degree of oxidation at the interfaces. Here, we demonstrate that the\nchirality of the DMI can change solely with variations in the thickness of the\nferromagnetic layer - an effect that has not been experimentally observed or\nexplained until now. Our experimental observation in the trilayer system\nTa\/FeCoB\/TaOx is supported by ab initio calculations: they reveal that\nvariations in orbital filling and inter-atomic distances at the interface,\ndriven by the number of ferromagnetic atomic layers, lead to an inversion of\nDMI chirality. This mechanism takes place for ferromagnetic layers with more\nthan three atomic layers, for which the two interfaces start to be decoupled.\nWe hence propose a new degree of freedom to tune DMI chirality and the\nassociated chiral spin textures by tailoring crystal structure e.g. using\nstrain or surface acoustic waves."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-301",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05881"
    ],
    "b_title":[
      "Smuggling unnoticed: Towards a 2D view of water and dust delivery to the\n  inner regions of protoplanetary discs"
    ],
    "b_abstract":[
      "Infrared spectroscopy, e.g., with JWST, provides a glimpse into the chemical\ninventory of the innermost region of protoplanetary discs, where terrestrial\nplanets eventually form. The chemical make-up of regions inside snowlines is\nconnected to the material drifting from the outer regions, which can be modeled\nwith dust evolution models. However, infrared observations are limited by the\nhigh dust extinction in the inner disc, and only probes the abundances of\ngaseous species in the disc surface layers. As a result, the bulk mass of\ndelivered volatiles is not directly relatable to what is measured through\ninfrared spectra. In this paper, we investigate how the delivery of dust and\nice after prolonged pebble drift affects the observable reservoir of water\nvapor in the inner disc. We develop a 1+1D approach based on dust evolution\nmodels to determine the delivery and distribution of vapor compared to the\nheight of the $\\tau = 1$ surface in the dust continuum. We find that the\nobservable column density of water vapor at wavelengths probed by JWST spans\nmany orders of magnitude over time, exhibiting different radial profiles\ndepending on dust properties, drift rate, and local processing. In the presence\nof a traffic-jam effect inside the snowline, the observable vapor reservoir\nappears constant in time despite the ongoing delivery by pebble drift, such\nthat water is effectively smuggled unnoticed. Differences in measured column\ndensities then originate not only from variations in bulk vapor content, but\nalso from differences in the properties and distribution of dust particles."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.16193"
    ],
    "c_title":[
      "Posting Patterns of Members of Parental Subreddits"
    ],
    "c_abstract":[
      "Online forums (e.g., Reddit) are used by many parents to discuss their\nchallenges, needs, and receive support. While studies have investigated the\ncontents of posts made to popular parental subreddits revealing the family\nhealth concerns being expressed, little is known about parents' posting\npatterns or other issues they engage in. In this study, we explore the posting\nactivity of users of 55 parental subreddits. Exploring posts made by these\nusers (667K) across Reddit (34M posts) reveals that over 85% of posters are not\none-time users of Reddit and actively engage with the community. Studying\ncross-posting patterns also reveals the use of subreddits dedicated to other\ntopics such as relationship and health advice (e.g., r\/AskDocs,\nr\/relationship_advice) by this population. As a result, for a comprehensive\nunderstanding of the type of information posters share and seek, future work\nshould investigate sub-communities outside of parental-specific ones. Finally,\nwe expand the list of parental subreddits, compiling a total of 115 subreddits\nthat could be utilized in future studies of parental concerns."
    ],
    "c_categories":[
      [
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-302",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03188"
    ],
    "b_title":[
      "Euska\\~nolDS: A Naturally Sourced Corpus for Basque-Spanish\n  Code-Switching"
    ],
    "b_abstract":[
      "Code-switching (CS) remains a significant challenge in Natural Language\nProcessing (NLP), mainly due a lack of relevant data. In the context of the\ncontact between the Basque and Spanish languages in the north of the Iberian\nPeninsula, CS frequently occurs in both formal and informal spontaneous\ninteractions. However, resources to analyse this phenomenon and support the\ndevelopment and evaluation of models capable of understanding and generating\ncode-switched language for this language pair are almost non-existent. We\nintroduce a first approach to develop a naturally sourced corpus for\nBasque-Spanish code-switching. Our methodology consists of identifying CS texts\nfrom previously available corpora using language identification models, which\nare then manually validated to obtain a reliable subset of CS instances. We\npresent the properties of our corpus and make it available under the name\nEuska\\~nolDS."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15530"
    ],
    "c_title":[
      "Constraints on fast radio burst population from the first CHIME\/FRB\n  catalog from Hierarchical Bayesian Inference"
    ],
    "c_abstract":[
      "Fast Radio Bursts (FRBs) have emerged as one of the most dynamic areas of\nresearch in astronomy and cosmology. Despite increasing number of FRBs have\nbeen reported, the exact origin of FRBs remains elusive. Investigating the\nintrinsic distributions of FRBs could provide valuable insights into their\npossible origins and enhance the power of FRBs a cosmological probe. In this\npaper, we propose a hierarchical Bayesian inference approach combining with\nseveral viable models to investigate the population information of FRBs\nreleased in the CHIME catalog 1. By utilizing this method, we aim to uncover\nthe underlying patterns and characteristics of the FRB population. Taking into\naccount the uncertainties and complex relationships within the data. We find\nthat the distribution of FRBs does not trace the history of star formation, and\nthere is evidence that the FRB population has time delay with respect to the\nhistory of star formation."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-303",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04962"
    ],
    "b_title":[
      "Intrinsic Spin Transport in a Topological Insulator Thin Film"
    ],
    "b_abstract":[
      "Topological insulators (TIs) are intriguing materials for advanced computing\napplications based on spintronics because they can host robust spin effects.\nFor instance, TIs have intrinsically large spin generation enabled by their\nlarge spin-orbit coupling. Furthermore, topological surface states (TSS) with\nspin-momentum locking and Dirac dispersion lead to long spin diffusion. Future\nspintronic device technology will require scalable film growth of high-quality\nmaterial. We grow epitaxial films of Bi$_{1-x}$Sb$_x$Te$_{3-y}$Se$_y$ (BSTS, $x\n= 0.58, y = 1$) and confirm the gapless band structure with optimal doping\nusing angle-resolved photoelectron spectra. The temperature dependence of\nlongitudinal resistivity shows bulk transport is suppressed as temperature is\ndecreased, and at low temperature surface transport dominates. We evaluate the\nspin transport properties in BSTS without using ferromagnetic tunnel contacts\nvia a non-local resistance experiment as a function of temperature and applied\ncharge current. As expected, these experiments reveal the necessity of\ndecreasing the bulk conduction to best enhance the spin transport. In the TSS,\nwe find high efficiency of charge-to-spin conversion (spin Hall angle,\n$\\theta_{SH} \\approx 1$) and spin diffusion over several microns. Further\ndevelopment of high-quality TIs will make them viable candidates for efficient\nand lossless spintronics."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.12552"
    ],
    "c_title":[
      "On the Uniqueness of Certain Types of Circle Packings on Translation\n  Surfaces"
    ],
    "c_abstract":[
      "Consider a collection of finitely many polygons in $\\mathbb C$, such that for\neach side of each polygon, there exists another side of some polygon in the\ncollection (possibly the same) that is parallel and of equal length. A\ntranslation surface is the surface formed by identifying these opposite sides\nwith one another. The $H(1, 1)$ stratum consists of genus two translation\nsurfaces with two singularities of order one. A circle packing corresponding to\na graph $G$ is a configuration of disjoint disks such that each vertex of $G$\ncorresponds to a circle, two disks are externally tangent if and only if their\nvertices are connected by an edge in $G$, and $G$ is a triangulation of the\nsurface. It is proven that for certain circle packings on $H(1, 1)$ translation\nsurfaces, there are only a finite number of ways the packing can vary without\nchanging the contacts graph, if two disks along the slit are fixed in place.\nThese variations can be explicitly characterized using a new concept known as\nsplitting bigons. Finally, the uniqueness theorem is generalized to a specific\ntype of translation surfaces with arbitrary genus $g \\geq 2$."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-304",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00647"
    ],
    "b_title":[
      "CAP: A Connectivity-Aware Hierarchical Coverage Path Planning Algorithm\n  for Unknown Environments using Coverage Guidance Graph"
    ],
    "b_abstract":[
      "Efficient coverage of unknown environments requires robots to adapt their\npaths in real time based on on-board sensor data. In this paper, we introduce\nCAP, a connectivity-aware hierarchical coverage path planning algorithm for\nefficient coverage of unknown environments. During online operation, CAP\nincrementally constructs a coverage guidance graph to capture essential\ninformation about the environment. Based on the updated graph, the hierarchical\nplanner determines an efficient path to maximize global coverage efficiency and\nminimize local coverage time. The performance of CAP is evaluated and compared\nwith five baseline algorithms through high-fidelity simulations as well as\nrobot experiments. Our results show that CAP yields significant improvements in\ncoverage time, path length, and path overlap ratio."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.06127"
    ],
    "c_title":[
      "Dynamics of contact points in 2D Boussinesq flow"
    ],
    "c_abstract":[
      "We consider the evolution of contact lines for thermal convection of viscous\nfluids in a 2D open-top vessel. The domain is bounded above by a free moving\nboundary and otherwise by the solid wall of a vessel. The dynamics of the fluid\nare governed by the incompressible Boussinesq approximation under the influence\nof gravity, and the interface between fluid and air is under the effect of\ncapillary forces. Motivated by energy-dissipation structure in [Guo-Tice, J.\nEur. Math. Soc, 2024], we develop global well posedness theory in the framework\nof nonlinear energy methods for the initial data sufficiently close to\nequilibrium. Moreover, the solutions decay to equilibrium at an exponential\nrate. Our methods are mainly based on the construction of solutions to\nconvected heat equation and a priori estimates of a geometric formulation of\nthe Boussinesq equations."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-305",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07470"
    ],
    "b_title":[
      "Sampling Theory for Function Approximation with Numerical Redundancy"
    ],
    "b_abstract":[
      "The study of numerical rounding errors is often greatly simplified in the\nanalytical treatment of mathematical problems, or even entirely separated from\nit. In sampling theory, for instance, it is standard to assume the availability\nof an orthonormal basis for computations, ensuring that numerical errors are\nnegligible. In reality, however, this assumption is often unmet. In this paper,\nwe discard it and demonstrate the advantages of integrating numerical insights\nmore deeply into sampling theory. To clearly pinpoint when the numerical\nphenomena play a significant role, we introduce the concept of numerical\nredundancy. A set of functions is numerically redundant if it spans a\nlower-dimensional space when analysed numerically rather than analytically.\nThis property makes it generally impossible to compute the best approximation\nof a function in its span using finite precision. In contrast,\n$\\ell^2$-regularized approximations are computable and, therefore, form the\nfoundation of many practical methods. Regularization generally reduces accuracy\ncompared to the best approximation, but our analysis shows that there is a\nbenefit: it also significantly reduces the amount of data needed for accurate\napproximation. Furthermore, we present a constructive method for optimally\nselecting data points for $L^2$-approximations, explicitly accounting for the\neffects of regularization. The results are illustrated for two common scenarios\nthat lead to numerical redundancy: (1) approximations on irregular domains and\n(2) approximations that incorporate specific features of the function to be\napproximated. In doing so, we obtain new results on random sampling for Fourier\nextension frames. Finally, we establish that regularization is implicit in\nnumerical orthogonalization of a numerically redundant set, indicating that its\nanalysis cannot be bypassed in a much broader range of methods."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11376"
    ],
    "c_title":[
      "Flavour Non-Universality and Higgs Compositeness"
    ],
    "c_abstract":[
      "We present a flavour non-universal extension of the Standard Model combined\nwith the idea of Higgs compositeness. At the TeV scale, the gauge groups\n$SU(2)_R$ and $U(1)_{B-L}$ are assumed to act in a non-universal manner on\nlight- and third-generation fermions, while the Higgs emerges as a pseudo\nNambu-Goldstone boson of the spontaneous global symmetry breaking $Sp(4)\\to\nSU(2)_L\\times SU(2)_R^{[3]}$, attributed to new strong dynamics. We discuss how\nthe radiatively generated Higgs potential has the ingredients to realize the\nunavoidable tuning necessary to separate electroweak and composite scales. In\nparticular, the flavoured gauge bosons resulting from the deconstruction must\nlie in the vicinity of the TeV scale, thereby providing interesting\nphenomenology that can be probed at near future colliders."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-306",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11698"
    ],
    "b_title":[
      "AstroPix: A Pixelated HVCMOS Sensor for Space-Based Gamma-Ray\n  Measurement"
    ],
    "b_abstract":[
      "A next-generation medium-energy gamma-ray telescope targeting the MeV range\nwould address open questions in astrophysics regarding how extreme conditions\naccelerate cosmic-ray particles, produce relativistic jet outflows, and more.\nOne concept, AMEGO-X, relies upon the mission-enabling CMOS Monolithic Active\nPixel Sensor silicon chip AstroPix. AstroPix is designed for space-based use,\nfeaturing low noise, low power consumption, and high scalability. Desired\nperformance of the device include an energy resolution of 5 keV (or 10% FWHM)\nat 122 keV and a dynamic range per-pixel of 25-700 keV, enabled by the addition\nof a high-voltage bias to each pixel which supports a depletion depth of 500\num. This work reports on the status of the AstroPix development process with\nemphasis on the current version under test, version three (v3), and highlights\nof version two (v2). Version 3 achieves energy resolution of 10.4 +\\- 3.2 % at\n59.5 keV and 94 +\\- 6 um depletion in a low-resistivity test silicon substrate."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16519"
    ],
    "c_title":[
      "Guarding the Privacy of Label-Only Access to Neural Network Classifiers\n  via iDP Verification"
    ],
    "c_abstract":[
      "Neural networks are susceptible to privacy attacks that can extract private\ninformation of the training set. To cope, several training algorithms guarantee\ndifferential privacy (DP) by adding noise to their computation. However, DP\nrequires to add noise considering every possible training set. This leads to a\nsignificant decrease in the network's accuracy. Individual DP (iDP) restricts\nDP to a given training set. We observe that some inputs deterministically\nsatisfy iDP without any noise. By identifying them, we can provide iDP\nlabel-only access to the network with a minor decrease to its accuracy.\nHowever, identifying the inputs that satisfy iDP without any noise is highly\nchallenging. Our key idea is to compute the iDP deterministic bound (iDP-DB),\nwhich overapproximates the set of inputs that do not satisfy iDP, and add noise\nonly to their predicted labels. To compute the tightest iDP-DB, which enables\nto guard the label-only access with minimal accuracy decrease, we propose\nLUCID, which leverages several formal verification techniques. First, it\nencodes the problem as a mixed-integer linear program, defined over a network\nand over every network trained identically but without a unique data point.\nSecond, it abstracts a set of networks using a hyper-network. Third, it\neliminates the overapproximation error via a novel branch-and-bound technique.\nFourth, it bounds the differences of matching neurons in the network and the\nhyper-network and employs linear relaxation if they are small. We show that\nLUCID can provide classifiers with a perfect individuals' privacy guarantee\n(0-iDP) -- which is infeasible for DP training algorithms -- with an accuracy\ndecrease of 1.4%. For more relaxed $\\varepsilon$-iDP guarantees, LUCID has an\naccuracy decrease of 1.2%. In contrast, existing DP training algorithms reduce\nthe accuracy by 12.7%."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.PL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-307",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14673"
    ],
    "b_title":[
      "ChunkFormer: Masked Chunking Conformer For Long-Form Speech\n  Transcription"
    ],
    "b_abstract":[
      "Deploying ASR models at an industrial scale poses significant challenges in\nhardware resource management, especially for long-form transcription tasks\nwhere audio may last for hours. Large Conformer models, despite their\ncapabilities, are limited to processing only 15 minutes of audio on an 80GB\nGPU. Furthermore, variable input lengths worsen inefficiencies, as standard\nbatching leads to excessive padding, increasing resource consumption and\nexecution time. To address this, we introduce ChunkFormer, an efficient ASR\nmodel that uses chunk-wise processing with relative right context, enabling\nlong audio transcriptions on low-memory GPUs. ChunkFormer handles up to 16\nhours of audio on an 80GB GPU, 1.5x longer than the current state-of-the-art\nFastConformer, while also boosting long-form transcription performance with up\nto 7.7% absolute reduction on word error rate and maintaining accuracy on\nshorter tasks compared to Conformer. By eliminating the need for padding in\nstandard batching, ChunkFormer's masked batching technique reduces execution\ntime and memory usage by more than 3x in batch processing, substantially\nreducing costs for a wide range of ASR systems, particularly regarding GPU\nresources for models serving in real-world applications."
    ],
    "b_categories":[
      [
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15527"
    ],
    "c_title":[
      "High-redshift quasars at $z \\geq 3$ -- III. Parsec-scale jet properties\n  from VLBI observations"
    ],
    "c_abstract":[
      "High redshift active galactic nuclei (AGN) provide key insights into early\nsupermassive black hole growth and cosmic evolution. This study investigates\nthe parsec-scale properties of 86 radio-loud quasars at z $\\geq$ 3 using very\nlong baseline interferometry (VLBI) observations. Our results show\npredominantly compact core and core-jet morphologies, with 35\\% unresolved\ncores, 59\\% core-jet structures, and only 6\\% core-double jet morphology.\nBrightness temperatures are generally lower than expected for highly radiative\nsources. The jet proper motions are surprisingly slow compared to\nlower-redshift samples. We observe a high fraction of young and\/or confined\npeak-spectrum sources, providing insights into early AGN evolution in dense\nenvironments during early cosmic epochs. The observed trends may reflect\ngenuine evolutionary changes in AGN structure over cosmic time, or selection\neffects favoring more compact sources at higher redshifts. These results stress\nthe complexity of high-redshift radio-loud AGN populations and emphasize the\nneed for multi-wavelength, high-resolution observations to fully characterize\ntheir properties and evolution through cosmic history."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-308",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00810"
    ],
    "b_title":[
      "Minimax Optimal Reinforcement Learning with Quasi-Optimism"
    ],
    "b_abstract":[
      "In our quest for a reinforcement learning (RL) algorithm that is both\npractical and provably optimal, we introduce EQO (Exploration via\nQuasi-Optimism). Unlike existing minimax optimal approaches, EQO avoids\nreliance on empirical variances and employs a simple bonus term proportional to\nthe inverse of the state-action visit count. Central to EQO is the concept of\nquasi-optimism, where estimated values need not be fully optimistic, allowing\nfor a simpler yet effective exploration strategy. The algorithm achieves the\nsharpest known regret bound for tabular RL under the mildest assumptions,\nproving that fast convergence can be attained with a practical and\ncomputationally efficient approach. Empirical evaluations demonstrate that EQO\nconsistently outperforms existing algorithms in both regret performance and\ncomputational efficiency, providing the best of both theoretical soundness and\npractical effectiveness."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18171"
    ],
    "c_title":[
      "DDO68-C: HST confirms yet another companion of the isolated dwarf galaxy\n  DDO 68"
    ],
    "c_abstract":[
      "We present the results of deep Hubble Space Telescope photometry of the dwarf\ngalaxy DDO 68-C, proposed as possibly associated with the isolated peculiar\ndwarf DDO 68. The new data resolve for the first time the stars of DDO 68-C\ndown to well below the tip of the Red Giant Branch (RGB), revealing a low mass\n(M$_{*}$ $\\sim$ 1.5 $\\times$ 10$^7$ M$_{\\odot}$) star forming galaxy with a\nbackbone of old stars. By means of a fully homogeneous analysis and using the\nRGB tip as a standard candle, we find that DDO 68 and DDO 68-C lie at the same\ndistance from us, within the uncertainties (D = 12.6 $\\pm$ 0.3 Mpc and D = 12.7\n$\\pm$ 0.4 Mpc, respectively), thus confirming that the two dwarfs are\nphysically associated. While paired dwarf galaxies with mutual projected\ndistance similar to DDO 68 and DDO 68-C are not exceptional in the Lynx-Cancer\nVoid where they live, DDO 68 remains a unicum as, in addition to the newly\nconfirmed companion, it records the evidence of at least two other satellites."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-309",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11889"
    ],
    "b_title":[
      "Towards shell model interactions with credible uncertainties"
    ],
    "b_abstract":[
      "Background: The nuclear shell model offers realistic predictions of nuclear\nstructure starting from (quasi-) proton and neutron degrees of freedom, but\nrelies on coupling constants (interaction matrix elements) that must be fit to\nexperiment. To extend the shell model's applicability across the nuclear chart,\nand specifically toward the driplines, we must first be able to efficiently\ntest new interaction matrix elements and assign credible uncertainties.\n  Purpose: We develop and test a framework to efficiently fit new shell model\ninteractions and obtain credible uncertainties. We further demonstrate its use\nby validating the uncertainty estimates of the known \\textit{sd}-shell\neffective interactions.\n  Methods: We use eigenvector continuation to emulate solutions to the exact\nshell model. First, we use the emulator to replicate earlier results using a\nwell-known linear-combination chi-squared minimization algorithm. Then, we\nemploy a modern Markov Chain Monte Carlo method to test for nonlinearities in\nthe observable posterior distributions, which previous sensitivity analyses\nprecluded.\n  Results: The emulator reproduces the USDB interaction within a small margin\nof error, allowing for the quantification of the matrix element uncertainty.\nHowever, we find that to obtain credible predictive intervals the model defect\nof the shell model itself, rather than experimental or emulator\nuncertainty\/error, must be taken into account.\n  Conclusions: Eigenvector continuation can be used to accelerate fitting shell\nmodel interactions. We confirm that the linear approximation used to develop\ninteractions in the past is indeed sufficient. However, we find that typical\nassumptions about the likelihood function must be modified in order to obtain a\ncredible uncertainty-quantified interaction."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08847"
    ],
    "c_title":[
      "Eigenvalue selectors for representations of compact connected groups"
    ],
    "c_abstract":[
      "A representation $\\rho$ of a compact group $\\mathbb{G}$ selects eigenvalues\nif there is a continuous circle-valued map on $\\mathbb{G}$ assigning an\neigenvalue of $\\rho(g)$ to every $g\\in \\mathbb{G}$. For every compact connected\n$\\mathbb{G}$, we characterize the irreducible $\\mathbb{G}$-representations\nwhich select eigenvalues as precisely those annihilating the intersection\n$Z_0(\\mathbb{G})\\cap \\mathbb{G}'$ of the connected center of $\\mathbb{G}$ with\nits derived subgroup. The result applies more generally to finite-spectrum\nrepresentations isotypic on $Z_0(\\mathbb{G})$, and recovers as applications\n(noted in prior work) the existence of a continuous eigenvalue selector for the\nnatural representation of $\\mathrm{SU}(n)$ and the non-existence of such a\nselector for $\\mathrm{U}(n)$."
    ],
    "c_categories":[
      [
        "math.AT",
        "math.GN",
        "math.GR",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-310",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12861"
    ],
    "b_title":[
      "Cubic congruences and binary quadratic forms"
    ],
    "b_abstract":[
      "Let $p>3$ be a prime, $a_1,a_2,a_3\\in\\Bbb Z$ and let\n$N_p(x^3+a_1x^2+a_2x+a_3)$ denote the number of solutions to the congruence\n$x^3+a_1x^2+a_2x+a_3\\equiv 0\\pmod p$. In this paper, we give an explicit\ncriterion for $N_p(x^3+a_1x^2+a_2x+a_3)=3$ via binary quadratic forms."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.09038"
    ],
    "c_title":[
      "Do generative video models understand physical principles?"
    ],
    "c_abstract":[
      "AI video generation is undergoing a revolution, with quality and realism\nadvancing rapidly. These advances have led to a passionate scientific debate:\nDo video models learn \"world models\" that discover laws of physics -- or,\nalternatively, are they merely sophisticated pixel predictors that achieve\nvisual realism without understanding the physical principles of reality? We\naddress this question by developing Physics-IQ, a comprehensive benchmark\ndataset that can only be solved by acquiring a deep understanding of various\nphysical principles, like fluid dynamics, optics, solid mechanics, magnetism\nand thermodynamics. We find that across a range of current models (Sora,\nRunway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical\nunderstanding is severely limited, and unrelated to visual realism. At the same\ntime, some test cases can already be successfully solved. This indicates that\nacquiring certain physical principles from observation alone may be possible,\nbut significant challenges remain. While we expect rapid advances ahead, our\nwork demonstrates that visual realism does not imply physical understanding.\nOur project page is at https:\/\/physics-iq.github.io; code at\nhttps:\/\/github.com\/google-deepmind\/physics-IQ-benchmark."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-311",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17342"
    ],
    "b_title":[
      "Comparison of dynamical dark energy with {\\Lambda}CDM in light of DESI\n  DR2"
    ],
    "b_abstract":[
      "We present an updated reconstruction of the dark energy equation of state,\n$w(a)$, using the newly released DESI DR2 Baryon Acoustic Oscillation (BAO)\ndata in combination with Pantheon+ and DES5Y Type Ia supernovae measurements,\nrespectively. Building on our previous analysis in arXiv:2503.08658, which\nemployed a nonparametric flexknot reconstruction approach, we examine whether\nthe evidence for dynamical dark energy persists with the improved precision of\nthe DESI DR2 dataset. We find that while the overall qualitative structure of\n$w(a)$ remains consistent with our earlier findings, the statistical support\nfor dynamical dark energy is reduced when considering DESI DR2 data alone,\nparticularly for more complex flexknot models with higher numbers of knots.\nHowever, the evidence for simpler dynamical models, such as $w$CDM and CPL\n(which correspond to $n=1$ and $n=2$ knots respectively), increases relative to\n$\\Lambda$CDM with DESI DR2 alone, consistent with previous DESI analyses. When\ncombined with Pantheon+ data, the conclusions remain broadly consistent with\nour earlier work, but the inclusion of DES5Y supernovae data leads to an\nincrease of preference for flexknot models with more than two knots, placing\n$w$CDM and CPL on par with $\\Lambda$CDM."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00945"
    ],
    "c_title":[
      "Predictive Information Decomposition as a Tool to Quantify Emergent\n  Dynamical Behaviors In Physiological Networks"
    ],
    "c_abstract":[
      "Objective: This work introduces a framework for multivariate time series\nanalysis aimed at detecting and quantifying collective emerging behaviors in\nthe dynamics of physiological networks. Methods: Given a network system mapped\nby a vector random process, we compute the predictive information (PI) between\nthe present and past network states and dissect it into amounts quantifying the\nunique, redundant and synergistic information shared by the present of the\nnetwork and the past of each unit. Emergence is then quantified as the\nprevalence of the synergistic over the redundant contribution. The framework is\nimplemented in practice using vector autoregressive (VAR) models. Results:\nValidation in simulated VAR processes documents that emerging behaviors arise\nin networks where multiple causal interactions coexist with internal dynamics.\nThe application to cardiovascular and respiratory networks mapping the\nbeat-to-beat variability of heart rate, arterial pressure and respiration\nmeasured at rest and during postural stress reveals the presence of\nstatistically significant net synergy, as well as its modulation with\nsympathetic nervous system activation. Conclusion: Causal emergence can be\nefficiently assessed decomposing the PI of network systems via VAR models\napplied to multivariate time series. This approach evidences the\nsynergy\/redundancy balance as a hallmark of integrated short-term autonomic\ncontrol in cardiovascular and respiratory networks. Significance: Measures of\ncausal emergence provide a practical tool to quantify the mechanisms of causal\ninfluence that determine the dynamic state of cardiovascular and neural network\nsystems across distinct physiopathological conditions."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-312",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00329"
    ],
    "b_title":[
      "ABC: Achieving Better Control of Multimodal Embeddings using VLMs"
    ],
    "b_abstract":[
      "Visual embedding models excel at zero-shot tasks like visual retrieval and\nclassification. However, these models cannot be used for tasks that contain\nambiguity or require user instruction. These tasks necessitate a multimodal\nembedding model, which outputs embeddings that combine visual and natural\nlanguage input. Existing CLIP-based approaches embed images and text\nindependently, and fuse the result. We find that this results in weak\ninteractions between modalities, and poor user control over the representation.\nWe introduce ABC, an open-source multimodal embedding model that uses a\nvision-language model backbone to deeply integrate image features with natural\nlanguage instructions. ABC achieves bestfor-size performance on MSCOCO\nimage-to-text retrieval and is the top performing model on classification and\nVQA tasks in the Massive Multimodal Embedding Benchmark. With a strongly\nunified vision-language representation, ABC can use natural language to solve\nsubtle and potentially ambiguous visual retrieval problems. To evaluate this\ncapability, we design CtrlBench, a benchmark that requires interleaving textual\ninstructions with image content for correct retrieval. ABC advances the state\nof multimodal embeddings by offering high-quality representations and flexible\nnatural language control. Our model and datasets are available at our project\npage."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11297"
    ],
    "c_title":[
      "Tri-layer SiN-on-Si 8x8 Optical Switches with Thermo-optic and\n  Electro-optic Actuators"
    ],
    "c_abstract":[
      "We present two spatial-multiplexed switch-and-select (S&S) 8x8 optical\nswitches incorporating a tri-layer SiN-on-Si platform, one equipped with\nthermo-optic (T-O) and the other electro-optic (E-O) switching elements. To the\nbest of our knowledge, the electro-optic switch fabric is the first-of-its-kind\ndevice assembled in such a multi-layer platform. The shuffle between the\nmultiplexer and demultiplexer array is established via a tri-layer Si-SiN-SiN\nstructure, creating a three-dimensional crossing-free photonic shuffle network.\nAt the same time, the implementation of the S&S topology can effectively\nsuppress the first-order crosstalk. The measured on-chip losses for the T-O\nswitch range from 2.1 to 11.5 dB, with a 5.2 dB average, while the E-O device\nexhibits losses between 8.7 to 19.6 dB, with a 15.1 dB average. Both switches\ndemonstrate ultra-low crosstalk, with measured ranges of 38.9 to 50.8 dB and\n42.8 to 51.9 dB, for the T-O and E-O devices respectively. The switching times\nare 17.6 us for the T-O switch and 5.9 ns with the E-O actuated one. These\nperformance metrics highlight the potential of these switches for\nnext-generation data center applications."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-313",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03209"
    ],
    "b_title":[
      "Percolation of Domain Walls in the Two-Higgs Doublet Model"
    ],
    "b_abstract":[
      "Domain walls formed during a phase transition in a simple field theory model\nwith $\\mathbb{Z}_2$ symmetry in a periodic box have been demonstrated to\nannihilate as fast as causality allows and their area density scales $\\propto\nt^{-1}$. We have performed numerical simulations of the dynamics of domain\nwalls in the Two-Higgs Doublet Model (2HDM) where the potential has\n$\\mathbb{Z}_2$ symmetry in two spatial dimensions. We observed significant\ndifferences with the standard case. Although the extreme long-time limit is the\nsame for the $\\approx 10^{5}$ sets of random initial configurations analysed,\nthe percolation process is much slower due to the formation of long-lived\nloops. We suggest that this is due to the build up of superconducting currents\non the walls which could lead ultimately to stationary configurations known as\nKinky Vortons. We discuss the relevance of these findings for the production of\nVortons in three spatial dimensions."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12993"
    ],
    "c_title":[
      "Robot Policy Transfer with Online Demonstrations: An Active\n  Reinforcement Learning Approach"
    ],
    "c_abstract":[
      "Transfer Learning (TL) is a powerful tool that enables robots to transfer\nlearned policies across different environments, tasks, or embodiments. To\nfurther facilitate this process, efforts have been made to combine it with\nLearning from Demonstrations (LfD) for more flexible and efficient policy\ntransfer. However, these approaches are almost exclusively limited to offline\ndemonstrations collected before policy transfer starts, which may suffer from\nthe intrinsic issue of covariance shift brought by LfD and harm the performance\nof policy transfer. Meanwhile, extensive work in the learning-from-scratch\nsetting has shown that online demonstrations can effectively alleviate\ncovariance shift and lead to better policy performance with improved sample\nefficiency. This work combines these insights to introduce online\ndemonstrations into a policy transfer setting. We present Policy Transfer with\nOnline Demonstrations, an active LfD algorithm for policy transfer that can\noptimize the timing and content of queries for online episodic expert\ndemonstrations under a limited demonstration budget. We evaluate our method in\neight robotic scenarios, involving policy transfer across diverse environment\ncharacteristics, task objectives, and robotic embodiments, with the aim to\ntransfer a trained policy from a source task to a related but different target\ntask. The results show that our method significantly outperforms all baselines\nin terms of average success rate and sample efficiency, compared to two\ncanonical LfD methods with offline demonstrations and one active LfD method\nwith online demonstrations. Additionally, we conduct preliminary sim-to-real\ntests of the transferred policy on three transfer scenarios in the real-world\nenvironment, demonstrating the policy effectiveness on a real robot\nmanipulator."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-314",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14296"
    ],
    "b_title":[
      "Fractional fast diffusion with initial data a Radon measure"
    ],
    "b_abstract":[
      "We establish a complete Widder Theory for the fractional fast diffusion\nequation. Our work focuses on nonnegative solutions satisfying a certain\nintegral size condition at infinity. We prove that these solutions possess a\nRadon measure as initial trace, and prove the existence and uniqueness of\nsolutions originating from such initial data. The uniqueness result is the main\nissue. Most of its difficulty comes from the singular character of the\nnonlinearity."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07454"
    ],
    "c_title":[
      "On the cosmological degrees of freedom of Proca field with non-minimal\n  coupling to gravity"
    ],
    "c_abstract":[
      "We study Proca theory with non-minimal coupling to gravity through the Ricci\ntensor and Ricci scalar interactions. We show that in the homogeneous and\nisotropic Universe together with cosmological constant, the temporal component\nof the vector field acquires a background value. As a result, we show that the\ntheory propagates an additional degree of freedom, with respect to the\ngeneralized Proca theories, whose kinetic term suggests the presence of several\nstrong coupling regimes that depend on the value of the background solution,\nthe combination and vanishing of coupling constants, together with a\nscale-dependent one. We show in addition, that the speed of propagation for\nthis mode vanishes, indicating the presence of another type of strong coupling.\nTo further investigate this, we extend our analysis to the Bianchi Type I\nUniverse, with the most general solution for the vector field. We show that the\nextra degree of freedom remains in the theory. Among the modes, we further show\nthat the mode with vanishing speed of propagation is still present, pointing to\nthe strong coupling. In addition, we discover a mode with scale-dependent\nstrong coupling (vanishing kinetic term), one mode that propagates only in one\nsingle direction and two unstable modes."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-315",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05805"
    ],
    "b_title":[
      "Multi-agent Auto-Bidding with Latent Graph Diffusion Models"
    ],
    "b_abstract":[
      "This paper proposes a diffusion-based auto-bidding framework that leverages\ngraph representations to model large-scale auction environments. In such\nsettings, agents must dynamically optimize bidding strategies under constraints\ndefined by key performance indicator (KPI) metrics, all while operating in\ncompetitive environments characterized by uncertain, sparse, and stochastic\nvariables. To address these challenges, we introduce a novel approach combining\nlearnable graph-based embeddings with a planning-based latent diffusion model\n(LDM). By capturing patterns and nuances underlying the interdependence of\nimpression opportunities and the multi-agent dynamics of the auction\nenvironment, the graph representation enable expressive computations regarding\nauto-bidding outcomes. With reward alignment techniques, the LDM's posterior is\nfine-tuned to generate auto-bidding trajectories that maximize KPI metrics\nwhile satisfying constraint thresholds. Empirical evaluations on both\nreal-world and synthetic auction environments demonstrate significant\nimprovements in auto-bidding performance across multiple common KPI metrics, as\nwell as accuracy in forecasting auction outcomes."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.16854"
    ],
    "c_title":[
      "A nonnegativity-preserving finite element method for a class of\n  parabolic SPDEs with multiplicative noise"
    ],
    "c_abstract":[
      "We consider a prototypical parabolic SPDE with finite-dimensional\nmultiplicative noise, which, subject to a nonnegative initial datum, has a\nunique nonnegative solution. Inspired by well-established techniques in the\ndeterministic case, we introduce a finite element discretization of this SPDE\nthat is convergent and which, subject to a nonnegative initial datum and\nunconditionally with respect to the spatial discretization parameter, preserves\nnonnegativity of the numerical solution throughout the course of evolution. We\nperform a mathematical analysis of this method. In addition, in the associated\nlinear setting, we develop a fully discrete scheme that also preserves\nnonnegativity, and we present numerical experiments that illustrate the\nadvantages of the proposed method over alternative finite element and finite\ndifference methods that were previously considered in the literature, which do\nnot necessarily guarantee nonnegativity of the numerical solution."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-316",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17673"
    ],
    "b_title":[
      "Mie-resonant silicon waveguide for efficient coupling with excitonic\n  emitters in InSe"
    ],
    "b_abstract":[
      "Enhancement of radiative coupling efficiency between out-of-plane excitonic\nemitters in an indium selenide (InSe) film and an integrated waveguide formed\nby silicon (Si) Mie-resonant nanodisks is experimentally studied.\nPhotoluminescence power at the resonant waveguide output is increased by~2.5\ntimes at 950~nm in comparison with the case of a conventional rib waveguide of\nthe same geometrical parameters due to the efficient excitation of Mie-type\nmagnetic dipole resonances in individual nanoparticles. These results show\ninspiring possibilities for creating new on-chip light emitters for various\nintegrated photonics applications."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.06111"
    ],
    "c_title":[
      "A note on the uniform ergodicity of diffusion processes"
    ],
    "c_abstract":[
      "In this note, we discuss the uniform ergodicity of a diffusion process given\nby an It\\^o stochastic differential equation. We present an integral condition\nin terms of the drift and diffusion coefficients that ensures the uniform\nergodicity of the corresponding transition kernel with respect to the total\nvariation distance. Applications of the obtained results to a class of\nsubordinate diffusion processes are also presented."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-317",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03038"
    ],
    "b_title":[
      "Piano Transcription by Hierarchical Language Modeling with Pretrained\n  Roll-based Encoders"
    ],
    "b_abstract":[
      "Automatic Music Transcription (AMT), aiming to get musical notes from raw\naudio, typically uses frame-level systems with piano-roll outputs or language\nmodel (LM)-based systems with note-level predictions. However, frame-level\nsystems require manual thresholding, while the LM-based systems struggle with\nlong sequences. In this paper, we propose a hybrid method combining pre-trained\nroll-based encoders with an LM decoder to leverage the strengths of both\nmethods. Besides, our approach employs a hierarchical prediction strategy,\nfirst predicting onset and pitch, then velocity, and finally offset. The\nhierarchical prediction strategy reduces computational costs by breaking down\nlong sequences into different hierarchies. Evaluated on two benchmark\nroll-based encoders, our method outperforms traditional piano-roll outputs 0.01\nand 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a\nperformance-enhancing plug-in for arbitrary roll-based music transcription\nencoder."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07626"
    ],
    "c_title":[
      "Foliated Plateau problems, geometric rigidity and equidistribution of\n  closed $k$-surfaces"
    ],
    "c_abstract":[
      "In this note, we survey recent advances in the study of dynamical properties\nof the space of surfaces with constant curvature in three-dimensional manifolds\nof negative sectional curvature. We interpret this space as a two-dimensional\nanalogue of the geodesic flow and explore the extent to which the thermodynamic\nproperties of the latter can be generalized to the surface setting.\nAdditionally, we apply this theory to derive geometric rigidity results,\nincluding the rigidity of the hyperbolic marked area spectrum."
    ],
    "c_categories":[
      [
        "math.DG",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-318",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02086"
    ],
    "b_title":[
      "Discovery of A Low-mass Strong-lens System in SMACS J0723.3-7327"
    ],
    "b_abstract":[
      "We report the discovery of an intriguing, low-mass galaxy-scale strong-lens\nsystem in the SMACS J0723.3-7327 galaxy cluster. By modeling James Webb Space\nTelescope imaging and Very Large Telescope Multi-Unit Spectroscopic Explorer\nspectroscopic data, we find that the lens is cluster member galaxy at $z=0.397$\nwith an Einstein radius of $0^{\\prime \\prime}.424$ $\\pm$ $0^{\\prime\n\\prime}.012$, stellar mass of $M_* = (3.3 \\pm 0.8) \\times 10^{10} M_\\odot$,\nhalf-light radius of $\\sim 1$ kpc, and central stellar velocity dispersion of\n$140 \\pm 6$ km s$^{-1}$. This lens galaxy is one of the few strong lens\ngalaxies known to date that have stellar mass as low as $M_* \\sim 10^{10.5}\nM_\\odot$, offering an exceptional opportunity to peek into the population of\nlow-mass galaxies that has largely remained unexplored in the context of\nstrong-lensing studies. This strong lens system can also assist in assessing\nthe systematic uncertainty in the lens modeling of cluster member galaxies."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.18139"
    ],
    "c_title":[
      "LevelRAG: Enhancing Retrieval-Augmented Generation with Multi-hop Logic\n  Planning over Rewriting Augmented Searchers"
    ],
    "c_abstract":[
      "Retrieval-Augmented Generation (RAG) is a crucial method for mitigating\nhallucinations in Large Language Models (LLMs) and integrating external\nknowledge into their responses. Existing RAG methods typically employ query\nrewriting to clarify the user intent and manage multi-hop logic, while using\nhybrid retrieval to expand search scope. However, the tight coupling of query\nrewriting to the dense retriever limits its compatibility with hybrid\nretrieval, impeding further RAG performance improvements. To address this\nchallenge, we introduce a high-level searcher that decomposes complex queries\ninto atomic queries, independent of any retriever-specific optimizations.\nAdditionally, to harness the strengths of sparse retrievers for precise keyword\nretrieval, we have developed a new sparse searcher that employs Lucene syntax\nto enhance retrieval accuracy.Alongside web and dense searchers, these\ncomponents seamlessly collaborate within our proposed method,\n\\textbf{LevelRAG}. In LevelRAG, the high-level searcher orchestrates the\nretrieval logic, while the low-level searchers (sparse, web, and dense) refine\nthe queries for optimal retrieval. This approach enhances both the completeness\nand accuracy of the retrieval process, overcoming challenges associated with\ncurrent query rewriting techniques in hybrid retrieval scenarios. Empirical\nexperiments conducted on five datasets, encompassing both single-hop and\nmulti-hop question answering tasks, demonstrate the superior performance of\nLevelRAG compared to existing RAG methods. Notably, LevelRAG outperforms the\nstate-of-the-art proprietary model, GPT4o, underscoring its effectiveness and\npotential impact on the RAG field."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-319",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17516"
    ],
    "b_title":[
      "Spectrum of weighted composition operators. Part XI. The essential\n  spectra of some weighted composition operators on the disc algebra"
    ],
    "b_abstract":[
      "We obtain a complete description of semi-Fredholm spectra of operators of the\nform $(Tf)(z) = w(z)f(B(z)$ acting on the disc algebra in the case when $B$ is\neither elliptic or double parabolic finite Blaschke product of degree $d \\geq\n2$ and $w$ has no zeros on the unit circle. In the case when $B$ has zeros on\nthe unit circle we provide only some partial results. Our results hint on the\npossibility of interesting connections between the spectral properties of\nweighted composition operators and complex dynamics."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.07805"
    ],
    "c_title":[
      "How Far are App Secrets from Being Stolen? A Case Study on Android"
    ],
    "c_abstract":[
      "Android apps can hold secret strings of themselves such as cloud service\ncredentials or encryption keys. Leakage of such secret strings can induce\nunprecedented consequences like monetary losses or leakage of user private\ninformation. In practice, various security issues were reported because many\napps failed to protect their secrets. However, little is known about the types,\nusages, exploitability, and consequences of app secret leakage issues. While a\nlarge body of literature has been devoted to studying user private information\nleakage, there is no systematic study characterizing app secret leakage issues.\nHow far are Android app secrets from being stolen?\n  To bridge this gap, we conducted the first systematic study to characterize\napp secret leakage issues in Android apps based on 575 potential app secrets\nsampled from 14,665 popular Android apps on Google Play. We summarized the\ncommon categories of leaked app secrets, assessed their security impacts and\ndisclosed app bad practices in storing app secrets. We devised a text mining\nstrategy using regular expressions and demonstrated that numerous app secrets\ncan be easily stolen, even from the highly popular Android apps on Google. In a\nfollow-up study, we harvested 3,711 distinct exploitable app secrets through\nautomatic analysis. Our findings highlight the prevalence of this problem and\ncall for greater attention to app secret protection."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-320",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03761"
    ],
    "b_title":[
      "UAV Cognitive Semantic Communications Enabled by Knowledge Graph for\n  Robust Object Detection"
    ],
    "b_abstract":[
      "Unmanned aerial vehicles (UAVs) are widely used for object detection.\nHowever, the existing UAV-based object detection systems are subject to severe\nchallenges, namely, their limited computation, energy and communication\nresources, which limits the achievable detection performance. To overcome these\nchallenges, a UAV cognitive semantic communication system is proposed by\nexploiting a knowledge graph. Moreover, we design a multi-scale codec for\nsemantic compression to reduce data transmission volume while guaranteeing\ndetection performance. Considering the complexity and dynamicity of UAV\ncommunication scenarios, a signal-to-noise ratio (SNR) adaptive module with\nrobust channel adaptation capability is introduced. Furthermore, an object\ndetection scheme is proposed by exploiting the knowledge graph to overcome\nchannel noise interference and compression distortion. Simulation results\nconducted on the practical aerial image dataset demonstrate that our proposed\nsemantic communication system outperforms benchmark systems in terms of\ndetection accuracy, communication robustness, and computation efficiency,\nespecially in dealing with low bandwidth compression ratios and low SNR\nregimes."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.16810"
    ],
    "c_title":[
      "Grounded Persuasive Language Generation for Automated Marketing"
    ],
    "c_abstract":[
      "This paper develops an agentic framework that employs large language models\n(LLMs) to automate the generation of persuasive and grounded marketing content,\nusing real estate listing descriptions as our focal application domain. Our\nmethod is designed to align the generated content with user preferences while\nhighlighting useful factual attributes. This agent consists of three key\nmodules: (1) Grounding Module, mimicking expert human behavior to predict\nmarketable features; (2) Personalization Module, aligning content with user\npreferences; (3) Marketing Module, ensuring factual accuracy and the inclusion\nof localized features. We conduct systematic human-subject experiments in the\ndomain of real estate marketing, with a focus group of potential house buyers.\nThe results demonstrate that marketing descriptions generated by our approach\nare preferred over those written by human experts by a clear margin. Our\nfindings suggest a promising LLM-based agentic framework to automate\nlarge-scale targeted marketing while ensuring responsible generation using only\nfacts."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-321",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17746"
    ],
    "b_title":[
      "Predictive Beamforming with Distributed MIMO"
    ],
    "b_abstract":[
      "In vehicle-to-everything (V2X) applications, roadside units (RSUs) can be\ntasked with both sensing and communication functions to enable sensing-assisted\ncommunications. Recent studies have demonstrated that distance, angle, and\nvelocity information obtained through sensing can be leveraged to reduce the\noverhead associated with communication beam tracking. In this work, we extend\nthis concept to scenarios involving multiple distributed RSUs and distributed\nMIMO (multiple-input multiple-output) systems. We derive the state evolution\nmodel, formulate the extended Kalman-filter equations, and implement predictive\nbeamforming for distributed MIMO. Simulation results indicate that, when\ncompared with a co-located massive MIMO antenna array, distributed antennas\nlead to more uniform and robust sensing performance, coverage, and data rates,\nwhile the vehicular user is in motion."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05054"
    ],
    "c_title":[
      "Charge transport limited by nonlocal electron-phonon interaction. I.\n  Hierarchical equations of motion approach"
    ],
    "c_abstract":[
      "Studying charge transport in models with nonlocal carrier-phonon interaction\nis difficult because it requires finite-temperature real-time correlation\nfunctions of mixed carrier-phonon operators. Focusing on models with discrete\nundamped phonon modes, we show that such correlation functions can be retrieved\nfrom the hierarchical equations of motion (HEOM), although phonons have been\nintegrated out. Our procedure relies on the explicit expression of HEOM\nauxiliaries in terms of phonon creation and annihilation operators. It reveals\nthat the auxiliaries describe multiphonon-assisted carrier transitions induced\nby genuine many-phonon correlations, from which lower-order correlations are\nsubtracted according to the finite-temperature Wick's theorem. Applying the\nprocedure to our recently developed momentum-space HEOM method featuring a\nspecific hierarchy closing, we compute the numerically exact dynamical mobility\nof a carrier within the one-dimensional Peierls model. The carrier mobility at\nmoderate temperatures decreases with increasing interaction, whereas high\ntemperatures see the opposite trend, reflecting the prevalence of the\nphonon-assisted current over the purely electronic band current. The pronounced\nfinite-size effects and HEOM instabilities delimit the range of applicability\nof our approach to moderate interactions, moderate to high temperatures, and\nnot too fast phonons. Importantly, this range comprises the values relevant for\ncharge transport in crystalline organic semiconductors, and we present and\ndiscuss the corresponding numerically exact results in a companion paper\n(arXiv:2501.05055)."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "physics.chem-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-322",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15280"
    ],
    "b_title":[
      "System of stochastic interacting wave functions that model quantum\n  measurements"
    ],
    "b_abstract":[
      "We develop a system of non-linear stochastic evolution equations that\ndescribes the continuous measurements of quantum systems with mixed initial\nstate. We address quantum systems with unbounded Hamiltonians and unbounded\ninteraction operators. Using arguments of the theory of quantum measurements we\nderive a system of stochastic interacting wave functions (SIWF for short) that\nmodels the continuous monitoring of quantum systems. We prove the existence and\nuniqueness of the solution to this system under conditions general enough for\nthe applications. We obtain that the mixed state generated by the SIWF at any\ntime does not depend on the initial state, and satisfies the diffusive\nstochastic quantum master equation, which is also known as Belavkin equation.\nWe present two physical examples. In one, the SIWF becomes a system of\nnon-linear stochastic partial differential equations. In the other, we deal\nwith a model of a circuit quantum electrodynamics."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.03507"
    ],
    "c_title":[
      "Mineral segmentation using electron microscope images and spectral\n  sampling through multimodal graph neural networks"
    ],
    "c_abstract":[
      "We propose a novel Graph Neural Network-based method for segmentation based\non data fusion of multimodal Scanning Electron Microscope (SEM) images. In most\ncases, Backscattered Electron (BSE) images obtained using SEM do not contain\nsufficient information for mineral segmentation. Therefore, imaging is often\ncomplemented with point-wise Energy-Dispersive X-ray Spectroscopy (EDS)\nspectral measurements that provide highly accurate information about the\nchemical composition but that are time-consuming to acquire. This motivates the\nuse of sparse spectral data in conjunction with BSE images for mineral\nsegmentation. The unstructured nature of the spectral data makes most\ntraditional image fusion techniques unsuitable for BSE-EDS fusion. We propose\nusing graph neural networks to fuse the two modalities and segment the mineral\nphases simultaneously. Our results demonstrate that providing EDS data for as\nfew as 1% of BSE pixels produces accurate segmentation, enabling rapid analysis\nof mineral samples. The proposed data fusion pipeline is versatile and can be\nadapted to other domains that involve image data and point-wise measurements."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-323",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.00761"
    ],
    "b_title":[
      "Giant Nonvolatile Multistate Resistance with Fully Magnetically\n  Controlled in van der Waals Multiferroic Tunnel Junctions"
    ],
    "b_abstract":[
      "Ferroelectric polarization switching in electrically controlled van der Waals\nmultiferroic tunnel junctions (vdW-MFTJs) causes atomic migration, compromising\ndevice stability and fatigue resistance. Here we propose a fully magnetically\ncontrolled vdW-MFTJ based on a \\(\\mathrm{CrBr_3\/MnPSe_3\/CrBr_3}\\) vertical\nheterostructure, which achieves ferroelectric polarization reversal without\nrelying on atomic migration driven by inversion symmetry breaking. Using\nfirst-principles calculations, we investigate the spin-polarized quantum\ntransport properties of the proposed structure. By integrating asymmetric\nPtTe$_2$\/alkali-metal (Li\/Na\/K)-doped\/intercalated CrBr$_3$ electrodes, the\ndevice demonstrates exceptional performance, with a maximum tunneling\nmagnetoresistance (TMR) exceeding $8.1\\times10^5$\\% and tunneling\nelectroresistance (TER) reaching 2499\\%, while the spin-filtering channels can\nbe flexibly controlled by the magnetization direction of the magnetic free\nlayer, achieving perfect spin-filtering over a broad bias voltage range.\nApplying an external bias voltage further enhances these metrics, increasing\nTMR to $3.6\\times 10^7$\\% and TER to 9990\\%. Notably, a pronounced negative\ndifferential resistance (NDR) effect is observed, yielding an unprecedented\npeak-to-valley ratio (PVR) of $9.55\\times10^9$\\%, representing the highest\nvalue reported for vertical tunnel junctions. These extraordinary\ncharacteristics highlight the potential of vdW-MFTJs for ultra-efficient\nelectronic switching, a key feature for next-generation spintronic devices. Our\nfindings provide a solid theoretical foundation for designing and developing\nhigh-performance magnetic storage and logic technologies."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02275"
    ],
    "c_title":[
      "ForaNav: Insect-inspired Online Target-oriented Navigation for MAVs in\n  Tree Plantations"
    ],
    "c_abstract":[
      "Autonomous Micro Air Vehicles (MAVs) are becoming essential in precision\nagriculture to enhance efficiency and reduce labor costs through targeted,\nreal-time operations. However, existing unmanned systems often rely on\nGPS-based navigation, which is prone to inaccuracies in rural areas and limits\nflight paths to predefined routes, resulting in operational inefficiencies. To\naddress these challenges, this paper presents ForaNav, an insect-inspired\nnavigation strategy for autonomous navigation in plantations. The proposed\nmethod employs an enhanced Histogram of Oriented Gradient (HOG)-based tree\ndetection approach, integrating hue-saturation histograms and global HOG\nfeature variance with hierarchical HOG extraction to distinguish oil palm trees\nfrom visually similar objects. Inspired by insect foraging behavior, the MAV\ndynamically adjusts its path based on detected trees and employs a recovery\nmechanism to stay on course if a target is temporarily lost. We demonstrate\nthat our detection method generalizes well to different tree types while\nmaintaining lower CPU usage, lower temperature, and higher FPS than lightweight\ndeep learning models, making it well-suited for real-time applications. Flight\ntest results across diverse real-world scenarios show that the MAV successfully\ndetects and approaches all trees without prior tree location, validating its\neffectiveness for agricultural automation."
    ],
    "c_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-324",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00550"
    ],
    "b_title":[
      "Validating Urban Scaling Laws through Mobile Phone Data: A\n  Continental-Scale Analysis of Brazil's Largest Cities"
    ],
    "b_abstract":[
      "\\abstract{Urban scaling theories posit that larger cities exhibit\ndisproportionately higher levels of socioeconomic activity and human\ninteractions. Yet, evidence from developing contexts (especially those marked\nby stark socioeconomic disparities) remains limited. To address this gap, we\nanalyse a month-long dataset of 3.1~billion voice-call records from Brazil's\n100 most populous cities, providing a continental-scale test of urban scaling\nlaws. We measure interactions using two complementary proxies: the number of\nphone-based contacts (voice-call degrees) and the number of trips inferred from\nconsecutive calls in distinct locations. Our findings reveal clear superlinear\nrelationships in both metrics, indicating that larger urban centres exhibit\nintensified remote communication and physical mobility. We further observe that\ngross domestic product (GDP) also scales superlinearly with population,\nconsistent with broader claims that economic output grows faster than city\nsize. Conversely, the number of antennas required per user scales sublinearly,\nsuggesting economies of scale in telecommunications infrastructure. Although\nthe dataset covers a single provider, its widespread coverage in major cities\nsupports the robustness of the results. We nonetheless discuss potential\nbiases, including city-specific marketing campaigns and predominantly prepaid\nusers, as well as the open question of whether higher interaction drives wealth\nor vice versa. Overall, this study enriches our understanding of urban scaling,\nemphasising how communication and mobility jointly shape the socioeconomic\nlandscapes of rapidly growing cities."
    ],
    "b_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.08707"
    ],
    "c_title":[
      "A Secure Blockchain-Assisted Framework for Real-Time Maritime\n  Environmental Compliance Monitoring"
    ],
    "c_abstract":[
      "The maritime industry is governed by stringent environmental regulations,\nmost notably the International Convention for the Prevention of Pollution from\nShips (MARPOL). Ensuring compliance with these regulations is difficult due to\nlow inspection rates and the risk of data fabrication. To address these issues,\nthis paper proposes a secure blockchain-assisted framework for real-time\nmaritime environmental compliance monitoring. By integrating IoT and shipboard\nsensors with blockchain technology, the framework ensures immutable and\ntransparent record-keeping of environmental data. Smart contracts automate\ncompliance verification and notify relevant authorities in case of\nnon-compliance. A proof-of-concept case study on sulfur emissions demonstrates\nthe framework's efficacy in enhancing MARPOL enforcement through real-time data\nintegrity and regulatory adherence. The proposed system leverages the Polygon\nblockchain for scalability and efficiency, providing a robust solution for\nmaritime environmental protection. The evaluation results demonstrate that the\nproposed blockchain-enhanced compliance monitoring system effectively and\nsecurely ensures real-time regulatory adherence with high scalability,\nefficiency, and cost-effectiveness, leveraging the robust capabilities of the\nPolygon blockchain."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.ET"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-325",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14717"
    ],
    "b_title":[
      "Towards Better Understanding Table Instruction Tuning: Decoupling the\n  Effects from Data versus Models"
    ],
    "b_abstract":[
      "Recent advances in natural language processing have leveraged instruction\ntuning to enhance Large Language Models (LLMs) for table-related tasks.\nHowever, previous works train different base models with different training\ndata, lacking an apples-to-apples comparison across the result table LLMs. To\naddress this, we fine-tune base models from the Mistral, OLMo, and Phi families\non existing public training datasets. Our replication achieves performance on\npar with or surpassing existing table LLMs, establishing new state-of-the-art\nperformance on Hitab, a table question-answering dataset. More importantly,\nthrough systematic out-of-domain evaluation, we decouple the contributions of\ntraining data and the base model, providing insight into their individual\nimpacts. In addition, we assess the effects of table-specific instruction\ntuning on general-purpose benchmarks, revealing trade-offs between\nspecialization and generalization."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12319"
    ],
    "c_title":[
      "Enhancing Stellarator Accessibility through Port Size Optimization"
    ],
    "c_abstract":[
      "Access to the plasma chamber in a stellarator reactor is essential for\nmaintenance and diagnostics. However, the complex geometry of stellarator\ncoils, often characterized by their strong twisting, can severely limit the\nspace available for access ports. This study introduces a novel optimization\napproach in which access ports are represented as closed curves on the plasma\nboundary. By carefully selecting a set of objectives and penalties related to\nthe access port, we demonstrate the first stellarator coil optimization\nexplicitly targeting improved access port size. The trade-off between magnetic\nfield quality and port size is analyzed through the Pareto front of their\nrespective objectives. The optimal location of a port is explained using a\ncurrent potential approach. Finally, we show that additional shaping coils,\nsuch as windowpane coils, can enable the crossing of the Pareto front to\nachieve superior configurations."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-326",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09241"
    ],
    "b_title":[
      "In-Context Defense in Computer Agents: An Empirical Study"
    ],
    "b_abstract":[
      "Computer agents powered by vision-language models (VLMs) have significantly\nadvanced human-computer interaction, enabling users to perform complex tasks\nthrough natural language instructions. However, these agents are vulnerable to\ncontext deception attacks, an emerging threat where adversaries embed\nmisleading content into the agent's operational environment, such as a pop-up\nwindow containing deceptive instructions. Existing defenses, such as\ninstructing agents to ignore deceptive elements, have proven largely\nineffective. As the first systematic study on protecting computer agents, we\nintroduce textbf{in-context defense}, leveraging in-context learning and\nchain-of-thought (CoT) reasoning to counter such attacks. Our approach involves\naugmenting the agent's context with a small set of carefully curated exemplars\ncontaining both malicious environments and corresponding defensive responses.\nThese exemplars guide the agent to first perform explicit defensive reasoning\nbefore action planning, reducing susceptibility to deceptive attacks.\nExperiments demonstrate the effectiveness of our method, reducing attack\nsuccess rates by 91.2% on pop-up window attacks, 74.6% on average on\nenvironment injection attacks, while achieving 100% successful defenses against\ndistracting advertisements. Our findings highlight that (1) defensive reasoning\nmust precede action planning for optimal performance, and (2) a minimal number\nof exemplars (fewer than three) is sufficient to induce an agent's defensive\nbehavior."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02431"
    ],
    "c_title":[
      "Solution of the Ovals problem"
    ],
    "c_abstract":[
      "In this paper, we bring a complete solution to the Ovals problem, as\nformulated in [3] and [24]."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-327",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14703"
    ],
    "b_title":[
      "Thermomechanical Processing of Pure Magnesium: Hot Extrusion, Hot\n  Rolling and Cold Drawing"
    ],
    "b_abstract":[
      "A comprehensive study on thermomechanical processing of pure Mg was conducted\nthrough sequential hot extrusion, hot rolling, and cold drawing operations.\nThree different extrusion ratios (6:1, 25:1, and 39:1) were investigated at\n350{\\deg}C, revealing that 39:1 ratio produced an optimal bimodal grain\nstructure with beneficial twin morphology. Subsequently, hot rolling\nexperiments were performed at varying linear speeds (26- and 130-mm s-1) and\ninterpass annealing times (2.5 and 10 minutes). Results demonstrated that\nhigher rolling speeds led to finer microstructure, while longer interpass\nannealing times resulted in reduced twin fraction and more inhomogeneous\nmicrostructure. The processed material was then subjected to cold drawing with\napproximately 12% true strain per pass. Different annealing conditions\n(275{\\deg}C and 375{\\deg}C for 2.5-10 minutes) between drawing passes were\nevaluated. Analysis showed that annealing at 375{\\deg}C for 2.5-5 minutes\nprovided optimal softening for subsequent deformation. Fracture analysis\nrevealed a mixed ductile-brittle behavior, with twin-matrix interfaces serving\nas preferred crack propagation paths This study establishes optimal processing\nparameters for pure Mg wire production, highlighting the critical role of twin\ncharacteristics and restoration processes in determining material formability\nduring multi-step thermomechanical processing."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.01794"
    ],
    "c_title":[
      "OFF-CLIP: Improving Normal Detection Confidence in Radiology CLIP with\n  Simple Off-Diagonal Term Auto-Adjustment"
    ],
    "c_abstract":[
      "Contrastive Language-Image Pre-Training (CLIP) has enabled zero-shot\nclassification in radiology, reducing reliance on manual annotations. However,\nconventional contrastive learning struggles with normal case detection due to\nits strict intra-sample alignment, which disrupts normal sample clustering and\nleads to high false positives (FPs) and false negatives (FNs). To address these\nissues, we propose OFF-CLIP, a contrastive learning refinement that improves\nnormal detection by introducing an off-diagonal term loss to enhance normal\nsample clustering and applying sentence-level text filtering to mitigate FNs by\nremoving misaligned normal statements from abnormal reports. OFF-CLIP can be\napplied to radiology CLIP models without requiring any architectural\nmodifications. Experimental results show that OFF-CLIP significantly improves\nnormal classification, achieving a 0.61 Area under the curve (AUC) increase on\nVinDr-CXR over CARZero, the state-of-the-art zero-shot classification baseline,\nwhile maintaining or improving abnormal classification performance.\nAdditionally, OFF-CLIP enhances zero-shot grounding by improving pointing game\naccuracy, confirming better anomaly localization. These results demonstrate\nOFF-CLIP's effectiveness as a robust and efficient enhancement for medical\nvision-language models."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-328",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14402"
    ],
    "b_title":[
      "On the Effectiveness of Microservices Tactics and Patterns to Reduce\n  Energy Consumption: An Experimental Study on Trade-Offs"
    ],
    "b_abstract":[
      "Context: Microservice-based systems have established themselves in the\nsoftware industry. However, sustainability-related legislation and the growing\ncosts of energy-hungry software increase the importance of energy efficiency\nfor these systems. While some proposals for architectural tactics and patterns\nexist, their effectiveness as well as potential trade-offs on other quality\nattributes (QAs) remain unclear.\n  Goal: We therefore aim to study the effectiveness of microservices tactics\nand patterns to reduce energy consumption, as well as potential trade-offs with\nperformance and maintainability.\n  Method: Using the open-source Online Boutique system, we conducted a\ncontrolled experiment with three tactics and three patterns, and analyzed the\nimpact of each technique compared to a baseline. We also tested with three\nlevels of simulated request loads (low, medium, high).\n  Results: Request load moderated the effectiveness of reducing energy\nconsumption. All techniques (tactics and patterns) reduced the energy\nconsumption for at least one load level, up to 5.6%. For performance, the\ntechniques could negatively impact response time by increasing it by up to\n25.9%, while some also decreased it by up to 72.5%. Two techniques increased\nthe throughput, by 1.9% and 34.0%. For maintainability, three techniques had a\nnegative, one a positive, and two no impact.\n  Conclusion: Some techniques reduced energy consumption while also improving\nperformance. However, these techniques usually involved a trade-off in\nmaintainability, e.g., via more code duplication and module coupling. Overall,\nall techniques significantly reduced energy consumption at higher loads, but\nmost of them sacrificed one of the other QAs. This highlights that the real\nchallenge is not simply reducing energy consumption of microservices, but to\nachieve energy efficiency."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16299"
    ],
    "c_title":[
      "On the finite basis of two-loop `t Hooft-Veltman Feynman integrals"
    ],
    "c_abstract":[
      "In this work, we investigate the finite basis topologies of two-loop\ndimensionally regularized Feynman integrals in the `t Hooft-Veltman scheme in\nthe Standard Model. We present a functionally distinct finite basis of Master\nIntegrals which spans the whole transcendental space of all two-loop Feynman\nintegrals with external momenta in four dimensions. We also indicate that all\nthe two-loop Master Integrals, in an appropriate basis, with more than 8\ndenominators do not contribute to the finite part of any two-loop scattering\namplitude. In addition, we elaborate on the application of the `t Hooft-Veltman\ndecomposition to improve the performance of numerical evaluation of Feynman\nintegrals using AMFlow and DCT packages. Moreover, we analyze the spectrum of\nspecial functions and the corresponding geometries appearing in any two-loop\nscattering amplitude. Our work will allow for a reduction in the computational\ncomplexity required for providing high-precision predictions for future\nhigh-multiplicity collider observables, both analytically and numerically."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-329",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18254"
    ],
    "b_title":[
      "Normalized solutions to lower critical Choquard equation in\n  mass-supercritical setting"
    ],
    "b_abstract":[
      "We study the normalized solutions to the following Choquard equation\n  \\begin{equation*}\n  \\aligned &-\\Delta u + \\lambda u =\\mu g(u) + \\gamma (I_\\alpha *\n|u|^{\\frac{N+\\alpha}{N}})|u|^{\\frac{N+\\alpha}{N}-2}u & \\text{in\\ \\ }\n\\mathbb{R}^N \\endaligned\n  \\end{equation*} under the $L^2$-norm constraint $\\|u\\|_2=c$. Here $\\gamma>0$,\n$ N\\geq 1$, $\\alpha\\in(0,N)$, $I_{\\alpha}$ is the Riesz potential, and the\nunknown $\\lambda$ appears as a Lagrange multiplier. In a mass supercritical\nsetting on $g$, we find regions in the $(c,\\mu)$--parameter space such that the\ncorresponding equation admits a positive radial ground state solution. To\novercome the lack of compactness resulting from the nonlocal term, we present a\nnovel compactness lemma and some prior energy estimate. These results are even\nnew for the power type nonlinearity $g(u)= |u|^{q-2}u$ with\n$2+\\frac{4}{N}<q<2^*$ ($2^*:=\\frac{2N}{N-2}$, if $N\\geq 3$ and $2^* = \\infty$,\nif $N=1, 2$). We also show that as $\\mu$ or $c$ tends to $0$ (resp. $\\mu$ or\n$c$ tends to $+\\infty$), after a suitable rescaling the ground state solutions\nconverge in $H^1(\\RN)$ to a particular solution of the limit equations.\nFurther, we study the non-existence and multiplicity of positive radial\nsolutions to \\begin{equation*}\n  -\\Delta u + u = \\eta |u|^{q-2}u + (I_\\alpha *\n|u|^{\\frac{N+\\alpha}{N}})|u|^{\\frac{N+\\alpha}{N}-2}u, \\quad \\text{in}\\ \\ \\RN\n\\end{equation*} where $N \\geq 1$, $ 2< q<2^*$ and $\\eta>0$. Based on some\nanalytical ideas the limit behaviors of the normalized solutions, we verify\nsome threshold regions of $\\eta$ such that the corresponding equation has no\npositive least action solution or admits multiple positive solutions. To the\nbest of our knowledge, this seems to be the first result concerning the\nnon-existence and multiplicity of positive solutions to Choquard type equations\ninvolving the lower critical exponent."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.11065"
    ],
    "c_title":[
      "Low-cost Real-world Implementation of the Swing-up Pendulum for Deep\n  Reinforcement Learning Experiments"
    ],
    "c_abstract":[
      "Deep reinforcement learning (DRL) has had success in virtual and simulated\ndomains, but due to key differences between simulated and real-world\nenvironments, DRL-trained policies have had limited success in real-world\napplications. To assist researchers to bridge the \\textit{sim-to-real gap}, in\nthis paper, we describe a low-cost physical inverted pendulum apparatus and\nsoftware environment for exploring sim-to-real DRL methods. In particular, the\ndesign of our apparatus enables detailed examination of the delays that arise\nin physical systems when sensing, communicating, learning, inferring and\nactuating. Moreover, we wish to improve access to educational systems, so our\napparatus uses readily available materials and parts to reduce cost and\nlogistical barriers. Our design shows how commercial, off-the-shelf electronics\nand electromechanical and sensor systems, combined with common metal\nextrusions, dowel and 3D printed couplings provide a pathway for affordable\nphysical DRL apparatus. The physical apparatus is complemented with a simulated\nenvironment implemented using a high-fidelity physics engine and OpenAI Gym\ninterface."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-330",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05487"
    ],
    "b_title":[
      "The Future of AI: Exploring the Potential of Large Concept Models"
    ],
    "b_abstract":[
      "The field of Artificial Intelligence (AI) continues to drive transformative\ninnovations, with significant progress in conversational interfaces, autonomous\nvehicles, and intelligent content creation. Since the launch of ChatGPT in late\n2022, the rise of Generative AI has marked a pivotal era, with the term Large\nLanguage Models (LLMs) becoming a ubiquitous part of daily life. LLMs have\ndemonstrated exceptional capabilities in tasks such as text summarization, code\ngeneration, and creative writing. However, these models are inherently limited\nby their token-level processing, which restricts their ability to perform\nabstract reasoning, conceptual understanding, and efficient generation of\nlong-form content. To address these limitations, Meta has introduced Large\nConcept Models (LCMs), representing a significant shift from traditional\ntoken-based frameworks. LCMs use concepts as foundational units of\nunderstanding, enabling more sophisticated semantic reasoning and context-aware\ndecision-making. Given the limited academic research on this emerging\ntechnology, our study aims to bridge the knowledge gap by collecting,\nanalyzing, and synthesizing existing grey literature to provide a comprehensive\nunderstanding of LCMs. Specifically, we (i) identify and describe the features\nthat distinguish LCMs from LLMs, (ii) explore potential applications of LCMs\nacross multiple domains, and (iii) propose future research directions and\npractical strategies to advance LCM development and adoption."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02889"
    ],
    "c_title":[
      "Bifurcations and stability of synchronized solutions in the Kuramoto\n  model with uniformly spaced natural frequencies"
    ],
    "c_abstract":[
      "We consider the classical Kuramoto model (KM) with natural frequencies and\nits continuum limit (CL), and discuss the existence of synchronized solutions\nand their bifurcations and stability. We specifically assume that the frequency\nfunction is symmetric and linear in the CL, so that the natural frequencies are\nevenly spaced in the KM. We show that in the KM, $O(2^n)$ one-parameter\nfamilies of synchronized solutions are born and $O(2^n)$ {saddle-node and}\npitchfork bifurcations occur at least, when the node number $n$ is odd and\ntends to infinity. Moreover, we prove that the family of synchronized solutions\nobtained in the previous work suffers a saddle-node bifurcation at which its\nstability changes from asymptotically stable to unstable and the other families\nof synchronized solutions are unstable in the KM. For the CL, we show that the\none-parameter family of synchronized solutions obtained in the previous work is\nthe only continuous one and there exist uncountably many one-parameter families\nof noncontinuous synchronized solutions and that the former is asymptotically\nstable and the latter are unstable."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-331",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19382"
    ],
    "b_title":[
      "LiDAR Loop Closure Detection using Semantic Graphs with Graph Attention\n  Networks"
    ],
    "b_abstract":[
      "In this paper, we propose a novel loop closure detection algorithm that uses\ngraph attention neural networks to encode semantic graphs to perform place\nrecognition and then use semantic registration to estimate the 6 DoF relative\npose constraint. Our place recognition algorithm has two key modules, namely, a\nsemantic graph encoder module and a graph comparison module. The semantic graph\nencoder employs graph attention networks to efficiently encode spatial,\nsemantic and geometric information from the semantic graph of the input point\ncloud. We then use self-attention mechanism in both node-embedding and\ngraph-embedding steps to create distinctive graph vectors. The graph vectors of\nthe current scan and a keyframe scan are then compared in the graph comparison\nmodule to identify a possible loop closure. Specifically, employing the\ndifference of the two graph vectors showed a significant improvement in\nperformance, as shown in ablation studies. Lastly, we implemented a semantic\nregistration algorithm that takes in loop closure candidate scans and estimates\nthe relative 6 DoF pose constraint for the LiDAR SLAM system. Extensive\nevaluation on public datasets shows that our model is more accurate and robust,\nachieving 13% improvement in maximum F1 score on the SemanticKITTI dataset,\nwhen compared to the baseline semantic graph algorithm. For the benefit of the\ncommunity, we open-source the complete implementation of our proposed algorithm\nand custom implementation of semantic registration at\nhttps:\/\/github.com\/crepuscularlight\/SemanticLoopClosure"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11357"
    ],
    "c_title":[
      "On the Dimension of Pullback Attractors in Recurrent Neural Networks"
    ],
    "c_abstract":[
      "Recurrent Neural Networks (RNNs) are high-dimensional state space models\ncapable of learning functions on sequence data. Recently, it has been\nconjectured that reservoir computers, a particular class of RNNs, trained on\nobservations of a dynamical systems can be interpreted as embeddings. This\nresult has been established for the case of linear reservoir systems. In this\nwork, we use a nonautonomous dynamical systems approach to establish an upper\nbound for the fractal dimension of the subset of reservoir state space\napproximated during training and prediction phase. We prove that when the input\nsequences comes from an Nin-dimensional invertible dynamical system, the\nfractal dimension of this set is bounded above by Nin. The result obtained here\nare useful in dimensionality reduction of computation in RNNs as well as\nestimating fractal dimensions of dynamical systems from limited observations of\ntheir time series. It is also a step towards understanding embedding properties\nof reservoir computers."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-332",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06055"
    ],
    "b_title":[
      "Dynamic Programming in Ordered Vector Space"
    ],
    "b_abstract":[
      "Recent approaches to the theory of dynamic programming view dynamic programs\nas families of policy operators acting on partially ordered sets. In this\npaper, we extend these ideas by shifting from arbitrary partially ordered sets\nto ordered vector space. The advantage of working in this setting is that\nordered vector spaces have well integrated algebric and order structure, which\nleads to sharper fixed point results. These fixed point results can then be\nexploited to obtain strong optimality properties. We illustrate our results\nthrough a range of applications, including new findings for several useful\nmodels."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.04359"
    ],
    "c_title":[
      "Exploring Spatial Language Grounding Through Referring Expressions"
    ],
    "c_abstract":[
      "Spatial Reasoning is an important component of human cognition and is an area\nin which the latest Vision-language models (VLMs) show signs of difficulty. The\ncurrent analysis works use image captioning tasks and visual question\nanswering. In this work, we propose using the Referring Expression\nComprehension task instead as a platform for the evaluation of spatial\nreasoning by VLMs. This platform provides the opportunity for a deeper analysis\nof spatial comprehension and grounding abilities when there is 1) ambiguity in\nobject detection, 2) complex spatial expressions with a longer sentence\nstructure and multiple spatial relations, and 3) expressions with negation\n('not'). In our analysis, we use task-specific architectures as well as large\nVLMs and highlight their strengths and weaknesses in dealing with these\nspecific situations. While all these models face challenges with the task at\nhand, the relative behaviors depend on the underlying models and the specific\ncategories of spatial semantics (topological, directional, proximal, etc.). Our\nresults highlight these challenges and behaviors and provide insight into\nresearch gaps and future directions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-333",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15719"
    ],
    "b_title":[
      "The Kodaira dimension of Hilbert modular threefolds"
    ],
    "b_abstract":[
      "Following a method introduced by Thomas-Vasquez and developed by Grundman, we\nprove that many Hilbert modular threefolds of arithmetic genus $0$ and $1$ are\nof general type, and that some are of nonnegative Kodaira dimension. The new\ningredient is a detailed study of the geometry and combinatorics of totally\npositive integral elements $x$ of a fractional ideal $I$ in a totally real\nnumber field $K$ with the property that $\\mathop{\\mathrm{tr}} xy <\n\\mathop{\\mathrm{min}} I \\mathop{\\mathrm{tr}} y$ for some $y \\gg 0 \\in K$."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16159"
    ],
    "c_title":[
      "ZiGong 1.0: A Large Language Model for Financial Credit"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) have demonstrated strong performance across\nvarious general Natural Language Processing (NLP) tasks. However, their\neffectiveness in financial credit assessment applications remains suboptimal,\nprimarily due to the specialized financial expertise required for these tasks.\nTo address this limitation, we propose ZiGong, a Mistral-based model enhanced\nthrough multi-task supervised fine-tuning. To specifically combat model\nhallucination in financial contexts, we introduce a novel data pruning\nmethodology. Our approach utilizes a proxy model to score training samples,\nsubsequently combining filtered data with original datasets for model training.\nThis data refinement strategy effectively reduces hallucinations in LLMs while\nmaintaining reliability in downstream financial applications. Experimental\nresults show our method significantly enhances model robustness and prediction\naccuracy in real-world financial scenarios."
    ],
    "c_categories":[
      [
        "cs.CE",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-334",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13997"
    ],
    "b_title":[
      "SigStyle: Signature Style Transfer via Personalized Text-to-Image Models"
    ],
    "b_abstract":[
      "Style transfer enables the seamless integration of artistic styles from a\nstyle image into a content image, resulting in visually striking and\naesthetically enriched outputs. Despite numerous advances in this field,\nexisting methods did not explicitly focus on the signature style, which\nrepresents the distinct and recognizable visual traits of the image such as\ngeometric and structural patterns, color palettes and brush strokes etc. In\nthis paper, we introduce SigStyle, a framework that leverages the semantic\npriors that embedded in a personalized text-to-image diffusion model to capture\nthe signature style representation. This style capture process is powered by a\nhypernetwork that efficiently fine-tunes the diffusion model for any given\nsingle style image. Style transfer then is conceptualized as the reconstruction\nprocess of content image through learned style tokens from the personalized\ndiffusion model. Additionally, to ensure the content consistency throughout the\nstyle transfer process, we introduce a time-aware attention swapping technique\nthat incorporates content information from the original image into the early\ndenoising steps of target image generation. Beyond enabling high-quality\nsignature style transfer across a wide range of styles, SigStyle supports\nmultiple interesting applications, such as local style transfer, texture\ntransfer, style fusion and style-guided text-to-image generation. Quantitative\nand qualitative evaluations demonstrate our approach outperforms existing style\ntransfer methods for recognizing and transferring the signature styles."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17281"
    ],
    "c_title":[
      "Stiff Transfer Learning for Physics-Informed Neural Networks"
    ],
    "c_abstract":[
      "Stiff differential equations are prevalent in various scientific domains,\nposing significant challenges due to the disparate time scales of their\ncomponents. As computational power grows, physics-informed neural networks\n(PINNs) have led to significant improvements in modeling physical processes\ndescribed by differential equations. Despite their promising outcomes, vanilla\nPINNs face limitations when dealing with stiff systems, known as failure modes.\nIn response, we propose a novel approach, stiff transfer learning for\nphysics-informed neural networks (STL-PINNs), to effectively tackle stiff\nordinary differential equations (ODEs) and partial differential equations\n(PDEs). Our methodology involves training a Multi-Head-PINN in a low-stiff\nregime, and obtaining the final solution in a high stiff regime by transfer\nlearning. This addresses the failure modes related to stiffness in PINNs while\nmaintaining computational efficiency by computing \"one-shot\" solutions. The\nproposed approach demonstrates superior accuracy and speed compared to\nPINNs-based methods, as well as comparable computational efficiency with\nimplicit numerical methods in solving stiff-parameterized linear and polynomial\nnonlinear ODEs and PDEs under stiff conditions. Furthermore, we demonstrate the\nscalability of such an approach and the superior speed it offers for\nsimulations involving initial conditions and forcing function\nreparametrization."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-335",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17715"
    ],
    "b_title":[
      "Bridging Information Gaps with Comprehensive Answers: Improving the\n  Diversity and Informativeness of Follow-Up Questions"
    ],
    "b_abstract":[
      "Effective conversational systems are expected to dynamically generate\ncontextual follow-up questions to elicit new information while maintaining the\nconversation flow. While humans excel at asking diverse and informative\nquestions by intuitively assessing both obtained and missing information,\nexisting models often fall short of human performance on this task. To mitigate\nthis, we propose a method that generates diverse and informative questions\nbased on targeting unanswered information using a hypothetical LLM-generated\n\"comprehensive answer\". Our method is applied to augment an existing follow-up\nquestions dataset. The experimental results demonstrate that language models\nfine-tuned on the augmented datasets produce follow-up questions of\nsignificantly higher quality and diversity. This promising approach could be\neffectively adopted to future work to augment information-seeking dialogues for\nreducing ambiguities and improving the accuracy of LLM answers."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17783"
    ],
    "c_title":[
      "Connection formulae for the radial Toda equations II"
    ],
    "c_abstract":[
      "This is a continuation of [arXiv:2309.16550] in which we computed the\nasymptotics near $x = \\infty$ of all solutions of the radial Toda equation. In\nthis article, we compute the asymptotics near $x = \\infty$ of all solutions of\na \"partner\" equation. The equations are related in the sense that their\nrespective monodromy data constitute connected components of the same\n\"monodromy manifold\". While all solutions of the radial Toda equation are\nsmooth, those of the partner equation have infinitely many singularities, and\nthis makes the Riemann-Hilbert nonlinear steepest descent method (and the\nasymptotics of solutions) more involved."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.CA",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-336",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09485"
    ],
    "b_title":[
      "Flow approach on the monotonicity of shape functionals"
    ],
    "b_abstract":[
      "We develop a geometric flow framework to investigate the following two\nclassical shape functionals: the torsional rigidity and the first Dirichlet\neigenvalue of the Laplacian. First, by constructing novel deformation paths\ngoverned by stretching flows, we prove several new monotonicity properties of\nthe torsional rigidity and the first eigenvalue along the evolutions restricted\nto triangles and rhombuses. These results also lead to new and simpler proofs\nof some known results, unifying and extending prior symmetrization-based\nproofs. Second, utilizing the mean curvature flow, we give a new proof of the\nSaint-Venant inequality for smooth convex bodies. This might represent the\nfirst flow-based proof to establish geometric functional inequalities that\ncouple both the domain and the state function associated with it. Third, by\ndiscovering a gradient norm inequality for the sides of rectangles, we prove\nmonotonicity and stronger rigidity results of the torsional rigidity on\nrectangles."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.07505"
    ],
    "c_title":[
      "An Error Analysis of Second Order Elliptic Optimal Control Problem via\n  Hybrid Higher Order Methods"
    ],
    "c_abstract":[
      "This paper presents the design and analysis of a Hybrid High-Order (HHO)\napproximation for a distributed optimal control problem governed by the Poisson\nequation. We propose three distinct schemes to address unconstrained control\nproblems and two schemes for constrained control problems. For the\nunconstrained control problem, while standard finite elements achieve a\nconvergence rate of \\( k+1 \\) (with \\( k \\) representing the polynomial\ndegree), our approach enhances this rate to \\( k+2 \\) by selecting the control\nfrom a carefully constructed reconstruction space. For the box-constrained\nproblem, we demonstrate that using lowest-order elements (\\( \\mathbb{P}_0 \\))\nyields linear convergence, in contrast to finite element methods (FEM) that\nrequire linear elements to achieve comparable results. Furthermore, we derive a\ncubic convergence rate for control in the variational discretization scheme.\nNumerical experiments are provided to validate the theoretical findings."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-337",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18261"
    ],
    "b_title":[
      "The effect of minimum wages on employment in the presence of\n  productivity fluctuations"
    ],
    "b_abstract":[
      "Traditionally, the impact of minimum wages on employment has been studied,\nand it is generally believed to have a negative effect. Yet, some recent\nstudies have shown that the impact of minimum wages on employment can sometimes\nbe positive. In addition, certain recent proposals set a higher minimum wage\nthan the wage earned by some high-productivity workers. However, the impact of\nminimum wages on employment has been primarily studied on low-skilled workers,\nwhereas there is limited research on high-skilled workers. To address this gap\nand examine the effects of minimum wages on high-productivity workers'\nemployment, I construct a macroeconomic model incorporating productivity\nfluctuations, incomplete markets, directed search, and on-the-job search and\ncompare the steady-state distributions between the baseline model and the model\nwith a minimum wage. As a result, binding minimum wages increase the\nunemployment rate of both low and high-productivity workers."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.10561"
    ],
    "c_title":[
      "VisiMark: Characterizing and Augmenting Landmarks for People with Low\n  Vision in Augmented Reality to Support Indoor Navigation"
    ],
    "c_abstract":[
      "Landmarks are critical in navigation, supporting self-orientation and mental\nmodel development. Similar to sighted people, people with low vision (PLV)\nfrequently look for landmarks via visual cues but face difficulties identifying\nsome important landmarks due to vision loss. We first conducted a formative\nstudy with six PLV to characterize their challenges and strategies in landmark\nselection, identifying their unique landmark categories (e.g., area\nsilhouettes, accessibility-related objects) and preferred landmark\naugmentations. We then designed VisiMark, an AR interface that supports\nlandmark perception for PLV by providing both overviews of space structures and\nin-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found\nthat VisiMark enabled PLV to perceive landmarks they preferred but could not\neasily perceive before, and changed PLV's landmark selection from only\nvisually-salient objects to cognitive landmarks that are more important and\nmeaningful. We further derive design considerations for AR-based landmark\naugmentation systems for PLV."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-338",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18043"
    ],
    "b_title":[
      "Microscopic study of halo nuclei through (p,t) reactions"
    ],
    "b_abstract":[
      "We analyze (p,t) two-neutron transfer reactions in a semi-microscopic model.\nThe overlap integrals of the target nucleus are calculated in a microscopic\ncluster model. The Resonating Group Method (RGM) assumes a cluster structure of\nthe nucleus, and is well adapted to halo nuclei since the long-range part of\nthe wave function is accurately described. We focus on (p,t) reactions\ninvolving 6He and 11Li, which are well known core+n+n halo nuclei. The RGM is\nbased on a nucleon-nucleon interaction, and therefore does not involve any\nfitting procedure. It also provides overlap integrals of excited states of the\ncore nucleus. We present overlap integrals and spectroscopic factors of 6He and\n11Li. We compute the 6He(p,t)alpha and 11Li(p,t)9Li cross sections at the DWBA,\nand compare them with experiments. For 11Li we also determine the 11Li(p,t)9Li*\ncross section which involves the first excited states of 9Li. A fair agreement\nwith experiment is obtained, considering that no parameter is adjusted."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05124"
    ],
    "c_title":[
      "Fixed-Throughput GRAND with FIFO Scheduling"
    ],
    "c_abstract":[
      "Guessing random additive noise decoding (GRAND) is a code-agnostic decoding\nmethod that iteratively guesses the noise pattern affecting the received\ncodeword. The number of noise sequences to test depends on the noise\nrealization. Thus, GRAND exhibits random runtime which results in\nnondeterministic throughput. However, real-time systems must process the\nincoming data at a fixed rate, necessitating a fixed-throughput decoder in\norder to avoid losing data. We propose a first-in first-out (FIFO) scheduling\narchitecture that enables a fixed throughput while improving the block error\nrate (BLER) compared to the common approach of imposing a maximum runtime\nconstraint per received codeword. Moreover, we demonstrate that the average\nthroughput metric of GRAND-based hardware implementations typically provided in\nthe literature can be misleading as one needs to operate at approximately one\norder of magnitude lower throughput to achieve the BLER of an unconstrained\ndecoder."
    ],
    "c_categories":[
      [
        "cs.AR",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-339",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04199"
    ],
    "b_title":[
      "MASTER: Multimodal Segmentation with Text Prompts"
    ],
    "b_abstract":[
      "RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20810"
    ],
    "c_title":[
      "Parabolic presentations of the modular Super Yangian Y(M|N)"
    ],
    "c_abstract":[
      "The present paper is devoted to extend parabolic presentations, depending on\nan arbitrary composition of M+N and an arbitrary 01-sequence, of the super\nYangian Y(M|N) to a field of positive characteristic."
    ],
    "c_categories":[
      [
        "math.QA",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-340",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05505"
    ],
    "b_title":[
      "Towards a Non-singular Paradigm of Black Hole Physics"
    ],
    "b_abstract":[
      "The study of regular black holes and black hole mimickers as alternatives to\nstandard black holes has recently gained significant attention, driven both by\nthe need to extend general relativity to describe black hole interiors, and by\nrecent advances in observational technologies. Despite considerable progress in\nthis field, significant challenges remain in identifying and characterizing\nphysically well-motivated classes of regular black holes and black hole\nmimickers. This report provides an overview of these challenges, and outlines\nsome of the promising research directions -- as discussed during a week-long\nfocus programme held at the Institute for Fundamental Physics of the Universe\n(IFPU) in Trieste from November 11th to 15th, 2024."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02332"
    ],
    "c_title":[
      "COMMA: Coordinate-aware Modulated Mamba Network for 3D Dispersed Vessel\n  Segmentation"
    ],
    "c_abstract":[
      "Accurate segmentation of 3D vascular structures is essential for various\nmedical imaging applications. The dispersed nature of vascular structures leads\nto inherent spatial uncertainty and necessitates location awareness, yet most\ncurrent 3D medical segmentation models rely on the patch-wise training strategy\nthat usually loses this spatial context. In this study, we introduce the\nCoordinate-aware Modulated Mamba Network (COMMA) and contribute a manually\nlabeled dataset of 570 cases, the largest publicly available 3D vessel dataset\nto date. COMMA leverages both entire and cropped patch data through global and\nlocal branches, ensuring robust and efficient spatial location awareness.\nSpecifically, COMMA employs a channel-compressed Mamba (ccMamba) block to\nencode entire image data, capturing long-range dependencies while optimizing\ncomputational costs. Additionally, we propose a coordinate-aware modulated\n(CaM) block to enhance interactions between the global and local branches,\nallowing the local branch to better perceive spatial information. We evaluate\nCOMMA on six datasets, covering two imaging modalities and five types of\nvascular tissues. The results demonstrate COMMA's superior performance compared\nto state-of-the-art methods with computational efficiency, especially in\nsegmenting small vessels. Ablation studies further highlight the importance of\nour proposed modules and spatial information. The code and data will be open\nsource at https:\/\/github.com\/shigen-StoneRoot\/COMMA."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-341",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05392"
    ],
    "b_title":[
      "Equilibrium and nonequilibrium steady states with the repeated\n  interaction protocol: Relaxation dynamics and energetic cost"
    ],
    "b_abstract":[
      "We study the dynamics of a qubit system interacting with thermalized\nbath-ancilla spins via a repeated interaction scheme. Considering generic\ninitial conditions for the system and employing a Heisenberg-type interaction\nbetween the system and the ancillas, we analytically prove the following: (i)\nThe population and coherences of the system qubit evolve independently toward a\nnonequilibrium steady-state solution, which is diagonal in the qubit's energy\neigenbasis. The population relaxes to this state geometrically, whereas the\ncoherences decay through a more compound behavior. (ii) In the long time limit,\nthe system approaches a steady state that generally differs from the thermal\nstate of the ancilla. We derive this steady-state solution and show its\ndependence on the interaction parameters and collision frequency. (iii) We\nbound the number of interaction steps required to achieve the steady state\nwithin a specified error tolerance, and we evaluate the energetic cost\nassociated with the process. Our key finding is that deterministic\nsystem-ancilla interactions do not typically result in the system thermalizing\nto the thermal state of the ancilla. Instead, they generate a distinct\nnonequilibrium steady state, which we explicitly derive. However, we also\nidentify an operational regime that leads to thermalization with a few long and\npossibly randomized collisions."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.14222"
    ],
    "c_title":[
      "Mirror symmetric Gamma conjecture for toric GIT quotients via Fourier\n  transform"
    ],
    "c_abstract":[
      "Let $\\mathcal X=[(\\mathbb C^r\\setminus Z)\/G]$ be a toric Fano orbifold. We\ncompute the Fourier transform of the $G$-equivariant quantum cohomology central\ncharge of any $G$-equivariant line bundle on $\\mathbb C^r$ with respect to\ncertain choice of parameters. This gives the quantum cohomology central charge\nof the corresponding line bundle on $\\mathcal X$, while in the oscillatory\nintegral expression it becomes the oscillatory integral in the mirror\nLandau-Ginzburg mirror of $\\mathcal X$. Moving these parameters to real numbers\nsimultaneously deforms the integration cycle to the mirror Lagrangian cycle of\nthat line bundle. This computation produces a new proof the mirror symmetric\nGamma conjecture for $\\mathcal X$."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.AG",
        "math.MP",
        "math.SG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-342",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03348"
    ],
    "b_title":[
      "Composite Nonlinear Trajectory Tracking Control of Co-Driving Vehicles\n  Using Self-Triggered Adaptive Dynamic Programming"
    ],
    "b_abstract":[
      "This article presents a composite nonlinear feedback (CNF) control method\nusing self-triggered (ST) adaptive dynamic programming (ADP) algorithm in a\nhuman-machine shared steering framework. For the overall system dynamics, a\ntwo-degrees-of-freedom (2-DOF) vehicle model is established and a two-point\npreview driver model is adopted. A dynamic authority allocation strategy based\non cooperation level is proposed to combine the steering input of the human\ndriver and the automatic controller. To make further improvements in the\ncontroller design, three main contributions are put forward. Firstly, the CNF\ncontroller is designed for trajectory tracking control with refined transient\nperformance. Besides, the self-triggered rule is applied such that the system\nwill update in discrete times to save computing resources and increase\nefficiency. Moreover, by introducing the data-based ADP algorithm, the optimal\ncontrol problem can be solved through iteration using system input and output\ninformation, reducing the need for accurate knowledge of system dynamics. The\neffectiveness of the proposed control method is validated through\nCarsim-Simulink co-simulations in diverse driving scenarios."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06451"
    ],
    "c_title":[
      "On Legacy of Starobinsky Inflation"
    ],
    "c_abstract":[
      "Alexei Alexandrovich Starobinsky was one of the greatest cosmologists of all\ntimes, who made fundamental contributions to gravitational theory and cosmology\nbased on geometrical ideas in physics, in the spirit of Einstein. One of his\nbig achievements is the famous Starobinsky model of cosmological inflation in\nthe early universe, proposed in 1979-1980. In this memorial paper, the\nStarobinsky inflation model is systematically reviewed from the modern\nperspective. Its deformation to include production of primordial black holes is\nproposed, and possible quantum corrections in the context of superstring theory\nand the Swampland Program are discussed. Starobinsky inflation also leads to\nthe universal reheating mechanism for particle production after inflation."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-343",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19226"
    ],
    "b_title":[
      "What is Connectivity?"
    ],
    "b_abstract":[
      "In this paper, we explore a taxonomy of connectivity for space-like\nstructures. It is inspired by isolating posets of connected pieces of a space\nand examining its embedding in the ambient space. The taxonomy includes in its\nscope all standard notions of connectivity in point-set and point-free\ncontexts, such as connectivity in graphs and hypergraphs (as well as\nk-connectivity in graphs), connectivity and path-connectivity in topology, and\nconnectivity of elements in a frame."
    ],
    "b_categories":[
      [
        "math.CT",
        "math.GN",
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.07225"
    ],
    "c_title":[
      "CAT: Contrastive Adversarial Training for Evaluating the Robustness of\n  Protective Perturbations in Latent Diffusion Models"
    ],
    "c_abstract":[
      "Latent diffusion models have recently demonstrated superior capabilities in\nmany downstream image synthesis tasks. However, customization of latent\ndiffusion models using unauthorized data can severely compromise the privacy\nand intellectual property rights of data owners. Adversarial examples as\nprotective perturbations have been developed to defend against unauthorized\ndata usage by introducing imperceptible noise to customization samples,\npreventing diffusion models from effectively learning them. In this paper, we\nfirst reveal that the primary reason adversarial examples are effective as\nprotective perturbations in latent diffusion models is the distortion of their\nlatent representations, as demonstrated through qualitative and quantitative\nexperiments. We then propose the Contrastive Adversarial Training (CAT)\nutilizing adapters as an adaptive attack against these protection methods,\nhighlighting their lack of robustness. Extensive experiments demonstrate that\nour CAT method significantly reduces the effectiveness of protective\nperturbations in customization configurations, urging the community to\nreconsider and enhance the robustness of existing protective perturbation\nmethods. Code is available at \\hyperlink{here}{https:\/\/github.com\/senp98\/CAT}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-344",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02204"
    ],
    "b_title":[
      "Backcasting Policies in Transport Systems as an Optimal Control Problem\n  : An Example with Electric Vehicle Purchase Incentives"
    ],
    "b_abstract":[
      "This study represents a first attempt to build a backcasting methodology to\nidentify the optimal policy roadmaps in transport systems. Specifically, it\nconsiders a passenger car fleet subsystem, modelling its evolution and\ngreenhouse gas emissions. The policy decision under consideration is the\nmonetary incentive to the purchase of electric vehicles. This process is cast\nas an optimal control problem with the objective to minimize the total budget\nof the state and reach a desired CO$_2$ target. A case study applied to\nMetropolitan France is presented to illustrate the approach. Additionally,\nalternative policy scenarios are also analyzed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.09764"
    ],
    "c_title":[
      "Localised frames for tensor product spaces"
    ],
    "c_abstract":[
      "In this paper, we investigate whether the tensor product of two frames, each\nindividually localised with respect to a spectral matrix algebra, is also\nlocalised with respect to a suitably chosen tensor product algebra. We provide\na partial answer by constructing an involutive Banach algebra of rank-four\ntensors that is built from two solid spectral matrix algebras. We show that\nthis algebra is inverse-closed, given that the original algebras satisfy a\nspecific property related to operator-valued versions of these algebras. This\ncondition is satisfied by all commonly used solid spectral matrix algebras. We\nthen prove that the tensor product of two self-localised frames remains\nself-localised with respect to our newly constructed tensor algebra.\nAdditionally, we discuss generalisations to localised frames of Hilbert-Schmidt\noperators, which may not necessarily consist of rank-one operators."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-345",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01312"
    ],
    "b_title":[
      "CleanPose: Category-Level Object Pose Estimation via Causal Learning and\n  Knowledge Distillation"
    ],
    "b_abstract":[
      "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be released."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13867"
    ],
    "c_title":[
      "Ribbon blocks for centraliser algebras of symmetric groups"
    ],
    "c_abstract":[
      "Suppose $l,m$ are natural numbers with $l\\le m$, and $\\mathbb{F}$ a field of\ncharacteristic $p$, and let $\\mathcal{C}_{l,m}^{\\mathbb{F}}$ denote the\ncentraliser of the group algebra $\\mathbb{F}S_l$ inside $\\mathbb{F}S_m$. Ellers\nand Murray give a conjectured classification of the blocks of\n$\\mathcal{C}_{l,m}^{\\mathbb{F}}$, in terms of the $p$-blocks of $S_l$ and\n$S_m$. We prove this conjecture for a family of blocks that we call ribbon\nblocks and belt blocks. These are the blocks containing Specht modules labelled\nby skew partitions having no repeated entries in their $p$-content."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-346",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02768"
    ],
    "b_title":[
      "Denotational Semantics for Probabilistic and Concurrent Programs"
    ],
    "b_abstract":[
      "We develop a denotational model for programs that have standard programming\nconstructs such as conditionals and while-loops, as well as probabilistic and\nconcurrent commands. Whereas semantic models for languages with either\nconcurrency or randomization are well studied, their combination is limited to\nlanguages with bounded loops. Our work is the first to consider both\nrandomization and concurrency for a language with unbounded looping constructs.\nThe interaction between Boolean tests (arising from the control flow\nstructures), probabilistic actions, and concurrent execution creates challenges\nin generalizing previous work on pomsets and convex languages, prominent models\nfor those effects, individually. To illustrate the generality of our model, we\nshow that it recovers a typical powerdomain semantics for concurrency, as well\nas the convex powerset semantics for probabilistic nondeterminism."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13343"
    ],
    "c_title":[
      "Fluctuation-driven topological Hall effect in room-temperature itinerant\n  helimagnet Fe3Ga4"
    ],
    "c_abstract":[
      "The topological Hall effect (THE) is a hallmark of a non-trivial geometric\nspin arrangement in a magnetic metal, originating from a finite scalar spin\nchirality (SSC). The associated Berry phase is often a consequence of\nnon-coplanar magnetic structures identified by multiple k-vectors. For single-k\nmagnetic structures however with zero SSC, the emergence of a finite\ntopological Hall signal presents a conceptual challenge. Here, we report that a\nfluctuation-driven mechanism involving chiral magnons is responsible for the\nobserved THE in a low-symmetry compound, monoclinic Fe3Ga4. Through neutron\nscattering experiments, we discovered several nontrivial magnetic phases in\nthis system. In our focus is the helical spiral phase at room temperature,\nwhich transforms into a transverse conical state in applied magnetic field,\nsupporting a significant THE signal up to and above room temperature. Our work\noffers a fresh perspective in the search for novel materials with intertwined\ntopological magnetic and transport properties."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-347",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12885"
    ],
    "b_title":[
      "DreamRenderer: Taming Multi-Instance Attribute Control in Large-Scale\n  Text-to-Image Models"
    ],
    "b_abstract":[
      "Image-conditioned generation methods, such as depth- and canny-conditioned\napproaches, have demonstrated remarkable abilities for precise image synthesis.\nHowever, existing models still struggle to accurately control the content of\nmultiple instances (or regions). Even state-of-the-art models like FLUX and\n3DIS face challenges, such as attribute leakage between instances, which limits\nuser control. To address these issues, we introduce DreamRenderer, a\ntraining-free approach built upon the FLUX model. DreamRenderer enables users\nto control the content of each instance via bounding boxes or masks, while\nensuring overall visual harmony. We propose two key innovations: 1) Bridge\nImage Tokens for Hard Text Attribute Binding, which uses replicated image\ntokens as bridge tokens to ensure that T5 text embeddings, pre-trained solely\non text data, bind the correct visual attributes for each instance during Joint\nAttention; 2) Hard Image Attribute Binding applied only to vital layers.\nThrough our analysis of FLUX, we identify the critical layers responsible for\ninstance attribute rendering and apply Hard Image Attribute Binding only in\nthese layers, using soft binding in the others. This approach ensures precise\ncontrol while preserving image quality. Evaluations on the COCO-POS and\nCOCO-MIG benchmarks demonstrate that DreamRenderer improves the Image Success\nRatio by 17.7% over FLUX and enhances the performance of layout-to-image models\nlike GLIGEN and 3DIS by up to 26.8%. Project Page:\nhttps:\/\/limuloo.github.io\/DreamRenderer\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05507"
    ],
    "c_title":[
      "On the Atomki nuclear anomaly after the MEG-II result"
    ],
    "c_abstract":[
      "Recent experimental results from the Atomki collaboration have reported the\nobservation of anomalous effects in Beryllium, Helium and Carbon nuclear\ntransitions that could hint at physics beyond the Standard Model. However, the\nMEG-II experiment has recently found no significant anomalous signal in the\nBeryllium transition ${^8}\\text{Be}^\\star\\to{^8}\\text{Be}+e^+e^-$. In view of\nthis result, we critically re-examine the possible theoretical interpretations\nof the anomalies observed by the Atomki experiment in terms of a new boson $X$\nwith mass around $17\\;$MeV. The present work aims to study the phenomenology of\na spin-2 state and revisit the possibility of a pure CP-even scalar, which was\ninitially dismissed due to its inability to explain the Beryllium anomalous\nsignal. Our analysis shows that a spin-2 state is highly disfavoured by the\nSINDRUM constraint while a scalar boson could explain the Helium and Carbon\nanomalies while being compatible with other experimental constraints."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-348",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15239"
    ],
    "b_title":[
      "RFSoC-based radio-frequency reflectometry in gate-defined bilayer\n  graphene quantum devices"
    ],
    "b_abstract":[
      "Quantum computers require both scalability and high performance for practical\napplications. While semiconductor quantum dots are promising candidates for\nquantum bits, the complexity of measurement setups poses an important challenge\nfor scaling up these devices. Here, radio-frequency system-on-chip (RFSoC)\ntechnology is exepcted for a promising approach that combines scalability with\nflexibility. In this paper, we demonstrate RF reflectometry in gate-defined\nbilayer graphene quantum devices using RFSoC-based measurement architecture. By\ncontrolling the confinement strength through gate voltages, we achieve both\nFabry-P\\'erot interferometer and quantum dot operations in a single device.\nAlthough impedance matching conditions currently limit the measurement\nsensitivity, we identify pathways for optimization through tunnel barrier\nengineering and resonator design. These results represent a step toward\nintegrating high-bandwidth measurements with scalable quantum devices."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08013"
    ],
    "c_title":[
      "Hierarchical Manifold Projection for Ransomware Detection: A Novel\n  Geometric Approach to Identifying Malicious Encryption Patterns"
    ],
    "c_abstract":[
      "Encryption-based cyber threats continue to evolve, employing increasingly\nsophisticated techniques to bypass traditional detection mechanisms. Many\nexisting classification strategies depend on static rule sets, signature-based\nmatching, or machine learning models that require extensive labeled datasets,\nmaking them ineffective against emerging ransomware families that exhibit\npolymorphic and adversarial behaviors. A novel classification framework\nstructured through hierarchical manifold projection introduces a mathematical\napproach to detecting malicious encryption workflows, preserving geometric\nconsistencies that differentiate ransomware-induced modifications from benign\ncryptographic operations. The proposed methodology transforms encryption\nsequences into structured manifold embeddings, ensuring classification\nrobustness through non-Euclidean feature separability rather than reliance on\nstatic indicators. Generalization capabilities remain stable across diverse\nransomware variants, as hierarchical decomposition techniques capture\nmulti-scale encryption characteristics while maintaining resilience against\ncode obfuscation and execution flow modifications. Empirical analysis\ndemonstrates that detection accuracy remains high even when encryption key\nvariability, delayed execution tactics, or API call obfuscation strategies are\nintroduced, reinforcing the reliability of manifold-based classification.\nReal-time scalability assessments confirm that the proposed approach maintains\ncomputational efficiency across increasing dataset volumes, validating its\napplicability to large-scale threat detection scenarios."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-349",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17779"
    ],
    "b_title":[
      "Gradient structures from extensions of over-extended Kac-Moody algebras"
    ],
    "b_abstract":[
      "Over-extended Kac-Moody algebras contain so-called gradient structures - a\ngl(d)-covariant level decomposition of the algebra contains strings of modules\nat different levels that can be interpreted as spatial gradients. We present an\nalgebraic origin for this phenomenon, based on the recently introduced Lie\nalgebra extension of an over-extended Kac-Moody algebra by its fundamental\nmodule, appearing in tensor hierarchy algebra super-extensions of over-extended\nKac-Moody algebras. The extensions are described in terms of Lie algebra\ncohomology, vanishing for finite-dimensional simple Lie algebras, but\nnon-vanishing in relevant infinite-dimensional cases. The extension is\ndescribed in a few different gradings, where it is given a covariant\ndescription with respect to different subalgebras. We expect the results to be\nimportant for the connection between extended geometry and cosmological\nbilliards."
    ],
    "b_categories":[
      [
        "hep-th",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.15906"
    ],
    "c_title":[
      "The Onsager-Machlup functional for distribution dependent SDEs driven by\n  fractional Brownian motion"
    ],
    "c_abstract":[
      "In this paper, we compute the Onsager-Machlup functional for distribution\ndependent SDEs driven by fractional Brownian motions with Hurst\n  parameter $H\\in (\\frac{1}{4},1)$. In the case $ \\frac{1}{4} < H < \\frac{1}{2}\n$, the norm can be either the supremum norm or H\\\"older norms of order $ \\beta\n$ with $ 0 < \\beta < H - \\frac{1}{4} $. In the case $\\frac{1}{2} < H < 1 $, the\nnorms can be a H\\\"older norm of order $ \\beta$ with $ H - \\frac{1}{2} < \\beta <\nH - \\frac{1}{4} $. As an example, we compute the Onsager-Machlup functional for\nthe stochastic pendulum equation"
    ],
    "c_categories":[
      [
        "math.DS",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-350",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07211"
    ],
    "b_title":[
      "Weak-coupling bound states in semi-infinite topological waveguide QED"
    ],
    "b_abstract":[
      "A striking feature of cavity quantum electrodynamics is the existence of\natom-photon bound states, which typically form when the coupling between the\natom and its environment are strong enough that after de-excitation the atom\ncan ``grab'' an emitted photon and re-absorb it, resulting in a virtual cloud\nsurrounding the atom. Here we will demonstrate the existence of bound states\nthat instead form in the case of weak coupling. Specifically, we show that when\na quantum emitter is weakly coupled to a structured reservoir exhibiting\ntopologically-protected surface states, hybridizations between these states and\nthe emitter can form, resulting in mid-gap bound states. We illustrate this\nusing a semi-infinite extension of the Su-Schrieffer-Heeger (SSH) model as our\nreservoir. First, we diagonalize the bare semi-infinite SSH chain and reveal a\nwinding number that predicts only the edge state on the finite side of the\nchain survives the semi-infinite extension. Then, after coupling the quantum\nemitter to this end of the chain, we analyze the modified emitter spectrum and\nreveal the existence of bound states in three parameter regions. Two of these\nrepresent the usual strong-coupling bound states, while the third gives the\nweak-coupling bound states with eigenvalue appearing in the SSH band gap and\nwhich exhibit partial sublattice localization. We demonstrate that oscillations\nbetween the weak-coupling bound states can be used to transfer the particle\nfrom the emitter into the lattice in a predictable and reversible manner."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.03186"
    ],
    "c_title":[
      "Designing Speech Technologies for Australian Aboriginal English:\n  Opportunities, Risks and Participation"
    ],
    "c_abstract":[
      "In Australia, post-contact language varieties, including creoles and local\nvarieties of international languages, emerged as a result of forced contact\nbetween Indigenous communities and English speakers. These contact varieties\nare widely used, yet are poorly supported by language technologies. This gap\npresents barriers to participation in civil and economic society for Indigenous\ncommunities using these varieties, and reproduces minoritisation of\ncontemporary Indigenous sociolinguistic identities. This paper concerns three\nquestions regarding this context. First, can speech technologies support\nspeakers of Australian Aboriginal English, a local indigenised variety of\nEnglish? Second, what risks are inherent in such a project? Third, what\ntechnology development practices are appropriate for this context, and how can\nresearchers integrate meaningful community participation in order to mitigate\nrisks? We argue that opportunities do exist -- as well as risks -- and\ndemonstrate this through a case study exploring design practices in a\nreal-world project aiming to improve speech technologies for Australian\nAboriginal English. We discuss how we integrated culturally appropriate and\nparticipatory processes throughout the project. We call for increased support\nfor languages used by Indigenous communities, including contact varieties,\nwhich provide practical economic and socio-cultural benefits, provided that\nparticipatory and culturally safe practices are enacted."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-351",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13207"
    ],
    "b_title":[
      "Beyond MESA Defaults: The Impact of Structural Resolution Uncertainty in\n  p-mode Asteroseismology"
    ],
    "b_abstract":[
      "Observations of pressure modes ($p$-modes) in stars have enabled profound\ninsights into stellar properties, and theoretical stellar evolution and\noscillation models are integral to these inferences. However, modeling\nuncertainties are often overlooked, even as they can rival or exceed\nobservational uncertainties. In this study, we quantify, for the first time,\nthe impact of structural resolution choices in 1D stellar evolution\ncalculations on predicted $p$-mode frequencies across the HR diagram, using\n\\texttt{MESA} and \\texttt{GYRE}. We present measurements of resolution-based\nmodeling uncertainty for a range of solar-like, upper main-sequence, and Mira\noscillators and compare these directly to TESS observational uncertainties. We\ndemonstrate that resolution-driven uncertainties can significantly influence\ntheoretical predictions and in some cases overwhelm observational uncertainties\nby orders of magnitude: while solar-like oscillators typically have fractional,\nresolution-based uncertainties at or below 1\\% of the test frequency,\nfractional uncertainties in Miras were as large as 20\\%. We also find that the\nlocation and morphology of the RGB bump and red clump are impacted\nsubstantially by resolution uncertainty. Stellar ages are impacted at the 10\\%\nlevel for young main-sequence stars, and the model-based correction factor for\nthe $\\Delta\\nu$--$\\sqrt{\\rho}$ scaling relation is impacted at the 2\\% level.\nOur results underscore the need to incorporate modeling uncertainties into\nasteroseismic analyses and provide a reference framework for observers\nevaluating the reliability of theoretical models."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.05746"
    ],
    "c_title":[
      "A Minimum Property for Cuboidal Lattice Sums"
    ],
    "c_abstract":[
      "We analyse a family of lattices considered by Conway and Sloane and show that\nthe corresponding Epstein zeta function attains a local minimum for the\nbody-centred cubic lattice."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-352",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15980"
    ],
    "b_title":[
      "Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data\n  Annotation"
    ],
    "b_abstract":[
      "Text-to-SQL models, which parse natural language (NL) questions to executable\nSQL queries, are increasingly adopted in real-world applications. However,\ndeploying such models in the real world often requires adapting them to the\nhighly specialized database schemas used in specific applications. We find that\nexisting text-to-SQL models experience significant performance drops when\napplied to new schemas, primarily due to the lack of domain-specific data for\nfine-tuning. This data scarcity also limits the ability to effectively evaluate\nmodel performance in new domains. Continuously obtaining high-quality\ntext-to-SQL data for evolving schemas is prohibitively expensive in real-world\nscenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop\ntext-to-SQL data annotation system. SQLsynth streamlines the creation of\nhigh-quality text-to-SQL datasets through human-LLM collaboration in a\nstructured workflow. A within-subjects user study comparing SQLsynth with\nmanual annotation and ChatGPT shows that SQLsynth significantly accelerates\ntext-to-SQL data annotation, reduces cognitive load, and produces datasets that\nare more accurate, natural, and diverse. Our code is available at\nhttps:\/\/github.com\/adobe\/nl_sql_analyzer."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.DB",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14253"
    ],
    "c_title":[
      "Theoretical studies on the spin-charge dynamics in Kondo-lattice models"
    ],
    "c_abstract":[
      "The Kondo-lattice model describes a typical spin-charge coupled system in\nwhich localized spins and itinerant electrons are strongly coupled via exchange\ninteractions and exhibits a variety of long-wavelength magnetic orders\noriginating from the nesting of Fermi surfaces. Recently, several magnetic\nmaterials that realize this model have been discovered experimentally, and they\nhave turned out to exhibit rich topological magnetic phases including skyrmion\ncrystals and hedgehog lattices. Our recent theoretical studies based on the\nlarge-scale spin-dynamics simulations have revealed several interesting\nnonequilibrium phenomena and excitation dynamics in the Kondo-lattice model,\ne.g., dynamical magnetic topology switching and peculiar spin-wave modes of the\nskyrmion crystals and the hedgehog lattices under irradiation with\nelectromagnetic waves such as microwaves and light. These achievements are\nexpected to open a new research field to explore novel nonequilibrium\ntopological phenomena and related material functions of the spin-charge coupled\nmagnets."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-353",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02503"
    ],
    "b_title":[
      "Near-Feasible Solutions to Complex Stable Matching Problems"
    ],
    "b_abstract":[
      "In this paper, we demonstrate that in many NP-complete variants of the stable\nmatching problem, such as the Stable Hypergraph Matching problem, the Stable\nMulticommodity Flow problem, and the College Admission problem with common\nquotas, a near-feasible stable solution - that is, a solution which is stable,\nbut may slightly violate some capacities - always exists. Our results provide\nstrong theoretical guarantees that even under complex constraints, stability\ncan be restored with minimal capacity modifications.\n  To achieve this, we present an iterative rounding algorithm that starts from\na stable fractional solution and systematically adjusts capacities to ensure\nthe existence of an integral stable solution. This approach leverages Scarf's\nalgorithm to compute an initial fractional stable solution, which serves as the\nfoundation for our rounding process. Notably, in the case of the Stable\nFixtures problem, where a stable fractional matching can be computed\nefficiently, our method runs in polynomial time.\n  These findings have significant practical implications for market design,\ncollege admissions, and other real-world allocation problems, where small\nadjustments to institutional constraints can guarantee stable and implementable\noutcomes."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01140"
    ],
    "c_title":[
      "Assouad dimension of the Takagi function"
    ],
    "c_abstract":[
      "For any integer $b\\geq2$ and real series $\\{c_n\\}$ such that\n$\\sum_{n=0}^\\infty|c_n|<\\infty$, the generalized Takagi function $f_{{\\mathbf\nc},b}(x)$ is defined by $$\n  f_{{\\mathbf c},b}(x):=\\sum_{n=0}^\\infty c_n\\phi(b^n x), \\quad x\\in [0,1], $$\nwhere $\\phi(x)=dist(x,\\mathbb{Z})$ is the distance from $x$ to the nearest\ninteger. The collection of functions with the form are called the Takagi class.\nIn this paper, we show that in the case that $\\varlimsup_{n \\to \\infty} b^n\n|c_n|<\\infty$, the Assouad dimension of the graph ${\\mathcal G} f_{{\\mathbf\nc},b}=\\{(x,f_{{\\mathbf c},b}(x)):x\\in[0,1]\\}$ for the generalized Takagi\nfunction $f_{{\\mathbf c},b}(x)$ is equal to one, that is, $$ \\dim_A {\\mathcal\nG} f_{{\\mathbf c},b}=1. $$ In particular, for each $0<a<1$ and integer $b \\geq\n2$, we define Takagi function $T_{a,b}$ as followed, $$\n  T_{a,b}(x):=\\sum_{n=0}^\\infty a^n \\phi(b^n x), \\quad x\\in [0,1]. $$ Then $\n  \\dim_A {\\mathcal G} T_{a,b}=1 $ if and only if $0<a \\leq 1\/b$."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-354",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06117"
    ],
    "b_title":[
      "Revisiting Dynamic Graph Clustering via Matrix Factorization"
    ],
    "b_abstract":[
      "Dynamic graph clustering aims to detect and track time-varying clusters in\ndynamic graphs, revealing the evolutionary mechanisms of complex real-world\ndynamic systems. Matrix factorization-based methods are promising approaches\nfor this task; however, these methods often struggle with scalability and can\nbe time-consuming when applied to large-scale dynamic graphs. Moreover, they\ntend to lack robustness and are vulnerable to real-world noisy data. To address\nthese issues, we make three key contributions. First, to improve scalability,\nwe propose temporal separated matrix factorization, where a single matrix is\ndivided into multiple smaller matrices for independent factorization, resulting\nin faster computation. Second, to improve robustness, we introduce\nbi-clustering regularization, which jointly optimizes graph embedding and\nclustering, thereby filtering out noisy features from the graph embeddings.\nThird, to further enhance effectiveness and efficiency, we propose selective\nembedding updating, where we update only the embeddings of dynamic nodes while\nthe embeddings of static nodes are fixed among different timestamps.\nExperimental results on six synthetic and five real-world benchmarks\ndemonstrate the scalability, robustness and effectiveness of our proposed\nmethod. Source code is available at https:\/\/github.com\/Clearloveyuan\/DyG-MF."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17210"
    ],
    "c_title":[
      "A novel approach to accounting for correlations in evolution over time\n  of an open quantum system"
    ],
    "c_abstract":[
      "A projection operator is introduced, which exactly transforms the\ninhomogeneous Nakajima--Zwanzig generalized master equation for the relevant\npart of a system +bath statistical operator, containing the inhomogeneous\nirrelevant term comprising the initial corrrelations, into the homogeneous\nequation accounting for initial correlations in the kernel governing its\nevolution. No \"molecular chaos\"-like approximation has been used. The obtained\nequation is equivalent to completely closed (homogeneous) equation for the\nstatistical operator of a system of interest interacting with a bath. In the\nBorn approximation (weak system-bath interaction) this equation can be\npresented as the time-local Redfield-like equation with additional terms caused\nby initial correlations. As an application, a quantum oscillator, interacting\nwith a Boson field and driven from a Gibbs initial equilibrium system+bath\nstate by an external force, is considered. All terms determining the oscillator\nevolution over time are explicitly calculated at all timescales. It is shown,\nhow the initial correlations influence the evolution process. It is also\ndemonstrated, that at the large timescale this influence vanishes, and the\nevolution equation for the quantum oscillator statistical operator acquires the\nLindblad form.."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-355",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11911"
    ],
    "b_title":[
      "Partial Topological Protection in C4 Lattices for Optical Communications"
    ],
    "b_abstract":[
      "In recent studies, analogs of the electronic Quantum Spin-Hall Effect have\nbeen explored within photonic crystals that incorporate spatial symmetries,\nespecially those with $ C_{6v} $ symmetry, where $ \\mathbb{Z}_2 $ topological\ninvariants are enforced by crystalline symmetry. These photonic crystals\npossess bulk states with well-defined pseudospins and exhibit helical edge\nstates, closely resembling their electronic counterparts. However, achieving\n$\\mathbb{Z}_2$ topological protection in a square lattice photonic crystal\nremains great theoretical and experimental challange. In this work, we propose\na single material photonic crystal structure based on a $ C_4 $ lattice that\nsupports partially $ \\mathbb{Z}_2 $-protected edge modes. We show that this\nstructure can host photonic band-gap that hosts $ \\mathbb{Z}_2 $-like modes,\nenabling perfect transmission in waveguide applications. Furthermore, we\ninvestigate the robustness of these modes against structural defects and\ndirectional turns, highlighting the distinctions between full $ \\mathbb{Z}_2 $\ntopological protection and partial topological protection. Finally, we analyze\nthe impact of the number of elementary cells surrounding the interface on the\nformation and stability of these protected modes."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11077"
    ],
    "c_title":[
      "SmartShards: Churn-Tolerant Continuously Available Distributed Ledger"
    ],
    "c_abstract":[
      "We present SmartShards: a new sharding algorithm for improving Byzantine\ntolerance and churn resistance in blockchains. Our algorithm places a peer in\nmultiple shards to create an overlap. This simplifies cross-shard communication\nand shard membership management. We describe SmartShards, prove it correct and\nevaluate its performance.\n  We propose several SmartShards extensions: defense against a slowly adaptive\nadversary, combining transactions into blocks, fortification against the\njoin\/leave attack."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-356",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08388"
    ],
    "b_title":[
      "The shadow and accretion disk images of the rotation loop quantum black\n  bounce"
    ],
    "b_abstract":[
      "In this paper, we study the shadow and observational image of the Kerr-like\nLoop Quantum Gravity (LQG) inspired black bounce with the help of the celestial\nlight source and the thin disk source by employing the backward ray-tracing\nmethod. The results indicate that both the LQG parameter alpha and the rotation\nparameter a contribute to a reduction in the shadow size; however, the\ninfluence of a is predominant, while the effect of alpha circular orbit. One\ncan find that the correlation parameter (a, alpha), along with the observer's\ninclination angle, affect the image's asymmetry and the distortion of the inner\nshadow. As the inclination increases, the direct and lensed images diverge,\ncreating a structure resembling a hat. Meanwhile, we also investigate the\nredshift distribution of the direct lensed images of the accretion disk under\ndifferent parameters and observation angle. The results show that the\ndistribution of redshift and observed intensity is obviously related to the\nbehavior of accretion flow. These results may provide a potential approach to\nlimit black hole parameters, detect quantum gravity effects, and distinguish\nthe LQG black hole from other black hole models."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.15410"
    ],
    "c_title":[
      "Equilibrium stresses in frameworks via symmetric averaging"
    ],
    "c_abstract":[
      "For a bar-joint framework $(G,p)$, a subgroup $\\Gamma$ of the automorphism\ngroup of $G$, and a subgroup of the orthogonal group isomorphic to $\\Gamma$, we\nintroduce a symmetric averaging map which produces a bar-joint framework on $G$\nwith that symmetry. If the original configuration is ``almost symmetric\", then\nthe averaged one will be near the original configuration. With a view on\nstructural engineering applications, we then introduce a hierarchy of\ndefinitions of ``localised\" and ``non-localised\" or ``extensive\" self-stresses\nof frameworks and investigate their behaviour under the symmetric averaging\nprocedure. Finally, we present algorithms for finding non-degenerate symmetric\nframeworks with many states of self-stress, as well as non-symmetric and\nsymmetric frameworks with extensive self-stresses. The latter uses the\nsymmetric averaging map in combination with symmetric Maxwell-type character\ncounts and a procedure based on the pure condition from algebraic geometry.\nThese algorithms provide new theoretical and computational tools for the design\nof engineering structures such as gridshell roofs."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-357",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06822"
    ],
    "b_title":[
      "Model-based edge clustering for weighted networks with a noise component"
    ],
    "b_abstract":[
      "Clustering is a fundamental task in network analysis, essential for\nuncovering hidden structures within complex systems. Edge clustering, which\nfocuses on relationships between nodes rather than the nodes themselves, has\ngained increased attention in recent years. However, existing edge clustering\nalgorithms often overlook the significance of edge weights, which can represent\nthe strength or capacity of connections, and fail to account for noisy\nedges--connections that obscure the true structure of the network. To address\nthese challenges, the Weighted Edge Clustering Adjusting for Noise (WECAN)\nmodel is introduced. This novel algorithm integrates edge weights into the\nclustering process and includes a noise component that filters out spurious\nedges. WECAN offers a data-driven approach to distinguishing between meaningful\nand noisy edges, avoiding the arbitrary thresholding commonly used in network\nanalysis. Its effectiveness is demonstrated through simulation studies and\napplications to real-world datasets, showing significant improvements over\ntraditional clustering methods. Additionally, the R package ``WECAN'' has been\ndeveloped to facilitate its practical implementation."
    ],
    "b_categories":[
      [
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.17238"
    ],
    "c_title":[
      "The First SRG\/eROSITA All-Sky Survey. Characterization of clusters of\n  galaxies misclassified in the eRASS1 point source catalog"
    ],
    "c_abstract":[
      "The detection of the extended X-ray-emission of the intracluster medium by\nthe first SRG\/eROSITA All-Sky Survey (eRASS1), combined with optical and\nnear-infrared follow-up, resulted in the identification of more than 12000\ngalaxy clusters, yielding precise constraints on cosmological parameters.\nHowever, some clusters of galaxies can be misclassified as point sources by\neROSITA's source detection algorithm due to the interplay between the\npoint-spread function, the shallow depth of the survey, compact (cool core)\nX-ray emission, and bright active galactic nuclei hosted in their centers or\ntheir vicinity. To identify such misclassified galaxy clusters and groups, we\napply optical follow-up to the eRASS1 X-ray point sources analogously to the\ntreatment of the extent-selected catalog. After rigorous filtering to ensure\npurity, we find a total of 8347 clusters of galaxies, of which 5819 are novel\ndetections, in a redshift range $0.05 < z \\lesssim 1.1$. This corresponds to a\n70 % discovery rate, a fraction similar to that of the extent-selected sample.\nTo facilitate finding new exceptional clusters such as the Phoenix cluster\n(which is recovered in our sample), we divide the clusters into five classes\nbased on the optical properties of likely single-source counterparts to the\nX-ray emission. We further investigate potential biases in our selection\nprocess by analyzing the optical and X-ray data. With this work, we provide a\ncatalog of galaxy clusters and groups in the eRASS1 point source catalog,\nincluding their optical and X-ray properties along with a meaningful\nclassification."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-358",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13384"
    ],
    "b_title":[
      "The bimodal distribution in the derivative of unitary polynomials"
    ],
    "b_abstract":[
      "The derivative of a polynomial with all zeros on the unit circle has the\nzeros of its derivative on or inside the unit circle. It has been observed that\nin many cases the zeros of the derivative have a bimodal distribution: there\nare two smaller circles near which it is more likely to find those zeros. We\nidentify the likely source of the second mode. This idea is supported with\nnumerical examples involving the characteristic polynomials of random unitary\nmatrices."
    ],
    "b_categories":[
      [
        "math.CV",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.13961"
    ],
    "c_title":[
      "The Computational Advantage of Depth: Learning High-Dimensional\n  Hierarchical Functions with Gradient Descent"
    ],
    "c_abstract":[
      "Understanding the advantages of deep neural networks trained by gradient\ndescent (GD) compared to shallow models remains an open theoretical challenge.\nWhile the study of multi-index models with Gaussian data in high dimensions has\nprovided analytical insights into the benefits of GD-trained neural networks\nover kernels, the role of depth in improving sample complexity and\ngeneralization in GD-trained networks remains poorly understood. In this paper,\nwe introduce a class of target functions (single and multi-index Gaussian\nhierarchical targets) that incorporate a hierarchy of latent subspace\ndimensionalities. This framework enables us to analytically study the learning\ndynamics and generalization performance of deep networks compared to shallow\nones in the high-dimensional limit. Specifically, our main theorem shows that\nfeature learning with GD reduces the effective dimensionality, transforming a\nhigh-dimensional problem into a sequence of lower-dimensional ones. This\nenables learning the target function with drastically less samples than with\nshallow networks. While the results are proven in a controlled training\nsetting, we also discuss more common training procedures and argue that they\nlearn through the same mechanisms. These findings open the way to further\nquantitative studies of the crucial role of depth in learning hierarchical\nstructures with deep networks."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-359",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09809"
    ],
    "b_title":[
      "Interpolation characterization of higher Thom polynomials"
    ],
    "b_abstract":[
      "Thom polynomials provide universal formulas for the fundamental class of\nsingularity loci in terms of characteristic classes. Ohmoto extended this\nnotion to SSM-Thom polynomials, which refine this description by capturing the\nricher Segre-Schwartz-MacPherson (SSM) class of singularity loci. While\nprevious methods for computing SSM-Thom polynomials relied on intricate\ngeometric arguments, we introduce a more efficient approach that depends solely\non the symmetries of singularities. Our method is inspired by connections to\nGeometric Representation Theory, particularly the interpolation properties of\nMaulik-Okounkov stable envelopes. By formulating SSM analogs of these axioms\nwithin a degree-bounded framework, we obtain new computational tools for\nSSM-Thom polynomials. We also present explicit examples of SSM-Thom\npolynomials, and illustrate their applications in enumerative geometry and\nsingularity theory."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.10648"
    ],
    "c_title":[
      "Hate Speech and Sentiment of YouTube Video Comments From Public and\n  Private Sources Covering the Israel-Palestine Conflict"
    ],
    "c_abstract":[
      "This study explores the prevalence of hate speech (HS) and sentiment in\nYouTube video comments concerning the Israel-Palestine conflict by analyzing\ncontent from both public and private news sources. The research involved\nannotating 4983 comments for HS and sentiments (neutral, pro-Israel, and\npro-Palestine). Subsequently, machine learning (ML) models were developed,\ndemonstrating robust predictive capabilities with area under the receiver\noperating characteristic (AUROC) scores ranging from 0.83 to 0.90. These models\nwere applied to the extracted comment sections of YouTube videos from public\nand private sources, uncovering a higher incidence of HS in public sources\n(40.4%) compared to private sources (31.6%). Sentiment analysis revealed a\npredominantly neutral stance in both source types, with more pronounced\nsentiments towards Israel and Palestine observed in public sources. This\ninvestigation highlights the dynamic nature of online discourse surrounding the\nIsrael-Palestine conflict and underscores the potential of moderating content\nin a politically charged environment."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-360",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15898"
    ],
    "b_title":[
      "Homotopy categories and fibrant model structures"
    ],
    "b_abstract":[
      "The homotopy category of a model structure on a weakly idempotent complete\nadditive category is proved to be equivalent to the additive quotient of the\ncategory of cofibrant-fibrant objects with respect to the subcategory of\ncofibrant-fibrant-trivial objects. A model structure on pointed category is\nfibrant, if every object is a fibrant object. Fibrant model structures is\nexplicitly described by trivial cofibrations, and also by fibrations. Fibrantly\nweak factorization systems are introduced, fibrant model structures are\nconstructed via fibrantly weak factorization systems, and a one-one\ncorrespondence between fibrantly weak factorization systems and fibrant model\nstructures is given. Applications are given to rediscover the $\\omega$-model\nstructures and the $\\mathcal W$-model structures, and their relations with\nexact model structures are discussed."
    ],
    "b_categories":[
      [
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.05857"
    ],
    "c_title":[
      "SYMBIOSIS: Systems Thinking and Machine Intelligence for Better Outcomes\n  in Society"
    ],
    "c_abstract":[
      "This paper presents SYMBIOSIS, an AI-powered framework and platform designed\nto make Systems Thinking accessible for addressing societal challenges and\nunlock paths for leveraging systems thinking frameworks to improve AI systems.\nThe platform establishes a centralized, open-source repository of systems\nthinking\/system dynamics models categorized by Sustainable Development Goals\n(SDGs) and societal topics using topic modeling and classification techniques.\nSystems Thinking resources, though critical for articulating causal theories in\ncomplex problem spaces, are often locked behind specialized tools and intricate\nnotations, creating high barriers to entry. To address this, we developed a\ngenerative co-pilot that translates complex systems representations - such as\ncausal loop and stock-flow diagrams - into natural language (and vice-versa),\nallowing users to explore and build models without extensive technical\ntraining.\n  Rooted in community-based system dynamics (CBSD) and informed by\ncommunity-driven insights on societal context, we aim to bridge the problem\nunderstanding chasm. This gap, driven by epistemic uncertainty, often limits ML\ndevelopers who lack the community-specific knowledge essential for problem\nunderstanding and formulation, often leading to ill informed causal\nassumptions, reduced intervention effectiveness and harmful biases. Recent\nresearch identifies causal and abductive reasoning as crucial frontiers for AI,\nand Systems Thinking provides a naturally compatible framework for both. By\nmaking Systems Thinking frameworks more accessible and user-friendly, SYMBIOSIS\naims to serve as a foundational step to unlock future research into responsible\nand society-centered AI. Our work underscores the need for ongoing research\ninto AI's capacity to understand essential characteristics of complex adaptive\nsystems paving the way for more socially attuned, effective AI systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-361",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01302"
    ],
    "b_title":[
      "Coupling of dynamical tide and orbital motion"
    ],
    "b_abstract":[
      "Dynamical tide consists of various waves that can resonate with orbital\nmotion. We test this coupling of dynamical tide and orbital motion using a\nsimple two-dimensional shallow water model, which can be applied to a rocky\nplanet covered with thin ocean or atmosphere. Then we take the earth-moon\nsystem as a fiducial model to calculate the tidal resonances and orbital\nevolution. We find that tidal dissipation can even increase with increasing\norbital separation because of the coupling of dynamical tide and orbital\nmotion. We draw the conclusion that the coupling is not negligible to study the\norbital evolution on secular timescale."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.08245"
    ],
    "c_title":[
      "ExMAG: Learning of Maximally Ancestral Graphs"
    ],
    "c_abstract":[
      "As one transitions from statistical to causal learning, one is seeking the\nmost appropriate causal model. Dynamic Bayesian networks are a popular model,\nwhere a weighted directed acyclic graph represents the causal relationships.\nStochastic processes are represented by its vertices, and weighted oriented\nedges suggest the strength of the causal relationships. When there are\nconfounders, one would like to utilize both oriented edges (when the direction\nof causality is clear) and edges that are not oriented (when there is a\nconfounder), yielding mixed graphs. A little-studied extension of acyclicity to\nthis mixed-graph setting is known as maximally ancestral graphs. We propose a\nscore-based learning algorithm for learning maximally ancestral graphs. A\nmixed-integer quadratic program is formulated, and an algorithmic approach is\nproposed, in which the pre-generation of exponentially many constraints is\navoided by generating only violated constraints in the so-called branch-and-cut\n(``lazy constraint'') method. Comparing the novel approach to the\nstate-of-the-art, we show that the proposed approach turns out to produce more\naccurate results when applied to small and medium-sized synthetic instances\ncontaining up to 25 variables."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-362",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03460"
    ],
    "b_title":[
      "K-theoretic Tate-Poitou duality at prime 2"
    ],
    "b_abstract":[
      "We extend the result of Blumberg and Mandell on K-theoretic Tate-Poitou\nduality at odd primes which serves as a spectral refinement of the classical\narithmetic Tate-Poitou duality. The duality is formulated for the\n$K(1)$-localized algebraic K-theory of the ring of $p$-integers in a number\nfield and its completion using the $\\bZ_p$-Anderson duality. This paper\ncompletes the picture by addressing the prime 2, where the real embeddings of\nnumber fields introduce extra complexities. As an application, we identify the\nhomotopy type at prime 2 of the homotopy fiber of the cyclotomic trace for the\nsphere spectrum in terms of the algebraic K-theory of the integers."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.KT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07978"
    ],
    "c_title":[
      "Detecting Backdoor Attacks in Federated Learning via Direction Alignment\n  Inspection"
    ],
    "c_abstract":[
      "The distributed nature of training makes Federated Learning (FL) vulnerable\nto backdoor attacks, where malicious model updates aim to compromise the global\nmodel's performance on specific tasks. Existing defense methods show limited\nefficacy as they overlook the inconsistency between benign and malicious model\nupdates regarding both general and fine-grained directions. To fill this gap,\nwe introduce AlignIns, a novel defense method designed to safeguard FL systems\nagainst backdoor attacks. AlignIns looks into the direction of each model\nupdate through a direction alignment inspection process. Specifically, it\nexamines the alignment of model updates with the overall update direction and\nanalyzes the distribution of the signs of their significant parameters,\ncomparing them with the principle sign across all model updates. Model updates\nthat exhibit an unusual degree of alignment are considered malicious and thus\nbe filtered out. We provide the theoretical analysis of the robustness of\nAlignIns and its propagation error in FL. Our empirical results on both\nindependent and identically distributed (IID) and non-IID datasets demonstrate\nthat AlignIns achieves higher robustness compared to the state-of-the-art\ndefense methods. The code is available at\nhttps:\/\/github.com\/JiiahaoXU\/AlignIns."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.DC",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-363",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17968"
    ],
    "b_title":[
      "The defocusing Calogero--Moser derivative nonlinear Schr{\\\"o}dinger\n  equation with a nonvanishing condition at infinity"
    ],
    "b_abstract":[
      "We consider the defocusing Calogero--Moser derivative nonlinear\nSchr{\\\"o}dinger equation\\begin{align*}i \\partial_{t} u+\\partial_{x}^2 u-2\\Pi\nD\\left(|u|^{2}\\right)u=0, \\quad (t,x ) \\in \\mathbb{R} \\times\n\\mathbb{R}\\end{align*}posed on $E := \\left\\{u \\in L^{\\infty}(\\mathbb{R}): u'\n\\in L^{2}(\\mathbb{R}), u'' \\in L^{2}(\\mathbb{R}), |u|^{2}-1 \\in\nL^{2}(\\mathbb{R})\\right\\}$. We prove the global well-posedness of this equation\nin $E$. Moreover, we give an explicit formula for the chiral solution to this\nequation."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.12964"
    ],
    "c_title":[
      "Trust Me, I'm Wrong: High-Certainty Hallucinations in LLMs"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) often generate outputs that lack grounding in\nreal-world facts, a phenomenon known as hallucinations. Prior research has\nassociated hallucinations with model uncertainty, leveraging this relationship\nfor hallucination detection and mitigation. In this paper, we challenge the\nunderlying assumption that all hallucinations are associated with uncertainty.\nUsing knowledge detection and uncertainty measurement methods, we demonstrate\nthat models can hallucinate with high certainty even when they have the correct\nknowledge. We further show that high-certainty hallucinations are consistent\nacross models and datasets, distinctive enough to be singled out, and challenge\nexisting mitigation methods. Our findings reveal an overlooked aspect of\nhallucinations, emphasizing the need to understand their origins and improve\nmitigation strategies to enhance LLM safety. The code is available at\nhttps:\/\/github.com\/technion-cs-nlp\/Trust_me_Im_wrong ."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-364",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14105"
    ],
    "b_title":[
      "Conformal Prediction under L\\'evy-Prokhorov Distribution Shifts:\n  Robustness to Local and Global Perturbations"
    ],
    "b_abstract":[
      "Conformal prediction provides a powerful framework for constructing\nprediction intervals with finite-sample guarantees, yet its robustness under\ndistribution shifts remains a significant challenge. This paper addresses this\nlimitation by modeling distribution shifts using L\\'evy-Prokhorov (LP)\nambiguity sets, which capture both local and global perturbations. We provide a\nself-contained overview of LP ambiguity sets and their connections to popular\nmetrics such as Wasserstein and Total Variation. We show that the link between\nconformal prediction and LP ambiguity sets is a natural one: by propagating the\nLP ambiguity set through the scoring function, we reduce complex\nhigh-dimensional distribution shifts to manageable one-dimensional distribution\nshifts, enabling exact quantification of worst-case quantiles and coverage.\nBuilding on this analysis, we construct robust conformal prediction intervals\nthat remain valid under distribution shifts, explicitly linking LP parameters\nto interval width and confidence levels. Experimental results on real-world\ndatasets demonstrate the effectiveness of the proposed approach."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00190"
    ],
    "c_title":[
      "Observation and mitigation of microwave echoes from dielectric defects\n  in Josephson traveling wave amplifiers"
    ],
    "c_abstract":[
      "Amplifying microwave signals with a noise close to the minimum imposed by\nquantum mechanics is now routinely performed with superconducting quantum\ndevices. In particular, Josephson-based Traveling Wave Parametric Amplifiers\n(JTWPA) have shown record bandwidth with added noise close to the quantum\nlimit. In this work, we report the appearance of echo signals emitted by JTWPAs\ndriven by trains of high-power pulses exceeding their dynamical range. we\nexplore the case of weak signals generated through high power pulses. By\nsending a train of such high-power pulses, beyond the 1 dB compression point of\nsuch amplifiers, we observe the appearance of echoes, solely due to the JTWPA.\nThese echoes have micro-second coherence and we attribute their origin to\nmicroscopic defects in the amplifier dielectric layer. By analyzing the power\nand the coherence of the echo signal as a function of temperature, we estimate\nthe dielectric loss brought by these defects, and their impact on the JTWPA\nquantum efficiency. We introduce a mitigation technique (BLAST) to prevent the\nappearance of these echoes, consisting in an additional high-power tone sent\nconcurrently with each pulse. We demonstrate that it suppresses the spurious\ndefect signals and we recover the typical gain and noise figure within 95% of\ntheir low-power values in 300 ns. These results can help to extend the use of\nJTWPAs in experiments where fast high-power sequences are necessary to generate\nweak microwave responses from the system under study, and also provide a path\ntowards characterizing in-situ the dielectric losses of these devices."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-365",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13988"
    ],
    "b_title":[
      "MCRL4OR: Multimodal Contrastive Representation Learning for Off-Road\n  Environmental Perception"
    ],
    "b_abstract":[
      "Most studies on environmental perception for autonomous vehicles (AVs) focus\non urban traffic environments, where the objects\/stuff to be perceived are\nmainly from man-made scenes and scalable datasets with dense annotations can be\nused to train supervised learning models. By contrast, it is hard to densely\nannotate a large-scale off-road driving dataset manually due to the inherently\nunstructured nature of off-road environments. In this paper, we propose a\nMultimodal Contrastive Representation Learning approach for Off-Road\nenvironmental perception, namely MCRL4OR. This approach aims to jointly learn\nthree encoders for processing visual images, locomotion states, and control\nactions by aligning the locomotion states with the fused features of visual\nimages and control actions within a contrastive learning framework. The\ncausation behind this alignment strategy is that the inertial locomotion state\nis the result of taking a certain control action under the current\nlandform\/terrain condition perceived by visual sensors. In experiments, we\npre-train the MCRL4OR with a large-scale off-road driving dataset and adopt the\nlearned multimodal representations for various downstream perception tasks in\noff-road driving scenarios. The superior performance in downstream tasks\ndemonstrates the advantages of the pre-trained multimodal representations. The\ncodes can be found in \\url{https:\/\/github.com\/1uciusy\/MCRL4OR}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.04451"
    ],
    "c_title":[
      "Observation of the $W$-annihilation process $D_s^+ \\to \\omega\\rho^+$ and\n  measurement of $D_s^+ \\to \\phi\\rho^+$ in $D^+_s\\to \\pi^+\\pi^+\\pi^-\\pi^0\\pi^0$\n  decays"
    ],
    "c_abstract":[
      "We present the first amplitude analysis and branching fraction measurement of\nthe decay $D^+_s\\to \\pi^+\\pi^+\\pi^-\\pi^0\\pi^0$, using $e^+e^-$ collision data\ncollected with the BESIII detector at center-of-mass energies between 4.128 and\n4.226 GeV corresponding to an integrated luminosity of 7.33 fb$^{-1}$, and\nreport the first observation of the pure $W$-annihilation decay $D_s^+ \\to\n\\omega\\rho^+$ with a branching fraction of $(0.99\\pm0.08_{\\rm stat}\\pm0.07_{\\rm\nsyst})\\%$. In comparison to the low significance of the $\\mathcal{D}$ wave in\nthe decay $D_s^+ \\to \\phi\\rho^+$, the dominance of the $\\mathcal{D}$ wave over\nthe $\\mathcal{S}$ and $\\mathcal{P}$ waves, with a fraction of\n$(51.85\\pm7.28_{\\rm stat}\\pm7.90_{\\rm syst})\\%$ observed in the decay, provides\ncrucial information for the``polarization puzzle\", as well as for the\nunderstanding of charm meson decays. The branching fraction of $D^+_s\\to\n\\pi^+\\pi^+\\pi^-\\pi^0\\pi^0$ is measured to be $(4.41\\pm0.15_{\\rm\nstat}\\pm0.13_{\\rm syst})\\%$. Moreover, the branching fraction of $D_s^+ \\to\n\\phi\\rho^+$ is measured to be $(3.98\\pm0.33_{\\rm stat}\\pm0.21_{\\rm syst})\\%$,\nand the $R_{\\phi}= {\\mathcal{B}(\\phi\\to\\pi^+\\pi^-\\pi^0)}\/{\\mathcal{B}(\\phi\\to\nK^+K^-)}$ is determined to be $(0.222\\pm0.019_{\\rm stat}\\pm0.016_{\\rm syst}$),\nwhich is consistent with the previous measurement based on charm meson decays,\nbut deviates from the results from $e^+e^-$ annihilation and $K$-$N$ scattering\nexperiments by more than 3$\\sigma$."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-366",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16412"
    ],
    "b_title":[
      "Dynamic Neutrino Mass Ordering and Its Imprint on the Diffuse Supernova\n  Neutrino Background"
    ],
    "b_abstract":[
      "Neutrino masses may have evolved dynamically throughout the history of the\nUniverse, potentially leading to a mass spectrum distinct from the normal or\ninverted ordering observed today. While cosmological measurements constrain the\ntotal energy density of neutrinos, they are not directly sensitive to a\ndynamically changing mass ordering unless future surveys achieve exceptional\nprecision in detecting the distinct imprints of each mass eigenstate on\nlarge-scale structures. In this work, we investigate the impact of a dynamic\nneutrino mass spectrum on the diffuse supernova neutrino background (DSNB),\nwhich is composed of neutrinos from all supernova explosions throughout cosmic\nhistory and is on the verge of experimental detection. Since neutrino\noscillations are highly sensitive to the mass spectrum, we show that the\nelectron neutrino survival probability carries distinct signatures of the\nevolving neutrino mass spectrum. Our results indicate that the resulting\nmodifications to the DSNB spectrum would exhibit unique energy-dependent\nfeatures. These features are distinguishable from the effects of significant\nastrophysical uncertainties, providing a potential avenue for probing the\ndynamic nature of neutrino masses."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.21065"
    ],
    "c_title":[
      "Lifted Frequency-Domain Identification of Closed-Loop Multirate Systems:\n  Applied to Dual-Stage Actuator Hard Disk Drives"
    ],
    "c_abstract":[
      "Frequency-domain representations are crucial for the design and performance\nevaluation of controllers in multirate systems, specifically to address\nintersample performance. The aim of this paper is to develop an effective\nfrequency-domain system identification technique for closed-loop multirate\nsystems using solely slow-rate output measurements. By indirect identification\nof multivariable time-invariant representations through lifting, in combination\nwith local modeling techniques, the multirate system is effectively identified.\nThe developed method is capable of accurate identification of closed-loop\nmultirate systems within a single identification experiment, using fast-rate\nexcitation and inputs, and slow-rate outputs. Finally, the developed framework\nis validated using a benchmark problem consisting of a multivariable dual-stage\nactuator from a hard disk drive, demonstrating its applicability and accuracy."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-367",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01219"
    ],
    "b_title":[
      "Control Strategy for Generalized Synchrony in Coupled Dynamical Systems"
    ],
    "b_abstract":[
      "Dynamical systems can be coupled in a manner that is designed to drive the\nresulting dynamics onto a specified lower dimensional submanifold in the phase\nspace of the combined system. On the submanifold, the variables of the two\nsystems have a well-defined unique functional relationship. This process can\nthus be viewed as a control technique that ensures generalized synchronization.\nDepending on the nature of the dynamical systems and the specified submanifold,\ndifferent coupling functions can be derived in order to achieve a desired\ncontrol objective. We discuss the circuit implementations of this strategy in\nrepresentative examples of coupled chaotic dynamical systems, namely Lorenz\noscillators"
    ],
    "b_categories":[
      [
        "nlin.CD"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.09887"
    ],
    "c_title":[
      "FLORA: Formal Language Model Enables Robust Training-free Zero-shot\n  Object Referring Analysis"
    ],
    "c_abstract":[
      "Object Referring Analysis (ORA), commonly known as referring expression\ncomprehension, requires the identification and localization of specific objects\nin an image based on natural descriptions. Unlike generic object detection, ORA\nrequires both accurate language understanding and precise visual localization,\nmaking it inherently more complex. Although recent pre-trained large visual\ngrounding detectors have achieved significant progress, they heavily rely on\nextensively labeled data and time-consuming learning. To address these, we\nintroduce a novel, training-free framework for zero-shot ORA, termed FLORA\n(Formal Language for Object Referring and Analysis). FLORA harnesses the\ninherent reasoning capabilities of large language models (LLMs) and integrates\na formal language model - a logical framework that regulates language within\nstructured, rule-based descriptions - to provide effective zero-shot ORA. More\nspecifically, our formal language model (FLM) enables an effective,\nlogic-driven interpretation of object descriptions without necessitating any\ntraining processes. Built upon FLM-regulated LLM outputs, we further devise a\nBayesian inference framework and employ appropriate off-the-shelf interpretive\nmodels to finalize the reasoning, delivering favorable robustness against LLM\nhallucinations and compelling ORA performance in a training-free manner. In\npractice, our FLORA boosts the zero-shot performance of existing pretrained\ngrounding detectors by up to around 45%. Our comprehensive evaluation across\ndifferent challenging datasets also confirms that FLORA consistently surpasses\ncurrent state-of-the-art zero-shot methods in both detection and segmentation\ntasks associated with zero-shot ORA. We believe our probabilistic parsing and\nreasoning of the LLM outputs elevate the reliability and interpretability of\nzero-shot ORA. We shall release codes upon publication."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-368",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18203"
    ],
    "b_title":[
      "Joint Design and Pricing of Extended Warranties for Multiple Automobiles\n  with Different Price Bands"
    ],
    "b_abstract":[
      "Extended warranties (EWs) are significant source of revenue for\ncapital-intensive products like automobiles. Such products consist of multiple\nsubsystems, providing flexibility in EW customization, for example, bundling a\ntailored set of subsystems in an EW contract. This, in turn, enables the\ncreation of a service menu with different EW contract options. From the\nperspective of a third-party EW provider servicing a fleet of automobile\nbrands, we develop a novel model to jointly optimize the design and pricing of\nEWs in order to maximize the profit. Specifically, the problem is to determine\nwhich contracts should be included in the EW menu and identify the appropriate\nprice for each contract. As the complexity of the joint optimization problem\nincreases exponentially with the number of subsystems, two solution approaches\nare devised to solve the problem. The first approach is based on a\nmixed-integer second-order cone programming reformulation, which guarantees\noptimality but is applicable only for a small number of subsystems. The second\napproach utilizes a two-step iteration process, offering enhanced computational\nefficiency in scenarios with a large number of subsystems. Through numerical\nexperiments, the effectiveness of our model is validated, particularly in\nscenarios characterized by high failure rates and a large number of subsystems."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09265"
    ],
    "c_title":[
      "Properties of Path-Independent Choice Correspondences and Their\n  Applications to Efficient and Stable Matchings"
    ],
    "c_abstract":[
      "Choice correspondences are crucial in decision-making, especially when faced\nwith indifferences or ties. While tie-breaking can transform a choice\ncorrespondence into a choice function, it often introduces inefficiencies. This\npaper introduces a novel notion of path-independence (PI) for choice\ncorrespondences, extending the existing concept of PI for choice functions.\nIntuitively, a choice correspondence is PI if any consistent tie-breaking\nproduces a PI choice function. This new notion yields several important\nproperties. First, PI choice correspondences are rationalizabile, meaning they\ncan be represented as the maximization of a utility function. This extends a\ncore feature of PI in choice functions. Second, we demonstrate that the set of\nchoices selected by a PI choice correspondence for any subset forms a\ngeneralized matroid. This property reveals that PI choice correspondences\nexhibit a nice structural property. Third, we establish that choice\ncorrespondences rationalized by ordinally concave functions inherently satisfy\nthe PI condition. This aligns with recent findings that a choice function\nsatisfies PI if and only if it can be rationalized by an ordinally concave\nfunction. Building on these theoretical foundations, we explore stable and\nefficient matchings under PI choice correspondences. Specifically, we\ninvestigate constrained efficient matchings, which are efficient (for one side\nof the market) within the set of stable matchings. Under responsive choice\ncorrespondences, such matchings are characterized by cycles. However, this\ncycle-based characterization fails in more general settings. We demonstrate\nthat when the choice correspondence of each school satisfies both PI and\nmonotonicity conditions, a similar cycle-based characterization is restored.\nThese findings provide new insights into the matching theory and its practical\napplications."
    ],
    "c_categories":[
      [
        "cs.GT",
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-369",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07269"
    ],
    "b_title":[
      "The wreath matrix"
    ],
    "b_abstract":[
      "Let $k\\leq n$ be positive integers and $\\mathbb{Z}_{n}$ be the set of\nintegers modulo $n$. A conjecture of Baranyai from 1974 asks for a\ndecomposition of $k$-element subsets of $\\mathbb{Z}_{n}$ into particular\nfamilies of sets called \"wreaths\". We approach this conjecture from a new\nalgebraic angle by introducing the key object of this paper, the wreath matrix\n$M$. As our first result, we establish that Baranyai's conjecture is equivalent\nto the existence of a particular vector in the kernel of $M$. We then employ\nresults from representation theory to study $M$ and its spectrum in detail. In\nparticular, we find all eigenvalues of $M$ and their multiplicities, and\nidentify several families of vectors which lie in the kernel of $M$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.08476"
    ],
    "c_title":[
      "Non-magnetic Fractional Conductance in High Mobility InAs Quantum Point\n  Contacts"
    ],
    "c_abstract":[
      "In this letter, we report the magneto-electronic properties of high mobility\nInAs quantum point contacts grown on InP substrates. The 1D conductance reaches\na maximum value of 17 plateaus, quantized in units of 2e^2\/h, where e is the\nfundamental unit of charge and h is Planck's constant. The in-plane effective\ng-factor was estimated to be -10.9 +\/- 1.5 for subband N = 1 and -10.8 +\/- 1.6\nfor subband N = 2. Furthermore, a study of the non-magnetic fractional\nconductance states at 0.2 (e^2\/h) and 0.1(e2\/h is provided. While their origin\nremains under discussion, evidence suggests that they arise from strong\nelectron-electron interactions and momentum-conserving backscattering between\nelectrons in two distinct channels within the 1D region. This phenomenon may\nalso be interpreted as an entanglement between the two channel directions\nfacilitated by momentum-conserving backscattering."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-370",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09930"
    ],
    "b_title":[
      "Human Physical Interaction based on UAV Cooperative Payload\n  Transportation System using Adaptive Backstepping and FNTSMC"
    ],
    "b_abstract":[
      "This paper presents a nonlinear control strategy for an aerial cooperative\npayload transportation system consisting of two quadrotor UAVs rigidly\nconnected to a payload. The system includes human physical interaction\nfacilitated by an admittance control. The proposed control framework integrates\nan adaptive Backstepping controller for the position subsystem and a Fast\nNonsingular Terminal Sliding Mode Control (FNTSMC) for the attitude subsystem\nto ensure asymptotic stabilization. The admittance controller interprets the\ninteraction forces from the human operator, generating reference trajectories\nfor the position controller to ensure accurate tracking of the operator's\nguidance. The system aims to assist humans in payload transportation, providing\nboth stability and responsiveness. The robustness and effectiveness of the\nproposed control scheme in maintaining system stability and performance under\nvarious conditions are presented."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18014"
    ],
    "c_title":[
      "Search for doubly charmed dibaryons in baryon-baryon scattering"
    ],
    "c_abstract":[
      "We perform a systematical investigation of the doubly charmed dibaryon system\nwith quantum numbers $IJ=01$, and strangeness numbers $S=0$, $-2$ and $-4$ in\nthe framework of the chiral quark model. Two resonance states with strangeness\nnumbers $S=-2$ is obtained in the $\\Lambda\\Omega_{cc}$ scattering channel,\nwhich are $\\Xi_{cc}^{\\ast}\\Xi$ with resonance mass 5081 MeV and decay width 0.3\nMeV, and the $\\Xi_{c}\\Xi_{c}^{\\ast}$ state with the mass 5213 MeV and decay\nwidth 19.8 MeV, respectively. These two predicted charmed dibaryon candidates\nare worth searching for experimentally. Besides, we would like to emphasize\nthat the multi-channel coupling calculation is important to confirm the\nexistence of multiquark states. The coupling can shift the energy of the\nresonance, give the width to the resonance and even destroy the resonance.\nTherefore, to provide the necessary information for experiments to search for\nexotic hadron states, the coupling calculation between the bound channels and\nopen channels is indispensable."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-lat",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-371",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19454"
    ],
    "b_title":[
      "TransVDM: Motion-Constrained Video Diffusion Model for Transparent Video\n  Synthesis"
    ],
    "b_abstract":[
      "Recent developments in Video Diffusion Models (VDMs) have demonstrated\nremarkable capability to generate high-quality video content. Nonetheless, the\npotential of VDMs for creating transparent videos remains largely uncharted. In\nthis paper, we introduce TransVDM, the first diffusion-based model specifically\ndesigned for transparent video generation. TransVDM integrates a Transparent\nVariational Autoencoder (TVAE) and a pretrained UNet-based VDM, along with a\nnovel Alpha Motion Constraint Module (AMCM). The TVAE captures the alpha\nchannel transparency of video frames and encodes it into the latent space of\nthe VDMs, facilitating a seamless transition to transparent video diffusion\nmodels. To improve the detection of transparent areas, the AMCM integrates\nmotion constraints from the foreground within the VDM, helping to reduce\nundesirable artifacts. Moreover, we curate a dataset containing 250K\ntransparent frames for training. Experimental results demonstrate the\neffectiveness of our approach across various benchmarks."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14989"
    ],
    "c_title":[
      "Morphology and kinematics of the gas in M51: How interaction with\n  NGC5195 has moulded the structure of its arms"
    ],
    "c_abstract":[
      "The Whirlpool Galaxy is a well studied grand design galaxy with two major\nspiral arms, and a large satellite NGC 5195. The arms both show long uniform\nsections with perturbations ('kinks' or sharp turns) in specific regions.\nComparing the two arms shows a small radial offset between the main kinked\nregions. We analysed the morphology and also the velocity field in the disk of\nM51 using kinematic maps based on H$\\alpha$ and CO line emission. These sample\ncomplementary radial ranges, with the CO map covering the central zone and the\nH$\\alpha$ map extending to cover the outer zone. We looked for indicators of\ndensity wave resonance, zones where radial flows of gas in the disk plane\nreverse their sign. These were present in both velocity maps; their\ntwo-dimensional localization placed them along or closely parallel to the\nspiral arms, at a set of well defined galactocentric radii, and notably more\nconcentrated along the southern, stronger arm. The results can be well\ninterpreted quantitatively, using a numerical model of the interaction of M51\nand NGC5195 in which the satellite has made two relatively recent passes\nthrough the disk plane of M51. During the first pass the pair of dominant\nspiral arms was stimulated, and during the second pass the strong kinks in both\narms were formed at about the same time. The second interaction is particularly\nwell characterised, because the timescale corresponding to the production of\nthe kinks and the recovery of the original pitch angle is identical for the two\narms."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-372",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07691"
    ],
    "b_title":[
      "Time-resolved second-order autocorrelation function of parametric\n  downconversion"
    ],
    "b_abstract":[
      "We study a possibility of measuring the time-resolved second-order\nautocorrelation function of one of two beams generated in type-II parametric\ndownconversion by means of temporal magnification of this beam, bringing its\ncorrelation time from the picosecond to the nanosecond scale, which can be\nresolved by modern photodetectors. We show that such a measurement enables one\nto infer directly the degree of global coherence of that beam, which is linked\nby a simple relation to the number of modes characterizing the entanglement\nbetween the two generated beams. We illustrate the proposed method by an\nexample of photon pairs generated in a periodically poled KTP crystal with a\nsymmetric group velocity matching for various durations of the pump pulse,\nresulting in different numbers of modes. Our theoretical model also shows that\nthe magnified double-heralded autocorrelation function of one beam exhibits a\nlocal maximum around zero delay time, corresponding to photon bunching at a\nshort time scale."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05440"
    ],
    "c_title":[
      "A path description for $\\varepsilon$-characters of representations of\n  type $A$ restricted quantum loop algebras at roots of unity"
    ],
    "c_abstract":[
      "Fix $\\varepsilon^{2\\ell}=1$ with $\\ell \\geq 2$. In this paper, we show that\nall finite-dimensional simple modules of any restricted quantum loop algebra\n$U_{\\varepsilon}^{\\rm res}({L\\mathfrak{sl}_{n+1}})$ in a certain category can\nbe transformed into snake modules. We obtain an effective and concrete path\ndescription for $\\varepsilon$-characters of any simple module with highest\n$l$-weight of degree two and any Kirillov-Reshetikhin module of\n$U_{\\varepsilon}^{\\rm res}({L\\mathfrak{sl}_{n+1}})$. As an application of our\npath description, we obtain a necessary and sufficient condition for the tensor\nproduct of two fundamental representations of $U_{\\varepsilon}^{\\rm\nres}({L\\mathfrak{sl}_{n+1}})$ to be irreducible. Additionally, we obtain a\nnecessary condition for the tensor product of two or more fundamental\nrepresentations of $U_{\\varepsilon}^{\\rm res}({L\\mathfrak{sl}_{n+1}})$ to be\nirreducible."
    ],
    "c_categories":[
      [
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-373",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17466"
    ],
    "b_title":[
      "Global Hypoellipticity and Solvability with Loss of Derivatives on the\n  Torus"
    ],
    "b_abstract":[
      "This paper provides a complete characterization of global hypoellipticity and\nsolvability with loss of derivatives for Fourier multiplier operators on the\n$n$-dimensional torus. We establish necessary and sufficient conditions for\nthese properties and examine their connections with classical notions of global\nhypoellipticity and solvability, particularly in relation to the closedness of\nthe operator's range.\n  As an application, we explore the interplay between these properties and\nnumber theory in the context of differential operators on the two-torus.\nSpecifically, we prove that the loss of derivatives in the solvability of the\nvector field $\\partial_{x_1} - \\alpha \\partial_{x_2}$ is precisely determined\nby the well-known irrationality measure $\\mu(\\alpha)$ of its coefficient\n$\\alpha$. Furthermore, we analyze the wave operator $\\partial_{x_1}^2 - \\eta^2\n\\Delta_{\\mathbb{T}^n}$ and show how the loss of derivatives depends explicitly\non the parameter $\\eta > 0$."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.16609"
    ],
    "c_title":[
      "CowPilot: A Framework for Autonomous and Human-Agent Collaborative Web\n  Navigation"
    ],
    "c_abstract":[
      "While much work on web agents emphasizes the promise of autonomously\nperforming tasks on behalf of users, in reality, agents often fall short on\ncomplex tasks in real-world contexts and modeling user preference. This\npresents an opportunity for humans to collaborate with the agent and leverage\nthe agent's capabilities effectively. We propose CowPilot, a framework\nsupporting autonomous as well as human-agent collaborative web navigation, and\nevaluation across task success and task efficiency. CowPilot reduces the number\nof steps humans need to perform by allowing agents to propose next steps, while\nusers are able to pause, reject, or take alternative actions. During execution,\nusers can interleave their actions with the agent by overriding suggestions or\nresuming agent control when needed. We conducted case studies on five common\nwebsites and found that the human-agent collaborative mode achieves the highest\nsuccess rate of 95% while requiring humans to perform only 15.2% of the total\nsteps. Even with human interventions during task execution, the agent\nsuccessfully drives up to half of task success on its own. CowPilot can serve\nas a useful tool for data collection and agent evaluation across websites,\nwhich we believe will enable research in how users and agents can work\ntogether. Video demonstrations are available at\nhttps:\/\/oaishi.github.io\/cowpilot.html"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-374",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01039"
    ],
    "b_title":[
      "The Role of the Schwinger Effect in Superradiant Axion Lasers"
    ],
    "b_abstract":[
      "Superradiance can cause the axion cloud around a rotating black hole to reach\nextremely high densities, and the decay of these axions can produce a powerful\nlaser. The electric field of these lasers is strong enough that the Schwinger\neffect may become significant, resulting in the production of an\nelectron-positron plasma. We explore the dynamics between axion lasers and this\nelectron-positron plasma. While there are several mechanisms by which the\ninclusion of a plasma can impact the laser's behavior, the most significant of\nthese mechanisms is that the electron-positron plasma imparts an effective mass\non the photon. As the plasma frequency increases, axion decay becomes\nenergetically unfavorable, up to the point where the axion no longer decays\ninto photons, shutting off the laser. We find that the impact of the\nelectron-positron plasma on the dynamics of the system depend heavily on the\nparameters, specifically the axion mass $m_\\phi$ and the superradiant coupling\n$\\alpha$, and that we may divide parameter space into three regimes: the\nunenhanced, enhanced, and unstable regimes. In the unenhanced and enhanced\nregime, the system will eventually settle into an equilibrium state, emitting a\nlaser of constant luminosity while the number of axions remains constant. In\nthe unenhanced regime, this equilibrium state can be calculated while\nneglecting the effects of Schwinger production; in the enhanced regime, the\nequilibrium luminosity is slightly larger than what it would be without\nSchwinger production. In the unstable regime, the electron-positron plasma\nsuppresses axion decay to the point where the system is never able to reach\nequilibrium; instead, the axions continue to grow superradiantly. In all three\ncases, the production of superradiant axions will eventually cause the black\nhole to spin down to the point where superradiance ceases."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03218"
    ],
    "c_title":[
      "Data Dams: A Novel Framework for Regulating and Managing Data Flow in\n  Large-Scale Systems"
    ],
    "c_abstract":[
      "In the era of big data, managing dynamic data flows efficiently is crucial as\ntraditional storage models struggle with real-time regulation and risk\noverflow. This paper introduces Data Dams, a novel framework designed to\noptimize data inflow, storage, and outflow by dynamically adjusting flow rates\nto prevent congestion while maximizing resource utilization. Inspired by\nphysical dam mechanisms, the framework employs intelligent sluice controls and\npredictive analytics to regulate data flow based on system conditions such as\nbandwidth availability, processing capacity, and security constraints.\nSimulation results demonstrate that the Data Dam significantly reduces average\nstorage levels (371.68 vs. 426.27 units) and increases total outflow (7999.99\nvs. 7748.76 units) compared to static baseline models. By ensuring stable and\nadaptive outflow rates under fluctuating data loads, this approach enhances\nsystem efficiency, mitigates overflow risks, and outperforms existing static\nflow control strategies. The proposed framework presents a scalable solution\nfor dynamic data management in large-scale distributed systems, paving the way\nfor more resilient and efficient real-time processing architectures."
    ],
    "c_categories":[
      [
        "cs.DB",
        "cs.DC",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-375",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11955"
    ],
    "b_title":[
      "A generalization of Zwegers' multivariable $\\mu$-function"
    ],
    "b_abstract":[
      "We introduce a one parameter deformation of Zwegers' multivariable\n$\\mu$-function by applying iterations of the $q$-Borel summation method, which\nis also a multivariate analogue of the generalized $\\mu$-function introduced by\nthe authors. For this deformed multivariable $\\mu$-function, we give some\nformulas, for example, forward shift formula, translation and\n$\\mathfrak{S}_{N+1}$-symmetry. Further we mention modular formulas for the\nZwegers' original multivariable $\\mu$-function."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.14037"
    ],
    "c_title":[
      "Intra and Inter Parser-Prompted Transformers for Effective Image\n  Restoration"
    ],
    "c_abstract":[
      "We propose Intra and Inter Parser-Prompted Transformers (PPTformer) that\nexplore useful features from visual foundation models for image restoration.\nSpecifically, PPTformer contains two parts: an Image Restoration Network\n(IRNet) for restoring images from degraded observations and a Parser-Prompted\nFeature Generation Network (PPFGNet) for providing IRNet with reliable parser\ninformation to boost restoration. To enhance the integration of the parser\nwithin IRNet, we propose Intra Parser-Prompted Attention (IntraPPA) and Inter\nParser-Prompted Attention (InterPPA) to implicitly and explicitly learn useful\nparser features to facilitate restoration. The IntraPPA re-considers cross\nattention between parser and restoration features, enabling implicit perception\nof the parser from a long-range and intra-layer perspective. Conversely, the\nInterPPA initially fuses restoration features with those of the parser,\nfollowed by formulating these fused features within an attention mechanism to\nexplicitly perceive parser information. Further, we propose a parser-prompted\nfeed-forward network to guide restoration within pixel-wise gating modulation.\nExperimental results show that PPTformer achieves state-of-the-art performance\non image deraining, defocus deblurring, desnowing, and low-light enhancement."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-376",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14415"
    ],
    "b_title":[
      "Classes of simple derivations on polynomial rings $k[x_1,x_2, \\ldots\n  ,x_n]$"
    ],
    "b_abstract":[
      "Let $k$ be a field of characteristic zero. Let $m$ and $\\alpha$ be positive\nintegers. For $n\\geq 2$, let $R_n=k[x_1,x_2,\\dots,x_n]$ with the $k$-derivation\n$d_n$ given by\n$d_n=(1-x_1x_2^{\\alpha})\\partial_{x_1}+x_1^m\\partial_{x_2}+x_2\\partial_{x_3}+\\dots+x_{n-1}\\partial_{x_n}$.\nWe prove that for integers $m\\geq 2$ and $\\alpha \\geq 1$, $d_n$ is a simple\nderivation on $R_n$ and $d_n(R_n)$ contains no units. This generalizes a result\nof D. A. Jordan. We also show that the isotropy group of $d_n$ is conjugate to\na subgroup of translations."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.02725"
    ],
    "c_title":[
      "A Joint Visual Compression and Perception Framework for Neuralmorphic\n  Spiking Camera"
    ],
    "c_abstract":[
      "The advent of neuralmorphic spike cameras has garnered significant attention\nfor their ability to capture continuous motion with unparalleled temporal\nresolution.However, this imaging attribute necessitates considerable resources\nfor binary spike data storage and transmission.In light of compression and\nspike-driven intelligent applications, we present the notion of Spike Coding\nfor Intelligence (SCI), wherein spike sequences are compressed and optimized\nfor both bit-rate and task performance.Drawing inspiration from the mammalian\nvision system, we propose a dual-pathway architecture for separate processing\nof spatial semantics and motion information, which is then merged to produce\nfeatures for compression.A refinement scheme is also introduced to ensure\nconsistency between decoded features and motion vectors.We further propose a\ntemporal regression approach that integrates various motion dynamics,\ncapitalizing on the advancements in warping and deformation\nsimultaneously.Comprehensive experiments demonstrate our scheme achieves\nstate-of-the-art (SOTA) performance for spike compression and analysis.We\nachieve an average 17.25% BD-rate reduction compared to SOTA codecs and a 4.3%\naccuracy improvement over SpiReco for spike-based classification, with 88.26%\ncomplexity reduction and 42.41% inference time saving on the encoding side."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-377",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15350"
    ],
    "b_title":[
      "Connecting a Magnetized Disk to a Convective Low-mass Protostar: A\n  Global Three-dimensional Model of Boundary Layer Accretion"
    ],
    "b_abstract":[
      "In the early stages of star formation, boundary layer accretion, where\nprotostars accrete material from disks extending down to their surfaces, plays\na crucial role. Understanding how a magneto-rotational-instability (MRI)-active\ndisk connects to a protostar's surface remains a significant challenge. To\ninvestigate the mechanisms of mass and angular momentum transfer, we develop a\nglobal, three-dimensional magnetohydrodynamic model of boundary layer accretion\naround a magnetized, convective low-mass protostar. Our results reveal that\nangular momentum transport mechanisms transition significantly from the outer\nMRI-active disk to the protostellar surface. Various mechanisms--MRI, spiral\nshocks, coronal accretion, jets, and disk winds--contribute to angular momentum\ntransfer, resulting in three distinct disk structures: (1) the MRI-active disk,\n(2) the transition layer, and (3) the boundary layer. The simulated protostar\nis strongly magnetized due to the accumulation of the disk fields, wrapping by\ndisk toroidal fields, and stellar dynamo activity. Magnetic concentrations\nanalogous to starspots form on the protostar and interact with the rotating\ndisk gas to generate spiral shocks. These shocks play a key role in driving\naccretion. These findings demonstrate the necessity of global MHD models for a\ncomprehensive understanding of angular momentum transport. Additionally, we\nidentify explosive events triggered by magnetic reconnection in both the\nprotostar and the disk atmosphere. We also find decretion flows in the disk\nmidplane, which may be important for the radial transport of refractory\nmaterials, such as Calcium-Aluminium-rich Inclusions (CAIs) precursor gas, to\nthe outer disk."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03712"
    ],
    "c_title":[
      "SDEs with subcritical Lebesgue--H\\\"{o}lder drifts and driven by\n  $\\alpha$-stable processes"
    ],
    "c_abstract":[
      "We obtain the unique weak and strong solvability for time inhomogeneous\nstochastic differential equations with the drifts in subcritical\nLebesgue--H\\\"{o}lder spaces $L^p([0,T];{\\mathcal C}_b^{\\beta}({\\mathbb\nR}^d;{\\mathbb R}^d))$ and driven by $\\alpha$-stable processes for $\\alpha\\in\n(0,2)$. The weak well-posedness is derived for $\\beta\\in (0,1)$,\n$\\alpha+\\beta>1$ and $p>\\alpha\/(\\alpha+\\beta-1)$ through the Prohorov theorem,\nSkorohod representation and the regularity estimates of solutions for a class\nof fractional parabolic partial differential equations. The pathwise uniqueness\nand Davie's type uniqueness are proved for $\\beta>1- \\alpha\/2$ by using\nIt\\^{o}--Tanaka's trick. Moreover, we give a counterexample to the pathwise\nuniqueness for the supercritical Lebesgue--H\\\"{o}lder drifts to explain the\npresent result is sharp."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-378",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08630"
    ],
    "b_title":[
      "On principal eigenvalues of linear time-periodic parabolic systems:\n  symmetric mutation case"
    ],
    "b_abstract":[
      "The paper is concerned with the effect of the spatio-temporal heterogeneity\non the principal eigenvalue of some linear time-periodic parabolic system.\nVarious asymptotic behaviors of the principal eigenvalue and its monotonicity,\nas a function of the diffusion rate and frequency, are first derived. In\nparticular, some singular behaviors of the principal eigenvalues are observed\nwhen both diffusion rate and frequency approach zero, with some scalar\ntime-periodic Hamilton-Jacobi equation as the limiting equation. Furthermore,\nwe completely classify the topological structures of the level sets for the\nprincipal eigenvalues in the plane of frequency and diffusion rate. Our results\nnot only generalize most of the findings in [S. Liu and Y. Lou, J. Funct.\nAnal., 282 (2022), 109338] for scalar periodic-parabolic operators, but also\nreveal more rich global information, for time-periodic parabolic systems, on\nthe dependence of the principal eigenvalues upon the spatio-temporal\nheterogeneity."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.06756"
    ],
    "c_title":[
      "Sphere Precoding for Robust Near-Field Communications"
    ],
    "c_abstract":[
      "Near-field communication with large antenna arrays promises significant\nbeamforming and multiplexing gains. These communication links, however, are\nvery sensitive to user mobility as any small change in the user position may\nsuddenly drop the signal power. This leads to critical challenges for the\nrobustness of these near-field communication systems. In this paper, we propose\n\\textit{sphere precoding}, which is a robust precoding design to address user\nmobility in near-field communications. To gain insights into the spatial\ncorrelation of near-field channels, we extend the one-ring channel model to\nwhat we call one-sphere channel model and derive the channel covariance\nconsidering user mobility. Based on the one-sphere channel model, a robust\nprecoding design problem is defined to optimize the minimum\nsignal-to-interference-plus-noise ratio (SINR) satisfaction probability among\nmobile users. By utilizing the eigen structure of channel covariance, we\nfurther design a relaxed convex problem to approximate the solution of the\noriginal non-convex problem. The low-complexity solution effectively shapes a\nsphere that maintains the signal power for the target user and also nulls its\ninterference within spheres around the other users. Simulation results\nhighlight the efficacy of the proposed solution in achieving robust precoding\nyet high achievable rates in near-field communication systems."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-379",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14812"
    ],
    "b_title":[
      "Byzantine Game Theory: Sun Tzus Boxes"
    ],
    "b_abstract":[
      "We introduce the Byzantine Selection Problem, living at the intersection of\ngame theory and fault-tolerant distributed computing. Here, an event organizer\nis presented with a group of $n$ agents, and wants to select $\\ell < n$ of them\nto form a team. For these purposes, each agent $i$ self-reports a positive\nskill value $v_i$, and a team's value is the sum of its members' skill values.\nIdeally, the value of the team should be as large as possible, which can be\neasily achieved by selecting agents with the highest $\\ell$ skill values.\nHowever, an unknown subset of at most $t < n$ agents are byzantine and hence\nnot to be trusted, rendering their true skill values as $0$. In the spirit of\nthe distributed computing literature, the identity of the byzantine agents is\nnot random but instead chosen by an adversary aiming to minimize the value of\nthe chosen team. Can we still select a team with good guarantees in this\nadversarial setting? As it turns out, deterministically, it remains optimal to\nselect agents with the highest $\\ell$ values. Yet, if $t \\geq \\ell$, the\nadversary can choose to make all selected agents byzantine, leading to a team\nof value zero. To provide meaningful guarantees, one hence needs to allow for\nrandomization, in which case the expected value of the selected team needs to\nbe maximized, assuming again that the adversary plays to minimize it. For this\ncase, we provide linear-time randomized algorithms that maximize the expected\nvalue of the selected team."
    ],
    "b_categories":[
      [
        "cs.DC",
        "cs.DS",
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.04917"
    ],
    "c_title":[
      "Peculiar radio-bright behaviour of the Galactic black hole transient 4U\n  1543-47 in the 2021-2023 outburst"
    ],
    "c_abstract":[
      "Correlated behaviours between the radio emission and the X-ray emission in\nGalactic black hole X-ray binaries (BH XRBs) in the X-ray hard state are\ncrucial to the understanding of disc-jet coupling of accreting black holes. The\nBH transient 4U 1543-47 went into outburst in 2021 following ~19 years of\nquiescence. We followed it up with ~weekly cadence with MeerKAT for about one\nyear and a half until it faded into quiescence. Multi-epoch quasi-simultaneous\nMeerKAT and X-ray observations allowed us to trace the compact jet emission and\nits X-ray emission. In its hard spectral state across three orders of magnitude\nof X-ray luminosities above ~10$^{34}$ ergs\/s, we found the correlation between\nradio and X-ray emission had a power-law index of 0.82$\\pm$0.09, steeper than\nthe canonical value of ~0.6 for BH XRBs. In addition, the radio vs. X-ray\ncorrelation shows a large range of the power-law normalization, with the\nmaximum significantly larger than that obtained for most BH XRBs, indicating it\ncan be particularly radio-bright and variable in the X-ray binary sample. The\nradio emission is unlikely diluted by discrete jet components. The observed\npeculiar radio-bright and variable behaviours provide the evidence for the\nrelativistic effects of a variable Lorentz factor in the range between 1 and ~2\nof the compact jet."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-380",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04400"
    ],
    "b_title":[
      "Adaptive Prototype Knowledge Transfer for Federated Learning with Mixed\n  Modalities and Heterogeneous Tasks"
    ],
    "b_abstract":[
      "Multimodal Federated Learning (MFL) enables multiple clients to\ncollaboratively train models on multimodal data while ensuring clients'\nprivacy. However, modality and task heterogeneity hinder clients from learning\na unified representation, weakening local model generalization, especially in\nMFL with mixed modalities where only some clients have multimodal data. In this\nwork, we propose an Adaptive prototype-based Multimodal Federated Learning\n(AproMFL) framework for mixed modalities and heterogeneous tasks to address the\naforementioned issues. Our AproMFL transfers knowledge through\nadaptively-constructed prototypes without a prior public dataset. Clients\nadaptively select prototype construction methods in line with tasks; server\nconverts client prototypes into unified multimodal prototypes and aggregates\nthem to form global prototypes, avoid clients keeping unified labels. We divide\nthe model into various modules and only aggregate mapping modules to reduce\ncommunication and computation overhead. To address aggregation issues in\nheterogeneity, we develop a client relationship graph-based scheme to\ndynamically adjust aggregation weights. Extensive experiments on representative\ndatasets evidence effectiveness of AproMFL."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.MM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15882"
    ],
    "c_title":[
      "Thermoelectric properties of magic angle twisted bilayer\n  graphene-superconductor hetero-junction: effect of valley polarization and\n  trigonal warping"
    ],
    "c_abstract":[
      "We theoretically investigate the thermoelectric properties (electronic\ncontribution) of a normal-superconductor (NS) hybrid junction, where the normal\nregion consists of magic-angle twisted bilayer graphene (MATBG). The\nsuperconducting region is characterized by a common $s$-wave superconductor\nclosely proximitized to the MATBG. We compute various thermoelectric\ncoefficients, including thermal conductance, thermopower, and the figure of\nmerit ($zT$), using the scattering matrix formalism. These results are further\nsupported by calculations based on a lattice-regularized version of the\neffective Hamiltonian. Additionally, we explore the impact of trigonal warping\nand valley polarization on the thermoelectric coefficients. Notably, we find a\nsignificant variation in $zT$ as a function of these parameters, reaching\nvalues as high as 2.5. Interestingly, we observe a violation of the\nWiedemann-Franz law near the charge neutrality point with the superconducting\ncorrelation, indicating that MATBG electrons behave as slow Dirac fermions in\nthis regime. This observation is further confirmed by the damped oscillatory\nbehavior of the thermal conductance as a function of the barrier strength when\nan insulating barrier is modelled at the interface of the NS junction. Beyond\ntheoretical insights, our findings suggest new possibilities for thermoelectric\napplications using MATBG based NS junctions."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-381",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09028"
    ],
    "b_title":[
      "Degradation-based Energy Management for Microgrids in the Presence of\n  Energy Storage Elements"
    ],
    "b_abstract":[
      "Integration of Inverter-based Resources (IBRs) such as solar-powered plants\nwhich lack the intrinsic characteristics such as the inertial response of the\ntraditional synchronous-generator (SG) based sources presents a new challenge\nin the form of analyzing the grid stability under their presence. For example,\nsolar power is available for approximately from 9 AM-5 PM. However, the result\nof the rise in power consumption after 6 PM and the reverting back to the\nnon-renewable source of power generation during that period puts immense stress\non the grid, testing the ramp limitations of the SGs. Failure to meet the\nrequired power demand due to SG ramp limitations leads to failure of the power\ngrid and other catastrophes. Numerous mitigation techniques exist in order to\naddress the ramping issues with adding the energy storage elements (ESE) to the\ngrid being one. ESEs have higher ramping capabilities compared to the\ntraditional SGs. Also, the ESEs can store the energy and supply it to the grid\nwhen required making them extremely responsive to high ramp situations.\nHowever, the rate of degradation of the ESEs is faster than the SGs. This\nraises an important issue of addressing the degradation of the ESEs while\nmeeting the required power demand objectives and constraints. This work\nproposes a battery degradation-aware model predictive energy management\nstrategy and it is tested via a numerical simulation on multiple physical\nsystems such as Shipboard Power Systems (SPS). Moreover, the risk arising due\nto the fault in the IBR is also studied by means of a numerical simulation.\nOverall, the goal of this study is to make the existing power grid more robust,\nresilient, and risk-free from component degradation and eventual failures."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.12028"
    ],
    "c_title":[
      "Active charge and discharge of a capacitor: scaling solution and energy\n  optimization"
    ],
    "c_abstract":[
      "Capacitors are ubiquitous in electronic and electrical devices. In this\narticle, we study -- both theoretically and experimentally -- the charging and\ndischarging of capacitors using active control of a voltage source. The energy\nof these processes is analyzed in terms of work and heat. We show how to\napproach the quasistatic regime by slowing down the charging or discharging\nprocesses. Conversely, we study the price to be paid in terms of Joule heat\nwhen we speed up these processes. Finally, we develop optimal processes that\nminimize energy consumption for a finite charging time. Our work combines\nfundamental concepts from thermodynamics, classical mechanics and electrical\ncircuits, thus blurring the artificial frontiers at the undergraduate level\nbetween these disciplines. Also, it provides a simple example of a prominent\nproblem in current science, the optimization of energy resources. Moreover, our\nstudy lends itself well to an experimental project in the classroom, involving\ncomputer control of a voltage source, data acquisition, and processing."
    ],
    "c_categories":[
      [
        "physics.class-ph",
        "physics.ed-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-382",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02531"
    ],
    "b_title":[
      "Deep Linear Network Training Dynamics from Random Initialization: Data,\n  Width, Depth, and Hyperparameter Transfer"
    ],
    "b_abstract":[
      "We theoretically characterize gradient descent dynamics in deep linear\nnetworks trained at large width from random initialization and on large\nquantities of random data. Our theory captures the ``wider is better\" effect of\nmean-field\/maximum-update parameterized networks as well as hyperparameter\ntransfer effects, which can be contrasted with the neural-tangent\nparameterization where optimal learning rates shift with model width. We\nprovide asymptotic descriptions of both non-residual and residual neural\nnetworks, the latter of which enables an infinite depth limit when branches are\nscaled as $1\/\\sqrt{\\text{depth}}$. We also compare training with one-pass\nstochastic gradient descent to the dynamics when training data are repeated at\neach iteration. Lastly, we show that this model recovers the accelerated power\nlaw training dynamics for power law structured data in the rich regime observed\nin recent works."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.10941"
    ],
    "c_title":[
      "Compact Turnkey Soliton Microcombs at Microwave Rates via Wafer-Scale\n  Fabrication"
    ],
    "c_abstract":[
      "Soliton microcombs generated in nonlinear microresonators facilitate the\nphotonic integration of timing, frequency synthesis, and astronomical\ncalibration functionalities. For these applications, low-repetition-rate\nsoliton microcombs are essential as they establish a coherent link between\noptical and microwave signals. However, the required pump power typically\nscales with the inverse of the repetition rate, and the device footprint scales\nwith the inverse of square of the repetition rate, rendering\nlow-repetition-rate soliton microcombs challenging to integrate within photonic\ncircuits. This study designs and fabricates silicon nitride microresonators on\n4-inch wafers with highly compact form factors. The resonator geometries are\nengineered from ring to finger and spiral shapes to enhance integration density\nwhile attaining quality factors over 10^7. Driven directly by an integrated\nlaser, soliton microcombs with repetition rates below 10 GHz are demonstrated\nvia turnkey initiation. The phase noise performance of the synthesized\nmicrowave signals reaches -130 dBc\/Hz at 100 kHz offset frequency for 10 GHz\ncarrier frequencies. This work enables the high-density integration of soliton\nmicrocombs for chip-based microwave photonics and spectroscopy applications."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-383",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14277"
    ],
    "b_title":[
      "Timing and spectral analysis of GK Persei during the 2010 dwarf nova\n  outburst"
    ],
    "b_abstract":[
      "GK Persei, an old nova and intermediate polar (IP), exhibited a dwarf nova\n(DN) outburst in 2010. This outburst was extensively observed by the Neil\nGehrels Swift Observatory, beginning 1.95 days after the eruption and\ncontinuing until 13.9 days before the maximum of the outburst in the optical.\nIn this paper, we present timing and spectral analyses, comparing the results\nwith those of other outbursts. We confirm the spin modulation in the 2 $-$ 10\nkeV X-ray range with a period of $P_{\\rm WD} = 351.325(9)$ s. Additionally, we\ndetected spin modulation in the 0.3 $-$ 2 keV band during the second half of\nthe observations, a feature not seen in the 2015 and 2018 outbursts. This\nfinding suggests that the soft X-ray emission in GK Per may originate partly\nnear the magnetic poles and partly from a wind or circumstellar material."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.04839"
    ],
    "c_title":[
      "Definitions and examples of algeebraic Morava K-theories"
    ],
    "c_abstract":[
      "Algebraic Morava K-theories are defined by Sechin,Vishik and others as\nquotients of algebraic cobordisms. On the other hand, the author had defined\nthem as some (two degrees) cohomology theories. In this paper, we compare these\ntheories."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-384",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17202"
    ],
    "b_title":[
      "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators"
    ],
    "b_abstract":[
      "An ideal multimodal agent should be aware of the quality of its input\nmodalities. Recent advances have enabled large language models (LLMs) to\nincorporate auditory systems for handling various speech-related tasks.\nHowever, most audio LLMs remain unaware of the quality of the speech they\nprocess. This limitation arises because speech quality evaluation is typically\nexcluded from multi-task training due to the lack of suitable datasets. To\naddress this, we introduce the first natural language-based speech evaluation\ncorpus, generated from authentic human ratings. In addition to the overall Mean\nOpinion Score (MOS), this corpus offers detailed analysis across multiple\ndimensions and identifies causes of quality degradation. It also enables\ndescriptive comparisons between two speech samples (A\/B tests) with human-like\njudgment. Leveraging this corpus, we propose an alignment approach with LLM\ndistillation (ALLD) to guide the audio LLM in extracting relevant information\nfrom raw speech and generating meaningful responses. Experimental results\ndemonstrate that ALLD outperforms the previous state-of-the-art regression\nmodel in MOS prediction, with a mean square error of 0.17 and an A\/B test\naccuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of\n25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific\nmodels. This work advances the comprehensive perception of speech signals by\naudio LLMs, contributing to the development of real-world auditory and sensory\nintelligent agents."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00650"
    ],
    "c_title":[
      "The Hidden Cost of Waiting for Accurate Predictions"
    ],
    "c_abstract":[
      "Algorithmic predictions are increasingly informing societal resource\nallocations by identifying individuals for targeting. Policymakers often build\nthese systems with the assumption that by gathering more observations on\nindividuals, they can improve predictive accuracy and, consequently, allocation\nefficiency. An overlooked yet consequential aspect of prediction-driven\nallocations is that of timing. The planner has to trade off relying on earlier\nand potentially noisier predictions to intervene before individuals experience\nundesirable outcomes, or they may wait to gather more observations to make more\nprecise allocations. We examine this tension using a simple mathematical model,\nwhere the planner collects observations on individuals to improve predictions\nover time. We analyze both the ranking induced by these predictions and optimal\nresource allocation. We show that though individual prediction accuracy\nimproves over time, counter-intuitively, the average ranking loss can worsen.\nAs a result, the planner's ability to improve social welfare can decline. We\nidentify inequality as a driving factor behind this phenomenon. Our findings\nprovide a nuanced perspective and challenge the conventional wisdom that it is\npreferable to wait for more accurate predictions to ensure the most efficient\nallocations."
    ],
    "c_categories":[
      [
        "cs.LG",
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-385",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03665"
    ],
    "b_title":[
      "Lithographically-controlled liquid metal diffusion in graphene:\n  Fabrication and magneto-transport signatures of superconductivity"
    ],
    "b_abstract":[
      "Metal intercalation in epitaxial graphene enables the emergence of\nproximity-induced superconductivity and modified quantum transport properties.\nHowever, systematic transport studies of intercalated graphene have been\nhindered by challenges in device fabrication, including processing-induced\ndeintercalation and instability under standard lithographic techniques. Here,\nwe introduce a lithographically controlled intercalation approach that enables\nthe scalable fabrication of gallium-intercalated quasi-freestanding bilayer\ngraphene (QFBLG) Hall bar devices. By integrating lithographic structuring with\nsubsequent intercalation through dedicated intercalation channels, this method\nensures precise control over metal incorporation while preserving device\nintegrity. Magneto-transport measurements reveal superconductivity with a\ncritical temperature Tc,onset ~ 3.5 K and the occurrence of a transverse\nresistance, including both symmetric and antisymmetric field components, which\nis attributed to the symmetric-in-field component to non-uniform currents.\nThese results establish an advanced fabrication method for intercalated\ngraphene devices, providing access to systematic investigations of confined 2D\nsuperconductivity and emergent electronic phases in van der Waals\nheterostructures."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.20764"
    ],
    "c_title":[
      "Visual Attention Exploration in Vision-Based Mamba Models"
    ],
    "c_abstract":[
      "State space models (SSMs) have emerged as an efficient alternative to\ntransformer-based models, offering linear complexity that scales better than\ntransformers. One of the latest advances in SSMs, Mamba, introduces a selective\nscan mechanism that assigns trainable weights to input tokens, effectively\nmimicking the attention mechanism. Mamba has also been successfully extended to\nthe vision domain by decomposing 2D images into smaller patches and arranging\nthem as 1D sequences. However, it remains unclear how these patches interact\nwith (or attend to) each other in relation to their original 2D spatial\nlocation. Additionally, the order used to arrange the patches into a sequence\nalso significantly impacts their attention distribution. To better understand\nthe attention between patches and explore the attention patterns, we introduce\na visual analytics tool specifically designed for vision-based Mamba models.\nThis tool enables a deeper understanding of how attention is distributed across\npatches in different Mamba blocks and how it evolves throughout a Mamba model.\nUsing the tool, we also investigate the impact of different patch-ordering\nstrategies on the learned attention, offering further insights into the model's\nbehavior."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-386",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16196"
    ],
    "b_title":[
      "Expediting quantum state transfer through long-range extended XY model"
    ],
    "b_abstract":[
      "Going beyond short-range interactions, we explore the role of long-range\ninteractions in the extended XY model for transferring quantum states through\nevolution. In particular, employing a spin-1\/2 chain with interactions decaying\nas a power law, we demonstrate that long-range interactions significantly\nenhance the efficiency of a quantum state transfer (QST) protocol, reducing the\nminimum time required to achieve fidelity beyond the classical limit. Our study\nidentifies the long-range regime as providing an optimal balance between\ninteraction range and transfer efficiency, outperforming the protocol with the\nshort-range interacting model. Our detailed analysis reveals the impact of\nsystem parameters, such as anisotropy, magnetic field strength, and\ncoordination number, on QST dynamics. Specifically, we find that intermediate\ncoordination numbers lead to a faster and more reliable state transfer, while\nextreme values diminish performance. Further, we exhibit that the presence of\nlong-range interactions also improves the achievable fidelity, mitigating its\ndecline associated with increasing system-size."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.13125"
    ],
    "c_title":[
      "RuozhiBench: Evaluating LLMs with Logical Fallacies and Misleading\n  Premises"
    ],
    "c_abstract":[
      "Recent advances in large language models (LLMs) have shown that they can\nanswer questions requiring complex reasoning. However, their ability to\nidentify and respond to text containing logical fallacies or deliberately\nmisleading premises remains less studied. To address this gap, we introduce\nRuozhiBench, a bilingual dataset comprising 677 carefully curated questions\nthat contain various forms of deceptive reasoning, meticulously crafted through\nextensive human effort and expert review. In a comprehensive evaluation of 17\nLLMs from 5 Series over RuozhiBench using both open-ended and two-choice\nformats, we conduct extensive analyses on evaluation protocols and result\npatterns. Despite their high scores on conventional benchmarks, these models\nshowed limited ability to detect and reason correctly about logical fallacies,\nwith even the best-performing model, Claude-3-haiku, achieving only 62%\naccuracy compared to the human of more than 90%."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-387",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15917"
    ],
    "b_title":[
      "RIS Assisted Wireless Communication: Advanced Modeling, Simulation, and\n  Analytical Insights"
    ],
    "b_abstract":[
      "This article presents a novel perspective to model and simulate\nreconfigurable intelligent surface (RIS)-assisted communication systems.\nTraditional methods in antenna design often rely on array method to simulate,\nwhereas communication system modeling tends to idealize antenna behavior.\nNeither approach sufficiently captures the detailed characteristics of\nRIS-assisted communication. To address this limitation, we propose a\ncomprehensive simulation framework that jointly models RIS antenna design and\nthe communication process. This framework simulates the entire communication\npipeline, encompassing signal generation, modulation, propagation, RIS-based\nradiation, signal reception, alignment, demodulation, decision, and processing.\nUsing a QPSK-modulated signal for validation, we analyze system performance and\ninvestigate the relationship between bit error rate (BER), aperture fill time,\narray size, and baseband symbol frequency. The results indicate that larger\narray sizes and higher baseband symbol frequencies exacerbate aperture fill\ntime effects, leading to increased BER. Furthermore, we examine BER variation\nwith respect to signal-to-noise ratio (SNR) and propose an optimal\nmatching-based alignment algorithm, which significantly reduces BER compared to\nconventional pilot-based alignment methods. This work demonstrates the entire\nprocess of RIS communication, and reveals the source of bit errors, which\nprovides valuable insights into the design and performance optimization of\nRIS-assisted communication systems."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.10048"
    ],
    "c_title":[
      "Virtual Nodes Improve Long-term Traffic Prediction"
    ],
    "c_abstract":[
      "Effective traffic prediction is a cornerstone of intelligent transportation\nsystems, enabling precise forecasts of traffic flow, speed, and congestion.\nWhile traditional spatio-temporal graph neural networks (ST-GNNs) have achieved\nnotable success in short-term traffic forecasting, their performance in\nlong-term predictions remains limited. This challenge arises from\nover-squashing problem, where bottlenecks and limited receptive fields restrict\ninformation flow and hinder the modeling of global dependencies. To address\nthese challenges, this study introduces a novel framework that incorporates\nvirtual nodes, which are additional nodes added to the graph and connected to\nexisting nodes, in order to aggregate information across the entire graph\nwithin a single GNN layer. Our proposed model incorporates virtual nodes by\nconstructing a semi-adaptive adjacency matrix. This matrix integrates\ndistance-based and adaptive adjacency matrices, allowing the model to leverage\ngeographical information while also learning task-specific features from data.\nExperimental results demonstrate that the inclusion of virtual nodes\nsignificantly enhances long-term prediction accuracy while also improving\nlayer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes\nalso offer enhanced explainability by focusing on key intersections and\nhigh-traffic areas, as shown by the visualization of their adjacency matrix\nweights on road network heat maps. Our advanced approach enhances the\nunderstanding and management of urban traffic systems, making it particularly\nwell-suited for real-world applications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-388",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18743"
    ],
    "b_title":[
      "Generation and Teleportation of three and four particle W state"
    ],
    "b_abstract":[
      "In this paper, we introduced circuits for three- and four-particle quantum\nsystems to generate W states with any arbitrary coefficients and phases.\nSubsequently, each qubit was transmitted separately through a four-qubit\nentangled channel. Before transmission, the sender performed pre-processing on\ntheir qubits to minimize the resources required for transmission. Additionally,\nthe receiver applied post-processing using the ancilla qubit(s) to recover the\nfinal states. To further improve efficiency, it is preferable to implement the\nprotocol in a bidirectional manner, as this allows the unknown qubits initially\nheld by the users to be utilized ancilla qubit(s). Finally, we compared our\nprotocol with similar works and validated the correctness of the protocol by\nsimulating it using Qiskit, a tool provided by IBM."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.15875"
    ],
    "c_title":[
      "LCTG Bench: LLM Controlled Text Generation Benchmark"
    ],
    "c_abstract":[
      "The rise of large language models (LLMs) has led to more diverse and\nhigher-quality machine-generated text. However, their high expressive power\nmakes it difficult to control outputs based on specific business instructions.\nIn response, benchmarks focusing on the controllability of LLMs have been\ndeveloped, but several issues remain: (1) They primarily cover major languages\nlike English and Chinese, neglecting low-resource languages like Japanese; (2)\nCurrent benchmarks employ task-specific evaluation metrics, lacking a unified\nframework for selecting models based on controllability across different use\ncases. To address these challenges, this research introduces LCTG Bench, the\nfirst Japanese benchmark for evaluating the controllability of LLMs. LCTG Bench\nprovides a unified framework for assessing control performance, enabling users\nto select the most suitable model for their use cases based on controllability.\nBy evaluating nine diverse Japanese-specific and multilingual LLMs like GPT-4,\nwe highlight the current state and challenges of controllability in Japanese\nLLMs and reveal the significant gap between multilingual models and\nJapanese-specific models."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-389",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18678"
    ],
    "b_title":[
      "NullSwap: Proactive Identity Cloaking Against Deepfake Face Swapping"
    ],
    "b_abstract":[
      "Suffering from performance bottlenecks in passively detecting high-quality\nDeepfake images due to the advancement of generative models, proactive\nperturbations offer a promising approach to disabling Deepfake manipulations by\ninserting signals into benign images. However, existing proactive perturbation\napproaches remain unsatisfactory in several aspects: 1) visual degradation due\nto direct element-wise addition; 2) limited effectiveness against face swapping\nmanipulation; 3) unavoidable reliance on white- and grey-box settings to\ninvolve generative models during training. In this study, we analyze the\nessence of Deepfake face swapping and argue the necessity of protecting source\nidentities rather than target images, and we propose NullSwap, a novel\nproactive defense approach that cloaks source image identities and nullifies\nface swapping under a pure black-box scenario. We design an Identity Extraction\nmodule to obtain facial identity features from the source image, while a\nPerturbation Block is then devised to generate identity-guided perturbations\naccordingly. Meanwhile, a Feature Block extracts shallow-level image features,\nwhich are then fused with the perturbation in the Cloaking Block for image\nreconstruction. Furthermore, to ensure adaptability across different identity\nextractors in face swapping algorithms, we propose Dynamic Loss Weighting to\nadaptively balance identity losses. Experiments demonstrate the outstanding\nability of our approach to fool various identity recognition models,\noutperforming state-of-the-art proactive perturbations in preventing face\nswapping models from generating images with correct source identities."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06089"
    ],
    "c_title":[
      "On the Computability of Multiclass PAC Learning"
    ],
    "c_abstract":[
      "We study the problem of computable multiclass learnability within the\nProbably Approximately Correct (PAC) learning framework of Valiant (1984). In\nthe recently introduced computable PAC (CPAC) learning framework of Agarwal et\nal. (2020), both learners and the functions they output are required to be\ncomputable. We focus on the case of finite label space and start by proposing a\ncomputable version of the Natarajan dimension and showing that it characterizes\nCPAC learnability in this setting. We further generalize this result by\nestablishing a meta-characterization of CPAC learnability for a certain family\nof dimensions: computable distinguishers. Distinguishers were defined by\nBen-David et al. (1992) as a certain family of embeddings of the label space,\nwith each embedding giving rise to a dimension. It was shown that the\nfiniteness of each such dimension characterizes multiclass PAC learnability for\nfinite label space in the non-computable setting. We show that the\ncorresponding computable dimensions for distinguishers characterize CPAC\nlearning. We conclude our analysis by proving that the DS dimension, which\ncharacterizes PAC learnability for infinite label space, cannot be expressed as\na distinguisher (even in the case of finite label space)."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-390",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17472"
    ],
    "b_title":[
      "Cosmic rays, gas and dust in the Central Molecular Zone I -- $X_{CO}$\n  factors, cosmic-ray densities and dust opacities"
    ],
    "b_abstract":[
      "Our goal is to estimate the total gas mass in the direction of the Central\nMolecular Zone (CMZ), quantify the various uncertainties associated, and\ndiscuss the implications for the estimates of CR energy densities and dust\nopacities. The $H_{\\rm{I}}$ 21 cm line and the carbon monoxide isotopes\n($^{12}\\rm{CO}$, $^{13}\\rm{CO}$ and $\\rm{C}^{18}\\rm{O}$) line emission maps are\nused to derive the total gas column density. The gas in the CMZ is separated\nfrom the disk contribution in position and velocity thanks to its different\nproperties in term of velocity dispersion and brightness ratio of CO isotopes.\nThe variations of the $X_{\\rm{CO}}$ factors are modelled relying on both\ntheoretical trends from simulations and empirical corrections. We use the new\ngas column density estimated together with gamma-ray and dust emission\nmeasurements to derive the CR energy density and dust opacities, respectively.\nThe $X_{\\rm{CO}}$ values in the CMZ range from $(0.32 - 1.37) \\ \\times$\n$10^{20}$ cm$^{-2}$ K$^{-1}$ km$^{-1}$ s, with a distribution that is highly\nasymmetric and skewed. The median value is $ \\rm{\\overline{X}_{CO}^{CMZ}} =\n0.39 \\ \\times$ $10^{20}$ cm$^{-2}$ K$^{-1}$ km$^{-1}$ s. The total gas mass in\nthe CMZ is estimated to be $2.3_{-0.3}^{+0.3}\\times10^{7} \\; \\rm{M_{\\odot}}$\nwith $\\sim 10 \\%$ contribution from the atomic phase. Without removing the disk\ncontamination the total mass is about twice higher, and the atomic gas fraction\nincreases to $\\sim30\\%$. The cosmic-ray (CR) energy density in the CMZ,\nassuming a 1\/r profile, is higher by a factor of two compared to the previous\ncalculations at TeV energies. Using molecular gas tracers which probes only the\ndensest molecular cores leads to an overestimation of the CR energy density,\nwhile ignoring the foreground\/background contribution leads to an\nunderestimation of the CR energy density in the CMZ."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.16893"
    ],
    "c_title":[
      "Improving the End-to-End Efficiency of Offline Inference for Multi-LLM\n  Applications Based on Sampling and Simulation"
    ],
    "c_abstract":[
      "As large language models (LLMs) have shown great success in many tasks, they\nare used in various applications. While a lot of works have focused on the\nefficiency of single-LLM application (e.g., offloading, request scheduling,\nparallelism strategy selection), multi-LLM applications receive less attention,\nparticularly in offline inference scenarios. In this work, we aim to improve\nthe offline end-to-end inference efficiency of multi-LLM applications in the\nsingle-node multi-GPU environment. The problem involves two key decisions: (1)\ndetermining which LLMs to run concurrently each time (we may not run all the\nmodels at the same time), and (2) selecting a parallelism strategy to use for\neach LLM. This problem is NP-hard. Naive solutions may not work well because\nthe running time for a model to complete a set of requests depends on the\nrequest workload and the selected parallelism strategy, and they lack an\naccurate model of the running time. As the LLM output lengths are unknown\nbefore running, to estimate the model running time, we propose a\nsampling-then-simulation method which first estimates the output lengths by\nsampling from an empirical cumulative function we obtained from a large dataset\nin advance, and then simulates the LLM inference process accordingly. Based on\nthe simulation, we estimate the per-iteration latencys to get the total\nlatency. A greedy method is proposed to optimize the scheduling of the LLMs in\nthe application across the GPUs. We then propose a framework SamuLLM which\ncontains two phases: planning, which calls the greedy method for an application\nand running, which runs the application and dynamically adjust the model\nscheduling based on the runtime information. Experiments on 3 applications and\na mixed application show that SamuLLM can achieve 1.0-2.4$\\times$ end-to-end\nspeedups compared to the competitors."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-391",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06806"
    ],
    "b_title":[
      "Logits are All We Need to Adapt Closed Models"
    ],
    "b_abstract":[
      "Many commercial Large Language Models (LLMs) are often closed-source,\nlimiting developers to prompt tuning for aligning content generation with\nspecific applications. While these models currently do not provide access to\ntoken logits, we argue that if such access were available, it would enable more\npowerful adaptation techniques beyond prompt engineering. In this paper, we\npropose a token-level probability reweighting framework that, given access to\nlogits and a small amount of task-specific data, can effectively steer\nblack-box LLMs toward application-specific content generation. Our approach\nviews next-token prediction through the lens of supervised classification. We\nshow that aligning black-box LLMs with task-specific data can be formulated as\na label noise correction problem, leading to \\emph{Plugin} model -- an\nautoregressive probability reweighting model that operates solely on logits. We\nprovide theoretical justification for why reweighting logits alone is\nsufficient for task adaptation. Extensive experiments with multiple datasets,\nLLMs, and reweighting models demonstrate the effectiveness of our method,\nadvocating for broader access to token logits in closed-source models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05659"
    ],
    "c_title":[
      "On the order statistics from the XLindley distribution and associated\n  inference with an application to fatigue data"
    ],
    "c_abstract":[
      "In this paper, we consider the order statistics from a newly-introduced\nlifetime distribution called the XLindley distribution. We have derived\nexplicit closed form expressions for the single moments and product moments of\norder statistics from the XLindley distribution. Utilizing these expressions,\nwe calculated the means, variances, and covariances of order statistics for\nsample sizes ranging from n = 1 to n = 10 and arbitrarily selected parameter\nvalues. Additionally, these moments allow us to identify the best linear\nunbiased estimators and best linear invariant estimators for the location and\nscale parameters based on both complete samples and Type-II right censored\nsamples. We also address the linear prediction of unobserved order statistics\nbased on Type-II right-censored samples. We also explore the formulation of\nconfidence intervals for location and scale parameters, along with prediction\nintervals for unobserved order statistics. To provide comparison and\nillustration, we conduct a simulation study and analyze a real data example.\nFinally, we conclude with several remarks."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-392",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14798"
    ],
    "b_title":[
      "Unlocking the Optoelectronic Potential of AGeX$_{3}$ (A = Ca, Sr, Ba; X\n  = S, Se): A Sustainable Alternative in Chalcogenide Perovskites"
    ],
    "b_abstract":[
      "The quest for environmentally benign and stable optoelectronic materials has\nintensified, and chalcogenide perovskites (CPs) have emerged as promising\ncandidates owing to their non-toxic composition, stability, small bandgaps,\nlarge absorption coefficients. However, a detailed theoretical study of\nexcitonic and polaronic properties of these materials remains underexplored due\nto high computational demands. Herein, we present a comprehensive theoretical\ninvestigation of Germanium-based CPs, AGeX$_{3}$ (A = Ca, Sr, Ba; X = S, Se),\nwhich adopt distorted perovskite structures (\\beta-phase) with an orthorhombic\ncrystal structure (space group : Pnma) by utilizing state-of-the-art density\nfunctional theory (DFT), density functional perturbation theory (DFPT), and\nmany-body perturbation theory (GW and Bethe-Salpeter equation). Our\ncalculations reveal that these materials are thermodynamically and mechanically\nstable, with the bandgaps calculated using G$_{0}$W$_{0}$@PBE ranging from\n0.646 to 2.001 eV - suitable for optoelectronic devices. We analyze the ionic\nand electronic contributions to dielectric screening using DFPT and BSE\nmethods, finding that the electronic component dominates. The exciton binding\nenergies range from 0.03 to 73.63 meV, indicating efficient exciton\ndissociation under ambient conditions. Additionally, these perovskites exhibit\nlow to high polaronic mobilities (1.67-167.65 cm$^{2}$V$^{-1}$s$^{-1}$),\nexceeding many lead-free CPs and halide perovskites due to reduced\ncarrier-phonon interactions. The unique combination of wide tunable bandgaps,\nlow exciton binding energies, and enhanced charge-carrier mobility highlights\nAGeX$_{3}$ as a potential material for next-generation optoelectronic\napplications. These compounds are stable, high-performing, and eco-friendly,\nshowing great promise for experimental realization and device integration."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.09626"
    ],
    "c_title":[
      "Certainly Bot Or Not? Trustworthy Social Bot Detection via Robust\n  Multi-Modal Neural Processes"
    ],
    "c_abstract":[
      "Social bot detection is crucial for mitigating misinformation, online\nmanipulation, and coordinated inauthentic behavior. While existing neural\nnetwork-based detectors perform well on benchmarks, they struggle with\ngeneralization due to distribution shifts across datasets and frequently\nproduce overconfident predictions for out-of-distribution accounts beyond the\ntraining data. To address this, we introduce a novel Uncertainty Estimation for\nSocial Bot Detection (UESBD) framework, which quantifies the predictive\nuncertainty of detectors beyond mere classification. For this task, we propose\nRobust Multi-modal Neural Processes (RMNP), which aims to enhance the\nrobustness of multi-modal neural processes to modality inconsistencies caused\nby social bot camouflage. RMNP first learns unimodal representations through\nmodality-specific encoders. Then, unimodal attentive neural processes are\nemployed to encode the Gaussian distribution of unimodal latent variables.\nFurthermore, to avoid social bots stealing human features to camouflage\nthemselves thus causing certain modalities to provide conflictive information,\nwe introduce an evidential gating network to explicitly model the reliability\nof modalities. The joint latent distribution is learned through the generalized\nproduct of experts, which takes the reliability of each modality into\nconsideration during fusion. The final prediction is obtained through Monte\nCarlo sampling of the joint latent distribution followed by a decoder.\nExperiments on three real-world benchmarks show the effectiveness of RMNP in\nclassification and uncertainty estimation, as well as its robustness to\nmodality conflicts."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-393",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11446"
    ],
    "b_title":[
      "Global Exponential Stabilization for a Simplified Fluid-Particle\n  Interaction System"
    ],
    "b_abstract":[
      "This work considers a system coupling a viscous Burgers equation (aimed to\ndescribe a simplified model of $1D$ fluid flow) with the ODE describing the\nmotion of a point mass moving inside the fluid. The point mass is possibly\nunder the action of a feedback control. Our main contributions are that we\nprove two global exponential stability results. More precisely, we first show\nthat the velocity field corresponding to the free dynamics case is globally\nexponentially stable. We next show that, in the presence of the feedback\ncontrol both the velocity field and the distance from the mass point to a\nprescribed target position decay exponentially. The proofs of these results\nheavily rely on the use of a special test function allowing both to prove that\nthe mass point stays away from the boundary and to construct a perturbed\nLyapunov function."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.10511"
    ],
    "c_title":[
      "Enhancing Age-Related Robustness in Children Speaker Verification"
    ],
    "c_abstract":[
      "One of the main challenges in children's speaker verification (C-SV) is the\nsignificant change in children's voices as they grow. In this paper, we propose\ntwo approaches to improve age-related robustness in C-SV. We first introduce a\nFeature Transform Adapter (FTA) module that integrates local patterns into\nhigher-level global representations, reducing overfitting to specific local\nfeatures and improving the inter-year SV performance of the system. We then\nemploy Synthetic Audio Augmentation (SAA) to increase data diversity and size,\nthereby improving robustness against age-related changes. Since the lack of\nlongitudinal speech datasets makes it difficult to measure age-related\nrobustness of C-SV systems, we introduce a longitudinal dataset to assess\ninter-year verification robustness of C-SV systems. By integrating both of our\nproposed methods, the average equal error rate was reduced by 19.4%, 13.0%, and\n6.1% in the one-year, two-year, and three-year gap inter-year evaluation sets,\nrespectively, compared to the baseline."
    ],
    "c_categories":[
      [
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-394",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02790"
    ],
    "b_title":[
      "Segmenting Text and Learning Their Rewards for Improved RLHF in Language\n  Model"
    ],
    "b_abstract":[
      "Reinforcement learning from human feedback (RLHF) has been widely adopted to\nalign language models (LMs) with human preference. Prior RLHF works typically\ntake a bandit formulation, which, though intuitive, ignores the sequential\nnature of LM generation and can suffer from the sparse reward issue. While\nrecent works propose dense token-level RLHF, treating each token as an action\nmay be oversubtle to proper reward assignment. In this paper, we seek to get\nthe best of both by training and utilizing a segment-level reward model, which\nassigns a reward to each semantically complete text segment that spans over a\nshort sequence of tokens. For reward learning, our method allows dynamic text\nsegmentation and compatibility with standard sequence-preference datasets. For\neffective RL-based LM training against segment reward, we generalize the\nclassical scalar bandit reward normalizers into location-aware normalizer\nfunctions and interpolate the segment reward for further densification. With\nthese designs, our method performs competitively on three popular RLHF\nbenchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation\nstudies are conducted to further demonstrate our method."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03802"
    ],
    "c_title":[
      "MXMap: A Multivariate Cross Mapping Framework for Causal Discovery in\n  Dynamical Systems"
    ],
    "c_abstract":[
      "Convergent Cross Mapping (CCM) is a powerful method for detecting causality\nin coupled nonlinear dynamical systems, providing a model-free approach to\ncapture dynamic causal interactions. Partial Cross Mapping (PCM) was introduced\nas an extension of CCM to address indirect causality in three-variable systems\nby comparing cross-mapping quality between direct cause-effect mapping and\nindirect mapping through an intermediate conditioning variable. However, PCM\nremains limited to univariate delay embeddings in its cross-mapping processes.\nIn this work, we extend PCM to the multivariate setting, introducing multiPCM,\nwhich leverages multivariate embeddings to more effectively distinguish\nindirect causal relationships. We further propose a multivariate cross-mapping\nframework (MXMap) for causal discovery in dynamical systems. This two-phase\nframework combines (1) pairwise CCM tests to establish an initial causal graph\nand (2) multiPCM to refine the graph by pruning indirect causal connections.\nThrough experiments on simulated data and the ERA5 Reanalysis weather dataset,\nwe demonstrate the effectiveness of MXMap. Additionally, MXMap is compared\nagainst several baseline methods, showing advantages in accuracy and causal\ngraph refinement."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.DS",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-395",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01064"
    ],
    "b_title":[
      "Scientific Reasoning: Assessment of Multimodal Generative LLMs"
    ],
    "b_abstract":[
      "Large language models (LLMs) can answer questions and reason about complex\ntasks, also from the scientific domain. We assess several multimodal LLMs\n(MLLMs) on ScienceQA and find that Gemini models show the highest accuracy with\nlittle context, and the highest textual similarity to human explanations with\nricher context. Adapter-tuning of smaller MLLMs did not lead to any reliable\nperformance. Training from Gemini outputs consistently underperformed training\nfrom the original data."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15037"
    ],
    "c_title":[
      "Sken and cluster algebras of punctured surfaces"
    ],
    "c_abstract":[
      "We prove the full Fock-Goncharov conjecture for\n$\\mathcal{A}_{SL_2,\\Sigma_{g,p}}$--the $\\mathcal{A}$-cluster variety associated\nto representation of $SL_2$ local systems on most punctured surfaces with at\nleast 2 punctures in the classical $q\\to 1$ setting, that is, the tagged skein\nalgebra coincides with the upper cluster algebra (namely $Sk^{ta}=U(\\Sigma)$ or\n$mid(\\mathcal{A})=up(\\mathcal{A})$), with methods being potentially useful to\ntackle the quantum case. We deduce similar results for the Roger Yang skein\nalgebra via a birational geometric description, obtaining\n$Sk^{RY}=U(\\Sigma)[v_i^{\\pm1}]$ as conjectured by Shen, Sun and Weng, proving\nimportant algebraic properties of $Sk^{RY}$ including normality and\nCohen-Macaulayness. Our result is complementary to what and Mandel and Qin have\nshown in arXiv:2301.11101 for surface with marked points, based on\narXiv:1411.1394 . The once-punctured case where cluster structures are\nsignificantly different is also discussed in the paper, and relevant\nconjectures are proposed (and proved in the once-punctured torus case).\n  By contrast, we define the ordinary cluster algebra with potentials added\n$A(\\Sigma)[v_i^{\\pm1}]$, introduced by Shen, Sun and Weng, which is shown to be\nusually smaller than $Sk^{RY}$ and $U(\\Sigma)[v_i^{\\pm1}]$. This strengthen the\nresult of arXiv:2201.08833 that the classical $A=U$ fails for $\\Sigma_{g,p}$\nwith $g\\geq 1, p\\geq 1$."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.AG",
        "math.GT",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-396",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03152"
    ],
    "b_title":[
      "QCD Equation of State with Strong Magnetic Fields and Nonzero Baryon\n  Density"
    ],
    "b_abstract":[
      "In this work, we have carried out lattice simulations of $(2+1)$-flavor QCD\nusing highly improved staggered quarks at the physical pion mass on $32^3\n\\times 8$ and $48^3 \\times 12$ lattices, with magnetic field strengths ranging\nup to 0.8 GeV$^2$ and nonzero baryon chemical potentials employing the Taylor\nexpansion framework. We present lattice QCD continuum estimate results, along\nwith the magnetized hadron resonance and ideal gas comparisons, for the\nleading-order Taylor expansion coefficients for bulk thermodynamic quantities\nsuch as pressure, number density, energy density, and entropy density, focusing\non the significant impact of strong magnetic fields."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.13183"
    ],
    "c_title":[
      "MONA: Moving Object Detection from Videos Shot by Dynamic Camera"
    ],
    "c_abstract":[
      "Dynamic urban environments, characterized by moving cameras and objects, pose\nsignificant challenges for camera trajectory estimation by complicating the\ndistinction between camera-induced and object motion. We introduce MONA, a\nnovel framework designed for robust moving object detection and segmentation\nfrom videos shot by dynamic cameras. MONA comprises two key modules: Dynamic\nPoints Extraction, which leverages optical flow and tracking any point to\nidentify dynamic points, and Moving Object Segmentation, which employs adaptive\nbounding box filtering, and the Segment Anything for precise moving object\nsegmentation. We validate MONA by integrating with the camera trajectory\nestimation method LEAP-VO, and it achieves state-of-the-art results on the MPI\nSintel dataset comparing to existing methods. These results demonstrate MONA's\neffectiveness for moving object detection and its potential in many other\napplications in the urban planning field."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-397",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19477"
    ],
    "b_title":[
      "Causality Bounds on the Primordial Power Spectrum"
    ],
    "b_abstract":[
      "Effective field theories (EFTs) parametrize our ignorance of the underlying\nUV theory through their Wilson coefficients. However, not all values of these\ncoefficients are consistent with fundamental physical principles. In this\npaper, we explore the consequences of imposing causal propagation on the\ncomoving curvature perturbation in the EFT of inflation, particularly its\nimpact on the primordial power spectrum and the effective sound speed\n$c_s^\\text{eff}$. We investigate scenarios where $c_s^\\text{eff}$ undergoes a\ntransition, remaining consistent with CMB constraints at early times but later\nexperiencing a drastic change, becoming highly subluminal. Such scenarios allow\nthe primordial power spectrum to grow at small scales, potentially leading to\nthe formation of primordial black holes or the generation of scalar-induced\ngravitational waves. We find the generic feature that in a causal theory,\nluminal sound speeds imply a free theory, effectively constraining the\ndynamics. Additionally, we obtain that when considering natural values for the\nWilson coefficients, maintaining the validity of the EFT and the weakly coupled\nregime, and enforcing causal propagation of the EFT modes, the power spectrum\ncannot increase drastically. This imposes significant constraints on the\nparameter space of models aiming to produce such features."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.11566"
    ],
    "c_title":[
      "Artificial Neural Networks for Magnetoencephalography: A review of an\n  emerging field"
    ],
    "c_abstract":[
      "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that\nmeasures the intricate brain dynamics underlying cognitive processes with an\nunparalleled combination of high temporal and spatial precision. MEG data\nanalytics has always relied on advanced signal processing and mathematical and\nstatistical tools for various tasks ranging from data cleaning to probing the\nsignals' rich dynamics and estimating the neural sources underlying the\nsurface-level recordings. Like in most domains, the surge in Artificial\nIntelligence (AI) has led to the increased use of Machine Learning (ML) methods\nfor MEG data classification. More recently, an emerging trend in this field is\nusing Artificial Neural Networks (ANNs) to address many MEG-related tasks. This\nreview provides a comprehensive overview of how ANNs are being used with MEG\ndata from three vantage points: First, we review work that employs ANNs for MEG\nsignal classification, i.e., for brain decoding. Second, we report on work that\nhas used ANNs as putative models of information processing in the human brain.\nFinally, we examine studies that use ANNs as techniques to tackle\nmethodological questions in MEG, including artifact correction and source\nestimation. Furthermore, we assess the current strengths and limitations of\nusing ANNs with MEG and discuss future challenges and opportunities in this\nfield. Finally, by establishing a detailed portrait of the field and providing\npractical recommendations for the future, this review seeks to provide a\nhelpful reference for both seasoned MEG researchers and newcomers to the field\nwho are interested in using ANNs to enhance the exploration of the complex\ndynamics of the human brain with MEG."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-398",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17117"
    ],
    "b_title":[
      "A New Statistical Model of Star Speckles for Learning to Detect and\n  Characterize Exoplanets in Direct Imaging Observations"
    ],
    "b_abstract":[
      "The search for exoplanets is an active field in astronomy, with direct\nimaging as one of the most challenging methods due to faint exoplanet signals\nburied within stronger residual starlight. Successful detection requires\nadvanced image processing to separate the exoplanet signal from this nuisance\ncomponent. This paper presents a novel statistical model that captures nuisance\nfluctuations using a multi-scale approach, leveraging problem symmetries and a\njoint spectral channel representation grounded in physical principles. Our\nmodel integrates into an interpretable, end-to-end learnable framework for\nsimultaneous exoplanet detection and flux estimation. The proposed algorithm is\nevaluated against the state of the art using datasets from the SPHERE\ninstrument operating at the Very Large Telescope (VLT). It significantly\nimproves the precision-recall trade-off, notably on challenging datasets that\nare otherwise unusable by astronomers. The proposed approach is computationally\nefficient, robust to varying data quality, and well suited for large-scale\nobservational surveys."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.CV",
        "cs.LG",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03788"
    ],
    "c_title":[
      "Frontend Diffusion: Empowering Self-Representation of Junior Researchers\n  and Designers Through Agentic Workflows"
    ],
    "c_abstract":[
      "With the continuous development of generative AI's logical reasoning\nabilities, AI's growing code-generation potential poses challenges for both\ntechnical and creative professionals. But how can these advances be directed\ntoward empowering junior researchers and designers who often require additional\nhelp to build and express their professional and personal identities? We\npresent Frontend Diffusion, a multi-stage agentic system, transforms user-drawn\nlayouts and textual prompts into refined website code, thereby supporting\nself-representation goals. A user study with 13 junior researchers and\ndesigners shows AI as a human capability enhancer rather than a replacement,\nand highlights the importance of bidirectional human-AI alignment. We then\ndiscuss future work such as leveraging AI for career development and fostering\nbidirectional human-AI alignment on the intent level."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-399",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11065"
    ],
    "b_title":[
      "Low-cost Real-world Implementation of the Swing-up Pendulum for Deep\n  Reinforcement Learning Experiments"
    ],
    "b_abstract":[
      "Deep reinforcement learning (DRL) has had success in virtual and simulated\ndomains, but due to key differences between simulated and real-world\nenvironments, DRL-trained policies have had limited success in real-world\napplications. To assist researchers to bridge the \\textit{sim-to-real gap}, in\nthis paper, we describe a low-cost physical inverted pendulum apparatus and\nsoftware environment for exploring sim-to-real DRL methods. In particular, the\ndesign of our apparatus enables detailed examination of the delays that arise\nin physical systems when sensing, communicating, learning, inferring and\nactuating. Moreover, we wish to improve access to educational systems, so our\napparatus uses readily available materials and parts to reduce cost and\nlogistical barriers. Our design shows how commercial, off-the-shelf electronics\nand electromechanical and sensor systems, combined with common metal\nextrusions, dowel and 3D printed couplings provide a pathway for affordable\nphysical DRL apparatus. The physical apparatus is complemented with a simulated\nenvironment implemented using a high-fidelity physics engine and OpenAI Gym\ninterface."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07069"
    ],
    "c_title":[
      "Semantics-Aware Updates from Remote IoT Devices to Interconnected LEO\n  Satellites"
    ],
    "c_abstract":[
      "Providing timely and informative data in Integrated Terrestrial and\nNon-Terrestrial Networks (T-NTNs) is critical as data volume continues to grow\nwhile the resources available on devices remain limited. To address this, we\nadopt a semantics-aware approach to optimize the Version Age of Information\n(VAoI) in a status update system in which a remote Energy Harvesting (EH)\nInternet of Things (IoT) device samples data and transmits it to a network of\ninterconnected Low Earth Orbit (LEO) satellites for dissemination and\nutilization. The optimal update policy is derived through stochastic modeling\nand optimization of the VAoI across the network. The results indicate that this\npolicy reduces the frequency of updates by skipping stale or irrelevant data,\nsignificantly improving energy efficiency."
    ],
    "c_categories":[
      [
        "cs.IT",
        "cs.NI",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-400",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04907"
    ],
    "b_title":[
      "Prospects of future MeV telescopes in probing weak-scale Dark Matter"
    ],
    "b_abstract":[
      "Galactic weak-scale Dark Matter (DM) particles annihilating into lepton-rich\nchannels not only produce gamma-rays via prompt radiation but also generate\nabundant energetic electrons and positrons, which subsequently emit through\nbremsstrahlung or inverse Compton scattering (collectively called\n`secondary-radiation photons'). While the prompt gamma-rays concentrate at\nhigh-energy, the secondary emission falls in the MeV range, which a number of\nupcoming experiments (AMEGO, E-ASTROGAM, MAST...) will probe. We investigate\nthe sensitivity of these future telescopes for weak-scale DM, focusing for\ndefiniteness on observations of the galactic center. We find that they have the\npotential of probing a wide region of the DM parameter space which is currently\nunconstrained. Namely, in rather optimistic configurations, future MeV\ntelescopes could probe thermally-produced DM with a mass up to the TeV range,\nor GeV DM with an annihilation cross section 2 to 3 orders of magnitude smaller\nthan the current bounds, precisely thanks to the significant leverage provided\nby their sensitivity to secondary emissions. We comment on astrophysical and\nmethodological uncertainties, and compare with the reach of high-energy gamma\nray experiments."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.13648"
    ],
    "c_title":[
      "Prescribed energy solutions to some scaled problems via a scaled Nehari\n  manifold"
    ],
    "c_abstract":[
      "We prove the existence, multiplicity, and bifurcation of solutions with\nprescribed energy for a broad class of scaled problems by introducing a\nsuitable notion of scaling based Nehari manifold. Applications are given to\nSchr\\\"{o}dinger--Poisson--Slater type equations."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-401",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09083"
    ],
    "b_title":[
      "Ion densities of cold clouds driven by galactic outflows"
    ],
    "b_abstract":[
      "Observations of the circumgalactic medium (CGM) often display coincident\nabsorption from species with widely varying ionization states, providing direct\nevidence for complex, multiphase interactions. Motivated by these measurements,\nwe perform a series of cloud-crushing simulations that model cold clouds\ntraveling through the hot CGM. We analyze the ion distributions of these\nclouds, generate mock absorption spectra, and study their implications on\nquasar (QSO) absorption observations. Our results show interesting multiphase\nfeatures, in which ions with significantly different ionization potentials\nexist in the same absorber and share similar spectral features. However, our\nsimulations are unable to explain high ions like O \\textsc{vi} and their\ncoexistence with lower ions that appear in many observed QSO absorption\nsystems."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.16778"
    ],
    "c_title":[
      "Displacement-Actuated Continuum Robots: A Joint Space Abstraction"
    ],
    "c_abstract":[
      "The displacement-actuated continuum robot as an abstraction has been shown as\na key abstraction to significantly simplify and improve approaches due to its\nrelation to the Clarke transform. To highlight further potentials, we revisit\nand extend this abstraction that features an increasingly popular length\nextension and an underutilized twisting. For each extension, the corresponding\nmapping from the joint values to the local coordinates of the manifold embedded\nin the joint spaces is provided. Each mapping is characterized by its\ncompactness and linearity."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-402",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18884"
    ],
    "b_title":[
      "Deterministic carving of quantum states with Grover's algorithm"
    ],
    "b_abstract":[
      "We show that iteration of a few ( $\\sim N^{1\/4}$) unitary steps of Grover's\nalgorithm suffices to perfectly prepare a Dicke state of $N$ atoms in a cavity.\nWe also show that a few subsequent Grover steps can be employed to generate GHZ\nand Cat states. The Grover iteration is physically realized by global qubit\nrotations and by the phase shift of single photons reflected on the cavity. Our\nprotocols are deterministic and require no individual addressing of the atoms.\nA detailed error analysis accounting for spatial mode matching of the photon to\nthe cavity, spontaneous emission, mirror scattering, and the finite bandwidth\nof the photon mode is used to predict the fidelity of the prepared states as a\nfunction of system parameters and atom-cavity cooperativity. The fidelity can\nbe increased by heralding on detection of the reflected photon."
    ],
    "b_categories":[
      [
        "physics.atom-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05703"
    ],
    "c_title":[
      "What I cannot execute, I do not understand: Training and Evaluating LLMs\n  on Program Execution Traces"
    ],
    "c_abstract":[
      "Code generation and understanding are critical capabilities for large\nlanguage models (LLMs). Thus, most LLMs are pretrained and fine-tuned on code\ndata. However, these datasets typically treat code as static strings and rarely\nexploit the dynamic information about their execution. Building upon previous\nwork on trace modeling, we study Execution Tuning (E.T.), a training procedure\nin which we explicitly model real-world program execution traces without\nrequiring manual test annotations. We train and evaluate models on different\nexecution trace granularities (line and instruction-level) and strategies on\nthe task of output prediction, obtaining around 80% accuracy on CruxEval and\nMBPP, and showing the advantages of dynamic scratchpads (i.e., self-contained\nintermediate computations updated by the model rather than accumulated as a\nhistory of past computations) on long executions (up to 14k steps). Finally, we\ndiscuss E.T.'s practical applications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-403",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16474"
    ],
    "b_title":[
      "From Voices to Worlds: Developing an AI-Powered Framework for 3D Object\n  Generation in Augmented Reality"
    ],
    "b_abstract":[
      "This paper presents Matrix, an advanced AI-powered framework designed for\nreal-time 3D object generation in Augmented Reality (AR) environments. By\nintegrating a cutting-edge text-to-3D generative AI model, multilingual\nspeech-to-text translation, and large language models (LLMs), the system\nenables seamless user interactions through spoken commands. The framework\nprocesses speech inputs, generates 3D objects, and provides object\nrecommendations based on contextual understanding, enhancing AR experiences. A\nkey feature of this framework is its ability to optimize 3D models by reducing\nmesh complexity, resulting in significantly smaller file sizes and faster\nprocessing on resource-constrained AR devices. Our approach addresses the\nchallenges of high GPU usage, large model output sizes, and real-time system\nresponsiveness, ensuring a smoother user experience. Moreover, the system is\nequipped with a pre-generated object repository, further reducing GPU load and\nimproving efficiency. We demonstrate the practical applications of this\nframework in various fields such as education, design, and accessibility, and\ndiscuss future enhancements including image-to-3D conversion, environmental\nobject detection, and multimodal support. The open-source nature of the\nframework promotes ongoing innovation and its utility across diverse\nindustries."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09295"
    ],
    "c_title":[
      "$k$-type chaos of $\\mathbb{Z}^d$ actions"
    ],
    "c_abstract":[
      "In this paper, we define and study the notions of $k$-type proximal pairs,\n$k$-type asymptotic pairs and $k$-type Li Yorke sensitivity for dynamical\nsystems given by $\\mathbb{Z}^d$ actions on compact metric spaces. We prove the\nAuslander-Yorke dichotomy theorem for $k$-type notions. The preservation of\nsome of these notions under uniform conjugacy is also studied. We also study\nrelations between these notions and their analogous notions in the usual\ndynamical systems."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-404",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00398"
    ],
    "b_title":[
      "Monitoring AGNs with H$\\beta$ Asymmetry. V. Long-term Variation and\n  Evolution of the Broad H$\\beta$ Emission-Line Profiles"
    ],
    "b_abstract":[
      "The physical origins of the diverse emission-line asymmetries observed in the\nspectra of active galactic nuclei (AGNs) remain incompletely understood.\nMonitoring the temporal variations of line profiles offers a promising approach\nto investigating the underlying physics. In this study, we present an analysis\nof the broad H$\\beta$ emission line profiles of eight AGNs observed from the\nend of 2016 to May 2023 as part of the reverberation mapping campaign titled\n\"Monitoring AGNs with H$\\beta$ Asymmetry\" (MAHA), utilizing data obtained from\nthe Wyoming Infrared Observatory (WIRO) 2.3-meter telescope. We measure the\ntemporal variations of line asymmetry, width, and central velocity shift for\nthe eight objects. Our findings reveal that the variation in asymmetry is\npositively correlated with H$\\beta$ flux in five of the eight objects, while\nthe remaining objects exhibit negative or complex correlations. Furthermore, we\nobserve anti-correlations between line width and H$\\beta$ flux for most\nobjects, indicating the presence of the \"breathing\" phenomenon in their\nH$\\beta$ emission lines. In contrast, two objects demonstrate an\n\"anti-breathing\" phenomenon or complex behavior. We discuss the physical\norigins of the temporal variations in line profiles and propose the possibility\nof decomposing the variations in H$\\beta$ asymmetry and width into components:\none that corresponds to short-term variations in H$\\beta$ flux and another that\nreflects long-term variations in continuum light curves, perhaps driven by\nradiation pressure."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.21022"
    ],
    "c_title":[
      "When Unsupervised Domain Adaptation meets One-class Anomaly Detection:\n  Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity"
    ],
    "c_abstract":[
      "This paper introduces the first fully unsupervised domain adaptation (UDA)\nframework for unsupervised anomaly detection (UAD). The performance of UAD\ntechniques degrades significantly in the presence of a domain shift, difficult\nto avoid in a real-world setting. While UDA has contributed to solving this\nissue in binary and multi-class classification, such a strategy is ill-posed in\nUAD. This might be explained by the unsupervised nature of the two tasks,\nnamely, domain adaptation and anomaly detection. Herein, we first formulate\nthis problem that we call the two-fold unsupervised curse. Then, we propose a\npioneering solution to this curse, considered intractable so far, by assuming\nthat anomalies are rare. Specifically, we leverage clustering techniques to\nidentify a dominant cluster in the target feature space. Posed as the normal\ncluster, the latter is aligned with the source normal features. Concretely,\ngiven a one-class source set and an unlabeled target set composed mostly of\nnormal data and some anomalies, we fit the source features within a hypersphere\nwhile jointly aligning them with the features of the dominant cluster from the\ntarget set. The paper provides extensive experiments and analysis on common\nadaptation benchmarks for anomaly detection, demonstrating the relevance of\nboth the newly introduced paradigm and the proposed approach. The code will be\nmade publicly available."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-405",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07334"
    ],
    "b_title":[
      "Anonymization of Documents for Law Enforcement with Machine Learning"
    ],
    "b_abstract":[
      "The steadily increasing utilization of data-driven methods and approaches in\nareas that handle sensitive personal information such as in law enforcement\nmandates an ever increasing effort in these institutions to comply with data\nprotection guidelines. In this work, we present a system for automatically\nanonymizing images of scanned documents, reducing manual effort while ensuring\ndata protection compliance. Our method considers the viability of further\nforensic processing after anonymization by minimizing automatically redacted\nareas by combining automatic detection of sensitive regions with knowledge from\na manually anonymized reference document. Using a self-supervised image model\nfor instance retrieval of the reference document, our approach requires only\none anonymized example to efficiently redact all documents of the same type,\nsignificantly reducing processing time. We show that our approach outperforms\nboth a purely automatic redaction system and also a naive copy-paste scheme of\nthe reference anonymization to other documents on a hand-crafted dataset of\nground truth redactions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17356"
    ],
    "c_title":[
      "Fast Convex Optimization with Quantum Gradient Methods"
    ],
    "c_abstract":[
      "We study quantum algorithms based on quantum (sub)gradient estimation using\nnoisy evaluation oracles, and demonstrate the first dimension independent query\ncomplexities (up to poly-logarithmic factors) for zeroth-order convex\noptimization in both smooth and nonsmooth settings. We match the first-order\nquery complexities of classical gradient descent, using only noisy evaluation\noracles, thereby exhibiting exponential separation between quantum and\nclassical zeroth-order optimization. Specifically, for the smooth case,\nzeroth-order quantum gradient descent achieves\n$\\widetilde{\\mathcal{O}}(LR^2\/\\varepsilon)$ and $\\widetilde{\\mathcal{O}} \\left(\n\\kappa \\log(1\/\\varepsilon \\right))$ query complexities, for the convex and\nstrongly convex case respectively; for the nonsmooth case, the zeroth-order\nquantum subgradient method attains a query complexity of\n$\\widetilde{\\mathcal{O}}((GR\/\\varepsilon)^2 )$. We then generalize these\nalgorithms to work in non-Euclidean settings by using quantum (sub)gradient\nestimation to instantiate mirror descent, dual averaging and mirror prox.\n  We demonstrate how our algorithm for nonsmooth optimization can be applied to\nsolve an SDP involving $m$ constraints and $n \\times n$ matrices to additive\nerror $\\varepsilon$ using $\\widetilde{\\mathcal{O}}\n((mn^2+n^{\\omega})(Rr\/\\varepsilon)^2)$ gates, where $\\omega \\in [2,2.38)$ is\nthe exponent of matrix-multiplication time and $R$ and $r$ are bounds on the\nprimal and dual optimal solutions, respectively. Specializing to linear\nprograms, we obtain a quantum LP solver with complexity $\n\\widetilde{\\mathcal{O}}((m+\\sqrt{n}) (Rr\/\\varepsilon)^2).$ For zero-sum games\nwe achieve the best quantum runtimes for any $\\varepsilon > 0$ when $m =\n\\mathcal{O}(\\sqrt{n})$. We obtain the best algorithm overall (quantum or\nclassical) whenever we further impose $\\varepsilon=\\Omega((m+n)^{-1\/4})$."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-406",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06914"
    ],
    "b_title":[
      "Spin of fractional quantum Hall neutral modes and \"missing states\" on a\n  sphere"
    ],
    "b_abstract":[
      "A low-energy neutral quasiparticle in a fractional quantum Hall system\nappears in the latter's energy spectrum on a sphere as a series of many-body\nexcited states labeled by the angular momentum $L$ and whose energy is a smooth\nfunction of $L$ in the limit of large sphere radius. We argue that the\nsignature of a nonvanishing spin (intrinsic angular momentum) $s$ of the\nquasiparticle is the absence, in this series, of states with total angular\nmomentum less than $s$.We reinterpret the missing of certain states, observed\nin an exact-diagonalization calculation of the spectrum of the $\\nu=7\/3$ FQH\nstate in a wide quantum well as well as in many proposed wave functions for the\nexcited states as a consequence of the spin-2 nature of the zero-momentum\nmagnetoroton."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11514"
    ],
    "c_title":[
      "Investigating Inference-time Scaling for Chain of Multi-modal Thought: A\n  Preliminary Study"
    ],
    "c_abstract":[
      "Recently, inference-time scaling of chain-of-thought (CoT) has been\ndemonstrated as a promising approach for addressing multi-modal reasoning\ntasks. While existing studies have predominantly centered on text-based\nthinking, the integration of both visual and textual modalities within the\nreasoning process remains unexplored. In this study, we pioneer the exploration\nof inference-time scaling with multi-modal thought, aiming to bridge this gap.\nTo provide a comprehensive analysis, we systematically investigate popular\nsampling-based and tree search-based inference-time scaling methods on 10\nchallenging tasks spanning various domains. Besides, we uniformly adopt a\nconsistency-enhanced verifier to ensure effective guidance for both methods\nacross different thought paradigms. Results show that multi-modal thought\npromotes better performance against conventional text-only thought, and\nblending the two types of thought fosters more diverse thinking. Despite these\nadvantages, multi-modal thoughts necessitate higher token consumption for\nprocessing richer visual inputs, which raises concerns in practical\napplications. We hope that our findings on the merits and drawbacks of this\nresearch line will inspire future works in the field."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-407",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17967"
    ],
    "b_title":[
      "A fully adaptive, high-order, fast Poisson solver for complex\n  two-dimensional geometries"
    ],
    "b_abstract":[
      "We present a new framework for the fast solution of inhomogeneous elliptic\nboundary value problems in domains with smooth boundaries. High-order solvers\nbased on adaptive box codes or the fast Fourier transform can efficiently treat\nthe volumetric inhomogeneity, but require care to be taken near the boundary to\nensure that the volume data is globally smooth. We avoid function extension or\ncut-cell quadratures near the boundary by dividing the domain into two regions:\na bulk region away from the boundary that is efficiently treated with a\ntruncated free-space box code, and a variable-width boundary-conforming strip\nregion that is treated with a spectral collocation method and accompanying fast\ndirect solver. Particular solutions in each region are then combined with\nLaplace layer potentials to yield the global solution. The resulting solver has\nan optimal computational complexity of $O(N)$ for an adaptive discretization\nwith $N$ degrees of freedom. With an efficient two-dimensional (2D)\nimplementation we demonstrate adaptive resolution of volumetric data, boundary\ndata, and geometric features across a wide range of length scales, to typically\n10-digit accuracy. The cost of all boundary corrections remains small relative\nto that of the bulk box code. The extension to 3D is expected to be\nstraightforward in many cases because the strip ``thickens'' an existing\nboundary quadrature."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15134"
    ],
    "c_title":[
      "Chain-of-Rank: Enhancing Large Language Models for Domain-Specific RAG\n  in Edge Device"
    ],
    "c_abstract":[
      "Retrieval-augmented generation (RAG) with large language models (LLMs) is\nespecially valuable in specialized domains, where precision is critical. To\nmore specialize the LLMs into a target domain, domain-specific RAG has recently\nbeen developed by allowing the LLM to access the target domain early via\nfinetuning. The domain-specific RAG makes more sense in resource-constrained\nenvironments like edge devices, as they should perform a specific task (e.g.\npersonalization) reliably using only small-scale LLMs. While the\ndomain-specific RAG is well-aligned with edge devices in this respect, it often\nrelies on widely-used reasoning techniques like chain-of-thought (CoT). The\nreasoning step is useful to understand the given external knowledge, and yet it\nis computationally expensive and difficult for small-scale LLMs to learn it.\nTackling this, we propose the Chain of Rank (CoR) which shifts the focus from\nintricate lengthy reasoning to simple ranking of the reliability of input\nexternal documents. Then, CoR reduces computational complexity while\nmaintaining high accuracy, making it particularly suited for\nresource-constrained environments. We attain the state-of-the-art (SOTA)\nresults in benchmarks, and analyze its efficacy."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-408",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15020"
    ],
    "b_title":[
      "Enhancing Reset Control Phase with Lead Shaping Filters: Applications to\n  Precision Motion Systems"
    ],
    "b_abstract":[
      "This study presents a shaped reset feedback control strategy to enhance the\nperformance of precision motion systems. The approach utilizes a phase-lead\ncompensator as a shaping filter to tune the phase of reset instants, thereby\nshaping the nonlinearity in the first-order reset control. {The design achieves\neither an increased phase margin while maintaining gain properties or improved\ngain without sacrificing phase margin, compared to reset control without the\nshaping filter.} Then, frequency-domain design procedures are provided for both\nClegg Integrator (CI)-based and First-Order Reset Element (FORE)-based reset\ncontrol systems. Finally, the effectiveness of the proposed strategy is\ndemonstrated through two experimental case studies on a precision motion stage.\nIn the first case, the shaped reset control leverages phase-lead benefits to\nachieve zero overshoot in the transient response. In the second case, the\nshaped reset control strategy enhances the gain advantages of the previous\nreset element, resulting in improved steady-state performance, including better\ntracking precision and disturbance rejection, while reducing overshoot for an\nimproved transient response."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15511"
    ],
    "c_title":[
      "Forecasting the performance of the Minimally Informed foreground\n  cleaning method for CMB polarization observations"
    ],
    "c_abstract":[
      "Astrophysical foreground substraction is crucial to retrieve the cosmic\nmicrowave background (CMB) polarization out of the observed data. Recent\nefforts have been carried out towards the development of a minimally informed\ncomponent separation method to handle a priori unknown foreground spectral\nenergy distributions (SEDs), while being able to estimate both cosmological,\nforeground, and potentially instrumental parameters, jointly. In this paper, we\ndevelop a semi-analytical performance forecasting framework for the minimally\ninformed method and we validate it by comparing its results against direct\nsampling of the harmonic-based likelihood and the pixel domain implementation\nMICMAC. We then use the forecasting tool to demonstrate the robustness of the\nbias correction procedure introduced in the minimally informed approach. We\nfind that a data-driven approach based on the currently available observational\ndata is enough to efficiently regularize the bias of the method."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-409",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16839"
    ],
    "b_title":[
      "Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans"
    ],
    "b_abstract":[
      "Among generative neural models, flow matching techniques stand out for their\nsimple applicability and good scaling properties. Here, velocity fields of\ncurves connecting a simple latent and a target distribution are learned. Then\nthe corresponding ordinary differential equation can be used to sample from a\ntarget distribution, starting in samples from the latent one. This paper\nreviews from a mathematical point of view different techniques to learn the\nvelocity fields of absolutely continuous curves in the Wasserstein geometry. We\nshow how the velocity fields can be characterized and learned via i) transport\nplans (couplings) between latent and target distributions, ii) Markov kernels\nand iii) stochastic processes, where the latter two include the coupling\napproach, but are in general broader. Besides this main goal, we show how flow\nmatching can be used for solving Bayesian inverse problems, where the\ndefinition of conditional Wasserstein distances plays a central role. Finally,\nwe briefly address continuous normalizing flows and score matching techniques,\nwhich approach the learning of velocity fields of curves from other directions."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06029"
    ],
    "c_title":[
      "DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations"
    ],
    "c_abstract":[
      "Pre-trained Vision Transformers now serve as powerful tools for computer\nvision. Yet, efficiently adapting them for multiple tasks remains a challenge\nthat arises from the need to modify the rich hidden representations encoded by\nthe learned weight matrices, without inducing interference between tasks.\nCurrent parameter-efficient methods like LoRA, which apply low-rank updates,\nforce tasks to compete within constrained subspaces, ultimately degrading\nperformance. We introduce DiTASK a novel Diffeomorphic Multi-Task Fine-Tuning\napproach that maintains pre-trained representations by preserving weight matrix\nsingular vectors, while enabling task-specific adaptations through neural\ndiffeomorphic transformations of the singular values. By following this\napproach, DiTASK enables both shared and task-specific feature modulations with\nminimal added parameters. Our theoretical analysis shows that DITASK achieves\nfull-rank updates during optimization, preserving the geometric structure of\npre-trained features, and establishing a new paradigm for efficient multi-task\nlearning (MTL). Our experiments on PASCAL MTL and NYUD show that DiTASK\nachieves state-of-the-art performance across four dense prediction tasks, using\n75% fewer parameters than existing methods. Our code is available\n[here](https:\/\/github.com\/ipsitmantri\/DiTASK)."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-410",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04410"
    ],
    "b_title":[
      "Nuclear magnetic resonance spectroscopy in pulsed magnetic fields"
    ],
    "b_abstract":[
      "This article provides an introduction to nuclear magnetic resonance\nspectroscopy in pulsed magnetic fields (PFNMR), focusing on its capabilities,\napplications, and future developments in research involving high magnetic\nfields. It highlights the significance of PFNMR in enhancing the understanding\nof solid-state materials, with particular emphasis on those exhibiting complex\ninteractions and strong electronic correlations. Several technical aspects are\ndiscussed, including the challenges associated with high-frequency NMR\nexperiments. The power of PFNMR is showcased through several examples,\nincluding studies on the topical materials LiCuVO$_4$, SrCu$_2$(BO$_3$)$_2$,\nand CeIn$_3$, offering insights into their magnetic and electronic properties\nat high magnetic fields. The article also discusses possible future directions\nfor the technique, including improvements in PFNMR instrumentation and the\nexploration of materials under extreme conditions. This exposition underscores\nthe role of PFNMR in advancing the frontiers of materials-science research."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.06527"
    ],
    "c_title":[
      "Scaffolding Creativity: Integrating Generative AI Tools and Real-world\n  Experiences in Business Education"
    ],
    "c_abstract":[
      "This case study explores the integration of Generative AI tools and\nreal-world experiences in business education. Through a study of an innovative\nundergraduate course, we investigate how AI-assisted learning, combined with\nexperiential components, impacts students' creative processes and learning\noutcomes. Our findings reveal that this integrated approach accelerates\nknowledge acquisition, enables students to overcome traditional creative\nbarriers, and facilitates a dynamic interplay between AI-generated insights and\nreal-world observations. The study also highlights challenges, including the\nneed for instructors with high AI literacy and the rapid evolution of AI tools\ncreating a moving target for curriculum design. These insights contribute to\nthe growing body of literature on AI in education and provide actionable\nrecommendations for educators preparing students for the complexities of modern\nbusiness environments."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-411",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02325"
    ],
    "b_title":[
      "Revisiting Compactness for District Plans"
    ],
    "b_abstract":[
      "Modern sampling methods create ensembles of district maps that score well on\ndiscrete compactness scores, whereas the Polsby-Popper and other shape-based\nscores remain highly relevant for building fair maps and litigating unfair\nones. The aim of this paper is twofold. First, we introduce population-weighted\nversions of shape-based scores and show a precise sense in which this\ninterpolates between shape-based and discrete scores. Second, we introduce a\nmodification of the ReCom sampling method that produces ensembles of maps with\nimproved shape-based compactness scores."
    ],
    "b_categories":[
      [
        "cs.CV",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14005"
    ],
    "c_title":[
      "Flexible BiSel\/NiO-based X-ray synapses bridging the functions of\n  detection and memory"
    ],
    "c_abstract":[
      "Currently, the X-ray detectors are widely used in medical imaging, industrial\ninspection, aerospace, and other fields, as the market demand for\nhigh-efficiency, flexible, and low-power detectors is increased. Although the\ntraditional inorganic X-ray detection materials have achieved great success and\neffectiveness, they have their own limitations and let alone\nflexibility\/bendability and memory function. In this study, we present the\ndesign of a BiSeI\/NiO-based X-ray synaptic detector and its application in the\nsimulation of biological synaptic processes. Herein, the BiSeI, a quasi-1D\ninorganic semiconductor, stands out as an ideal choice for the X-ray detectors,\nespecially for flexible and portable devices due to its large atomic number,\nlarge photoelectric absorption coefficient, and mechanical plasticity.\nMeanwhile, the NiO-based materials provide the memory function required for the\nintelligent detection systems. Moreover, our devices offer notable advantages\nin terms of low power consumption, compared with traditional X-ray detectors.\nThe BiSeI\/NiO detectors demonstrate advanced features with an ultrahigh\nsensitivity, an ultralow detection limit, and include the paired-pulse\nfacilitation (PPF) and the transition from short- to long-term memory,\nmaintaining the functionality on flexible substrates. This design represents a\nsignificant step toward the development of intelligent and flexible X-ray\ndetectors."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.ins-det",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-412",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11354"
    ],
    "b_title":[
      "Towards Advancing Code Generation with Large Language Models: A Research\n  Roadmap"
    ],
    "b_abstract":[
      "Recently, we have witnessed the rapid development of large language models,\nwhich have demonstrated excellent capabilities in the downstream task of code\ngeneration. However, despite their potential, LLM-based code generation still\nfaces numerous technical and evaluation challenges, particularly when embedded\nin real-world development. In this paper, we present our vision for current\nresearch directions, and provide an in-depth analysis of existing studies on\nthis task. We propose a six-layer vision framework that categorizes code\ngeneration process into distinct phases, namely Input Phase, Orchestration\nPhase, Development Phase, and Validation Phase. Additionally, we outline our\nvision workflow, which reflects on the currently prevalent frameworks. We\nsystematically analyse the challenges faced by large language models, including\nthose LLM-based agent frameworks, in code generation tasks. With these, we\noffer various perspectives and actionable recommendations in this area. Our aim\nis to provide guidelines for improving the reliability, robustness and\nusability of LLM-based code generation systems. Ultimately, this work seeks to\naddress persistent challenges and to provide practical suggestions for a more\npragmatic LLM-based solution for future code generation endeavors."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07409"
    ],
    "c_title":[
      "On the expressive power of $2$-edge-colourings of graphs"
    ],
    "c_abstract":[
      "Given a finite set of $2$-edge-coloured graphs $\\mathcal F$ and a hereditary\nproperty of graphs $\\mathcal{P}$, we say that $\\mathcal F$ expresses\n$\\mathcal{P}$ if a graph $G$ has the property $\\mathcal{P}$ if and only if it\nadmits a $2$-edge-colouring not having any graph in $\\mathcal F$ as an induced\n$2$-edge-coloured subgraph. We show that certain classic hereditary classes are\nexpressible by some set of $2$-edge-coloured graphs on three vertices. We then\ninitiate a systematic study of the following problem. Given a finite set of\n$2$-edge-coloured graphs $\\mathcal F$, structurally characterize the hereditary\nproperty expressed by $\\mathcal F$. In our main results we describe all\nhereditary properties expressed by $\\mathcal F$ when $\\mathcal F$ consists of\n2-edge-coloured graphs on three vertices and (1) patterns have at most two\nedges, or (2) $\\mathcal F$ consists of both monochromatic paths and a set of\ncoloured triangles.\n  On the algorithmic side, we consider the $\\mathcal F$-free colouring problem,\ni.e., deciding if an input graph admits an $\\mathcal F$-free\n$2$-edge-colouring. It follows from our structural characterizations, that for\nall sets considered in (1) and (2) the $\\mathcal F$-free colouring problem is\nsolvable in polynomial time. We complement these tractability results with a\nuniform reduction to boolean constraint satisfaction problems which yield\npolynomial-time algorithms that recognize most graph classes expressible by a\nset $\\mathcal F$ of $2$-edge-coloured graphs on at most three vertices.\nFinally, we exhibit some sets $\\mathcal F$ such that the $\\mathcal F$-free\ncolouring problem is NP-complete."
    ],
    "c_categories":[
      [
        "cs.DM",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-413",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10222"
    ],
    "b_title":[
      "Spectral Instability of Random Fredholm Operators"
    ],
    "b_abstract":[
      "If $A \\colon D(A) \\subset \\mathcal{H} \\to \\mathcal{H}$ is an unbounded\nFredholm operator of index $0$ on a Hilbert space $\\mathcal{H}$ with a dense\ndomain $D(A)$, then its spectrum is either discrete or the entire complex\nplane. This spectral dichotomy plays a central role in the study of\n\\textit{magic angles} in twisted bilayer graphene.\n  This paper proves that if such operators (with certain additional\nassumptions) are perturbed by certain random trace-class operators, their\nspectrum is discrete with high probability."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.09074"
    ],
    "c_title":[
      "Bilevel gradient methods and Morse parametric qualification"
    ],
    "c_abstract":[
      "Morse parametric qualification condition is a new condition that generalizes\nuniform strong convexity. Generic semi-algebraic functions are Morse parametric\nin a piecewise sense, implying that generic semi-algebraic bilevel problems\nreduce to mixed-integer programming. In this new framework, we study bilevel\ngradient algorithms with two strategies: the single-step multi-step strategy,\nwhich involves a sequence of steps on the lower-level problems followed by one\nstep on the upper-level problem, and a differentiable programming strategy that\noptimizes a smooth approximation of the bilevel problem. While the first is\nshown to be a biased gradient method on the problem with rich properties, the\nsecond, inspired by meta-learning applications, is less stable but offers\nsimplicity and ease of implementation."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-414",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03170"
    ],
    "b_title":[
      "Universality in the microwave shielding of ultracold polar molecules"
    ],
    "b_abstract":[
      "Microwave shielding is an important technique that can suppress the losses\nthat arise from collisions of ultracold polar molecules. It has been\ninstrumental in achieving molecular Bose-Einstein condensation (BEC) for NaCs\n[Bigagli et al., Nature 631, 289 (2024)]. We demonstrate that microwave\nshielding is universal, in the sense that the 2-body collision properties of\ndifferent molecules are very similar when expressed in suitable reduced units\nof length and energy. This applies to rate coefficients for inelastic\nscattering and loss, to scattering lengths, and to the properties of 2-molecule\nbound states. We also explore the small deviations from universality that arise\nat very large Rabi frequencies. In general, the collision properties are\nnear-universal except when the Rabi frequency exceeds a few percent of the\nmolecular rotational constant. The universality extends to elliptically\npolarized microwaves and to combinations of multiple fields. Our results\nindicate that the methods that have been used to achieve BEC for NaCs can be\ntransferred directly to most other polar molecules."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10654"
    ],
    "c_title":[
      "Trees with non log-concave independent set sequences"
    ],
    "c_abstract":[
      "We construct a family of trees with independence numbers going to infinity\nfor which the log-concavity relation for the independent set sequence of a tree\n$T$ in the family fails at around $\\alpha(T)\\left(1-1\/(16\\log\n\\alpha(T))\\right)$. Here $\\alpha(T)$ is the independence number of $T$. This\nresolves a conjecture of Kadrawi and Levit."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-415",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05920"
    ],
    "b_title":[
      "Full Implementation via Information Design in Nonatomic Games"
    ],
    "b_abstract":[
      "This paper studies the implementation of Bayes correlated equilibria in\nsymmetric Bayesian nonatomic games, using direct information structures and\nobedient strategies. The main results demonstrate full implementation in a\nclass of games with positive cost externalities. Specifically, if the game\nadmits a strictly convex potential in every state, then for every Bayes\ncorrelated equilibrium outcome with finite support and rational action\ndistributions, there exists a direct information structure that implements this\noutcome under all equilibria. When the potential is only weakly convex, we show\nthat all equilibria implement the same expected social cost. Additionally, all\nBayes correlated equilibria, including those with infinite support or\nirrational action distributions, are approximately implemented."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2501.17043"
    ],
    "c_title":[
      "Entanglement and squeezing of gravitational waves"
    ],
    "c_abstract":[
      "We show that the self-interactions present in the effective field theory\nformulation of general relativity can couple gravitational wave modes and\ngenerate nonclassical states. The output of gravitational nonlinear processes\ncan also be sensitive to quantum features of the input states, indicating that\nnonlinearities can act both as sources and detectors of quantum features of\ngravitational waves. Due to gauge and quantization issues in strongly curved\nspacetimes, we work in the geometric optics limit of gravitational radiation,\nbut we expect the key ideas extend to situations of astrophysical interest.\nThis offers a new direction for probing the quantum nature of gravity,\nanalogous to how the quantumness of electrodynamics was established through\nquantum optics."
    ],
    "c_categories":[
      [
        "gr-qc",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-416",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04653"
    ],
    "b_title":[
      "Three-dimensional spin liquid state in the frustrated $S = 1\/2$\n  Heisenberg garnet NaCa$_{2}$Cu$_{2}$(VO$_{4}$)$_{3}$"
    ],
    "b_abstract":[
      "Three-dimensional quantum spin liquids have remained elusive, hindered by\nreduced quantum fluctuations from larger lattice connectivity inherent to\nhigh-dimensional systems. Here, we investigate the remarkable persistence of\ndynamical short-range magnetic correlations in the nearly body-centered cubic\ngarnet NaCa$_2$Cu$_2$(VO$_4$)$_3$ down to $T = 50$ mK, two orders of magnitude\nbelow its Curie-Weiss temperature. Using a combination of neutron and muon\nspectroscopies plus numerical simulations, we demonstrate that a spin-liquid\nphase emerges from the interplay of strongly frustrated exchange interactions\nand subtle temperature-dependent Jahn-Teller spin-lattice effects."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.12152"
    ],
    "c_title":[
      "Learning Getting-Up Policies for Real-World Humanoid Robots"
    ],
    "c_abstract":[
      "Automatic fall recovery is a crucial prerequisite before humanoid robots can\nbe reliably deployed. Hand-designing controllers for getting up is difficult\nbecause of the varied configurations a humanoid can end up in after a fall and\nthe challenging terrains humanoid robots are expected to operate on. This paper\ndevelops a learning framework to produce controllers that enable humanoid\nrobots to get up from varying configurations on varying terrains. Unlike\nprevious successful applications of humanoid locomotion learning, the\ngetting-up task involves complex contact patterns, which necessitates\naccurately modeling the collision geometry and sparser rewards. We address\nthese challenges through a two-phase approach that follows a curriculum. The\nfirst stage focuses on discovering a good getting-up trajectory under minimal\nconstraints on smoothness or speed \/ torque limits. The second stage then\nrefines the discovered motions into deployable (i.e. smooth and slow) motions\nthat are robust to variations in initial configuration and terrains. We find\nthese innovations enable a real-world G1 humanoid robot to get up from two main\nsituations that we considered: a) lying face up and b) lying face down, both\ntested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass\nand snowfield). To the best of our knowledge, this is the first successful\ndemonstration of learned getting-up policies for human-sized humanoid robots in\nthe real world. Project page: https:\/\/humanoid-getup.github.io\/"
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-417",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16560"
    ],
    "b_title":[
      "Early Prediction of Alzheimer's and Related Dementias: A Machine\n  Learning Approach Utilizing Social Determinants of Health Data"
    ],
    "b_abstract":[
      "Alzheimer's disease and related dementias (AD\/ADRD) represent a growing\nhealthcare crisis affecting over 6 million Americans. While genetic factors\nplay a crucial role, emerging research reveals that social determinants of\nhealth (SDOH) significantly influence both the risk and progression of\ncognitive functioning, such as cognitive scores and cognitive decline. This\nreport examines how these social, environmental, and structural factors impact\ncognitive health trajectories, with a particular focus on Hispanic populations,\nwho face disproportionate risk for AD\/ADRD. Using data from the Mexican Health\nand Aging Study (MHAS) and its cognitive assessment sub study (Mex-Cog), we\nemployed ensemble of regression trees models to predict 4-year and 9-year\ncognitive scores and cognitive decline based on SDOH. This approach identified\nkey predictive SDOH factors to inform potential multilevel interventions to\naddress cognitive health disparities in this population."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08719"
    ],
    "c_title":[
      "Extrapolated Hard Thresholding Algorithms with Finite Length for\n  Composite $\\ell_0$ Penalized Problems"
    ],
    "c_abstract":[
      "For a class of sparse optimization problems with the penalty function of\n$\\|(\\cdot)_+\\|_0$, we first characterize its local minimizers and then propose\nan extrapolated hard thresholding algorithm to solve such problems. We show\nthat the iterates generated by the proposed algorithm with $\\epsilon>0$ (where\n$\\epsilon$ is the dry friction coefficient) have finite length, without relying\non the Kurdyka-{\\L}ojasiewicz inequality. Furthermore, we demonstrate that the\nalgorithm converges to an $\\epsilon$-local minimizer of this problem. For the\nspecial case that $\\epsilon=0$, we establish that any accumulation point of the\niterates is a local minimizer of the problem. Additionally, we analyze the\nconvergence when an error term is present in the algorithm, showing that the\nalgorithm still converges in the same manner as before, provided that the\nerrors asymptotically approach zero. Finally, we conduct numerical experiments\nto verify the theoretical results of the proposed algorithm."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-418",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16534"
    ],
    "b_title":[
      "Multilingual != Multicultural: Evaluating Gaps Between Multilingual\n  Capabilities and Cultural Alignment in LLMs"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are becoming increasingly capable across global\nlanguages. However, the ability to communicate across languages does not\nnecessarily translate to appropriate cultural representations. A key concern is\nUS-centric bias, where LLMs reflect US rather than local cultural values. We\npropose a novel methodology that compares LLM-generated response distributions\nagainst population-level opinion data from the World Value Survey across four\nlanguages (Danish, Dutch, English, and Portuguese). Using a rigorous linear\nmixed-effects regression framework, we compare two families of models: Google's\nGemma models (2B--27B parameters) and successive iterations of OpenAI's\nturbo-series. Across the families of models, we find no consistent\nrelationships between language capabilities and cultural alignment. While the\nGemma models have a positive correlation between language capability and\ncultural alignment across languages, the OpenAI models do not. Importantly, we\nfind that self-consistency is a stronger predictor of multicultural alignment\nthan multilingual capabilities. Our results demonstrate that achieving\nmeaningful cultural alignment requires dedicated effort beyond improving\ngeneral language capabilities."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14847"
    ],
    "c_title":[
      "Efficient Lower Bounding of Single Transferable Vote Election Margins"
    ],
    "c_abstract":[
      "The single transferable vote (STV) is a system of preferential proportional\nvoting employed in multi-seat elections. Each ballot cast by a voter is a\n(potentially partial) ranking over a set of candidates. The margin of victory,\nor simply margin, is the smallest number of ballots that, if manipulated (e.g.,\ntheir rankings changed, or ballots being deleted or added), can alter the set\nof winners. Knowledge of the margin of an election gives greater insight into\nboth how much time and money should be spent on auditing the election, and\nwhether uncovered mistakes (such as ballot box losses) throw the election\nresult into doubt -- requiring a costly repeat election -- or can be safely\nignored. Lower bounds on the margin can also be used for this purpose, in cases\nwhere exact margins are difficult to compute. There is one existing approach to\ncomputing lower bounds on the margin of STV elections, while there are multiple\napproaches to finding upper bounds. In this paper, we present improvements to\nthis existing lower bound computation method for STV margins. In many cases the\nimprovements compute tighter (higher) lower bounds as well as making the\ncomputation of lower bounds more computationally efficient. For small\nelections, in conjunction with existing upper bounding approaches, the new\nalgorithms are able to compute exact margins of victory."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.GT",
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-419",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02031"
    ],
    "b_title":[
      "A Comparative Modelling of Essential Characteristics of Volatility:\n  Simulation and Empirical Study"
    ],
    "b_abstract":[
      "This study utilised the dynamics of five time-varying models to estimate six\nessential features of financial return volatility that are relevant for robust\nrisk management. These features include pronounced persistence, mean reversion,\nleverage effect or volatility asymmetry, conditional skewness, conditional\nfat-tailedness, and the long memory behaviour of volatility decomposition into\nlong-term and short-term components. Both simulation and empirical evidence are\nprovided. Through the applications of these models using the S&P Indian index,\nthe study shows that the market returns are characterised by these volatility\nfeatures. Our findings from the long-memory behaviour revealed that although\nthe response to shocks is greater in the short-term component, it is however\nshort-lived. On the contrary, despite a high degree of persistence in the\nlong-term component, market information or unexpected news arrival only has a\nlow long-run impact on the market. Based on this, the long-run investment risks\nwithin the Indian stock market seem to be under control. Hence, our findings\nsuggest that rational investors should try to stay calm with the arrival of\nunexpected news in the market because the long-run effect of such news will not\nbe severe, and the market will eventually return to its normal state."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.00430"
    ],
    "c_title":[
      "Performance-Driven Optimization of Parallel Breadth-First Search"
    ],
    "c_abstract":[
      "Breadth-first search (BFS) is a fundamental graph algorithm that presents\nsignificant challenges for parallel implementation due to irregular memory\naccess patterns, load imbalance and synchronization overhead. In this paper, we\nintroduce a set of optimization strategies for parallel BFS on multicore\nsystems, including hybrid traversal, bitmap-based visited set, and a novel\nnon-atomic distance update mechanism. We evaluate these optimizations across\ntwo different architectures - a 24-core Intel Xeon platform and a 128-core AMD\nEPYC system - using a diverse set of synthetic and real-world graphs. Our\nresults demonstrate that the effectiveness of optimizations varies\nsignificantly based on graph characteristics and hardware architecture. For\nsmall-diameter graphs, our hybrid BFS implementation achieves speedups of 3-8x\non the Intel platform and $3-10\\times$ on the AMD system compared to a\nconventional parallel BFS implementation. However, the performance of\nlarge-diameter graphs is more nuanced, with some of the optimizations showing\nvaried performance across platforms including performance degradation in some\ncases."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-420",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01283"
    ],
    "b_title":[
      "Covariant non-perturbative pointer variables for quantum fields"
    ],
    "b_abstract":[
      "We describe the dynamics of a detector modeled by a harmonic oscillator\ncoupled with an otherwise free quantum field in a curved spacetime in terms of\ncovariant equations of motion leading to local observables. To achieve this, we\nderive and renormalize the integro-differential equation that governs the\ndetector pointer-variable dynamics, introducing phenomenological parameters\nsuch as a dispersion coefficient and a Lamb-shift parameter. Our formal\nsolution, expressed in terms of Green's functions, allows for the covariant,\nand causal analysis of induced observables on the field. This formalism can be\nused for instance to detect non-Gaussianities present in the field's state."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.18025"
    ],
    "c_title":[
      "Decision from Suboptimal Classifiers: Excess Risk Pre- and\n  Post-Calibration"
    ],
    "c_abstract":[
      "Probabilistic classifiers are central for making informed decisions under\nuncertainty. Based on the maximum expected utility principle, optimal decision\nrules can be derived using the posterior class probabilities and\nmisclassification costs. Yet, in practice only learned approximations of the\noracle posterior probabilities are available. In this work, we quantify the\nexcess risk (a.k.a. regret) incurred using approximate posterior probabilities\nin batch binary decision-making. We provide analytical expressions for\nmiscalibration-induced regret ($R^{\\mathrm{CL}}$), as well as tight and\ninformative upper and lower bounds on the regret of calibrated classifiers\n($R^{\\mathrm{GL}}$). These expressions allow us to identify regimes where\nrecalibration alone addresses most of the regret, and regimes where the regret\nis dominated by the grouping loss, which calls for post-training beyond\nrecalibration. Crucially, both $R^{\\mathrm{CL}}$ and $R^{\\mathrm{GL}}$ can be\nestimated in practice using a calibration curve and a recent grouping loss\nestimator. On NLP experiments, we show that these quantities identify when the\nexpected gain of more advanced post-training is worth the operational cost.\nFinally, we highlight the potential of multicalibration approaches as efficient\nalternatives to costlier fine-tuning approaches."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-421",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16601"
    ],
    "b_title":[
      "SOFIA: Singularities of Feynman Integrals Automatized"
    ],
    "b_abstract":[
      "We introduce SOFIA, a Mathematica package that automatizes the computation of\nsingularities of Feynman integrals, based on new theoretical understanding of\ntheir analytic structure. Given a Feynman diagram, SOFIA generates a list of\npotential singularities along with a candidate symbol alphabet. The package\nalso provides a comprehensive set of tools for analyzing the analytic\nproperties of Feynman integrals and related objects, such as cosmological and\nenergy correlators. We showcase its capabilities by reproducing known results\nand predicting singularities and symbol alphabets of Feynman integrals at and\nbeyond the high-precision frontier."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17763"
    ],
    "c_title":[
      "Design and implementation of a distributed security threat detection\n  system integrating federated learning and multimodal LLM"
    ],
    "c_abstract":[
      "Traditional security protection methods struggle to address sophisticated\nattack vectors in large-scale distributed systems, particularly when balancing\ndetection accuracy with data privacy concerns. This paper presents a novel\ndistributed security threat detection system that integrates federated learning\nwith multimodal large language models (LLMs). Our system leverages federated\nlearning to ensure data privacy while employing multimodal LLMs to process\nheterogeneous data sources including network traffic, system logs, images, and\nsensor data. Experimental evaluation on a 10TB distributed dataset demonstrates\nthat our approach achieves 96.4% detection accuracy, outperforming traditional\nbaseline models by 4.1 percentage points. The system reduces both false\npositive and false negative rates by 1.8 and 2.4 percentage points\nrespectively. Performance analysis shows that our system maintains efficient\nprocessing capabilities in distributed environments, requiring 180 seconds for\nmodel training and 3.8 seconds for threat detection across the distributed\nnetwork. These results demonstrate significant improvements in detection\naccuracy and computational efficiency while preserving data privacy, suggesting\nstrong potential for real-world deployment in large-scale security systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.PF"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-422",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07733"
    ],
    "b_title":[
      "In Search of the First Stars: An Ultra-Compact and Very Low Metallicity\n  Lyman-$\\alpha$ Emitter Deep Within the Epoch of Reionization"
    ],
    "b_abstract":[
      "We present {\\it JWST} observations of a gravitationally-lensed, extremely\nmetal-poor galaxy at redshift $z=8.203\\pm 0.001$ from the CANUCS survey. Based\non the low oxygen to Balmer line ratios we infer a gas-phase metallicity of\n$12+{\\rm log(O\/H)}=6.85$ (1.4\\% solar), making CANUCS-A370-z8-LAE the most\nmetal-poor galaxy known at $z>7$. With a high H$\\beta$ equivalent width of\n$225\\pm50$\\,\\AA\\ and a half-light radius of only $r_{\\rm hl} = 38 ^{+3}_{-19}\n$\\,pc, the galaxy has a high star-formation-rate density of $50 -\n100\\,M_{\\odot}$\\,yr$^{-1}$\\,kpc$^{-2}$. The galaxy shows high equivalent width\nLyman-$\\alpha$ emission with an inferred Lyman-$\\alpha$ escape fraction of\n$0.21 \\pm 0.05$. The high escape fraction of Lyman-$\\alpha$ is likely due to\nthe compact starbursting nature of the galaxy combined with its location in an\noverdensity traced by at least two other galaxies spectroscopically confirmed\nto lie within $\\delta z = 0.01$ that have helped to reionize the environment.\nThe low metallicity of CANUCS-A370-z8-LAE is best explained by a model where\ninfalling metal-poor gas dilutes the interstellar medium, rather than being a\nyoung galaxy forming its first stellar populations."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17475"
    ],
    "c_title":[
      "Spatiotemporal Learning with Context-aware Video Tubelets for Ultrasound\n  Video Analysis"
    ],
    "c_abstract":[
      "Computer-aided pathology detection algorithms for video-based imaging\nmodalities must accurately interpret complex spatiotemporal information by\nintegrating findings across multiple frames. Current state-of-the-art methods\noperate by classifying on video sub-volumes (tubelets), but they often lose\nglobal spatial context by focusing only on local regions within detection ROIs.\nHere we propose a lightweight framework for tubelet-based object detection and\nvideo classification that preserves both global spatial context and fine\nspatiotemporal features. To address the loss of global context, we embed\ntubelet location, size, and confidence as inputs to the classifier.\nAdditionally, we use ROI-aligned feature maps from a pre-trained detection\nmodel, leveraging learned feature representations to increase the receptive\nfield and reduce computational complexity. Our method is efficient, with the\nspatiotemporal tubelet classifier comprising only 0.4M parameters. We apply our\napproach to detect and classify lung consolidation and pleural effusion in\nultrasound videos. Five-fold cross-validation on 14,804 videos from 828\npatients shows our method outperforms previous tubelet-based approaches and is\nsuited for real-time workflows."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-423",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07754"
    ],
    "b_title":[
      "Unveiling stellar spin: Determining inclination angles in Be stars"
    ],
    "b_abstract":[
      "The physical properties of stellar atmospheres in rapidly rotating massive\nstars, such as Be stars, are critical to understanding their evolution and\ntheir role as progenitors of supernovae. These stars, which often have\nnear-critical rotation, exhibit equatorial stretching and gravity darkening,\nwhich significantly complicates the determination of parameters such as the\ninclination angle. Be stars, characterized by their extreme rotational\nvelocities, serve as excellent candidates for exploring these phenomena.\nHowever, fundamental quantities such as polar and equatorial radii and\ninclination angles are typically derived from interferometry, which applies\nonly to a limited number of stars. This study aims to enhance the determination\nof inclination angles for Be stars using the ZPEKTR spectral synthesis code. By\nincorporating advanced models of gravity darkening and stellar deformation, we\nevaluated the effectiveness of this method with a sample of ten Be stars from\nthe BeSOS database, comparing results with established interferometric data.\nMethods. We used the ZPEKTR code to model the effects of stellar oblateness and\ngravity darkening on spectral lines, focusing on the HeI 4471 line. We applied\na chi-squared test minimization approach to identify the best-fitting models,\nand we evaluated the inclination angles derived against interferometric\nmeasurements. Our analysis reveals a robust linear correlation between the\ninclination angles derived from ZPEKTR and using interferometric techniques,\nwhich demonstrates an excellent agreement. The ZPEKTR code effectively models\nhigh rotational velocity effects, providing precise stellar parameter\ndeterminations. The results underscore the potential of advanced spectroscopic\ntechniques to yield inclination measurements comparable to interferometry,\nwhich offers a pathway to studying distant massive stars."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.15224"
    ],
    "c_title":[
      "Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs"
    ],
    "c_abstract":[
      "Given the remarkable performance of Large Language Models (LLMs), an\nimportant question arises: Can LLMs conduct human-like scientific research and\ndiscover new knowledge, and act as an AI scientist? Scientific discovery is an\niterative process that demands efficient knowledge updating and encoding. It\ninvolves understanding the environment, identifying new hypotheses, and\nreasoning about actions; however, no standardized benchmark specifically\ndesigned for scientific discovery exists for LLM agents. In response to these\nlimitations, we introduce a novel benchmark, \\textit{Auto-Bench}, that\nencompasses necessary aspects to evaluate LLMs for scientific discovery in both\nnatural and social sciences. Our benchmark is based on the principles of causal\ngraph discovery. It challenges models to uncover hidden structures and make\noptimal decisions, which includes generating valid justifications. By engaging\ninteractively with an oracle, the models iteratively refine their understanding\nof underlying interactions, the chemistry and social interactions, through\nstrategic interventions. We evaluate state-of-the-art LLMs, including GPT-4,\nGemini, Qwen, Claude, and Llama, and observe a significant performance drop as\nthe problem complexity increases, which suggests an important gap between\nmachine and human intelligence that future development of LLMs need to take\ninto consideration."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-424",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01396"
    ],
    "b_title":[
      "CorrNetDroid: Android Malware Detector leveraging a Correlation-based\n  Feature Selection for Network Traffic features"
    ],
    "b_abstract":[
      "Copious mobile operating systems exist in the market, but Android remains the\nuser's choice. Meanwhile, its growing popularity has also attracted malware\ndevelopers. Researchers have proposed various static solutions for Android\nmalware detection. However, stealthier malware evade static analysis. This\nraises the need for a robust Android malware detection system capable of\ndealing with advanced threats and overcoming the shortcomings of static\nanalysis.\n  Hence, this work proposes a dynamic analysis-based Android malware detection\nsystem, CorrNetDroid, that works over network traffic flows. Many traffic\nfeatures exhibit overlapping ranges in normal and malware datasets. Therefore,\nwe first rank the features using two statistical measures, crRelevance and\nNormalized Mean Residue Similarity (NMRS), to assess feature-class and\nfeature-feature correlations. Thereafter, we introduce a novel\ncorrelation-based feature selection algorithm that applies NMRS on crRelevance\nrankings to identify the optimal feature subset for Android malware detection.\n  Experimental results highlight that our model effectively reduces the feature\nset while detecting Android malware with 99.50 percent accuracy when\nconsidering only two network traffic features. Furthermore, our experiments\ndemonstrate that the NMRS-based algorithm on crRelevance rankings outperforms\nstatistical tests such as chi-square, ANOVA, Mann-Whitney U test, and\nKruskal-Wallis test. In addition, our model surpasses various state-of-the-art\nAndroid malware detection techniques in terms of detection accuracy."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.MM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16026"
    ],
    "c_title":[
      "Dynamical systems for remote validation of very high-resolution ocean\n  models"
    ],
    "c_abstract":[
      "This paper presents and investigates a novel methodology for validating\nhigh-resolution ocean models using satellite imagery. High-resolution ocean\nmodels provide detailed information in coastal areas where other available data\nproducts are too coarse. Models are usually fitted by comparing them with\nobservations; However, accessing in situ data in all small coastal areas is not\nfeasible, as in situ observations are scarce and obtained through dedicated\nships or instruments in limited and selected regions. Our work aims to use\nalternative remote sensing information to overcome this challenge. The approach\ninvolves establishing connections between the satellite observations and the\noutcomes of various computational experiments carried out using the Regional\nOcean Modeling System (ROMS), which allows the selection of different\nparameters to run the ocean model. These choices are not fully determined a\npriori and each one produces distinct outputs, which are then linked to the\nimages through dynamical systems objects. By defining a performance index, we\nare able to quantify which experiment provides a better representation of the\nlocal ocean state."
    ],
    "c_categories":[
      [
        "math.DS",
        "nlin.CD",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-425",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02822"
    ],
    "b_title":[
      "RDD4D: 4D Attention-Guided Road Damage Detection And Classification"
    ],
    "b_abstract":[
      "Road damage detection and assessment are crucial components of infrastructure\nmaintenance. However, current methods often struggle with detecting multiple\ntypes of road damage in a single image, particularly at varying scales. This is\ndue to the lack of road datasets with various damage types having varying\nscales. To overcome this deficiency, first, we present a novel dataset called\nDiverse Road Damage Dataset (DRDD) for road damage detection that captures the\ndiverse road damage types in individual images, addressing a crucial gap in\nexisting datasets. Then, we provide our model, RDD4D, that exploits Attention4D\nblocks, enabling better feature refinement across multiple scales. The\nAttention4D module processes feature maps through an attention mechanism\ncombining positional encoding and \"Talking Head\" components to capture local\nand global contextual information. In our comprehensive experimental analysis\ncomparing various state-of-the-art models on our proposed, our enhanced model\ndemonstrated superior performance in detecting large-sized road cracks with an\nAverage Precision (AP) of 0.458 and maintained competitive performance with an\noverall AP of 0.445. Moreover, we also provide results on the CrackTinyNet\ndataset; our model achieved around a 0.21 increase in performance. The code,\nmodel weights, dataset, and our results are available on\n\\href{https:\/\/github.com\/msaqib17\/Road_Damage_Detection}{https:\/\/github.com\/msaqib17\/Road\\_Damage\\_Detection}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09488"
    ],
    "c_title":[
      "Foundation Neural-Network Quantum States"
    ],
    "c_abstract":[
      "Foundation models are highly versatile neural-network architectures capable\nof processing different data types, such as text and images, and generalizing\nacross various tasks like classification and generation. Inspired by this\nsuccess, we propose Foundation Neural-Network Quantum States (FNQS) as an\nintegrated paradigm for studying quantum many-body systems. FNQS leverage key\nprinciples of foundation models to define variational wave functions based on a\nsingle, versatile architecture that processes multimodal inputs, including spin\nconfigurations and Hamiltonian physical couplings. Unlike specialized\narchitectures tailored for individual Hamiltonians, FNQS can generalize to\nphysical Hamiltonians beyond those encountered during training, offering a\nunified framework adaptable to various quantum systems and tasks. FNQS enable\nthe efficient estimation of quantities that are traditionally challenging or\ncomputationally intensive to calculate using conventional methods, particularly\ndisorder-averaged observables. Furthermore, the fidelity susceptibility can be\neasily obtained to uncover quantum phase transitions without prior knowledge of\norder parameters. These pretrained models can be efficiently fine-tuned for\nspecific quantum systems. The architectures trained in this paper are publicly\navailable at https:\/\/huggingface.co\/nqs-models, along with examples for\nimplementing these neural networks in NetKet."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-426",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11126"
    ],
    "b_title":[
      "SIC-free Multicast Scheduling for Multi-antenna Coded Caching"
    ],
    "b_abstract":[
      "Multi-antenna coded caching (CC) with multicast beamforming typically relies\non a complex successive interference cancellation (SIC) structure to decode a\nsuperposition of multiple streams received by each user. Signal-level CC\nschemes require the regeneration and cancellation of interfering signals at the\nphysical layer of each receiver, which complicates practical implementations.\nTo address this, we propose a bit-level multicast scheduling scheme enabling\nlinear, SIC-free decoding of parallel streams by repeatedly transmitting data\nterms with linearly independent coefficients. Two reference strategies and a\nnovel sparse strategy are considered for constructing the coefficient matrix.\nThe reference cases include the random strategy, which lacks control over\nmatrix construction, and the equal-distant strategy, which balances users'\ninterference and data terms equally. In contrast, the sparse strategy minimizes\nthe number of multicast streams transmitted in parallel during each interval.\nThis approach simplifies both the decoding process and the beamforming design\nby decoupling the desired data terms for each user and reducing the number of\nSINR constraints, respectively. To further enhance the symmetric rate, a\nsuccessive projection algorithm is applied to exploit channel properties and\noptimize user ordering. With the coefficient matrix and optimized user ordering\nin place, multicast beamformers are devised to aggregate desired data from\nrelevant multicast streams. Numerical simulations validate the effectiveness of\nthe sparse strategy and user scheduling, demonstrating significant gains in\nsymmetric rate."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10732"
    ],
    "c_title":[
      "Enhanced kinematics and distribution characteristics of Upper Scorpius\n  and Ophiuchus associations based on Gaia DR3"
    ],
    "c_abstract":[
      "The kinematics within the Solar vicinity have revealed interesting features\nrelevant to both stellar and Galactic structures. This study examines three\nstellar associations in the Upper Scorpius and Ophiuchus regions, along with\ntheir sub-samples among Gaia DR3. The calculated kinematics and velocity\nellipsoid characteristics, including the mean spatial velocity components (U,\nV, W)."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-427",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09864"
    ],
    "b_title":[
      "Quantitative analysis of vectorial torques in thin 3d Co ferromagnet\n  using orbital-spin conversion"
    ],
    "b_abstract":[
      "Recent findings in orbitronics pointed out large current-induced torques\noriginating, in the current understanding, from incident orbital currents.\nThese are generated by orbital Rashba-Edelstein effect (OREE) produced at the\ninterface between some light metal and oxides films e.g. by naturally oxidized\ncopper layer (Cu*). In the present work, by using second harmonic Hall\ntechniques, we determine the ratio of orbital vs spin currents exerting torques\non thin transition metals Co ferromagnet in systems using an orbit-to-spin Pt\nconverter as interlayer with Cu*. Our results quantifying damping like torques\nshow that both orbital and spin currents are enhanced in these systems.\nMoreover, the experimental determination of the decoherence length in a sample\nseries with varying Co thickness clearly demonstrates the interfacial\ngeneration of the orbital currents in Cu* by Orbital Rashba-Edelstein effects\n(REE) leading to subsequent magnetic torque in Co over a typical lengthscale of\nseveral nanometers"
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05336"
    ],
    "c_title":[
      "Leveraging Order-Theoretic Tournament Graphs for Assessing Internal\n  Consistency in Survey-Based Instruments Across Diverse Scenarios"
    ],
    "c_abstract":[
      "This paper introduces Monotone Delta, an order-theoretic measure designed to\nenhance the reliability assessment of survey-based instruments in human-machine\ninteractions. Traditional reliability measures, such as Cronbach's Alpha and\nMcDonald's Omega, often yield misleading estimates due to their sensitivity to\nredundancy, multidimensional constructs, and assumptions of normality and\nuncorrelated errors. These limitations can compromise decision-making in\nhuman-centric evaluations, where survey instruments inform adaptive interfaces,\ncognitive workload assessments, and human-AI trust models. Monotone Delta\naddresses these issues by quantifying internal consistency through the\nminimization of ordinal contradictions and alignment with a unidimensional\nlatent order using weighted tournaments. Unlike traditional approaches, it\noperates without parametric or model-based assumptions. We conducted\ntheoretical analyses and experimental evaluations on four challenging\nscenarios: tau-equivalence, redundancy, multidimensionality, and non-normal\ndistributions, and proved that Monotone Delta provides more stable reliability\nassessments compared to existing methods. The Monotone Delta is a valuable\nalternative for evaluating questionnaire-based assessments in psychology, human\nfactors, healthcare, and interactive system design, enabling organizations to\noptimize survey instruments, reduce costly redundancies, and enhance confidence\nin human-system interactions."
    ],
    "c_categories":[
      [
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-428",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12282"
    ],
    "b_title":[
      "Complexity of Jelly-No and Hanano games with various constraints"
    ],
    "b_abstract":[
      "This work shows new results on the complexity of games Jelly-No and Hanano\nwith various constraints on the size of the board and number of colours. Hanano\nand Jelly-No are one-player, 2D side-view puzzle games with a dynamic board\nconsisting of coloured, movable blocks disposed on platforms. These blocks can\nbe moved by the player and are subject to gravity. Both games somehow vary in\ntheir gameplay, but the goal is always to move the coloured blocks in order to\nreach a specific configuration and make them interact with each other or with\nother elements of the game. In Jelly-No the goal is to merge all coloured\nblocks of a same colour, which also happens when they make contact. In Hanano\nthe goal is to make all the coloured blocks bloom by making contact with\nflowers of the same colour. Jelly-No was proven by Chao Yang to be NP-Complete\nunder the restriction that all movable blocks are the same colour and NP-Hard\nfor more colours. Hanano was proven by Michael C. Chavrimootoo to be\nPSPACE-Complete under the restriction that all movable blocks are the same\ncolour. However, the question whether Jelly-No for more than one colours is\nalso PSPACE-complete or if it too stays in NP was left open. In this paper, we\nsettle this question, proving that Jelly-No is PSPACE-Complete with an\nunbounded number of colours. We further show that, if we allow black jellies\n(that is, jellies that do not need to be merged), the game is PSPACE-complete\neven for one colour. We further show that one-colour Jelly-No and Hanano remain\nNP-Hard even if the width or the height of the board are small constants."
    ],
    "b_categories":[
      [
        "cs.CC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07714"
    ],
    "c_title":[
      "Relativistic ions with power-law spectra explain radio phoenixes"
    ],
    "c_abstract":[
      "Radio phoenixes are filamentary sources in the intracluster medium (ICM) of\ngalaxy clusters, often extending over $>100$ kpc, arising from fossil radio\nlobes. Their soft, curved spectrum is widely attributed to aged relativistic\nelectrons recently accelerated or compressed, but at high frequencies is shown\nto approach a power-law. Moreover, the full, curved spectrum is naturally\nreproduced by secondary $e^{\\pm}$ from a pure power-law spectrum of\nrelativistic ions, radiating in highly-magnetized filaments; this model\nprovides a better fit to all phoenixes, with only three free parameters. Weaker\nmagnetization shifts the curvature to low frequencies, explaining pure\npower-law phoenixes. Hadronic high-curvature phoenixes require $e^{\\pm}$\nheating, by a factor $\\gtrsim 15$ if at ICM pressure. The $\\sim$keV Compton-\nand $\\sim$GeV $\\pi^0$-decay-peaked counterparts of hadronic phoenixes may be\ndetectable as non-thermal X-rays and $\\gamma$-rays."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-429",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18140"
    ],
    "b_title":[
      "Trace conjunction inequalities"
    ],
    "b_abstract":[
      "Trace conjunction integrals are introduced and studied. They appear in trace\nconjunction inequalities which unify the Hardy inequality on a halfspace and\nthe classical Gagliardo trace inequality. At the endpoint they satisfy a\nBourgain-Brezis-Mironescu formula for smooth maps, which raises some new open\nproblems."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.05211"
    ],
    "c_title":[
      "Decoding FL Defenses: Systemization, Pitfalls, and Remedies"
    ],
    "c_abstract":[
      "While the community has designed various defenses to counter the threat of\npoisoning attacks in Federated Learning (FL), there are no guidelines for\nevaluating these defenses. These defenses are prone to subtle pitfalls in their\nexperimental setups that lead to a false sense of security, rendering them\nunsuitable for practical deployment. In this paper, we systematically\nunderstand, identify, and provide a better approach to address these\nchallenges. First, we design a comprehensive systemization of FL defenses along\nthree dimensions: i) how client updates are processed, ii) what the server\nknows, and iii) at what stage the defense is applied. Next, we thoroughly\nsurvey 50 top-tier defense papers and identify the commonly used components in\ntheir evaluation setups. Based on this survey, we uncover six distinct pitfalls\nand study their prevalence. For example, we discover that around 30% of these\nworks solely use the intrinsically robust MNIST dataset, and 40% employ\nsimplistic attacks, which may inadvertently portray their defense as robust.\nUsing three representative defenses as case studies, we perform a critical\nreevaluation to study the impact of the identified pitfalls and show how they\nlead to incorrect conclusions about robustness. We provide actionable\nrecommendations to help researchers overcome each pitfall."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-430",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12159"
    ],
    "b_title":[
      "Paving the way to carbon neutrality: Evaluating the decarbonization of\n  residential building electrification worldwide"
    ],
    "b_abstract":[
      "In the context of increasing global climate change, decarbonizing the\nresidential building sector is crucial for sustainable development. This study\nis the first to analyze the role of various influencing factors in carbon\nintensity changes using the decomposing structural decomposition (DSD) to\nassess and compare the potential and effectiveness of electrifying end-use\nactivities during the operational phase of residential buildings worldwide for\ndecarbonization. The results show that (1) while the electrification rate\nvaried in its impact on emissions across different countries and regions, the\noverall increase in electrification contributed to higher carbon intensity. In\ncontrast, changes in the emission factor of electricity generally made a\npositive contribution to emission reduction globally. (2) The global\nelectrification level has significantly increased, with the electrification\nrate rising from 29.9% in 2000 to 40.1% in 2021. A 39.8% increase in the\nelectricity-related carbon emissions of global residential buildings was\nobserved, increasing from 1452 MtCO2 to 2032 MtCO2, 2000-2021. (3) From 2000 to\n2021, electrification of space heating was the main contributor to carbon\nreduction, whereas the contributions of electrification to cooling and lighting\nwere relatively limited. Emission reductions from appliances and others\nremained stable. The electrification of water heating and cooking had varying\neffects on emission reductions in different countries. Furthermore, this study\nproposes a series of electrification decarbonization strategies. Overall, this\nstudy analyzes and contrasts decarbonization efforts from building\nelectrification at the global and regional levels, explores the key motivations\nbehind these efforts to aid national net-zero emission targets and accelerate\nthe transition of the global residential building sector toward a\ncarbon-neutral future."
    ],
    "b_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.07474"
    ],
    "c_title":[
      "Estimating Musical Surprisal in Audio"
    ],
    "c_abstract":[
      "In modeling musical surprisal expectancy with computational methods, it has\nbeen proposed to use the information content (IC) of one-step predictions from\nan autoregressive model as a proxy for surprisal in symbolic music. With an\nappropriately chosen model, the IC of musical events has been shown to\ncorrelate with human perception of surprise and complexity aspects, including\ntonal and rhythmic complexity. This work investigates whether an analogous\nmethodology can be applied to music audio. We train an autoregressive\nTransformer model to predict compressed latent audio representations of a\npretrained autoencoder network. We verify learning effects by estimating the\ndecrease in IC with repetitions. We investigate the mean IC of musical segment\ntypes (e.g., A or B) and find that segment types appearing later in a piece\nhave a higher IC than earlier ones on average. We investigate the IC's relation\nto audio and musical features and find it correlated with timbral variations\nand loudness and, to a lesser extent, dissonance, rhythmic complexity, and\nonset density related to audio and musical features. Finally, we investigate if\nthe IC can predict EEG responses to songs and thus model humans' surprisal in\nmusic. We provide code for our method on github.com\/sonycslparis\/audioic."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-431",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14948"
    ],
    "b_title":[
      "HECLIP: Histology-Enhanced Contrastive Learning for Imputation of\n  Transcriptomics Profiles"
    ],
    "b_abstract":[
      "Histopathology, particularly hematoxylin and eosin (H\\&E) staining, plays a\ncritical role in diagnosing and characterizing pathological conditions by\nhighlighting tissue morphology. However, H\\&E-stained images inherently lack\nmolecular information, requiring costly and resource-intensive methods like\nspatial transcriptomics to map gene expression with spatial resolution. To\naddress these challenges, we introduce HECLIP (Histology-Enhanced Contrastive\nLearning for Imputation of Profiles), an innovative deep learning framework\nthat bridges the gap between histological imaging and molecular profiling.\nHECLIP is specifically designed to infer gene expression profiles directly from\nH\\&E-stained images, eliminating the need for expensive spatial transcriptomics\nassays. HECLIP leverages an advanced image-centric contrastive loss function to\noptimize image representation learning, ensuring that critical morphological\npatterns in histology images are effectively captured and translated into\naccurate gene expression profiles. This design enhances the predictive power of\nthe image modality while minimizing reliance on gene expression data. Through\nextensive benchmarking on publicly available datasets, HECLIP demonstrates\nsuperior performance compared to existing approaches, delivering robust and\nbiologically meaningful predictions. Detailed ablation studies further\nunderscore its effectiveness in extracting molecular insights from histology\nimages. Additionally, HECLIP's scalable and cost-efficient approach positions\nit as a transformative tool for both research and clinical applications,\ndriving advancements in precision medicine. The source code for HECLIP is\nopenly available at https:\/\/github.com\/QSong-github\/HECLIP."
    ],
    "b_categories":[
      [
        "cs.CE",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10023"
    ],
    "c_title":[
      "Using Context to Improve Word Segmentation"
    ],
    "c_abstract":[
      "An important step in understanding how children acquire languages is studying\nhow infants learn word segmentation. It has been established in previous\nresearch that infants may use statistical regularities in speech to learn word\nsegmentation. The research of Goldwater et al., demonstrated that incorporating\ncontext in models improves their ability to learn word segmentation. We\nimplemented two of their models, a unigram and bigram model, to examine how\ncontext can improve statistical word segmentation. The results are consistent\nwith our hypothesis that the bigram model outperforms the unigram model at\npredicting word segmentation. Extending the work of Goldwater et al., we also\nexplored basic ways to model how young children might use previously learned\nwords to segment new utterances."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-432",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09457"
    ],
    "b_title":[
      "Effective conductivity of conduit networks with random conductivities"
    ],
    "b_abstract":[
      "The effective conductivity ($T^{eff}$) of 2D and 3D Random Resistor Networks\n(RRNs) with random edge conductivity is studied. The combined influence of\ngeometrical disorder, which controls the overall connectivity of the medium and\nleads to percolation effects, and conductivity randomness is investigated. A\nformula incorporating connectivity aspects and second-order averaging methods,\nwidely used in the stochastic hydrology community, is derived and extrapolated\nto higher orders using a power averaging formula based on a mean-field\nargument. This approach highlights the role of the so-called resistance\ndistance introduced by graph theorists. Simulations are performed on various\nRRN geometries constructed from 2D and 3D bond-percolation lattices. The\nresults confirm the robustness of the power averaging technique and the\nrelevance of the mean-field assumption."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05875"
    ],
    "c_title":[
      "Extended weak order for the affine symmetric group"
    ],
    "c_abstract":[
      "The extended weak order on a Coxeter group $W$ is the poset of biclosed sets\nin its root system. In (Barkley-Speyer 2024), it was shown that when\n$W=\\widetilde{S}_n$ is the affine symmetric group, then the extended weak order\nis a quotient of the lattice $L_n$ of translation-invariant total orderings of\nthe integers. In this article, we give a combinatorial introduction to $L_n$\nand the extended weak order on $\\widetilde{S}_n$. We show that $L_n$ is an\nalgebraic completely semidistributive lattice. We describe its canonical join\nrepresentations using a cyclic version of Reading's non-crossing arc diagrams.\nWe also show analogous statements for the lattice of all total orders of the\nintegers, which is the extended weak order on the symmetric group $S_\\infty$. A\nkey property of both of these lattices is that they are profinite; we also\nprove that a profinite lattice is join semidistributive if and only if its\ncompact elements have canonical join representations. We conjecture that the\nextended weak order of any Coxeter group is a profinite semidistributive\nlattice."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-433",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03578"
    ],
    "b_title":[
      "Four-body coupler for superconducting qubits based on Josephson\n  parametric oscillators"
    ],
    "b_abstract":[
      "We theoretically propose a circuit of the four-body coupler for\nsuperconducting qubits based on Josephson parametric oscillators (JPOs). Our\ncoupler for the four-body interaction has a superconducting loop, similar to a\ncapacitively shunted flux qubit, where an external magnetic flux set to half a\nflux quantum is threaded. This coupler circuit is a specific setup of the\ncircuit called superconducting nonlinear asymmetric inductive elements (SNAIL)\nand also is a generalization of the previously proposed one for the four-body\ninteraction of JPOs. We clarify roles of circuit parameters in the four-body\ninteraction and, in particular, show that the four-body coupling constant in\nour circuit can be significantly increased by tuning capacitance of the coupler\nor the area ratio of the Josephson junctions of the coupler."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.01830"
    ],
    "c_title":[
      "Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large\n  Language Models"
    ],
    "c_abstract":[
      "Automated red-teaming has become a crucial approach for uncovering\nvulnerabilities in large language models (LLMs). However, most existing methods\nfocus on isolated safety flaws, limiting their ability to adapt to dynamic\ndefenses and uncover complex vulnerabilities efficiently. To address this\nchallenge, we propose Auto-RT, a reinforcement learning framework that\nautomatically explores and optimizes complex attack strategies to effectively\nuncover security vulnerabilities through malicious queries. Specifically, we\nintroduce two key mechanisms to reduce exploration complexity and improve\nstrategy optimization: 1) Early-terminated Exploration, which accelerate\nexploration by focusing on high-potential attack strategies; and 2) Progressive\nReward Tracking algorithm with intermediate downgrade models, which dynamically\nrefine the search trajectory toward successful vulnerability exploitation.\nExtensive experiments across diverse LLMs demonstrate that, by significantly\nimproving exploration efficiency and automatically optimizing attack\nstrategies, Auto-RT detects a boarder range of vulnerabilities, achieving a\nfaster detection speed and 16.63\\% higher success rates compared to existing\nmethods."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-434",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16351"
    ],
    "b_title":[
      "AquaNeRF: Neural Radiance Fields in Underwater Media with Distractor\n  Removal"
    ],
    "b_abstract":[
      "Neural radiance field (NeRF) research has made significant progress in\nmodeling static video content captured in the wild. However, current models and\nrendering processes rarely consider scenes captured underwater, which are\nuseful for studying and filming ocean life. They fail to address visual\nartifacts unique to underwater scenes, such as moving fish and suspended\nparticles. This paper introduces a novel NeRF renderer and optimization scheme\nfor an implicit MLP-based NeRF model. Our renderer reduces the influence of\nfloaters and moving objects that interfere with static objects of interest by\nestimating a single surface per ray. We use a Gaussian weight function with a\nsmall offset to ensure that the transmittance of the surrounding media remains\nconstant. Additionally, we enhance our model with a depth-based scaling\nfunction to upscale gradients for near-camera volumes. Overall, our method\noutperforms the baseline Nerfacto by approximately 7.5\\% and SeaThru-NeRF by\n6.2% in terms of PSNR. Subjective evaluation also shows a significant reduction\nof artifacts while preserving details of static targets and background compared\nto the state of the arts."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10773"
    ],
    "c_title":[
      "On Finsler metric measure manifolds with integral weighted Ricci\n  curvature bounds"
    ],
    "c_abstract":[
      "In this paper, we study deeply geometric and topological properties of\nFinsler metric measure manifolds with the integral weighted Ricci curvature\nbounds. We first establish Laplacian comparison theorem, Bishop-Gromov type\nvolume comparison theorem and relative volume comparison theorem on such\nFinsler manifolds. Then we obtain a volume growth estimate and Gromov\npre-compactness under the integral weighted Ricci curvature bounds.\nFurthermore, we prove the local Dirichlet isoperimetric constant estimate on\nFinsler metric measure manifolds with integral weighted Ricci curvature bounds.\nAs applications of the Dirichlet isoperimetric constant estimates, we get first\nDirichlet eigenvalue estimate and a gradient estimate for harmonic functions."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-435",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10327"
    ],
    "b_title":[
      "Klingen Eisenstein series congruences and modularity"
    ],
    "b_abstract":[
      "We construct a mod $\\ell$ congruence between a Klingen Eisenstein series\n(associated to a classical newform $\\phi$ of weight $k$) and a Siegel cusp form\n$f$ with irreducible Galois representation. We use this congruence to show\nnon-vanishing of the Bloch-Kato Selmer group $H^1_f(\\mathbf{Q},\n\\textrm{ad}^0\\rho_{\\phi}(2-k)\\otimes \\mathbf{Q}_{\\ell}\/\\mathbf{Z}_{\\ell})$\nunder certain assumptions and provide an example. We then prove an $R=dvr$\ntheorem for the Fontaine-Laffaille universal deformation ring of\n$\\overline{\\rho}_f$ under some assumptions, in particular, that the residual\nSelmer group $H^1_f(\\mathbf{Q}, \\textrm{ad}^0\\overline{\\rho}_{\\phi}(k-2))$ is\ncyclic. For this we prove a result about extensions of Fontaine-Laffaille\nmodules. We end by formulating conditions for when $H^1_f(\\mathbf{Q},\n\\textrm{ad}^0\\overline{\\rho}_{\\phi}(k-2))$ is non-cyclic and the Eisenstein\nideal is non-principal."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.07817"
    ],
    "c_title":[
      "Cosmological Constraints using the Void Size Function Data from BOSS\n  DR16"
    ],
    "c_abstract":[
      "We measure the void size function (VSF) from the Baryon Oscillation\nSpectroscopic Survey (BOSS DR16) and perform the cosmological constraints. The\nBOSS DR16 galaxy sample is selected in the redshift range from $z = 0.2$ to\n0.8, considering the selection criteria based on galaxy number density. We\nidentify non-spherical voids from this galaxy catalog using the Voronoi\ntessellation and watershed algorithm without assuming any void shape. We select\nthe void samples based on the void ellipticity, and derive the VSFs in two\nredshift bins, i.e. $z=0.2-0.5$ and $0.5-0.8$. The VSF model we use is based on\nthe excursion-set theory, including the void linear underdensity threshold\n$\\delta_{\\rm v}$ and the redshift space distortion (RSD) parameter $\\beta$. The\nMarkov Chain Monte Carlo (MCMC) method is applied to perform the joint\nconstraints on the cosmological and void parameters. We find that the VSF\nmeasurement from BOSS DR16 gives $w = -1.214_{-0.375}^{+0.293}$, $\\Omega_{\\rm\nm} = 0.280_{-0.047}^{+0.056}$, and $\\sigma_8 = 0.874_{-0.210}^{+0.203}$, which\ncan be a good complementary probe to galaxy clustering measurements. Our method\ndemonstrates the potential of using the VSF to study cosmological models, and\nit can provide a reference for future VSF analysis in the upcoming galaxy\nspectroscopic surveys."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-436",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14963"
    ],
    "b_title":[
      "Continual Multimodal Contrastive Learning"
    ],
    "b_abstract":[
      "Multimodal contrastive learning (MCL) advances in aligning different\nmodalities and generating multimodal representations in a joint space. By\nleveraging contrastive learning across diverse modalities, large-scale\nmultimodal data enhances representational quality. However, a critical yet\noften overlooked challenge remains: multimodal data is rarely collected in a\nsingle process, and training from scratch is computationally expensive.\nInstead, emergent multimodal data can be used to optimize existing models\ngradually, \\textit{i.e.}, models are trained on a sequence of modality pair\ndata. We define this problem as Continual Multimodal Contrastive Learning\n(CMCL), an underexplored yet crucial research direction at the intersection of\nmultimodal and continual learning. In this paper, we formulate CMCL through two\nspecialized principles of stability and plasticity. We theoretically derive a\nnovel optimization-based method, which projects updated gradients from dual\nsides onto subspaces where any gradient is prevented from interfering with the\npreviously learned knowledge. Two upper bounds provide theoretical insights on\nboth stability and plasticity in our solution. Beyond our theoretical\ncontributions, we conduct experiments on multiple datasets by comparing our\nmethod against advanced continual learning baselines. The empirical results\nfurther support our claims and demonstrate the efficacy of our method. The code\nwill be publicly available."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01022"
    ],
    "c_title":[
      "Propagation Delays of Ultra-High-Energy Cosmic Ray from Active Galactic\n  Nuclei"
    ],
    "c_abstract":[
      "We investigate the time delay incurred during ultra-high energy cosmic ray\n(UHECR) propagation over cosmological distances and its potential impact on the\ncorrelation between UHECR directions of arrival and sources such as Active\nGalactic Nuclei (AGNs), the UHECR chemical composition, and extragalactic\nmagnetic field constraints. We propagate particles in different magnetic field\nconfigurations, spanning over an extended range of particle Larmor radii and\nmagnetic field coherence lengths, also including attenuation losses. We find\nthat UHECR delays could easily be comparable to (and longer than) AGN duty\ncycles, effectively erasing the correlation between known AGNs and UHECR\nanisotropies. We finally consider how strong constraints on the chemical\ncomposition of the heaviest UHECRs could enable a better characterization of\nextragalactic magnetic fields."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-437",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16326"
    ],
    "b_title":[
      "A mixed integer programming approach to minibeam aperture optimization\n  for multi-collimator proton minibeam radiotherapy"
    ],
    "b_abstract":[
      "Background: Multi-collimator proton minibeam radiation therapy (MC-pMBRT) has\nrecently emerged as a versatile technique for dose shaping, enabling\npeak-valley dose patterns in organs-at-risk (OAR) while maintaining a uniform\ndose distribution in tumor. MC-pMBRT leverages a set of generic multi-slit\ncollimators (MSC) with varying center-to-center distances. However, the current\nmethod for minibeam aperture optimization (MAO), i.e., the selection of MSC per\nbeam angle, is manual and heuristic, resulting in computational inefficiencies\nand no guarantee of optimality. This work introduces a novel mixed integer\nprogramming (MIP) approach to MAO for optimizing MC-pMBRT plan quality.\nMethods: The proposed MIP approach jointly optimizes dose distributions,\npeak-to-valley dose ratio (PVDR), and selects the optimal set of MSC per beam\nangle. The optimization problem includes decision variables for MSC selection\nper beam angle and spot weights. The proposed MIP approach is a two-step\nprocess: Step1: the binary variables are optimally determined to select MSC for\neach beam angle; Step 2: the continuous variables are solved to determine the\nspot weights. Both steps utilize iterative convex relaxation and the\nalternating direction method of multipliers to solve the problems. Results: The\nproposed MIP method for MAO (MIP-MAO) was validated against the conventional\nheuristic method (CONV) for MC-pMBRT treatment planning. Results indicate that\nMIP-MAO enhances the conformity index (CI) for the target and improves PVDR for\nOAR. For instance, in a head-and-neck case, CI improved from 0.61 (CONV) to\n0.70 (MIP-MAO); in an abdomen case, CI improved from 0.78 (CONV) to 0.83\n(MIP-MAO). Additionally, MIP-MAO reduced mean doses in the body and OAR.\nConclusions: A novel MIP approach for MAO in MC-pMBRT is presented, showing\ndemonstrated improvements in plan quality and PVDR compared to the heuristic\nmethod."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.01320"
    ],
    "c_title":[
      "Evaluating the Impacts of Swapping on the US Decennial Census"
    ],
    "c_abstract":[
      "To meet its dual burdens of providing useful statistics and ensuring privacy\nof individual respondents, the US Census Bureau has for decades introduced some\nform of \"noise\" into published statistics. Initially, they used a method known\nas \"swapping\" (1990-2010). In 2020, they switched to an algorithm called\nTopDown that ensures a form of Differential Privacy. While the TopDown\nalgorithm has been made public, no implementation of swapping has been released\nand many details of the deployed swapping methodology deployed have been kept\nsecret. Further, the Bureau has not published (even a synthetic) \"original\"\ndataset and its swapped version. It is therefore difficult to evaluate the\neffects of swapping, and to compare these effects to those of other privacy\ntechnologies. To address these difficulties we describe and implement a\nparameterized swapping algorithm based on Census publications, court documents,\nand informal interviews with Census employees. With this implementation, we\ncharacterize the impacts of swapping on a range of statistical quantities of\ninterest. We provide intuition for the types of shifts induced by swapping and\ncompare against those introduced by TopDown. We find that even when swapping\nand TopDown introduce errors of similar magnitude, the direction in which\nstatistics are biased need not be the same across the two techniques. More\nbroadly, our implementation provides researchers with the tools to analyze and\npotentially correct for the impacts of disclosure avoidance systems on the\nquantities they study."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-438",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18940"
    ],
    "b_title":[
      "MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical\n  Capabilities of LLM Tutors"
    ],
    "b_abstract":[
      "Evaluating the pedagogical capabilities of AI-based tutoring models is\ncritical for making guided progress in the field. Yet, we lack a reliable,\neasy-to-use, and simple-to-run evaluation that reflects the pedagogical\nabilities of models. To fill this gap, we present MathTutorBench, an\nopen-source benchmark for holistic tutoring model evaluation. MathTutorBench\ncontains a collection of datasets and metrics that broadly cover tutor\nabilities as defined by learning sciences research in dialog-based teaching. To\nscore the pedagogical quality of open-ended teacher responses, we train a\nreward model and show it can discriminate expert from novice teacher responses\nwith high accuracy. We evaluate a wide set of closed- and open-weight models on\nMathTutorBench and find that subject expertise, indicated by solving ability,\ndoes not immediately translate to good teaching. Rather, pedagogy and subject\nexpertise appear to form a trade-off that is navigated by the degree of\ntutoring specialization of the model. Furthermore, tutoring appears to become\nmore challenging in longer dialogs, where simpler questioning strategies begin\nto fail. We release the benchmark, code, and leaderboard openly to enable rapid\nbenchmarking of future models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12681"
    ],
    "c_title":[
      "Shear jamming transition in alternating shear rotation for frictional\n  and frictionless suspensions"
    ],
    "c_abstract":[
      "Alternating shear rotations in dense suspensions have recently shown the\nability to reduce both viscosity and dissipation per strain (at a fixed global\nshear rate). Here, we study alternating shear rotation, with extensive\nnumerical simulations, at various angles and up to their corresponding jamming\npoints. For increasing shear rotation angles, we find that the jamming point is\ncontinuously shifted to higher packing fractions for frictional particles,\nwhile it remains constant for frictionless particles. As a consequence, the\nalternating shear rotation is unable to reduce the dissipation per strain for\nsuspensions composed of frictionless particles. We detail the individual\ncontributions, hydrodynamic or contact, to the shear stress, being uncharted\nfor this protocol. As the angle of rotation increases, the average contact\nstress decreases. However, we find that the hydrodynamics shows the opposite\ntrend, instead increasing with increasing angle. Hence, hydrodynamic stress\nwill dominate up to much higher packing fractions as the angle of rotation\nincreases. In addition, we report how the microstructure varies and establish a\none-to-one mapping between the contact number and its contribution to the total\nstress for both frictionless and frictional particles."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-439",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09367"
    ],
    "b_title":[
      "PICE: A Semantic-Driven Progressive Inference System for LLM Serving in\n  Cloud-Edge Networks"
    ],
    "b_abstract":[
      "Large language models (LLMs), while driving a new wave of interactive AI\napplications across numerous domains, suffer from high inference costs and\nheavy cloud dependency. Motivated by the redundancy phenomenon in linguistics,\nwe propose a progressive inference paradigm over cloud and edge, i.e., firstly\ngenerating the sketch of the answer by LLMs at cloud, and then conducting\nparallel extension to fill in details by small models (SLMs) at edge.\nProgressive inference offers potential benefits to improve throughput and\nreduce inference latency while facing key implementation challenges, including\ndecreased response quality from SLMs, a tradeoff between the brevity and\ncomprehensiveness of sketches, as well as increased latency caused by network\ntransmission and edge inference. In this work, we propose and implement PICE,\nan LLM serving system with semantic-level cloud-edge collaboration, enhancing\ninference throughput and quality through dynamic inference task scheduling,\nensemble learning, and parallel edge inference. Extensive testbed experiments\nillustrate that our approach achieves $1.5-2\\times$ throughput enhancement and\nup to 43% latency reduction, while also potentially enhancing the quality\ncompared to SOTA systems."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14251"
    ],
    "c_title":[
      "Bayesian Parameter Inference and Uncertainty Quantification for a\n  Computational Pulmonary Hemodynamics Model Using Gaussian Processes"
    ],
    "c_abstract":[
      "Patient-specific modeling is a valuable tool in cardiovascular disease\nresearch, offering insights beyond what current clinical equipment can measure.\nGiven the limitations of available clinical data, models that incorporate\nuncertainty can provide clinicians with better guidance for tailored\ntreatments. However, such modeling must align with clinical time frameworks to\nensure practical applicability. In this study, we employ a one-dimensional\nfluid dynamics model integrated with data from a canine model of chronic\nthromboembolic pulmonary hypertension (CTEPH) to investigate microvascular\ndisease, which is believed to involve complex mechanisms. To enhance\ncomputational efficiency during model calibration, we implement a Gaussian\nprocess emulator. This approach enables us to explore the relationship between\ndisease severity and microvascular parameters, offering new insights into the\nprogression and treatment of CTEPH in a timeframe that is compatible with a\nreasonable clinical timeframe."
    ],
    "c_categories":[
      [
        "cs.CE",
        "physics.bio-ph",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-440",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05910"
    ],
    "b_title":[
      "Interactive Visualization Framework for Forensic Bullet Comparisons"
    ],
    "b_abstract":[
      "The current method for forensic analysis of bullet comparison relies on\nmanual examination by forensic examiners to determine if bullets were\ndischarged from the same firearm. This process is highly subjective, prompting\nthe development of algorithmic methods to provide objective statistical support\nfor comparisons. However, a gap exists between the technical understanding of\nthese algorithms and the typical background of many forensic examiners. We\npresent a visualization tool designed to bridge this gap, allowing for the\npresentation of statistical information in a more familiar format to forensic\nprofessionals. The forensic bullet comparison visualizer (FBCV) features a\nvariety of plots that will enable the user to examine every step of the\nalgorithmic comparison process. We demonstrate the utility of the FBCV by\napplying it to data from the Houston Science Lab, where it helped identify an\nerror in the comparison process caused by mislabeling. This tool can be used\nfor future investigations, such as examining how distance between shots affects\nscores. The FBCV offers a user-friendly way to convey complex statistical\ninformation to forensic examiners, facilitating their understanding and\nutilization of algorithmic comparison methods."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.04325"
    ],
    "c_title":[
      "GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain\n  tumour Segmentation on mp-MRI"
    ],
    "c_abstract":[
      "Gliomas are brain tumours that stand out for their highly lethal and\naggressive nature, which demands a precise approach in their diagnosis. Medical\nimage segmentation plays a crucial role in the evaluation and follow-up of\nthese tumours, allowing specialists to analyse their morphology. However,\nexisting methods for automatic glioma segmentation often lack generalization\ncapability across other brain tumour domains, require extensive computational\nresources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used\nto delineate them. In this work, we introduce GBT-SAM, a novel Generalizable\nBrain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to\nbrain tumour segmentation tasks. Our method employs a two-step training\nprotocol: first, fine-tuning the patch embedding layer to process the entire\nmp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks\nand a Depth-Condition block into the Vision Transformer (ViT) to capture\ninter-slice correlations. GBT-SAM achieves state-of-the-art performance on the\nAdult Glioma dataset (Dice Score of $93.54$) while demonstrating robust\ngeneralization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma\ndatasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus\noffering an efficient solution for brain tumour segmentation. \\\\ Our code and\nmodels are available at https:\/\/github.com\/vpulab\/med-sam-brain ."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-441",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06953"
    ],
    "b_title":[
      "MERLION: Marine ExploRation with Language guIded Online iNformative\n  Visual Sampling and Enhancement"
    ],
    "b_abstract":[
      "Autonomous and targeted underwater visual monitoring and exploration using\nAutonomous Underwater Vehicles (AUVs) can be a challenging task due to both\nonline and offline constraints. The online constraints comprise limited onboard\nstorage capacity and communication bandwidth to the surface, whereas the\noffline constraints entail the time and effort required for the selection of\ndesired key frames from the video data. An example use case of targeted\nunderwater visual monitoring is finding the most interesting visual frames of\nfish in a long sequence of an AUV's visual experience. This challenge of\ntargeted informative sampling is further aggravated in murky waters with poor\nvisibility. In this paper, we present MERLION, a novel framework that provides\nsemantically aligned and visually enhanced summaries for murky underwater\nmarine environment monitoring and exploration. Specifically, our framework\nintegrates (a) an image-text model for semantically aligning the visual samples\nto the users' needs, (b) an image enhancement model for murky water visual data\nand (c) an informative sampler for summarizing the monitoring experience. We\nvalidate our proposed MERLION framework on real-world data with user studies\nand present qualitative and quantitative results using our evaluation metric\nand show improved results compared to the state-of-the-art approaches. We have\nopen-sourced the code for MERLION at the following link\nhttps:\/\/github.com\/MARVL-Lab\/MERLION.git."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17618"
    ],
    "c_title":[
      "Periodic Boundary Conditions for Bosonic Path Integral Molecular\n  Dynamics"
    ],
    "c_abstract":[
      "We develop an algorithm for bosonic path integral molecular dynamics (PIMD)\nsimulations with periodic boundary conditions (PBC) that scales quadratically\nwith the number of particles. Path integral methods are a powerful tool to\nsimulate bosonic condensed phases, which exhibit fundamental physical phenomena\nsuch as Bose--Einstein condensation and superfluidity. Recently, we developed a\nquadratic scaling algorithm for bosonic PIMD, but employed an ad hoc treatment\nof PBC. Here we rigorously enforce PBC in bosonic PIMD. It requires summing\nover the spring energies of all periodic images in the partition function, and\na naive implementation scales exponentially with the system size. We present an\nalgorithm for bosonic PIMD simulations of periodic systems that scales only\nquadratically. We benchmark our implementation on the free Bose gas and a model\nsystem of cold atoms in optical lattices. We also study an approximate\ntreatment of PBC based on the minimum-image convention, and derive a numerical\ncriterion to determine when it is valid."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-442",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00858"
    ],
    "b_title":[
      "Learning to Plan with Personalized Preferences"
    ],
    "b_abstract":[
      "Effective integration of AI agents into daily life requires them to\nunderstand and adapt to individual human preferences, particularly in\ncollaborative roles. Although recent studies on embodied intelligence have\nadvanced significantly, they typically adopt generalized approaches that\noverlook personal preferences in planning. We address this limitation by\ndeveloping agents that not only learn preferences from few demonstrations but\nalso learn to adapt their planning strategies based on these preferences. Our\nresearch leverages the observation that preferences, though implicitly\nexpressed through minimal demonstrations, can generalize across diverse\nplanning scenarios. To systematically evaluate this hypothesis, we introduce\nPreference-based Planning (PbP) benchmark, an embodied benchmark featuring\nhundreds of diverse preferences spanning from atomic actions to complex\nsequences. Our evaluation of SOTA methods reveals that while symbol-based\napproaches show promise in scalability, significant challenges remain in\nlearning to generate and execute plans that satisfy personalized preferences.\nWe further demonstrate that incorporating learned preferences as intermediate\nrepresentations in planning significantly improves the agent's ability to\nconstruct personalized plans. These findings establish preferences as a\nvaluable abstraction layer for adaptive planning, opening new directions for\nresearch in preference-guided plan generation and execution."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.19312"
    ],
    "c_title":[
      "Test of a two-level algorithm for the glueball spectrum in $SU(N_c)$\n  Yang-Mills theory"
    ],
    "c_abstract":[
      "We present preliminary results obtained using a new code for $SU (N_c)$\nYang-Mills theory which performs a 2-level sampling of glueball correlators\nobtained from a suitably chosen basis of (APE) smeared and unsmeared operators.\nThe code builds loop operators of any shape and length and classifies them\naccording to the irreducible representations of the cubic group. We report on\nthe performances of the algorithm and on the computation of the first low-lying\nglueball states choosing $N_c = 3$ as a reference to compare our results with\nthe literature."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-443",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14369"
    ],
    "b_title":[
      "Low-rank Prompt Interaction for Continual Vision-Language Retrieval"
    ],
    "b_abstract":[
      "Research on continual learning in multi-modal tasks has been receiving\nincreasing attention. However, most existing work overlooks the explicit\ncross-modal and cross-task interactions. In this paper, we innovatively propose\nthe Low-rank Prompt Interaction (LPI) to address this general problem of\nmulti-modal understanding, which considers both cross-modal and cross-task\ninteractions. Specifically, as for the former, we employ multi-modal\ncorrelation modules for corresponding Transformer layers. Considering that the\ntraining parameters scale to the number of layers and tasks, we propose\nlow-rank interaction-augmented decomposition to avoid memory explosion while\nenhancing the cross-modal association through sharing and separating\ncommon-specific low-rank factors. In addition, due to the multi-modal semantic\ndifferences carried by the low-rank initialization, we adopt hierarchical\nlow-rank contrastive learning to ensure training robustness. As for the latter,\nwe initially employ a visual analysis and identify that different tasks have\nclear distinctions in proximity. Therefore, we introduce explicit task\ncontrastive constraints in the prompt learning process based on task semantic\ndistances. Experiments on two retrieval tasks show performance improvements\nwith the introduction of a minimal number of parameters, demonstrating the\neffectiveness of our method. Code is available at\nhttps:\/\/github.com\/Kelvin-ywc\/LPI."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09728"
    ],
    "c_title":[
      "Perch like a bird: bio-inspired optimal maneuvers and nonlinear control\n  for Flapping-Wing Unmanned Aerial Vehicles"
    ],
    "c_abstract":[
      "This research endeavors to design the perching maneuver and control in\nornithopter robots. By analyzing the dynamic interplay between the robot's\nflight dynamics, feedback loops, and the environmental constraints, we aim to\nadvance our understanding of the perching maneuver, drawing parallels to\nbiological systems. Inspired by the elegant control strategies observed in\navian flight, we develop an optimal maneuver and a corresponding controller to\nachieve stable perching. The maneuver consists of a deceleration and a rapid\npitch-up (vertical turn), which arises from analytically solving the\noptimization problem of minimal velocity at perch, subject to kinematic and\ndynamic constraints. The controller for the flapping frequency and tail\nsymmetric deflection is nonlinear and adaptive, ensuring robustly stable\nperching. Indeed, such adaptive behavior in a sense incorporates homeostatic\nprinciples of cybernetics into the control system, enhancing the robot's\nability to adapt to unexpected disturbances and maintain a stable posture\nduring the perching maneuver. The resulting autonomous perching maneuvers --\nclosed-loop descent and turn -- , have been verified and validated,\ndemonstrating excellent agreement with real bird perching trajectories reported\nin the literature. These findings lay the theoretical groundwork for the\ndevelopment of future prototypes that better imitate the skillful perching\nmaneuvers of birds."
    ],
    "c_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-444",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12791"
    ],
    "b_title":[
      "Topological invariant for holographic Weyl-$\\mathrm Z_2$ semimetal"
    ],
    "b_abstract":[
      "The occurrence of a topological phase transition can be demonstrated by a\ndirect observation of a change in the topological invariant. For holographic\ntopological semimetals, a topological Hamiltonian method needs to be employed\nto calculate the topological invariants due to the strong coupling nature of\nthe system. We calculate the topological invariants for the holographic Weyl\nsemimetal and the holographic Weyl-$\\mathrm Z_2$ semimetal, which correspond to\nthe chiral charge and the spin-Chern number, respectively. This is achieved by\nprobing fermions within the system and deriving the topological Hamiltonian\nfrom the zero-frequency Green's function. In both cases, we have identified an\neffective band structure characterized by an infinite number of Weyl or\n$\\mathrm Z_2$ nodes, a distinctive feature of holographic systems different\nfrom weakly coupled systems. The topological invariants of these nodes are\ncomputed numerically and found to be nonzero, thereby confirming the\ntopologically nontrivial nature of these nodes."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03709"
    ],
    "c_title":[
      "How to Make Your Multi-Image Posts Popular? An Approach to Enhanced Grid\n  for Nine Images on Social Media"
    ],
    "c_abstract":[
      "The nine-grid layout is commonly used for multi-image posts, arranging nine\nimages in a tic-tac-toe board. This layout effectively presents content within\nlimited space. Moreover, due to the numerous possible arrangements within the\nnine-image grid, the optimal arrangement that yields the highest level of\nattractiveness remains unknown. Our study investigates how the arrangement of\nimages within a nine-grid layout affects the overall popularity of the image\nset, aiming to explore alignment schemes more aligned with user preferences.\nBased on survey results regarding user preferences in image arrangement, we\nhave identified two ordering sequences that are widely recognized: sequential\norder and center prioritization, considering both image visual content and\naesthetic quality as alignment metrics, resulting in four layout schemes.\nFinally, we recruited participants to annotate various layout schemes of the\nsame set of images. Our experience-centered evaluation indicates that layout\nschemes based on aesthetic quality outperformed others. This research yields\nempirical evidence supporting the optimization of the nine-grid layout for\nmulti-image posts, thereby furnishing content creators with valuable insights\nto enhance both attractiveness and user experience."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-445",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04312"
    ],
    "b_title":[
      "Quantum metric induced magneto-optical effects in\n  $\\mathcal{PT}$-symmetric antiferromagnets"
    ],
    "b_abstract":[
      "The magneto-optical effects (MOEs), as a fundamental physical phenomenon, can\nreveal the electronic structures of materials. The related probing methods are\nwidely used in the study of magnetic materials. However, space-time inversion\n($\\mathcal{PT}$) symmetric antiferromagnets were previously believed to be\nmagneto-optically inactive. Here, we point out that this traditional\nunderstanding is incorrect. Based on our generic formulas and symmetry\nanalysis, we find that in $\\mathcal{PT}$-symmetric antiferromagnets, it is the\nquantum metric, i.e., the real part of the quantum geometry, that induces MOEs.\nCombining a tight-binding model and first-principles calculations, we confirm\nthis observation by showing MOEs in the $\\mathcal{PT}$-symmetric\nantiferromagnet. Our work demonstrates that $\\mathcal{PT}$-symmetric\nantiferromagnets previously thought to lack MOEs can indeed exhibit MOEs and\ngreatly broaden the research on MOEs."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02381"
    ],
    "c_title":[
      "Estimating Discrete Choice Demand Models with Sparse Market-Product\n  Shocks"
    ],
    "c_abstract":[
      "We propose a new approach to estimating the random coefficient logit demand\nmodel for differentiated products when the vector of market-product level\nshocks is sparse. Assuming sparsity, we establish nonparametric identification\nof the distribution of random coefficients and demand shocks under mild\nconditions. Then we develop a Bayesian procedure, which exploits the sparsity\nstructure using shrinkage priors, to conduct inference about the model\nparameters and counterfactual quantities. Comparing to the standard BLP (Berry,\nLevinsohn, & Pakes, 1995) method, our approach does not require demand\ninversion or instrumental variables (IVs), thus provides a compelling\nalternative when IVs are not available or their validity is questionable. Monte\nCarlo simulations validate our theoretical findings and demonstrate the\neffectiveness of our approach, while empirical applications reveal evidence of\nsparse demand shocks in well-known datasets."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-446",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07550"
    ],
    "b_title":[
      "The Expanding 3-Kiloparsec Arms are neither Expanding nor Spiral Arms,\n  but X1 Orbits driven by the Galactic Bar"
    ],
    "b_abstract":[
      "Near the center of our Milky Way is a bar-like structure and the so-called\nExpanding 3-kpc arms. We currently have limited knowledge of this important\nregion, since we are about 8.2 kpc from the center and cannot directly observe\nit at optical wavelengths, owing to strong extinction from interstellar dust.\nHere we present extremely precise VLBI measurements of water maser sources from\nthe BeSSeL Survey, where extinction is not a problem, which accurately\ndetermine the 3-dimensional locations and motions of three massive young stars.\nCombined with previous measurements, these stars delineate a trail of orbits\noutlining the Milky Way's Galactic Bar. We present the first measurements\ncapturing the dynamics of quasi-elliptical (X1) orbits around the Galactic Bar.\nOur findings provide evidence substantiating the existence of such orbits\npopulated by massive young stars. Our measurements of the position and velocity\nof a number of massive young stars, previously identified with the Expanding\n3-kpc arms, show that they are more likely located in the X1 orbits about the\nGalactic Bar. Also, some stars previously assigned to the Norma spiral arm\nappear to be in these orbits, which suggests that this spiral arm does not\nextend past the end of the bar."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11579"
    ],
    "c_title":[
      "Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers"
    ],
    "c_abstract":[
      "State-of-the-art transformer-based large multimodal models (LMMs) struggle to\nhandle hour-long video inputs due to the quadratic complexity of the causal\nself-attention operations, leading to high computational costs during training\nand inference. Existing token compression-based methods reduce the number of\nvideo tokens but often incur information loss and remain inefficient for\nextremely long sequences. In this paper, we explore an orthogonal direction to\nbuild a hybrid Mamba-Transformer model (VAMBA) that employs Mamba-2 blocks to\nencode video tokens with linear complexity. Without any token reduction, VAMBA\ncan encode more than 1024 frames (640$\\times$360) on a single GPU, while\ntransformer-based models can only encode 256 frames. On long video input, VAMBA\nachieves at least 50% reduction in GPU memory usage during training and\ninference, and nearly doubles the speed per training step compared to\ntransformer-based LMMs. Our experimental results demonstrate that VAMBA\nimproves accuracy by 4.3% on the challenging hour-long video understanding\nbenchmark LVBench over prior efficient video LMMs, and maintains strong\nperformance on a broad spectrum of long and short video understanding tasks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-447",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03818"
    ],
    "b_title":[
      "Dirichlet dynamical zeta function for billiard flow"
    ],
    "b_abstract":[
      "We study the Dirichlet dynamical zeta function $\\eta_D(s)$ for billiard flow\ncorresponding to several strictly convex disjoint obstacles. For large ${\\rm\nRe}\\: s$ we have $\\eta_D(s) =\\sum_{n= 1}^{\\infty} a_n e^{-\\lambda_n s}, \\: a_n\n\\in \\mathbb R$ and $\\eta_D$ admits a meromorphic continuation to $\\mathbb C$.\nWe obtain some conditions of the frequencies $\\lambda_n$ and some sums of\ncoefficients $a_n$ which imply that $\\eta_D$ cannot be prolonged as entire\nfunction."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16114"
    ],
    "c_title":[
      "InterLink: Linking Text with Code and Output in Computational Notebooks"
    ],
    "c_abstract":[
      "Computational notebooks, widely used for ad-hoc analysis and often shared\nwith others, can be difficult to understand because the standard linear layout\nis not optimized for reading. In particular, related text, code, and outputs\nmay be spread across the UI making it difficult to draw connections. In\nresponse, we introduce InterLink, a plugin designed to present the\nrelationships between text, code, and outputs, thereby making notebooks easier\nto understand. In a formative study, we identify pain points and derive design\nrequirements for identifying and navigating relationships among various pieces\nof information within notebooks. Based on these requirements, InterLink\nfeatures a new layout that separates text from code and outputs into two\ncolumns. It uses visual links to signal relationships between text and\nassociated code and outputs and offers interactions for navigating related\npieces of information. In a user study with 12 participants, those using\nInterLink were 13.6% more accurate at finding and integrating information from\ncomplex analyses in computational notebooks. These results show the potential\nof notebook layouts that make them easier to understand."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-448",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09231"
    ],
    "b_title":[
      "Order-by-order uncertainties of nucleon-nucleon Wolfenstein amplitudes\n  in chiral effective field theory"
    ],
    "b_abstract":[
      "Quantum mechanical invariance principles dictate the most general operator\nstructure that can be present in the nucleon-nucleon (NN) interaction. Five\nindependent operators appear in the on-shell NN amplitude together with five\ncorresponding coefficient functions. The usual choice for these coefficient\nfunctions is known as the NN Wolfenstein amplitudes. We analyze the\norder-by-order convergence of each of the five NN Wolfenstein amplitudes\npredicted by a semi-local coordinate space potential implementation of chiral\neffective field theory ($\\chi$EFT). We do this at laboratory kinetic energies\nbetween 25 and 200 MeV for both neutron-proton and proton-proton scattering.\nOur analysis uses the Gaussian-Process methods developed by the BUQEYE\ncollaboration to describe the contributions of each $\\chi$EFT order, and so\nyields truncation uncertainties for each Wolfenstein amplitude that are\ncorrelated across scattering angles. We combine information on the size of\ndifferent orders in the EFT to infer the $\\chi$EFT breakdown scale for each\namplitude, finding, on average, $\\Lambda_b$ between 750 and 800 MeV. With this\nchoice of $\\Lambda_b$, the EFT truncation uncertainties cover both higher-order\nresults and empirical Wolfenstein amplitudes well for all orders other than the\nleading order."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17812"
    ],
    "c_title":[
      "Can Multimodal LLMs Perform Time Series Anomaly Detection?"
    ],
    "c_abstract":[
      "Large language models (LLMs) have been increasingly used in time series\nanalysis. However, the potential of multimodal LLMs (MLLMs), particularly\nvision-language models, for time series remains largely under-explored. One\nnatural way for humans to detect time series anomalies is through visualization\nand textual description. Motivated by this, we raise a critical and practical\nresearch question: Can multimodal LLMs perform time series anomaly detection?\nTo answer this, we propose VisualTimeAnomaly benchmark to evaluate MLLMs in\ntime series anomaly detection (TSAD). Our approach transforms time series\nnumerical data into the image format and feed these images into various MLLMs,\nincluding proprietary models (GPT-4o and Gemini-1.5) and open-source models\n(LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant. In\ntotal, VisualTimeAnomaly contains 12.4k time series images spanning 3 scenarios\nand 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with\nthe univariate case (point- and range-wise anomalies), we extend our evaluation\nto more practical scenarios, including multivariate and irregular time series\nscenarios, and variate-wise anomalies. Our study reveals several key insights:\n  1) MLLMs detect range- and variate-wise anomalies more effectively than\npoint-wise anomalies.\n  2) MLLMs are highly robust to irregular time series, even with 25% of the\ndata missing.\n  3) Open-source MLLMs perform comparably to proprietary models in TSAD. While\nopen-source MLLMs excel on univariate time series, proprietary MLLMs\ndemonstrate superior effectiveness on multivariate time series.\n  To the best of our knowledge, this is the first work to comprehensively\ninvestigate MLLMs for TSAD, particularly for multivariate and irregular time\nseries scenarios. We release our dataset and code at\nhttps:\/\/github.com\/mllm-ts\/VisualTimeAnomaly to support future research."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-449",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00006"
    ],
    "b_title":[
      "Classification of states on certain orthomodular structures"
    ],
    "b_abstract":[
      "We define various type of states on implicative involutive BE algebras\n(Jauch-Piron state, (P)-state, (B)-state, subadditive state, valuation), and we\ninvestigate the relationships between these states. Moreover, we introduce the\nunital, full and rich sets of states, and we prove certain properties involving\nthese notions. In the case when an implicative involutive BE algebra possesses\na rich or a full set of states, we prove that it is an implicative-orthomodular\nlattice. If an implicative involutive BE algebra possesses a rich set of\n(P)-states or a full set of valuations, then it is an implicative-Boolean\nalgebra. Additionally, based on their deductive systems, we give\ncharacterizations of implicative-orthomodular lattices and implicative-Boolean\nalgebras."
    ],
    "b_categories":[
      [
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16114"
    ],
    "c_title":[
      "InterLink: Linking Text with Code and Output in Computational Notebooks"
    ],
    "c_abstract":[
      "Computational notebooks, widely used for ad-hoc analysis and often shared\nwith others, can be difficult to understand because the standard linear layout\nis not optimized for reading. In particular, related text, code, and outputs\nmay be spread across the UI making it difficult to draw connections. In\nresponse, we introduce InterLink, a plugin designed to present the\nrelationships between text, code, and outputs, thereby making notebooks easier\nto understand. In a formative study, we identify pain points and derive design\nrequirements for identifying and navigating relationships among various pieces\nof information within notebooks. Based on these requirements, InterLink\nfeatures a new layout that separates text from code and outputs into two\ncolumns. It uses visual links to signal relationships between text and\nassociated code and outputs and offers interactions for navigating related\npieces of information. In a user study with 12 participants, those using\nInterLink were 13.6% more accurate at finding and integrating information from\ncomplex analyses in computational notebooks. These results show the potential\nof notebook layouts that make them easier to understand."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-450",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15213"
    ],
    "b_title":[
      "Sig2text, a Vision-language model for Non-cooperative Radar Signal\n  Parsing"
    ],
    "b_abstract":[
      "Automatic non-cooperative analysis of intercepted radar signals is essential\nfor intelligent equipment in both military and civilian domains. Accurate\nmodulation identification and parameter estimation enable effective signal\nclassification, threat assessment, and the development of countermeasures. In\nthis paper, we propose a symbolic approach for radar signal recognition and\nparameter estimation based on a vision-language model that combines\ncontext-free grammar with time-frequency representation of radar waveforms. The\nproposed model, called Sig2text, leverages the power of vision transformers for\ntime-frequency feature extraction and transformer-based decoders for symbolic\nparsing of radar waveforms. By treating radar signal recognition as a parsing\nproblem, Sig2text can effectively recognize and parse radar waveforms with\ndifferent modulation types and parameters. We evaluate the performance of\nSig2text on a synthetic radar signal dataset and demonstrate its effectiveness\nin recognizing and parsing radar waveforms with varying modulation types and\nparameters. The training code of the model is available at\nhttps:\/\/github.com\/Na-choneko\/sig2text."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17743"
    ],
    "c_title":[
      "Exclusive $J\/\\psi$ production in proton-proton ultraperipheral\n  collisions adopting GPD approach"
    ],
    "c_abstract":[
      "Exclusive $J\/\\psi$ production is investigated in proton-proton\nultraperipheral collisions within GPD approach. Three\n  sets gluon density are used in the calculations of $J\/\\psi$ production. The\nsurvival factors and equivalent photon approximation are applied to predict\n  the $J\/\\psi$ photoproduction in proton-proton ultraperipheral collisions. The\nGPD model predictions give a good agreement with the experimental data\n  at LHCb. The exclusive $J\/\\psi$ production at RHIC and NICA proton-proton\nultraperipheral\n  collisions are performed. These predictions of GPD approach can be employed\nto estimate the $J\/\\psi$ cross sections\n  in future proton-proton collisions."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-451",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07480"
    ],
    "b_title":[
      "Trapping and Transport of Inertial Particles in a Taylor-Green Vortex:\n  Effects of Added Mass and History Force"
    ],
    "b_abstract":[
      "We investigate the dynamics of small inertial particles in a two-dimensional,\nsteady Taylor-Green vortex flow. A classic study by Taylor (2022) showed that\nheavy inertial point particles (having density parameter R = 1) are trapped by\nthe flow separatrices when the particle Stokes number St, which measures the\nparticle's inertia, is less than 1\/4. Here, we consider finitely dense\nparticles, incorporating the previously neglected effects of added mass and the\nBoussinesq-Basset history force. Using linear stability analysis near\nstagnation points, we determine the critical parametric conditions in the St-R\nplane that leads to particle trapping within vortex cells. We identify\nadditional stagnation points perceived by inertial particles, beyond the\ntraditional ones at vortex cell corners, when the added mass effect is\nincluded, and we analyze their stability. Numerical analysis of the full\nnonlinear system confirms the existence of distinct particle\nbehaviours--trapped, diffusive, and ballistic--depending on initial conditions,\nconsistent with Nath et al. (2024), with modifications due to added mass\neffect. We delineate the regions in the St-R plane where these behaviours\ndominate based on the prominent particle dynamics. However, when both the\nhistory force and added mass effect are included, all particles exhibit\nballistic motion regardless of St and R."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03078"
    ],
    "c_title":[
      "Qinco2: Vector Compression and Search with Improved Implicit Neural\n  Codebooks"
    ],
    "c_abstract":[
      "Vector quantization is a fundamental technique for compression and\nlarge-scale nearest neighbor search. For high-accuracy operating points,\nmulti-codebook quantization associates data vectors with one element from each\nof multiple codebooks. An example is residual quantization (RQ), which\niteratively quantizes the residual error of previous steps. Dependencies\nbetween the different parts of the code are, however, ignored in RQ, which\nleads to suboptimal rate-distortion performance. QINCo recently addressed this\ninefficiency by using a neural network to determine the quantization codebook\nin RQ based on the vector reconstruction from previous steps. In this paper we\nintroduce QINCo2 which extends and improves QINCo with (i) improved vector\nencoding using codeword pre-selection and beam-search, (ii) a fast approximate\ndecoder leveraging codeword pairs to establish accurate short-lists for search,\nand (iii) an optimized training procedure and network architecture. We conduct\nexperiments on four datasets to evaluate QINCo2 for vector compression and\nbillion-scale nearest neighbor search. We obtain outstanding results in both\nsettings, improving the state-of-the-art reconstruction MSE by 34% for 16-byte\nvector compression on BigANN, and search accuracy by 24% with 8-byte encodings\non Deep1M."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-452",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14206"
    ],
    "b_title":[
      "Linear stability analysis of the Couette flow for 2D compressible\n  Navier-Stokes-Poisson system"
    ],
    "b_abstract":[
      "In this paper, we study the linear stability of Couette flow for 2D\ncompressible Navier-Stokes-Poisson system at high Reynolds number in the domain\n$\\mathbb{T}\\times\\mathbb{R}$ with initial perturbation in Sobolev spaces. We\nestablish the upper bounds for the solutions of linearized system near Couette\nflow. In particular, we show that the irrotational component of the\nperturbation may have a transient growth, after which it decays exponentially."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.07649"
    ],
    "c_title":[
      "Linting is People! Exploring the Potential of Human Computation as a\n  Sociotechnical Linter of Data Visualizations"
    ],
    "c_abstract":[
      "Traditionally, linters are code analysis tools that help developers by\nflagging potential issues from syntax and logic errors to enforcing syntactical\nand stylistic conventions. Recently, linting has been taken as an interface\nmetaphor, allowing it to be extended to more complex inputs, such as\nvisualizations, which demand a broader perspective and alternative approach to\nevaluation. We explore a further extended consideration of linting inputs, and\nmodes of evaluation, across the puritanical, neutral, and rebellious\ndimensions. We specifically investigate the potential for leveraging human\ncomputation in linting operations through Community Notes -- crowd-sourced\ncontextual text snippets aimed at checking and critiquing potentially accurate\nor misleading content on social media. We demonstrate that human-powered\nassessments not only identify misleading or error-prone visualizations but that\nintegrating human computation enhances traditional linting by offering social\ninsights. As is required these days, we consider the implications of building\nlinters powered by Artificial Intelligence."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-453",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02324"
    ],
    "b_title":[
      "PromptCoT: Synthesizing Olympiad-level Problems for Mathematical\n  Reasoning in Large Language Models"
    ],
    "b_abstract":[
      "The ability of large language models to solve complex mathematical problems\nhas progressed significantly, particularly for tasks requiring advanced\nreasoning. However, the scarcity of sufficiently challenging problems,\nparticularly at the Olympiad level, hinders further advancements. In this work,\nwe introduce PromptCoT, a novel approach for automatically generating\nhigh-quality Olympiad-level math problems. The proposed method synthesizes\ncomplex problems based on mathematical concepts and the rationale behind\nproblem construction, emulating the thought processes of experienced problem\ndesigners. We provide a theoretical analysis demonstrating that an optimal\nrationale should maximize both the likelihood of rationale generation given the\nassociated concepts and the likelihood of problem generation conditioned on\nboth the rationale and the concepts. Our method is evaluated on standard\nbenchmarks including GSM8K, MATH-500, and AIME2024, where it consistently\noutperforms existing problem generation methods. Furthermore, we demonstrate\nthat PromptCoT exhibits superior data scalability, consistently maintaining\nhigh performance as the dataset size increases, outperforming the baselines.\nThe implementation is available at https:\/\/github.com\/zhaoxlpku\/PromptCoT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17495"
    ],
    "c_title":[
      "Investigation of FWER and Power for Methodological Changes Introduced in\n  the BDOTS R Package"
    ],
    "c_abstract":[
      "In 2025, we identified a methodological issue in the bootstrapped differences\nof times series (BDOTS) first introduced in 2017 resulting in a significant\ninflation of the family-wise error rate. The goal of the present manuscript is\nthreefold: to identify the problem in the original methodology, to present two\nalternative solutions, and to compare estimates of the FWER and power of each\nof the considered methods across a variety of experimental conditions. We find\nconclusive evidence that the original BDOTS method does inflate the FWER, while\neach of the proposed alternatives maintain a FWER much closer to the nominal\nrate. Additionally, we demonstrate the relationship between power and effect\nsize for each of the proposed methods. In total, the results presented justify\nthe methodological changes presented in the new iteration of the bdots package."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-454",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06209"
    ],
    "b_title":[
      "Enhancing Cost Efficiency in Active Learning with Candidate Set Query"
    ],
    "b_abstract":[
      "This paper introduces a cost-efficient active learning (AL) framework for\nclassification, featuring a novel query design called candidate set query.\nUnlike traditional AL queries requiring the oracle to examine all possible\nclasses, our method narrows down the set of candidate classes likely to include\nthe ground-truth class, significantly reducing the search space and labeling\ncost. Moreover, we leverage conformal prediction to dynamically generate small\nyet reliable candidate sets, adapting to model enhancement over successive AL\nrounds. To this end, we introduce an acquisition function designed to\nprioritize data points that offer high information gain at lower cost.\nEmpirical evaluations on CIFAR-10, CIFAR-100, and ImageNet64x64 demonstrate the\neffectiveness and scalability of our framework. Notably, it reduces labeling\ncost by 42% on ImageNet64x64."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11607"
    ],
    "c_title":[
      "Composite quarks and leptons with embedded QCD"
    ],
    "c_abstract":[
      "We construct a model of quark and lepton compositeness based on an $SU(15)$\ngauge interaction that confines chiral preons, which are also charged under the\nweakly-coupled $SU(4)_{\\rm PS} \\times SU(2)_L\\times SU(2)_R$ gauge group. The\nbreaking of the latter, down to the Standard Model group, is achieved by scalar\n$SU(15)$ bound states at a scale in the $30 - 100$ TeV range. The embedding of\nthe QCD gauge group in $SU(4)_{\\rm PS} $ slows down the running of $\\alpha_s$\nin the UV. We estimate the effects of the strongly-coupled $SU(15)$ dynamics on\nthe running of the $SU(4)_{\\rm PS} \\times SU(2)_L\\times SU(2)_R$ gauge\ncouplings, which likely remain perturbative beyond the compositeness scale of\nabout $10^3 - 10^4$ TeV, and even above a unification scale. A composite\nvectorlike lepton doublet acquires a mass in the TeV range probed at future\ncolliders, and an extended Higgs sector arises from 6-preon bound states."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-455",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18385"
    ],
    "b_title":[
      "Monolithic On-Chip Phononic Chiral Anomalous Bulk States on LiNbO3\n  Thin-films"
    ],
    "b_abstract":[
      "Phononic materials are crucial for developing efficient, robust mechanical\nwaveguides with strong transport properties, enabling advances in sensing,\nsignal processing, energy harvesting, and microfluidics. A key motivation is\ntheir integration into monolithic systems for on-chip applications. While\ntopological phononic materials developed in the past decade offer\nunidirectional edge states immune to backscattering, their integration requires\nlarge volumes to control localized small volumes' transport properties,\nlimiting their efficiency and application in modern phononic circuits. The\nrecently introduced chiral anomalous bulk states (CABSs) combine the advantages\nof topological materials with innovative boundary designs, overcoming\ntransmission limitations and ensuring full material utilization for superior\nwave propagation. Here, we present the first on-chip monolithic CABS device\nintegrated on a suspended LiNbO3 thin film. This breakthrough enables the\ncreation of phononic waveguides with unmatched unidirectionality, low loss, and\nhigh transmission efficiency, seamlessly integrated with broadband\npiezoelectric transducers, and showcasing their potential for high-fidelity,\nbroad-bandwidth microwave signal transmission. Additionally, we exploit the\nslow-wave characteristics of CABSs for delay lines and high-density signal\nprocessing. Tailoring wave propagation through boundary engineering opens a new\nparadigm for phononic\/photonic device design, with implications across\nmicroelectronics, high-frequency communications, radar, and advanced sensing\ntechnologies. The work sets the stage for the future development of highly\nscalable, multifunctional, and robust phononic systems, unlocking new avenues\nfor integrated acoustic technologies."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17645"
    ],
    "c_title":[
      "\"It felt more real\": Investigating the User Experience of the MiWaves\n  Personalizing JITAI Pilot Study"
    ],
    "c_abstract":[
      "Cannabis use among emerging adults is increasing globally, posing significant\nhealth risks and creating a need for effective interventions. We present an\nexploratory analysis of the MiWaves pilot study, a digital intervention aimed\nat supporting cannabis use reduction among emerging adults (ages 18-25). Our\nfindings indicate the potential of self-monitoring check-ins and trend\nvisualizations in fostering self-awareness and promoting behavioral reflection\nin participants. MiWaves intervention message timing and frequency were also\ngenerally well-received by the participants. The participants' perception of\neffort were queried on intervention messages with different tasks, and our\nfindings suggest that messages with tasks like exploring links and typing in\nresponses are perceived as requiring more effort as compared to messages with\ntasks involving reading and acknowledging. Finally, we discuss the findings and\nlimitations from this study and analysis, and their impact on informing future\niterations on MiWaves."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-456",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04659"
    ],
    "b_title":[
      "$\\mathsf{CRATE}$: Cross-Rollup Atomic Transaction Execution"
    ],
    "b_abstract":[
      "Blockchains have revolutionized decentralized applications, with\ncomposability enabling atomic, trustless interactions across smart contracts.\nHowever, layer 2 (L2) scalability solutions like rollups introduce\nfragmentation and hinder composability. Current cross-chain protocols,\nincluding atomic swaps, bridges, and shared sequencers, lack the necessary\ncoordination mechanisms or rely on trust assumptions, and are thus not\nsufficient to support full cross-rollup composability. This paper presents\n$\\mathsf{CRATE}$, a secure protocol for cross-rollup composability that ensures\nall-or-nothing and serializable execution of cross-rollup transactions (CRTs).\n$\\mathsf{CRATE}$ supports rollups on distinct layer 1 (L1) chains, achieves\nfinality in 4 rounds on L1, and only relies on the underlying L1s and the\nliveness of L2s. We introduce two formal models for CRTs, define atomicity\nwithin them, and formally prove the security of $\\mathsf{CRATE}$. We also\nprovide an implementation of $\\mathsf{CRATE}$ along with a cross-rollup flash\nloan application; our experiments demonstrate that $\\mathsf{CRATE}$ is\npractical in terms of gas usage on L1."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04383"
    ],
    "c_title":[
      "Generalized Brieskorn Modules II: Higher Bernstein Polynomials and\n  Multiple Poles"
    ],
    "c_abstract":[
      "Our main result is to show that the existence of a root in. --$\\alpha$--Nfor\nthe p-th Bernstein polynomial of the (a,b)-module generated by a\nholomorphicform in the (convergent) Brieskorn (a,b)-module associated to f,\nunder the hypothesis that f has an isolated singularity at the origin relative\nto the eigenvalue exp(2i$\\pi$$\\alpha$) of the monodromy, produces poles of\norder at least p for themeromorphic extension of the (conjugate) analytic\nfunctional given by polar partsat points--$\\alpha$--N for N well chosen\ninteger. This result is new, even forp= 1. As a corollary, this implies that,\nin the case of an isolated singularity for f,the existence of a root in.\n--$\\alpha$--N for the p-th Bernstein polynomial of the (a,b)-module generated\nby a holomorphic form implies the existence of at leastp roots (counting\nmultiplicities) for the usual reduced Bernstein polynomial of thegerm of f at\nthe origin.In the case of an isolated singularity for f, we obtain that for\neach $\\alpha$ thebiggest root --$\\alpha$--m. of the reduced Bernstein\npolynomial of f in --$\\alpha$--N producesa pole at--$\\alpha$--m for the\nmeromorphic extension of the associated distribution"
    ],
    "c_categories":[
      [
        "math.AG",
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-457",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12082"
    ],
    "b_title":[
      "A Multi-annotated and Multi-modal Dataset for Wide-angle Video Quality\n  Assessment"
    ],
    "b_abstract":[
      "Wide-angle video is favored for its wide viewing angle and ability to capture\na large area of scenery, making it an ideal choice for sports and adventure\nrecording. However, wide-angle video is prone to deformation, exposure and\nother distortions, resulting in poor video quality and affecting the perception\nand experience, which may seriously hinder its application in fields such as\ncompetitive sports. Up to now, few explorations focus on the quality assessment\nissue of wide-angle video. This deficiency primarily stems from the absence of\na specialized dataset for wide-angle videos. To bridge this gap, we construct\nthe first Multi-annotated and multi-modal Wide-angle Video quality assessment\n(MWV) dataset. Then, the performances of state-of-the-art video quality methods\non the MWV dataset are investigated by inter-dataset testing and intra-dataset\ntesting. Experimental results show that these methods impose significant\nlimitations on their applicability."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14461"
    ],
    "c_title":[
      "Tomographic electron flow in confined geometries: Beyond the\n  dual-relaxation time approximation"
    ],
    "c_abstract":[
      "Hydrodynamic-like electron flows are typically modeled using the Stokes-Ohm\nequation or a kinetic description that is based on a dual-relaxation time\napproximation. Such models assume a short intrinsic mean free path $\\ell_e$ due\nto momentum-conserving electronic scattering and a large extrinsic mean free\npath $\\ell_\\text{MR}$ due to momentum-relaxing impurity scattering. This\nassumption, however, is overly simplistic and falls short at low temperatures,\nwhere it is known from exact diagonalization studies of the electronic\ncollision integral that another large electronic mean free path $\\ell_o$\nemerges, which describes long-lived odd electron modes -- this is sometimes\nknown as the tomographic effect. Here, using a matched asymptotic expansion of\nthe Fermi liquid kinetic equation that includes different electron relaxation\ntimes, we derive a general asymptotic theory for tomographic flows in arbitrary\nsmooth boundary geometries. Our key results are a set of governing equations\nfor the electron density and electron current, their slip boundary conditions\nand boundary layer corrections near diffuse edges. We find that the tomographic\neffect strongly modifies previous hydrodynamic theories for electron flows: In\nparticular, we find that (i) an equilibrium is established in the bulk, where\nthe flow is governed by Stokes-Ohm like equations with significant\nfinite-wavelength corrections, (ii) the velocity slip conditions for these\nequations are strongly modified from the widely-used hydrodynamic slip-length\ncondition (iii) a large kinetic boundary layer arises near diffuse boundaries\nof width $\\sim\\sqrt{\\ell_e \\ell_o}$, and (iv) all these effects are strongly\nsuppressed by an external magnetic field. We illustrate our findings for\nelectron flow in a channel. The equations derived here represent the\nfundamental governing equations for tomographic electron flow in arbitrary\nsmooth geometries."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.quant-gas",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-458",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.21272"
    ],
    "b_title":[
      "$B_h$-sets of real and complex numbers"
    ],
    "b_abstract":[
      "Let $K = \\mathbb{R}$ or $\\mathbb{C}$. An $n$-element subset $A$ of $K$ is a\n$B_h$-set if every element of $K$ has at most one representation as the sum of\n$h$ not necessarily distinct elements of $A$. Associated to the $B_h$ set $A =\n\\{a_1,\\ldots, a_n\\}$ are the $B_h$-vectors $\\mathbf{a} = (a_1,\\ldots, a_n)$ in\n$K^n$. This paper proves that ``almost all'' $n$-element subsets of $K$ are\n$B_h$-sets in the sense that the set of all $B_h$-vectors is a dense open\nsubset of $K^n$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.02626"
    ],
    "c_title":[
      "ArtistIC: An Open-Source Toolchain for Top-Metal IC Art and\n  Ultra-High-Fidelity GDSII Renders"
    ],
    "c_abstract":[
      "Open-source projects require outreach material to grow their community,\nsecure funds, and strengthen their influence. Numbers, specifications, and\nfacts alone are intangible to uninvolved people; using a clear brand and\nappealing visual material is thus ample to reach a broad audience. This is\nespecially true for application-specific integrated circuits (ASICs) during the\nearly stages of the development cycle without running prototype systems. This\nwork presents ArtistIC, an open-source framework to brand ASICs with top-metal\nart and to render GDSII layouts with ultra-high fidelity reaching render\ndensities below 25 nm\/px and gigapixels-scale resolutions."
    ],
    "c_categories":[
      [
        "cs.OH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-459",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05549"
    ],
    "b_title":[
      "On the characterization of uniqueness polynomials: both complex and\n  p-adic versions"
    ],
    "b_abstract":[
      "The problem \"A general characterization of uniqueness polynomial for\nnon-critically injective polynomials\" has been remained open since the last two\ndecades. In this paper, we explore this open problem. To this end, we initiate\na new approach that also includes critically injective polynomials. We provide\nthis characterization for both the complex and p-adic cases. We also provide\nvarious examples as an application of our results along with the verification\nof the existing examples. Consequently, we find examples of unique range sets\ngenerated by non-critically injective polynomials with least cardinalities\nachieved so far and one of these results is sharp with respect to all the\navailable formulas in the literature. Furthermore, we cover the part of least\ndegree uniqueness polynomials. In this part, we also provide some sharp bounds."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16922"
    ],
    "c_title":[
      "Benchmarking Temporal Reasoning and Alignment Across Chinese Dynasties"
    ],
    "c_abstract":[
      "Temporal reasoning is fundamental to human cognition and is crucial for\nvarious real-world applications. While recent advances in Large Language Models\nhave demonstrated promising capabilities in temporal reasoning, existing\nbenchmarks primarily rely on rule-based construction, lack contextual depth,\nand involve a limited range of temporal entities. To address these limitations,\nwe introduce Chinese Time Reasoning (CTM), a benchmark designed to evaluate\nLLMs on temporal reasoning within the extensive scope of Chinese dynastic\nchronology. CTM emphasizes cross-entity relationships, pairwise temporal\nalignment, and contextualized and culturally-grounded reasoning, providing a\ncomprehensive evaluation. Extensive experimental results reveal the challenges\nposed by CTM and highlight potential avenues for improvement."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-460",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16733"
    ],
    "b_title":[
      "Testing the bloated star hypothesis in the massive young stellar object\n  IRAS 19520+2759 through optical and infrared variability"
    ],
    "b_abstract":[
      "Using optical time series with Telescopi Joan Or\\'o (TJO), Gaia, TESS, and\nNEOWISE archival data, we performed a variability study on the candidate\nbloated massive young stellar object (MYSO) IRAS 19520+2759. This is the first\ntime that a bloated star candidate has been tested for the theoretically\npredicted periodic variability. The source is found to be variable at optical\nand mid-infrared wavelengths and classified as a long-period variable MYSO. The\nobserved TJO data gives a period of the source of $\\sim$ 270$\\pm$40 days (in\nthe Rc band) and $\\sim$ 270$\\pm$50 days (in the Ic band), which is very close\nto the value predicted by the theoretical Period-Luminosity relation for a\nbloated young star of $\\sim 10^5 L\\odot$. Additionally, a large period of\n$\\sim$ 460$\\pm$80 days (in the G band) and $\\sim$ 440$\\pm$70 (in the Rp band)\nis also visible in the Gaia light curve. The physical parameters of the source,\nsuch as mass, radius, and accretion rate, based on the theoretical predictions\nfor the spherical accretion case and corresponding to a period of 270--460\ndays, are $\\sim 24$--28$\\,M\\odot$, $\\sim 650$--900$\\,R\\odot$ and $\\sim\n(6$--$9)\\times10^{-3}\\,M\\odot yr^{-1}$. However, these numbers are very\nsensitive to the effective temperatures assumed in the models. Additionally,\nthese values strongly depend on the geometry of accretion and could\nsignificantly decrease for the case of a MYSO accreting through a disc. The\nobserved periodic variability, the observed colour trend, and the nature of the\nvariability are found to be consistent with the pulsational model for a bloated\nMYSO."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12335"
    ],
    "c_title":[
      "GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from\n  Illumination-Inconsistent Images"
    ],
    "c_abstract":[
      "Accurate geometric surface reconstruction, providing essential environmental\ninformation for navigation and manipulation tasks, is critical for enabling\nrobotic self-exploration and interaction. Recently, 3D Gaussian Splatting\n(3DGS) has gained significant attention in the field of surface reconstruction\ndue to its impressive geometric quality and computational efficiency. While\nrecent relevant advancements in novel view synthesis under inconsistent\nillumination using 3DGS have shown promise, the challenge of robust surface\nreconstruction under such conditions is still being explored. To address this\nchallenge, we propose a method called GS-3I. Specifically, to mitigate 3D\nGaussian optimization bias caused by underexposed regions in single-view\nimages, based on Convolutional Neural Network (CNN), a tone mapping correction\nframework is introduced. Furthermore, inconsistent lighting across multi-view\nimages, resulting from variations in camera settings and complex scene\nillumination, often leads to geometric constraint mismatches and deviations in\nthe reconstructed surface. To overcome this, we propose a normal compensation\nmechanism that integrates reference normals extracted from single-view image\nwith normals computed from multi-view observations to effectively constrain\ngeometric inconsistencies. Extensive experimental evaluations demonstrate that\nGS-3I can achieve robust and accurate surface reconstruction across complex\nillumination scenarios, highlighting its effectiveness and versatility in this\ncritical challenge. https:\/\/github.com\/TFwang-9527\/GS-3I"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-461",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11461"
    ],
    "b_title":[
      "MRS-CWC: A Weakly Constrained Multi-Robot System with Controllable\n  Constraint Stiffness for Mobility and Navigation in Unknown 3D Rough\n  Environments"
    ],
    "b_abstract":[
      "Navigating unknown three-dimensional (3D) rugged environments is challenging\nfor multi-robot systems. Traditional discrete systems struggle with rough\nterrain due to limited individual mobility, while modular systems--where rigid,\ncontrollable constraints link robot units--improve traversal but suffer from\nhigh control complexity and reduced flexibility. To address these limitations,\nwe propose the Multi-Robot System with Controllable Weak Constraints (MRS-CWC),\nwhere robot units are connected by constraints with dynamically adjustable\nstiffness. This adaptive mechanism softens or stiffens in real-time during\nenvironmental interactions, ensuring a balance between flexibility and\nmobility. We formulate the system's dynamics and control model and evaluate\nMRS-CWC against six baseline methods and an ablation variant in a benchmark\ndataset with 100 different simulation terrains. Results show that MRS-CWC\nachieves the highest navigation completion rate and ranks second in success\nrate, efficiency, and energy cost in the highly rugged terrain group,\noutperforming all baseline methods without relying on environmental modeling,\npath planning, or complex control. Even where MRS-CWC ranks second, its\nperformance is only slightly behind a more complex ablation variant with\nenvironmental modeling and path planning. Finally, we develop a physical\nprototype and validate its feasibility in a constructed rugged environment. For\nvideos, simulation benchmarks, and code, please visit\nhttps:\/\/wyd0817.github.io\/project-mrs-cwc\/."
    ],
    "b_categories":[
      [
        "cs.MA",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13416"
    ],
    "c_title":[
      "Correlation uncertainty: a decision-theoretic approach"
    ],
    "c_abstract":[
      "We provide a decision-theoretic foundation for uncertainty about the\ncorrelation structure on a Cartesian product of probability spaces. Our\ncontribution is two-fold: we first provide a full characterization of the set\nof possible correlations between subspaces as a convex polytope. Its extreme\npoints are identified as the local maxima of mutual information and as\nmaximally zero probability measures. Second, we derive an axiomatic\ncharacterization of preferences narrowing down the set of correlations a\ndecision maker considers, making behavior about correlation testable. Thereby,\nshe may regard collections of subspaces as independent from one another. We\nillustrate our model and results in simple examples on climate change,\ninsurance and portfolio choice."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-462",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13051"
    ],
    "b_title":[
      "Permutation Learning with Only N Parameters: From SoftSort to\n  Self-Organizing Gaussians"
    ],
    "b_abstract":[
      "Sorting and permutation learning are key concepts in optimization and machine\nlearning, especially when organizing high-dimensional data into meaningful\nspatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N\nparameters to determine a full permutation matrix, making it computationally\nexpensive for large datasets. Low-rank matrix factorization approximations\nreduce memory requirements to 2MN (with M << N), but they still struggle with\nvery large problems. SoftSort, by providing a continuous relaxation of the\nargsort operator, allows differentiable 1D sorting, but it faces challenges\nwith multidimensional data and complex permutations. In this paper, we present\na novel method for learning permutations using only N parameters, which\ndramatically reduces storage costs. Our approach builds on SoftSort, but\nextends it by iteratively shuffling the N indices of the elements to be sorted\nthrough a separable learning process. This modification significantly improves\nsorting quality, especially for multidimensional data and complex optimization\ncriteria, and outperforms pure SoftSort. Our method offers improved memory\nefficiency and scalability compared to existing approaches, while maintaining\nhigh-quality permutation learning. Its dramatically reduced memory requirements\nmake it particularly well-suited for large-scale optimization tasks, such as\n\"Self-Organizing Gaussians\", where efficient and scalable permutation learning\nis critical."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16117"
    ],
    "c_title":[
      "Improving Discriminator Guidance in Diffusion Models"
    ],
    "c_abstract":[
      "Discriminator Guidance has become a popular method for efficiently refining\npre-trained Score-Matching Diffusion models. However, in this paper, we\ndemonstrate that the standard implementation of this technique does not\nnecessarily lead to a distribution closer to the real data distribution.\nSpecifically, we show that training the discriminator using Cross-Entropy loss,\nas commonly done, can in fact increase the Kullback-Leibler divergence between\nthe model and target distributions, particularly when the discriminator\noverfits. To address this, we propose a theoretically sound training objective\nfor discriminator guidance that properly minimizes the KL divergence. We\nanalyze its properties and demonstrate empirically across multiple datasets\nthat our proposed method consistently improves over the conventional method by\nproducing samples of higher quality."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-463",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02731"
    ],
    "b_title":[
      "New investigation of the electronic and structural properties of\n  (Mg,Ti)-doped and co-doped ZnO structures: A DFT and DFT+U study"
    ],
    "b_abstract":[
      "This study investigates the novelty of the crystalline and electronic\nstructure of (Mg,Ti)-doped ZnO and the co-doped Zn1-x-yMgxTiyO structures using\nGaussian and plane-wave basis sets, as implemented in the CP2K code. The goal\nof incorporating low concentration of Mg and Ti into ZnO is to influence its\nelectronic properties without significantly altering its geometrical and\ncrystalline structure. Within the framework of density functional theory (DFT),\nwe analyze various doped and co-doped configurations. Our results show that\nTi-doped ZnO exhibits an indirect band gap, while Mg doping preserves the\ndirect semiconductor behavior of ZnO structure, with an increase in band gap\nenergy. Additionally, the co-doped Zn1-x-yMgxTiyO system, at varying\nconcentrations of Ti and Mg, displays minimal lattice deformation. These\nfindings suggest that this material could be a promising candidate for\ntransparent electronic devices, highlighting the importance of understanding\nthe electronic structure of ZnO to optimize its physical properties."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.09318"
    ],
    "c_title":[
      "FpgaHub: Fpga-centric Hyper-heterogeneous Computing Platform for Big\n  Data Analytics"
    ],
    "c_abstract":[
      "Modern data analytics requires a huge amount of computing power and processes\na massive amount of data. At the same time, the underlying computing platform\nis becoming much more heterogeneous on both hardware and software. Even though\nspecialized hardware, e.g., FPGA- or GPU- or TPU-based systems, often achieves\nbetter performance than a CPU-only system due to the slowing of Moore's law,\nsuch systems are limited in what they can do. For example, GPU-only approaches\nsuffer from severe IO limitations. To truly exploit the potential of hardware\nheterogeneity, we present FpgaHub, an FPGA-centric hyper-heterogeneous\ncomputing platform for big data analytics. The key idea of FpgaHub is to use\nreconfigurable computing to implement a versatile hub complementing other\nprocessors (CPUs, GPUs, DPUs, programmable switches, computational storage,\netc.). Using an FPGA as the basis, we can take advantage of its highly\nreconfigurable nature and rich IO interfaces such as PCIe, networking, and\non-board memory, to place it at the center of the architecture and use it as a\ndata and control plane for data movement, scheduling, pre-processing, etc.\nFpgaHub enables architectural flexibility to allow exploring the rich design\nspace of heterogeneous computing platforms."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-464",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08486"
    ],
    "b_title":[
      "The NEMESIS Catalogue of Young Stellar Objects for the Orion Star\n  Formation Complex. I. General description of data curation"
    ],
    "b_abstract":[
      "The past decade has seen a rise in the use of Machine Learning methods in the\nstudy of young stellar evolution. This trend has led to a growing need for a\ncomprehensive database of young stellar objects (YSO) that goes beyond\nsurvey-specific biases and that can be employed for training, validation, and\nrefining the physical interpretation of machine learning outcomes. We reviewed\nthe literature focused on the Orion Star Formation complex (OSFC) to compile a\nthorough catalogue of previously identified YSO candidates in the region\nincluding the curation of observables relevant to probe their youth. Starting\nfrom the NASA\/ADS database, we assembled YSO candidates from more than 200\npeer-reviewed publications. We collated data products relevant to the study of\nYSOs into a dedicated catalogue, which was complemented with data from large\nphotometric and spectroscopic surveys and in the Strasbourg astronomical Data\nCenter. We also added significant value to the catalogue by homogeneously\nderiving YSO infrared classification labels and through a comprehensive\ncuration of labels concerning sources' multiplicity. Finally, we used a\npanchromatic approach to derive the probabilities that the sources in our\ncatalogue were contaminant extragalactic sources or giant stars. We present the\nNEMESIS catalogue of YSOs for the OSFC, which includes data collated for 27879\nsources covering the whole mass spectrum and the various stages of pre-Main\nSequence evolution from protostars to diskless young stars. The catalogue\nincludes a collection of panchromatic photometric data processed into spectral\nenergy distributions, stellar parameters, infrared classes, equivalent widths\nof emission lines related to YSOs accretion and star-disk interaction, and\nabsorption lines such as lithium and lines related to source's gravity, X-ray\nemission observables, photometric variability observables, and multiplicity\nlabels."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12291"
    ],
    "c_title":[
      "Text-Driven Video Style Transfer with State-Space Models: Extending\n  StyleMamba for Temporal Coherence"
    ],
    "c_abstract":[
      "StyleMamba has recently demonstrated efficient text-driven image style\ntransfer by leveraging state-space models (SSMs) and masked directional losses.\nIn this paper, we extend the StyleMamba framework to handle video sequences. We\npropose new temporal modules, including a \\emph{Video State-Space Fusion\nModule} to model inter-frame dependencies and a novel \\emph{Temporal Masked\nDirectional Loss} that ensures style consistency while addressing scene changes\nand partial occlusions. Additionally, we introduce a \\emph{Temporal\nSecond-Order Loss} to suppress abrupt style variations across consecutive\nframes. Our experiments on DAVIS and UCF101 show that the proposed approach\noutperforms competing methods in terms of style consistency, smoothness, and\ncomputational efficiency. We believe our new framework paves the way for\nreal-time text-driven video stylization with state-of-the-art perceptual\nresults."
    ],
    "c_categories":[
      [
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-465",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01838"
    ],
    "b_title":[
      "Electronic band structures of topological kagome materials"
    ],
    "b_abstract":[
      "The kagome lattice has garnered significant attention due to its ability to\nhost quantum spin Fermi liquid states. Recently, the combination of unique\nlattice geometry, electron-electron correlations, and adjustable magnetism in\nsolid kagome materials has led to the discovery of numerous fascinating quantum\nproperties. These include unconventional superconductivity, charge and spin\ndensity waves (CDW\/SDW), pair density waves (PDW), and Chern insulator phases.\nThese emergent states are closely associated with the distinctive\ncharacteristics of the kagome lattice's electronic structure, such as van Hove\nsingularities, Dirac fermions, and flat bands, which can exhibit exotic\nquasi-particle excitations under different symmetries and magnetic conditions.\nRecently, various quantum kagome materials have been developed, typically\nconsisting of kagome layers stacked along the $z$-axis with atoms either\nfilling the geometric centers of the kagome lattice or embedded between the\nlayers. In this topical review, we begin by introducing the fundamental\nproperties of several kagome materials. To gain an in-depth understanding of\nthe relationship between topology and correlation, we then discuss the complex\nphenomena observed in these systems. These include the simplest kagome metal\n$T_3X$, kagome intercalation metal $TX$, and the ternary compounds $AT_6X_6$\nand $RT_3X_5$ ($A$ = Li, Mg, Ca, or rare earth; $T$ = V, Cr, Mn, Fe, Co, Ni;\n$X$ = Sn, Ge; $R$ = K, Rb, Cs). Finally, we provide a perspective on future\nexperimental work in this field."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17645"
    ],
    "c_title":[
      "A Modular Dataset to Demonstrate LLM Abstraction Capability"
    ],
    "c_abstract":[
      "Large language models (LLMs) exhibit impressive capabilities but struggle\nwith reasoning errors due to hallucinations and flawed logic. To investigate\ntheir internal representations of reasoning, we introduce ArrangementPuzzle, a\nnovel puzzle dataset with structured solutions and automated stepwise\ncorrectness verification. We trained a classifier model on LLM activations on\nthis dataset and found that it achieved over 80% accuracy in predicting\nreasoning correctness, implying that LLMs internally distinguish between\ncorrect and incorrect reasoning steps, with the strongest representations in\nmiddle-late Transformer layers. Further analysis reveals that LLMs encode\nabstract reasoning concepts within the middle activation layers of the\ntransformer architecture, distinguishing logical from semantic equivalence.\nThese findings provide insights into LLM reasoning mechanisms and contribute to\nimproving AI reliability and interpretability, thereby offering the possibility\nto manipulate and refine LLM reasoning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-466",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09588"
    ],
    "b_title":[
      "Atleus: Accelerating Transformers on the Edge Enabled by 3D\n  Heterogeneous Manycore Architectures"
    ],
    "b_abstract":[
      "Transformer architectures have become the standard neural network model for\nvarious machine learning applications including natural language processing and\ncomputer vision. However, the compute and memory requirements introduced by\ntransformer models make them challenging to adopt for edge applications.\nFurthermore, fine-tuning pre-trained transformers (e.g., foundation models) is\na common task to enhance the model's predictive performance on specific\ntasks\/applications. Existing transformer accelerators are oblivious to\ncomplexities introduced by fine-tuning. In this paper, we propose the design of\na three-dimensional (3D) heterogeneous architecture referred to as Atleus that\nincorporates heterogeneous computing resources specifically optimized to\naccelerate transformer models for the dual purposes of fine-tuning and\ninference. Specifically, Atleus utilizes non-volatile memory and systolic array\nfor accelerating transformer computational kernels using an integrated 3D\nplatform. Moreover, we design a suitable NoC to achieve high performance and\nenergy efficiency. Finally, Atleus adopts an effective quantization scheme to\nsupport model compression. Experimental results demonstrate that Atleus\noutperforms existing state-of-the-art by up to 56x and 64.5x in terms of\nperformance and energy efficiency respectively"
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07097"
    ],
    "c_title":[
      "Does Entanglement Correlation in Ground State Guarantee Quantum Energy\n  Teleportation?"
    ],
    "c_abstract":[
      "Although extraction of energy from the ground state is forbidden, one can\nutilize Quantum Energy Teleportation (QET) protocol for energy extraction -- a\ntwo-step protocol involving quantum measurements followed by LOCC. This is an\nunique method to ``extract energy from ground states'' of quantum systems. QET\nrequires some correlation in the ground state, and entanglement correlation\nplays a crucial roles as a resource. The general belief is that if the ground\nstate is quantum-correlated via entanglement for two different sites in a\nquantum system, and if we perform measurements on one of the sites, we can find\nan LOCC for the other site to successfully accomplish QET. In this paper, we\nshow that this belief may not be true in the case of the Toric Code. We\ndemonstrate this by performing a PVM measurements on spins in the Toric Code.\nBased on the measurement outcomes, we found that there is no LOCC for\nsuccessful QET."
    ],
    "c_categories":[
      [
        "cond-mat.other",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-467",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08447"
    ],
    "b_title":[
      "Investigating the broadening phenomenon in two-particle correlations\n  induced by gluon saturation"
    ],
    "b_abstract":[
      "It has been found that the gluon density inside the proton grows rapidly at\nsmall momentum fractions. Quantum Chromodynamics (QCD) predicts that this\ngrowth can be regulated by nonlinear effects, ultimately leading to gluon\nsaturation. Within the color glass condensate framework, nonlinear QCD effects\nare predicted to suppress and broaden back-to-back angular correlations in\ncollisions involving heavy nuclei. While suppression has been observed in\nvarious experiments in $d\/p$$+$A collisions compared to $p$$+$$p$ collisions,\nthe predicted broadening remains unobserved. This study investigates the\ncontributions of intrinsic transverse momentum ($k_T$), which is associated\nwith saturation physics, as well as parton showers and transverse motion from\nfragmentation ($p_T^{\\mathrm{frag}}$), which are not saturation dependent, to\nthe width of the correlation function. Our findings show that the\nnon-saturation dependent effects, especially the initial-state parton shower\nand $p_T^{\\mathrm{frag}}$, which occur independently of the collision system,\nsmear the back-to-back correlation more than gluon saturation does, making the\nbroadening phenomenon difficult to observe."
    ],
    "b_categories":[
      [
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11464"
    ],
    "c_title":[
      "BagChain: A Dual-functional Blockchain Leveraging Bagging-based\n  Distributed Learning"
    ],
    "c_abstract":[
      "This work proposes a dual-functional blockchain framework named BagChain for\nbagging-based decentralized learning. BagChain integrates blockchain with\ndistributed machine learning by replacing the computationally costly hash\noperations in proof-of-work with machine-learning model training. BagChain\nutilizes individual miners' private data samples and limited computing\nresources to train potentially weak base models, which may be very weak, and\nfurther aggregates them into strong ensemble models. Specifically, we design a\nthree-layer blockchain structure associated with the corresponding generation\nand validation mechanisms to enable distributed machine learning among\nuncoordinated miners in a permissionless and open setting. To reduce\ncomputational waste due to blockchain forking, we further propose the cross\nfork sharing mechanism for practical networks with lengthy delays. Extensive\nexperiments illustrate the superiority and efficacy of BagChain when handling\nvarious machine learning tasks on both independently and identically\ndistributed (IID) and non-IID datasets. BagChain remains robust and effective\neven when facing constrained local computing capability, heterogeneous private\nuser data, and sparse network connectivity."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-468",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01491"
    ],
    "b_title":[
      "Memorization Inheritance in Sequence-Level Knowledge Distillation for\n  Neural Machine Translation"
    ],
    "b_abstract":[
      "In this work, we explore how instance-level memorization in the teacher\nNeural Machine Translation (NMT) model gets inherited by the student model in\nsequence-level knowledge distillation (SeqKD). We find that despite not\ndirectly seeing the original training data, students memorize more than\nbaseline models (models of the same size, trained on the original data) -- 3.4%\nfor exact matches and 57% for extractive memorization -- and show increased\nhallucination rates. Further, under this SeqKD setting, we also characterize\nhow students behave on specific training data subgroups, such as subgroups with\nlow quality and specific counterfactual memorization (CM) scores, and find that\nstudents exhibit amplified denoising on low-quality subgroups. Finally, we\npropose a modification to SeqKD named Adaptive-SeqKD, which intervenes in SeqKD\nto reduce memorization and hallucinations. Overall, we recommend caution when\napplying SeqKD: students inherit both their teachers' superior performance and\ntheir fault modes, thereby requiring active monitoring."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08998"
    ],
    "c_title":[
      "CrystalGRW: Generative Modeling of Crystal Structures with Targeted\n  Properties via Geodesic Random Walks"
    ],
    "c_abstract":[
      "Determining whether a candidate crystalline material is thermodynamically\nstable depends on identifying its true ground-state structure, a central\nchallenge in computational materials science. We introduce CrystalGRW, a\ndiffusion-based generative model on Riemannian manifolds that proposes novel\ncrystal configurations and can predict stable phases validated by density\nfunctional theory. The crystal properties, such as fractional coordinates,\natomic types, and lattice matrices, are represented on suitable Riemannian\nmanifolds, ensuring that new predictions generated through the diffusion\nprocess preserve the periodicity of crystal structures. We incorporate an\nequivariant graph neural network to also account for rotational and\ntranslational symmetries during the generation process. CrystalGRW demonstrates\nthe ability to generate realistic crystal structures that are close to their\nground states with accuracy comparable to existing models, while also enabling\nconditional control, such as specifying a desired crystallographic point group.\nThese features help accelerate materials discovery and inverse design by\noffering stable, symmetry-consistent crystal candidates for experimental\nvalidation."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech",
        "cs.LG",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-469",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15548"
    ],
    "b_title":[
      "Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval"
    ],
    "b_abstract":[
      "The widespread adoption of Retrieval-Augmented Generation (RAG) systems in\nreal-world applications has heightened concerns about the confidentiality and\nintegrity of their proprietary knowledge bases. These knowledge bases, which\nplay a critical role in enhancing the generative capabilities of Large Language\nModels (LLMs), are increasingly vulnerable to breaches that could compromise\nsensitive information. To address these challenges, this paper proposes an\nadvanced encryption methodology designed to protect RAG systems from\nunauthorized access and data leakage. Our approach encrypts both textual\ncontent and its corresponding embeddings prior to storage, ensuring that all\ndata remains securely encrypted. This mechanism restricts access to authorized\nentities with the appropriate decryption keys, thereby significantly reducing\nthe risk of unintended data exposure. Furthermore, we demonstrate that our\nencryption strategy preserves the performance and functionality of RAG\npipelines, ensuring compatibility across diverse domains and applications. To\nvalidate the robustness of our method, we provide comprehensive security proofs\nthat highlight its resilience against potential threats and vulnerabilities.\nThese proofs also reveal limitations in existing approaches, which often lack\nrobustness, adaptability, or reliance on open-source models. Our findings\nsuggest that integrating advanced encryption techniques into the design and\ndeployment of RAG systems can effectively enhance privacy safeguards. This\nresearch contributes to the ongoing discourse on improving security measures\nfor AI-driven services and advocates for stricter data protection standards\nwithin RAG architectures."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16202"
    ],
    "c_title":[
      "Non-ergodicity for the noisy majority vote process on trees"
    ],
    "c_abstract":[
      "We consider the noisy majority vote process on infinite regular trees with\ndegree $d\\geq 3$, and we prove the non-ergodicity, i.e., there exist multiple\nequilibrium measures. Our work extends a result of Bramson and Gray (2021) for\n$d\\geq 5$."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-470",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00593"
    ],
    "b_title":[
      "Electromagnetic Electron Kelvin-Helmholtz Instability"
    ],
    "b_abstract":[
      "On electron kinetic scales, ions and electrons decouple, and electron\nvelocity shear on electron inertial length $\\sim d_e$ can trigger\nelectromagnetic (EM) electron Kelvin-Helmholtz instability (EKHI). In this\npaper, we present an analytic study of EM EKHI in an inviscid collisionless\nplasma with a step-function electron shear flow. We show that in incompressible\ncollisionless plasma the ideal electron frozen-in condition $\\mathbf{E} +\n\\mathbf{v}_e \\times \\mathbf{B}\/c = 0$ must be broken for the EM EKHI to occur.\nIn a step-function electron shear flow, the ideal electron frozen-in condition\nis replaced by magnetic flux conservation, i.e., $\\nabla \\times (\\mathbf{E} +\n\\mathbf{v}_e\\times \\mathbf{B}\/c) = 0$, resulting in a dispersion relation\nsimilar to that of the standard ideal and incompressible magnetohydrodynamics\nKHI. The magnetic field parallel to the electron streaming suppresses the EM\nEKHI due to magnetic tension. The threshold for the EM mode of the EKHI is\n$(\\mathbf{k}\\cdot\\Delta\\mathbf{U}_e)^2>\\frac{n_{e1}+n_{e2}}{n_{e1}\nn_{e2}}[n_{e1}(\\mathbf{v}_{Ae1}\\cdot\\mathbf{k})^2+n_{e2}(\\mathbf{v}_{Ae2}\\cdot\\mathbf{k})^2]$,\nwhere $\\mathbf{v}_{Ae} =\\mathbf{B}\/(4\\pi m_e n_e)^{1\/2}$, $\\Delta\\mathbf{U}_e$\nand $n_e$ are the electron streaming velocity shear and densities,\nrespectively. The growth rate of the EM mode is $\\gamma_{em} \\sim \\Omega_{ce}$,\nthe electron gyro-frequency."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.00129"
    ],
    "c_title":[
      "The Zakharov System on the Upper Half-Plane"
    ],
    "c_abstract":[
      "In this paper we study the Zakharov system on the upper half--plane $U=\\{(x\n,y)\\in \\R^2: y>0\\}$ with non-homogenous boundary conditions. In particular we\nobtain low regularity local well--posedness using the restricted norm method of\nBourgain and the Fourier--Laplace method of solving initial and boundary value\nproblems. Moreover we prove that the nonlinear part of the solution is in a\nsmoother space than the initial data. To our knowledge this is the first paper\nwhich establishes low regularity results for the 2d initial-boundary value\nZakharov system."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-471",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00562"
    ],
    "b_title":[
      "Quantum Lamb model"
    ],
    "b_abstract":[
      "H. Lamb considered the classical dynamics of a vibrating particle embedded in\nan elastic medium before the development of quantum theory. Lamb was interested\nin how the back-action of the elastic waves generated can damp the vibrations\nof the particle. We propose a quantum version of Lamb's model. We show that\nthis model is exactly solvable by using a multimode Bogoliubov transformation.\nWe show that the exact system ground state is a multimode squeezed vacuum\nstate, and we obtain the exact Bogoliubov frequencies by numerically solving a\nnonlinear integral equation. A closed-form expression for the damping rate of\nthe particle is obtained, and we find that it agrees with the result obtained\nby perturbation theory for coupling strength below a critical value. The model\nis found to break down for coupling strength above the critical value where the\nlowest Bogoliubov frequency vanishes. We show that the addition of an\nanharmonic elastic term is sufficient to stabilize the system in this strong\ncoupling regime."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.14256"
    ],
    "c_title":[
      "Revisiting Applicable and Comprehensive Knowledge Tracing in Large-Scale\n  Data"
    ],
    "c_abstract":[
      "Knowledge Tracing (KT) is a fundamental component of Intelligent Tutoring\nSystems (ITS), enabling the modeling of students' knowledge states to predict\nfuture performance. The introduction of Deep Knowledge Tracing (DKT), the first\ndeep learning-based KT (DLKT) model, has brought significant advantages in\nterms of applicability and comprehensiveness. However, recent DLKT models, such\nas Attentive Knowledge Tracing (AKT), have often prioritized predictive\nperformance at the expense of these benefits. While deep sequential models like\nDKT have shown potential, they face challenges related to parallel computing,\nstorage decision modification, and limited storage capacity. To address these\nlimitations, we propose DKT2, a novel KT model that leverages the recently\ndeveloped xLSTM architecture. DKT2 enhances input representation using the\nRasch model and incorporates Item Response Theory (IRT) for interpretability,\nallowing for the decomposition of learned knowledge into familiar and\nunfamiliar knowledge. By integrating this knowledge with predicted questions,\nDKT2 generates comprehensive knowledge states. Extensive experiments conducted\nacross three large-scale datasets demonstrate that DKT2 consistently\noutperforms 17 baseline models in various prediction tasks, underscoring its\npotential for real-world educational applications. This work bridges the gap\nbetween theoretical advancements and practical implementation in KT.Our code\nand datasets will be available at https:\/\/github.com\/codebase-2025\/DKT2."
    ],
    "c_categories":[
      [
        "cs.IR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-472",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05238"
    ],
    "b_title":[
      "Neutrino spin oscillations near a black hole"
    ],
    "b_abstract":[
      "In this work, we study neutrino spin oscillations in the case when they are\ngravitationally scattered off a rotating Kerr black hole surrounded by a thick\nmagnetized accretion disk. We consider only toroidal magnetic field inside the\ndisk. Neutrino spin precession is caused by the interaction of the neutrino\nmagnetic moment with the magnetic field in the disk. Our treatment of the spin\noscillations of the observed neutrino fluxes is based on numerical simulations\nof the propagation of a large number of incoming test neutrinos using High\nPerformance Parallel Computing. We briefly discuss our results and their\napplications in the observations of astrophysical neutrinos."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08868"
    ],
    "c_title":[
      "Extendibility of Latin Hypercuboids"
    ],
    "c_abstract":[
      "A Latin hypercuboid of order $n$ is a $d$-dimensional matrix of dimensions\n$n\\times n\\times\\cdots\\times n\\times k$, with symbols from a set of cardinality\n$n$ such that each symbol occurs at most once in each axis-parallel line. If\n$k=n$ the hypercuboid is a Latin hypercube. The Latin hypercuboid is\n\\emph{completable} if it is contained in a Latin hypercube of the same order\nand dimension. It is \\emph{extendible} if it can have one extra layer added. In\nthis note we consider which Latin hypercuboids are completable\/extendible. We\nalso consider a generalisation that involves multidimensional arrays of sets\nthat satisfy certain balance properties. The extendibility problem corresponds\nto choosing representatives from the sets in a way that is analogous to a\nchoice of a Hall system of distinct representatives, but in higher dimensions.\nThe completability problem corresponds to partitioning the sets into such SDRs.\nWe provide a construction for such an array of sets that does not have the\nproperty analogous to completability. A related concept was introduced by\nH\\\"aggkvist under the name $(m,m,m)$-array. We generalise a construction of\n$(m,m,m)$-arrays credited to Pebody, but show that it cannot be used to build\nthe arrays that we need."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-473",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17066"
    ],
    "b_title":[
      "Formation of condensations for non-radial solutions to 3-wave kinetic\n  equations"
    ],
    "b_abstract":[
      "We consider in this work a $2$-dimensional $3$-wave kinetic equation\ndescribing the dynamics of the thermal cloud outside a Bose-Einstein\nCondensate. We construct global non-radial mild solutions for the equation.\nThose mild solutions are the summation of Dirac masses on circles. We prove\nthat in each spatial direction, either Dirac masses at the origin, which are\nthe so-called Bose-Einstein condensates, can be formed in finite time or the\nsolutions converge to Bose-Einstein condensates as time evolves to infinity. We\nalso describe a dynamics of the formation of the Bose-Einstein condensates\nlatter case. In this case, on each direction, the solutions accumulate around\ncircles close to the origin at growth rates at least linearly in time."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.18233"
    ],
    "c_title":[
      "Deciphering the Origins of the Elements Through Galactic Archeology"
    ],
    "c_abstract":[
      "Low-metallicity stars preserve the signatures of the first stellar\nnucleosynthesis events in the Galaxy, as their surface abundances reflect the\ncomposition of the interstellar medium from which they were born. Aside from\nprimordial Big Bang nucleosynthesis, massive stars, due to their short\nlifetimes, dominate the ejecta into the interstellar medium of the early\nGalaxy. Most of them will end as core-collapse supernova (CCSN) explosions, and\ntypical ejected abundance distributions, e.g. in terms of the\nalpha-element-to-Fe ratios, reflect these contributions. Essentially all CCSNe\ncontribute 56Fe. Therefore, low-metallicity stars can be used to test whether\nthe abundances of any other elements are correlated with those of Fe, i.e.\nwhether these elements have been co-produced in the progenitor sources or if\nthey require either a different or additional astrophysical origin(s). The\npresent analysis focuses on stars with [Fe\/H]<-2, as they probe the earliest\nformation phase of the Galaxy when only one or very few nucleosynthesis events\nhad contributed their ejecta to the gas from which the lowest metallicity stars\nform. This was also the era before low and intermediate mass stars (or type Ia\nsupernovae) could contribute any additional heavy elements. Following earlier\nworks into the origin of heavy r-process elements [1], we extend the present\nstudy to examine Pearson and Spearman correlations of Fe with Li, Be, C, N, Na,\nMg, Si, S, Ca, Ti, Cr, Ni, Zn, Ge, Se, Sr, Zr, Ba, Ce, Sm, Eu, Yb, Lu, Hf, Os,\nIr, Pb, Th, and U, using high-resolution stellar abundance data from the SAGA\n[2] and JINA [3] databases. The main goal is to identify which of the observed\nelements (i) may have been co-produced with Fe in (possibly a variety of)\nCCSNe, and which elements require (ii) either a completely different, or (iii)\nat least an additional astrophysical origin."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-474",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02139"
    ],
    "b_title":[
      "The space writhes and signatures of polymer knots"
    ],
    "b_abstract":[
      "The space writhe of a knot is a property of its three-dimensional embedding\nthat contains information about its underlying topology, but the correspondence\nbetween space writhe and other topological invariants is not fully understood.\nWe perform Langevin dynamics simulations of knotted semiflexible polymers and\nmeasure their ensemble average space writhe. We show that for all knots up to\n10 crossings, alternating and non-alternating, the average space writhe is\nalmost equal to that of the tightest known configuration of the same knot, with\nminor differences. Using this equivalence, we show that for more complex knots\nwith up to 38 crossings, the average space writhe is strongly correlated with\nthe signature of the knot. This establishes that the connection between\nsignature and space writhe holds at larger crossing numbers."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.13572"
    ],
    "c_title":[
      "VeriContaminated: Assessing LLM-Driven Verilog Coding for Data\n  Contamination"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) have revolutionized code generation, achieving\nexceptional results on various established benchmarking frameworks. However,\nconcerns about data contamination - where benchmark data inadvertently leaks\ninto pre-training or fine-tuning datasets - raise questions about the validity\nof these evaluations. While this issue is known, limiting the industrial\nadoption of LLM-driven software engineering, hardware coding has received\nlittle to no attention regarding these risks. For the first time, we analyze\nstate-of-the-art (SOTA) evaluation frameworks for Verilog code generation\n(VerilogEval and RTLLM), using established methods for contamination detection\n(CCD and Min-K% Prob). We cover SOTA commercial and open-source LLMs\n(CodeGen2.5, Minitron 4b, Mistral 7b, phi-4 mini, LLaMA-{1,2,3.1},\nGPT-{2,3.5,4o}, Deepseek-Coder, and CodeQwen 1.5), in baseline and fine-tuned\nmodels (RTLCoder and Verigen). Our study confirms that data contamination is a\ncritical concern. We explore mitigations and the resulting trade-offs for code\nquality vs fairness (i.e., reducing contamination toward unbiased\nbenchmarking)."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.CR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-475",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09610"
    ],
    "b_title":[
      "Elucidating the Physical and Mathematical Properties of the\n  Prouhet-Thue-Morse Sequence in Quantum Computing"
    ],
    "b_abstract":[
      "This study explores the applications of the Prouhet-Thue-Morse (PTM) sequence\nin quantum computing, highlighting its mathematical elegance and practical\nrelevance. We demonstrate the critical role of the PTM sequence in quantum\nerror correction, in noise-resistant quantum memories, and in providing\ninsights into quantum chaos. Notably, we demonstrate how the PTM sequence\nnaturally appears in Ising X-X interacting systems, leading to a proposed\nrobust encoding of quantum memories in such systems. Furthermore, connections\nto number theory, including the Riemann zeta function, bridge quantum computing\nwith pure mathematics. Our findings emphasize the PTM sequence's importance in\nunderstanding the mathematical structure of quantum computing systems and the\ndevelopment of the full potential of quantum technologies and invite further\ninterdisciplinary research."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.14470"
    ],
    "c_title":[
      "What's the matter with $\\Sigma m_{\\nu}$?"
    ],
    "c_abstract":[
      "Due to non-zero neutrino rest masses we expect the energy density today in\nnon-relativistic matter, $\\omega_{\\rm m}$, to be greater than the sum of baryon\nand cold dark matter densities, $\\omega_{\\rm cb}$. We also expect the amplitude\nof deflections of CMB photons due to gravitational lensing to be suppressed\nrelative to expectations assuming massless neutrinos. The combination of CMB\nand BAO data, however, appear to be defying both of these expectations. Here we\nreview how the neutrino rest mass is determined from cosmological observations,\nand emphasize the complementary roles played by BAO and lensing data in this\nprocess. We explain why, for current constraints on the sum of neutrino masses,\nthe addition of BAO data to primary CMB data is much more informative than the\naddition of CMB lensing reconstruction data. We then use a phenomenological\nmodel to find that the preference from CMB and BAO data for a matter density\nthat is below expectations from the CMB alone is at the $3\\, \\sigma$ level. We\nalso show that if a fraction of the dark matter decays to dark radiation, the\npreference for $\\omega_{\\rm m} > \\omega_{\\rm cb}$ can be restored, but with a\nsmall increase to the CMB lensing excess."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-476",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09803"
    ],
    "b_title":[
      "Graph Neural Networks for Travel Distance Estimation and Route\n  Recommendation Under Probabilistic Hazards"
    ],
    "b_abstract":[
      "Estimating the shortest travel time and providing route recommendation\nbetween different locations in a city or region can quantitatively measure the\nconditions of the transportation network during or after extreme events. One\ncommon approach is to use Dijkstra's Algorithm, which produces the shortest\npath as well as the shortest distance. However, this option is computationally\nexpensive when applied to large-scale networks. This paper proposes a novel\nfast framework based on graph neural networks (GNNs) which approximate the\nsingle-source shortest distance between pairs of locations, and predict the\nsingle-source shortest path subsequently. We conduct multiple experiments on\nsynthetic graphs of different size to demonstrate the feasibility and\ncomputational efficiency of the proposed model. In real-world case studies, we\nalso applied the proposed method of flood risk analysis of coastal urban areas\nto calculate delays in evacuation to public shelters during hurricanes. The\nresults indicate the accuracy and computational efficiency of the GNN model,\nand its potential for effective implementation in emergency planning and\nmanagement."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12768"
    ],
    "c_title":[
      "The geometry of zonotopal algebras I: cohomology of graphical\n  configuration spaces"
    ],
    "c_abstract":[
      "Zonotopal algebras of vector arrangements are combinatorially-defined\nalgebras with connections to approximation theory, introduced by Holtz and Ron\nand independently by Ardila and Postnikov. We show that the internal zonotopal\nalgebra of a cographical vector arrangement is isomorphic to the cohomology\nring of a certain configuration space introduced by Moseley, Proudfoot, and\nYoung. We also study an integral form of this algebra, which in the cographical\ncase is isomorphic to the integral cohomology ring. Our results rely on\ninterpreting the internal zonotopal algebra of a totally unimodular arrangement\nas an orbit harmonics ring, that is, as the associated graded of the ring of\nfunctions on a finite set of lattice points."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-477",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14421"
    ],
    "b_title":[
      "Reasoning about Weak Isolation Levels in Separation Logic"
    ],
    "b_abstract":[
      "Isolation levels, consistency guarantees among concurrently execution\ntransactions in local- and distributed systems, have been formalized in a\nnumber of models. Thus far, no model can reason about executable\nimplementations of databases or local transaction libraries providing weak\nisolation levels. Weak isolation levels are characterized by being highly\nconcurrent and, unlike their stronger counterpart serializability, they are not\nequivalent to the consistency guarantees provided by a transaction library\nimplemented using a global lock. In this paper, we formalize three weak\nisolation levels in separation logic, namely read uncommitted, read committed,\nand snapshot isolation. We define modular separation logic specifications that\nare independent of the underlying transaction library implementation.\nHistorically, isolation levels have been specified using examples of executions\nbetween concurrent transactions that are not allowed to occur, and we\ndemonstrate that our specifications correctly prohibit such examples. To show\nthat our specifications are realizable, we formally verify that an executable\nimplementation of a key-value database running the multi-version concurrency\ncontrol algorithm from the original snapshot isolation paper satisfies our\nspecification of snapshot isolation. Moreover, we prove implications between\nthe specifications -- snapshot isolation implies read committed and read\ncommitted implies read uncommitted -- and thus the verification effort of the\ndatabase serves as proof that all of our specifications are realizable. All\nresults are mechanised in the Coq proof assistant on top of the Iris separation\nlogic framework."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04913"
    ],
    "c_title":[
      "The HST-Hyperion Survey: Companion Fraction and Overdensity in a z ~ 2.5\n  Proto-supercluster"
    ],
    "c_abstract":[
      "We present a study of the galaxy merger and interaction activity within the\nHyperion Proto-supercluster at z~2.5 in an effort to assess the occurrence of\ngalaxy mergers and interactions in contrast to the coeval field and their\nimpact on the build up of stellar mass in high density environments at\nhigher-z. For this work, we utilize data from the Charting Cluster Construction\nwith VUDS and ORELSE Survey (C3VO) along with extensive spectroscopic and\nphotometric datasets available for the COSMOS field, including the HST-Hyperion\nSurvey. To evaluate potential merger and interaction activity, we measure the\nfraction of galaxies with close kinematic companions ($f_{ckc}$) both within\nHyperion and the coeval field by means of a Monte Carlo (MC) methodology\ndeveloped in this work that probabilistically employs our entire combined\nspectroscopic and photometric dataset. We validate our $f_{ckc}$ MC methodology\non a simulated lightcone built from the GAlaxy Evolution and Assembly\nsemi-analytic model, and we determine correction factors that account for the\nunderlying spectroscopic sampling rate of our dataset. We find that galaxies in\nHyperion have close kinematic companions $\\gtrsim 2\\times$ more than galaxies\nin the field and measure a corrected $f_{ckc}=49_{-7.8}^{+7.4}$% for Hyperion\nand a corrected $f_{ckc}=23_{-1.3}^{+1.2}$% for the surrounding field; a\n$>3\\sigma$ difference. This increase in $f_{ckc}$ indicates an enhancement in\nthe merger and interaction activity within Hyperion and matches the trend seen\nin other structures. The rate of merger and interactions within the field\nimplied from our field $f_{ckc}$ measurement is well aligned with values\nmeasured from other observations in similar redshift ranges. The enhanced\n$f_{ckc}$ measured within Hyperion suggests that merger and interaction\nactivity play an important role in the mass growth of galaxies in denser\nenvironments at higher z."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-478",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01186"
    ],
    "b_title":[
      "Unbounded rough drivers, rough PDEs and applications"
    ],
    "b_abstract":[
      "A summary of recent contributions in the field of rough partial differential\nequations is given. For that purpose we rely on the formalism of ``unbounded\nrough driver''. We present applications to concrete models including\nLandau-Lifshitz-Gilbert, Navier-Stokes and Euler equations."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07971"
    ],
    "c_title":[
      "Adaptive Control with Rate-Limited Integral Action for Systems with\n  Matched, Time-Varying Uncertainties"
    ],
    "c_abstract":[
      "This paper considers the problem of controlling a piecewise continuously\ndifferentiable system subject to time-varying uncertainties. The uncertainties\nare decomposed into a time-invariant, linearly-parameterized portion and a\ntime-varying unstructured portion. The former is addressed using conventional\nmodel reference adaptive control. The latter is handled using disturbance\nobserver-based control. The objective is to ensure good performance through\nobserver-based disturbance rejection when possible, while preserving the\nrobustness guarantees of adaptive control. A key feature of the observer-based\ndisturbance compensation is a magnitude and rate limit on the integral action\nthat prevents fast fluctuations in the control command due to the observer\ndynamics."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-479",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04290"
    ],
    "b_title":[
      "Research on the Interstellar Medium and Star Formation in the Galaxy: An\n  Indian Perspective"
    ],
    "b_abstract":[
      "Although the star formation process has been studied for decades, many\nimportant aspects of the physics involved remain unsolved. Recent advancement\nof instrumentation in the infrared, far-infrared and sub-millimetre wavelength\nregimes have contributed to a significantly improved understanding of processes\nin the interstellar medium (ISM) leading to star formation. The future of\nresearch on the ISM and star formation looks exciting with instruments like the\nJWST, ALMA, etc., already contributing to the topic by gathering\nhigh-resolution high-sensitivity data and with several larger ground- and\nspace-bound facilities either being planned or constructed. India has a sizable\nnumber of astronomers engaged in research on topics related to the ISM and star\nformation. In this white paper invited by the Astronomical Society of India to\nprepare a vision document for Indian astronomy, we review the Indian\ncontributions to the global understanding of the star formation process and\nsuggest areas that require focused efforts both in creating observing\nfacilities and in theoretical front in India, in order to improve the impact of\nour research in the coming decades."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.04135"
    ],
    "c_title":[
      "Biological Sequence with Language Model Prompting: A Survey"
    ],
    "c_abstract":[
      "Large Language models (LLMs) have emerged as powerful tools for addressing\nchallenges across diverse domains. Notably, recent studies have demonstrated\nthat large language models significantly enhance the efficiency of biomolecular\nanalysis and synthesis, attracting widespread attention from academics and\nmedicine. In this paper, we systematically investigate the application of\nprompt-based methods with LLMs to biological sequences, including DNA, RNA,\nproteins, and drug discovery tasks. Specifically, we focus on how prompt\nengineering enables LLMs to tackle domain-specific problems, such as promoter\nsequence prediction, protein structure modeling, and drug-target binding\naffinity prediction, often with limited labeled data. Furthermore, our\ndiscussion highlights the transformative potential of prompting in\nbioinformatics while addressing key challenges such as data scarcity,\nmultimodal fusion, and computational resource limitations. Our aim is for this\npaper to function both as a foundational primer for newcomers and a catalyst\nfor continued innovation within this dynamic field of study."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-480",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14797"
    ],
    "b_title":[
      "FACTS&EVIDENCE: An Interactive Tool for Transparent Fine-Grained Factual\n  Verification of Machine-Generated Text"
    ],
    "b_abstract":[
      "With the widespread consumption of AI-generated content, there has been an\nincreased focus on developing automated tools to verify the factual accuracy of\nsuch content. However, prior research and tools developed for fact verification\ntreat it as a binary classification or a linear regression problem. Although\nthis is a useful mechanism as part of automatic guardrails in systems, we argue\nthat such tools lack transparency in the prediction reasoning and diversity in\nsource evidence to provide a trustworthy user experience. We develop\nFacts&Evidence - an interactive and transparent tool for user-driven\nverification of complex text. The tool facilitates the intricate\ndecision-making involved in fact-verification, presenting its users a breakdown\nof complex input texts to visualize the credibility of individual claims along\nwith an explanation of model decisions and attribution to multiple, diverse\nevidence sources. Facts&Evidence aims to empower consumers of machine-generated\ntext and give them agency to understand, verify, selectively trust and use such\ntext."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18584"
    ],
    "c_title":[
      "Radiation Magnetohydrodynamic Simulation of sub-Eddington Circumbinary\n  Disk around an Equal-mass Massive Black Hole Binary"
    ],
    "c_abstract":[
      "We present the first three-dimensional radiation magnetohydrodynamic (RMHD)\nsimulation of a sub-Eddington circumbinary disk (CBD) around an equal-mass\nmassive black hole binary (MBHB) with a total mass of\n$2\\,\\times\\,10^7\\,M_{\\odot}$ on a circular orbit, separated by 100$\\,GM_{\\rm\ntot}\/c^2$. The inclusion of radiation leads to a denser, thinner, and more\nfilamentary disk compared to non-radiative magnetohydrodynamic simulation,\nprimarily due to reduced pressure support and an altered equation of state. The\nRMHD disk also features $\\sim 3$ times lower accretion rate ($\\approx\n0.15\\,\\dot{M}_{\\rm Edd}$), weaker accretion streams and a less pronounced\noverdensity (a.k.a., ``lump\") at the inner edge. Our analysis of the light\ncurves and thermal spectra reveals that the variability induced by the\nbinary-CBD interaction is distinguishable in the optical\/UV band, where CBD\nshines at about $1\\%$ of the Eddington luminosity. These findings underscore\nthe crucial role of radiation on the structure and observational properties of\nCBDs around massive black hole binaries and have implications for detecting\nelectromagnetic counterparts to LISA gravitational wave precursors, and for\nheavier binaries that are Pulsar Timing Array sources."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-481",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20639"
    ],
    "b_title":[
      "FedConv: A Learning-on-Model Paradigm for Heterogeneous Federated\n  Clients"
    ],
    "b_abstract":[
      "Federated Learning (FL) facilitates collaborative training of a shared global\nmodel without exposing clients' private data. In practical FL systems, clients\n(e.g., edge servers, smartphones, and wearables) typically have disparate\nsystem resources. Conventional FL, however, adopts a one-size-fits-all\nsolution, where a homogeneous large global model is transmitted to and trained\non each client, resulting in an overwhelming workload for less capable clients\nand starvation for other clients. To address this issue, we propose FedConv, a\nclient-friendly FL framework, which minimizes the computation and memory burden\non resource-constrained clients by providing heterogeneous customized\nsub-models. FedConv features a novel learning-on-model paradigm that learns the\nparameters of the heterogeneous sub-models via convolutional compression.\nUnlike traditional compression methods, the compressed models in FedConv can be\ndirectly trained on clients without decompression. To aggregate the\nheterogeneous sub-models, we propose transposed convolutional dilation to\nconvert them back to large models with a unified size while retaining\npersonalized information from clients. The compression and dilation processes,\ntransparent to clients, are optimized on the server leveraging a small public\ndataset. Extensive experiments on six datasets demonstrate that FedConv\noutperforms state-of-the-art FL systems in terms of model accuracy (by more\nthan 35% on average), computation and communication overhead (with 33% and 25%\nreduction, respectively)."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12242"
    ],
    "c_title":[
      "Weighing the curvature invariants"
    ],
    "c_abstract":[
      "We prove several inequalities between the curvature invariants, which impose\nconstraints on curvature singularities, as well as asymptotic properties of\nspacetimes. Some of the inequalities hold for a family of spacetimes which\ninclude static, Friedmann--Lema\\^itre--Robertson--Walker, and Bianchi type I\nmetrics, independently of whether they are solutions of some particular field\nequations. In contrast, others hold for solutions of Einstein's gravitational\nfield equation and a family of energy-momentum tensors, independently of the\nspecific form of the spacetime metric. We illustrate different behaviour of the\nbasic curvature invariants with numerous examples and discuss the consequences\nand limitations of the proven results."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-482",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11330"
    ],
    "b_title":[
      "System Message Generation for User Preferences using Open-Source Models"
    ],
    "b_abstract":[
      "System messages play a crucial role in interactions with large language\nmodels (LLMs), often serving as prompts to initiate conversations. Through\nsystem messages, users can assign specific roles, perform intended tasks,\nincorporate background information, specify various output formats and\ncommunication styles. Despite such versatility, publicly available data are\noften lack system messages and subject to strict license constraints in the\nindustry field. Manual labeling of publicly available data with system messages\nthat align with user instructions demands significant resources. In view of\nsuch challenges, our work introduces SysGen, a pipeline for generating system\nmessages with better aligned assistant responses from the supervised\nfine-tuning dataset without system messages. Training on SysGen data has\ndemonstrated substantial improvements in the alignment of model responses with\nsystem messages and user instructions, as demonstrated across various\nopen-source models on the Multifacet benchmark, while maintaining minimal\nimpact on other unseen benchmarks such as Open LLM Leaderboard 2. Our\nqualitative analysis highlights the importance of diverse system messages to\nensure better adaptability across different contexts."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08010"
    ],
    "c_title":[
      "Improvements to SHINS, the SHARK-NIR Instrument Software, during the AIT\n  phase"
    ],
    "c_abstract":[
      "In the context of SHARK-NIR (System for coronagraphy with High Order adaptive\noptics in Z and H band), we present the development of SHINS, the SHARK-NIR\nINstrument control Software, in particular focusing on the changes introduced\nduring the Assembly, Integration, and Test (AIT) phase. SHARK-NIR observing\nsessions will be carried out with \"ESO-style\" Observation Blocks (OBs) based on\nso-called Templates scripts that will be prepared by observers. We decided to\ndevelop Templates also for the large number of AIT tests (flexures,\ncoronagraphic mask alignment, scientific camera performances...). Here we\npresent the adopted HTTP API for the OBs generation and a web-based frontend\nthat implements it. Taking advantage of this approach, we decided to expose\nAPIs also for individual device movement and monitoring, as well as for general\nstatus. These APIs are then used in the web-based instrument control and\nsynoptic panels. During the recent AIT phase, a potential collision issue\nbetween two motorized components emerged. While we are exploring the\npossibility of a hardware interlock, we present a software solution developed\nat the Observation Software level, that is also available while using other\nsoftware such as engineering panels. The system is based on three protection\nlayers and it has been successfully tested."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-483",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18396"
    ],
    "b_title":[
      "Quantum Geometry and Many-Body Landau-Zener Tunneling in Time-dependent\n  Quantum Systems with Instantaneous Quantum Integrability"
    ],
    "b_abstract":[
      "We study quantum geometric effects in time-dependent quantum many-body\nsystems quenched from integrable systems through a unitary transformation whose\nphase operator is linear in time. We establish a theorem stating that the Berry\nconnection matrix thus all associated geometric quantities of the\ntime-dependent many-body system, can be precisely characterized by excitations\nup to two-particle processes derived from the quantum integrable system. This\ngeometric characterization provides a powerful lens for analyzing dynamical\ntransitions in driven many-body settings. To illustrate the many-body geometric\ninfluence, we analyze a prototypical time-dependent Ising chain subjected to\nboth a small longitudinal field and a slowly rotating transverse field, whose\nlow-energy physics in the scaling limit is instantaneously governed by the\nquantum $E_8$ integrable field theory. Focusing on the quantum geometric\npotential (QGP), we show the QGP continuously suppresses the instantaneous\nenergy gaps with decreasing longitudinal field, thereby enhancing many-body\nLandau-Zener tunneling as evidenced by the Loschmidt echo and its associated\nspectral entropy. The critical threshold for the longitudinal field strength is\ndetermined, where the spectral entropy linearly increases with system size and\nexhbits hyperscaling behavior when approaching to the threshold. When the\nlongitudinal field passes the threshold and decreases toward zero, the QGP\ncontinuously leads to vanishing instantaneous energy gaps involving more\nlow-energy excitations, resulting in increasing spectral entropy indicative of\nmany-body Landau-Zener tunneling. Our results unveil telltale quantum geometric\nsignatures in time-dependent many-body systems, elucidating the intricate\ninterplay between quantum geometry and dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.11525"
    ],
    "c_title":[
      "Technical Report for the Forgotten-by-Design Project: Targeted\n  Obfuscation for Machine Learning"
    ],
    "c_abstract":[
      "The right to privacy, enshrined in various human rights declarations, faces\nnew challenges in the age of artificial intelligence (AI). This paper explores\nthe concept of the Right to be Forgotten (RTBF) within AI systems, contrasting\nit with traditional data erasure methods. We introduce Forgotten by Design, a\nproactive approach to privacy preservation that integrates instance-specific\nobfuscation techniques during the AI model training process. Unlike machine\nunlearning, which modifies models post-training, our method prevents sensitive\ndata from being embedded in the first place. Using the LIRA membership\ninference attack, we identify vulnerable data points and propose defenses that\ncombine additive gradient noise and weighting schemes. Our experiments on the\nCIFAR-10 dataset demonstrate that our techniques reduce privacy risks by at\nleast an order of magnitude while maintaining model accuracy (at 95%\nsignificance). Additionally, we present visualization methods for the\nprivacy-utility trade-off, providing a clear framework for balancing privacy\nrisk and model accuracy. This work contributes to the development of\nprivacy-preserving AI systems that align with human cognitive processes of\nmotivated forgetting, offering a robust framework for safeguarding sensitive\ninformation and ensuring compliance with privacy regulations."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-484",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04483"
    ],
    "b_title":[
      "Demystification and Near-perfect Estimation of Minimum Gas Limit and Gas\n  Used for Ethereum Smart Contracts"
    ],
    "b_abstract":[
      "The Ethereum blockchain has a \\emph{gas system} that associates operations\nwith a cost in gas units. Two central concepts of this system are the \\emph{gas\nlimit} assigned by the issuer of a transaction and the \\emph{gas used} by a\ntransaction. The former is a budget that must not be exhausted before the\ncompletion of the transaction execution; otherwise, the execution fails.\nTherefore, it seems rather essential to determine the \\emph{minimum gas limit}\nthat ensures the execution of a transaction will not abort due to the lack of\ngas. Despite its practical relevance, this concept has not been properly\naddressed. In the literature, gas used and minimum gas limit are conflated.\nThis paper proposes a precise notion of minimum gas limit and how it can differ\nfrom gas used by a transaction; this is also demonstrated with a quantitative\nstudy on real transactions of the Ethereum blockchain. Another significant\ncontribution is the proposition of a fairly precise estimator for each of the\ntwo metrics. Again, the confusion between these concepts has led to the\ncreation of estimators only for the gas used by a transaction. We demonstrate\nthat the minimum gas limit for the state of the Ethereum blockchain (after the\nblock) $t$ can serve as a near-perfect estimation for the execution of the\ntransaction at block $t + \\Delta$, where $\\Delta \\leq 11$; the same holds for\nestimating gas used. These precise estimators can be very valuable in helping\nthe users predict the gas budget of transactions and developers in optimising\ntheir smart contracts; over and underestimating gas used and minimum gas limit\ncan lead to a number of practical issues. Overall, this paper serves as an\nimportant reference for blockchain developers and users as to how the gas\nsystem really works."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.DC",
        "cs.ET",
        "cs.NI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03749"
    ],
    "c_title":[
      "PINS: Proximal Iterations with Sparse Newton and Sinkhorn for Optimal\n  Transport"
    ],
    "c_abstract":[
      "Optimal transport (OT) is a critical problem in optimization and machine\nlearning, where accuracy and efficiency are paramount. Although entropic\nregularization and the Sinkhorn algorithm improve scalability, they frequently\nencounter numerical instability and slow convergence, especially when the\nregularization parameter is small. In this work, we introduce Proximal\nIterations with Sparse Newton and Sinkhorn methods (PINS) to efficiently\ncompute highly accurate solutions for large-scale OT problems. A reduced\ncomputational complexity through overall sparsity and global convergence are\nguaranteed by rigorous theoretical analysis. Our approach offers three key\nadvantages: it achieves accuracy comparable to exact solutions, progressively\naccelerates each iteration for greater efficiency, and enhances robustness by\nreducing sensitivity to regularization parameters. Extensive experiments\nconfirm these advantages, demonstrating superior performance compared to\nrelated methods."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-485",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12129"
    ],
    "b_title":[
      "When Wyner and Ziv Met Bayes in Quantum-Classical Realm"
    ],
    "b_abstract":[
      "In this work, we address the lossy quantum-classical source coding with the\nquantum side-information (QC-QSI) problem. The task is to compress the\nclassical information about a quantum source, obtained after performing a\nmeasurement while incurring a bounded reconstruction error. Here, the decoder\nis allowed to use the side information to recover the classical data obtained\nfrom measurements on the source states. We introduce a new formulation based on\na backward (posterior) channel, replacing the single-letter distortion\nobservable with a single-letter posterior channel to capture reconstruction\nerror. Unlike the rate-distortion framework, this formulation imposes a block\nerror constraint. An analogous formulation is developed for lossy classical\nsource coding with classical side information (C-CSI) problem. We derive an\ninner bound on the asymptotic performance limit in terms of single-letter\nquantum and classical mutual information quantities of the given posterior\nchannel for QC-QSI and C-CSI cases, respectively. Furthermore, we establish a\nconnection between rate-distortion and rate-channel theory, showing that a\nrate-channel compression protocol attains the optimal rate-distortion function\nfor a specific distortion measure and level."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19367"
    ],
    "c_title":[
      "dCMF: Learning interpretable evolving patterns from temporal multiway\n  data"
    ],
    "c_abstract":[
      "Multiway datasets are commonly analyzed using unsupervised matrix and tensor\nfactorization methods to reveal underlying patterns. Frequently, such datasets\ninclude timestamps and could correspond to, for example, health-related\nmeasurements of subjects collected over time. The temporal dimension is\ninherently different from the other dimensions, requiring methods that account\nfor its intrinsic properties. Linear Dynamical Systems (LDS) are specifically\ndesigned to capture sequential dependencies in the observed data. In this work,\nwe bridge the gap between tensor factorizations and dynamical modeling by\nexploring the relationship between LDS, Coupled Matrix Factorizations (CMF) and\nthe PARAFAC2 model. We propose a time-aware coupled factorization model called\nd(ynamical)CMF that constrains the temporal evolution of the latent factors to\nadhere to a specific LDS structure. Using synthetic datasets, we compare the\nperformance of dCMF with PARAFAC2 and t(emporal)PARAFAC2 which incorporates\ntemporal smoothness. Our results show that dCMF and PARAFAC2-based approaches\nperform similarly when capturing smoothly evolving patterns that adhere to the\nPARAFAC2 structure. However, dCMF outperforms alternatives when the patterns\nevolve smoothly but deviate from the PARAFAC2 structure. Furthermore, we\ndemonstrate that the proposed dCMF method enables to capture more complex\ndynamics when additional prior information about the temporal evolution is\nincorporated."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-486",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07724"
    ],
    "b_title":[
      "A Doubly-Dispersive MIMO Channel Model Parametrized with Stacked\n  Intelligent Metasurfaces"
    ],
    "b_abstract":[
      "Introduced with the advent of statistical wireless channel models for high\nmobility communications and having a profound role in communication-centric\n(CC) integrated sensing and communications (ISAC), the doubly-dispersive (DD)\nchannel structure has long been heralded as a useful tool enabling the capture\nof the most important fading effects undergone by an arbitrary time-domain\ntransmit signal propagating through some medium. However, the incorporation of\nthis model into multiple-input multiple-output (MIMO) system setups, relying on\nthe recent paradigm-shifting transceiver architecture based on stacked\nintelligent metasurfaces (SIM), in an environment with reconfigurable\nintelligent surfaces (RISs) remains an open problem due to the many intricate\ndetails that have to be accounted for. In this paper, we fill this gap by\nintroducing a novel DD MIMO channel model that incorporates an arbitrary number\nof RISs in the ambient, as well as SIMs equipping both the transmitter and\nreceiver. We then discuss how the proposed metasurfaces-parametrized DD (MPDD)\nchannel model can be seamlessly applied to waveforms that are known to perform\nwell in DD environments, namely, orthogonal frequency division multiplexing\n(OFDM), orthogonal time frequency space (OTFS), and affine frequency division\nmultiplexing (AFDM), with each having their own inherent advantages and\ndisadvantages. An illustrative application of the programmable functionality of\nthe proposed model is finally presented to showcase its potential for boosting\nthe performance of the aforementioned waveforms. Our numerical results indicate\nthat the design of waveforms suitable to mitigating the effects of DD channels\nis significantly impacted by the emerging SIM technology."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05036"
    ],
    "c_title":[
      "$q$-numerical radius of rank-one operators and the generalized Buzano\n  inequality"
    ],
    "c_abstract":[
      "Here, we study the $q$-numerical radius of rank-one operators on a Hilbert\nspace $\\mathcal{H}$. More precisely, for $q \\in [0,1]$ and $a, b \\in\n\\mathcal{H}$, we establish the formula \\[ \\omega_q(a \\otimes b) =\n\\frac{1}{2}\\left(\\|a\\|\\|b\\| + q|\\langle a, b \\rangle| +\n\\sqrt{1-q^2}\\sqrt{\\|a\\|^2\\|b\\|^2 - |\\langle a, b \\rangle|^2}\\right), \\] which\nrepresents a generalization of the well-known formula for the numerical radius\nof a rank-one operator in a Hilbert space, obtained by setting $q = 1$. As a\ncorollary, we also derive a generalization of the classical Buzano inequality."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-487",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06144"
    ],
    "b_title":[
      "Exploring the usage of Probabilistic Neural Networks for Ionospheric\n  electron density estimation"
    ],
    "b_abstract":[
      "A fundamental limitation of traditional Neural Networks (NN) in predictive\nmodelling is their inability to quantify uncertainty in their outputs. In\ncritical applications like positioning systems, understanding the reliability\nof predictions is critical for constructing confidence intervals, early warning\nsystems, and effectively propagating results. For instance, Precise Point\nPositioning in satellite navigation heavily relies on accurate error models for\nancillary data (orbits, clocks, ionosphere, and troposphere) to compute precise\nerror estimates. In addition, these uncertainty estimates are needed to\nestablish robust protection levels in safety critical applications.\n  To address this challenge, the main objectives of this paper aims at\nexploring a potential framework capable of providing both point estimates and\nassociated uncertainty measures of ionospheric Vertical Total Electron Content\n(VTEC). In this context, Probabilistic Neural Networks (PNNs) offer a promising\napproach to achieve this goal. However, constructing an effective PNN requires\nmeticulous design of hidden and output layers, as well as careful definition of\nprior and posterior probability distributions for network weights and biases.\n  A key finding of this study is that the uncertainty provided by the PNN model\nin VTEC estimates may be systematically underestimated. In low-latitude areas,\nthe actual error was observed to be as much as twice the model's estimate. This\nunderestimation is expected to be more pronounced during solar maximum,\ncorrelating with increased VTEC values."
    ],
    "b_categories":[
      [
        "cs.AI",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08624"
    ],
    "c_title":[
      "Light-by-Light scattering in ultraperipheral heavy ion collisions:\n  Estimating inelastic contributions"
    ],
    "c_abstract":[
      "The current state-of-the-art theoretical estimations lead to cross-sections\nfor $AA \\to \\gamma \\gamma AA$ which are somewhat smaller than the measured ones\nby the ATLAS and CMS Collaborations, which motivates the searching and\ncalculation of subleading corrections disregarded in these previous studies. In\nthis paper, we estimate the contribution of inelastic channels to the Light -\nby - Light (LbL) scattering in ultraperipheral collisions of heavy ions\n(UPHICs), in which one or both of the incident nuclei dissociate ($A A \\to\n\\gamma \\gamma X Y$ where $X, Y = A, A'$) due to the photon emission. These new\nmechanisms are related to extra emissions that are rather difficult to identify\nat the LHC and can be mistakenly interpreted as enhanced $\\gamma \\gamma \\to\n\\gamma \\gamma$ scattering compared to the Standard Model result. We include\nprocesses of coupling of photons to individual nucleons (protons and neutrons)\nin addition to coherent coupling to the whole nuclei (called standard approach\nhere). Both elastic (nucleon in the ground state) and inelastic (nucleon in an\nexcited state) in the couplings of photons to nucleons are taken into account.\nThe inelastic nucleon fluxes are calculated using CT18qed photon in nucleon\nPDFs. The inelastic photon fluxes are shown and compared to standard photon\nfluxes in the nucleus. In addition, we show the ratio of the inelastic\ncorrections to the standard contribution as a function of diphoton invariant\nmass and photon rapidity difference. We find the maximal effect of the\ninelastic corrections at $M_{\\gamma \\gamma} \\sim$ 14 GeV for the ATLAS rapidity\nand transverse momentum acceptance. Furthermore, the inelastic contribution\nincreases gradually with photon rapidity difference. Our results indicate that\nthe inelastic contributions can increase locally by 10-15 \\% the traditional\n(no nuclear excitation) predictions for the LbL scattering in UPCs."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-488",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15125"
    ],
    "b_title":[
      "Weighted BMO-BLO estimates for Littlewood--Paley square operators"
    ],
    "b_abstract":[
      "Let $T(f)$ denote the Littlewood--Paley square operators, including the\nLittlewood--Paley $\\mathcal{G}$-function $\\mathcal{G}(f)$, Lusin's area\nintegral $\\mathcal{S}(f)$ and Stein's function\n$\\mathcal{G}^{\\ast}_{\\lambda}(f)$ with $\\lambda>2$. We establish the\nboundedness of Littlewood--Paley square operators on the weighted spaces\n$\\mathrm{BMO}(\\omega)$ with $\\omega\\in A_1$. The weighted space\n$\\mathrm{BLO}(\\omega)$ (the space of functions with bounded lower oscillation)\nis introduced and studied in this paper. This new space is a proper subspace of\n$\\mathrm{BMO}(\\omega)$. It is proved that if $T(f)(x_0)$ is finite for a single\npoint $x_0\\in\\mathbb R^n$, then $T(f)(x)$ is finite almost everywhere in\n$\\mathbb R^n$. Moreover, it is shown that $T(f)$ is bounded from\n$\\mathrm{BMO}(\\omega)$ into $\\mathrm{BLO}(\\omega)$, provided that $\\omega\\in\nA_1$. The corresponding John--Nirenberg inequality suitable for the space\n$\\mathrm{BLO}(\\omega)$ with $\\omega\\in A_1$ is discussed. Based on this, the\nequivalent characterization of the space $\\mathrm{BLO}(\\omega)$ is also given."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.02886"
    ],
    "c_title":[
      "Advancements in Mobile Edge Computing and Open RAN: Leveraging\n  Artificial Intelligence and Machine Learning for Wireless Systems"
    ],
    "c_abstract":[
      "Mobile Edge Computing (MEC) and Open Radio Access Networks (ORAN) are\ntransformative technologies in the development of next-generation wireless\ncommunication systems. MEC pushes computational resources closer to end-users,\nenabling low latency and efficient processing, while ORAN promotes\ninteroperability and openness in radio networks, thereby fostering innovation.\nThis paper explores recent advancements in these two domains, with a particular\nfocus on how Artificial Intelligence (AI) and Machine Learning (ML) techniques\nare being utilized to solve complex wireless challenges. In MEC, Deep\nReinforcement Learning (DRL) is leveraged for optimizing computation\noffloading, ensuring energy-efficient solutions, and meeting Quality of Service\n(QoS) requirements. In ORAN, AI\/ML is used to develop intelligent xApps for\nnetwork slicing, scheduling, and online training to enhance network\nadaptability. This reading report provides an in-depth analysis of multiple key\npapers, discusses the methodologies employed, and highlights the impact of\nthese technologies in improving network efficiency and scalability."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-489",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14237"
    ],
    "b_title":[
      "Make Your Training Flexible: Towards Deployment-Efficient Video Models"
    ],
    "b_abstract":[
      "Popular video training methods mainly operate on a fixed number of tokens\nsampled from a predetermined spatiotemporal grid, resulting in sub-optimal\naccuracy-computation trade-offs due to inherent video redundancy. They also\nlack adaptability to varying computational budgets for downstream tasks,\nhindering applications of the most competitive model in real-world scenes. We\nthus propose a new test setting, Token Optimization, for maximized input\ninformation across budgets, which optimizes the size-limited set of input\ntokens through token selection from more suitably sampled videos. To this end,\nwe propose a novel augmentation tool termed Flux. By making the sampling grid\nflexible and leveraging token selection, it is easily adopted in most popular\nvideo training frameworks, boosting model robustness with nearly no additional\ncost. We integrate Flux in large-scale video pre-training, and the resulting\nFluxViT establishes new state-of-the-art results across extensive tasks at\nstandard costs. Notably, with 1\/4 tokens only, it can still match the\nperformance of previous state-of-the-art models with Token Optimization,\nyielding nearly 90\\% savings. All models and data are available at\nhttps:\/\/github.com\/OpenGVLab\/FluxViT."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06051"
    ],
    "c_title":[
      "Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual\n  Bandits under Single-Policy Concentrability"
    ],
    "c_abstract":[
      "KL-regularized policy optimization has become a workhorse in learning-based\ndecision making, while its theoretical understanding is still very limited.\nAlthough recent progress has been made towards settling the sample complexity\nof KL-regularized contextual bandits, existing sample complexity bounds are\neither $\\tilde{O}(\\epsilon^{-2})$ under single-policy concentrability or\n$\\tilde{O}(\\epsilon^{-1})$ under all-policy concentrability. In this paper, we\npropose the \\emph{first} algorithm with $\\tilde{O}(\\epsilon^{-1})$ sample\ncomplexity under single-policy concentrability for offline contextual bandits.\nOur algorithm is designed for general function approximation and based on the\nprinciple of \\emph{pessimism in the face of uncertainty}. The core of our proof\nleverages the strong convexity of the KL regularization, and the conditional\nnon-negativity of the gap between the true reward and its pessimistic estimator\nto refine a mean-value-type risk upper bound to its extreme. This in turn leads\nto a novel covariance-based analysis, effectively bypassing the need for\nuniform control over the discrepancy between any two functions in the function\nclass. The near-optimality of our algorithm is demonstrated by an\n$\\tilde{\\Omega}(\\epsilon^{-1})$ lower bound. Furthermore, we extend our\nalgorithm to contextual dueling bandits and achieve a similar nearly optimal\nsample complexity."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-490",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12647"
    ],
    "b_title":[
      "Optimal Transmission Sequence Design with ISI Matching in Molecular\n  Communication"
    ],
    "b_abstract":[
      "Molecular communication (MC) offers a groundbreaking approach to\ncommunication inspired by biological signaling. It is particularly suited for\nenvironments where traditional electromagnetic methods fail, such as fluid\nmediums or within the human body. This study focuses on addressing a major\nchallenge in MC systems: inter symbol interference (ISI), which arises due to\nthe random, diffusive propagation of molecules. We propose a novel technique\nthat leverages transmission shaping to mitigate ISI effectively by designing\noptimal transmission pulse (or sequence) for symbols. Our approach centers on\nsolving a multi-objective optimization problem that aims to maximize the\nseparability of individual symbol's responses within the symbol duration while\nmatching the interference caused by molecular spillover for all symbols. By\nmaking ISI of each symbol similar, the approach reduces the effect of previous\nsymbols and thus not require any adaptive computations. We introduce a\ngeometric analogy involving two families of ellipses to derive the optimal\nsolution. Analytical insights are supported by numerical simulations to design\noptimized transmission profiles to enhance the resilience toward ISI. The\nproposed transmission shaping method is evaluated through symbol error rate\n(SER). These results mark a significant step forward in developing robust and\nefficient MC systems, opening doors to advanced applications in bio-inspired\nand nano-scale communication technologies."
    ],
    "b_categories":[
      [
        "eess.SP",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12418"
    ],
    "c_title":[
      "A Causality-Inspired Model for Intima-Media Thickening Assessment in\n  Ultrasound Videos"
    ],
    "c_abstract":[
      "Carotid atherosclerosis represents a significant health risk, with its early\ndiagnosis primarily dependent on ultrasound-based assessments of carotid\nintima-media thickening. However, during carotid ultrasound screening,\nsignificant view variations cause style shifts, impairing content cues related\nto thickening, such as lumen anatomy, which introduces spurious correlations\nthat hinder assessment. Therefore, we propose a novel causal-inspired method\nfor assessing carotid intima-media thickening in frame-wise ultrasound videos,\nwhich focuses on two aspects: eliminating spurious correlations caused by style\nand enhancing causal content correlations. Specifically, we introduce a novel\nSpurious Correlation Elimination (SCE) module to remove non-causal style\neffects by enforcing prediction invariance with style perturbations.\nSimultaneously, we propose a Causal Equivalence Consolidation (CEC) module to\nstrengthen causal content correlation through adversarial optimization during\ncontent randomization. Simultaneously, we design a Causal Transition\nAugmentation (CTA) module to ensure smooth causal flow by integrating an\nauxiliary pathway with text prompts and connecting it through contrastive\nlearning. The experimental results on our in-house carotid ultrasound video\ndataset achieved an accuracy of 86.93\\%, demonstrating the superior performance\nof the proposed method. Code is available at\n\\href{https:\/\/github.com\/xielaobanyy\/causal-imt}{https:\/\/github.com\/xielaobanyy\/causal-imt}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-491",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09476"
    ],
    "b_title":[
      "A Multi-objective Sequential Quadratic Programming Algorithm Based on\n  Low-order Smooth Penalty Function"
    ],
    "b_abstract":[
      "In this paper,we propose a Multi-Objective Sequential Quadratic Programming\n(MOSQP) algorithm for constrained multi-objective optimization problems,basd on\na low-order smooth penalty function as the merit function for line search. The\nalgorithm constructs single-objective optimization subproblems based on each\nobjective function, solves quadratic programming (QP) subproblems to obtain\ndescent directions for expanding the iterative point set within the feasible\nregion, and filters non-dominated points after expansion. A new QP problem is\nthen formulated using information from all objective functions to derive\ndescent directions. The Armijo step size rule is employed for line search,\ncombined with Powell's correction formula (1978) for B iteration updates. If QP\nsubproblems is infesible, the negative gradient of the merit function is\nadopted as the search direction. The algorithm is proven to converge to an\napproximate Pareto front for constrained multi-objective optimization. Finally,\nnumerical experiments are performed for specific multi-objective optimization\nproblems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.18327"
    ],
    "c_title":[
      "Sparsity covariance: a source of uncertainty when estimating correlation\n  functions with a discrete sample of observations in the sky"
    ],
    "c_abstract":[
      "Cosmological observables rely heavily on summary statistics such as two-point\ncorrelation functions. In many practical cases (e.g. the weak-lensing cosmic\nshear), those correlation functions are estimated from a finite, discrete\nsample of measurements that are randomly distributed in the sky. The result\nthen inevitably depends on the sample at hand, regardless of any experimental\nnoise. This sample dependence is a source of uncertainty for cosmological\nobservables which I call sparsity covariance. This article proposes a\nmathematical definition and a generic method to compute sparsity covariance. It\nis then applied to the concrete case of cosmic shear, showing that sparsity\ncovariance mostly enhances shape noise, whose amplitude is determined by the\napparent ellipticity of galaxies rather than their intrinsic ellipticity. In\ngeneral, sparsity covariance is non-negligible when the signal-to-noise ratio\nof individual measurements in the sample is comparable to, or larger than,\nunity."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-492",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07355"
    ],
    "b_title":[
      "Tools for Supergravity in the spin coframe formalism"
    ],
    "b_abstract":[
      "This paper contains a review of the theoretical foundations of Clifford\nalgebras, spinors and spinor bundles in the so-called co-frame formalism. A\ncompact index-free notation is introduced, along with a series of identities\nuseful for computations in supergravity theories."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.16804"
    ],
    "c_title":[
      "Anisotropic flows of identified hadrons in the equal-velocity quark\n  combination model at RHIC energy"
    ],
    "c_abstract":[
      "We employ an equal-velocity quark combination model to study anisotropic\nflows $v_{2}$, $v_{3}$ and $v_{4}$ of identified hadrons at mid-rapidity in\nheavy-ion collisions at RHIC energies. Under the equal-velocity combination\nmechanism of constituent quarks at hadronization, we build analytical formulas\nof anisotropic flows of hadrons in terms of those of quarks just before\nhadronization. We systematically analyze the contribution of higher order flows\nof quarks, and show how simple formulas of $v_{2}$, $v_{3}$ and $v_{4}$ of\nidentified hadrons with the desired precision can be obtained by neglecting the\nsmall contribution of higher order flows of quarks. We systematically test\nthese simple formulas of hadronic flows by the experimental data of $v_{2}$,\n$v_{3}$ and $v_{4}$ of identified hadrons $\\phi$, $\\Lambda$, $\\Xi^{-}$,\n$\\Omega^{-}$, $\\bar{\\Lambda}$, $\\bar{\\Xi}^{+}$, $\\bar{\\Omega}^{+}$, $p$ and\n$\\bar{p}$ in Au+Au collisions at $\\sqrt{s_{NN}}=$ 19.6, 54.4 and 200 GeV, and\nwe find that the equal-velocity quark combination model can well describe the\nmeasured $v_{2}$, $v_{3}$ and $v_{4}$ of identified hadrons in Au+Au collisions\nat those collision energies. We further study the obtained anisotropic flows of\nquarks and find two scaling properties\\textcolor{red}{{} }which can be\nqualitatively understood by the hydrodynamic evolution of thermal quark medium\nproduced in relativistic heavy-ion collisions."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-493",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18780"
    ],
    "b_title":[
      "Gotta Hash 'Em All! Speeding Up Hash Functions for Zero-Knowledge Proof\n  Applications"
    ],
    "b_abstract":[
      "Collision-resistant cryptographic hash functions (CRHs) are crucial for\nsecurity in modern systems but are optimized for standard CPUs. While heavily\nused in zero-knowledge proof (ZKP) applications, traditional CRHs are\ninefficient in the ZK domain. ZK-friendly hashes have been developed but\nstruggle on consumer hardware due to a lack of specialized ZK-specific\nhardware. To address this, we present HashEmAll, a novel collection of\nFPGA-based realizations of three ZK-friendly hash functions: Griffin,\nRescue-Prime, and Reinforced Concrete. Each hash offers different optimization\nfocuses, allowing users to choose based on the constraints of their\napplications. Through our ZK-optimized arithmetic functions on reconfigurable\nhardware, HashEmAll outperforms CPU implementations by up to $23\\times$ with\nlower power consumption and compatibility with accessible FPGAs."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16850"
    ],
    "c_title":[
      "Guaranteed upper bounds for iteration errors and modified Kacanov\n  schemes via discrete duality"
    ],
    "c_abstract":[
      "We apply duality theory to discretized convex minimization problems to obtain\ncomputable guaranteed upper bounds for the distance of given discrete functions\nand the exact discrete minimizer. Furthermore, we show that the discrete\nduality framework extends convergence results for the Kacanov scheme to a\nbroader class of problems."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-494",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06778"
    ],
    "b_title":[
      "Optical appearance of the Konoplya-Zhidenko rotating non-Kerr black hole\n  surrounded by a thin accretion disk"
    ],
    "b_abstract":[
      "In this study, we analyze the observational images of a Konoplya-Zhidenko\nrotating non-Kerr black hole, wherein a thin accretion disk, serving as the\nsole background light source, is situated on the equatorial plane of the black\nhole. The inner boundary of the thin accretion disk extends to the event\nhorizon, and the accretion material in the disk exhibits two different motion\nbehaviors, that is, it moves along the critical plunging orbit inside the\ninnermost stable circular orbit (ISCO) and follows the Keplerian orbit outside\nthe ISCO. The shadow image is captured on the imaging plane of a zero angular\nmomentum observer utilizing advanced fisheye camera ray-tracing techniques. The\nresults demonstrate that an image consistently reveals a dark region encircled\nby a narrow photon ring, which is called the inner shadow. At low observation\ninclination angles, the observation intensity is highly concentrated, with the\nlensed image of accretion disk being superimposed on the direct image. As\nobservation inclination angle increases, the direct and lensed images gradually\nseparate, becoming distinctly distinguishable and forming a hat-like structure.\nFurthermore, variations in the parameter space and observation angle will\ninfluence pertinent image characteristics, including image symmetry, the range\nor deformation degree of the inner shadow. We further examined the distinctive\ncharacteristics of images observed in both prograde and retrograde accretion\ndisk scenarios. Subsequently, we also examined the redshift distribution on the\ndisk. The findings indicate that while variations in relevant parameters do\ninfluence the redshift distribution, the primary factor is the change in\nobservational inclination. The observer can detect both redshift and blueshift\nphenomena on the screen when viewed at a higher observation angle."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.14838"
    ],
    "c_title":[
      "Think Like Human Developers: Harnessing Community Knowledge for\n  Structured Code Reasoning"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) have significantly advanced automated code\ngeneration, yet they struggle with complex coding tasks requiring multi-step\nlogical reasoning. High-quality reasoning data is crucial for improving LLMs'\nreasoning capabilities, but such datasets remain scarce. Existing approaches\neither rely on computationally expensive reinforcement learning (RL) or\nerror-prone reasoning chains synthesized by LLMs, posing challenges in\nscalability and accuracy.\n  To address this challenge, we propose SVRC (Structured and Validated\nReasoning Chains for Code Generation), a novel framework that mines,\nrestructures, and enriches reasoning chains from community-driven discussions\non software engineering platforms. SVRC refines unstructured and incomplete\ndiscussions of coding problems by aligning them with Software Development Life\nCycle (SDLC) principles, ensuring that reasoning chains capture real-world\nproblem-solving strategies and support iterative refinement.\n  To evaluate the effectiveness of SVRC, we introduce CodeThinker, an LLM\nfine-tuned on 12,444 reasoning-augmented samples generated by SVRC. Experiments\non LiveCodeBench show that CodeThinker surpasses its base model by 42.86\\% on\nmedium-level code problems in terms of pass@1 and outperforms GPT-4o-mini and\nGPT-4o by 73.14\\% and 115.86\\%, respectively. Our ablation study further\nhighlights that each component of SVRC contributes to the reasoning\ncapabilities of CodeThinker."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-495",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06396"
    ],
    "b_title":[
      "Optimizing Minimum Vertex Cover Solving via a GCN-assisted Heuristic\n  Algorithm"
    ],
    "b_abstract":[
      "The problem of finding a minimum vertex cover (MVC) in a graph is a\nwell-known NP-hard problem with significant practical applications in\noptimization and scheduling. Its complexity, combined with the increasing scale\nof problems, underscores the need for efficient and effective algorithms.\nHowever, existing heuristic algorithms for MVC often rely on simplistic\ninitialization strategies and overlook the impact of edge attributes and\nneighborhood information on vertex selection. In this paper, we introduce\nGCNIVC, a novel heuristic search algorithm designed to address the limitations\nof existing methods for solving MVC problems in large-scale graphs. Our\napproach features two main innovations. First, it utilizes a Graph\nConvolutional Network (GCN) to capture the global structure of graphs, which\nenables the generation of high-quality initial solutions that enhance the\nefficiency of the subsequent search process. Second, GCNIVC introduces a new\nheuristic that employs three containers and the concept of double-covered edges\n(dc-edges), improving search efficiency and providing greater flexibility for\nadding and removing operations based on edge attributes. Through extensive\nexperiments on benchmark datasets, we demonstrate that GCNIVC outperforms\nstate-of-the-art MVC algorithms in terms of both accuracy and efficiency. Our\nresults highlight the effectiveness of GCNIVC's GCN-assisted initialization and\nits edge-informed search strategy. This study not only advances the\nunderstanding of MVC problem-solving but also contributes a new tool for\naddressing large-scale graph optimization challenges."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09296"
    ],
    "c_title":[
      "Causal Spike Timing Dependent Plasticity Prevents Assembly Fusion in\n  Recurrent Networks"
    ],
    "c_abstract":[
      "The organization of neurons into functionally related assemblies is a\nfundamental feature of cortical networks, yet our understanding of how these\nassemblies maintain distinct identities while sharing members remains limited.\nHere we analyze how spike-timing-dependent plasticity (STDP) shapes the\nformation and stability of overlapping neuronal assemblies in recurrently\ncoupled networks of spiking neuron models. Using numerical simulations and an\nassociated mean-field theory, we demonstrate that the temporal structure of the\nSTDP rule, specifically its degree of causality, critically determines whether\nassemblies that share neurons maintain segregation or merge together after\ntraining is completed. We find that causal STDP rules, where\npotentiation\/depression occurs strictly when presynaptic spikes precede\/proceed\npostsynaptic spikes, allow assemblies to remain distinct even with substantial\noverlap in membership. This stability arises because causal STDP effectively\ncancels the symmetric correlations introduced by common inputs from shared\nneurons. In contrast, acausal STDP rules lead to assembly fusion when overlap\nexceeds a critical threshold, due to unchecked growth of common input\ncorrelations. Our results provide theoretical insight into how\nspike-timing-dependent learning rules can support distributed representation\nwhere individual neurons participate in multiple assemblies while maintaining\nfunctional specificity."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-496",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12301"
    ],
    "b_title":[
      "One Goal, Many Challenges: Robust Preference Optimization Amid\n  Content-Aware and Multi-Source Noise"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have made significant strides in generating\nhuman-like responses, largely due to preference alignment techniques. However,\nthese methods often assume unbiased human feedback, which is rarely the case in\nreal-world scenarios. This paper introduces Content-Aware Noise-Resilient\nPreference Optimization (CNRPO), a novel framework that addresses multiple\nsources of content-dependent noise in preference learning. CNRPO employs a\nmulti-objective optimization approach to separate true preferences from\ncontent-aware noises, effectively mitigating their impact. We leverage backdoor\nattack mechanisms to efficiently learn and control various noise sources within\na single model. Theoretical analysis and extensive experiments on different\nsynthetic noisy datasets demonstrate that CNRPO significantly improves\nalignment with primary human preferences while controlling for secondary noises\nand biases, such as response length and harmfulness."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18580"
    ],
    "c_title":[
      "First Computation of Entanglement Dynamics in the SYK Model on Quantum\n  Computers"
    ],
    "c_abstract":[
      "The Sachdev-Ye-Kitaev (SYK) model, fundamental to quantum chaos, many-body\nphysics, and holographic duality, features random all-to-all quartic or\nhigher-order interactions, exhibiting both maximal chaos and exact\nsolvability--yet its entanglement entropy has remained challenging and never\nbeen measured on a real quantum device. We overcome this limitation by\npresenting the first measurement of entanglement entropy growth under the SYK\nHamiltonian using IBM's superconducting quantum computer. We implement an\noptimized version of swap-based many-body interference protocol, alleviating\nthe challenges posed by IBM's limited qubit connectivity. Additionally, to\nreduce the statistical uncertainty in the randomized measurement protocol, we\nexpand the unitary ensemble, which increases the volume of quantum circuits\nthat are difficult to execute on current quantum computers. We tackle this\nchallenge for the first time by parallelizing these quantum circuits through\nquantum multi-programming--establishing a foundation for how tailored\ninnovations reveal complex quantum dynamics within current hardware\nconstraints."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "hep-lat",
        "hep-ph",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-497",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20342"
    ],
    "b_title":[
      "Reservoir Computing and Photoelectrochemical Sensors: A Marriage of\n  Convenience"
    ],
    "b_abstract":[
      "Sensing technology is an important aspect of information processing. Current\ndevelopment in artificial intelligence systems (especially those aimed at\nmedical and environmental applications) requires a lot of data on the chemical\ncomposition of biological fluids or environmental samples. These complex\nmatrices require advanced sensing devices, and photoelectrochemical ones seem\nto have potential to overcome at least some of the obstacles. Furthermore, the\ndevelopment of artificial intelligence (AI) technology for autonomous robotics\nrequires technology mimicking human senses, also those operating at the\nmolecular level, such as gustation and olfaction. Again, photoelectrochemical\nsensing can provide some suitable solutions. In this review, we introduce the\nidea of integration of photoelectrochemical sensors with some unconventional\ncomputing paradigm - reservoir computing. This approach should not only boost\nthe performance of the sensors itself, but also open new pathways through\nscience. Integration of sensing devices with computing systems will also\ncontribute to a better understanding (or at least mimicking) of the human\nsenses and neuromorphic sensory information processing. Although reservoir\nsystems can be considered magic \"black boxes\" and their operation is at the\nsame time simple and hard to comprehend, this combination is expected to open a\nnew era of effective information harvesting and processing systems."
    ],
    "b_categories":[
      [
        "cs.ET",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04224"
    ],
    "c_title":[
      "Speeding up Local Search for the Indicator-based Subset Selection\n  Problem by a Candidate List Strategy"
    ],
    "c_abstract":[
      "In evolutionary multi-objective optimization, the indicator-based subset\nselection problem involves finding a subset of points that maximizes a given\nquality indicator. Local search is an effective approach for obtaining a\nhigh-quality subset in this problem. However, local search requires high\ncomputational cost, especially as the size of the point set and the number of\nobjectives increase. To address this issue, this paper proposes a candidate\nlist strategy for local search in the indicator-based subset selection problem.\nIn the proposed strategy, each point in a given point set has a candidate list.\nDuring search, each point is only eligible to swap with unselected points in\nits associated candidate list. This restriction drastically reduces the number\nof swaps at each iteration of local search. We consider two types of candidate\nlists: nearest neighbor and random neighbor lists. This paper investigates the\neffectiveness of the proposed candidate list strategy on various Pareto fronts.\nThe results show that the proposed strategy with the nearest neighbor list can\nsignificantly speed up local search on continuous Pareto fronts without\nsignificantly compromising the subset quality. The results also show that the\nsequential use of the two lists can address the discontinuity of Pareto fronts."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-498",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08661"
    ],
    "b_title":[
      "Task-Oriented Co-Design of Communication, Computing, and Control for\n  Edge-Enabled Industrial Cyber-Physical Systems"
    ],
    "b_abstract":[
      "This paper proposes a task-oriented co-design framework that integrates\ncommunication, computing, and control to address the key challenges of\nbandwidth limitations, noise interference, and latency in mission-critical\nindustrial Cyber-Physical Systems (CPS). To improve communication efficiency\nand robustness, we design a task-oriented Joint Source-Channel Coding (JSCC)\nusing Information Bottleneck (IB) to enhance data transmission efficiency by\nprioritizing task-specific information. To mitigate the perceived End-to-End\n(E2E) delays, we develop a Delay-Aware Trajectory-Guided Control Prediction\n(DTCP) strategy that integrates trajectory planning with control prediction,\npredicting commands based on E2E delay. Moreover, the DTCP is co-designed with\ntask-oriented JSCC, focusing on transmitting task-specific information for\ntimely and reliable autonomous driving. Experimental results in the CARLA\nsimulator demonstrate that, under an E2E delay of 1 second (20 time slots), the\nproposed framework achieves a driving score of 48.12, which is 31.59 points\nhigher than using Better Portable Graphics (BPG) while reducing bandwidth usage\nby 99.19%."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.IT",
        "eess.IV",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16939"
    ],
    "c_title":[
      "On-Sensor Convolutional Neural Networks with Early-Exits"
    ],
    "c_abstract":[
      "Tiny Machine Learning (TinyML) is a novel research field aiming at\nintegrating Machine Learning (ML) within embedded devices with limited memory,\ncomputation, and energy. Recently, a new branch of TinyML has emerged, focusing\non integrating ML directly into the sensors to further reduce the power\nconsumption of embedded devices. Interestingly, despite their state-of-the-art\nperformance in many tasks, none of the current solutions in the literature aims\nto optimize the implementation of Convolutional Neural Networks (CNNs)\noperating directly into sensors. In this paper, we introduce for the first time\nin the literature the optimized design and implementation of Depth-First CNNs\noperating on the Intelligent Sensor Processing Unit (ISPU) within an Inertial\nMeasurement Unit (IMU) by STMicroelectronics. Our approach partitions the CNN\nbetween the ISPU and the microcontroller (MCU) and employs an Early-Exit\nmechanism to stop the computations on the IMU when enough confidence about the\nresults is achieved, hence significantly reducing power consumption. When using\na NUCLEO-F411RE board, this solution achieved an average current consumption of\n4.8 mA, marking an 11% reduction compared to the regular inference pipeline on\nthe MCU, while having equal accuracy."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-499",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04946"
    ],
    "b_title":[
      "Non-asymptotic analysis of the performance of the penalized least\n  trimmed squares in sparse models"
    ],
    "b_abstract":[
      "The least trimmed squares (LTS) estimator is a renowned robust alternative to\nthe classic least squares estimator and is popular in location, regression,\nmachine learning, and AI literature. Many studies exist on LTS, including its\nrobustness, computation algorithms, extension to non-linear cases, asymptotics,\netc. The LTS has been applied in the penalized regression in a high-dimensional\nreal-data sparse-model setting where dimension $p$ (in thousands) is much\nlarger than sample size $n$ (in tens, or hundreds). In such a practical\nsetting, the sample size $n$ often is the count of sub-population that has a\nspecial attribute (e.g. the count of patients of Alzheimer's, Parkinson's,\nLeukemia, or ALS, etc.) among a population with a finite fixed size N.\nAsymptotic analysis assuming that $n$ tends to infinity is not practically\nconvincing and legitimate in such a scenario. A non-asymptotic or finite sample\nanalysis will be more desirable and feasible.\n  This article establishes some finite sample (non-asymptotic) error bounds for\nestimating and predicting based on LTS with high probability for the first\ntime."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15438"
    ],
    "c_title":[
      "OccLinker: Deflickering Occupancy Networks through Lightweight\n  Spatio-Temporal Correlation"
    ],
    "c_abstract":[
      "Vision-based occupancy networks (VONs) provide an end-to-end solution for\nreconstructing 3D environments in autonomous driving. However, existing methods\noften suffer from temporal inconsistencies, manifesting as flickering effects\nthat compromise visual experience and adversely affect decision-making. While\nrecent approaches have incorporated historical data to mitigate the issue, they\noften incur high computational costs and introduce noisy information that\ninterferes with object detection. We propose OccLinker, a novel plugin\nframework designed to seamlessly integrate with existing VONs for boosting\nperformance. Our method employs a three-stage architecture that consolidates\nhistorical static and motion cues, correlates them with current features\nthrough a Motion-Static Integration (MSI) mechanism, and generates correction\noccupancy to refine base network predictions. Extensive experiments on two\nbenchmarks demonstrate the efficiency and effectiveness of our method,\noutperforming the latest baseline models. The source code are available in the\nsupplementary material."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-500",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16947"
    ],
    "b_title":[
      "Exceptional field theories"
    ],
    "b_abstract":[
      "We review exceptional field theories as the duality-covariant reformulation\nof maximal supergravity theories in ten and eleven dimensions, that make the\nunderlying exceptional symmetries explicit. Beyond their structural role in\nunifying the various maximal supergravities, we illustrate how they also\nprovide access to very efficient techniques for tackling concrete computational\nproblems in supergravity."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02510"
    ],
    "c_title":[
      "Remote Sensing Image Classification Using Convolutional Neural Network\n  (CNN) and Transfer Learning Techniques"
    ],
    "c_abstract":[
      "This study investigates the classification of aerial images depicting\ntransmission towers, forests, farmland, and mountains. To complete the\nclassification job, features are extracted from input photos using a\nConvolutional Neural Network (CNN) architecture. Then, the images are\nclassified using Softmax. To test the model, we ran it for ten epochs using a\nbatch size of 90, the Adam optimizer, and a learning rate of 0.001. Both\ntraining and assessment are conducted using a dataset that blends\nself-collected pictures from Google satellite imagery with the MLRNet dataset.\nThe comprehensive dataset comprises 10,400 images. Our study shows that\ntransfer learning models and MobileNetV2 in particular, work well for landscape\ncategorization. These models are good options for practical use because they\nstrike a good mix between precision and efficiency; our approach achieves\nresults with an overall accuracy of 87% on the built CNN model. Furthermore, we\nreach even higher accuracies by utilizing the pretrained VGG16 and MobileNetV2\nmodels as a starting point for transfer learning. Specifically, VGG16 achieves\nan accuracy of 90% and a test loss of 0.298, while MobileNetV2 outperforms both\nmodels with an accuracy of 96% and a test loss of 0.119; the results\ndemonstrate the effectiveness of employing transfer learning with MobileNetV2\nfor classifying transmission towers, forests, farmland, and mountains."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-501",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15454"
    ],
    "b_title":[
      "On the Discrimination and Consistency for Exemplar-Free Class\n  Incremental Learning"
    ],
    "b_abstract":[
      "Exemplar-free class incremental learning (EF-CIL) is a nontrivial task that\nrequires continuously enriching model capability with new classes while\nmaintaining previously learned knowledge without storing and replaying any old\nclass exemplars. An emerging theory-guided framework for CIL trains\ntask-specific models for a shared network, shifting the pressure of forgetting\nto task-id prediction. In EF-CIL, task-id prediction is more challenging due to\nthe lack of inter-task interaction (e.g., replays of exemplars). To address\nthis issue, we conduct a theoretical analysis of the importance and feasibility\nof preserving a discriminative and consistent feature space, upon which we\npropose a novel method termed DCNet. Concretely, it progressively maps class\nrepresentations into a hyperspherical space, in which different classes are\northogonally distributed to achieve ample inter-class separation. Meanwhile, it\nalso introduces compensatory training to adaptively adjust supervision\nintensity, thereby aligning the degree of intra-class aggregation. Extensive\nexperiments and theoretical analysis verified the superiority of the proposed\nDCNet."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07201"
    ],
    "c_title":[
      "Well-to-Tank Carbon Intensity Variability of Fossil Marine Fuels: A\n  Country-Level Assessment"
    ],
    "c_abstract":[
      "The transition toward a low-carbon maritime transportation requires\nunderstanding lifecycle carbon intensity (CI) of marine fuels. While\nwell-to-tank emissions significantly contribute to total greenhouse gas\nemissions, many studies lack global perspective in accounting for upstream\noperations, transportation, refining, and distribution. This study evaluates\nwell-to-tank CI of High Sulphur Fuel Oil (HSFO) and well-to-refinery exit CI of\nLiquefied Petroleum Gas (LPG) worldwide at asset level. HSFO represents\ntraditional marine fuel, while LPG serves as potential transition fuel due to\nlower tank-to-wake emissions and compatibility with low-carbon fuels. Using\nOPGEE and PRELIM tools with R-based geospatial methods, we derive country-level\nCI values for 72 countries (HSFO) and 74 countries (LPG), covering 98% of\nglobal production. Results show significant variation in climate impacts\nglobally. HSFO upstream CI ranges 1-22.7 gCO2e\/MJ, refining CI 1.2-12.6\ngCO2e\/MJ, with global volume-weighted-average well-to-tank CI of 12.4 gCO2e\/MJ.\nUpstream and refining account for 55% and 32% of HSFO well-to-tank CI, with\nlarge exporters and intensive refining practices showing higher emissions. For\nLPG, upstream CI ranges 0.9-22.7 gCO2e\/MJ, refining CI 2.8-13.9 gCO2e\/MJ, with\nvolume-weighted-average well-to-refinery CI of 15.6 gCO2e\/MJ. Refining\ncomprises 49% of LPG well-to-refinery CI, while upstream and transport\nrepresent 44% and 6%. Major players include China, United States and Russia.\nThese findings reveal significant CI variability across countries and supply\nchains, offering opportunities for targeted emission reduction policies."
    ],
    "c_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-502",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09236"
    ],
    "b_title":[
      "Early Validation of High-level Requirements on Cyber-Physical Systems"
    ],
    "b_abstract":[
      "The overarching, broad topic of my research are advancements in the area of\nsafety-critical, cyber-physical systems (CPS) development with emphasis on\nvalidation and verification. The particular focus of my research is the early\nvalidation of high-level requirements on CPS. My current approach for tackling\nthis problem is transforming the requirements into Event Calculus and\nsubsequently reasoning about them using ASP solvers such as the grounding-free\ns(CASP). Below, I discuss my research, its current state, and the open issues\nthat are still left to tackle. The first results of my work will be presented\nin a paper that was accepted for ICLP'24, which is my first paper in this area."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18428"
    ],
    "c_title":[
      "Convergence of a semi-explicit scheme for a one dimensional periodic\n  nonlocal eikonal equation modeling dislocation dynamics"
    ],
    "c_abstract":[
      "In this paper, we derive a periodic model from a one dimensional nonlocal\neikonal equation set on the full space modeling dislocation dynamics. Thanks to\na gradient entropy estimate, we show that this periodic model converges toward\nthe initial one when the period goes to infinity. Moreover, we design a\nsemi-explicit numerical scheme for the periodic model that we introduce. We\nshow the well-posedness of the scheme and a discrete gradient entropy\ninequality. We also prove the convergence of the scheme and we present some\nnumerical experiments."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-503",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03004"
    ],
    "b_title":[
      "Large $N$ Vertex Algebras via Deligne Category"
    ],
    "b_abstract":[
      "In this paper, we propose a new construction of vertex algebras using the\nDeligne category. This approach provides a rigorous framework for defining the\nso-called large $N$ vertex algebra, which has appeared in recent physics\nliteratures. We first define the notion of a vertex algebra in a symmetric\nmonoidal category and extend familiar constructions in ordinary vertex algebras\nto this broader categorical context. As an application, we consider a\n$\\beta\\gamma$ vertex algebra in the Deligne category and construct the large N\nvertex algebra from it. We study some simple properties of this vertex algebra\nand analyze a certain vertex Poisson algebra limit."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.05533"
    ],
    "c_title":[
      "Compactness and related properties of weighted composition operators on\n  weighted BMOA spaces"
    ],
    "c_abstract":[
      "It is shown that a large class of properties coincide for weighted\ncomposition operators on a large class of weighted VMOA spaces, including the\nones with logarithmic weights and the ones with standard weights $(1-|z|)^{-c},\n\\ 0\\leq c< 1\/2$. Some of these properties are compactness, weak compactness,\ncomplete continuity and strict singularity. A function-theoretic\ncharacterization for these properties is also given. Similar results are also\nproved for many weighted composition operators on similarly weighted BMOA\nspaces. The main results extend the theorems given in [Proc. Amer. Math. Soc.\n151 (2023), 1195--1207], and new test functions that are suitable for the\nweighted setting are developed."
    ],
    "c_categories":[
      [
        "math.CV",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-504",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18610"
    ],
    "b_title":[
      "Exploring the Onset of Collectivity Approaching N=40 through Manganese\n  Masses"
    ],
    "b_abstract":[
      "Isotopes in the region of the nuclear chart below $^{68}\\mathrm{Ni}$ have\nbeen the subject of intense experimental and theoretical effort due to the\npotential onset of a new ``island of inversion'' when crossing the harmonic\noscillator subshell closure at $N = 40$. We have measured the masses of\n$^{64-68}\\textrm{Mn}$ using TITAN's multiple-reflection time-of-flight mass\nspectrometer, resulting in the first precision mass measurements of\n$^{67}\\mathrm{Mn}$ and $^{68}\\mathrm{Mn}$. These results are compared to\n\\textit{ab initio} calculations and modern shell model calculations and show an\nincrease in collectivity approaching $N=40$."
    ],
    "b_categories":[
      [
        "nucl-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.12987"
    ],
    "c_title":[
      "Ensemble Kalman filter in latent space using a variational autoencoder\n  pair"
    ],
    "c_abstract":[
      "Popular (ensemble) Kalman filter data assimilation (DA) approaches assume\nthat the errors in both the a priori estimate of the state and those in the\nobservations are Gaussian. For constrained variables, e.g. sea ice\nconcentration or stress, such an assumption does not hold. The variational\nautoencoder (VAE) is a machine learning (ML) technique that allows to map an\narbitrary distribution to\/from a latent space in which the distribution is\nsupposedly closer to a Gaussian. We propose a novel hybrid DA-ML approach in\nwhich VAEs are incorporated in the DA procedure. Specifically, we introduce a\nvariant of the popular ensemble transform Kalman filter (ETKF) in which the\nanalysis is applied in the latent space of a single VAE or a pair of VAEs. In\ntwin experiments with a simple circular model, whereby the circle represents an\nunderlying submanifold to be respected, we find that the use of a VAE ensures\nthat a posteri ensemble members lie close to the manifold containing the truth.\nFurthermore, online updating of the VAE is necessary and achievable when this\nmanifold varies in time, i.e. when it is non-stationary. We demonstrate that\nintroducing an additional second latent space for the observational innovations\nimproves robustness against detrimental effects of non-Gaussianity and bias in\nthe observational errors but it slightly lessens the performance if\nobservational errors are strictly Gaussian."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-505",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01058"
    ],
    "b_title":[
      "Giant emitter magnetometer"
    ],
    "b_abstract":[
      "Leveraging the sensitive dependence of a giant atom's radiation rate on its\nfrequency [A. F. Kockum, $et~al$., Phys. Rev. A 90, 013837 (2014)], we propose\nan effective magnetometer model based on single giant emitter. In this model,\nthe emitter's frequency is proportional to the applied bias magnetic field. The\nself-interference effect causes the slope of the dissipation spectrum to vary\nlinearly with the number of emitter-coupling points. The giant emitter\nmagnetometer achieves a sensitivity as high as $10^{-8}-10^{-9}\\,{\\rm\nT\/\\sqrt{Hz}}$, demonstrating the significant advantages of the\nself-interference effect compared to small emitters. We hope our proposal will\nexpand the applications of giant emitters in precision measurement and\nmagnetometry."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02276"
    ],
    "c_title":[
      "Singular flows with time-varying weights"
    ],
    "c_abstract":[
      "We study the mean field limit for singular dynamics with time evolving\nweights. Our results are an extension of the work of Serfaty\n\\cite{duerinckx2020mean} and Bresch-Jabin-Wang \\cite{bresch2019modulated},\nwhich consider singular Coulomb flows with weights which are constant time. The\ninclusion of time dependent weights necessitates the commutator estimates of\n\\cite{duerinckx2020mean,bresch2019modulated}, as well as a new functional\ninequality. The well-posedness of the mean field PDE and the associated system\nof trajectories is also proved."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-506",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10174"
    ],
    "b_title":[
      "Sensitivity-Based Distributed Programming for Non-Convex Optimization"
    ],
    "b_abstract":[
      "This paper presents a novel sensitivity-based distributed programming (SBDP)\napproach for non-convex, large-scale nonlinear programs (NLP). The algorithm\nrelies on first-order sensitivities to cooperatively solve the central NLP in a\ndistributed manner with only neighbor-to-neighbor communication and\nparallelizable local computations. The scheme is based on primal decomposition\nand offers minimal algorithmic complexity. We derive sufficient local\nconvergence conditions for non-convex problems. Furthermore, we consider the\nSBDP method in a distributed optimal control context and derive favorable\nconvergence properties in this setting. We illustrate these theoretical\nfindings and the performance of the proposed algorithm with simulations of\nvarious distributed optimization and control problems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.18522"
    ],
    "c_title":[
      "Digital Quantum Simulations of the Non-Resonant Open Tavis-Cummings\n  Model"
    ],
    "c_abstract":[
      "The open Tavis-Cummings model consists of $N$ quantum emitters interacting\nwith a common cavity mode, accounts for losses and decoherence, and is\nfrequently explored for quantum information processing and designing quantum\ndevices. As $N$ increases, it becomes harder to simulate the open\nTavis-Cummings model using traditional methods. To address this problem, we\nimplement two quantum algorithms for simulating the dynamics of this model in\nthe inhomogenous, non-resonant regime, with up to three excitations in the\ncavity. We show that the implemented algorithms have gate complexities that\nscale polynomially, as $O(N^2)$ and $O(N^3)$. One of these algorithms is the\nsampling-based wave matrix Lindbladization algorithm, for which we propose two\nprotocols to implement its system-independent fixed interaction, resolving key\nopen questions of [Patel and Wilde, Open Sys. & Info. Dyn., 30:2350014 (2023)].\nFurthermore, we benchmark our results against a classical differential equation\nsolver and demonstrate the ability to simulate classically intractable systems."
    ],
    "c_categories":[
      [
        "cs.DS",
        "physics.comp-ph",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-507",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03605"
    ],
    "b_title":[
      "Accelerating OTA Circuit Design: Transistor Sizing Based on a\n  Transformer Model and Precomputed Lookup Tables"
    ],
    "b_abstract":[
      "Device sizing is crucial for meeting performance specifications in\noperational transconductance amplifiers (OTAs), and this work proposes an\nautomated sizing framework based on a transformer model. The approach first\nleverages the driving-point signal flow graph (DP-SFG) to map an OTA circuit\nand its specifications into transformer-friendly sequential data. A specialized\ntokenization approach is applied to the sequential data to expedite the\ntraining of the transformer on a diverse range of OTA topologies, under\nmultiple specifications. Under specific performance constraints, the trained\ntransformer model is used to accurately predict DP-SFG parameters in the\ninference phase. The predicted DP-SFG parameters are then translated to\ntransistor sizes using a precomputed look-up table-based approach inspired by\nthe gm\/Id methodology. In contrast to previous conventional or\nmachine-learning-based methods, the proposed framework achieves significant\nimprovements in both speed and computational efficiency by reducing the need\nfor expensive SPICE simulations within the optimization loop; instead, almost\nall SPICE simulations are confined to the one-time training phase. The method\nis validated on a variety of unseen specifications, and the sizing solution\ndemonstrates over 90% success in meeting specifications with just one SPICE\nsimulation for validation, and 100% success with 3-5 additional SPICE\nsimulations."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.16093"
    ],
    "c_title":[
      "The heterotic $G_2$ moduli space metric"
    ],
    "c_abstract":[
      "In this article we dimensionally reduce a heterotic supergravity on a $G_2$\nbackground with Minkowski spacetime using a certain cohomology as a basis for\nthe Kaluza-Klein expansion, up to and including first order in $\\alpha'$. We\nconstruct the moduli space heterotic $G_2$ compactifications. The\n$\\alpha'$-correction induces a curvature correction to the Weyl-Peterson\nmetric. In the limit in which the $G_2$ manifold reduces to $SU(3)$, we recover\nknown results."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-508",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09337"
    ],
    "b_title":[
      "Some aspects of descent theory and applications"
    ],
    "b_abstract":[
      "This thesis is an exposition of the author's contribution on effective\ndescent morphisms in various categories of generalized categorical structures.\nIt consists of: Chapter 1, where an elementary description of descent theory\nand the content of each remaining chapter is provided, supplemented with\nreferences; Chapter 2, consisting of various descent theoretical definitions\nand results employed in the remainder of this work; four chapters, each\ncorresponding to an article written by the author during the period of his PhD\nstudies."
    ],
    "b_categories":[
      [
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.12559"
    ],
    "c_title":[
      "AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for\n  Video-language Understanding"
    ],
    "c_abstract":[
      "Multimodal Large Language Models (MLLMs) have revolutionized video\nunderstanding, yet are still limited by context length when processing long\nvideos. Recent methods compress videos by leveraging visual redundancy\nuniformly, yielding promising results. Nevertheless, our quantitative analysis\nshows that redundancy varies significantly across time and model layers,\nnecessitating a more flexible compression strategy. We propose AdaReTaKe, a\ntraining-free method that flexibly reduces visual redundancy by allocating\ncompression ratios among time and layers with theoretical guarantees.\nIntegrated into state-of-the-art MLLMs, AdaReTaKe improves processing capacity\nfrom 256 to 2048 frames while preserving critical information. Experiments on\nVideoMME, MLVU, LongVideoBench, and LVBench datasets demonstrate that AdaReTaKe\noutperforms existing methods by 2.3% and 2.8% for 7B and 72B models,\nrespectively, with even greater improvements of 5.9% and 6.0% on the longest\nLVBench. Our code is available at\nhttps:\/\/github.com\/SCZwangxiao\/video-FlexReduc.git."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-509",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11876"
    ],
    "b_title":[
      "FNIN: A Fourier Neural Operator-based Numerical Integration Network for\n  Surface-form-gradients"
    ],
    "b_abstract":[
      "Surface-from-gradients (SfG) aims to recover a three-dimensional (3D) surface\nfrom its gradients. Traditional methods encounter significant challenges in\nachieving high accuracy and handling high-resolution inputs, particularly\nfacing the complex nature of discontinuities and the inefficiencies associated\nwith large-scale linear solvers. Although recent advances in deep learning,\nsuch as photometric stereo, have enhanced normal estimation accuracy, they do\nnot fully address the intricacies of gradient-based surface reconstruction. To\novercome these limitations, we propose a Fourier neural operator-based\nNumerical Integration Network (FNIN) within a two-stage optimization framework.\nIn the first stage, our approach employs an iterative architecture for\nnumerical integration, harnessing an advanced Fourier neural operator to\napproximate the solution operator in Fourier space. Additionally, a\nself-learning attention mechanism is incorporated to effectively detect and\nhandle discontinuities. In the second stage, we refine the surface\nreconstruction by formulating a weighted least squares problem, addressing the\nidentified discontinuities rationally. Extensive experiments demonstrate that\nour method achieves significant improvements in both accuracy and efficiency\ncompared to current state-of-the-art solvers. This is particularly evident in\nhandling high-resolution images with complex data, achieving errors of fewer\nthan 0.1 mm on tested objects."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10374"
    ],
    "c_title":[
      "Use of frit-disc crucible sets to make solution growth more quantitative\n  and versatile"
    ],
    "c_abstract":[
      "The recent availability of step-edge, frit-disc crucible sets (generally sold\nas Canfield Crucible Sets or CCS) has led to multiple innovations associated\nwith our group's use of solution growth. Use of CCS allows for the clean\nseparation of liquid from solid phases during the growth process. This clean\nseparation enables the reuse of the decanted liquid, either allowing for\nsimple, economic, savings associated with recycling expensive precursor\nelements or allowing for the fractionation of a growth into multiple, small\nsteps, revealing the progression of multiple solidifications. Clean separation\nof liquid from solid phases also allows for the determination of the liquidus\nline (or surface) and the creation, or correction, of composition-temperature\nphase diagrams. The reuse of clean decanted liquid has also allowed us to\nprepare liquids ideally suited for the growth of large single crystals of\nspecific phases by tuning the composition of the melt to the optimal\ncomposition for growth of the desired phase, often with reduced nucleation\nsites. Finally, we discuss how solution growth and CCS use can be harnessed to\nprovide a plethora of composition-temperature data points defining liquidus\nlines or surfaces with differing degrees of precision to either test or anchor\nartificial intelligence and\/or machine learning based attempts to augment and\nextend the limited experimentally determined data base."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-510",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04028"
    ],
    "b_title":[
      "Stress-stress correlations in two-dimensional amorphous and crystalline\n  solids"
    ],
    "b_abstract":[
      "Stress-stress correlations in crystalline solids with long-range order can be\nstraightforwardly derived using elasticity theory. In contrast, the `emergent\nelasticity' of amorphous solids, rigid materials characterized by an underlying\ndisordered structure, defies direct explanation within traditional theoretical\nframeworks. To address this challenge, tensor gauge theories have been recently\nproposed as a promising approach to describe the emergent elasticity of\ndisordered solids and predict their stress-stress correlations. In this work,\nwe revisit this problem in two-dimensional amorphous and crystalline solids by\nemploying a canonical elasticity theory approach, supported by experimental and\nsimulation data. We demonstrate that, with respect to static stress-stress\ncorrelations, the response of a 2D disordered solid is indistinguishable from\nthat of a 2D isotropic crystalline solid and it is well predicted by vanilla\nelasticity theory. Moreover, we show that the presence of pinch-point\nsingularities in the stress response is not an exclusive feature of amorphous\nsolids. Our results confirm previous observations about the universal character\nof static stress-stress correlations in crystalline and amorphous packings."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.00977"
    ],
    "c_title":[
      "Host-guided data placement: whose job is it anyway?"
    ],
    "c_abstract":[
      "The increasing demand for SSDs coupled with scaling difficulties have left\nmanufacturers scrambling for newer SSD interfaces which promise better\nperformance and durability. While these interfaces reduce the rigidity of\ntraditional abstractions, they require application or system-level changes that\ncan impact the stability, security, and portability of systems. To make matters\nworse, such changes are rendered futile with introduction of next-generation\ninterfaces. Further, there is little guidance on data placement and hardware\nspecifics are often abstracted from the application layer. It is no surprise\ntherefore that such interfaces have seen limited adoption, leaving behind a\ngraveyard of experimental interfaces ranging from open-channel SSDs to zoned\nnamespaces.\n  In this paper, we show how shim layers can to shield systems from changing\nhardware interfaces while benefiting from them. We present Reshim, an\nall-userspace shim layer that performs affinity and lifetime based data\nplacement with no change to the operating system or the application. We\ndemonstrate Reshim's ease of adoption with host-device coordination for three\nwidely-used data-intensive systems: RocksDB, MongoDB, and CacheLib. With\nReshim, these systems see 2-6 times highe write throughput, up to 6 times lower\nlatency, and reduced write amplification compared to filesystems like F2FS.\nReshim performs on par with application-specific backends like ZenFS while\noffering more generality, lower latency, and richer data placement. With Reshim\nwe demonstrate the value of isolating the complexity of the placement logic,\nallowing easy deployment of dynamic placement rules across several applications\nand storage interfaces."
    ],
    "c_categories":[
      [
        "cs.ET",
        "cs.OS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-511",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17464"
    ],
    "b_title":[
      "Modelling a storage system of a wind farm with a ramp-rate limitation: a\n  semi-Markov modulated Brownian bridge approach"
    ],
    "b_abstract":[
      "We propose a new methodology to simulate the discounted penalty applied to a\nwind-farm operator by violating ramp-rate limitation policies. It is assumed\nthat the operator manages a wind turbine plugged into a battery, which either\nprovides or stores energy on demand to avoid ramp-up and ramp-down events. The\nbattery stages, namely charging, discharging, or neutral, are modeled as a\nsemi-Markov process. During each charging\/discharging period, the energy\nstored\/supplied is assumed to follow a modified Brownian bridge that depends on\nthree parameters. We prove the validity of our methodology by testing the model\non 10 years of real wind-power data and comparing real versus simulated\nresults."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.16343"
    ],
    "c_title":[
      "Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading\n  Agents"
    ],
    "c_abstract":[
      "Companies across all economic sectors continue to deploy large language\nmodels at a rapid pace. Reinforcement learning is experiencing a resurgence of\ninterest due to its association with the fine-tuning of language models from\nhuman feedback. Tool-chain language models control task-specific agents; if the\nconverse has not already appeared, it soon will. In this paper, we present what\nwe believe is the first investigation of an intelligent trading agent based on\ncontinuous deep reinforcement learning that also controls a large language\nmodel with which it can post to a social media feed observed by other traders.\nWe empirically investigate the performance and impact of such an agent in a\nsimulated financial market, finding that it learns to optimize its total\nreward, and thereby augment its profit, by manipulating the sentiment of the\nposts it produces. The paper concludes with discussion, limitations, and\nsuggestions for future work."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-512",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13529"
    ],
    "b_title":[
      "The impact of artificial intelligence technology on cross-border trade\n  in Southeast Asia: A meta-analytic approach"
    ],
    "b_abstract":[
      "This study investigates the impact of artificial intelligence (AI) technology\non cross-border trade using a qualitative content analysis approach. By\nsynthesizing existing empirical studies, we aim to quantify the overall effect\nof AI on trade flows and identify the key moderating and mediating variables.\nBesides, our results show that AI adoption significantly increases trade\nvolumes in Southeast Asia. Likewise, these effects are stronger in regions with\nadvanced technological infrastructure and favorable regulatory frameworks. In\naddition, Trade firm size partially mediates the relationship between AI\ntechnology and trade performance. Furthermore, this study draws on several key\ntheoretical frameworks that provide a comprehensive understanding of the\nmechanisms through which AI technology is affecting cross-border trade in\nSoutheast Asia. The primary theories used in this research include the\ntechnology, organization, and environment (TOE) framework, the diffuse\ninnovation (DOI) theory, Dynamic Capabilities Theory, Comparative Advantage\nTheory, Network theory, Transaction Cost Economics (TCE), the resource-based\nview, and the institution theory. Consequently, this study contributes to the\nexisting literature by providing a comprehensive analysis of the role of AI in\ninternational trade and highlighting the importance of contextual factors in\nmaximizing the benefits of AI. Thus, our findings underscore the need for\nfavorable policies and robust infrastructure to facilitate AI-driven trade\ngrowth. A discussion of limitations and future research directions will also be\npart of the report in Southeast Asia Trade."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2503.04513"
    ],
    "c_title":[
      "A Novel Solution for Drone Photogrammetry with Low-overlap Aerial Images\n  using Monocular Depth Estimation"
    ],
    "c_abstract":[
      "Low-overlap aerial imagery poses significant challenges to traditional\nphotogrammetric methods, which rely heavily on high image overlap to produce\naccurate and complete mapping products. In this study, we propose a novel\nworkflow based on monocular depth estimation to address the limitations of\nconventional techniques. Our method leverages tie points obtained from aerial\ntriangulation to establish a relationship between monocular depth and metric\ndepth, thus transforming the original depth map into a metric depth map,\nenabling the generation of dense depth information and the comprehensive\nreconstruction of the scene. For the experiments, a high-overlap drone dataset\ncontaining 296 images is processed using Metashape to generate depth maps and\nDSMs as ground truth. Subsequently, we create a low-overlap dataset by\nselecting 20 images for experimental evaluation. Results demonstrate that while\nthe recovered depth maps and resulting DSMs achieve meter-level accuracy, they\nprovide significantly better completeness compared to traditional methods,\nparticularly in regions covered by single images. This study showcases the\npotential of monocular depth estimation in low-overlap aerial photogrammetry."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-513",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02987"
    ],
    "b_title":[
      "On the numerical evaluation of wall shear stress using the finite\n  element method"
    ],
    "b_abstract":[
      "Wall shear stress (WSS) is a crucial hemodynamic quantity extensively studied\nin cardiovascular research, yet its numerical computation is not\nstraightforward. This work aims to compare WSS results obtained from two\ndifferent finite element discretizations, quantify the differences between\ncontinuous and discontinuous stresses, and introduce a novel method for WSS\nevaluation through the formulation of a boundary-flux problem. Two benchmark\nproblems are considered - a 2D Stokes flow on a unit square and a 3D Poiseuille\nflow through a cylindrical pipe. These are followed by investigations of\nsteady-state Navier-Stokes flow in two patient-specific aneurysms. The study\nfocuses on P1\/P1 stabilized and Taylor-Hood P2\/P1 mixed finite elements for\nvelocity and pressure. WSS is computed using either the proposed boundary-flux\nmethod or as a projection of tangential traction onto First order Lagrange\n(P1), Discontinuous Galerkin first order (DG-1), or Discontinuous Galerkin zero\norder (DG-0) space. For the P1\/P1 stabilized element, the boundary-flux and P1\nprojection methods yielded equivalent results. With the P2\/P1 element, the\nboundary-flux evaluation demonstrated faster convergence in the Poiseuille flow\nexample but showed increased sensitivity to pressure field inaccuracies in\npatient-specific geometries compared to the projection method. In\npatient-specific cases, the P2\/P1 element exhibited superior robustness to mesh\nsize when evaluating average WSS and low shear area (LSA), outperforming the\nP1\/P1 stabilized element. Projecting discontinuous finite element results into\ncontinuous spaces can introduce artifacts, such as the Gibbs phenomenon.\nConsequently, it becomes crucial to carefully select the finite element space\nfor boundary stress calculations - not only in applications involving WSS\ncomputations for aneurysms."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10158"
    ],
    "c_title":[
      "Primordial Black Holes Formed during Magneto-Hydrodynamic Turbulence in\n  Early Universe as Dominant Part of Dark Matter"
    ],
    "c_abstract":[
      "Primordial black holes (PBH) offer a compelling candidate for dark matter.\nWithin the framework of the Standard Model, the production of PBHs through\nwell-tested physical processes is highly worthy of investigations. This work\nhighlights the role of turbulences in the very early universe in sustaining\nintense and persistent fluctuations of energy or mass density, which could\nprovide a natural mechanism for PBH formations in the primordial universe. We\nanalyze the mass range and abundance of PBHs produced in the\nmagnetohydrodynamic turbulence induced by the first-order electroweak phase\ntransition. Remarkably, without invoking any new physics beyond the Standard\nModel, we find that the mass range of the produced PBHs falls within the only\nallowed \"asteroid mass\" window, and within natural parameter regions their\nabundance can be sufficiently large. These findings strongly suggest that PBHs\nproduced in the magnetohydrodynamic turbulence in the early universe could\ncomprise the dominant part of dark matter."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.HE",
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-514",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14366"
    ],
    "b_title":[
      "QuGStep: Refining Step Size Selection in Gradient Estimation for\n  Variational Quantum Algorithms"
    ],
    "b_abstract":[
      "Variational quantum algorithms (VQAs) offer a promising approach to solving\ncomputationally demanding problems by combining parameterized quantum circuits\nwith classical optimization. Estimating probabilistic outcomes on quantum\nhardware requires repeated measurements (shots). However, in practice, the\nlimited shot budget introduces significant noise in the evaluation of the\nobjective function. Gradient estimation in VQAs often relies on the\nfinite-difference, which evaluates the noisy objective function at perturbed\ncircuit parameter values. The accuracy of this estimation is highly dependent\non the choice of step size for these perturbations. An inappropriate step size\ncan exacerbate the impact of noise, causing inaccurate gradient estimates and\nhindering the classical optimization in VQAs. This paper proposes QuGStep, an\nalgorithm that addresses the challenge of determining the appropriate step size\nfor finite-difference gradient estimation under a shot budget. QuGStep is\ngrounded in a theorem that proves the optimal step size, which accounts for the\nshot budget, minimizes the error bound in gradient estimation using finite\ndifferences. Numerical experiments approximating the ground state energy of\nseveral molecules demonstrate that QuGStep can identify the appropriate step\nsize for the given shot budget to obtain effective gradient estimation.\nNotably, the step size identified by QuGStep achieved convergence to the ground\nstate energy with over 96% fewer shots compared to using a default step size.\nThese findings highlight the potential of QuGStep to improve the practical\ndeployment and scalability of quantum computing technologies."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.12663"
    ],
    "c_title":[
      "Trajectories of light beams in a Kerr metric: the influence of the\n  rotation of an observer on the shadow of a black hole"
    ],
    "c_abstract":[
      "This paper investigates the trajectories of light beams in a Kerr metric,\nwhich describes the gravitational field in the neighborhood of a rotating black\nhole. After reduction by cyclic coordinates, this problem reduces to analysis\nof a Hamiltonian system with two degrees of freedom. A bifurcation diagram is\nconstructed and a classification is made of the types of trajectories of the\nsystem according to the values of first integrals. Relations describing the\nboundary of the shadow of the black hole are obtained for a stationary observer\nwho rotates with an arbitrary angular velocity about the axis of rotation of\nthe black hole."
    ],
    "c_categories":[
      [
        "gr-qc",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-515",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19152"
    ],
    "b_title":[
      "Oddities in the Entanglement Scaling of the Quantum Six-Vertex Model"
    ],
    "b_abstract":[
      "We investigate the entanglement properties of the Quantum Six-Vertex Model on\na cylinder, focusing on the Shannon-Renyi entropy in the limit of Renyi order\n$n = \\infty$. This entropy, calculated from the ground state amplitudes of the\nequivalent XXZ spin-1\/2 chain, allows us to determine the Renyi entanglement\nentropy of the corresponding Rokhsar-Kivelson wavefunctions, which describe the\nground states of certain conformal quantum critical points. Our analysis\nreveals a novel logarithmic correction to the expected entanglement scaling\nwhen the system size is odd. This anomaly arises from the geometric frustration\nof spin configurations imposed by periodic boundary conditions on odd-sized\nchains. We demonstrate that the scaling prefactor of this logarithmic term is\ndirectly related to the compactification radius of the low-energy bosonic field\ntheory description, or equivalently, the Luttinger parameter. Thus, this\ncorrection provides a direct probe of the underlying Conformal Field Theory\n(CFT) describing the critical point. Our findings highlight the crucial role of\nsystem size parity in determining the entanglement properties of this model and\noffer insights into the interplay between geometry, frustration, and\ncriticality."
    ],
    "b_categories":[
      [
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05538"
    ],
    "c_title":[
      "Coalition Formation for Heterogeneous Federated Learning Enabled Channel\n  Estimation in RIS-assisted Cell-free MIMO"
    ],
    "c_abstract":[
      "Downlink channel estimation remains a significant bottleneck in\nreconfigurable intelligent surface-assisted cell-free multiple-input\nmultiple-output communication systems. Conventional approaches primarily rely\non centralized deep learning methods to estimate the high-dimensional and\ncomplex cascaded channels. These methods require data aggregation from all\nusers for centralized model training, leading to excessive communication\noverhead and significant data privacy concerns. Additionally, the large size of\nlocal learning models imposes heavy computational demands on end users,\nnecessitating strong computational capabilities that most commercial devices\nlack. To address the aforementioned challenges, a coalition-formation-guided\nheterogeneous federated learning (FL) framework is proposed. This framework\nleverages coalition formation to guide the formation of heterogeneous FL user\ngroups for efficient channel estimation. Specifically, by utilizing a\ndistributed deep reinforcement learning (DRL) approach, each FL user\nintelligently and independently decides whether to join or leave a coalition,\naiming at improving channel estimation accuracy, while reducing local model\nsize and computational costs for end users. Moreover, to accelerate the DRL-FL\nconvergence process and reduce computational burdens on end users, a transfer\nlearning method is introduced. This method incorporates both received reference\nsignal power and distance similarity metrics, by considering that nodes with\nsimilar distances to the base station and comparable received signal power have\na strong likelihood of experiencing similar channel fading. Massive experiments\nperformed that reveal that, compared with the benchmarks, the proposed\nframework significantly reduces the computational overhead of end users by 16%,\nimproves data privacy, and improves channel estimation accuracy by 20%."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-516",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14100"
    ],
    "b_title":[
      "JWST 1.5 {\\mu}m and 4.8 {\\mu}m Photometry of Y Dwarfs"
    ],
    "b_abstract":[
      "Brown dwarfs lack nuclear fusion and cool with time; the coldest known have\nan effective temperature below 500 K, and are known as Y dwarfs. We present a\nJames Webb Space Telescope (JWST) photometric dataset of Y dwarfs: twenty-three\nwere imaged in wide-field mode, 20 using NIRCam with the F150W and F480M\nfilters, and 3 using NIRISS with the F480M filter. We present an F480M vs.\nF150W $-$ F480M color-magnitude diagram for our sample, and other brown dwarfs\nwith F150W and F480M colors synthesized from JWST spectra by Beiler et al.\n(2024). For one target, WISEA J083011.95$+$283716.0, its detection in the\nnear-infrared confirms it as one of the reddest Y dwarfs known, with F150W $-$\nF480M $= 9.62$ mag. We provide its updated parallax and proper motion. One of\nthe Beiler et al. Y dwarfs, CWISEP J104756.81+545741.6, is unusually blue,\nconsistent with strong CO absorption seen in its spectrum which the F480M\nfilter is particularly sensitive to. The strong CO and the kinematics of the\nobject suggest it may be very low-mass and young. We update the resolved\nphotometry for the close binary system WISE J033605.05$-$014350.4 AB, and find\nthat the secondary is almost as cold as WISE 085510.83$-$071442.5, with $T_{\\rm\neff} \\lesssim 300$ K, however the F150W $-$ F480M color is significantly bluer,\npossibly suggesting the presence of water clouds. Astrometry is measured at the\nJWST epoch for the sample which is consistent with parallax and proper motion\nvalues reported by Kirkpatrick et al. (2021) and Marocco et al. (in prep)."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15788"
    ],
    "c_title":[
      "A two-stage model leveraging friendship network for community evolution\n  prediction in interactive networks"
    ],
    "c_abstract":[
      "Interactive networks representing user participation and interactions in\nspecific \"events\" are highly dynamic, with communities reflecting collective\nbehaviors that evolve over time. Predicting these community evolutions is\ncrucial for forecasting the trajectory of the related \"event\". Some models for\ncommunity evolution prediction have been witnessed, but they primarily focused\non coarse-grained evolution types (e.g., expand, dissolve, merge, split), often\nneglecting fine-grained evolution extents (e.g., the extent of community\nexpansion). Furthermore, these models typically utilize only one network data\n(here is interactive network data) for dynamic community featurization,\noverlooking the more stable friendship network that represents the friendships\nbetween people to enrich community representations. To address these\nlimitations, we propose a two-stage model that predicts both the type and\nextent of community evolution. Our model unifies multi-class classification for\nevolution type and regression for evolution extent within a single framework\nand fuses data from both interactive and friendship networks for a\ncomprehensive community featurization. We also introduce a hybrid strategy to\ndifferentiate between evolution types that are difficult to distinguish.\nExperimental results on three datasets show the significant superiority of the\nproposed model over other models, confirming its efficacy in predicting\ncommunity evolution in interactive networks."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-517",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09402"
    ],
    "b_title":[
      "VLog: Video-Language Models by Generative Retrieval of Narration\n  Vocabulary"
    ],
    "b_abstract":[
      "Human daily activities can be concisely narrated as sequences of routine\nevents (e.g., turning off an alarm) in video streams, forming an event\nvocabulary. Motivated by this, we introduce VLog, a novel video understanding\nframework that define video narrations as vocabulary, going beyond the typical\nsubword vocabularies in existing generative video-language models. Built on the\nlightweight language model GPT-2, VLog feature three key innovations: (i) A\ngenerative retrieval model, marrying language model's complex reasoning\ncapabilities with contrastive retrieval's efficient similarity search. (ii) A\nhierarchical vocabulary derived from large-scale video narrations using our\nnarration pair encoding algorithm, enabling efficient indexing of specific\nevents (e.g., cutting a tomato) by identifying broader scenarios (e.g.,\nkitchen) with expressive postfixes (e.g., by the left hand). (iii) A vocabulary\nupdate strategy leveraging generative models to extend the vocabulary for novel\nevents encountered during inference. To validate our approach, we introduce\nVidCap-Eval, a development set requiring concise narrations with reasoning\nrelationships (e.g., before and after). Experiments on EgoSchema, COIN, and\nHiREST further demonstrate the effectiveness of VLog, highlighting its ability\nto generate concise, contextually accurate, and efficient narrations, offering\na novel perspective on video understanding. Codes are released at\nhttps:\/\/github.com\/showlab\/VLog."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00103"
    ],
    "c_title":[
      "Theory of ab initio downfolding with arbitrary range electron-phonon\n  coupling"
    ],
    "c_abstract":[
      "Ab initio downfolding describes the electronic structure of materials within\na low-energy subspace, often around the Fermi level. Typically starting from\nmean-field calculations, this framework allows for the calculation of one- and\ntwo-electron interactions, and the parametrization of a many-body Hamiltonian\nrepresenting the active space of interest. The subsequent solution of such\nHamiltonians can provide insights into the physics of strongly-correlated\nmaterials. While phonons can substantially screen electron-electron\ninteractions, electron-phonon coupling has been commonly ignored within ab\ninitio downfolding, and when considered this is done only for short-range\ninteractions. Here we propose a theory of ab initio downfolding that accounts\nfor all mechanisms of electron-phonon coupling on equal footing, regardless of\nthe range of the interactions. Our practical computational implementation is\nreadily compatible with current downfolding approaches. We apply our approach\nto polar materials MgO and GeTe, and we reveal the importance of both\nshort-range and long-range electron-phonon coupling in determining the\nmagnitude of electron-electron interactions. Our results show that in the\nstatic limit, phonons reduce the on-site repulsion between electrons by 40% for\nMgO, and by 79% for GeTe. Our framework also predicts that overall attractive\nnearest-neighbor interactions arise between electrons in GeTe, consistent with\nsuperconductivity in this material."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-518",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10182"
    ],
    "b_title":[
      "Secure Semantic Communication With Homomorphic Encryption"
    ],
    "b_abstract":[
      "In recent years, Semantic Communication (SemCom), which aims to achieve\nefficient and reliable transmission of meaning between agents, has garnered\nsignificant attention from both academia and industry. To ensure the security\nof communication systems, encryption techniques are employed to safeguard\nconfidentiality and integrity. However, traditional cryptography-based\nencryption algorithms encounter obstacles when applied to SemCom. Motivated by\nthis, this paper explores the feasibility of applying homomorphic encryption to\nSemCom. Initially, we review the encryption algorithms utilized in mobile\ncommunication systems and analyze the challenges associated with their\napplication to SemCom. Subsequently, we employ scale-invariant feature\ntransform to demonstrate that semantic features can be preserved in homomorphic\nencrypted ciphertext. Based on this finding, we propose a task-oriented SemCom\nscheme secured through homomorphic encryption. We design the privacy preserved\ndeep joint source-channel coding (JSCC) encoder and decoder, and the frequency\nof key updates can be adjusted according to service requirements without\ncompromising transmission performance. Simulation results validate that, when\ncompared to plaintext images, the proposed scheme can achieve almost the same\nclassification accuracy performance when dealing with homomorphic ciphertext\nimages. Furthermore, we provide potential future research directions for\nhomomorphic encrypted SemCom."
    ],
    "b_categories":[
      [
        "cs.CR",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03004"
    ],
    "c_title":[
      "$2$-Restricted Optimal Pebbling Number of Some Graphs"
    ],
    "c_abstract":[
      "Let $G=(V,E)$ be a simple graph. A pebbling configuration on $G$ is a\nfunction $f:V\\rightarrow \\mathbb{N}\\cup \\{0\\}$ that assigns a non-negative\ninteger number of pebbles to each vertex. The weight of a configuration $f$ is\n$w(f)=\\sum_{u\\in V}f(u)$, the total number of pebbles. A pebbling move consists\nof removing two pebbles from a vertex $u$ and placing one pebble on an adjacent\nvertex $v$. A configuration $f$ is a $t$-restricted pebbling configuration\n($t$RPC) if no vertex has more than $t$ pebbles. The $t$-restricted optimal\npebbling number $\\pi_t^*(G)$ is the minimum weight of a $t$RPC on $G$ that\nallows any vertex to be reached by a sequence of pebbling moves. The\ndistinguishing number $D(G)$ is the minimum number of colors needed to label\nthe vertices of $G$ such that the only automorphism preserving the coloring is\nthe trivial one (i.e., the identity map). In this paper, we investigate the\n$2$-restricted optimal pebbling number of trees $T$ with $D(T)=2$ and radius at\nmost $2$ and enumerate their $2$-restricted optimal pebbling configurations.\nAlso we study the $2$-restricted optimal pebbling number of some graphs that\nare of importance in chemistry such as some alkanes."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-519",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19475"
    ],
    "b_title":[
      "Impulsive mixing of stellar populations in dwarf spheroidal galaxies"
    ],
    "b_abstract":[
      "We study the response of mono-energetic stellar populations with initially\nisotropic kinematics to impulsive and adiabatic changes to an underlying dark\nmatter potential. Half-light radii expand and velocity dispersions decrease as\nenclosed dark matter is removed. The details of this expansion and cooling\ndepend on the time scale on which the underlying potential changes. In the\nadiabatic regime, the product of half-light radius and average velocity\ndispersion is conserved. We show that the stellar populations maintain\ncentrally isotropic kinematics throughout their adiabatic evolution, and their\ndensities can be approximated by a family of analytical radial profiles.\nMetallicity gradients within the galaxy flatten as dark matter is slowly\nremoved. In the case of strong impulsive perturbations, stellar populations\ndevelop power-law-like density tails with radially biased kinematics. We show\nthat the distribution of stellar binding energies within the dark matter halo\nsubstantially widens after an impulsive perturbation, no matter the sign of the\nperturbation. This allows initially energetically separated stellar populations\nto mix, to the extent that previously chemo-dynamically distinct populations\nmay masquerade as a single population with large metallicity and energy spread.\nFinally, we show that in response to an impulsive perturbation, stellar\npopulations that are deeply embedded in cored dark matter halos undergo a\nseries of damped oscillations before reaching a virialised equilibrium state,\ndriven by inefficient phase mixing in the harmonic potentials of cored halos.\nThis slow return to equilibrium adds substantial systematic uncertainty to\ndynamical masses estimated from Jeans modeling or the virial theorem."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.09026"
    ],
    "c_title":[
      "Intelligent Anti-Money Laundering Solution Based upon Novel Community\n  Detection in Massive Transaction Networks on Spark"
    ],
    "c_abstract":[
      "Criminals are using every means available to launder the profits from their\nillegal activities into ostensibly legitimate assets. Meanwhile, most\ncommercial anti-money laundering systems are still rule-based, which cannot\nadapt to the ever-changing tricks. Although some machine learning methods have\nbeen proposed, they are mainly focused on the perspective of abnormal behavior\nfor single accounts. Considering money laundering activities are often involved\nin gang criminals, these methods are still not intelligent enough to crack down\non criminal gangs all-sidedly. In this paper, a systematic solution is\npresented to find suspicious money laundering gangs. A temporal-directed\nLouvain algorithm has been proposed to detect communities according to relevant\nanti-money laundering patterns. All processes are implemented and optimized on\nSpark platform. This solution can greatly improve the efficiency of anti-money\nlaundering work for financial regulation agencies."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-520",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00284"
    ],
    "b_title":[
      "Bounded-Confidence Models of Multi-Dimensional Opinions with\n  Topic-Weighted Discordance"
    ],
    "b_abstract":[
      "People's opinions on a wide range of topics often evolve over time through\ntheir interactions with others. Models of opinion dynamics primarily focus on\none-dimensional opinions which represent opinions on one topic. However,\nopinions on various topics are rarely isolated; instead, they can be\ninterdependent and exhibit correlations. In a bounded-confidence model (BCM) of\nopinion dynamics, agents influence each other's opinions only if their opinions\nare sufficiently similar. We extend classical agent-based BCMs -- namely, the\nHegeselmann--Krause BCM, which has synchronous interactions, and the\nDeffuant--Weisbuch BCM, which has asynchronous interactions -- to a\nmultidimensional setting, in which the opinions are multidimensional vectors\nrepresenting opinions of different topics and opinions on different topics are\ninterdependent. To measure opinion differences between agents, we introduce\ntopic-weighted discordance functions that account for opinion differences in\nall topics. We use the regions of receptiveness to characterize the\nsteady-state opinion clusters and provide an analytical approach to compute\nthese regions. In addition, we numerically simulate our models on various\nnetworks with initial opinions drawn from a variety of distributions. When\ninitial opinions are correlated across different topics, our topic-weighted\nBCMs yield significantly different results in both transient and steady states\ncompared to baseline models, where the dynamics of each opinion topic are\nindependent."
    ],
    "b_categories":[
      [
        "cs.SI",
        "math.DS",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.02914"
    ],
    "c_title":[
      "Bayesian Power and Sample Size Calculations for Bayes Factors in the\n  Binomial Setting"
    ],
    "c_abstract":[
      "Bayesian design of experiments and sample size calculations usually rely on\ncomplex Monte Carlo simulations in practice. Obtaining bounds on Bayesian\nnotions of the false-positive rate and power therefore often lack closed-form\nor approximate numerical solutions. In this paper, we focus on the sample size\ncalculation in the binomial setting via Bayes factors, the predictive updating\nfactor from prior to posterior odds. We discuss the drawbacks of sample size\ncalculations via Monte Carlo simulations and propose a numerical root-finding\napproach which allows to determine the necessary sample size to obtain\nprespecified bounds of Bayesian power and type-I-error rate almost\ninstantaneously. Real-world examples and applications in clinical trials\nillustrate the advantage of the proposed method. We focus on point-null versus\ncomposite and directional hypothesis tests, derive the corresponding Bayes\nfactors, and discuss relevant aspects to consider when pursuing Bayesian design\nof experiments with the introduced approach. In summary, our approach allows\nfor a Bayes-frequentist compromise by providing a Bayesian analogue to a\nfrequentist power analysis for the Bayes factor in binomial settings. A case\nstudy from a Phase II trial illustrates the utility of our approach. The\nmethods are implemented in our R package bfpwr."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-521",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09972"
    ],
    "b_title":[
      "A bijection for descent sets of permutations with only even and only odd\n  cycles"
    ],
    "b_abstract":[
      "It is known that, when $n$ is even, the number of permutations of\n$\\{1,2,\\dots,n\\}$ all of whose cycles have odd length equals the number of\nthose all of whose cycles have even length. Adin, Heged\\H{u}s and Roichman\nrecently found a surprising refinement of this identity. They showed that, for\nany fixed set $J$, the equality still holds when restricting to permutations\nwith descent set $J$ on one side, and permutations with ascent set $J$ on the\nother. Their proof uses generating functions for higher Lie characters. They\nalso deduce a version for odd $n$.\n  Here we give a bijective proof of their result. We first use known bijections\nto restate the identity in terms of multisets of necklaces, and then describe a\nnew weight-preserving bijection between words all of whose Lyndon factors have\nodd length and are distinct, and words all of whose Lyndon factors have even\nlength. We also show that the corresponding equality about Lyndon\nfactorizations has a short proof using generating functions."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.01857"
    ],
    "c_title":[
      "A strictly predefined-time convergent and anti-noise fractional-order\n  zeroing neural network for solving time-variant quadratic programming in\n  kinematic robot control"
    ],
    "c_abstract":[
      "This paper proposes a strictly predefined-time convergent and anti-noise\nfractional-order zeroing neural network (SPTC-AN-FOZNN) model, meticulously\ndesigned for addressing time-variant quadratic programming (TVQP) problems.\nThis model marks the first variable-gain ZNN to collectively manifest strictly\npredefined-time convergence and noise resilience, specifically tailored for\nkinematic motion control of robots. The SPTC-AN-FOZNN advances traditional ZNNs\nby incorporating a conformable fractional derivative in accordance with the\nLeibniz rule, a compliance not commonly achieved by other fractional derivative\ndefinitions. It also features a novel activation function designed to ensure\nfavorable convergence independent of the model's order. When compared to five\nrecently published recurrent neural networks (RNNs), the SPTC-AN-FOZNN,\nconfigured with $0<\\alpha\\leq 1$, exhibits superior positional accuracy and\nrobustness against additive noises for TVQP applications. Extensive empirical\nevaluations, including simulations with two types of robotic manipulators and\nexperiments with a Flexiv Rizon robot, have validated the SPTC-AN-FOZNN's\neffectiveness in precise tracking and computational efficiency, establishing\nits utility for robust kinematic control."
    ],
    "c_categories":[
      [
        "cs.NE",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-522",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12422"
    ],
    "b_title":[
      "CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer\n  and Metric Learning"
    ],
    "b_abstract":[
      "Multimodal Fake News Detection has received increasing attention recently.\nExisting methods rely on independently encoded unimodal data and overlook the\nadvantages of capturing intra-modality relationships and integrating\ninter-modal similarities using advanced techniques. To address these issues,\nCross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News\nDetection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image\nPre-training with Frozen Image Encoders and Large Language Models (BLIP2) as\nencoders to capture detailed text, image and combined image-text\nrepresentations. The metric learning module employs a proxy anchor method to\ncapture intra-modality relationships while the feature fusion module uses a\nCross-Modal and Tri-Transformer for effective integration. The final fake news\ndetector processes the fused features through a classifier to predict the\nauthenticity of the content. Experiments on datasets show that CroMe excels in\nmultimodal fake news detection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05407"
    ],
    "c_title":[
      "The Complexity of Learning Sparse Superposed Features with Feedback"
    ],
    "c_abstract":[
      "The success of deep networks is crucially attributed to their ability to\ncapture latent features within a representation space. In this work, we\ninvestigate whether the underlying learned features of a model can be\nefficiently retrieved through feedback from an agent, such as a large language\nmodel (LLM), in the form of relative \\textit{triplet comparisons}. These\nfeatures may represent various constructs, including dictionaries in LLMs or\ncomponents of a covariance matrix of Mahalanobis distances. We analyze the\nfeedback complexity associated with learning a feature matrix in sparse\nsettings. Our results establish tight bounds when the agent is permitted to\nconstruct activations and demonstrate strong upper bounds in sparse scenarios\nwhen the agent's feedback is limited to distributional information. We validate\nour theoretical findings through experiments on two distinct applications:\nfeature recovery from Recursive Feature Machine-trained models and dictionary\nextraction from sparse autoencoders trained on Large Language Models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-523",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16719"
    ],
    "b_title":[
      "Practical Acoustic Eavesdropping On Typed Passphrases"
    ],
    "b_abstract":[
      "Cloud services have become an essential infrastructure for enterprises and\nindividuals. Access to these cloud services is typically governed by Identity\nand Access Management systems, where user authentication often relies on\npasswords. While best practices dictate the implementation of multi-factor\nauthentication, it's a reality that many such users remain solely protected by\npasswords. This reliance on passwords creates a significant vulnerability, as\nthese credentials can be compromised through various means, including\nside-channel attacks. This paper exploits keyboard acoustic emanations to infer\ntyped natural language passphrases via unsupervised learning, necessitating no\nprevious training data. Whilst this work focuses on short passphrases, it is\nalso applicable to longer messages, such as confidential emails, where the\nmargin for error is much greater, than with passphrases, making the attack even\nmore effective in such a setting. Unlike traditional attacks that require\nphysical access to the target device, acoustic side-channel attacks can be\nexecuted within the vicinity, without the user's knowledge, offering a\nworthwhile avenue for malicious actors. Our findings replicate and extend\nprevious work, confirming that cross-correlation audio preprocessing\noutperforms methods like mel-frequency-cepstral coefficients and fast-fourier\ntransforms in keystroke clustering. Moreover, we show that partial passphrase\nrecovery through clustering and a dictionary attack can enable faster than\nbrute-force attacks, further emphasizing the risks posed by this attack vector."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18255"
    ],
    "c_title":[
      "Large frequency nonreciprocity of azimuthal spin wave modes in submicron\n  vortex state disks"
    ],
    "c_abstract":[
      "Vortex states in thin film disks host spin wave modes that are geometrically\nquantized according to their radial and azimuthal indices. Previous studies\nhave shown that hybridization between these modes and the vortex core results\nin a sizeable frequency nonreciprocity between low-order clockwise and\ncounterclockwise propagating azimuthal modes. Here, we present a computational\nstudy of these spin wave modes in submicron disks in which the spatial\nextension of the vortex core becomes comparable to the wavelength of certain\nmodes. In such cases, we find that the frequency nonreciprocity can be large\neven for higher order radial and azimuthal indices, reaching several GHz and\ncomparable to the mode frequencies themselves."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-524",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04801"
    ],
    "b_title":[
      "Entanglement and Bell Nonlocality in $\\tau^+ \\tau^-$ at the BEPC"
    ],
    "b_abstract":[
      "Quantum entanglement and Bell nonlocality are two phenomena that occur only\nin quantum systems. In both cases, these are correlations between two\nsubsystems that are classically absent. Traditionally, these phenomena have\nbeen measured in low-energy photon and electron experiments, but more recently\nthey have also been measured in high-energy particle collider environments. In\nthis work, we propose measuring the entanglement and Bell nonlocality in the\n$\\tau^+\\tau^-$ state near and above its kinematic threshold at the Beijing\nElectron Positron Collider (BEPC). We find that in the existing dataset,\nentanglement is observable if systematic uncertainties are kept to 1%. In the\nupcoming run between 4.0 and 5.6 GeV, the entanglement is predicted to be\nmeasurable with a precision better than 4% and Bell nonlocality can be\nestablished at $5\\sigma$ as long as systematic uncertainty can be controlled at\nlevel of 0.5% - 2.0%, depending on the center-of-mass energy."
    ],
    "b_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08543"
    ],
    "c_title":[
      "Stability and convergence of relaxed scalar auxiliary variable schemes\n  for Cahn-Hilliard systems with bounded mass source"
    ],
    "c_abstract":[
      "The scalar auxiliary variable (SAV) approach of Shen et al. (2018), which\npresents a novel way to discretize a large class of gradient flows, has been\nextended and improved by many authors for general dissipative systems. In this\nwork we consider a Cahn-Hilliard system with mass source that, for image\nprocessing and biological applications, may not admit a dissipative structure\ninvolving the Ginzburg-Landau energy. Hence, compared to previous works, the\nstability of SAV-discrete solutions for such systems is not immediate. We\nestablish, with a bounded mass source, stability and convergence of time\ndiscrete solutions for a first-order relaxed SAV scheme in the sense of Jiang\net al. (2022), and apply our ideas to Cahn-Hilliard systems appearing in\ndiblock co-polymer phase separation, tumor growth, image inpainting and\nsegmentation."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-525",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15712"
    ],
    "b_title":[
      "SeqSeg: Learning Local Segments for Automatic Vascular Model\n  Construction"
    ],
    "b_abstract":[
      "Computational modeling of cardiovascular function has become a critical part\nof diagnosing, treating and understanding cardiovascular disease. Most\nstrategies involve constructing anatomically accurate computer models of\ncardiovascular structures, which is a multistep, time-consuming process. To\nimprove the model generation process, we herein present SeqSeg (sequential\nsegmentation): a novel deep learning based automatic tracing and segmentation\nalgorithm for constructing image-based vascular models. SeqSeg leverages local\nU-Net-based inference to sequentially segment vascular structures from medical\nimage volumes. We tested SeqSeg on CT and MR images of aortic and aortofemoral\nmodels and compared the predictions to those of benchmark 2D and 3D global\nnnU-Net models, which have previously shown excellent accuracy for medical\nimage segmentation. We demonstrate that SeqSeg is able to segment more complete\nvasculature and is able to generalize to vascular structures not annotated in\nthe training data."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV",
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17853"
    ],
    "c_title":[
      "Stability analysis of a branching diffusion solver for nonlinear PDEs"
    ],
    "c_abstract":[
      "Stochastic branching algorithms provide a useful alternative to grid-based\nschemes for the numerical solution of partial differential equations,\nparticularly in high-dimensional settings. However, they require a strict\ncontrol of the integrability of random functionals of branching processes in\norder to ensure the non-explosion of solutions. In this paper, we study the\nstability of a functional branching representation of PDE solutions by deriving\nsufficient criteria for the integrability of the multiplicative weighted\nprogeny of stochastic branching processes. We also prove the uniqueness of mild\nsolutions under uniform integrability assumptions on random functionals."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-526",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09674"
    ],
    "b_title":[
      "The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Safety\n  Analysis"
    ],
    "b_abstract":[
      "Large Language Models' safety-aligned behaviors, such as refusing harmful\nqueries, can be represented by linear directions in activation space. Previous\nresearch modeled safety behavior with a single direction, limiting mechanistic\nunderstanding to an isolated safety feature. In this work, we discover that\nsafety-aligned behavior is jointly controlled by multi-dimensional directions.\nNamely, we study the vector space of representation shifts during safety\nfine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal\ndirections in the space, we first find that a dominant direction governs the\nmodel's refusal behavior, while multiple smaller directions represent distinct\nand interpretable features like hypothetical narrative and role-playing. We\nthen measure how different directions promote or suppress the dominant\ndirection, showing the important role of secondary directions in shaping the\nmodel's refusal representation. Finally, we demonstrate that removing certain\ntrigger tokens in harmful queries can mitigate these directions to bypass the\nlearned safety capability, providing new insights on understanding safety\nalignment vulnerability from a multi-dimensional perspective. Code and\nartifacts are available at https:\/\/github.com\/BMPixel\/safety-residual-space."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19296"
    ],
    "c_title":[
      "Equivariant Kuznetsov components for cubic fourfolds with a symplectic\n  involution"
    ],
    "c_abstract":[
      "We study the equivariant Kuznetsov component $\\mathrm{Ku}_G(X)$ of a general\ncubic fourfold $X$ with a symplectic involution. We show that\n$\\mathrm{Ku}_G(X)$ is equivalent to the derived category $D^b(S)$ of a $K3$\nsurface $S$, where $S$ is given as a component of the fixed locus of the\ninduced symplectic action on the Fano variety of lines on $X$."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-527",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18515"
    ],
    "b_title":[
      "Recovering a (1+1)-dimensional wave equation from a single white noise\n  boundary measurement"
    ],
    "b_abstract":[
      "We consider the following inverse problem: Suppose a $(1+1)$-dimensional wave\nequation on $\\mathbb R_+$ with zero initial conditions is excited with a\nNeumann boundary data modelled as a white noise process. Given also the\nDirichlet data at the same point, determine the unknown first order coefficient\nfunction of the system.\n  We first establish that direct problem is well-posed. The inverse problem is\nthen solved by showing that correlations of the boundary data determine the\nNeumann-to-Dirichlet operator in the sense of distributions, which is known to\nuniquely identify the coefficient. This approach has applications in acoustic\nmeasurements of internal cross-sections of fluid pipes such as pressurised\nwater supply pipes and vocal tract shape determination."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.06113"
    ],
    "c_title":[
      "Spatiotemporal Analysis of Graphite Electrode Aging Through X-rays"
    ],
    "c_abstract":[
      "Aging limits commercial lithium-ion battery lifetime and must be understood\nat the level of active materials to improve both cell durability and\nperformance. We show that in state-of-the-art technologies such as\ngraphite\/LiFePO4-Li(NiCoAl)O2 cells, degradation mostly arises at the negative\nelectrode side due to both loss of active material and cyclable lithium. The\ncharacteristics of these phenomena are unraveled by applying a multi-technique\nworkflow in which electrochemical, structural, and morphological analyses are\ncombined. Series of post mortem, ex situ and operando experiments performed on\naged materials dismounted from a large format cell at its end-of-life are\nbenchmarked against pristine materials to highlight how in-plane and\nthrough-plane heterogeneities in graphite dynamics are profoundly modified in\nnature and exacerbated by aging. We discover inactive regions, where pure\ngraphite or lithiated phases (LixC6) are invariant on cycling. They correspond\nto particles either disconnected (irreversibly lost) or kinetically-limited\n(reactivated at a very slow C-rate). As we map their distribution in 2D during\nbattery cycling, we observe that LixC6-inactivity is heterogeneously\ndistributed in the depth of the aged negative electrode and depends on both the\nx value and the C-rate. In particular, the negative electrode-separator\ninterface is much more inactivated after long-term usage. Inactivity is\ncorrelated with an overall increased spatial heterogeneity of lithium\nconcentration. This work suggests that the origin of aging lies in overworking\ngraphite close to the separator."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-528",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04928"
    ],
    "b_title":[
      "AUTOFRAME -- A Software-driven Integration Framework for Automotive\n  Systems"
    ],
    "b_abstract":[
      "The evolution of automotive technologies towards more integrated and\nsophisticated systems requires a shift from traditional distributed\narchitectures to centralized vehicle architectures. This work presents a novel\nframework that addresses the increasing complexity of Software Defined Vehicles\n(SDV) through a centralized approach that optimizes software and hardware\nintegration. Our approach introduces a scalable, modular, and secure automotive\ndeployment framework that leverages a hardware abstraction layer and dynamic\nsoftware deployment capabilities to meet the growing demands of the industry.\nThe framework supports centralized computing of vehicle functions, making\nsoftware development more dynamic and easier to update and upgrade. We\ndemonstrate the capabilities of our framework by implementing it in a simulated\nenvironment where it effectively handles several automotive operations such as\nlane detection, motion planning, and vehicle control. Our results highlight the\nframework's potential to facilitate the development and maintenance of future\nvehicles, emphasizing its adaptability to different hardware configurations and\nits readiness for real-world applications. This work lays the foundation for\nfurther exploration of robust, scalable, and secure SDV systems, setting a new\nstandard for future automotive architectures."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08932"
    ],
    "c_title":[
      "Convergence Analysis of Levenberg-Marquardt Method for Inverse Problem\n  with H\\\"{o}lder Stability Estimate"
    ],
    "c_abstract":[
      "We analyze convergence of the Levenberg-Marquardt method for solving\nnonlinear inverse problems in Hilbert spaces. Specifically, we establish local\nconvergence and convergence rates for a class of inverse problems that satisfy\nH\\\"{o}lder stability estimate. Furthermore, based on what we found in the\nmentioned analysis, we develop global reconstruction algorithms for solving\ninverse problems with finite measurements for exact and noisy data,\nrespectively."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-529",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00670"
    ],
    "b_title":[
      "Transformer Based Self-Context Aware Prediction for Few-Shot Anomaly\n  Detection in Videos"
    ],
    "b_abstract":[
      "Anomaly detection in videos is a challenging task as anomalies in different\nvideos are of different kinds. Therefore, a promising way to approach video\nanomaly detection is by learning the non-anomalous nature of the video at hand.\nTo this end, we propose a one-class few-shot learning driven transformer based\napproach for anomaly detection in videos that is self-context aware. Features\nfrom the first few consecutive non-anomalous frames in a video are used to\ntrain the transformer in predicting the non-anomalous feature of the subsequent\nframe. This takes place under the attention of a self-context learned from the\ninput features themselves. After the learning, given a few previous frames, the\nvideo-specific transformer is used to infer if a frame is anomalous or not by\ncomparing the feature predicted by it with the actual. The effectiveness of the\nproposed method with respect to the state-of-the-art is demonstrated through\nqualitative and quantitative results on different standard datasets. We also\nstudy the positive effect of the self-context used in our approach."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18662"
    ],
    "c_title":[
      "ReviewCoin: Paying for Real Work"
    ],
    "c_abstract":[
      "The peer-review process is broken and the problem is getting worse,\nespecially in AI: large conferences like NeurIPS increasingly struggle to\nadequately review huge numbers of paper submissions. I propose a scalable\nsolution that, foremost, recognizes reviewing as important, necessary,\n\\emph{work} and rewards it with crypto-coins owned and managed by the\nconferences themselves. The idea is at its core quite simple: paper submissions\nrequire work (reviews, meta-reviews, etc.) to be done, and therefore the\nsubmitter must pay for that work. Each reviewer submits their review to be\napproved by some designated conference officer (e.g. PC chair, Area Chair,\netc.), and upon approval is paid a single coin for a single review. If three\nreviews are required, the cost of submission should be three coins + a tax that\ncovers payments to all the volunteers who organize the conference. After some\none-time startup costs to fairly distribute coins, the process should be\nrelatively stable with new coins minted only when a conference grows."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-530",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02963"
    ],
    "b_title":[
      "A data-driven merit order: Learning a fundamental electricity price\n  model"
    ],
    "b_abstract":[
      "Power prices can be forecasted using data-driven models or fundamental\nmodels. Data-driven models learn from historical patterns, while fundamental\nmodels simulate electricity markets. Traditionally, fundamental models have\nbeen too computationally demanding to allow for intrinsic parameter estimation\nor frequent updates, which are essential for short-term forecasting. In this\npaper, we propose a novel data-driven fundamental model that combines the\nstrengths of both approaches. We estimate the parameters of a fully fundamental\nmerit order model using historical data, similar to how data-driven models\nwork. This removes the need for fixed technical parameters or expert\nassumptions, allowing most parameters to be calibrated directly to\nobservations. The model is efficient enough for quick parameter estimation and\nforecast generation. We apply it to forecast German day-ahead electricity\nprices and demonstrate that it outperforms both classical fundamental and\npurely data-driven models. The hybrid model effectively captures price\nvolatility and sequential price clusters, which are becoming increasingly\nimportant with the expansion of renewable energy sources. It also provides\nvaluable insights, such as fuel switches, marginal power plant contributions,\nestimated parameters, dispatched plants, and power generation."
    ],
    "b_categories":[
      [
        "econ.EM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2502.13877"
    ],
    "c_title":[
      "Near-Optimal List-Recovery of Linear Code Families"
    ],
    "c_abstract":[
      "We prove several results on linear codes achieving list-recovery capacity. We\nshow that random linear codes achieve list-recovery capacity with constant\noutput list size (independent of the alphabet size and length). That is, over\nalphabets of size at least $\\ell^{\\Omega(1\/\\varepsilon)}$, random linear codes\nof rate $R$ are $(1-R-\\varepsilon, \\ell,\n(\\ell\/\\varepsilon)^{O(\\ell\/\\varepsilon)})$-list-recoverable for all $R\\in(0,1)$\nand $\\ell$. Together with a result of Levi, Mosheiff, and Shagrithaya, this\nimplies that randomly punctured Reed-Solomon codes also achieve list-recovery\ncapacity. We also prove that our output list size is near-optimal among all\nlinear codes: all $(1-R-\\varepsilon, \\ell, L)$-list-recoverable linear codes\nmust have $L\\ge \\ell^{\\Omega(R\/\\varepsilon)}$.\n  Our simple upper bound combines the Zyablov-Pinsker argument with recent\nbounds from Kopparty, Ron-Zewi, Saraf, Wootters, and Tamo on the maximum\nintersection of a \"list-recovery ball\" and a low-dimensional subspace with\nlarge distance. Our lower bound is inspired by a recent lower bound of Chen and\nZhang."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.CO",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-531",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02520"
    ],
    "b_title":[
      "Privacy by Design for Self-Sovereign Identity Systems: An in-depth\n  Component Analysis completed by a Design Assistance Dashboard"
    ],
    "b_abstract":[
      "The use of Self-Sovereign Identity (SSI) systems for digital identity\nmanagement is gaining traction and interest. Countries such as Bhutan have\nalready implemented an SSI infrastructure to manage the identity of their\ncitizens. The EU, thanks to the revised eIDAS regulation, is opening the door\nfor SSI vendors to develop SSI systems for the planned EU digital identity\nwallet. These developments, which fall within the sovereign domain, raise\nquestions about individual privacy.\n  The purpose of this article is to help SSI solution designers make informed\nchoices to ensure that the designed solution is privacy-friendly. The\nobservation is that the range of possible solutions is very broad, from DID and\nDID resolution methods to verifiable credential types, publicly available\ninformation (e.g. in a blockchain), type of infrastructure, etc. As a result,\nthe article proposes (1) to group the elementary building blocks of a SSI\nsystem into 5 structuring layers, (2) to analyze for each layer the privacy\nimplications of using the chosen building block, and (3) to provide a design\nassistance dashboard that gives the complete picture of the SSI, and shows the\ninterdependencies between architectural choices and technical building blocks,\nallowing designers to make informed choices and graphically achieve a SSI\nsolution that meets their need for privacy."
    ],
    "b_categories":[
      [
        "cs.CY",
        "cs.ET",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14665"
    ],
    "c_title":[
      "Landscape of Correlated Orders in Strained Bilayer Nickelate Thin Films"
    ],
    "c_abstract":[
      "The discovery of high-temperature superconductivity in bilayer nickelates\nLa$_3$Ni$_2$O$_7$ under pressure has sparked significant research interest.\nThis interest has been further fueled by the recent achievement of\nsuperconductivity in compressed thin films at ambient pressure, although the\norigin and underlying mechanism remain elusive. In this work, we explore the\nelectronic structures and instabilities of strained thin films on substrates to\nidentify the key factors for achieving superconductivity, using\nfirst-principles and functional renormalization group calculations. Our\nfindings suggest that the compressed NiO$_2$ bilayer near the interface is\nunlikely to exhibit superconductivity, despite its electron-doped nature. In\ncontrast, the NiO$_2$ bilayer away from the interface shows density-wave\ninstability when undoped or slightly hole-doped. However, when this bilayer is\nhole-doped, leading to the emergence of a hole pocket around the M point, it\nexhibits robust $s_{\\pm}$-wave superconductivity, which may account for\nsuperconductivity observed in thin films. For the stretched NiO$_2$ bilayer,\nrobust spin-density-wave instability is observed due to enhanced Fermi surface\nnesting, despite the presence of a hole pocket around the M point. Potential\nexperimental implications are discussed. Our study highlights the crucial role\nof fermiology in determining electronic instability and establishes a unified\nscenario for superconductivity in both pressurized bulk and strained thin films\nof bilayer nickelates."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-532",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17842"
    ],
    "b_title":[
      "Task-Driven Semantic Quantization and Imitation Learning for\n  Goal-Oriented Communications"
    ],
    "b_abstract":[
      "Semantic communication marks a new paradigm shift from bit-wise data\ntransmission to semantic information delivery for the purpose of bandwidth\nreduction. To more effectively carry out specialized downstream tasks at the\nreceiver end, it is crucial to define the most critical semantic message in the\ndata based on the task or goal-oriented features. In this work, we propose a\nnovel goal-oriented communication (GO-COM) framework, namely Goal-Oriented\nSemantic Variational Autoencoder (GOS-VAE), by focusing on the extraction of\nthe semantics vital to the downstream tasks. Specifically, we adopt a Vector\nQuantized Variational Autoencoder (VQ-VAE) to compress media data at the\ntransmitter side. Instead of targeting the pixel-wise image data\nreconstruction, we measure the quality-of-service at the receiver end based on\na pre-defined task-incentivized model. Moreover, to capture the relevant\nsemantic features in the data reconstruction, imitation learning is adopted to\nmeasure the data regeneration quality in terms of goal-oriented semantics. Our\nexperimental results demonstrate the power of imitation learning in\ncharacterizing goal-oriented semantics and bandwidth efficiency of our proposed\nGOS-VAE."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17100"
    ],
    "c_title":[
      "Social Optimization in Noncooperative Games under Central Regulation"
    ],
    "c_abstract":[
      "This paper proposes a novel optimization problem building on noncooperative\ngames under central regulation, which can be formulated as a bilevel structure.\nIn the low-level, each player competes to minimize its own cost function that\ndepends not only on the strategies of all players, but also on an intervention\ndecision of the central regulator, while the central regulator located at the\nhigh-level attempts to achieve the social optimum, that is, to minimize the sum\nof cost functions of all players through an adjustable intervention decision.\nIn this setting, under the intervention of the central regulator, the low-level\nplayers perform in a noncooperative game and aim to seek the Nash equilibrium,\nwhich indeed is related with the regulator's decision. Meanwhile, the objective\nof the regulator is to choose a decision such that the social cost, i.e., the\nsum of cost functions of all players is minimum. This formulated bilevel social\noptimization problem is proven to be constrained, nonconvex and nonsmooth. To\naddress this intricate problem, an inexact zeroth-order algorithm is developed\nby virtue of the smoothing techniques, allowing for the Nash equilibrium of the\nlow-level game to be computed in an inexact manner. Levering the properties of\nsmoothing techniques, it is rigorously shown that the devised algorithm\nachieves a sublinear convergence rate for computing a stationary point of a\nrelated optimization problem with a smoothed objective. Moreover, the sublinear\nconvergence rate in the scenario where the exact equilibrium of the low-level\ngame is available is also discussed. Finally, numerical simulations are\nconducted to demonstrate the efficiency of theoretical findings."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-533",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14394"
    ],
    "b_title":[
      "Enhancing Portuguese Variety Identification with Cross-Domain Approaches"
    ],
    "b_abstract":[
      "Recent advances in natural language processing have raised expectations for\ngenerative models to produce coherent text across diverse language varieties.\nIn the particular case of the Portuguese language, the predominance of\nBrazilian Portuguese corpora online introduces linguistic biases in these\nmodels, limiting their applicability outside of Brazil. To address this gap and\npromote the creation of European Portuguese resources, we developed a\ncross-domain language variety identifier (LVI) to discriminate between European\nand Brazilian Portuguese. Motivated by the findings of our literature review,\nwe compiled the PtBrVarId corpus, a cross-domain LVI dataset, and study the\neffectiveness of transformer-based LVI classifiers for cross-domain scenarios.\nAlthough this research focuses on two Portuguese varieties, our contribution\ncan be extended to other varieties and languages. We open source the code,\ncorpus, and models to foster further research in this task."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10683"
    ],
    "c_title":[
      "Variations of saturation vapor pressure and evaporation rate with\n  cohesive energy of liquids"
    ],
    "c_abstract":[
      "Cohesion energy is an important property of liquid, and thus should affect\nthe saturation vapor pressure and the evaporation rate of the liquids. Here, an\nanalytical expression that relates the saturation vapor pressure of a liquid\nwith its cohesive energy was first deduced, and the relationship of the\nevaporation rate of sessile liquid droplet to the liquid cohesive energy was\nthen obtained."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-534",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11495"
    ],
    "b_title":[
      "V-STaR: Benchmarking Video-LLMs on Video Spatio-Temporal Reasoning"
    ],
    "b_abstract":[
      "Human processes video reasoning in a sequential spatio-temporal reasoning\nlogic, we first identify the relevant frames (\"when\") and then analyse the\nspatial relationships (\"where\") between key objects, and finally leverage these\nrelationships to draw inferences (\"what\"). However, can Video Large Language\nModels (Video-LLMs) also \"reason through a sequential spatio-temporal logic\" in\nvideos? Existing Video-LLM benchmarks primarily focus on assessing object\npresence, neglecting relational reasoning. Consequently, it is difficult to\nmeasure whether a model truly comprehends object interactions (actions\/events)\nin videos or merely relies on pre-trained \"memory\" of co-occurrences as biases\nin generating answers. In this work, we introduce a Video Spatio-Temporal\nReasoning (V-STaR) benchmark to address these shortcomings. The key idea is to\ndecompose video understanding into a Reverse Spatio-Temporal Reasoning (RSTR)\ntask that simultaneously evaluates what objects are present, when events occur,\nand where they are located while capturing the underlying Chain-of-thought\n(CoT) logic. To support this evaluation, we construct a dataset to elicit the\nspatial-temporal reasoning process of Video-LLMs. It contains coarse-to-fine\nCoT questions generated by a semi-automated GPT-4-powered pipeline, embedding\nexplicit reasoning chains to mimic human cognition. Experiments from 14\nVideo-LLMs on our V-STaR reveal significant gaps between current Video-LLMs and\nthe needs for robust and consistent spatio-temporal reasoning."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.10799"
    ],
    "c_title":[
      "On The Image of Automorphic Galois Representations"
    ],
    "c_abstract":[
      "In this paper, we study extra-twists for automorphic representations of\n$\\mathrm{GL}_n$ and use them to give a precise description of the image of the\nGalois representations associated with regular algebraic cuspidal automorphic\nrepresentations of $\\mathrm{GL}_3$ over totally real fields. We also formulate\na conjecture for the $\\mathrm{GL}_n$-case and show how it follows from some\nstandard conjectures in the Langlands program. Finally, assuming the existence\nof a motive associated with the representation, we study the relation of our\nconstructions with the Mumford-Tate group."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-535",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16282"
    ],
    "b_title":[
      "Brain-Adapter: Enhancing Neurological Disorder Analysis with\n  Adapter-Tuning Multimodal Large Language Models"
    ],
    "b_abstract":[
      "Understanding brain disorders is crucial for accurate clinical diagnosis and\ntreatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a\npromising approach to interpreting medical images with the support of text\ndescriptions. However, previous research has primarily focused on 2D medical\nimages, leaving richer spatial information of 3D images under-explored, and\nsingle-modality-based methods are limited by overlooking the critical clinical\ninformation contained in other modalities. To address this issue, this paper\nproposes Brain-Adapter, a novel approach that incorporates an extra bottleneck\nlayer to learn new knowledge and instill it into the original pre-trained\nknowledge. The major idea is to incorporate a lightweight bottleneck layer to\ntrain fewer parameters while capturing essential information and utilize a\nContrastive Language-Image Pre-training (CLIP) strategy to align multimodal\ndata within a unified representation space. Extensive experiments demonstrated\nthe effectiveness of our approach in integrating multimodal data to\nsignificantly improve the diagnosis accuracy without high computational costs,\nhighlighting the potential to enhance real-world diagnostic workflows."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07665"
    ],
    "c_title":[
      "Theory of Generalized Hertzian Hyperspheres"
    ],
    "c_abstract":[
      "While hard-sphere models form the foundation of theoretical condensed matter\nphysics, real systems often exhibit some degree of softness. We present a\ntheoretical and numerical study of a class of nearly hard-sphere systems,\ngeneralized Hertzian hyperspheres, where particles interact via a finite-range\nrepulsive potential that allows slight overlaps. Well-studied examples of this\nclass include particles with harmonic repulsions, Hertzian spheres, and\nHertzian disks. We derive closed-form expressions for thermodynamic properties,\ncoexistence pressures, and scaling laws governing structure and dynamics. The\ntheory predicts how quantities scale with temperature, density, spatial\ndimension, and potential softness. These theoretical predictions are tested\nthrough numerical simulations in dimensions ranging from one to eight."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-536",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16959"
    ],
    "b_title":[
      "Observe Gamma-Rays and Neutrinos Associated with Ultra-High Energy\n  Cosmic Rays"
    ],
    "b_abstract":[
      "IceCube measures a diffuse neutrino flux comparable to the Waxman-Bahcall\nbound, which suggests the possibility that the ultra-high energy cosmic rays\n(UHECRs) have a common origin with diffuse high energy neutrinos. We propose\nhigh energy gamma-ray and\/or neutrino observations toward the arrival\ndirections of UHECRs to search for the sources and test this possibility. We\ncalculate the detection probability of gamma-ray\/neutrino sources, and find\nthat the average probability per UHECR of >10 EeV is $\\sim$10% if the\nsensitivity of the gamma-ray or neutrino telescope is $\\sim$10$^{-12}$ erg\ncm$^{-2}$s$^{-1}$ and the source number density is $\\sim$10$^{-5}$ Mpc$^{-3}$.\nFuture gamma-ray and neutrino observations toward UHECRs, e.g., by LHAASO-WCDA,\nCTA, IceCube\/Gen2, are encouraged to constrain the density of UHECR sources or\neven identify the sources of UHECRs."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.02520"
    ],
    "c_title":[
      "Privacy by Design for Self-Sovereign Identity Systems: An in-depth\n  Component Analysis completed by a Design Assistance Dashboard"
    ],
    "c_abstract":[
      "The use of Self-Sovereign Identity (SSI) systems for digital identity\nmanagement is gaining traction and interest. Countries such as Bhutan have\nalready implemented an SSI infrastructure to manage the identity of their\ncitizens. The EU, thanks to the revised eIDAS regulation, is opening the door\nfor SSI vendors to develop SSI systems for the planned EU digital identity\nwallet. These developments, which fall within the sovereign domain, raise\nquestions about individual privacy.\n  The purpose of this article is to help SSI solution designers make informed\nchoices to ensure that the designed solution is privacy-friendly. The\nobservation is that the range of possible solutions is very broad, from DID and\nDID resolution methods to verifiable credential types, publicly available\ninformation (e.g. in a blockchain), type of infrastructure, etc. As a result,\nthe article proposes (1) to group the elementary building blocks of a SSI\nsystem into 5 structuring layers, (2) to analyze for each layer the privacy\nimplications of using the chosen building block, and (3) to provide a design\nassistance dashboard that gives the complete picture of the SSI, and shows the\ninterdependencies between architectural choices and technical building blocks,\nallowing designers to make informed choices and graphically achieve a SSI\nsolution that meets their need for privacy."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.ET",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-537",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14118"
    ],
    "b_title":[
      "Selecting Critical Scenarios of DER Adoption in Distribution Grids Using\n  Bayesian Optimization"
    ],
    "b_abstract":[
      "We develop a new methodology to select scenarios of DER adoption most\ncritical for distribution grids. Anticipating risks of future voltage and line\nflow violations due to additional PV adopters is central for utility investment\nplanning but continues to rely on deterministic or ad hoc scenario selection.\nWe propose a highly efficient search framework based on multi-objective\nBayesian Optimization. We treat underlying grid stress metrics as\ncomputationally expensive black-box functions, approximated via Gaussian\nProcess surrogates and design an acquisition function based on probability of\nscenarios being Pareto-critical across a collection of line- and bus-based\nviolation objectives. Our approach provides a statistical guarantee and offers\nan order of magnitude speed-up relative to a conservative exhaustive search.\nCase studies on realistic feeders with 200-400 buses demonstrate the\neffectiveness and accuracy of our approach."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16422"
    ],
    "c_title":[
      "Gravitational wave inference of star cluster properties from\n  intermediate-mass black hole mergers"
    ],
    "c_abstract":[
      "Next-generation ground-based gravitational wave observatories will observe\nmergers of intermediate-mass black holes (IMBHs) out to high redshift. Such\nIMBHs can form through runaway tidal encounters in the cores of dense stellar\nclusters. In this paper, we ask if the gravitational wave observation of a\nsingle merger event between two IMBHs, occurring in the aftermath of the\ncoalescence of the clusters in which they formed, can be used to infer the\nproperties of their host clusters, such as mass, redshift, and half-mass\nradius. We implement an astrophysically motivated analytic model for cluster\nevolution and IMBH growth, and we perform IMBH binary parameter estimation\nusing a network of three next-generation detectors. We find that inferring the\nstructural properties of clusters in this way is challenging due to model\ndegeneracy. However, the posteriors on the cluster formation redshifts have\nrelatively narrow peaks, and it may still be possible to infer the cluster\nformation history by measuring a whole population of IMBH binary merger events."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-538",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02817"
    ],
    "b_title":[
      "A Stable Measure for Conditional Periodicity of Time Series using\n  Persistent Homology"
    ],
    "b_abstract":[
      "Given a pair of time series, we study how the periodicity of one influences\nthe periodicity of the other. There are several known methods to measure the\nsimilarity between a pair of time series, such as cross-correlation, coherence,\ncross-recurrence, and dynamic time warping. But we have yet to find any\nmeasures with theoretical stability results.\n  Persistence homology has been utilized to construct a scoring function with\ntheoretical guarantees of stability that quantifies the periodicity of a single\nunivariate time series f1, denoted score(f1). Building on this concept, we\npropose a conditional periodicity score that quantifies the periodicity of one\nunivariate time series f1 given another f2, denoted score(f1|f2), and derive\ntheoretical stability results for the same. With the use of dimension reduction\nin mind, we prove a new stability result for score(f1|f2) under principal\ncomponent analysis (PCA) when we use the projections of the time series\nembeddings onto their respective first K principal components. We show that the\nchange in our score is bounded by a function of the eigenvalues corresponding\nto the remaining (unused) N-K principal components and hence is small when the\nfirst K principal components capture most of the variation in the time series\nembeddings. Finally we derive a lower bound on the minimum embedding dimension\nto use in our pipeline which guarantees that any two such embeddings give\nscores that are within a given epsilon of each other.\n  We present a procedure for computing conditional periodicity scores and\nimplement it on several pairs of synthetic signals. We experimentally compare\nour similarity measure to the most-similar statistical measure of\ncross-recurrence, and show the increased accuracy and stability of our score\nwhen predicting and measuring whether or not the periodicities of two time\nseries are similar."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.08350"
    ],
    "c_title":[
      "Search for weak components in pulsar radiation"
    ],
    "c_abstract":[
      "The search for weak components outside the main pulse (MP) in the radiation\nof pulsars at a frequency of 110 MHz observed on the LPA LPI telescope in the\nPushchino Multibeam Pulsar Search (PUMPS) has been carried out. The sample\nincluded 96 pulsars, for which the signal-to-noise ratio (S\/N) in the MP of the\naverage profile during accumulation over 10 years was more than 40. It was\nfound that PSR J1543+0929 has radiation for almost the entire period. The\nprofile is three-component. The relative amplitudes of the lateral weak\ncomponents are 0.013 and 0.026. For PSR J2234+2114, a precursor was detected\nthat is $53^o$ away from MP."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-539",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02307"
    ],
    "b_title":[
      "UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training"
    ],
    "b_abstract":[
      "Despite decades of research on data collection and model architectures,\ncurrent gaze estimation models encounter significant challenges in generalizing\nacross diverse data domains. Recent advances in self-supervised pre-training\nhave shown remarkable performances in generalization across various vision\ntasks. However, their effectiveness in gaze estimation remains unexplored. We\npropose UniGaze, for the first time, leveraging large-scale in-the-wild facial\ndatasets for gaze estimation through self-supervised pre-training. Through\nsystematic investigation, we clarify critical factors that are essential for\neffective pretraining in gaze estimation. Our experiments reveal that\nself-supervised approaches designed for semantic tasks fail when applied to\ngaze estimation, while our carefully designed pre-training pipeline\nconsistently improves cross-domain performance. Through comprehensive\nexperiments of challenging cross-dataset evaluation and novel protocols\nincluding leave-one-dataset-out and joint-dataset settings, we demonstrate that\nUniGaze significantly improves generalization across multiple data domains\nwhile minimizing reliance on costly labeled data. source code and model are\navailable at https:\/\/github.com\/ut-vision\/UniGaze."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16278"
    ],
    "c_title":[
      "Electric transport as a probe to unveil microscopic aspects of\n  oxygen-depleted YBCO"
    ],
    "c_abstract":[
      "We report on the characterization of Pt-YBa$_2$Cu$_3$O$_{7-\\delta}$\ninterfaces, focusing on how oxygen vacancies content ($\\delta$) affects\nelectrical transport mechanisms. Our study examines four\nPt-YBa$_2$Cu$_3$O$_{7-\\delta}$ samples with varying $\\delta$ (0.12 $\\leq \\delta\n\\leq$ 0.56) using voltage-current measurements across a temperature range. We\nsuccessfully model the electrical behavior using a Poole-Frenkel conduction\nframework, revealing that oxygen vacancies create potential wells that trap\ncarriers, directly influencing conduction. We observe that the energy of these\ntraps increases as $\\delta$ rises, in agreement with a peak previously detected\nin optical conductivity measurements. This result supports earlier\ninterpretations, strengthening the proposed connection between oxygen vacancies\nand the ionization energy associated with impurity bands in\nYBa$_2$Cu$_3$O$_{7-\\delta}$."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-540",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17020"
    ],
    "b_title":[
      "Benign Overfitting with Quantum Kernels"
    ],
    "b_abstract":[
      "Quantum kernels quantify similarity between data points by measuring the\ninner product between quantum states, computed through quantum circuit\nmeasurements. By embedding data into quantum systems, quantum kernel feature\nmaps, that may be classically intractable to compute, could efficiently exploit\nhigh-dimensional Hilbert spaces to capture complex patterns. However, designing\neffective quantum feature maps remains a major challenge. Many quantum kernels,\nsuch as the fidelity kernel, suffer from exponential concentration, leading to\nnear-identity kernel matrices that fail to capture meaningful data correlations\nand lead to overfitting and poor generalization. In this paper, we propose a\nnovel strategy for constructing quantum kernels that achieve good\ngeneralization performance, drawing inspiration from benign overfitting in\nclassical machine learning. Our approach introduces the concept of local-global\nquantum kernels, which combine two complementary components: a local quantum\nkernel based on measurements of small subsystems and a global quantum kernel\nderived from full-system measurements. Through numerical experiments, we\ndemonstrate that local-global quantum kernels exhibit benign overfitting,\nsupporting the effectiveness of our approach in enhancing quantum kernel\nmethods."
    ],
    "b_categories":[
      [
        "cs.LG",
        "quant-ph",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16697"
    ],
    "c_title":[
      "An Analysis of the Interdependence Between Peanut and Other Agricultural\n  Commodities in China's Futures Market"
    ],
    "c_abstract":[
      "This study analyzes historical data from five agricultural commodities in the\nChinese futures market to explore the correlation, cointegration, and Granger\ncausality between Peanut futures and related futures. Multivariate linear\nregression models are constructed for prices and logarithmic returns, while\ndynamic relationships are examined using VAR and DCC-EGARCH models. The results\nreveal a significant dynamic linkage between Peanut and Soybean Oil futures\nthrough DCC-EGARCH, whereas the VAR model suggests limited influence from other\nfutures. Additionally, the application of MLP, CNN, and LSTM neural networks\nfor price prediction highlights the critical role of time step configurations\nin forecasting accuracy. These findings provide valuable insights into the\ninterconnectedness of agricultural futures markets and the efficacy of advanced\nmodeling techniques in financial analysis."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-541",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02128"
    ],
    "b_title":[
      "Emission processes in a self-consistent field"
    ],
    "b_abstract":[
      "We present a microscopic description of cluster emission processes within the\nCluster--Hartree--Fock (CHF) self--consistent field (SCF) theory. The starting\npoint is a Woods--Saxon (WS) mean field (MF) with spin--orbit and Coulomb\nterms. Pairing is treated through standard Bardeen--Cooper--Schrieffer (BCS)\nquasiparticles. The residual two--body interaction is given by a\ndensity--dependent Wigner force having a Gaussian shape with a center of mass\n(com) correction located in a region of low nuclear density slightly beyond the\ngeometrical contact radius of a system comprised from a nucleus and a surface\ncluster. We show that such a description adequately reproduces the ground state\n(gs) shape of a spherical nucleus while the surface correction enhances the\nradial tail of single particle orbitals, thus allowing for an adequate\ndescription of the $\\alpha$-decay width for unstable systems."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08603"
    ],
    "c_title":[
      "Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based\n  Automatic Heuristic Design"
    ],
    "c_abstract":[
      "Handcrafting heuristics for solving complex optimization tasks (e.g., route\nplanning and task allocation) is a common practice but requires extensive\ndomain knowledge. Recently, Large Language Model (LLM)-based automatic\nheuristic design (AHD) methods have shown promise in generating high-quality\nheuristics without manual interventions. Existing LLM-based AHD methods employ\na population to maintain a fixed number of top-performing LLM-generated\nheuristics and introduce evolutionary computation (EC) to iteratively enhance\nthe population. However, these population-based procedures cannot fully develop\nthe potential of each heuristic and are prone to converge into local optima. To\nmore comprehensively explore the space of heuristics, this paper proposes to\nuse Monte Carlo Tree Search (MCTS) for LLM-based heuristic evolution. The\nproposed MCTS-AHD method organizes all LLM-generated heuristics in a tree\nstructure and can better develop the potential of temporarily underperforming\nheuristics. In experiments, MCTS-AHD delivers significantly higher-quality\nheuristics on various complex tasks. Our code is available."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-542",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06664"
    ],
    "b_title":[
      "Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets"
    ],
    "b_abstract":[
      "High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18468"
    ],
    "c_title":[
      "Future Collider Measurements for Cosmic Ray Induced Air Shower Modelling"
    ],
    "c_abstract":[
      "The identification of gamma-ray induced air showers with Cherenkov telescopes\nsuffers from contamination with a specific class of cosmic ray induced air\nshowers. The predictions for this background show strong discrepancies between\nthe available event generators. In this study, we identify collision events of\ncosmic rays with atmospheric nuclei in which a large fraction of the original\nbeam energy is transmitted to the electromagnetic part of the shower as the\nmain source for this background. Consequently, we define a pseudorapidity\nregion of interest for hadron collider experiments that corresponds to this\nbackground, taking into account the center-of-mass energy. This region of\ninterest is compared with the available datasets and the pseudorapidity\ncoverage of the detectors that recorded it. We find that the LHCf and RHICf\ndetectors are the only ones covering substantial parts of this region of\ninterest and suggest a measurement of the energy spectra of reconstructed\nneutral pions to be made with this data. Such results could serve as valuable\nconstraints for a future parameter tuning of the event generators to improve\nthe background estimation uncertainties for gamma-ray induced air shower\nidentification."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.IM",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-543",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03171"
    ],
    "b_title":[
      "Hybrid Near-Field and Far-Field Localization with Multiple Holographic\n  MIMO Surfaces"
    ],
    "b_abstract":[
      "Localization methods based on holographic multiple input multiple output\n(HMIMO) have gained much attention for its potential to achieve high accuracy.\nBy deploying multiple HMIMOs, we can improve the link quality and system\ncoverage. As the scale of HMIMO increases to improve beam control capability,\nthe near-field (NF) region of each HMIMO expands. However, existing multiple\nHMIMO-enabled methods mainly focus on the far-field (FF) of each HMIMO, which\nleads to low localization accuracy when applied in the NF. In this paper, a\nhybrid NF and FF localization method aided by multiple RISs, a low cost\nimplementation of HMIMO, is proposed. In such a scenario, it is difficult to\nachieve user localization and RIS optimization since the equivalent NF of all\nRISs expands, which results in high complexity, and we need to handle the\ninterference caused by multiple RISs. To tackle this challenge, we propose a\ntwo-phase RIS-enabled localization method that first estimate the relative\nlocations of the user to each RIS and fuse the results to obtain the global\nestimation. In this way, the algorithm complexity is reduced. We formulate the\nRIS optimization problem to keep the RIS sidelobe as low as possible to\nminimize the interference. The effectiveness of the proposed method is verified\nthrough simulations."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09071"
    ],
    "c_title":[
      "The LHC as a TeV Muon Beam Dump: Muonphilic Scalars at FASER"
    ],
    "c_abstract":[
      "The FASER experiment was designed to study long-lived dark sector particles\nand neutrinos traveling in the forward direction at the LHC. Neutrinos are\npredominantly produced from meson decays, which also result in an intense\nenergetic flux of muons in the forward direction regularly observed by FASER.\nSo far, these muons are treated only as backgrounds to neutrino and new physics\nstudies, and extensive effort is required to suppress them. In this study, we\nconsider the opposite scenario and use muons produced in the forward direction\nto produce new muonphilic scalars, which can then be searched for at the FASER\ndetector. To minimize the backgrounds for this search, we make use of an\nupgraded preshower component, which is expected to be installed at FASER before\nthe end of Run 3, and is capable of spatially resolving two energetic photons.\nWe find that FASER, and its upgrade, FASER2 can probe currently unconstrained\nregions of parameter space, including regions that can potentially explain the\n$(g-2)_{\\mu}$ anomaly. This highlights the physics opportunities that the\nintense TeV muon beam at the LHC can bring."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-544",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05859"
    ],
    "b_title":[
      "Large Model Empowered Streaming Speech Semantic Communications"
    ],
    "b_abstract":[
      "In this paper, we introduce a large model-empowered streaming semantic\ncommunication system for speech transmission across various languages, named\nLSSC-ST. Specifically, we devise an edge-device collaborative semantic\ncommunication architecture by offloading the intricate semantic extraction and\nchannel coding modules to edge servers, thereby reducing the computational\nburden on local devices. To support multilingual speech transmission,\npre-trained large speech models are utilized to learn unified semantic features\nfrom speech in different languages, breaking the constraint of a single input\nlanguage and enhancing the practicality of the LSSC-ST. Moreover, the input\nspeech is sequentially streamed into the developed system as short speech\nsegments, which enables low transmission latency without degrading the quality\nof the produced speech. A novel dynamic speech segmentation algorithm is\nproposed to further reduce the transmission latency by adaptively adjusting the\nduration of speech segments. According to simulation results, the LSSC-ST\nprovides more accurate speech transmission and achieves a streaming manner with\nlower latency compared to the existing non-streaming semantic communication\nsystems."
    ],
    "b_categories":[
      [
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13148"
    ],
    "c_title":[
      "Theoretical Frameworks for Integrating Sustainability Factors into\n  Institutional Investment Decision-Making"
    ],
    "c_abstract":[
      "This paper explores key theoretical frameworks instrumental in understanding\nthe relationship between sustainability and institutional investment decisions.\nThe study identifies and analyzes various theories, including Behavioral\nFinance Theory, Modern Portfolio Theory, Risk Management Theory, and others, to\nexplain how sustainability considerations increasingly influence investment\nchoices. By examining these frameworks, the paper highlights how investors\nintegrate Environmental, Social, and Governance (ESG) factors to optimize\nfinancial outcomes and align with broader societal goals."
    ],
    "c_categories":[
      [
        "q-fin.GN",
        "q-fin.PM",
        "q-fin.RM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-545",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04329"
    ],
    "b_title":[
      "An Efficient Adaptive Compression Method for Human Perception and\n  Machine Vision Tasks"
    ],
    "b_abstract":[
      "While most existing neural image compression (NIC) and neural video\ncompression (NVC) methodologies have achieved remarkable success, their\noptimization is primarily focused on human visual perception. However, with the\nrapid development of artificial intelligence, many images and videos will be\nused for various machine vision tasks. Consequently, such existing compression\nmethodologies cannot achieve competitive performance in machine vision. In this\nwork, we introduce an efficient adaptive compression (EAC) method tailored for\nboth human perception and multiple machine vision tasks. Our method involves\ntwo key modules: 1), an adaptive compression mechanism, that adaptively selects\nseveral subsets from latent features to balance the optimizations for multiple\nmachine vision tasks (e.g., segmentation, and detection) and human vision. 2),\na task-specific adapter, that uses the parameter-efficient delta-tuning\nstrategy to stimulate the comprehensive downstream analytical networks for\nspecific machine vision tasks. By using the above two modules, we can optimize\nthe bit-rate costs and improve machine vision performance. In general, our\nproposed EAC can seamlessly integrate with existing NIC (i.e., Ball\\'e2018, and\nCheng2020) and NVC (i.e., DVC, and FVC) methods. Extensive evaluation on\nvarious benchmark datasets (i.e., VOC2007, ILSVRC2012, VOC2012, COCO, UCF101,\nand DAVIS) shows that our method enhances performance for multiple machine\nvision tasks while maintaining the quality of human vision."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.09862"
    ],
    "c_title":[
      "Demonstration of a new CLLBC-based gamma- and neutron-sensitive\n  free-moving omnidirectional imaging detector"
    ],
    "c_abstract":[
      "We have developed a CLLBC-based gamma- and neutron-sensitive multi-channel\nomnidirectional imaging detector, suitable for handheld or vehicle-borne\noperation and capable of quantitative radiation mapping in 3D. The system\ncomprises 62 CLLBC modules in an active-masked configuration, and is coupled to\na Localization and Mapping Platform (LAMP) suite of contextual sensors that\nprovides a 3D map of the environment. The contextual and radiation data is\ncombined using Scene Data Fusion (SDF) methods to better inform the\nreconstruction of the source radiation distribution from variations in the\nmeasured counts as the detector moves throughout the 3D environment. Here, we\nfirst present benchtop-scale characterization studies for both the neutron and\ngamma ray channels. In tandem, we present Geant4 simulations of both the\nsingle-crystal and full-system detection efficiencies over the omnidirectional\nfield of view, and compare against validation measurements. We then demonstrate\nthe imager's capabilities in a variety of different scenarios, ranging from\nfree-moving handheld simultaneous measurements of Cs-137 and Cf-252 to more\nchallenging motion-constrained or static measurement scenarios. In several of\nthese scenarios we also demonstrate how the full omnidirectional multi-crystal\nresponses markedly improve the reconstruction quality. The imager is therefore\na promising system for conducting simultaneous gamma and neutron radiation\nmeasurements in applications such as homeland security, contamination mapping,\nand nuclear decommissioning."
    ],
    "c_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-546",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12166"
    ],
    "b_title":[
      "Beyond Window-Based Detection: A Graph-Centric Framework for Discrete\n  Log Anomaly Detection"
    ],
    "b_abstract":[
      "Detecting anomalies in discrete event logs is critical for ensuring system\nreliability, security, and efficiency. Traditional window-based methods for log\nanomaly detection often suffer from context bias and fuzzy localization, which\nhinder their ability to precisely and efficiently identify anomalies. To\naddress these challenges, we propose a graph-centric framework, TempoLog, which\nleverages multi-scale temporal graph networks for discrete log anomaly\ndetection. Unlike conventional methods, TempoLog constructs continuous-time\ndynamic graphs directly from event logs, eliminating the need for fixed-size\nwindow grouping. By representing log templates as nodes and their temporal\nrelationships as edges, the framework dynamically captures both local and\nglobal dependencies across multiple temporal scales. Additionally, a\nsemantic-aware model enhances detection by incorporating rich contextual\ninformation. Extensive experiments on public datasets demonstrate that our\nmethod achieves state-of-the-art performance in event-level anomaly detection,\nsignificantly outperforming existing approaches in both accuracy and\nefficiency."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17545"
    ],
    "c_title":[
      "Hyperbolic Monopoles, (Semi-)Holomorphic Chern-Simons Theories, and\n  Generalized Chiral Potts Models"
    ],
    "c_abstract":[
      "We study the relation between spectral data of magnetic monopoles in\nhyperbolic space and the curve of the spectral parameter of generalized chiral\nPotts models (gCPM) through the lens of (semi-)holomorphic field theories. We\nrealize the identification of the data on the two sides, which we call the\nhyperbolic monopole\/gCPM correspondence. For the group $\\text{SU}(2)$, this\ncorrespondence had been observed by Atiyah and Murray in the 80s. Here, we\nrevisit and generalize this correspondence and establish its origin. By\ninvoking the work of Murray and Singer on hyperbolic monopoles, we first\ngeneralize the observation of Atiyah and Murray to the group $\\text{SU}(n)$. We\nthen propose a technology to engineer gCPM within the 4d Chern-Simons (CS)\ntheory, which explains various features of the model, including the lack of\nrapidity-difference property of its R-matrix and its peculiarity of having a\ngenus$\\,\\ge 2$ curve of the spectral parameter. Finally, we investigate the\norigin of the correspondence. We first clarify how the two sides of the\ncorrespondence can be realized from the 6d holomorphic CS theory on\n$\\mathbb{P}S(M)$, the projective spinor bundle of the Minkowski space\n$M=\\mathbb{R}^{1,3}$, for hyperbolic $\\text{SU}(n)$-monopoles, and the\nEuclidean space $M=\\mathbb{R}^4$, for the gCPM. We then establish that\n$\\mathbb{P}S(M)$ can be holomorphically embedded into\n$\\mathbb{P}S(\\mathbb{C}^{1,3})$, the projective spinor bundle of\n$\\mathbb{C}^{1,3}$, of complex dimension five with a fixed complex structure.\nWe finally explain how the 6d CS theory on $\\mathbb{P}S(M)$ can be realized as\nthe dimensional reduction of the 10d holomorphic CS theory on\n$\\mathbb{P}S(\\mathbb{C}^{1,3})$. As the latter theory is only sensitive to the\ncomplex structure of $\\mathbb{P}S(\\mathbb{C}^{1,3})$, which has been fixed, we\nrealize the correspondence as two incarnations of the same physics in ten\ndimensions."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "hep-th",
        "math-ph",
        "math.MP",
        "math.QA",
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-547",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14385"
    ],
    "b_title":[
      "Study $\\Xi_c^+ \\to \\Lambda {\\bar{K}}^0 \\pi^+$ and search for the\n  low-lying baryons $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$"
    ],
    "b_abstract":[
      "Since searches for the low-lying excited baryons $\\Xi(1\/2^-)$ and\n$\\Sigma(1\/2^-)$ are crucial to deepening our understanding of the light baryon\nspectrum, we have investigated the Cabibbo-favored process $\\Xi_c^+ \\to \\Lambda\n{\\bar{K}}^0 \\pi^+$ by taking into account the $S$-wave pseudoscalar meson-octet\nbaryon interactions within the chiral unitary approach, which could dynamically\ngenerate the resonances $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$. The contributions\nfrom the excited kaons are double Cabibbo-suppressed, and the contribution from\nthe $\\Sigma(1385)$ is also suppressed due to Korner-Pati-Woo theory, thus those\nstates are expected to play negligible contributions in this process. We have\npredicted the $\\bar{K}^0 \\Lambda$ and $\\pi^+\\Lambda$ invariant mass\ndistributions, which have the clear signals of the $\\Xi(1\/2^-)$ and\n$\\Sigma(1\/2^-)$. Thus, the $\\Xi_c^+ \\to \\Lambda {\\bar{K}}^0 \\pi^+$ is an ideal\nprocess to search for the low-lying baryons $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$,\nand we make a call for a precise measurements of this process in experiments,\nsuch as Belle II, LHCb, and the proposed Super Tau-Charm Facility (STCF)."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.06237"
    ],
    "c_title":[
      "Forecasting Anonymized Electricity Load Profiles"
    ],
    "c_abstract":[
      "In the evolving landscape of data privacy, the anonymization of electric load\nprofiles has become a critical issue, especially with the enforcement of the\nGeneral Data Protection Regulation (GDPR) in Europe. These electric load\nprofiles, which are essential datasets in the energy industry, are classified\nas personal behavioral data, necessitating stringent protective measures. This\narticle explores the implications of this classification, the importance of\ndata anonymization, and the potential of forecasting using microaggregated\ndata. The findings underscore that effective anonymization techniques, such as\nmicroaggregation, do not compromise the performance of forecasting models under\ncertain conditions (i.e., forecasting aggregated). In such an aggregated level,\nmicroaggregated data maintains high levels of utility, with minimal impact on\nforecasting accuracy. The implications for the energy sector are profound,\nsuggesting that privacy-preserving data practices can be integrated into smart\nmetering technology applications without hindering their effectiveness."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-548",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08686"
    ],
    "b_title":[
      "EEG Artifact Detection and Correction with Deep Autoencoders"
    ],
    "b_abstract":[
      "EEG signals convey important information about brain activity both in healthy\nand pathological conditions. However, they are inherently noisy, which poses\nsignificant challenges for accurate analysis and interpretation. Traditional\nEEG artifact removal methods, while effective, often require extensive expert\nintervention. This study presents LSTEEG, a novel LSTM-based autoencoder\ndesigned for the detection and correction of artifacts in EEG signals.\nLeveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear\ndependencies in sequential EEG data. LSTEEG demonstrates superior performance\nin both artifact detection and correction tasks compared to other\nstate-of-the-art convolutional autoencoders. Our methodology enhances the\ninterpretability and utility of the autoencoder's latent space, enabling\ndata-driven automated artefact removal in EEG its application in downstream\ntasks. This research advances the field of efficient and accurate multi-channel\nEEG preprocessing, and promotes the implementation and usage of automated EEG\nanalysis pipelines for brain health applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.02884"
    ],
    "c_title":[
      "Physically Consistent Global Atmospheric Data Assimilation with Machine\n  Learning in a Latent Space"
    ],
    "c_abstract":[
      "Data assimilation (DA) provides more accurate, physically consistent analysis\nfields and is used for estimating initial conditions in numerical weather\nforecasting. Traditional DA methods derive statistically optimal analyses in\nmodel space based on Bayesian theory. However, their effectiveness is limited\nby the difficulty of accurately estimating the background error covariances\nmatrix B, which represents the intricate interdependencies among atmospheric\nvariables, as well as the standard linearity assumptions required during the\nassimilation step. To address these limitations, we propose Latent Data\nAssimilation (LDA) for a multi-variable global atmosphere, performing\nnon-linear Machine-Learning based Bayesian DA on an atmospheric latent\nrepresentation learned by an autoencoder. The feasibility of LDA is supported\nby the near-linear relationship between increments in latent space (within the\ntypical magnitude range for DA) and their corresponding impacts in model space,\nensuring that the optimal analysis obtained in latent space approximates the\noptimal analysis in model space. Due to the relationships among the atmospheric\nvariables encoded in the latent space, LDA can physically propagate observation\ninformation across unobserved regions and atmospheric variables, even with a\nfully diagonal B in latent space. We perform idealized experiments with\nsimulated observations and demonstrate the superiority of LDA over traditional\nDA methods in model space, while the experiments assimilating real observations\nhighlight its potential application for operational reanalysis and weather\nforecasting systems."
    ],
    "c_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-549",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00395"
    ],
    "b_title":[
      "Pressure Tuning of Layer-hybridized Excitons in Trilayer WSe2"
    ],
    "b_abstract":[
      "We demonstrate dynamic pressure tuning (0-6.6 GPa) of layer-hybridized\nexcitons in AB-stacked trilayer WSe$_2$ via diamond-anvil-cell-integrated\nreflectance spectroscopy. Pressure-controlled interlayer coupling manifests in\nenhanced energy-level anti-crossings and oscillator strength redistribution,\nwith Stark shift analysis revealing a characteristic dipole moment reduction of\n11%. Notably, the hybridization strength between the intra- and interlayer\nexcitons triples from $\\sim$10 meV to above $\\sim$30 meV, exhibiting a\nnear-linear scaling of 3.5$\\pm$0.2 meV\/GPa. Spectral density simulations\nresolve four distinct components, i.e., intralayer ground\/excited and\ninterlayer ground\/excited excitons, with their relative weights transitioning\nfrom one component dominant to strongly hybridized at higher pressures. Our\nfindings highlight the potential for controlling excitonic properties and\nengineering novel optoelectronic devices through interlayer compression."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.13202"
    ],
    "c_title":[
      "Subtree Distances, Tight Spans and Diversities"
    ],
    "c_abstract":[
      "Metric embeddings are central to metric theory and its applications. Here we\nconsider embeddings of a different sort: maps from a set to subsets of a metric\nspace so that distances between points are approximated by minimal distances\nbetween subsets. Our main result is a characterization of when a set of\ndistances $d(x,y)$ between elements in a set $X$ have a subtree representation,\na real tree $T$ and a collection $\\{S_x\\}_{x \\in X}$ of subtrees of~$T$ such\nthat $d(x,y)$ equals the length of the shortest path in~$T$ from a point in\n$S_x$ to a point in $S_y$ for all $x,y \\in X$. The characterization was first\nestablished for {\\em finite} $X$ by Hirai (2006) using a tight span\nconstruction defined for distance spaces, metric spaces without the triangle\ninequality. To extend Hirai's result beyond finite $X$ we establish fundamental\nresults of tight span theory for general distance spaces, including the\nsurprising observation that the tight span of a distance space is hyperconvex.\nWe apply the results to obtain the first characterization of when a diversity\n-- a generalization of a metric space which assigns values to all finite\nsubsets of $X$, not just to pairs -- has a tight span which is tree-like."
    ],
    "c_categories":[
      [
        "cs.DM",
        "math.MG",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-550",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05583"
    ],
    "b_title":[
      "Efficient Sampling Allocation Strategies for General Graph-Filter-Based\n  Signal Recovery"
    ],
    "b_abstract":[
      "Sensor placement plays a crucial role in graph signal recovery in\nunderdetermined systems. In this paper, we present the graph-filtered\nregularized maximum likelihood (GFR-ML) estimator of graph signals, which\nintegrates general graph filtering with regularization to enhance signal\nrecovery performance under a limited number of sensors. Then, we investigate\ntask-based sampling allocation aimed at minimizing the mean squared error (MSE)\nof the GFR-ML estimator by wisely choosing sensor placement. Since this MSE\ndepends on the unknown graph signals to be estimated, we propose four cost\nfunctions for the optimization of the sampling allocation: the biased\nCram$\\acute{\\text{e}}$r-Rao bound (bCRB), the worst-case MSE (WC-MSE), the\nBayesian MSE (BMSE), and the worst-case BMSE (WC-BMSE), where the last two\nassume a Gaussian prior. We investigate the properties of these cost functions\nand develop two algorithms for their practical implementation: 1) the\nstraightforward greedy algorithm; and 2) the alternating projection gradient\ndescent (PGD) algorithm that reduces the computational complexity. Simulation\nresults on synthetic and real-world datasets of the IEEE 118-bus power system\nand the Minnesota road network demonstrate that the proposed sampling\nallocation methods reduce the MSE by up to $50\\%$ compared to the common\nsampling methods A-design, E-design, and LR-design in the tested scenarios.\nThus, the proposed methods improve the estimation performance and reduce the\nrequired number of measurements in graph signal processing (GSP)-based signal\nrecovery in the case of underdetermined systems."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07735"
    ],
    "c_title":[
      "Excursion Sets with a \"Perfect\" Collapse Model"
    ],
    "c_abstract":[
      "The $\\Lambda$CDM model predicts structure formation across a vast mass range,\nfrom massive clusters ($\\sim10^{15}\\,\\text{M}_\\odot$) to Earth-mass\nmicro-haloes ($\\sim 10^{-6} \\, \\text{M}_\\odot$), resolving which far exceeds\nthe capabilities of current simulations. Excursion set models are the most\nefficient theoretical tool to disentangle this hierarchy in mass. We test the\nexcursion set paradigm by combining smoothed initial density fields with a\n\"perfect\" collapse model -- $N$-body simulations. We find that a core excursion\nset assumption -- small-scale perturbations do not impact larger-scale collapse\n-- is approximately fulfilled but exhibits small quantitative violations\ndependent on the smoothing filter. For a sharp $k-$space cut-off $\\sim 20\\%$ of\nmass elements revert collapse as the smoothing scale decreases, while only\n$3.5\\%$ do for a Gaussian and $5\\%$ for a top-hat. Further, we test the simple\ndeterministic mass-mapping $M \\propto R^3$ (first-crossing scale to halo mass)\nrelation. We find that particles that are first accreted into haloes at the\nsame smoothing scale may end up in haloes of significantly different masses,\nwith a scatter of 0.4-0.8 dex. We also demonstrate that the proportionally\nconstant of this relation should be considered as a degree of freedom. Finally,\nwe measure the mass fraction in different structure morphologies (voids,\npancakes, filaments and haloes) as a function of filter scale. Typical\nparticles appear to be part of a large-scale pancake, a smaller-scale filament\nand a notably smaller halo. We conclude that validating predictions of\nexcursion set models on a particle-by-particle basis against simulations may\nenhance their realism."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-551",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13388"
    ],
    "b_title":[
      "A mathematical model for a universal digital quantum computer with an\n  application to the Grover-Rudolph algorithm"
    ],
    "b_abstract":[
      "In this work, we develop a novel mathematical framework for universal digital\nquantum computation using algebraic probability theory. We rigorously define\nquantum circuits as finite sequences of elementary quantum gates and establish\ntheir role in implementing unitary transformations. A key result demonstrates\nthat every unitary matrix in \\(\\mathrm{U}(N)\\) can be expressed as a product of\nelementary quantum gates, leading to the concept of a universal dictionary for\nquantum computation. We apply this framework to the construction of quantum\ncircuits that encode probability distributions, focusing on the Grover-Rudolph\nalgorithm. By leveraging controlled quantum gates and rotation matrices, we\ndesign a quantum circuit that approximates a given probability density\nfunction. Numerical simulations, conducted using Qiskit, confirm the\ntheoretical predictions and validate the effectiveness of our approach. These\nresults provide a rigorous foundation for quantum circuit synthesis within an\nalgebraic probability framework and offer new insights into the encoding of\nprobability distributions in quantum algorithms. Potential applications include\nquantum machine learning, circuit optimization, and experimental\nimplementations on real quantum hardware."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01456"
    ],
    "c_title":[
      "Process Reinforcement through Implicit Rewards"
    ],
    "c_abstract":[
      "Dense process rewards have proven a more effective alternative to the sparse\noutcome-level rewards in the inference-time scaling of large language models\n(LLMs), particularly in tasks requiring complex multi-step reasoning. While\ndense rewards also offer an appealing choice for the reinforcement learning\n(RL) of LLMs since their fine-grained rewards have the potential to address\nsome inherent issues of outcome rewards, such as training efficiency and credit\nassignment, this potential remains largely unrealized. This can be primarily\nattributed to the challenges of training process reward models (PRMs) online,\nwhere collecting high-quality process labels is prohibitively expensive, making\nthem particularly vulnerable to reward hacking. To address these challenges, we\npropose PRIME (Process Reinforcement through IMplicit rEwards), which enables\nonline PRM updates using only policy rollouts and outcome labels through\nimplict process rewards. PRIME combines well with various advantage functions\nand forgoes the dedicated reward model training phrase that existing approaches\nrequire, substantially reducing the development overhead. We demonstrate\nPRIME's effectiveness on competitional math and coding. Starting from\nQwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several\nkey reasoning benchmarks over the SFT model. Notably, our resulting model,\nEurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning\nbenchmarks with 10% of its training data."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-552",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09455"
    ],
    "b_title":[
      "Recoil nuclear size corrections in hydrogenic systems"
    ],
    "b_abstract":[
      "Formulas for the combined nuclear-recoil and finite-nuclear-size effects of\norder $(Z\\,\\alpha)^5$ and $(Z\\,\\alpha)^6$ are derived without any expansion in\nthe nuclear charge radius $r_C$, making them applicable to both electronic and\nmuonic atoms. The obtained results are particularly relevant for high-precision\ndeterminations of root-mean-square charge radii from muonic atom spectroscopy.\nWe demonstrate that calculations of the atomic isotope shift based on the\nwidely used Breit approximation give rise to an unphysical nuclear-size\ncontribution that is linear in the nuclear charge radius $r_C$ at order\n$(Z\\,\\alpha)^5$. This spurious term vanishes in a full QED treatment, leaving\nthe correct contribution quadratic in $r_C$. For electronic atoms, this\nquadratic term is significantly smaller than the spurious linear contribution."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.20478"
    ],
    "c_title":[
      "Explainable AI for Clinical Outcome Prediction: A Survey of Clinician\n  Perceptions and Preferences"
    ],
    "c_abstract":[
      "Explainable AI (XAI) techniques are necessary to help clinicians make sense\nof AI predictions and integrate predictions into their decision-making\nworkflow. In this work, we conduct a survey study to understand clinician\npreference among different XAI techniques when they are used to interpret model\npredictions over text-based EHR data. We implement four XAI techniques (LIME,\nAttention-based span highlights, exemplar patient retrieval, and free-text\nrationales generated by LLMs) on an outcome prediction model that uses ICU\nadmission notes to predict a patient's likelihood of experiencing in-hospital\nmortality. Using these XAI implementations, we design and conduct a survey\nstudy of 32 practicing clinicians, collecting their feedback and preferences on\nthe four techniques. We synthesize our findings into a set of recommendations\ndescribing when each of the XAI techniques may be more appropriate, their\npotential limitations, as well as recommendations for improvement."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-553",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04060"
    ],
    "b_title":[
      "SFADNet: Spatio-temporal Fused Graph based on Attention Decoupling\n  Network for Traffic Prediction"
    ],
    "b_abstract":[
      "In recent years, traffic flow prediction has played a crucial role in the\nmanagement of intelligent transportation systems. However, traditional\nprediction methods are often limited by static spatial modeling, making it\ndifficult to accurately capture the dynamic and complex relationships between\ntime and space, thereby affecting prediction accuracy. This paper proposes an\ninnovative traffic flow prediction network, SFADNet, which categorizes traffic\nflow into multiple traffic patterns based on temporal and spatial feature\nmatrices. For each pattern, we construct an independent adaptive\nspatio-temporal fusion graph based on a cross-attention mechanism, employing\nresidual graph convolution modules and time series modules to better capture\ndynamic spatio-temporal relationships under different fine-grained traffic\npatterns. Extensive experimental results demonstrate that SFADNet outperforms\ncurrent state-of-the-art baselines across four large-scale datasets."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19073"
    ],
    "c_title":[
      "Non-divergence evolution operators modeled on H\\\"ormander's vector\n  fields with Dini continuous coefficients"
    ],
    "c_abstract":[
      "In this paper we construct a fundamental solution for operators of the form H\n= a_ij(x,t) X_i X_j - d\/dt (having adopted Einstein's convention on repeated\nindexes) and we show that the latter satisfies suitable Gaussian estimates.\nHere the X_i are H\\\"ormander's vector fields generating a Carnot group and A =\n(a_ij) is a symmetric and uniformly positive-definite matrix with bounded\ndouble Dini continuous entries. As a consequence of this procedure we also\nprove an existence result for the related Cauchy problem, under a Dini-type\ncondition on the source."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-554",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13214"
    ],
    "b_title":[
      "A General Adaptive Dual-level Weighting Mechanism for Remote Sensing\n  Pansharpening"
    ],
    "b_abstract":[
      "Currently, deep learning-based methods for remote sensing pansharpening have\nadvanced rapidly. However, many existing methods struggle to fully leverage\nfeature heterogeneity and redundancy, thereby limiting their effectiveness. We\nuse the covariance matrix to model the feature heterogeneity and redundancy and\npropose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW\ncaptures these correlations through the covariance matrix, which is then\nprocessed by a nonlinear function to generate weights for adjustment. Building\nupon CACW, we introduce a general adaptive dual-level weighting mechanism\n(ADWM) to address these challenges from two key perspectives, enhancing a wide\nrange of existing deep-learning methods. First, Intra-Feature Weighting (IFW)\nevaluates correlations among channels within each feature to reduce redundancy\nand enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts\ncontributions across layers based on inter-layer correlations, refining the\nfinal output. Extensive experiments demonstrate the superior performance of\nADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we\nvalidate the effectiveness of our approach through generality experiments,\nredundancy visualization, comparison experiments, key variables and complexity\nanalysis, and ablation studies. Our code is available at\nhttps:\/\/github.com\/Jie-1203\/ADWM."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05624"
    ],
    "c_title":[
      "The route of shear to Ising superconductivity in bilayer graphene"
    ],
    "c_abstract":[
      "We show that the sheared graphene bilayers can be tuned to have flat\nlow-energy bands for sufficiently large size of their moir\\'e supercell. In\nthis regime, the interacting system becomes prone to develop broken-symmetry\nphases, with valley symmetry breaking as the dominant pattern. The strong\nsignal of symmetry breaking favors the onset of a pairing instability in which\nthe electrons with opposite spin projection in the Cooper pairs live in\ndifferent valleys. The Fermi lines become distorted due to the repulsive\nCoulomb interaction, which makes the screening highly anisotropic, leading\neasily to attraction in some of the interaction channels. We also show that the\nsheared graphene bilayers offer the possibility to realize the combined\nbreakdown of parity and valley symmetry, making them very suitable to study the\ninterplay between correlations and topology in a two-dimensional electron\nsystem."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-555",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00069"
    ],
    "b_title":[
      "Societal Alignment Frameworks Can Improve LLM Alignment"
    ],
    "b_abstract":[
      "Recent progress in large language models (LLMs) has focused on producing\nresponses that meet human expectations and align with shared values - a process\ncoined alignment. However, aligning LLMs remains challenging due to the\ninherent disconnect between the complexity of human values and the narrow\nnature of the technological approaches designed to address them. Current\nalignment methods often lead to misspecified objectives, reflecting the broader\nissue of incomplete contracts, the impracticality of specifying a contract\nbetween a model developer, and the model that accounts for every scenario in\nLLM alignment. In this paper, we argue that improving LLM alignment requires\nincorporating insights from societal alignment frameworks, including social,\neconomic, and contractual alignment, and discuss potential solutions drawn from\nthese domains. Given the role of uncertainty within societal alignment\nframeworks, we then investigate how it manifests in LLM alignment. We end our\ndiscussion by offering an alternative view on LLM alignment, framing the\nunderspecified nature of its objectives as an opportunity rather than perfect\ntheir specification. Beyond technical improvements in LLM alignment, we discuss\nthe need for participatory alignment interface designs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08932"
    ],
    "c_title":[
      "Simulation of STIRAP from the 1S to the 2S states of the\n  Hydrogen\/Antihydrogen atoms"
    ],
    "c_abstract":[
      "The 1S-2S transition of hydrogen and antihydrogen atoms services a crucial\nrole in comparing matter to antimatter and testing charge conjugation, parity,\nand time reversal similarities. Achieving high transition rates with low\nionization rates when preparing atoms in the 2S level is essential for such\ntests. We propose and examine the efficiency of applying the STIRAP (Stimulated\nRaman Adiabatic Passage) process in achieving such transition. We simulated a\ncircularly polarized Lyman alpha, Ly-$\\alpha$, pulse to couple the 1S state to\nthe 2P state and a microwave pulse to couple the 2P state and the 2S state. We\ncalculate the efficiency of the STIRAP process for transferring the population\nbetween the stretched states $(1S_d, 2S_d)$ as a function of experimental\nparameters such as Rabi frequencies and the pulse durations. We find that a\nLy-$\\alpha$ pulse with an energy of a few nanojoules could produce nearly\nperfect transfer at zero detunings. We extended the analysis to a thermal\nensemble of atoms where the Doppler detuning plays a crucial role in the\nvelocity distribution of the produced hydrogen atoms in the 2S level. We found\nthat the width of such velocity distribution is controlled by the Rabi\nfrequency. We show that the peak velocity of the hydrogen atoms in the 2S level\nafter STIRAP can be controlled by the Ly-$\\alpha$ pulse detuning. The STIRAP\nefficiency in transferring population increases at low temperature\n(T$\\sim$1~mK). Finally, we show that a background magnetic field improves the\ntransfer rates between the other trappable states $(1S_c, 2S_c)$."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-556",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08654"
    ],
    "b_title":[
      "Statistical tests based on Renyi entropy estimation"
    ],
    "b_abstract":[
      "Entropy and its various generalizations are important in many fields,\nincluding mathematical statistics, communication theory, physics and computer\nscience, for characterizing the amount of information associated with a\nprobability distribution. In this paper we propose goodness-of-fit statistics\nfor the multivariate Student and multivariate Pearson type II distributions,\nbased on the maximum entropy principle and a class of estimators for Renyi\nentropy based on nearest neighbour distances. We prove the L2-consistency of\nthese statistics using results on the subadditivity of Euclidean functionals on\nnearest neighbour graphs, and investigate their rate of convergence and\nasymptotic distribution using Monte Carlo methods."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.01133"
    ],
    "c_title":[
      "A thermal-noise-resilient microwave quantum network traversing 4 K"
    ],
    "c_abstract":[
      "Quantum communication at microwave frequencies has been fundamentally\nconstrained by the susceptibility of microwave photons to thermal noise,\nhindering their application in scalable quantum networks. Here we demonstrate a\nthermal-noise-resilient microwave quantum network that establishes coherent\ncoupling between two superconducting qubits through a 4 K thermalized\nniobium-titanium transmission line. By overcoupling the communication channel\nto a cold load at 10 mK, we suppress the effective thermal occupancy of the\nchannel to 0.06 photons through radiative cooling -- a two-order-of-magnitude\nreduction below ambient thermal noise. We then decouple the cold load and\nrapidly transfer microwave quantum states through the channel while it\nrethermalizes, achieving a 58.5% state transfer fidelity and a 52.3% Bell\nentanglement fidelity, both exceeding the classical communication threshold.\nOur architecture overcomes the temperature-compatibility barrier for microwave\nquantum systems, providing a scalable framework for distributed quantum\ncomputing and enabling hybrid quantum networks with higher-temperature\nsemiconductor or photonic platforms."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-557",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06011"
    ],
    "b_title":[
      "Uncertainty Quantification and Causal Considerations for Off-Policy\n  Decision Making"
    ],
    "b_abstract":[
      "Off-policy evaluation (OPE) is a critical challenge in robust decision-making\nthat seeks to assess the performance of a new policy using data collected under\na different policy. However, the existing OPE methodologies suffer from several\nlimitations arising from statistical uncertainty as well as causal\nconsiderations. In this thesis, we address these limitations by presenting\nthree different works. Firstly, we consider the problem of high variance in the\nimportance-sampling-based OPE estimators. We introduce the Marginal Ratio (MR)\nestimator, a novel OPE method that reduces variance by focusing on the marginal\ndistribution of outcomes rather than direct policy shifts, improving robustness\nin contextual bandits. Next, we propose Conformal Off-Policy Prediction (COPP),\na principled approach for uncertainty quantification in OPE that provides\nfinite-sample predictive intervals, ensuring robust decision-making in\nrisk-sensitive applications. Finally, we address causal unidentifiability in\noff-policy decision-making by developing novel bounds for sequential decision\nsettings, which remain valid under arbitrary unmeasured confounding. We apply\nthese bounds to assess the reliability of digital twin models, introducing a\nfalsification framework to identify scenarios where model predictions diverge\nfrom real-world behaviour. Our contributions provide new insights into robust\ndecision-making under uncertainty and establish principled methods for\nevaluating policies in both static and dynamic settings."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13775"
    ],
    "c_title":[
      "Quantum dots for quantum repeaters"
    ],
    "c_abstract":[
      "This article reviews the current state of the field of quantum repeaters\n(QRs) based on Quantum Dots (QDs). First, we provide a short introduction to\nQRs. Then, we give an overview of the state of the art of non-classical photon\nsources based on III-V QDs. We discuss their performance and benchmark them\naccording to critical parameters such as their low multiphoton emission\nprobability and indistinguishability. Then, we discuss quantum repeaters\nfocusing firstly on all-photonic QRs. Secondly, we discuss memory based QRs\nwith QDs as photon sources and alkali vapors as memories. We review storage\nprotocols and their compatibility with NIR and telecom QDs. Finally, we review\nenabling technologies that facilitate deploying these systems in commercial\nfiber networks."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-558",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09671"
    ],
    "b_title":[
      "Undulatory underwater swimming: Linking vortex dynamics, thrust, and\n  wake structure with a biorobotic fish"
    ],
    "b_abstract":[
      "Flapping-based propulsive systems rely on fluid-structure interactions to\nproduce thrust. At intermediate and high Reynolds numbers, vortex formation and\norganization in the wake of such systems are crucial for the generation of a\npropulsive force. In this work, we experimentally investigate the wake produced\nby a tethered robotic fish immersed in a water tunnel. By systematically\nvarying the amplitude and frequency of the fish tail as well as the free-stream\nspeed, we are able to observe and characterize different vortex streets as a\nfunction of the Strouhal number. The produced wakes are three-dimensional and\nexhibit a classical V-shape, mainly with two oblique trains of vortex rings\nconvecting outward. Using two-dimensional Particle Image Velocimetry (PIV) in\nthe mid-span plane behind the fish and through extensive data processing of the\nvelocity and vorticity fields, we demonstrate the strong couplings at place\nbetween vortex dynamics, thrust production and wake structure. We first measure\nthe evolution of the vortex velocity with the Strouhal number, and model it\nusing a momentum balance equation directly related to thrust production. We\nthen focus on the wake structure, such as wake angle as well as vortex ring\norientation, diameter and vorticity. The wake structure is modelled in a simple\ngeometrical framework where the vortex ring velocity is composed of the\nfree-stream speed and the ring self-advecting speed. This framework is tested\nand validated by our experimental measurements as well as literature data\ncollapsing on master curves, highlighting a universal behavior dominated by the\nStrouhal number. This allows us to establish a comprehensive understanding of\nhow the wake structure varies with this number and, thus, thrust production."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10049"
    ],
    "c_title":[
      "Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based\n  Planner and Graph-based Policy"
    ],
    "c_abstract":[
      "Multi-agent systems (MAS) have shown great potential in executing complex\ntasks, but coordination and safety remain significant challenges. Multi-Agent\nReinforcement Learning (MARL) offers a promising framework for agent\ncollaboration, but it faces difficulties in handling complex tasks and\ndesigning reward functions. The introduction of Large Language Models (LLMs)\nhas brought stronger reasoning and cognitive abilities to MAS, but existing\nLLM-based systems struggle to respond quickly and accurately in dynamic\nenvironments. To address these challenges, we propose LLM-based Graph\nCollaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and\nMARL. This framework decomposes complex tasks into executable subtasks and\nachieves efficient collaboration among multiple agents through graph-based\ncoordination. Specifically, LGC-MARL consists of two main components: an LLM\nplanner and a graph-based collaboration meta policy. The LLM planner transforms\ncomplex task instructions into a series of executable subtasks, evaluates the\nrationality of these subtasks using a critic model, and generates an action\ndependency graph. The graph-based collaboration meta policy facilitates\ncommunication and collaboration among agents based on the action dependency\ngraph, and adapts to new task environments through meta-learning. Experimental\nresults on the AI2-THOR simulation platform demonstrate the superior\nperformance and scalability of LGC-MARL in completing various complex tasks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-559",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10778"
    ],
    "b_title":[
      "Supervised Large Neighbourhood Search for MIPs"
    ],
    "b_abstract":[
      "Large Neighbourhood Search (LNS) is a powerful heuristic framework for\nsolving Mixed-Integer Programming (MIP) problems. However, designing effective\nvariable selection strategies in LNS remains challenging, especially for\ndiverse sets of problems. In this paper, we propose an approach that integrates\nMachine Learning (ML) within the destroy operator of LNS for MIPs with a focus\non minimal offline training. We implement a modular LNS matheuristic as a test\nbench to compare different LNS heuristics, including our ML-enhanced LNS.\nExperimental results on the MIPLIB 2017 dataset demonstrate that the\nmatheuristic can significantly improve the performance of state-of-the-art\nsolvers like Gurobi and SCIP. We conduct analyses on noisy oracles to explore\nthe impact of prediction accuracy on solution quality. Additionally, we develop\ntechniques to enhance the ML model through loss adjustments and sampling\nroutines. Our findings suggest that while random LNS remains competitive, our\nSupervised LNS (SLNS) outperforms other baselines and helps set the foundation\nfor future research on ML for LNS methods that are both efficient and general."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.15790"
    ],
    "c_title":[
      "Experimental demonstration of electric power generation from Earth's\n  rotation through its own magnetic field"
    ],
    "c_abstract":[
      "Earth rotates through the axisymmetric part of its own magnetic field, but a\nsimple proof shows that it is impossible to use this to generate electricity in\na conductor rotating with Earth.However, we previously identified implicit\nassumptions underlying this proof and showed theoretically that these could be\nviolated and the proof circumvented. This requires using a soft magnetic\nmaterial with a topology satisfying a particular mathematical condition and a\ncomposition and scale favoring magnetic diffusion, i.e. having a low magnetic\nReynolds number Rm (C.F. Chyba, K.P. Hand, Electric power generation from\nEarth's rotation through its own magnetic field. Phys. Rev. Applied 6,\n014017-1-18 (2016)). Here we realize these requirements with a cylindrical\nshell of manganese-zinc ferrite. Controlling for thermoelectric and other\npotentially confounding effects (including 60 Hz and RF background), we show\nthat this small demonstration system generates a continuous DC voltage and\ncurrent of the (low) predicted magnitude. We test and verify other predictions\nof the theory: voltage and current peak when the cylindrical shell's long axis\nis orthogonal to both Earth's rotational velocity v and magnetic field; voltage\nand current go to zero when the entire apparatus (cylindrical shell together\nwith current leads and multimeters) is rotated 90 degrees to orient the shell\nparallel to v; voltage and current again reach a maximum but of opposite sign\nwhen the apparatus is rotated a further 90 degrees; an otherwise-identical\nsolid MnZn cylinder generates zero voltage at all orientations; and a highRm\ncylindrical shell produces zero voltage. We also reproduce the effect at a\nsecond experimental location. The purpose of these experiments was to test the\nexistence of the predicted effect. Ways in which this effect might be scaled to\ngenerate higher voltage and current may now be investigated."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-560",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02487"
    ],
    "b_title":[
      "ACE++: Instruction-Based Image Creation and Editing via Context-Aware\n  Content Filling"
    ],
    "b_abstract":[
      "We report ACE++, an instruction-based diffusion framework that tackles\nvarious image generation and editing tasks. Inspired by the input format for\nthe inpainting task proposed by FLUX.1-Fill-dev, we improve the Long-context\nCondition Unit (LCU) introduced in ACE and extend this input paradigm to any\nediting and generation tasks. To take full advantage of image generative\npriors, we develop a two-stage training scheme to minimize the efforts of\nfinetuning powerful text-to-image diffusion models like FLUX.1-dev. In the\nfirst stage, we pre-train the model using task data with the 0-ref tasks from\nthe text-to-image model. There are many models in the community based on the\npost-training of text-to-image foundational models that meet this training\nparadigm of the first stage. For example, FLUX.1-Fill-dev deals primarily with\npainting tasks and can be used as an initialization to accelerate the training\nprocess. In the second stage, we finetune the above model to support the\ngeneral instructions using all tasks defined in ACE. To promote the widespread\napplication of ACE++ in different scenarios, we provide a comprehensive set of\nmodels that cover both full finetuning and lightweight finetuning, while\nconsidering general applicability and applicability in vertical scenarios. The\nqualitative analysis showcases the superiority of ACE++ in terms of generating\nimage quality and prompt following ability. Code and models will be available\non the project page: https:\/\/ali-vilab. github.io\/ACE_plus_page\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.02832"
    ],
    "c_title":[
      "Small-scale inhomogeneity effects on coherent solar radio emission"
    ],
    "c_abstract":[
      "Coherent radio emission mechanism of solar radio bursts is one of the most\ncomplicated and controversial topics in solar physics. To clarify the\nmechanism(s) of different types of solar radio bursts, (radio) wave excitation\nby energetic electrons in homogeneous plasmas has been widely studied via\nparticle-in-cell (PIC) code numerical simulations. The solar corona is,\nhowever, inhomogeneous over almost all spatial scales. Inhomogeneities of the\nplasma could influence the emission properties of solar radio bursts. In this\npaper, we, hence, investigate effects of inhomogeneity (in the magnetic field,\nplasma density and temperature) of plasmas in the solar corona on radio wave\nemission by ring-beam distributed energetic electrons utilizing 2.5-dimensional\nPIC simulations. Both the beam and electron cyclotron maser (ECM) instabilities\ncould be triggered with the presence of the energetic ring-beam electrons. The\nresultant spectrum of the excited electromagnetic waves presents a zebra-stripe\npattern in the frequency space. The inhomogeneous density or temperature in\nplasmas influences the frequency bandwidth and location of these excited waves.\nOur results can, hence, help to diagnose the plasma properties at the emission\nsites of solar radio bursts. Applications of our results to the solar radio\nbursts with zebra-stripe pattern are discussed."
    ],
    "c_categories":[
      [
        "astro-ph.SR",
        "physics.plasm-ph",
        "physics.space-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-561",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04086"
    ],
    "b_title":[
      "On gcd-graphs over finite rings"
    ],
    "b_abstract":[
      "Gcd-graphs represent an interesting and historically important class of\nintegral graphs. Since the pioneering work of Klotz and Sander, numerous\nincarnations of these graphs have been explored in the literature. In this\narticle, we define and establish some foundational properties of gcd-graphs\ndefined over a general finite commutative ring. In particular, we investigate\nthe connectivity and diameter of these graphs. Additionally, when the ring is a\nfinite symmetric $\\mathbb{Z}\/n$-algebra, we give an explicit description of\ntheir spectrum using the theory of Ramanujan sums that gives a unified\ntreatment of various results in the literature."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.21052"
    ],
    "c_title":[
      "Integrable boundary conditions for the nonlinear Schr\\\"{o}dinger\n  hierarchy"
    ],
    "c_abstract":[
      "We study integrable boundary conditions associated with the whole hierarchy\nof nonlinear Schr\\\"{o}dinger (NLS) equations defined on the half-line. We find\nthat the even order NLS equations and the odd order NLS equations admit rather\ndifferent integrable boundary conditions. In particular, the odd order NLS\nequations permit a new class of integrable boundary conditions that involves\nthe time reversal. We prove the integrability of the NLS hierarchy in the\npresence of our new boundary conditions in the sense that the models possess\ninfinitely many integrals of the motion in involution. Moreover, we develop\nfurther the boundary dressing technique to construct soliton solutions for our\nnew boundary value problems."
    ],
    "c_categories":[
      [
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-562",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15192"
    ],
    "b_title":[
      "A polynomial-time algorithm for the automatic Baire property"
    ],
    "b_abstract":[
      "A subset of a topological space possesses the Baire property if it can be\n  covered by an open set up to a meagre set. For the Cantor space of infinite\n  words Finkel introduced the automatic Baire category where both sets, the\n  open and the meagre, can be chosen to be definable by finite automata. Here\n  we show that, given a Muller automaton defining the original set, resulting\n  open and meagre sets can be constructed in polynomial time.\n  Since the constructed sets are of simple topological structure, it is\n  possible to construct not only Muller automata defining them but also the\n  simpler B\\\"uchi automata. To this end we give, for a restricted class of\n  Muller automata, a conversion to equivalent B\\\"uchi automata of at most\n  quadratic size."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04315"
    ],
    "c_title":[
      "Provable Robust Overfitting Mitigation in Wasserstein Distributionally\n  Robust Optimization"
    ],
    "c_abstract":[
      "Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-563",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16101"
    ],
    "b_title":[
      "Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the\n  Robustness of RAG Against Misleading Retrievals"
    ],
    "b_abstract":[
      "Retrieval-augmented generation (RAG) has shown impressive capabilities in\nmitigating hallucinations in large language models (LLMs). However, LLMs\nstruggle to handle misleading retrievals and often fail to maintain their own\nreasoning when exposed to conflicting or selectively-framed evidence, making\nthem vulnerable to real-world misinformation. In such real-world retrieval\nscenarios, misleading and conflicting information is rampant, particularly in\nthe political domain, where evidence is often selectively framed, incomplete,\nor polarized. However, existing RAG benchmarks largely assume a clean retrieval\nsetting, where models succeed by accurately retrieving and generating answers\nfrom gold-standard documents. This assumption fails to align with real-world\nconditions, leading to an overestimation of RAG system performance. To bridge\nthis gap, we introduce RAGuard, a fact-checking dataset designed to evaluate\nthe robustness of RAG systems against misleading retrievals. Unlike prior\nbenchmarks that rely on synthetic noise, our dataset constructs its retrieval\ncorpus from Reddit discussions, capturing naturally occurring misinformation.\nIt categorizes retrieved evidence into three types: supporting, misleading, and\nirrelevant, providing a realistic and challenging testbed for assessing how\nwell RAG systems navigate different retrieval information. Our benchmark\nexperiments reveal that when exposed to misleading retrievals, all tested\nLLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no\nretrieval at all), highlighting their susceptibility to noisy environments. To\nthe best of our knowledge, RAGuard is the first benchmark to systematically\nassess RAG robustness against misleading evidence. We expect this benchmark\nwill drive future research toward improving RAG systems beyond idealized\ndatasets, making them more reliable for real-world applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09734"
    ],
    "c_title":[
      "Gravitational Effects of a Small Primordial Black Hole Passing Through\n  the Human Body"
    ],
    "c_abstract":[
      "The gravitational effects of a primordial black hole (PBH) passing through\nthe human body are examined, with the goal of determining the minimum mass\nnecessary to produce significant injury or death. Two effects are examined: the\ndamage caused by a shock wave propagating outward from the black hole\ntrajectory, and the dissociation of brain cells from tidal forces produced by\nthe black hole on its passage through the human body. It is found that the\nformer is the dominant effect, with a cutoff mass for serious injury or death\nof approximately $M_{PBH} > 1.4 \\times 10^{17} {\\rm g}$. The number density of\nprimordial black holes with a mass above this cutoff is far too small to\nproduce any observable effects on the human population."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-564",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13688"
    ],
    "b_title":[
      "Non-Linear Function Computation Broadcast"
    ],
    "b_abstract":[
      "This work addresses the $K$-user computation broadcast problem consisting of\na master node, that holds all datasets and users for a general class of\nfunction demands, including linear and non-linear functions, over finite\nfields. The master node sends a broadcast message to enable each of $K$\ndistributed users to compute its demanded function in an asymptotically\nlossless manner with user's side information. We derive bounds on the optimal\n$K$-user computation broadcast rate that allows the users to compute their\ndemanded functions by capturing the structures of the computations and\navailable side information. Our achievability scheme involves the design of a\nnovel graph-based coding model to build a broadcast message to meet each user's\ndemand, by leveraging the structural dependencies among the datasets, the user\ndemands, and the side information of each user, drawing on K{\\\"o}rner's\ncharacteristic graph framework. The converse uses the structures of the demands\nand the side information available at $K$ users to yield a tight lower bound on\nthe broadcast rate. With the help of examples, we demonstrate our scheme\nachieves a better communication rate than the existing state of the art."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06029"
    ],
    "c_title":[
      "Bound-State Beta Decay of $\\mathbf{\\mathrm{^{205}{Tl}^{81+}}}$ Ions and\n  the LOREX Project"
    ],
    "c_abstract":[
      "Stable $^{205}$Tl ions have the lowest known energy threshold for capturing\nelectron neutrinos ($\\nu_e$) of ${ E}_{\\nu_e}\\ge50.6$\\,keV. The Lorandite\nExperiment (LOREX), proposed in the 1980s, aims at obtaining the longtime\naveraged solar neutrino flux by utilizing natural deposits of Tl-bearing\nlorandite ores. To determine the $\\nu_e$ capture cross section, it is required\nto know the strength of the weak transition connecting the ground state of\n$^{205}$Tl and the 2.3 keV first excited state in $^{205}$Pb. The only way to\nexperimentally address this transition is to measure the bound-state beta decay\n($\\beta_{b}$) of fully ionized $\\mathrm{^{205}Tl^{81+}}$ ions. After three\ndecades of meticulous preparation, the half-life of the $\\beta_{b}$ decay of\n$\\mathrm{^{205}Tl^{81+}}$ has been measured to be $291_{-27}^{+33}$ days using\nthe Experimental Storage Ring (ESR) at GSI, Darmstadt. The longer measured\nhalf-life compared to theoretical estimates reduces the expected\nsignal-to-noise ratio in the LOREX, thus challenging its feasibility."
    ],
    "c_categories":[
      [
        "astro-ph.SR",
        "nucl-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-565",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04565"
    ],
    "b_title":[
      "Private Federated Learning In Real World Application -- A Case Study"
    ],
    "b_abstract":[
      "This paper presents an implementation of machine learning model training\nusing private federated learning (PFL) on edge devices. We introduce a novel\nframework that uses PFL to address the challenge of training a model using\nusers' private data. The framework ensures that user data remain on individual\ndevices, with only essential model updates transmitted to a central server for\naggregation with privacy guarantees. We detail the architecture of our app\nselection model, which incorporates a neural network with attention mechanisms\nand ambiguity handling through uncertainty management. Experiments conducted\nthrough off-line simulations and on device training demonstrate the feasibility\nof our approach in real-world scenarios. Our results show the potential of PFL\nto improve the accuracy of an app selection model by adapting to changes in\nuser behavior over time, while adhering to privacy standards. The insights\ngained from this study are important for industries looking to implement PFL,\noffering a robust strategy for training a predictive model directly on edge\ndevices while ensuring user data privacy."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01343"
    ],
    "c_title":[
      "The reformed hydrodynamic Schr\\\"odinger equation and the effective\n  method for eliminating pseudo-quantum potential: a case study on barotropic\n  potential flow"
    ],
    "c_abstract":[
      "Given the discrepancies between the framework of the hydrodynamic\nSchr\\\"odinger equation (HSE) and classical fluid dynamics, we propose a\nreformed framework, termed the reformed hydrodynamic Schr\\\"odinger equation\n(RHSE) for clarity. The RHSE for barotropic potential flow is developed;\nnotably, we demonstrate an alternative approach to eliminate the pseudo-quantum\npotential without resorting to the classical limit. We call this approach the\n''correction method.'' We then examine the correction method using Noether's\ntheorem, confirming that it enforces the conservation of energy and momentum.\nFurthermore, we find that the classical limit fails to completely remove\nredundant terms when a two-component wave function is used to introduce\nvorticity. This fact suggests that the classical limit is not a universal\nfallback, highlighting the importance of further investigating the correction\nmethod."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-566",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10699"
    ],
    "b_title":[
      "Exploring Synaptic Resonance in Large Language Models: A Novel Approach\n  to Contextual Memory Integration"
    ],
    "b_abstract":[
      "Contextual memory integration remains a high challenge in the development of\nlanguage models, particularly in tasks that require maintaining coherence over\nextended sequences. Traditional approaches, such as self-attention mechanisms\nand memory-augmented architectures, often prioritize short-term dependencies,\nleading to fragmentation and inconsistency in long-range contextual\nunderstanding. Inspired by principles of synaptic plasticity observed in\nbiological neural systems, a novel mechanism, Synaptic Resonance, is introduced\nto dynamically reinforce relevant memory pathways during training and\ninference. Unlike static memory representations, this mechanism continuously\nadjusts synaptic weight matrices based on contextual relevance, allowing for\nimproved information retention without excessive computational overhead.\nEvaluations conducted on an open-source language model demonstrate reductions\nin perplexity, enhancements in contextual coherence, and increased robustness\nagainst input noise, highlighting the effectiveness of reinforcement-driven\nmemory modulation. Comparative analysis against baseline models further reveals\nthat the proposed approach achieves higher memory retention efficiency while\nmaintaining computational feasibility. The architectural modifications\nintegrate seamlessly into existing transformer-based frameworks, ensuring\nstable convergence and efficient inference without sacrificing scalability.\nApplications benefiting from improved long-term contextual consistency, such as\ndialogue systems and document summarization, stand to gain from this approach.\nEmpirical findings suggest that dynamically reinforced memory pathways offer a\npromising alternative to conventional memory mechanisms, addressing\nlongstanding limitations in extended sequence modeling."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01414"
    ],
    "c_title":[
      "Temporal Correlations and Inelastic Dynamics in a Vibrated Binary\n  Granular Mixture"
    ],
    "c_abstract":[
      "We investigate the dynamics of binary mixtures of inelastic particles through\nevent-driven molecular dynamics simulations, focusing on velocity\nautocorrelation functions (VACFs). The study examines two distinct particle\ntypes under varying inelasticity conditions, systematically analyzing\ncoefficients of restitution (CoR) ranging from 0.80 to 0.95. Like-particle\ninteractions (AA and BB) maintain equal CoR values, while unlike-particle\ninteractions (AB) are assigned the average CoR. The simulation framework\nincorporates a vibrating base system to maintain energy input and system\nstability. Our analysis reveals significant differences in VACF decay rates\nbetween Type 1 and Type 2 particles, demonstrating non-equipartition of energy\nwithin the binary mixture. The degree of this disparity is strongly influenced\nby the coefficient of restitution, with lower CoR values leading to more\npronounced differences between particle types. These findings provide insights\ninto the complex dynamics of granular gases and the role of inelasticity in\nenergy distribution within binary mixtures. Our study contributes to the\nunderstanding of non-equilibrium statistical mechanics in granular systems and\nhas potential implications for industrial processes involving particulate\nmaterials, such as fluidized beds and pneumatic conveying systems."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-567",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01003"
    ],
    "b_title":[
      "EasySplat: View-Adaptive Learning makes 3D Gaussian Splatting Easy"
    ],
    "b_abstract":[
      "3D Gaussian Splatting (3DGS) techniques have achieved satisfactory 3D scene\nrepresentation. Despite their impressive performance, they confront challenges\ndue to the limitation of structure-from-motion (SfM) methods on acquiring\naccurate scene initialization, or the inefficiency of densification strategy.\nIn this paper, we introduce a novel framework EasySplat to achieve high-quality\n3DGS modeling. Instead of using SfM for scene initialization, we employ a novel\nmethod to release the power of large-scale pointmap approaches. Specifically,\nwe propose an efficient grouping strategy based on view similarity, and use\nrobust pointmap priors to obtain high-quality point clouds and camera poses for\n3D scene initialization. After obtaining a reliable scene structure, we propose\na novel densification approach that adaptively splits Gaussian primitives based\non the average shape of neighboring Gaussian ellipsoids, utilizing KNN scheme.\nIn this way, the proposed method tackles the limitation on initialization and\noptimization, leading to an efficient and accurate 3DGS modeling. Extensive\nexperiments demonstrate that EasySplat outperforms the current state-of-the-art\n(SOTA) in handling novel view synthesis."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08223"
    ],
    "c_title":[
      "Demonstration of the third-order nonlinear Hall effect in topological\n  Dirac semimetal NiTe$_2$"
    ],
    "c_abstract":[
      "We experimentally investigate third-order nonlinear Hall effect for\nthree-dimensional NiTe$_2$ single crystal samples. NiTe$_2$ is the recently\ndiscovered type-II Dirac semimetal, so both the inversion and the time-reversal\nsymmetries are conserved in the bulk. As a result, the well known second-order\nnonlinear Hall effect does not expected for this material, which we confirm as\nnegligibly small second-harmonic transverse Hall voltage response to the\nlongitudinal ac electric current. As the main experimental result, we\ndemonstrate the unsaturated third-harmonic Hall response in NiTe$_2$, which\nwell corresponds to the theoretically predicted third-order nonlinear Hall\neffect in Dirac semimetals. We also demonstrate, that the third harmonic signal\ndoes not depend on the external magnetic field, in contrast to the\nfield-depended first-order and second-order Hall effects."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-568",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08481"
    ],
    "b_title":[
      "Operational solutions for the generalized Fokker-Planck and generalized\n  diffusion-wave equations"
    ],
    "b_abstract":[
      "The evolution operator method is used to solve the generalized Fokker-Planck\nequations and the generalized diffusion-wave equations in the (1+1) dimensional\nspace in which $x\\in\\mathbb{R}$ and $t\\in\\mathbb{R}_+$. These equations contain\neither the first- or the second-time derivatives smeared by memory functions,\neach of which forms an integral kernel (denoted by $f(\\xi, t)$,\n$\\xi\\in\\mathbb{R}_+$) of suitable evolution operators. If memory functions in\nthe Laplace space are Stieltjes functions, then $f(\\xi, t)$ satisfy\nnormalization, non-negativity, and infinite divisibility to be considered a\nprobability density function. The evolution operators also contain\nexponential-like operators whose action on initial condition $p_0(x) > 0$ leads\nto the parent process distribution functions. This makes the results fully\nanalogous to those obtained within the standard subordination approach. The\nabove conclusion is satisfied by the solution of the generalized Fokker-Planck\nequation. In the case of the generalized diffusion-wave equation, to get this\nproperty, we should employ a special class, namely \"diffusion-like\" initial\nconditions. The key models of the operator method involve power-law memory\nfunctions. It leads to the characterization of $f(\\xi, t)$ by applying\none-sided stable L\\'{e}vy distributions. The article also examines the\nproperties of evolution operators in terms of evolution and self-reproduction."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.15965"
    ],
    "c_title":[
      "Global stability of Wright-type equations with negative Schwarzian"
    ],
    "c_abstract":[
      "Simplicity of the $37\/24$-global stability criterion announced by E.M. Wright\nin 1955 and rigorously proved by B. B\\'{a}nhelyi et al in 2014 for the delayed\nlogistic equation raised the question of its possible extension for other\npopulation models. In our study, we answer this question by extending the\n$37\/24$-stability condition for the Wright-type equations with decreasing\nsmooth nonlinearity $f$ which has a negative Schwarzian and satisfies the\nstandard negative feedback and boundedness assumptions. The proof contains the\nconstruction and careful analysis of qualitative properties of certain bounding\nrelations. To validate our conclusions, these relations are evaluated at finite\nsets of points; for this purpose, we systematically use interval analysis."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.CA",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-569",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.19317"
    ],
    "b_title":[
      "LLM-based Affective Text Generation Quality Based on Different\n  Quantization Values"
    ],
    "b_abstract":[
      "Large language models exhibit a remarkable capacity in language generation\nand comprehension. These advances enable AI systems to produce more human-like\nand emotionally engaging text. However, these models rely on a large number of\nparameters, requiring significant computational resources for training and\ninference. In some scenarios, accessing these resources can be challenging\n(e.g., budget or hardware limitations). Techniques like reducing precision bits\ncan make models more memory-efficient, reducing the computational resources\nneeded, at the cost of reduced accuracy. This paper addresses the trade-off\nbetween different quantization values, GPU RAM utilization, and text quality in\naffective text generation (e.g., \"I really enjoy running in the snow-covered\nforest\"). To evaluate, we use an emotion classifier and ten seed prompts to\ngenerate affective text. We test three setups of precision bits (8, 16, and 32)\nacross five open-weight language models from two different families. Our\nfindings demonstrate that bit reductions lead to memory savings, achieving a\nreduction of 76%. However, this optimization comes with a trade-off, leading to\na decrease of up to 10 pp in F1 score for larger models and an increase of 10\npp for smaller models, along with roughly double the inference time. In terms\nof text quality, larger models at lower quantization levels generally\noutperform smaller, higher-precision models -- while requiring similar memory."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16910"
    ],
    "c_title":[
      "A Probabilistic Model of Bilateral Lymphatic Spread in Head and Neck\n  Cancer"
    ],
    "c_abstract":[
      "Current guidelines for elective nodal irradiation in oropharyngeal squamous\ncell carcinoma (OPSCC) recommend including large portions of the contralateral\nlymph system in the clinical target volume (CTV-N), even for lateralized tumors\nwith no clinical lymph node involvement in the contralateral neck. This study\nintroduces a probabilistic model of bilateral lymphatic tumor progression in\nOPSCC to estimate personalized risks of occult disease in specific lymph node\nlevels (LNLs) based on clinical involvement, T-stage, and tumor lateralization.\nBuilding on a previously developed hidden Markov model for ipsilateral spread,\nwe extend the approach to the contralateral neck. The model represents LNLs I,\nII, III, IV, V, and VII on both sides of the neck as binary hidden variables\n(healthy\/involved), connected via arcs representing spread probabilities. These\nprobabilities are learned using Markov chain Monte Carlo (MCMC) sampling from a\ndataset of 833 OPSCC patients, enabling the model to reflect the underlying\nlymphatic progression dynamics. The model accurately and precisely describes\nobserved patterns of involvement with a compact set of interpretable\nparameters. Midline extension of the primary tumor is identified as the primary\nrisk factor for contralateral involvement, with advanced T-stage and extensive\nipsilateral involvement further increasing risk. Occult disease in\ncontralateral LNL III is highly unlikely if upstream LNL II is clinically\nnegative, and in contralateral LNL IV, occult disease is exceedingly rare\nwithout LNL III involvement. For lateralized tumors not crossing the midline,\nthe model suggests the contralateral neck may safely be excluded from the\nCTV-N. For tumors extending across the midline but with a clinically negative\ncontralateral neck, the CTV-N could be limited to LNL II, reducing unnecessary\nexposure of normal tissue while maintaining regional tumor control."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-570",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15795"
    ],
    "b_title":[
      "Can Multimodal Large Language Models be Guided to Improve Industrial\n  Anomaly Detection?"
    ],
    "b_abstract":[
      "In industrial settings, the accurate detection of anomalies is essential for\nmaintaining product quality and ensuring operational safety. Traditional\nindustrial anomaly detection (IAD) models often struggle with flexibility and\nadaptability, especially in dynamic production environments where new defect\ntypes and operational changes frequently arise. Recent advancements in\nMultimodal Large Language Models (MLLMs) hold promise for overcoming these\nlimitations by combining visual and textual information processing\ncapabilities. MLLMs excel in general visual understanding due to their training\non large, diverse datasets, but they lack domain-specific knowledge, such as\nindustry-specific defect tolerance levels, which limits their effectiveness in\nIAD tasks. To address these challenges, we propose Echo, a novel multi-expert\nframework designed to enhance MLLM performance for IAD. Echo integrates four\nexpert modules: Reference Extractor which provides a contextual baseline by\nretrieving similar normal images, Knowledge Guide which supplies\ndomain-specific insights, Reasoning Expert which enables structured, stepwise\nreasoning for complex queries, and Decision Maker which synthesizes information\nfrom all modules to deliver precise, context-aware responses. Evaluated on the\nMMAD benchmark, Echo demonstrates significant improvements in adaptability,\nprecision, and robustness, moving closer to meeting the demands of real-world\nindustrial anomaly detection."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18124"
    ],
    "c_title":[
      "On the Topological Nature of the Butterfly Effect"
    ],
    "c_abstract":[
      "Non-integrability in the sense of dynamical systems, also known as dynamical\nchaos, is a strongly nonlinear qualitative phenomenon. Its most promising\ntheoretical descriptions are likely to emerge from non-perturbative approaches,\nwith symmetry-based methods being particularly reliable. One such\nsymmetry-based framework is supersymmetric theory of stochastic dynamics (STS).\nSTS reformulates a general form stochastic (partial) differential equations\n(SDE) as a cohomological topological field theory (TFT) and identifies the\norder associated with the spontaneous breakdown of the corresponding\ntopological supersymmetry (TS) as the stochastic generalization of chaos. The\nFaddeev-Popov ghosts of STS act as a systematic bookkeeping tool for the\ndynamic differentials from the definition of the butterfly effect (BE): the\ninfinitely long dynamical memory unique to chaos. Accordingly, the effective\nfield theory (EFT) of the TS breaking is essentially a field theory of the BE\nin the long-wavelength limit. Building on this perspective, here we demonstrate\nthat one way to build such EFTs is the background field method with the\nexternal $\\mathfrak{gl}(1|1)$ supergauge field coupled to N=2 supercurrents of\nSTS, the fermion number conservation, and translations in time. By the\nGoldstone theorem, the resulting EFTs are conformal field theories (CFTs) and\nthe operator product expansion provides an explanation for 1\/f noise -- the\nexperimental signature of chaos in the form of dynamical power-law\ncorrelations. Moreover, the generating functional of the background field\npossesses its own TS, revealing the topological nature of the BE. Particularly,\nwhen the Anti-de Sitter(AdS)\/CFT correspondence is an acceptable approximation,\nthe holographic dual of EFT is a cohomological TFT on AdS in which the\nassociated TS and the isometry of the basespace underlie the BE and 1\/f noise,\nrespectively."
    ],
    "c_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP",
        "nlin.CD"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-571",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07779"
    ],
    "b_title":[
      "The route to turbulence in magnetohydrodynamic square duct flow"
    ],
    "b_abstract":[
      "The transition route from laminar to turbulent flow in a magnetohydrodynamic\n(MHD) duct with a square cross-section is investigated in the limit of low\nmagnetic Reynolds number. In the presence of a transverse magnetic field,\nHartmann and Shercliff layers are present on the walls orthogonal and parallel\nto the field direction, respectively. We assume reflection symmetries in both\ntransverse directions, and investigate the competition between transition\nmechanisms specific to each boundary layer using direct numerical simulations.\nIndependently of which wall turbulence eventually occupies, transition relies\nexclusively on a tripping of the Shercliff layer by perturbations, while the\nHartmann layer plays a passive role. This is explained, using a dynamical\nsystems interpretation, by the spatial localization of the edge states in the\nShercliff layer at the expense of the Hartmann layer. The link between these\nnon-linear coherent structures and the linear optimal modes known from\nnon-modal stability and energy stability theory is pointed out."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.15672"
    ],
    "c_title":[
      "VaViM and VaVAM: Autonomous Driving through Video Generative Modeling"
    ],
    "c_abstract":[
      "We explore the potential of large-scale generative video models for\nautonomous driving, introducing an open-source auto-regressive video model\n(VaViM) and its companion video-action model (VaVAM) to investigate how video\npre-training transfers to real-world driving. VaViM is a simple auto-regressive\nvideo model that predicts frames using spatio-temporal token sequences. We show\nthat it captures the semantics and dynamics of driving scenes. VaVAM, the\nvideo-action model, leverages the learned representations of VaViM to generate\ndriving trajectories through imitation learning. Together, the models form a\ncomplete perception-to-action pipeline. We evaluate our models in open- and\nclosed-loop driving scenarios, revealing that video-based pre-training holds\npromise for autonomous driving. Key insights include the semantic richness of\nthe learned representations, the benefits of scaling for video synthesis, and\nthe complex relationship between model size, data, and safety metrics in\nclosed-loop evaluations. We release code and model weights at\nhttps:\/\/github.com\/valeoai\/VideoActionModel"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-572",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12502"
    ],
    "b_title":[
      "Enhanced Approximation Algorithms for the Capacitated Location Routing\n  Problem"
    ],
    "b_abstract":[
      "The Capacitated Location Routing Problem is an important planning and routing\nproblem in logistics, which generalizes the capacitated vehicle routing problem\nand the uncapacitated facility location problem. In this problem, we are given\na set of depots and a set of customers where each depot has an opening cost and\neach customer has a demand. The goal is to open some depots and route\ncapacitated vehicles from the opened depots to satisfy all customers' demand,\nwhile minimizing the total cost. In this paper, we propose a\n$4.169$-approximation algorithm for this problem, improving the best-known\n$4.38$-approximation ratio. Moreover, if the demand of each customer is allowed\nto be delivered by multiple tours, we propose a more refined\n$4.091$-approximation algorithm. Experimental study on benchmark instances\nshows that the quality of our computed solutions is better than that of the\nprevious algorithm and is also much closer to optimality than the provable\napproximation factor."
    ],
    "b_categories":[
      [
        "cs.DS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14628"
    ],
    "c_title":[
      "Irreducibility of determinants, and Esterov's conjecture on\n  $\\mathscr{A}$-discriminants"
    ],
    "c_abstract":[
      "In the space of square matrices, we characterize row-generated subspaces, on\nwhich the determinant is an irreducible polynomial. As a corollary, we\ncharacterize square systems of polynomial equations with indeterminate\ncoefficients, whose discriminant is an irreducible hypersurface. This resolves\na conjecture of Esterov, and, in a sequel paper, leads to a complete\ndescription of components and codimensions for discriminants of square systems\nof equations."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-573",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06130"
    ],
    "b_title":[
      "Self-Correcting Decoding with Generative Feedback for Mitigating\n  Hallucinations in Large Vision-Language Models"
    ],
    "b_abstract":[
      "While recent Large Vision-Language Models (LVLMs) have shown remarkable\nperformance in multi-modal tasks, they are prone to generating hallucinatory\ntext responses that do not align with the given visual input, which restricts\ntheir practical applicability in real-world scenarios. In this work, inspired\nby the observation that the text-to-image generation process is the inverse of\nimage-conditioned response generation in LVLMs, we explore the potential of\nleveraging text-to-image generative models to assist in mitigating\nhallucinations in LVLMs. We discover that generative models can offer valuable\nself-feedback for mitigating hallucinations at both the response and token\nlevels. Building on this insight, we introduce self-correcting Decoding with\nGenerative Feedback (DeGF), a novel training-free algorithm that incorporates\nfeedback from text-to-image generative models into the decoding process to\neffectively mitigate hallucinations in LVLMs. Specifically, DeGF generates an\nimage from the initial response produced by LVLMs, which acts as an auxiliary\nvisual reference and provides self-feedback to verify and correct the initial\nresponse through complementary or contrastive decoding. Extensive experimental\nresults validate the effectiveness of our approach in mitigating diverse types\nof hallucinations, consistently surpassing state-of-the-art methods across six\nbenchmarks. Code is available at https:\/\/github.com\/zhangce01\/DeGF."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00607"
    ],
    "c_title":[
      "PAC Learning is just Bipartite Matching (Sort of)"
    ],
    "c_abstract":[
      "The main goal of this article is to convince you, the reader, that supervised\nlearning in the Probably Approximately Correct (PAC) model is closely related\nto -- of all things -- bipartite matching! En-route from PAC learning to\nbipartite matching, I will overview a particular transductive model of\nlearning, and associated one-inclusion graphs, which can be viewed as a\ngeneralization of some of the hat puzzles that are popular in recreational\nmathematics. Whereas this transductive model is far from new, it has recently\nseen a resurgence of interest as a tool for tackling deep questions in learning\ntheory. A secondary purpose of this article could be as a (biased) tutorial on\nthe connections between the PAC and transductive models of learning."
    ],
    "c_categories":[
      [
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-574",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03531"
    ],
    "b_title":[
      "Traversable AdS Wormhole via Non-local Double Trace or Janus Deformation"
    ],
    "b_abstract":[
      "We study (i) Janus deformations and (ii) non-local double trace deformations\nof a pair of CFTs, as two different ways to construct CFT duals of traversable\nAdS wormholes. First, we construct a simple model of traversable wormholes by\ngluing two Poincar\\'e AdS geometries and BTZ black holes and compute\nholographic two point functions and (pseudo) entanglement entropy. We point out\nthat a Janus gravity solution describes a traversable wormhole when the\ndeformation parameter takes imaginary values. On the other hand, we show that\ndouble trace deformations between two decoupled CFTs can reproduce two point\nfunctions of traversable AdS wormholes. By considering the case where the\ndouble trace deformation is given by a non-local $T\\overline{T}$ deformation,\nwe analyze the dual gravity which implies emergence of wormholes. We present\ntoy model of these deformed CFTs by using free scalars and obtain qualitative\nbehaviors expected for them. We argue that the crucial difference between the\ntwo constructions is that a global time slice of wormhole is described by a\npure state for Janus deformations, while it is a mixed state for the double\ntrace deformations."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.04338"
    ],
    "c_title":[
      "In-depth Analysis of Graph-based RAG in a Unified Framework"
    ],
    "c_abstract":[
      "Graph-based Retrieval-Augmented Generation (RAG) has proven effective in\nintegrating external knowledge into large language models (LLMs), improving\ntheir factual accuracy, adaptability, interpretability, and trustworthiness. A\nnumber of graph-based RAG methods have been proposed in the literature.\nHowever, these methods have not been systematically and comprehensively\ncompared under the same experimental settings. In this paper, we first\nsummarize a unified framework to incorporate all graph-based RAG methods from a\nhigh-level perspective. We then extensively compare representative graph-based\nRAG methods over a range of questing-answering (QA) datasets -- from specific\nquestions to abstract questions -- and examine the effectiveness of all\nmethods, providing a thorough analysis of graph-based RAG approaches. As a\nbyproduct of our experimental analysis, we are also able to identify new\nvariants of the graph-based RAG methods over specific QA and abstract QA tasks\nrespectively, by combining existing techniques, which outperform the\nstate-of-the-art methods. Finally, based on these findings, we offer promising\nresearch opportunities. We believe that a deeper understanding of the behavior\nof existing methods can provide new valuable insights for future research."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.DB",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-575",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02310"
    ],
    "b_title":[
      "Improving the stability and efficiency of high-order operator-splitting\n  methods"
    ],
    "b_abstract":[
      "Operator-splitting methods are widely used to solve differential equations,\nespecially those that arise from multi-scale or multi-physics models, because a\nmonolithic (single-method) approach may be inefficient or even infeasible. The\nmost common operator-splitting methods are the first-order Lie--Trotter (or\nGodunov) and the second-order Strang (Strang--Marchuk) splitting methods.\nHigh-order splitting methods with real coefficients require backward-in-time\nintegration in each operator and hence may be adversely impacted by instability\nfor certain operators such as diffusion. However, besides the method\ncoefficients, there are many other ancillary aspects to an overall\noperator-splitting method that are important but often overlooked. For example,\nthe operator ordering and the choice of sub-integration methods can\nsignificantly affect the stability and efficiency of an operator-splitting\nmethod. In this paper, we investigate some design principles for the\nconstruction of operator-splitting methods, including minimization of local\nerror measure, choice of sub-integration method, maximization of linear\nstability, and minimization of overall computational cost. We propose a new\nfour-stage, third-order, 2-split operator-splitting method with seven\nsub-integrations per step and optimized linear stability for a benchmark\nproblem from cardiac electrophysiology. We then propose a general principle to\nfurther improve stability and efficiency of such operator-splitting methods by\nusing low-order, explicit sub-integrators for unstable sub-integrations. We\ndemonstrate an almost 30\\% improvement in the performance of methods derived\nfrom these design principles compared to the best-known third-order methods."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17959"
    ],
    "c_title":[
      "Quantum Computing from Graphs"
    ],
    "c_abstract":[
      "While stabilizer tableaus have proven exceptionally useful as a descriptive\ntool for additive quantum codes, they offer little guidance for concrete\nconstructions or coding algorithm analysis. We introduce a representation of\nstabilizer codes as graphs with certain structures. Specifically, the graphs\ntake a semi-bipartite form where input nodes map to output nodes, such that\noutput nodes may connect to each other but input nodes may not. Intuitively,\nthe graph's input-output edges represent information propagation of the\nencoder, while output-output edges represent the code's entanglement. We prove\nthat this graph representation is in bijection with tableaus and give an\nefficient compilation algorithm that transforms tableaus into graphs. We show\nthat this map is efficiently invertible, which gives a universal recipe for\ncode construction by finding graphs with nice properties. The graph\nrepresentation gives insight into both code construction and algorithms. To the\nformer, we argue that graphs provide a flexible platform for building codes. We\nconstruct several constant-size codes and several infinite code families. We\nalso use graphs to extend the quantum Gilbert-Varshamov bound to a three-way\ndistance-rate-weight trade-off. To the latter, we show that key coding\nalgorithms, distance approximation, weight reduction, and decoding, are unified\nas instances of a single optimization game on a graph. Moreover, key code\nproperties such as distance, weight, and encoding circuit depth, are all\ncontrolled by the graph degree. We give efficient algorithms for producing\nencoding circuits whose depths scale with the degree and for implementing\ncertain logical diagonal and Clifford gates with reduced depth. Finally, we\nfind an efficient decoding algorithm for certain classes of graphs. These\nresults give evidence that graphs are useful for the study of quantum computing\nand its implementations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-576",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11528"
    ],
    "b_title":[
      "A Survey of Personalized Large Language Models: Progress and Future\n  Directions"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) excel in handling general knowledge tasks, yet\nthey struggle with user-specific personalization, such as understanding\nindividual emotions, writing styles, and preferences. Personalized Large\nLanguage Models (PLLMs) tackle these challenges by leveraging individual user\ndata, such as user profiles, historical dialogues, content, and interactions,\nto deliver responses that are contextually relevant and tailored to each user's\nspecific needs. This is a highly valuable research topic, as PLLMs can\nsignificantly enhance user satisfaction and have broad applications in\nconversational agents, recommendation systems, emotion recognition, medical\nassistants, and more. This survey reviews recent advancements in PLLMs from\nthree technical perspectives: prompting for personalized context (input level),\nfinetuning for personalized adapters (model level), and alignment for\npersonalized preferences (objective level). To provide deeper insights, we also\ndiscuss current limitations and outline several promising directions for future\nresearch. Updated information about this survey can be found at the\nhttps:\/\/github.com\/JiahongLiu21\/Awesome-Personalized-Large-Language-Models."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13894"
    ],
    "c_title":[
      "Bayesian high-dimensional biological pathway-guided mediation analysis\n  with application to metabolomics"
    ],
    "c_abstract":[
      "With advances in high-resolution mass spectrometry technologies, metabolomics\ndata are increasingly used to investigate biological mechanisms underlying\nassociations between exposures and health outcomes in clinical and\nepidemiological studies. Mediation analysis is a powerful framework for\ninvestigating a hypothesized causal chain and when applied to metabolomics\ndata, a large number of correlated metabolites belonging to interconnected\nmetabolic pathways need to be considered as mediators. To identify metabolic\npathways as active mediators, existing approaches typically focus on first\nidentifying individual metabolites as active mediators, followed by post-hoc\nmetabolic pathway determination. These multi-stage procedures make statistical\ninference challenging. We propose a Bayesian biological pathway-guided\nmediation analysis that aims to jointly analyze all metabolites together,\nidentify metabolic pathways directly, and estimate metabolic pathway-specific\nindirect effects. This is accomplished by incorporating existing biological\nknowledge of metabolic pathways to account for correlations among mediators,\nalong with variable selection and dimension reduction techniques. Advantages of\nthe proposed method is demonstrated in extensive simulation studies with\nreal-word metabolic pathway structure. We apply the proposed method to two\nstudies examining the role of metabolism in mediating (1) the effect of\nRoux-en-Y gastric bypass on glycemic control, and (2) the effect of prenatal\nexposure to per- and polyfluoroalkyl substances (PFAS) on gestational age at\nbirth. Our analyses confirm metabolic pathways previously identified and\nprovide additional uncertainty quantification for the mediation effects."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-577",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00563"
    ],
    "b_title":[
      "Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for\n  Semantic Segmentation"
    ],
    "b_abstract":[
      "Recent advancements in deep neural networks have significantly enhanced the\nperformance of semantic segmentation. However, class imbalance and instance\nimbalance remain persistent challenges, where smaller instances and thin\nboundaries are often overshadowed by larger structures. To address the\nmultiscale nature of segmented objects, various models have incorporated\nmechanisms such as spatial attention and feature pyramid networks. Despite\nthese advancements, most loss functions are still primarily pixel-wise, while\nregional and boundary-focused loss functions often incur high computational\ncosts or are restricted to small-scale regions. To address this limitation, we\npropose complex wavelet mutual information (CWMI) loss, a novel loss function\nthat leverages mutual information from subband images decomposed by a complex\nsteerable pyramid. The complex steerable pyramid captures features across\nmultiple orientations and preserves structural similarity across scales.\nMeanwhile, mutual information is well-suited for capturing high-dimensional\ndirectional features and exhibits greater noise robustness. Extensive\nexperiments on diverse segmentation datasets demonstrate that CWMI loss\nachieves significant improvements in both pixel-wise accuracy and topological\nmetrics compared to state-of-the-art methods, while introducing minimal\ncomputational overhead. The code is available at\nhttps:\/\/anonymous.4open.science\/r\/CWMI-83B7\/"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14291"
    ],
    "c_title":[
      "The infrared-safe Minkowskian Curci-Ferrari model"
    ],
    "c_abstract":[
      "We discuss the existence of Landau-pole-free renormalization group\ntrajectories in the Minkowskian version of the Curci-Ferrari model as a\nfunction of a running parameter $q^2$ associated to the four-vector $q$ at\nwhich renormalization conditions are imposed, and which can take both\nspace-like ($\\smash{q^2<0}$) and time-like ($\\smash{q^2>0}$) values. We discuss\ntwo possible extensions of the infrared-safe scheme defined in Ref. [Phys. Rev.\nD, 84, 045018, 2011] for the Euclidean version of the model, which coincide\nwith the latter in the space-like region upon identifying\n$\\smash{Q^2\\equiv-q^2}$ with the square of the renormalization scale in that\nreference. The first extension uses real-valued renormalization factors and\nleads to a flow in the time-like region with a similar structure as the flow in\nthe space-like region (or in the Euclidean model), including a non-trivial\nfixed point and a family of trajectories bounded at all scales by the value of\nthe coupling at this fixed point. Interestingly, the fixed point in the\ntime-like region has a much smaller value of $\\lambda\\equiv g^2N\/16\\pi^2$ than\nthe corresponding one in the space-like region, a value closer to the\nperturbative boundary $\\smash{\\lambda=1}$. However, in this real-valued\ninfrared-safe scheme, the flow cannot connect the time-like and space-like\nregions. Thus, it is not possible to deduce the relevant time-like flow\ntrajectory from the sole knowledge of a space-like flow trajectory. To try to\ncure this problem, we investigate a second extension of the Euclidean IR-safe\nscheme, which allows for complex-valued renormalization factors. We discuss\nunder which conditions these schemes can make sense and study their ability to\nconnect space- and time-like flow trajectories. In particular, we investigate\nto which types of time-like trajectories the perturbative space-like\ntrajectories are mapped onto."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-578",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01731"
    ],
    "b_title":[
      "Dark Photons can Prevent Core-Collapse Supernova Explosions"
    ],
    "b_abstract":[
      "During the accretion phase of a core-collapse supernova (SN), dark-photon\n(DP) cooling can be largest in the gain layer below the stalled shock wave. In\nthis way, it could counter-act the usual shock rejuvenation by neutrino energy\ndeposition and thus prevent the explosion. This peculiar energy-loss profile\nderives from the resonant nature of DP production. The largest cooling and thus\nstrongest constraints obtain for DP masses of 0.1-0.4 MeV, a range\ncorresponding to the photon plasma mass in the gain region. Electron-capture\nSNe, once observationally unambiguously identified, could provide strong bounds\neven down to nearly 0.01 MeV. For a coupling strength so small that\nneutrino-driven explosions are expected to survive, the DP cooling of the core\nis too small to modify the neutrino signal, i.e., our new argument supersedes\nthe traditional SN1987A cooling bound."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.19735"
    ],
    "c_title":[
      "R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning\n  Learning"
    ],
    "c_abstract":[
      "Despite recent breakthroughs in reasoning-enhanced large language models\n(LLMs) like DeepSeek-R1, incorporating inference-time reasoning into machine\ntranslation (MT), where human translators naturally employ structured,\nmulti-layered reasoning chain-of-thoughts (CoTs), is yet underexplored.\nExisting methods either design a fixed CoT tailored for a specific MT sub-task\n(e.g., literature translation), or rely on synthesizing CoTs unaligned with\nhumans, limiting their adaptability to diverse translation scenarios. This\npaper introduces R1-Translator (R1-T1), a novel framework to achieve\ninference-time reasoning for general MT via reinforcement learning (RL) with\nhuman-aligned CoTs comprising six common patterns. Our approach pioneers three\ninnovations: (1) extending reasoning-based translation beyond MT sub-tasks to\nsix languages and diverse tasks (e.g., legal\/medical domain adaptation, idiom\nresolution); (2) formalizing six expert-curated CoT templates that mirror\nhybrid human strategies like context-aware paraphrasing and back translation;\nand (3) enabling self-evolving CoT discovery through RL. Experimental results\nindicate a steady translation performance improvement in 11 languages and 40\ntranslation directions on Flores-101 test set, especially on the languages\nunseen from training."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-579",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08827"
    ],
    "b_title":[
      "CHEmical-shift selective Adiabatic Pulse (CHEAP): Fast and High\n  Resolution Downfield 3D 1H-MRSI at 7T"
    ],
    "b_abstract":[
      "The key molecules such as triphosphate (ATP), glutathione (GSH), and\nhomocarnosine (hCs) - central to metabolic processes in the human brain remain\nelusive or challenging to detect with upfield 1H-MRSI. Traditional 3D 1H-MRSI\nin vivo faces challenges, including a low signal-to-noise ratio and\nmagnetization transfer effects with water, leading to prolonged measurement\ntimes and reduced resolution. To address these limitations, we propose a\ndownfield 3D-MRSI method aimed at measuring downfield metabolites with enhanced\nspatial resolution, and speed acceptable for clinical practice at 7T. The\nCHEmical-shift selective Adiabatic Pulse (CHEAP) technique was integrated into\necho-planar spectroscopic imaging (EPSI) readout sequence for downfield\nmetabolite and water reference 3D-MRSI. Five healthy subjects and two glioma\npatients were scanned to test the feasibility. In this work, CHEAP-EPSI\ntechnique is shown to significantly enhance spatial the resolution to 0.37 ml\nwhile simultaneously reducing the scan time to 10.5 minutes. Its distinct\nadvantages include low specific absorption rate, effective suppression of water\nand lipid signals, and minimal baseline distortions, making it a valuable tool\nfor research or potentially diagnostic purposes. CHEAP-EPSI improves the\ndetection sensitivity of downfield metabolites like N-acetyl-aspartate (NAA+)\nand DF8.18 (ATP&GSH+), and offers new possibilities for the study of metabolism\nin healthy and diseased brain."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14449"
    ],
    "c_title":[
      "Bohmian Mechanics fails to compute multi-time correlations"
    ],
    "c_abstract":[
      "The violation of Bell type inequalities in quantum systems manifests that\nquantum states cannot be described by classical probability distributions. Yet,\nBohmian mechanics is a realistic, non-local theory of classical particle\ntrajectories that is claimed to be indistinguishable by observations from more\ntraditional approaches to quantum mechanics. We set up a spatial version of the\nGHZ system with qubits realised as positional observables that demonstrates\nthat the Bohmian theory fails to match predictions of textbook quantum\nmechanics (and most likely experients) unless enlarged by a microscopic theory\nof collapse of the wave function after observation. For this discrepancy to\noccur it is essential that positions at different times do not commute."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "physics.hist-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-580",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12602"
    ],
    "b_title":[
      "Learning-based Dynamic Robot-to-Human Handover"
    ],
    "b_abstract":[
      "This paper presents a novel learning-based approach to dynamic robot-to-human\nhandover, addressing the challenges of delivering objects to a moving receiver.\nWe hypothesize that dynamic handover, where the robot adjusts to the receiver's\nmovements, results in more efficient and comfortable interaction compared to\nstatic handover, where the receiver is assumed to be stationary. To validate\nthis, we developed a nonparametric method for generating continuous handover\nmotion, conditioned on the receiver's movements, and trained the model using a\ndataset of 1,000 human-to-human handover demonstrations. We integrated\npreference learning for improved handover effectiveness and applied impedance\ncontrol to ensure user safety and adaptiveness. The approach was evaluated in\nboth simulation and real-world settings, with user studies demonstrating that\ndynamic handover significantly reduces handover time and improves user comfort\ncompared to static methods. Videos and demonstrations of our approach are\navailable at https:\/\/zerotohero7886.github.io\/dyn-r2h-handover ."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.04096"
    ],
    "c_title":[
      "Non-stop Variability of Sgr A* using JWST at 2.1 and 4.8 micron\n  Wavelengths: Evidence for Distinct Populations of Faint and Bright Variable\n  Emission"
    ],
    "c_abstract":[
      "We present first results of JWST Cycle 1 and 2 observations of Sgr A* using\nNIRCam taken simultaneously at 2.1 and 4.8 micron for a total of ~48 hours over\nseven different epochs in 2023 and 2024. We find correlated variability at 2.1\nand 4.8 micron in all epochs, continual short-time scale (a few seconds)\nvariability and epoch-to-epoch variable emission implying long-term ( ~days to\nmonths) variability of Sgr A*. A highlight of this analysis is the evidence for\nsub-minute, horizon-scale time variability of Sgr A*, probing inner accretion\ndisk size scales. The power spectra of the light curves in each observing epoch\nalso indicate long-term variable emission. With continuous observations, JWST\ndata suggest that the flux of Sgr A* is fluctuating constantly. The flux\ndensity correlation exhibits a distinct break in the slope at ~3 mJy at 2.1\nmicron. The analysis indicates two different processes contributing to the\nvariability of Sgr A*. Brighter emission trends towards shallower spectral\nindices than the fainter emission. Cross correlation of the light curves\nindicates for the first time, a time delay of 3 - 40 sec in the 4.8 micron\nvariability with respect to 2.1 micron. This phase shift leads to loops in\nplots of flux density vs spectral index as the emission rises and falls.\nModeling suggests that the synchrotron emission from the evolving,\nage-stratified electron population reproduces the shape of the observed light\ncurves with a direct estimate of the magnetic field strengths in the range\nbetween 40-90 G, and upper cutoff energy, E_c, between 420 and 720 MeV."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-581",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10512"
    ],
    "b_title":[
      "Conformal Prediction Sets for Deep Generative Models via Reduction to\n  Conformal Regression"
    ],
    "b_abstract":[
      "We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16958"
    ],
    "c_title":[
      "Thermodynamically consistent lattice Monte Carlo method for active\n  particles"
    ],
    "c_abstract":[
      "Recent years have seen a growing interest in the thermodynamic cost of\ndissipative structures formed by active particles. Given the strong finite-size\neffects of such systems, it is essential to develop efficient numerical\napproaches that discretize both space and time while preserving the original\ndynamics and thermodynamics of active particles in the continuum limit. To\naddress this challenge, we propose two thermodynamically consistent kinetic\nMonte Carlo methods for active lattice gases, both of which correctly reproduce\nthe continuum dynamics. One method follows the conventional Kawasaki dynamics,\nwhile the other incorporates an extra state-dependent prefactor in the\ntransition rate to more accurately capture the self-propulsion velocity. We\nfind that the error scales linearly with time step size and that the\nstate-dependent prefactor improves accuracy at high P\\'{e}clet numbers by a\nfactor of $\\mathrm{Pe}^2$. Our results are supported by rigorous proof of\nconvergence as well as extensive simulations."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-582",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01756"
    ],
    "b_title":[
      "Stueckelberg field and Cosmology"
    ],
    "b_abstract":[
      "Stueckelberg introduced an axion like scalar field to provide mass to the\ngauge electromagnetic field without breaking gauge invariance. This can be\nconsidered as a precursor to the spontaneously broken abelian Higgs model. We\nwill consider its role in cosmology to provide a novel candidate to the dark\nmatter question. In addition its implications to deeper issues will be pointed\nout."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.13054"
    ],
    "c_title":[
      "STMDNet: A Lightweight Directional Framework for Motion Pattern\n  Recognition of Tiny Targets"
    ],
    "c_abstract":[
      "Recognizing motions of tiny targets - only few dozen pixels - in cluttered\nbackgrounds remains a fundamental challenge when standard feature-based or deep\nlearning methods fail under scarce visual cues. We propose STMDNet, a\nmodel-based computational framework to Recognize motions of tiny targets at\nvariable velocities under low-sampling frequency scenarios. STMDNet designs a\nnovel dual-dynamics-and-correlation mechanism, harnessing ipsilateral\nexcitation to integrate target cues and leakage-enhancing-type contralateral\ninhibition to suppress large-object and background motion interference.\nMoreover, we develop the first collaborative directional encoding-decoding\nstrategy that determines the motion direction from only one correlation per\nspatial location, cutting computational costs to one-eighth of prior methods.\nFurther, simply substituting the backbone of a strong STMD model with STMDNet\nraises AUC by 24%, yielding an enhanced STMDNet-F. Evaluations on real-world\nlow sampling frequency datasets show state-of-the-art results, surpassing the\ndeep learning baseline. Across diverse speeds, STMDNet-F improves mF1 by 19%,\n16%, and 8% at 240Hz, 120Hz, and 60Hz, respectively, while STMDNet achieves 87\nFPS on a single CPU thread. These advances highlight STMDNet as a\nnext-generation backbone for tiny target motion pattern recognition and\nunderscore its broader potential to revitalize model-based visual approaches in\nmotion detection."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-583",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08747"
    ],
    "b_title":[
      "Every group is the automorphism group of a graph with arbitrarily large\n  genus"
    ],
    "b_abstract":[
      "We prove that, to every abstract group $G$, we can associate a sequence of\ngraphs $\\Gamma_n$ such that the automorphism group of $\\Gamma_n$ is isomorphic\nto $G$ and the genus of $\\Gamma_n$ is an unbounded function of $n$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.05210"
    ],
    "c_title":[
      "Regression and Forecasting of U.S. Stock Returns Based on LSTM"
    ],
    "c_abstract":[
      "This paper analyses the investment returns of three stock sectors, Manuf,\nHitec, and Other, in the U.S. stock market, based on the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model, in order to test the validity of the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model for the three sectors of the market. French five-factor model\nfor the three sectors of the market. Also, the LSTM model is used to explore\nthe additional factors affecting stock returns. The empirical results show that\nthe Fama-French five-factor model has better validity for the three segments of\nthe market under study, and the LSTM model has the ability to capture the\nfactors affecting the returns of certain industries, and can better regress and\npredict the stock returns of the relevant industries. Keywords- Fama-French\nmodel; Carhart model; Factor model; LSTM model."
    ],
    "c_categories":[
      [
        "cs.LG",
        "q-fin.ST"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-584",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09028"
    ],
    "b_title":[
      "Second-order derivations of functions spaces -- a characterization of\n  second-order differential operators"
    ],
    "b_abstract":[
      "Let $\\Omega \\subset \\mathbb{R}$ be a nonempty and open set, then for all $f,\ng, h\\in \\mathscr{C}^{2}(\\Omega)$ we have \\begin{multline*}\n\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot g\\cdot h) -\nf\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(g\\cdot\nh)-g\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot\nh)-h\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot g) + f\\cdot\ng\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}} h+f\\cdot\nh\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}} g+g\\cdot h\n\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}f=0 \\end{multline*} The aim of this\npaper is to consider the corresponding operator equation \\[D(f\\cdot g \\cdot h)\n- fD(g\\cdot h) - gD(f\\cdot h) - hD(f \\cdot g) + f\\cdot g D(h) + f\\cdot h D(g)\n+g\\cdot h D(f) = 0\\] for operators $D\\colon \\mathscr{C}^{k}(\\Omega)\\to\n\\mathscr{C}(\\Omega)$, where $k$ is a given nonnegative integer and the above\nidentity is supposed to hold for all $f, g, h \\in \\mathscr{C}^{k}(\\Omega)$. We\nshow that besides the operators of first and second derivative, there are more\nsolutions to this equation. Some special cases characterizing differential\noperators are also studied."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.11241"
    ],
    "c_title":[
      "Compound Expression Recognition via Large Vision-Language Models"
    ],
    "c_abstract":[
      "Compound Expression Recognition (CER) is crucial for understanding human\nemotions and improving human-computer interaction. However, CER faces\nchallenges due to the complexity of facial expressions and the difficulty of\ncapturing subtle emotional cues. To address these issues, we propose a novel\napproach leveraging Large Vision-Language Models (LVLMs). Our method employs a\ntwo-stage fine-tuning process: first, pre-trained LVLMs are fine-tuned on basic\nfacial expressions to establish foundational patterns; second, the model is\nfurther optimized on a compound-expression dataset to refine visual-language\nfeature interactions. Our approach achieves advanced accuracy on the RAF-DB\ndataset and demonstrates strong zero-shot generalization on the C-EXPR-DB\ndataset, showcasing its potential for real-world applications in emotion\nanalysis and human-computer interaction."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-585",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15223"
    ],
    "b_title":[
      "Efficient and Interpretable Neural Networks Using Complex Lehmer\n  Transform"
    ],
    "b_abstract":[
      "We propose an efficient and interpretable neural network with a novel\nactivation function called the weighted Lehmer transform. This new activation\nfunction enables adaptive feature selection and extends to the complex domain,\ncapturing phase-sensitive and hierarchical relationships within data. Notably,\nit provides greater interpretability and transparency compared to existing\nmachine learning models, facilitating a deeper understanding of its\nfunctionality and decision-making processes. We analyze the mathematical\nproperties of both real-valued and complex-valued Lehmer activation units and\ndemonstrate their applications in modeling nonlinear interactions. Empirical\nevaluations demonstrate that our proposed neural network achieves competitive\naccuracy on benchmark datasets with significantly improved computational\nefficiency. A single layer of real-valued or complex-valued Lehmer activation\nunits is shown to deliver state-of-the-art performance, balancing efficiency\nwith interpretability."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09908"
    ],
    "c_title":[
      "Rigorous lower bound of the dynamical critical exponent of the Ising\n  model"
    ],
    "c_abstract":[
      "To date, the best known bound of the dynamic critical exponent $z$ of the\n$d$-dimensional kinetic Ising model is $z\\geq 2-\\eta$. We rigorously improve\nthis bound to $z\\geq 2$."
    ],
    "c_categories":[
      [
        "cond-mat.other",
        "cond-mat.stat-mech",
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-586",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03644"
    ],
    "b_title":[
      "Finite length for unramified $\\mathrm{GL}_2$"
    ],
    "b_abstract":[
      "Let $p$ be a prime number and $K$ a finite unramified extension of\n$\\mathbb{Q}_p$. If $p$ is large enough with respect to $[K:\\mathbb{Q}_p]$ and\nunder mild genericity assumptions, we prove that the admissible smooth\nrepresentations of $\\mathrm{GL}_2(K)$ that occur in Hecke eigenspaces of the\nmod $p$ cohomology are of finite length. We also prove many new structural\nresults about these representations of $\\mathrm{GL}_2(K)$ and their\nsubquotients."
    ],
    "b_categories":[
      [
        "math.NT",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.05663"
    ],
    "c_title":[
      "Learning to Measure Quantum Neural Networks"
    ],
    "c_abstract":[
      "The rapid progress in quantum computing (QC) and machine learning (ML) has\nattracted growing attention, prompting extensive research into quantum machine\nlearning (QML) algorithms to solve diverse and complex problems. Designing\nhigh-performance QML models demands expert-level proficiency, which remains a\nsignificant obstacle to the broader adoption of QML. A few major hurdles\ninclude crafting effective data encoding techniques and parameterized quantum\ncircuits, both of which are crucial to the performance of QML models.\nAdditionally, the measurement phase is frequently overlooked-most current QML\nmodels rely on pre-defined measurement protocols that often fail to account for\nthe specific problem being addressed. We introduce a novel approach that makes\nthe observable of the quantum system-specifically, the Hermitian\nmatrix-learnable. Our method features an end-to-end differentiable learning\nframework, where the parameterized observable is trained alongside the ordinary\nquantum circuit parameters simultaneously. Using numerical simulations, we show\nthat the proposed method can identify observables for variational quantum\ncircuits that lead to improved outcomes, such as higher classification\naccuracy, thereby boosting the overall performance of QML models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-587",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18904"
    ],
    "b_title":[
      "An Empirical Study on Commit Message Generation using LLMs via\n  In-Context Learning"
    ],
    "b_abstract":[
      "Commit messages concisely describe code changes in natural language and are\nimportant for software maintenance. Several approaches have been proposed to\nautomatically generate commit messages, but they still suffer from critical\nlimitations, such as time-consuming training and poor generalization ability.\nTo tackle these limitations, we propose to borrow the weapon of large language\nmodels (LLMs) and in-context learning (ICL). Our intuition is based on the fact\nthat the training corpora of LLMs contain extensive code changes and their\npairwise commit messages, which makes LLMs capture the knowledge about commits,\nwhile ICL can exploit the knowledge hidden in the LLMs and enable them to\nperform downstream tasks without model tuning. However, it remains unclear how\nwell LLMs perform on commit message generation via ICL. In this paper, we\nconduct an empirical study to investigate the capability of LLMs to generate\ncommit messages via ICL. Specifically, we first explore the impact of different\nsettings on the performance of ICL-based commit message generation. We then\ncompare ICL-based commit message generation with state-of-the-art approaches on\na popular multilingual dataset and a new dataset we created to mitigate\npotential data leakage. The results show that ICL-based commit message\ngeneration significantly outperforms state-of-the-art approaches on subjective\nevaluation and achieves better generalization ability. We further analyze the\nroot causes for LLM's underperformance and propose several implications, which\nshed light on future research directions for using LLMs to generate commit\nmessages."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08018"
    ],
    "c_title":[
      "Scaling of wall-pressure--velocity correlations in high Reynolds number\n  turbulent pipe flow"
    ],
    "c_abstract":[
      "An experimental study was conducted in the CICLoPE long-pipe facility to\ninvestigate the correlation between wall-pressure and turbulent velocity\nfluctuations in the logarithmic region, at high friction Reynolds numbers\n($4\\,794 \\lesssim Re_\\tau \\lesssim 47\\,015$). Hereby we explore the scalability\nof employing wall-pressure to effectively estimate off-the-wall velocity states\n(e.g., to be of use in real-time control of wall-turbulence). Coherence spectra\nfor wall-pressure and streamwise (or wall-normal) velocity fluctuations\ncollapse when plotted against $\\lambda_x\/y$ and thus reveals a\nReynolds-number-independent scaling with distance-from-the-wall. When the\nsquared wall-pressure fluctuations are considered instead of the linear\nwall-pressure term, the coherence spectra for the wall-pressure--squared and\nvelocity are higher in amplitude at wavelengths corresponding to large-scale\nstreamwise velocity fluctuations (e.g., at $\\lambda_x\/y = 60$ the coherence\nvalue increases from roughly 0.1 up to 0.3). This higher coherence typifies a\nmodulation effect, because low-frequency content is introduced when squaring\nthe wall-pressure time series. Finally, quadratic stochastic estimation is\nemployed to estimate turbulent velocity fluctuations from the wall-pressure\ntime series only. For each $Re_\\tau$ investigated, the estimated time series\nand a true temporal measurement of velocity inside the turbulent pipe flow,\nyield a normalized correlation coefficient of $\\rho \\approx 0.6$ for all cases.\nThis suggests that wall-pressure sensing can be employed for meaningful\nestimation of off-the-wall velocity fluctuations, and thus for real-time\ncontrol of energetic turbulent velocity fluctuations at high $Re_\\tau$\napplications."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-588",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16805"
    ],
    "b_title":[
      "Martians Among Us: Observing Private or Reserved IPs on the Public\n  Internet"
    ],
    "b_abstract":[
      "Spoofed traffic has been identified as one of the main issues of concern for\nnetwork hygiene nowadays, as it facilitates Distributed Denial-of-Service\n(DDoS) attacks by hiding their origin and complicating forensic investigations.\nSome indicators of poor network hygiene are packets with Bogon or Martian\nsource addresses representing either misconfigurations or spoofed packets.\nDespite the development of Source Address Validation (SAV) techniques and\nguidelines such as BCP 38 and BCP 84, Bogons are often overlooked in the\nfiltering practices of network operators. This study uses traceroute\nmeasurements from the CAIDA Ark dataset, enriched with historical BGP routing\ninformation from RIPE RIS and RouteViews, to investigate the prevalence of\nBogon addresses over seven years (2017-2023). Our analysis reveals widespread\nnon-compliance with best practices, with Bogon traffic detected across\nthousands of ASes. Notably, 82.69%-97.83% of CAIDA Ark vantage points observe\npaths containing Bogon IPs, primarily RFC1918 addresses. Additionally, 19.70%\nof all analyzed traceroutes include RFC1918 addresses, while smaller\nproportions involve RFC6598 (1.50%) and RFC3927 (0.10%) addresses. We identify\nmore than 13,000 unique ASes transiting Bogon traffic, with only 11.64%\nappearing in more than half of the measurements. Cross-referencing with the\nSpoofer project and MANRS initiatives shows a concerning gap: 62.67% of ASes\nthat do not filter packets with Bogon sources are marked as non-spoofable,\nsuggesting incomplete SAV implementation. Our contributions include an\nassessment of network hygiene using the transiting of Bogon packets as a\nmetric, an analysis of the main types of Bogon addresses found in traceroutes,\nand several proposed recommendations to address the observed gaps, enforcing\nthe need for stronger compliance with best practices to improve global network\nsecurity."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19957"
    ],
    "c_title":[
      "Unveiling individual and collective temporal patterns in the tanker\n  shipping network"
    ],
    "c_abstract":[
      "The global shipping network, which moves over 80% of the world's goods, is\nnot only a vital backbone of the global economy but also one of the most\npolluting industries. Studying how this network operates is crucial for\nimproving its efficiency and sustainability. While the transport of solid goods\nlike packaged products and raw materials has been extensively researched, far\nless is known about the competitive trade of crude oil and petroleum, despite\nthese commodities accounting for nearly 30% of the market. Using 4 years of\nhigh-resolution data on oil tanker movements, we employ sequential motif mining\nand dynamic mode decomposition to uncover global spatio-temporal patterns in\nthe movement of individual ships. Across all ship classes, we demonstrate that\nmaximizing the proportion of time ships spend carrying cargo -- a metric of\nefficiency -- is achieved through strategic diversification of routes and the\neffective use of intra-regional ports for trips without cargo. Moreover, we\nuncover a globally stable travel structure in the fleet, with pronounced\nseasonal variations linked to annual and semi-annual regional climate patterns\nand economic cycles. Our findings highlight the importance of integrating\nhigh-resolution data with innovative analysis methods not only to improve our\nunderstanding of the underlying dynamics of shipping patterns, but to design\nand evaluate strategies aimed at reducing their environmental impact."
    ],
    "c_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-589",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12453"
    ],
    "b_title":[
      "Shape Bias and Robustness Evaluation via Cue Decomposition for Image\n  Classification and Segmentation"
    ],
    "b_abstract":[
      "Previous works studied how deep neural networks (DNNs) perceive image content\nin terms of their biases towards different image cues, such as texture and\nshape. Previous methods to measure shape and texture biases are typically\nstyle-transfer-based and limited to DNNs for image classification. In this\nwork, we provide a new evaluation procedure consisting of 1) a\ncue-decomposition method that comprises two AI-free data pre-processing methods\nextracting shape and texture cues, respectively, and 2) a novel\ncue-decomposition shape bias evaluation metric that leverages the\ncue-decomposition data. For application purposes we introduce a corresponding\ncue-decomposition robustness metric that allows for the estimation of the\nrobustness of a DNN w.r.t. image corruptions. In our numerical experiments, our\nfindings for biases in image classification DNNs align with those of previous\nevaluation metrics. However, our cue-decomposition robustness metric shows\nsuperior results in terms of estimating the robustness of DNNs. Furthermore,\nour results for DNNs on the semantic segmentation datasets Cityscapes and\nADE20k for the first time shed light into the biases of semantic segmentation\nDNNs."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02732"
    ],
    "c_title":[
      "Micro\/nanoscale spacers for enhanced thermophotovoltaic and thermionic\n  energy conversion: a comprehensive review"
    ],
    "c_abstract":[
      "Thermionics and thermophotovoltaics are solid-state technologies that convert\nhigh-temperature heat into electricity by utilizing fundamental particles,\nelectrons in thermionics and photons in thermophotovoltaics, as energy\ncarriers. Both systems have the potential to achieve high efficiency and power\ndensity, contingent on the optimization of radiative\/electronic energy fluxes.\nA critical factor in enhancing energy flux in these devices is the introduction\nof microscale (thermionics) or nanoscale (thermophotovoltaics) gaps between the\nhot thermal emitter and the cooler receiver. In thermionic converters,\nmicroscale gaps mitigate space charge effects that create energy barriers to\nelectron flow. For thermophotovoltaic systems, nanoscale gaps facilitate photon\ntunneling, significantly boosting photon flux towards the thermophotovoltaic\ncell. Forming these small-scale gaps often necessitates intermediate materials\nor spacers between the emitter and receiver. Over the past few decades, various\nspacer designs have been proposed and studied, demonstrating their\neffectiveness in enhancing energy transfer and conversion. However, challenges\nremain regarding their reliability and scalability. This article provides a\ncomprehensive overview of spacer technologies for thermionics and\nthermophotovoltaics and summarizes recent advancements, current capabilities,\nand persistent challenges."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-590",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06957"
    ],
    "b_title":[
      "A Spectral Theory of Scalar Volterra Equations"
    ],
    "b_abstract":[
      "Volterra integral and integro-differential equations have been extensively\nstudied in both pure mathematics and applied science. In one direction,\ndevelopments in analysis have yielded far-ranging existence, uniqueness, and\nregularity results. In the other, applications in science have inspired a\nsubstantial library of practical techniques to deal with such equations.\n  The present work connects these research areas by examining five large\nclasses of linear Volterra equations: integral and integro-differential\nequations with completely monotone (CM) kernels, corresponding to linear\nviscoelastic models; those with positive definite (PD) kernels, corresponding\nto partially-observed quantum systems; difference equations with PD kernels; a\nclass of generalized delay differential equations; and a class of generalized\nfractional differential equations. We develop a system of correspondences\nbetween these problems, showing that all five can be understood within the\nsame, spectral theory. We leverage this theory to recover practical,\nclosed-form solutions of all five classes, and we show that interconversion\nyields a natural, continuous involution within each class. Our work unifies\nseveral results from science: the interconversion formula of Gross, recent\nresults in viscoelasticity and operator theory for integral equations of the\nsecond type, classical formulas for Prony series and fractional differential\nequations, and the convergence of Prony series to CM kernels. Finally, our\ntheory yields a novel, geometric construction of the regularized Hilbert\ntransform, extends it to a wide class of infinite measures, and reveals a\nnatural connection to delay and fractional differential equations.\n  We leverage our theory to develop a powerful, spectral method to handle\nscalar Volterra equations numerically, and illustrate it with a number of\npractical examples."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.DS",
        "math.SP",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20198"
    ],
    "c_title":[
      "Optics of Plasmon-Exciton Nanostructures: Theoretical Models and\n  Physical Phenomena in Metal\/J-aggregate Systems"
    ],
    "c_abstract":[
      "We review the studies of a wide range of optical phenomena resulting from\nnear-field coupling between excitons and localized surface plasmon-polaritons\nin hybrid nanostructures. Modern physical approaches and theoretical models\nreported here for the description of light absorption, scattering, and\nextinction spectra are appropriate for interpreting physical effects in\nnanosystems containing metals and various excitonic materials, such as\nmolecular aggregates of organic dyes or inorganic quantum-confined\nsemiconductor structures. Using the example of hybrid nanosystems composed of a\nmetal core and an outer shell of dye J-aggregate, we perform a theoretical\nanalysis of the optical spectra behavior in the regimes of weak, strong, and\nultrastrong plasmon--exciton coupling. We consider resonance and antiresonance\nphenomena induced by the coupling of an exciton with dipole and multipole\nplasmons, including a pronounced dip in light absorption, as well as the\nspectral band replication effect of plexcitonic nanoparticles and their dimers.\nWe discuss the significant roles of the size-dependent permittivity of the\nmetal core, the effects of anisotropy and chirality of the excitonic\nJ-aggregate shell, and the influence of an intermediate passive layer on the\nformation of the optical spectra of bilayer, trilayer, and multilayer\nnanoparticles. The review outlines the experimental and theoretical results for\nhybrid nanosystems of various geometrical shapes, sizes, and compositions,\nbroadens our understanding of the physical phenomena caused by the\nplasmon--exciton coupling, and represents the current state of research in the\noptics of metalorganic nanostructures."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-591",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04968"
    ],
    "b_title":[
      "Gravitational waves from r-mode oscillations of stochastically accreting\n  neutron stars"
    ],
    "b_abstract":[
      "$r$-mode oscillations in rotating neutron stars are a source of continuous\ngravitational radiation. We investigate the excitation of $r$-modes by the\nmechanical impact on the neutron star surface of stochastically accreted clumps\nof matter, assuming that the Chandrasekhar-Friedman-Schutz instability is not\ntriggered. The star is idealised as a slowly-rotating, unmagnetised,\none-component fluid with a barotropic equation of state in Newtonian gravity.\nIt is found that the $r$-mode amplitude depends weakly on the equation of state\nbut sensitively on the rotation frequency $\\nu_{\\rm s}$. The gravitational wave\nstrain implicitly depends on the equation of state through the damping\ntimescale. The root-mean-square strain is $h_{\\rm rms} \\approx 10^{-35}\n(\\nu_{\\rm s}\/ 10 {\\rm Hz})^{2} (R_*\/10 {\\rm km})^2 (\\Delta t_{\\rm acc}\/1 {\\rm\nyr})^{1\/2} (f_{\\rm acc}\/1 {\\rm kHz})^{-1\/2} (\\dot{M}\/10^{-8} \\text{M}_{\\odot}\n\\text{yr}^{-1}) (v\/0.4c) (d\/1 {\\rm kpc})^{-1}$, which is comparable to the\nstrain from $g$-, $p$- and $f$-modes excited by stochastic accretion, where\n$R_*$ is the radius of the star, $\\Delta t_{\\rm acc}$ is the uninterrupted\nduration of an accretion episode, $f_{\\rm acc}$ is the mean clump impact\nfrequency, $\\dot{M}$ is the accretion rate, $v$ is the impact speed, and $d$ is\nthe distance of the star from the Earth. An observational test is proposed,\nbased on the temporal autocorrelation function of the gravitational wave\nsignal, to discern whether the Chandrasekhar-Friedman-Schutz instability\nswitches on and coexists with impact-excited $r$-modes before or during a\ngravitational wave observation."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08935"
    ],
    "c_title":[
      "Topological sheaves and spaces of distributions in the global case"
    ],
    "c_abstract":[
      "We extend the theory of fields\/distributions developed the paper \"A\nFeigin-Frenkel theorem with n singularities\" to a general base scheme. In order\nto do so we introduce suitable notions of topological sheaves on schemes and\nstudy their basic properties. We then construct appropriate analogues of the\nspaces of fields, consider multiplication of fields between them and rebuild\nthe basic theory of vertex algebras in the setting of global distributions in\nplace of formal power series, which takes the form of chiral algebras\nintroduced Beilinson and Drinfeld in \"Chiral Algebras\"."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-592",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00319"
    ],
    "b_title":[
      "Current-driven collective control of helical spin texture in van der\n  Waals antiferromagnet"
    ],
    "b_abstract":[
      "Electrical control of quantum magnetic states is essential in spintronic\nscience. Initial studies on the ferromagnetic state control were extended to\ncollinear antiferromagnets and, more recently, noncollinear antiferromagnets.\nHowever, electrical control mechanisms of such exotic magnetic states remain\npoorly understood. Here, we report the first experimental and theoretical\nexample of the current control of helical antiferromagnets, arising from the\ncompetition between collinear antiferromagnetic exchange and interlayer\nDzyaloshinskii-Moriya interaction in new van-der-Waals (vdW) material\nNi1\/3NbS2. Due to the intrinsic broken inversion symmetry, an in-plane current\ngenerates spin-orbit torque that, in turn, interacts directly with the helical\nantiferromagnetic order. Our theoretical analyses indicate that a weak\nferromagnetic order coexists due to the Dzyaloshinskii-Moriya interaction,\nmediating the spin-orbit torque to collectively rotate the helical\nantiferromagnetic order. Our Ni1\/3NbS2 nanodevice experiments produce\ncurrent-dependent resistance change consistent with the theoretical prediction.\nThis work widens our understanding of the electrical control of helical\nantiferromagnets and promotes vdW quantum magnets as interesting material\nplatforms for electrical control."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.other",
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.02430"
    ],
    "c_title":[
      "A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals"
    ],
    "c_abstract":[
      "Web refresh crawling is the problem of keeping a cache of web pages fresh,\nthat is, having the most recent copy available when a page is requested, given\na limited bandwidth available to the crawler. Under the assumption that the\nchange and request events, resp., to each web page follow independent Poisson\nprocesses, the optimal scheduling policy was derived by Azar et al. 2018. In\nthis paper, we study an extension of this problem where side information\nindicating content changes, such as various types of web pings, for example,\nsignals from sitemaps, content delivery networks, etc., is available.\nIncorporating such side information into the crawling policy is challenging,\nbecause (i) the signals can be noisy with false positive events and with\nmissing change events; and (ii) the crawler should achieve a fair performance\nover web pages regardless of the quality of the side information, which might\ndiffer from web page to web page. We propose a scalable crawling algorithm\nwhich (i) uses the noisy side information in an optimal way under mild\nassumptions; (ii) can be deployed without heavy centralized computation; (iii)\nis able to crawl web pages at a constant total rate without spikes in the total\nbandwidth usage over any time interval, and automatically adapt to the new\noptimal solution when the total bandwidth changes without centralized\ncomputation. Experiments clearly demonstrate the versatility of our approach."
    ],
    "c_categories":[
      [
        "cs.IR",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-593",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04637"
    ],
    "b_title":[
      "Effective action for relativistic hydrodynamics from Crooks fluctuation\n  theorem"
    ],
    "b_abstract":[
      "A new effective theory framework for fluctuating hydrodynamics in the\nrelativistic regime is derived using standard thermodynamical principles and\ngeneral properties of non-equilibrium stochastic dynamics. For the first time,\nwe establish clear and concise conditions for ensuring that the resulting\neffective theories are causal, stable, and well-posed within general\nrelativity. These properties are independent of spacetime foliation and are\nvalid in the full nonlinear regime. Out-of-equilibrium fluctuations are\nconstrained by a relativistically covariant version of Crooks fluctuation\ntheorem, which determines how the entropy production is distributed even when\nthe system is driven by an external force. This leads to an emerging\n$\\mathbb{Z}_2$ symmetry responsible for imposing fluctuation-dissipation\nrelations for n-point correlation functions, which matches the standard\nconstraints for the Schwinger-Keldysh effective action."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17175"
    ],
    "c_title":[
      "Linear Bandits on Ellipsoids: Minimax Optimal Algorithms"
    ],
    "c_abstract":[
      "We consider linear stochastic bandits where the set of actions is an\nellipsoid. We provide the first known minimax optimal algorithm for this\nproblem. We first derive a novel information-theoretic lower bound on the\nregret of any algorithm, which must be at least $\\Omega(\\min(d \\sigma \\sqrt{T}\n+ d \\|\\theta\\|_{A}, \\|\\theta\\|_{A} T))$ where $d$ is the dimension, $T$ the\ntime horizon, $\\sigma^2$ the noise variance, $A$ a matrix defining the set of\nactions and $\\theta$ the vector of unknown parameters. We then provide an\nalgorithm whose regret matches this bound to a multiplicative universal\nconstant. The algorithm is non-classical in the sense that it is not\noptimistic, and it is not a sampling algorithm. The main idea is to combine a\nnovel sequential procedure to estimate $\\|\\theta\\|$, followed by an\nexplore-and-commit strategy informed by this estimate. The algorithm is highly\ncomputationally efficient, and a run requires only time $O(dT + d^2 \\log(T\/d) +\nd^3)$ and memory $O(d^2)$, in contrast with known optimistic algorithms, which\nare not implementable in polynomial time. We go beyond minimax optimality and\nshow that our algorithm is locally asymptotically minimax optimal, a much\nstronger notion of optimality. We further provide numerical experiments to\nillustrate our theoretical findings."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-594",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11724"
    ],
    "b_title":[
      "Proportion of Nilpotent Subgroups in Finite Groups and Their Properties"
    ],
    "b_abstract":[
      "This work introduces and investigates the function $J(G) =\n\\frac{\\text{Nil}(G)}{L(G)}$, where $\\text{Nil}(G)$ denotes the number of\nnilpotent subgroups and $L(G)$ the total number of subgroups of a finite group\n$G$. The function $J(G)$, defined over the interval $(0,1]$, serves as a tool\nto analyze structural patterns in finite groups, particularly within\nnon-nilpotent families such as supersolvable and dihedral groups. Analytical\nresults demonstrate the product density of $J(G)$ values in $(0,1]$,\nhighlighting its distribution across products of dihedral groups. Additionally,\na probabilistic analysis was conducted, and based on extensive computational\nsimulations, it was conjectured that the sample mean of $J(G)$ values converges\nin distribution to the standard normal distribution, in accordance with the\nCentral Limit Theorem, as the sample size increases. These findings expand the\nunderstanding of multiplicative functions in group theory, offering novel\ninsights into the structural and probabilistic behavior of finite groups."
    ],
    "b_categories":[
      [
        "math.GR",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.05178"
    ],
    "c_title":[
      "QLIP: Text-Aligned Visual Tokenization Unifies Auto-Regressive\n  Multimodal Understanding and Generation"
    ],
    "c_abstract":[
      "We introduce Quantized Language-Image Pretraining (QLIP), a visual\ntokenization method that combines state-of-the-art reconstruction quality with\nstate-of-the-art zero-shot image understanding. QLIP trains a\nbinary-spherical-quantization-based autoencoder with reconstruction and\nlanguage-image alignment objectives. We are the first to show that the two\nobjectives do not need to be at odds. We balance the two loss terms dynamically\nduring training and show that a two-stage training pipeline effectively mixes\nthe large-batch requirements of image-language pre-training with the memory\nbottleneck imposed by the reconstruction objective. We validate the\neffectiveness of QLIP for multimodal understanding and text-conditioned image\ngeneration with a single model. Specifically, QLIP serves as a drop-in\nreplacement for the visual encoder for LLaVA and the image tokenizer for\nLlamaGen with comparable or even better performance. Finally, we demonstrate\nthat QLIP enables a unified mixed-modality auto-regressive model for\nunderstanding and generation."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-595",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17990"
    ],
    "b_title":[
      "SUNAR: Semantic Uncertainty based Neighborhood Aware Retrieval for\n  Complex QA"
    ],
    "b_abstract":[
      "Complex question-answering (QA) systems face significant challenges in\nretrieving and reasoning over information that addresses multi-faceted queries.\nWhile large language models (LLMs) have advanced the reasoning capabilities of\nthese systems, the bounded-recall problem persists, where procuring all\nrelevant documents in first-stage retrieval remains a challenge. Missing\npertinent documents at this stage leads to performance degradation that cannot\nbe remedied in later stages, especially given the limited context windows of\nLLMs which necessitate high recall at smaller retrieval depths. In this paper,\nwe introduce SUNAR, a novel approach that leverages LLMs to guide a\nNeighborhood Aware Retrieval process. SUNAR iteratively explores a neighborhood\ngraph of documents, dynamically promoting or penalizing documents based on\nuncertainty estimates from interim LLM-generated answer candidates. We validate\nour approach through extensive experiments on two complex QA datasets. Our\nresults show that SUNAR significantly outperforms existing retrieve-and-reason\nbaselines, achieving up to a 31.84% improvement in performance over existing\nstate-of-the-art methods for complex QA."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06131"
    ],
    "c_title":[
      "Nonlinearity-induced Fractional Thouless Pumping of Solitons"
    ],
    "c_abstract":[
      "Recent studies have shown that a soliton can be {\\it fractionally}\ntransported by slowly varying a system parameter over one period in a nonlinear\nsystem. This phenomenon is attributed to the nontrivial topology of the\ncorresponding energy bands of a linear Hamiltonian. Here we find the occurrence\nof fractional Thouless pumping of solitons in a nonlinear off-diagonal\nAubry-Andr\\'{e}-Harper model. Surprisingly, this happens despite the fact that\nall the energy bands of the linear Hamiltonian are topologically trivial,\nindicating that nonlinearity can induce fractional Thouless pumping of\nsolitons. Specifically, our results show that a soliton can be pumped across\none unit cell over one, two, three or four pump periods, implying an average\ndisplacement of $1$, $1\/2$, $1\/3$ or $1\/4$ unit cells per cycle, respectively.\nWe attribute these behaviors to changes in on-site potentials induced by a\nsoliton solution, leading to the nontrivial topology for the modified linear\nHamiltonian. Given that our model relies solely on varying nearest-neighbor\nhoppings, it is readily implementable on existing state-of-the-art photonic\nplatforms."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "nlin.PS",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-596",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09950"
    ],
    "b_title":[
      "Mixing rate exponent of planar Fortuin-Kasteleyn percolation"
    ],
    "b_abstract":[
      "Duminil-Copin and Manolescu (2022) recently proved the scaling relations for\nplanar Fortuin-Kasteleyn (FK) percolation. In particular, they showed that the\none-arm exponent and the mixing rate exponent are sufficient to derive the\nother near-critical exponents. The scaling limit of critical FK percolation is\nconjectured to be a conformally invariant random collection of loops called the\nconformal loop ensemble (CLE). In this paper, we define the CLE analog of the\nmixing rate exponent. Assuming the convergence of FK percolation to CLE, we\nshow that the mixing rate exponent for FK percolation agrees with that of CLE.\nWe prove that the CLE$_\\kappa$ mixing rate exponent equals $\\frac{3\n\\kappa}{8}-1$, thereby answering Question 3 of Duminil-Copin and Manolescu\n(2022). The derivation of the CLE exponent is based on an exact formula for the\nRadon-Nikodym derivative between the marginal laws of the odd-level and\neven-level CLE loops, which is obtained from the coupling between Liouville\nquantum gravity and CLE."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.06246"
    ],
    "c_title":[
      "AmazonNetLink: Enabling Education Access in Remote Amazonian Regions\n  through Delay-Tolerant Networks"
    ],
    "c_abstract":[
      "Access to educational materials in remote Amazonian communities is challenged\nby limited communication infrastructure. This paper proposes a novel\ndelay-tolerant network (DTN) approach for content distribution and compares the\nEpidemic, MaxProp, and PRoPHETv2 routing protocols using the ONE simulator\nunder dynamically changing educational file sizes. Results show that while\nEpidemic routing achieves higher delivery rates due to extensive message\nreplication, it also leads to increased resource usage. MaxProp offers a\nbalance between delivery efficiency and resource utilization by prioritizing\nmessage delivery based on predefined heuristics but struggles under high\ncongestion and resource constraints. PRoPHETv2, with its probability-based\nforwarding, uses resources more efficiently but is less effective in dynamic,\ndense networks. This analysis highlights trade-offs between delivery\nperformance and resource efficiency, guiding protocol selection for specific\ncommunity needs. In our future work, we aim to explore adaptive buffer\nmanagement and congestion-aware DTN protocols."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-597",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13506"
    ],
    "b_title":[
      "Reproducing NevIR: Negation in Neural Information Retrieval"
    ],
    "b_abstract":[
      "Negation is a fundamental aspect of human communication, yet it remains a\nchallenge for Language Models (LMs) in Information Retrieval (IR). Despite the\nheavy reliance of modern neural IR systems on LMs, little attention has been\ngiven to their handling of negation. In this study, we reproduce and extend the\nfindings of NevIR, a benchmark study that revealed most IR models perform at or\nbelow the level of random ranking when dealing with negation. We replicate\nNevIR's original experiments and evaluate newly developed state-of-the-art IR\nmodels. Our findings show that a recently emerging category - listwise Large\nLanguage Model (LLM) rerankers - outperforms other models but still\nunderperforms human performance. Additionally, we leverage ExcluIR, a benchmark\ndataset designed for exclusionary queries with extensive negation, to assess\nthe generalizability of negation understanding. Our findings suggest that\nfine-tuning on one dataset does not reliably improve performance on the other,\nindicating notable differences in their data distributions. Furthermore, we\nobserve that only cross-encoders and listwise LLM rerankers achieve reasonable\nperformance across both negation tasks."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15959"
    ],
    "c_title":[
      "Orbital-Free Density Functional Theory for Periodic Solids: Construction\n  of the Pauli Potential"
    ],
    "c_abstract":[
      "The practical success of density functional theory (DFT) is largely credited\nto the Kohn-Sham approach, which enables the exact calculation of the\nnon-interacting electron kinetic energy via an auxiliary noninteracting system.\nYet, the realization of DFT's full potential awaits the discovery of a direct\nlink between the electron density, $n$, and the non-interacting kinetic energy,\n$T_{S}[n]$. In this work, we address two key challenges towards this objective.\nFirst, we introduce a new algorithm for directly solving the constrained\nminimization problem yielding $T_{S}[n]$ for periodic densities -- a class of\ndensities that, in spite of its central importance for materials science, has\nreceived limited attention in the literature. Second, we present a numerical\nprocedure that allows us to calculate the functional derivative of $T_{S}[n]$\nwith respect to the density at constant electron number, also known as the\nKohn-Sham potential $V_{S}[n](\\rv)$. Lastly, the algorithm is augmented with a\nsubroutine that computes the ``derivative discontinuity\", i.e., the spatially\nuniform jump in $V_{S}[n](\\rv)$ which occurs upon increasing or decreasing the\ntotal number of electrons. This feature allows us to distinguish between\n``insulating\" and ``conducting\" densities for non interacting electrons. The\ncode integrates key methodological innovations, such as the use of an adaptive\nbasis set (``equidensity orbitals\") for wave function expansion and the QR\ndecomposition to accelerate the implementation of the orthogonality constraint.\nNotably, we derive a closed-form expression for the Pauli potential in one\ndimension, expressed solely in terms of the input density, without relying on\nKohn-Sham eigenvalues and eigenfunctions. We validate this method on\none-dimensional periodic densities, achieving results within ``chemical\naccuracy\"."
    ],
    "c_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-598",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15299"
    ],
    "b_title":[
      "Sensitive bioassay with an ultra-large dynamic range via microlaser\n  ensemble quenching"
    ],
    "b_abstract":[
      "We present a bioassay platform that leverages the lasing threshold\ndistribution in a microlaser ensemble (ME), consisting of hundreds of\nindividual microlasers, to measure analyte concentrations in solution. An ME is\nformed by placing dye-doped microbeads in a micro Fabry-Perot cavity.\nMicrobeads are surface modified with biorecognition molecules to capture\nanalytes, while the quenchers resulting from the presence of the analytes on\nthe microbeads' surfaces increase the lasing thresholds of microlasers. Since\nthe number of analytes varies from one microbead (or microlaser) to another due\nto the randomness in binding processes, a distribution of the analytes (and\nhence the quenchers) in the ME is created, which in turn leads to a lasing\nthreshold distribution in the ME. Experimentally, multiple pumping energy\ndensities are used to probe the lasing threshold distribution. A theoretical\nmodel is developed to map the lasing threshold distribution to analyte\ndistribution in the ME, and then to recover the analyte concentration in\nsolution. Using streptavidin and interleukin-6 as a model system, our platform\nachieves a detection limit of 0.1 pg\/mL and a dynamic range exceeding five\norders of magnitude, showing that the ME quenching method can provide a high\nsensitivity with a superior dynamic range."
    ],
    "b_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.06540"
    ],
    "c_title":[
      "CeViT: Copula-Enhanced Vision Transformer in multi-task learning and\n  bi-group image covariates with an application to myopia screening"
    ],
    "c_abstract":[
      "We aim to assist image-based myopia screening by resolving two longstanding\nproblems, \"how to integrate the information of ocular images of a pair of eyes\"\nand \"how to incorporate the inherent dependence among high-myopia status and\naxial length for both eyes.\" The classification-regression task is modeled as a\nnovel 4-dimensional muti-response regression, where discrete responses are\nallowed, that relates to two dependent 3rd-order tensors (3D ultrawide-field\nfundus images). We present a Vision Transformer-based bi-channel architecture,\nnamed CeViT, where the common features of a pair of eyes are extracted via a\nshared Transformer encoder, and the interocular asymmetries are modeled through\nseparated multilayer perceptron heads. Statistically, we model the conditional\ndependence among mixture of discrete-continuous responses given the image\ncovariates by a so-called copula loss. We establish a new theoretical framework\nregarding fine-tuning on CeViT based on latent representations, allowing the\nblack-box fine-tuning procedure interpretable and guaranteeing higher relative\nefficiency of fine-tuning weight estimation in the asymptotic setting. We apply\nCeViT to an annotated ultrawide-field fundus image dataset collected by\nShanghai Eye \\& ENT Hospital, demonstrating that CeViT enhances the baseline\nmodel in both accuracy of classifying high-myopia and prediction of AL on both\neyes."
    ],
    "c_categories":[
      [
        "cs.CV",
        "math.ST",
        "stat.AP",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-599",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12769"
    ],
    "b_title":[
      "How Much Do LLMs Hallucinate across Languages? On Multilingual\n  Estimation of LLM Hallucination in the Wild"
    ],
    "b_abstract":[
      "In the age of misinformation, hallucination -- the tendency of Large Language\nModels (LLMs) to generate non-factual or unfaithful responses -- represents the\nmain risk for their global utility. Despite LLMs becoming increasingly\nmultilingual, the vast majority of research on detecting and quantifying LLM\nhallucination are (a) English-centric and (b) focus on machine translation (MT)\nand summarization, tasks that are less common ``in the wild'' than open\ninformation seeking. In contrast, we aim to quantify the extent of LLM\nhallucination across languages in knowledge-intensive long-form question\nanswering. To this end, we train a multilingual hallucination detection model\nand conduct a large-scale study across 30 languages and 6 open-source LLM\nfamilies. We start from an English hallucination detection dataset and rely on\nMT to generate (noisy) training data in other languages. We also manually\nannotate gold data for five high-resource languages; we then demonstrate, for\nthese languages, that the estimates of hallucination rates are similar between\nsilver (LLM-generated) and gold test sets, validating the use of silver data\nfor estimating hallucination rates for other languages. For the final rates\nestimation, we build a knowledge-intensive QA dataset for 30 languages with\nLLM-generated prompts and Wikipedia articles as references. We find that, while\nLLMs generate longer responses with more hallucinated tokens for\nhigher-resource languages, there is no correlation between length-normalized\nhallucination rates of languages and their digital representation. Further, we\nfind that smaller LLMs exhibit larger hallucination rates than larger models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14412"
    ],
    "c_title":[
      "Quantum Neural Networks: A Comparative Analysis and Noise Robustness\n  Evaluation"
    ],
    "c_abstract":[
      "In current noisy intermediate-scale quantum (NISQ) devices, hybrid quantum\nneural networks (HQNNs) offer a promising solution, combining the strengths of\nclassical machine learning with quantum computing capabilities. However, the\nperformance of these networks can be significantly affected by the quantum\nnoise inherent in NISQ devices. In this paper, we conduct an extensive\ncomparative analysis of various HQNN algorithms, namely Quantum Convolution\nNeural Network (QCNN), Quanvolutional Neural Network (QuanNN), and Quantum\nTransfer Learning (QTL), for image classification tasks. We evaluate the\nperformance of each algorithm across quantum circuits with different entangling\nstructures, variations in layer count, and optimal placement in the\narchitecture. Subsequently, we select the highest-performing architectures and\nassess their robustness against noise influence by introducing quantum gate\nnoise through Phase Flip, Bit Flip, Phase Damping, Amplitude Damping, and the\nDepolarizing Channel. Our results reveal that the top-performing models exhibit\nvarying resilience to different noise gates. However, in most scenarios, the\nQuanNN demonstrates greater robustness across various quantum noise channels,\nconsistently outperforming other models. This highlights the importance of\ntailoring model selection to specific noise environments in NISQ devices."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-600",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15216"
    ],
    "b_title":[
      "Nanoscale resolved mapping of the dipole emission of hBN color centers\n  with a scattering-type scanning near-field optical microscope"
    ],
    "b_abstract":[
      "Color centers in hexagonal boron nitride (hBN) are promising candidates as\nquantum light sources for future technologies. In this work, we utilize a\nscattering-type near-field optical microscope (s-SNOM) to study the\nphotoluminescence (PL) emission characteristics of such quantum emitters in\nmetalorganic vapor phase epitaxy grown hBN. On the one hand, we demonstrate\ndirect near-field optical excitation and emission through interaction with the\nnanofocus of the tip resulting in a sub-diffraction limited tip-enhanced PL\nhotspot. On the other hand, we show that indirect excitation and emission via\nscattering from the tip significantly increases the recorded PL intensity. This\ndemonstrates that the tip-assisted PL (TAPL) process efficiently guides the\ngenerated light to the detector. We apply the TAPL method to map the in-plane\ndipole orientations of the hBN color centers on the nanoscale. This work\npromotes the widely available s-SNOM approach to applications in the quantum\ndomain including characterization and optical control."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.01835"
    ],
    "c_title":[
      "Efficient Denial of Service Attack Detection in IoT using\n  Kolmogorov-Arnold Networks"
    ],
    "c_abstract":[
      "The proliferation of Internet of Things (IoT) devices has created a pressing\nneed for efficient security solutions, particularly against Denial of Service\n(DoS) attacks. While existing detection approaches demonstrate high accuracy,\nthey often require substantial computational resources, making them impractical\nfor IoT deployment. This paper introduces a novel lightweight approach to DoS\nattack detection based on Kolmogorov-Arnold Networks (KANs). By leveraging\nspline-based transformations instead of traditional weight matrices, our\nsolution achieves state-of-the-art detection performance while maintaining\nminimal resource requirements. Experimental evaluation on the CICIDS2017\ndataset demonstrates 99.0% detection accuracy with only 0.19 MB memory\nfootprint and 2.00 ms inference time per sample. Compared to existing\nsolutions, KAN reduces memory requirements by up to 98% while maintaining\ncompetitive detection rates. The model's linear computational complexity\nensures efficient scaling with input size, making it particularly suitable for\nlarge-scale IoT deployments. We provide comprehensive performance comparisons\nwith recent approaches and demonstrate effectiveness across various DoS attack\npatterns. Our solution addresses the critical challenge of implementing\nsophisticated attack detection on resource-constrained devices, offering a\npractical approach to enhancing IoT security without compromising computational\nefficiency."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-601",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09731"
    ],
    "b_title":[
      "Results from an Einstein@Home search for continuous gravitational waves\n  from Cassiopeia A and Vela Jr. using LIGO O2 data"
    ],
    "b_abstract":[
      "We conduct two searches for continuous, nearly monochromatic gravitational\nwaves originating from the central compact objects in the supernova remnants\nCassiopeia A and Vela Jr. using public LIGO data. The search for Cassiopeia A\ntargets signal frequencies between 20 Hz and 400 Hz; the Vela Jr. search\nbetween 400 Hz and 1700 Hz, and both investigate the broadest set of waveforms\never considered with highly sensitive deterministic search methods. Above 1500\nHz the Vela Jr. search is the most sensitive carried out thus far, improving on\nprevious results by over 300\\%. Above 976 Hz these results improve on existing\nones by 50\\%. In all we investigate over $10^{18}$ waveforms, leveraging the\ncomputational power donated by thousands of Einstein@Home volunteers. We\nperform a 4-stage follow-up on more than 6 million waveforms. None of the\nconsidered waveforms survives the follow-up scrutiny, indicating no significate\ndetection candidate. Our null results constrain the maximum amplitude of\ncontinuous signals as a function of signal frequency from the targets. The most\nstringent 90\\% confidence upper limit for Cas A is $h_0^{90 \\%}\\approx\n7.3\\times10^{-26}$ near 200 Hz, and for Vela Jr. it is $h_0^{90 \\%}\\approx\n8.9\\times10^{-26}$ near 400 Hz. Translated into upper limits on the ellipticity\nand r-mode amplitude, our results probe physically interesting regions: for\nexample the ellipticity of Vela Jr. is constrained to be smaller than $10^{-7}$\nacross the frequency band, with a tighter constraint of less than\n$2\\times10^{-8}$ at the highest frequencies."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.07730"
    ],
    "c_title":[
      "DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force\n  Feedback Glove"
    ],
    "c_abstract":[
      "Dexterous hand teleoperation plays a pivotal role in enabling robots to\nachieve human-level manipulation dexterity. However, current teleoperation\nsystems often rely on expensive equipment and lack multi-modal sensory\nfeedback, restricting human operators' ability to perceive object properties\nand perform complex manipulation tasks. To address these limitations, we\npresent DOGlove, a low-cost, precise, and haptic force feedback glove system\nfor teleoperation and manipulation. DoGlove can be assembled in hours at a cost\nunder 600 USD. It features a customized joint structure for 21-DoF motion\ncapture, a compact cable-driven torque transmission mechanism for 5-DoF\nmultidirectional force feedback, and a linear resonate actuator for 5-DoF\nfingertip haptic feedback. Leveraging action and haptic force retargeting,\nDOGlove enables precise and immersive teleoperation of dexterous robotic hands,\nachieving high success rates in complex, contact-rich tasks. We further\nevaluate DOGlove in scenarios without visual feedback, demonstrating the\ncritical role of haptic force feedback in task performance. In addition, we\nutilize the collected demonstrations to train imitation learning policies,\nhighlighting the potential and effectiveness of DOGlove. DOGlove's hardware and\nsoftware system will be fully open-sourced at https:\/\/do-glove.github.io\/."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-602",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04098"
    ],
    "b_title":[
      "A Detection of Circumgalactic Dust at Megaparsec Scales with Maximum\n  Likelihood Estimation"
    ],
    "b_abstract":[
      "One of the more surprising astrophysical discoveries of the last decade has\nbeen the presence of enormous quantities of dust at megaparsec distances from\ngalaxies, which has important implications for galaxy evolution, the\ncircumgalactic and intergalactic medium, and observational cosmology. In this\nwork, we present a novel method for studying these vast halos of circumgalactic\ndust: a maximum-likelihood estimator for dust-induced extinction of background\ngalaxies. This estimator can accommodate a broad range of archival photometric\ndata and can incorporate different dust reddening prescriptions, making it\napplicable to diverse galaxy types and redshifts. We apply the estimator to the\nredMaGiC catalog of luminous red galaxies, selected for their tight dispersion\nin color and well-constrained photometric redshifts, and measure the resulting\nextinction as a function of projected distance from WISExSuperCOSMOS and\nredMaGiC foreground galaxies. We detect significant dust-induced extinction\nprofiles extending to at least 1 megaparsec from galactic disks, with\nnoticeable differences between star-forming and quiescent galaxies:\nstar-forming galaxies exhibit a pronounced rise in extinction within the inner\n50 kiloparsecs and a steep decline beyond 1 megaparsec, while the quiescent\ngalaxies host little dust in the inner halo but have detectable extinction out\nto 30 megaparsecs. We test the robustness of our results using star catalogs\nand inverted foreground and background samples and find no evidence for\nsignificant systematic error. Our approach provides a powerful tool for\nstudying the interplay between circumgalactic dust, galaxy evolution, and\nlarge-scale structure, with potential applications in a number of astrophysical\nsubfields."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03374"
    ],
    "c_title":[
      "An explicitly solvable NLS model with discontinuous standing waves"
    ],
    "c_abstract":[
      "We study the nonlinear Schr\\\"odinger Equation on the line in the presence of\na point interaction that consists in the superposition of an attractive delta\npotential with a dipole interaction. In the energy space it induces a\ndiscontinuity at the origin that breaks the parity symmetry. We treat the\n$L^2$-subcritical and the $L^2$-critical nonlinearity. For a subcritical\nnonlinearity we prove the existence and the uniqueness of the Ground State at\nany mass, namely the positive minimizer of the associated energy among all\nfunctions with the same mass. If the mass is larger than an explicit threshold,\nthen there exists another stationary solution, i.e. an excited state, which is\npositive too. For the critical nonlinearity we prove that Ground States exist\nonly in a specific interval of masses. Furthermore, one branch of excited\nstates exists in a range of masses disjoint from that of the Ground States. For\na dipole interaction, i.e. without the Dirac's delta, all Ground States\nconcentrate at the same value of the mass and all excited states concentrate at\nanother value of the mass. Both masses depend on the strength of the dipole\ninteractions. Furthermore, we provide the value of the optimal constant in the\nGagliardo-Nirenberg estimate and describe in detail the bifurcation from the\nunperturbed soliton that gives rise to both branches of stationary states,\nproviding the motivation for the values of the mass that characterize the two\nbranches, in the limit of a dipole interaction of infinite strength. Since all\nstationary states are explicitly computed, ours is a solvable model involving a\nnon-standard interplay of a nonlinearity with a point interaction, in the sense\nthat is richer than in the well-known model of a delta interaction with a\nnonlinearity."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-603",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17363"
    ],
    "b_title":[
      "Assessment various control methods a digital copy of enterprise by\n  integral indicator"
    ],
    "b_abstract":[
      "The difficulty of assessing the state lies in a little predictable change in\nthe dimension of a dynamic system under the influence of internal changes and\nenvironmental parameters. In the work, the state of such a system is estimated\nby the method of integral indicators. The application of the method of integral\nindicators allowed us to evaluate the activity of an enterprise. In the present\nwork, the method of integrated indicators is used to assess the control of a\ndigital copy (enterprise)."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07507"
    ],
    "c_title":[
      "PE3R: Perception-Efficient 3D Reconstruction"
    ],
    "c_abstract":[
      "Recent advancements in 2D-to-3D perception have significantly improved the\nunderstanding of 3D scenes from 2D images. However, existing methods face\ncritical challenges, including limited generalization across scenes, suboptimal\nperception accuracy, and slow reconstruction speeds. To address these\nlimitations, we propose Perception-Efficient 3D Reconstruction (PE3R), a novel\nframework designed to enhance both accuracy and efficiency. PE3R employs a\nfeed-forward architecture to enable rapid 3D semantic field reconstruction. The\nframework demonstrates robust zero-shot generalization across diverse scenes\nand objects while significantly improving reconstruction speed. Extensive\nexperiments on 2D-to-3D open-vocabulary segmentation and 3D reconstruction\nvalidate the effectiveness and versatility of PE3R. The framework achieves a\nminimum 9-fold speedup in 3D semantic field reconstruction, along with\nsubstantial gains in perception accuracy and reconstruction precision, setting\nnew benchmarks in the field. The code is publicly available at:\nhttps:\/\/github.com\/hujiecpp\/PE3R."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-604",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19893"
    ],
    "b_title":[
      "A Multiple Transferable Neural Network Method with Domain Decomposition\n  for Elliptic Interface Problems"
    ],
    "b_abstract":[
      "The transferable neural network (TransNet) is a two-layer shallow neural\nnetwork with pre-determined and uniformly distributed neurons in the hidden\nlayer, and the least-squares solvers can be particularly used to compute the\nparameters of its output layer when applied to the solution of partial\ndifferential equations. In this paper, we integrate the TransNet technique with\nthe nonoverlapping domain decomposition and the interface conditions to develop\na novel multiple transferable neural network (Multi-TransNet) method for\nsolving elliptic interface problems, which typically contain discontinuities in\nboth solutions and their derivatives across interfaces. We first propose an\nempirical formula for the TransNet to characterize the relationship between the\nradius of the domain-covering ball, the number of hidden-layer neurons, and the\noptimal neuron shape. In the Multi-TransNet method, we assign each subdomain\none distinct TransNet with an adaptively determined number of hidden-layer\nneurons to maintain the globally uniform neuron distribution across the entire\ncomputational domain, and then unite all the subdomain TransNets together by\nincorporating the interface condition terms into the loss function. The\nempirical formula is also extended to the Multi-TransNet and further employed\nto estimate appropriate neuron shapes for the subdomain TransNets, greatly\nreducing the parameter tuning cost. Additionally, we propose a normalization\napproach to adaptively select the weighting parameters for the terms in the\nloss function. Ablation studies and extensive experiments with comparison tests\non different types of elliptic interface problems with low to high contrast\ndiffusion coefficients in two and three dimensions are carried out to\nnumerically demonstrate the superior accuracy, efficiency, and robustness of\nthe proposed Multi-TransNet method."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18363"
    ],
    "c_title":[
      "Robust Online Conformal Prediction under Uniform Label Noise"
    ],
    "c_abstract":[
      "Conformal prediction is an emerging technique for uncertainty quantification\nthat constructs prediction sets guaranteed to contain the true label with a\npredefined probability. Recent work develops online conformal prediction\nmethods that adaptively construct prediction sets to accommodate distribution\nshifts. However, existing algorithms typically assume perfect label accuracy\nwhich rarely holds in practice. In this work, we investigate the robustness of\nonline conformal prediction under uniform label noise with a known noise rate,\nin both constant and dynamic learning rate schedules. We show that label noise\ncauses a persistent gap between the actual mis-coverage rate and the desired\nrate $\\alpha$, leading to either overestimated or underestimated coverage\nguarantees. To address this issue, we propose Noise Robust Online Conformal\nPrediction (dubbed NR-OCP) by updating the threshold with a novel robust\npinball loss, which provides an unbiased estimate of clean pinball loss without\nrequiring ground-truth labels. Our theoretical analysis shows that NR-OCP\neliminates the coverage gap in both constant and dynamic learning rate\nschedules, achieving a convergence rate of $\\mathcal{O}(T^{-1\/2})$ for both\nempirical and expected coverage errors under uniform label noise. Extensive\nexperiments demonstrate the effectiveness of our method by achieving both\nprecise coverage and improved efficiency."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-605",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18262"
    ],
    "b_title":[
      "Enhanced State Estimation for turbulent flows combining Ensemble Data\n  Assimilation and Machine Learning"
    ],
    "b_abstract":[
      "A novel strategy is proposed to improve the accuracy of state estimation and\nreconstruction from low-fidelity models and sparse data from sensors. This\nstrategy combines ensemble Data Assimilation (DA) and Machine Learning (ML)\ntools, exploiting their complementary features. ML techniques rely on the data\nproduced by DA methods during analysis phases to train physics-informed\ncorrective algorithms, which are then coupled with the low-fidelity models when\ndata from sensors is unavailable. The methodology is validated via the analysis\nof the turbulent plane channel flow test case for $Re_\\tau \\approx 550$. Here,\nthe low-fidelity model consists of coarse-grained simulations coupled with the\nImmersed Boundary Method (IBM), while observation is sampled by a highly\nrefined body-fitted calculation. The analysis demonstrates the capabilities of\nthe algorithm based on DA and ML to accurately predict the flow features with\nsignificantly reduced computational costs. This approach exhibits potential for\nfuture synergistic applications of DA and ML, leveraging the robustness and\nefficiency of ML models alongside the physical interpretability ensured by DA\nalgorithms."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.15035"
    ],
    "c_title":[
      "Semi-supervised Anomaly Detection with Extremely Limited Labels in\n  Dynamic Graphs"
    ],
    "c_abstract":[
      "Semi-supervised graph anomaly detection (GAD) has recently received\nincreasing attention, which aims to distinguish anomalous patterns from graphs\nunder the guidance of a moderate amount of labeled data and a large volume of\nunlabeled data. Although these proposed semi-supervised GAD methods have\nachieved great success, their superior performance will be seriously degraded\nwhen the provided labels are extremely limited due to some unpredictable\nfactors. Besides, the existing methods primarily focus on anomaly detection in\nstatic graphs, and little effort was paid to consider the continuous evolution\ncharacteristic of graphs over time (dynamic graphs). To address these\nchallenges, we propose a novel GAD framework (EL$^{2}$-DGAD) to tackle anomaly\ndetection problem in dynamic graphs with extremely limited labels.\nSpecifically, a transformer-based graph encoder model is designed to more\neffectively preserve evolving graph structures beyond the local neighborhood.\nThen, we incorporate an ego-context hypersphere classification loss to classify\ntemporal interactions according to their structure and temporal neighborhoods\nwhile ensuring the normal samples are mapped compactly against anomalous data.\nFinally, the above loss is further augmented with an ego-context contrasting\nmodule which utilizes unlabeled data to enhance model generalization. Extensive\nexperiments on four datasets and three label rates demonstrate the\neffectiveness of the proposed method in comparison to the existing GAD methods."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-606",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03616"
    ],
    "b_title":[
      "Noncooperative Equilibrium Selection via a Trading-based Auction"
    ],
    "b_abstract":[
      "Noncooperative multi-agent systems often face coordination challenges due to\nconflicting preferences among agents. In particular, agents acting in their own\nself-interest can settle on different equilibria, leading to suboptimal\noutcomes or even safety concerns. We propose an algorithm named trading auction\nfor consensus (TACo), a decentralized approach that enables noncooperative\nagents to reach consensus without communicating directly or disclosing private\nvaluations. TACo facilitates coordination through a structured trading-based\nauction, where agents iteratively select choices of interest and provably reach\nan agreement within an a priori bounded number of steps. A series of numerical\nexperiments validate that the termination guarantees of TACo hold in practice,\nand show that TACo achieves a median performance that minimizes the total cost\nacross all agents, while allocating resources significantly more fairly than\nbaseline approaches."
    ],
    "b_categories":[
      [
        "cs.GT",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15033"
    ],
    "c_title":[
      "Anisotropic quadratic equations in three variables"
    ],
    "c_abstract":[
      "Let $f(x_1, x_2, x_3)$ be an indefinite anisotropic integral quadratic form\nwith determinant $d(f)$, and $t$ a non-zero integer such that $d(f)t$ is\nsquare-free. It is proved in this paper that, as long as there is one integral\nsolution to $f(x_1, x_2, x_3) = t$, there are infinitely many such solutions\nfor which (i) $x_1$ has at most $6$ prime factors, and (ii) the product $x_1\nx_2$ has at most $16$ prime factors. Various methods, such as algebraic theory\nof quadratic forms, harmonic analysis, Jacquet-Langlands theory, as well as\ncombinatorics, interact here, and the above results come from applying the\nsharpest known bounds towards Selberg's eigenvalue conjecture. Assuming the\nlatter the number $6$ or $16$ may be reduced to $5$ or $14$, respectively."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-607",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06663"
    ],
    "b_title":[
      "Energy-Adaptive Checkpoint-Free Intermittent Inference for Low Power\n  Energy Harvesting Systems"
    ],
    "b_abstract":[
      "Deep neural network (DNN) inference in energy harvesting (EH) devices poses\nsignificant challenges due to resource constraints and frequent power\ninterruptions. These power losses not only increase end-to-end latency, but\nalso compromise inference consistency and accuracy, as existing checkpointing\nand restore mechanisms are prone to errors. Consequently, the quality of\nservice (QoS) for DNN inference on EH devices is severely impacted. In this\npaper, we propose an energy-adaptive DNN inference mechanism capable of\ndynamically transitioning the model into a low-power mode by reducing\ncomputational complexity when harvested energy is limited. This approach\nensures that end-to-end latency requirements are met. Additionally, to address\nthe limitations of error-prone checkpoint-and-restore mechanisms, we introduce\na checkpoint-free intermittent inference framework that ensures consistent,\nprogress-preserving DNN inference during power failures in energy-harvesting\nsystems."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.09812"
    ],
    "c_title":[
      "Methods of Selective Inference for Linear Mixed Models: a Review and\n  Empirical Comparison"
    ],
    "c_abstract":[
      "Selective inference aims at providing valid inference after a data-driven\nselection of models or hypotheses. It is essential to avoid overconfident\nresults and replicability issues. While significant advances have been made in\nthis area for standard regression models, relatively little attention has been\ngiven to linear mixed models (LMMs), which are widely used for analyzing\nclustered or longitudinal data. This paper reviews the existing selective\ninference approaches developed for LMMs, focusing on selection of fixed\neffects, where the random effects structure is given. We present these methods\nin detail and, through comparative simulations, assess their practical\nperformance and computational feasibility under varying data structures. In\naddition, we apply them to a real-world biological dataset to examine how\nmethod choice can impact inference in practice. Our findings highlight an\nexisting trade-off between computational complexity and statistical power and\nemphasize the scarcity of methods that perform well as the number of variables\nincreases. In such scenarios, basic sample splitting emerges as the most\nreliable approach."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-608",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01902"
    ],
    "b_title":[
      "H$\\alpha$-X-ray Surface Brightness Correlation for Filaments in Cooling\n  Flow Clusters"
    ],
    "b_abstract":[
      "Massive galaxies in cooling flow clusters display clear evidence of feedback\nfrom Active Galactic Nuclei (AGN). Joint X-ray and radio observations have\nshown that AGN radio jets push aside the surrounding hot gas and form cavities\nin the hot intracluster medium (ICM). These systems host complex,\nkiloparsec-scale, multiphase filamentary structures, from warm ionized (10,000\nK) to cold molecular ($<$100 K). These striking clumpy filaments are believed\nto be a natural outcome of thermally unstable cooling from the hot ICM, likely\ntriggered by feedback processes while contributing to feeding the AGN via\nChaotic Cold Accretion (CCA). However, the detailed constraints on the\nformation mechanism of the filaments are still uncertain, and the connection\nbetween the different gas phases has to be fully unveiled. By leveraging a\nsample of seven X-ray bright cooling-flow clusters, we have discovered a tight\npositive correlation between the X-ray surface brightness and the H$\\alpha$\nsurface brightness of the filaments over two orders of magnitude, as also found\nin stripped tails."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.20467"
    ],
    "c_title":[
      "Robust statistical inference for accelerated life-tests with one-shot\n  devices under log-logistic distributions"
    ],
    "c_abstract":[
      "A one-shot device is a unit that operates only once, after which it is either\ndestroyed or needs to be rebuilt. For this type of device, the operational\nstatus can only be assessed at a specific inspection time, determining whether\nfailure occurred before or after it. Consequently, lifetimes are subject to\nleft- or right-censoring. One-shot devices are usually highly reliables. To\nanalyze the reliability of such products, an accelerated life test (ALT) plan\nis typically employed by subjecting the devices to increased levels of stress\nfactors, thus allowing life characteristics observed under high-stress\nconditions to be extrapolated to normal operating conditions. By accelerating\nthe degradation process, ALT significantly reduces both the time required for\ntesting and the associated experimental costs.\n  Recently, robust inferential methods have gained considerable interest in\nstatistical analysis. Among them, weighted minimum density power divergence\nestimators (WMDPDEs) are widely recognized for their robust statistical\nproperties with small loss of efficiency. In this work, robust WMDPDE and\nassociated statistical tests are developed under a log-logistic lifetime\ndistribution with multiple stresses. Explicit expressions for the estimating\nequations and asymptotic distribution of the estimators are obtained. Further,\na Monte Carlo simulation study is presented to evaluate the performance of the\nWMDPDE in practical applications."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-609",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13892"
    ],
    "b_title":[
      "Formation and evolution of new primordial open cluster groups:\n  Feedback-driven star formation"
    ],
    "b_abstract":[
      "The formation mechanisms of open cluster (OCs) groups remain unclear due to\nlimited sample sizes and data precision. Recent advancements in Gaia\nastrometric data provide an unprecedented opportunity to study OC groups in\ngreater detail. This study aims to extend the sample of OC groups and\ninvestigate their formation and evolution mechanisms, with a focus on the role\nof stellar feedback in triggering star formation. We identify four new OC\ngroups based on Gaia data, whose member OCs are spatially proximate and\nkinematically coherent. Their age spreads are consistent with the timescale of\ncontinuous star formation, suggesting that their member OCs formed sequentially\nfrom the same molecular cloud. N-body simulation results further reveal that\nthese groups will gradually disperse, evolving into independent OCs. By\nanalyzing the correlation between OC ages and their separation from potential\nSN explosion sites, we predict SN explosion regions around the birthplaces of\nOC groups. The strong correlation between OC ages and predicted SN explosion\nsites supports a supernova-triggered star formation scenario. Additionally, we\ntrace pulsar (PSR) orbits to examine their association with these regions. We\ndetected three PSRs near Group 1 and 26 PSRs near Group 2, whose birthplaces\nalign with the predicted SN explosions regions. The presence of PSRs associated\nwith OC groups provides additional observational evidence for SN explosions in\nthis region, further supporting a supernova-triggered star formation scenario\nfor G1 and G2. We propose that multiple SN explosions in a short period\ntriggered the formation of Group 1 and Group 2, reinforcing the hierarchical\nstar formation model. These results highlight the multi-scale interactions\ndriving star and OC formation and provide new insights into the role of stellar\nfeedback in shaping OC groups."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17571"
    ],
    "c_title":[
      "Towards Conditioning Clinical Text Generation for User Control"
    ],
    "c_abstract":[
      "Deploying natural language generation systems in clinical settings remains\nchallenging despite advances in Large Language Models (LLMs), which continue to\nexhibit hallucinations and factual inconsistencies, necessitating human\noversight. This paper explores automated dataset augmentation using LLMs as\nhuman proxies to condition LLMs for clinician control without increasing\ncognitive workload. On the BioNLP ACL'24 Discharge Me! Shared Task, we achieve\nnew state-of-the-art results with simpler methods than prior submissions\nthrough more efficient training, yielding a 9\\% relative improvement without\naugmented training and up to 34\\% with dataset augmentation. Preliminary human\nevaluation further supports the effectiveness of our approach, highlighting the\npotential of augmenting clinical text generation for control to enhance\nrelevance, accuracy, and factual consistency."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-610",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11137"
    ],
    "b_title":[
      "Clustering indications before the Mw7.0 2020 Samos, Greece, main shock\n  as revealed in an equivalent dimensions space"
    ],
    "b_abstract":[
      "The transformation to equivalent dimensions that offers a novel approach for\ninvestigating earthquake clustering was engaged to analyze the preparatory\nphase of the 2020 Samos, Greece, Mw7.0 main shock. The analysis considered\nearthquakes that occurred between 2006 and October 2020, covering an area\nextended three times the length of the main rupture. Each earthquake was\nparameterized by its magnitude, the interevent time (interval since the\nprevious earthquake), and the interevent spatial distance (distance between the\nepicenters of consecutive earthquakes). Transforming these parameters into\nequivalent dimensions allowed them to be directly compared. The degree of\nclustering was quantified using the average distance between earthquakes in\nthis transformed parameter space, calculated within consecutive 100 events data\nwindows. Results revealed a distinct pattern, the average distance was\nincreasing steadily during the twelve year period before the main shock. These\ntemporal changes in the average distance were driven by a systematic evolution\nof earthquake clustering in the used parameter space. Beginning from a\ntwo-cluster system, when the distance was minimal, the clustering development\ncontinued along two branches and ended before the main shock with the formation\nof five earthquake clusters of different characteristics."
    ],
    "b_categories":[
      [
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05222"
    ],
    "c_title":[
      "VistaFlow: Photorealistic Volumetric Reconstruction with Dynamic\n  Resolution Management via Q-Learning"
    ],
    "c_abstract":[
      "We introduce VistaFlow, a scalable three-dimensional imaging technique\ncapable of reconstructing fully interactive 3D volumetric images from a set of\n2D photographs. Our model synthesizes novel viewpoints through a differentiable\nrendering system capable of dynamic resolution management on photorealistic 3D\nscenes. We achieve this through the introduction of QuiQ, a novel intermediate\nvideo controller trained through Q-learning to maintain a consistently high\nframerate by adjusting render resolution with millisecond precision. Notably,\nVistaFlow runs natively on integrated CPU graphics, making it viable for mobile\nand entry-level devices while still delivering high-performance rendering.\nVistaFlow bypasses Neural Radiance Fields (NeRFs), using the PlenOctree data\nstructure to render complex light interactions such as reflection and\nsubsurface scattering with minimal hardware requirements. Our model is capable\nof outperforming state-of-the-art methods with novel view synthesis at a\nresolution of 1080p at over 100 frames per second on consumer hardware. By\ntailoring render quality to the capabilities of each device, VistaFlow has the\npotential to improve the efficiency and accessibility of photorealistic 3D\nscene rendering across a wide spectrum of hardware, from high-end workstations\nto inexpensive microcontrollers."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-611",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03996"
    ],
    "b_title":[
      "Power-over-fiber and distributed acoustic sensing hybridization in\n  single fiber channel"
    ],
    "b_abstract":[
      "The efficient and independent operation of power-over-fiber (PoF) and\ndistributed acoustic sensing (DAS) has been demonstrated using standard\nsingle-mode fiber (SSMF). A transmission optical power efficiency (OPTE) of\n6.67% was achieved over an 11.8 km fiber link, supporting both power delivery\nand distributed optical fiber sensing (DOFS). To minimize cross-talk, the\nsystem separates the power and sensing channels by a 40 THz bandwidth. In the\nexperiment, the power and sensing light wavelengths are 1064 nm (continuous)\nand 1550 nm (pulsed), respectively. As the transmitted optical power increased\nfrom 0 W to 2.13 W, the DAS system successfully localized vibration sources and\nreconstructed phase information, confirming its ability to operate under high\noptical power. The reported scheme verifies the possibility of constructing the\nsensing-energy hybrid network based on conventional optical fiber with the\nadvantages of flexibility and low cost."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03441"
    ],
    "c_title":[
      "Building a Smart, Secured and Sustainable Campus: A Self-Powered\n  Wireless Network for Environmental Monitoring"
    ],
    "c_abstract":[
      "The objective of this study is to propose a self-powered wireless network\nsolution that utilizes strategically deployed wireless sensor nodes within\nbuildings for environmental data collection, while integrating advanced\nsecurity measures and sustainable power management strategies."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-612",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17933"
    ],
    "b_title":[
      "Experience Retrieval-Augmentation with Electronic Health Records Enables\n  Accurate Discharge QA"
    ],
    "b_abstract":[
      "To improve the reliability of Large Language Models (LLMs) in clinical\napplications, retrieval-augmented generation (RAG) is extensively applied to\nprovide factual medical knowledge. However, beyond general medical knowledge\nfrom open-ended datasets, clinical case-based knowledge is also critical for\neffective medical reasoning, as it provides context grounded in real-world\npatient experiences. Motivated by this, we propose Experience Retrieval\nAugmentation - ExpRAG framework based on Electronic Health Record (EHR), aiming\nto offer the relevant context from other patients' discharge reports. ExpRAG\nperforms retrieval through a coarse-to-fine process, utilizing an EHR-based\nreport ranker to efficiently identify similar patients, followed by an\nexperience retriever to extract task-relevant content for enhanced medical\nreasoning. To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset\nwith 1,280 discharge-related questions across diagnosis, medication, and\ninstruction tasks. Each problem is generated using EHR data to ensure realistic\nand challenging scenarios. Experimental results demonstrate that ExpRAG\nconsistently outperforms a text-based ranker, achieving an average relative\nimprovement of 5.2%, highlighting the importance of case-based knowledge for\nmedical reasoning."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11355"
    ],
    "c_title":[
      "Relax-and-round strategies for solving the Unit Commitment problem with\n  AC Power Flow constraints"
    ],
    "c_abstract":[
      "The Unit Commitment problem with AC power flow constraints (UC-ACOPF) is a\nnon-convex mixed-integer nonlinear programming (MINLP) problem encountered in\npower systems. Its combination of combinatorial complexity and non-convex\nnonlinear constraints makes it particularly challenging. A common approach to\ntackle this issue is to relax the integrality condition, but this often results\nin infeasible solutions. Consequently, rounding heuristics are frequently\nemployed to restore integer feasibility. This paper addresses recent\nadvancements in heuristics aimed at quickly obtaining feasible solutions for\nthe UC-ACOPF problem, focusing specifically on direct relax-and-round\nstrategies. We propose a model-based heuristic that rescales the solution of\nthe integer-relaxed problem before rounding. Furthermore, we introduce rounding\nformulas designed to enforce combinatorial constraints and aim to maintain AC\nfeasibility in the resulting solutions. These methodologies are compared\nagainst standard direct rounding techniques in the literature, applied to a\n6-bus and a 118-bus test systems. Additionally, we integrate the proposed\nheuristics into an implementation of the Feasibility Pump (FP) method,\ndemonstrating their utility and potential to enhance existing rounding\nstrategies."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-613",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12663"
    ],
    "b_title":[
      "Trajectories of light beams in a Kerr metric: the influence of the\n  rotation of an observer on the shadow of a black hole"
    ],
    "b_abstract":[
      "This paper investigates the trajectories of light beams in a Kerr metric,\nwhich describes the gravitational field in the neighborhood of a rotating black\nhole. After reduction by cyclic coordinates, this problem reduces to analysis\nof a Hamiltonian system with two degrees of freedom. A bifurcation diagram is\nconstructed and a classification is made of the types of trajectories of the\nsystem according to the values of first integrals. Relations describing the\nboundary of the shadow of the black hole are obtained for a stationary observer\nwho rotates with an arbitrary angular velocity about the axis of rotation of\nthe black hole."
    ],
    "b_categories":[
      [
        "gr-qc",
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.06503"
    ],
    "c_title":[
      "Charging a Dimerized Quantum XY Chain"
    ],
    "c_abstract":[
      "Quantum batteries are quantum systems designed to store energy and release it\non demand. The optimization of their performance is an intensively studied\ntopic within the realm of quantum technologies. Such optimization forces the\nquestion: how do quantum many-body systems work as quantum batteries? To\naddress this issue, we rely on symmetry and symmetry breaking via quantum phase\ntransitions. Specifically, we analyze a dimerized quantum XY chain in a\ntransverse field as a prototype of an energy storage device. This model, which\nis characterized by ground states with different symmetries depending on the\nHamiltonian parameters, can be mapped onto a spinless fermionic chain with\nsuperconducting correlations, displaying a rich quantum phase diagram. We show\nthat the stored energy strongly depends on the quantum phase diagram of the\nmodel when large charging times are considered."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-614",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13681"
    ],
    "b_title":[
      "A projection method for particle resampling"
    ],
    "b_abstract":[
      "Particle discretizations of partial differential equations are advantageous\nfor high-dimensional kinetic models in phase space due to their better\nscalability than continuum approaches with respect to dimension. Complex\nprocesses collectively referred to as \\textit{particle noise} hamper long-time\nsimulations with particle methods. One approach to address this problem is\nparticle mesh adaptivity or remapping, known as \\textit{particle resampling}.\nThis paper introduces a resampling method that projects particles to and from a\n(finite element) function space. The method is simple; using standard sparse\nlinear algebra and finite element techniques, it can adapt to almost any set of\nnew particle locations and preserves all moments up to the order of polynomial\nrepresented exactly by the continuum function space.\n  This work is motivated by the Vlasov-Maxwell-Landau model of magnetized\nplasmas with up to six dimensions, $3X$ in physical space and $3V$ in velocity\nspace, and is developed in the context of a $1X$ + $1V$ Vlasov-Poisson model of\nLandau damping with logically regular particle and continuum phase space grids.\nThe evaluation codes are publicly available, along with the data and\nreproducibility artifacts, and developed in the PETSc numerical library\n(petsc.org)."
    ],
    "b_categories":[
      [
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.15711"
    ],
    "c_title":[
      "DanmuA11y: Making Time-Synced On-Screen Video Comments (Danmu)\n  Accessible to Blind and Low Vision Users via Multi-Viewer Audio Discussions"
    ],
    "c_abstract":[
      "By overlaying time-synced user comments on videos, Danmu creates a\nco-watching experience for online viewers. However, its visual-centric design\nposes significant challenges for blind and low vision (BLV) viewers. Our\nformative study identified three primary challenges that hinder BLV viewers'\nengagement with Danmu: the lack of visual context, the speech interference\nbetween comments and videos, and the disorganization of comments. To address\nthese challenges, we present DanmuA11y, a system that makes Danmu accessible by\ntransforming it into multi-viewer audio discussions. DanmuA11y incorporates\nthree core features: (1) Augmenting Danmu with visual context, (2) Seamlessly\nintegrating Danmu into videos, and (3) Presenting Danmu via multi-viewer\ndiscussions. Evaluation with twelve BLV viewers demonstrated that DanmuA11y\nsignificantly improved Danmu comprehension, provided smooth viewing\nexperiences, and fostered social connections among viewers. We further\nhighlight implications for enhancing commentary accessibility in video-based\nsocial media and live-streaming platforms."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-615",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04572"
    ],
    "b_title":[
      "Social Imitation Dynamics of Vaccination Driven by Vaccine Effectiveness\n  and Beliefs"
    ],
    "b_abstract":[
      "Declines in vaccination coverage for vaccine-preventable diseases, such as\nmeasles and chickenpox, have enabled their surprising comebacks and pose\nsignificant public health challenges in the wake of growing vaccine hesitancy.\nVaccine opt-outs and refusals are often fueled by beliefs concerning\nperceptions of vaccine effectiveness and exaggerated risks. Here, we quantify\nthe impact of competing beliefs -- vaccine-averse versus vaccine-neutral -- on\nsocial imitation dynamics of vaccination, alongside the epidemiological\ndynamics of disease transmission. These beliefs may be pre-existing and fixed,\nor coevolving attitudes. This interplay among beliefs, behaviors, and disease\ndynamics demonstrates that individuals are not perfectly rational; rather, they\nbase their vaccine uptake decisions on beliefs, personal experiences, and\nsocial influences. We find that the presence of a small proportion of fixed\nvaccine-averse beliefs can significantly exacerbate the vaccination dilemma,\nmaking the tipping point in the hysteresis loop more sensitive to changes in\nindividuals' perceived costs of vaccination and vaccine effectiveness. However,\nin scenarios where competing beliefs spread concurrently with vaccination\nbehavior, their double-edged impact can lead to self-correction and alignment\nbetween vaccine beliefs and behaviors. The results show that coevolution of\nvaccine beliefs and behaviors makes populations more sensitive to abrupt\nchanges in perceptions of vaccine cost and effectiveness compared to scenarios\nwithout beliefs. Our work provides valuable insights into harnessing the social\ncontagion of even vaccine-neutral attitudes to overcome vaccine hesitancy."
    ],
    "b_categories":[
      [
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2501.15499"
    ],
    "c_title":[
      "One Model to Forecast Them All and in Entity Distributions Bind Them"
    ],
    "c_abstract":[
      "Probabilistic forecasting in power systems often involves multi-entity\ndatasets like households, feeders, and wind turbines, where generating reliable\nentity-specific forecasts presents significant challenges. Traditional\napproaches require training individual models for each entity, making them\ninefficient and hard to scale. This study addresses this problem using\nGUIDE-VAE, a conditional variational autoencoder that allows entity-specific\nprobabilistic forecasting using a single model. GUIDE-VAE provides flexible\noutputs, ranging from interpretable point estimates to full probability\ndistributions, thanks to its advanced covariance composition structure. These\ndistributions capture uncertainty and temporal dependencies, offering richer\ninsights than traditional methods. To evaluate our GUIDE-VAE-based forecaster,\nwe use household electricity consumption data as a case study due to its\nmulti-entity and highly stochastic nature. Experimental results demonstrate\nthat GUIDE-VAE outperforms conventional quantile regression techniques across\nkey metrics while ensuring scalability and versatility. These features make\nGUIDE-VAE a powerful and generalizable tool for probabilistic forecasting\ntasks, with potential applications beyond household electricity consumption."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-616",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09954"
    ],
    "b_title":[
      "AIRCHITECT v2: Learning the Hardware Accelerator Design Space through\n  Unified Representations"
    ],
    "b_abstract":[
      "Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21116"
    ],
    "c_title":[
      "The two filter formula reconsidered: Smoothing in partially observed\n  Gauss--Markov models without information parametrization"
    ],
    "c_abstract":[
      "In this article, the two filter formula is re-examined in the setting of\npartially observed Gauss--Markov models. It is traditionally formulated as a\nfilter running backward in time, where the Gaussian density is parametrized in\n``information form''. However, the quantity in the backward recursion is\nstrictly speaking not a distribution, but a likelihood. Taking this observation\nseriously, a recursion over log-quadratic likelihoods is formulated instead,\nwhich obviates the need for ``information'' parametrization. In particular, it\ngreatly simplifies the square-root formulation of the algorithm. Furthermore,\nformulae are given for producing the forward Markov representation of the a\nposteriori distribution over paths from the proposed likelihood representation."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-617",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09016"
    ],
    "b_title":[
      "Soliton resuscitations: asymmetric revivals of the breathing mode of an\n  atomic bright soliton in a harmonic trap"
    ],
    "b_abstract":[
      "We study the collective modes of an atomic bright soliton realised in a\nquasi-one-dimensional Bose-Einstein condensate, using Bogoliubov-de Gennes\ntheory. In particular we focus on the breathing mode of the soliton, which is\nnot a single linearized normal mode but a common component of many modes, and\ntherefore decays within a $t^{-1\/2}$ envelope due to dispersion. If the soliton\nis held in the center of a harmonic trap, we show that the breathing amplitude\nrevives periodically, as atoms shed from the vibrating soliton oscillate in the\ntrap, and return. After each revival the breathing amplitude again decays, and\nthis cycle repeats every trap half-period. The amplitude envelope of these\nbreathing revivals shows a curious asymmetry, however, with a gradual increase\nin breathing followed by sudden drop in breathing amplitude that becomes more\nand more pronounced in later revivals. We explain this asymmetrical revival\npattern by deriving a close analytical approximation to the Bogoliubov-de\nGennes frequency spectrum, and offer this coherent Bogoliubov-de Gennes\nphenomenon as a background against which to compare possible quantum many-body\neffects, including decoherence over trap-period time scales."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11919"
    ],
    "c_title":[
      "From Text to Trust: Empowering AI-assisted Decision Making with Adaptive\n  LLM-powered Analysis"
    ],
    "c_abstract":[
      "AI-assisted decision making becomes increasingly prevalent, yet individuals\noften fail to utilize AI-based decision aids appropriately especially when the\nAI explanations are absent, potentially as they do not %understand reflect on\nAI's decision recommendations critically. Large language models (LLMs), with\ntheir exceptional conversational and analytical capabilities, present great\nopportunities to enhance AI-assisted decision making in the absence of AI\nexplanations by providing natural-language-based analysis of AI's decision\nrecommendation, e.g., how each feature of a decision making task might\ncontribute to the AI recommendation. In this paper, via a randomized\nexperiment, we first show that presenting LLM-powered analysis of each task\nfeature, either sequentially or concurrently, does not significantly improve\npeople's AI-assisted decision performance. To enable decision makers to better\nleverage LLM-powered analysis, we then propose an algorithmic framework to\ncharacterize the effects of LLM-powered analysis on human decisions and\ndynamically decide which analysis to present. Our evaluation with human\nsubjects shows that this approach effectively improves decision makers'\nappropriate reliance on AI in AI-assisted decision making."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-618",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14669"
    ],
    "b_title":[
      "Reinforcement Learning-Based Neuroadaptive Control of Robotic\n  Manipulators under Deferred Constraints"
    ],
    "b_abstract":[
      "This paper presents a reinforcement learning-based neuroadaptive control\nframework for robotic manipulators operating under deferred constraints. The\nproposed approach improves traditional barrier Lyapunov functions by\nintroducing a smooth constraint enforcement mechanism that offers two key\nadvantages: (i) it minimizes control effort in unconstrained regions and\nprogressively increases it near constraints, improving energy efficiency, and\n(ii) it enables gradual constraint activation through a prescribed-time\nshifting function, allowing safe operation even when initial conditions violate\nconstraints. To address system uncertainties and improve adaptability, an\nactor-critic reinforcement learning framework is employed. The critic network\nestimates the value function, while the actor network learns an optimal control\npolicy in real time, enabling adaptive constraint handling without requiring\nexplicit system modeling. Lyapunov-based stability analysis guarantees the\nboundedness of all closed-loop signals. The effectiveness of the proposed\nmethod is validated through numerical simulations."
    ],
    "b_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21077"
    ],
    "c_title":[
      "Enhancing deep neural networks through complex-valued representations\n  and Kuramoto synchronization dynamics"
    ],
    "c_abstract":[
      "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "nlin.AO",
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-619",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18627"
    ],
    "b_title":[
      "A Radiance Field Loss for Fast and Simple Emissive Surface\n  Reconstruction"
    ],
    "b_abstract":[
      "We present a fast and simple technique to convert images into an emissive\nsurface-based scene representation. Building on existing emissive volume\nreconstruction algorithms, we introduce a subtle yet impactful modification of\nthe loss function requiring changes to only a few lines of code: instead of\nintegrating the radiance field along rays and supervising the resulting images,\nwe project the training images into the scene to directly supervise the\nspatio-directional radiance field.\n  The primary outcome of this change is the complete removal of alpha blending\nand ray marching from the image formation model, instead moving these steps\ninto the loss computation. In addition to promoting convergence to surfaces,\nthis formulation assigns explicit semantic meaning to 2D subsets of the\nradiance field, turning them into well-defined emissive surfaces. We finally\nextract a level set from this representation, which results in a high-quality\nemissive surface model.\n  Our method retains much of the speed and quality of the baseline algorithm.\nFor instance, a suitably modified variant of Instant~NGP maintains comparable\ncomputational efficiency, while achieving an average PSNR that is only 0.1 dB\nlower. Most importantly, our method generates explicit surfaces in place of an\nexponential volume, doing so with a level of simplicity not seen in prior work."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.06555"
    ],
    "c_title":[
      "A modified dynamic diffusion finite element method with optimal\n  convergence rate for convection-diffusion-reaction equations"
    ],
    "c_abstract":[
      "In this paper, we develop a modified nonlinear dynamic diffusion (DD) finite\nelement method for convection-diffusion-reaction equations. This method is free\nof stabilization parameters and is capable of precluding spurious oscillations.\nWe prove existence and, under an assumption of small mesh size, uniqueness of\nthe discrete solution, and derive the optimal first order convergence rate of\nthe approximation error in the energy norm plus a dissipation term. Numerical\nexamples are provided to verify the theoretical analysis."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-620",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05908"
    ],
    "b_title":[
      "Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo"
    ],
    "b_abstract":[
      "In image processing, solving inverse problems is the task of finding\nplausible reconstructions of an image that was corrupted by some (usually\nknown) degradation model. Commonly, this process is done using a generative\nimage model that can guide the reconstruction towards solutions that appear\nnatural. The success of diffusion models over the last few years has made them\na leading candidate for this task. However, the sequential nature of diffusion\nmodels makes this conditional sampling process challenging. Furthermore, since\ndiffusion models are often defined in the latent space of an autoencoder, the\nencoder-decoder transformations introduce additional difficulties. Here, we\nsuggest a novel sampling method based on sequential Monte Carlo (SMC) in the\nlatent space of diffusion models. We use the forward process of the diffusion\nmodel to add additional auxiliary observations and then perform an SMC sampling\nas part of the backward process. Empirical evaluations on ImageNet and FFHQ\nshow the benefits of our approach over competing methods on various inverse\nproblem tasks."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08778"
    ],
    "c_title":[
      "New constraints on the galactic ionizing efficiency and escape fraction\n  at 2.5 < z < 6 based on quasar absorption spectra"
    ],
    "c_abstract":[
      "Measurements of the ionization state of the intergalactic medium (IGM) can\nprobe the sources of the extragalactic ionizing background. We provide new\nmeasurements of the ionizing emissivity of galaxies using measurements of the\nionizing background and ionizing photon mean free path from high-redshift\nquasar spectra at $2.5 < z < 6$. Unlike most prior works, we account for\nradiative-transfer effects and possible neutral islands from the tail of\nreionization at $z > 5$. We combine our results with measurements of the UV\nluminosity function to constrain the average escaping ionizing efficiency of\ngalaxies, $\\langle f_{\\rm esc} \\xi_{\\rm ion}\\rangle_{L_{\\rm UV}}$. Assuming\ngalaxies with $M_{\\rm UV} < -11$ emit ionizing photons, we find $\\log (\\langle\nf_{\\rm esc} \\xi_{\\rm ion}\\rangle_{L_{\\rm UV}}\/{\\rm erg^{-1}Hz}) =\n24.47_{-0.17}^{+0.09}$ and $24.75_{-0.28}^{+0.15}$ at $z=5$ and $6$, and\n$1\\sigma$ upper limits of $24.48$ and $24.31$ at $z = 2.5$ and $4$,\nrespectively. We also estimate the population-averaged $f_{\\rm esc}$ using\nmeasurements of intrinsic ionizing efficiency from JWST. We find $\\langle\nf_{\\rm esc} \\rangle = 0.126_{-0.041}^{+0.034}$ and $0.224_{-0.108}^{+0.098}$ at\n$z=5$ and $6$, and $1\\sigma$ upper limits of $f_{\\rm esc}< 0.138$ and $0.096$\nat $z=2.5$ and $4$, respectively, for $M_{\\rm UV} < -11$. Our findings are\nconsistent with prior measurements of $f_{\\rm esc} \\lesssim 10\\%$ at $z \\leq\n4$, but indicate a factor of several increase between $z = 4$ and $6$. The\nsteepness of this evolution is sensitive to the highly uncertain mean free path\nand ionizing background intensity at $z>5$. Lastly, we find\n$1.10^{+0.21}_{-0.39}$ photons per H atom are emitted into the IGM between\n$z=6$ and $=5.3$. This is $\\approx 4\\times$ more than needed to complete the\nlast $20\\%$ of reionization absent recombinations, suggesting that\nreionization's end was likely absorption-dominated."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-621",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13199"
    ],
    "b_title":[
      "The Role of GitHub Copilot on Software Development: A Perspec-tive on\n  Productivity, Security, Best Practices and Future Directions"
    ],
    "b_abstract":[
      "GitHub Copilot is transforming software development by automating tasks and\nboosting productivity through AI-driven code generation. In this paper, we\ncon-duct a literature survey to synthesize insights on Copilot's impact on\nproductivity and security. We review academic journal databases, industry\nreports, and official docu-mentation to highlight key findings and challenges.\nWhile Copilot accelerates coding and prototyping, concerns over security\nvulnerabilities and intellectual property risks persist. Drawing from the\nliterature, we provide a perspective on best practices and future directions\nfor responsible AI adoption in software engineering, offering action-able\ninsights for developers and organizations to integrate Copilot effectively\nwhile maintaining high standards of quality and security."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20164"
    ],
    "c_title":[
      "At most n-valued maps"
    ],
    "c_abstract":[
      "This paper concerns various models of ``at-most-$n$-valued maps''. That is,\nmultivalued maps $f:X\\multimap Y$ for which $f(x)$ has cardinality at most $n$\nfor each $x$. We consider 4 classes of such maps which have appeared in the\nliterature: $\\mathcal U$, the set of exactly $n$-valued maps, or unions of\nsuch; $\\mathcal F$, the set of $n$-fold maps defined by Crabb; $\\mathcal S$,\nthe set of symmetric product maps; and $\\mathcal W$, the set of weighted maps\nwith weights in $\\mathbb N$. Our main result is roughly that these classes\nsatisfy the following containments: \\[ \\mathcal U \\subsetneq \\mathcal F\n\\subsetneq \\mathcal S = \\mathcal W \\]\n  Furthermore we define the general class $\\mathcal C$ of all\nat-most-$n$-valued maps, and show that there are maps in $\\mathcal C$ which are\noutside of any of the other classes above. We also describe a\nconfiguration-space point of view for the class $\\mathcal C$, defining a\nconfiguration space $C_n(Y)$ such that any at-most-$n$-valued map $f:X\\multimap\nY$ corresponds naturally to a single-valued map $f:X\\to C_n(Y)$. We give a full\ncalculation of the fundamental group and homology groups of $C_n(S^1)$."
    ],
    "c_categories":[
      [
        "math.GN"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-622",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17813"
    ],
    "b_title":[
      "Connectedness: a dimension of security bug severity assessment for\n  measuring uncertainty"
    ],
    "b_abstract":[
      "Current frameworks for evaluating security bug severity, such as the Common\nVulnerability Scoring System (CVSS), prioritize the ratio of exploitability to\nimpact. This paper suggests that the above approach measures the \"known knowns\"\nbut inadequately addresses the \"known unknowns\" especially when there exist\nmultiple possible exploit paths and side effects, which introduce significant\nuncertainty. This paper introduces the concept of connectedness, which measures\nhow strongly a security bug is connected with different entities, thereby\nreflecting the uncertainty of impact and the exploit potential. This work\nhighlights the critical but underappreciated role connectedness plays in\nseverity assessments."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16020"
    ],
    "c_title":[
      "Quantum skyrmions and antiskyrmions in monoaxial chiral magnets"
    ],
    "c_abstract":[
      "Classical monoaxial chiral magnets represent a unique magnetic system that\nallows for the stabilization of both skyrmions and antiskyrmions of equal\nenergy. Unlike a similar situation in frustrated magnets, the energy landscape\nhere is much simpler, consisting of four states: the saturated ferromagnetic\nstate, spin-spiral, skyrmion, and antiskyrmion. This simplicity makes such\nsystems interesting for potential applications that rely on manipulating these\nstates. We study the quantum analog of the already established classical theory\nby investigating the low-energy excitation spectra of a spin-1\/2 quantum\nHeisenberg model with monoaxial Dzyaloshinskii-Moriya interaction. Using the\ndensity matrix renormalization group method, we establish that such a model\nsupports the existence of skyrmion and antiskyrmion states of equal energy.\nThis degeneracy allows for the existence of a mesoscopic Schr\\\"odinger cat\nstate exhibiting properties of both skyrmion and antiskyrmion. To characterize\nthis superposition, we calculate two-point correlation functions that can be\nmeasured in neutron scattering experiments. Finally, we introduce a\nperturbation in the form of a magnetic field gradient to induce a non-trivial\ntime evolution of the superposition state. We study this time evolution using\nboth a numerical variational approach and the collective coordinates method."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-623",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03116"
    ],
    "b_title":[
      "Poincar\\'{e}-Birkhoff-Witt Theorems in Higher Algebra"
    ],
    "b_abstract":[
      "We extend the classical Poincar\\'e-Birkhoff-Witt theorem to higher algebra by\nestablishing a version that applies to spectral Lie algebras. We deduce this\nstatement from a basic relation between operads in spectra: the commutative\noperad is the quotient of the associative operad by a right action of the\nspectral Lie operad. This statement, in turn, is a consequence of a fundamental\nrelation between different $\\mathbb{E}_n$-operads, which we articulate and\nprove. We deduce a variant of the Poincar\\'{e}--Birkhoff--Witt theorem for\nrelative enveloping algebras of $\\mathbb{E}_n$-algebras. Our methods also give\na simple construction and description of the higher enveloping\n$\\mathbb{E}_n$-algebras of a spectral Lie algebra."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.CT",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.05658"
    ],
    "c_title":[
      "Instability of the ferromagnetic phase under random fields in an Ising\n  spin glass with correlated disorder"
    ],
    "c_abstract":[
      "It is well established that the ferromagnetic phase remains stable under\nrandom magnetic fields in three and higher dimensions for the ferromagnetic\nIsing model and the Edwards-Anderson model of spin glasses without correlation\nin the disorder variables. We investigate an Ising spin glass with correlated\ndisorder and demonstrate that the ferromagnetic phase on the Nishimori line\nbecomes unstable under random fields in any dimension, provided that magnetic\nfield chaos exists in the Edwards-Anderson model on the same lattice. This\nresult underscores the profound impact of spatial correlations in the disorder.\nAdditionally, we show that this instability can also be attributed to disorder\n(bond) chaos. Furthermore, we argue that the model with correlated disorder\nremains in the ferromagnetic phase even in the presence of symmetry-breaking\nfields, as long as the Edwards-Anderson model on the same lattice exhibits a\nspin glass phase under a magnetic field. These findings reveal fundamentally\ndifferent properties of the ferromagnetic phase in models with correlation in\ndisorder compared to those without."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-624",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15196"
    ],
    "b_title":[
      "Detectability of oxygen fugacity regimes in the magma ocean world 55\n  Cancri e at high spectral resolution"
    ],
    "b_abstract":[
      "Ultra-short Period exoplanets (USPs) like 55 Cnc e, hosting dayside magma\noceans, present unique opportunities to study surface-atmosphere interactions.\nThe composition of a vaporised mineral atmosphere enveloping the dayside is\ndictated by that of the surface magma ocean, which in turn is sensitive to its\noxygen fugacity ($f$O$_2$). Observability estimations and characterisation of\nthe atmospheric emission of 55 Cnc e have mostly remained limited to low\nspectral resolution space-based studies. Here, we aim to examine ground-based\nhigh-resolution observabilities of a diverse set of mineral atmospheres\nproduced across a grid of mantle $f$O$_2$s varying over 12 orders of magnitude.\nWe assume a Bulk Silicate Earth mantle composition and a substellar dayside\ntemperature of T = 2500K in the near infrared wavelength (NIR) region. This\nspectral range is often featureless for this class of atmospheres at\nlow-resolution. Coupling our newly developed simulator for synthesising\nrealistic observations from high-resolution ground-based spectrographs (Ratri)\nto a pre-developed high-resolution cross-correlation spectroscopy (HRCCS)\nanalysis pipeline (Upamana), we find that this array of mineral atmospheres\nwould all be detectable with 11 hours of observing time of the dayside of 55\nCnc e with CARMENES and each individual scenario can be correctly\ndifferentiated within 1$\\sigma$. Our analysis is readily able to distinguish\nbetween a planet with an Earth-like redox state (with $f$O$_2$ $\\sim$3.5\nlog$_{10}$ units above the iron-w\\\"ustite, IW buffer) from a Mercury-like\nplanet ($f$O$_2$ $\\sim$5 log$_{10}$ units below IW). We thus conclude that the\nHRCCS technique holds promise for cataloguing the diversity of redox states\namong the rocky exoplanetary population."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.17645"
    ],
    "c_title":[
      "A modified Bellman-Ford Algorithm for Application in Symbolic Optimal\n  Control and Plan and Goal Recognition"
    ],
    "c_abstract":[
      "The contributions of this short technical note are two-fold. Firstly, we\nintroduce a modified version of a generalized Bellman-Ford algorithm\ncalculating the value function of optimal control problems defined on\nhyper-graphs. Those Bellman-Ford algorithms can be used in particular for the\nsynthesis of near-optimal controllers by the principle of symbolic control. Our\nmodification causes less nodes of the hyper-graph being iterated during the\nexecution compared to our initial version of the algorithm published in 2020.\nOur second contribution lies in the field of Plan recognition applied to drone\nmissions driven by symbolic controllers. We address and resolve the Plan and\nGoal Recognition monitor's dependence on a pre-defined initial guess for a\ndrone's task allocation and mission execution. To validate the enhanced\nimplementation, we use a more challenging scenario for UAV-based aerial\nfirefighting, demonstrating the practical applicability and robustness of the\nsystem architecture."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-625",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05388"
    ],
    "b_title":[
      "Modular programming of interaction and geometric specificity enables\n  assembly of complex DNA origami nanostructures"
    ],
    "b_abstract":[
      "We present a modular DNA origami design approach to address the challenges of\nassembling geometrically complex nanoscale structures, including those with\nnonuniform Gaussian curvature. This approach features a core structure that\ncompletely conserves the scaffold routing across different designs and\npreserves more than 70% of the DNA staples between designs, dramatically\nreducing both cost and effort, while enabling precise and independent\nprogramming of subunit interactions and binding angles through adjustable\noverhang lengths and sequences. Using cryogenic electron microscopy, gel\nelectrophoresis, and coarse-grained molecular dynamics simulations, we validate\na set of robust design rules. We demonstrate the method's utility by assembling\na variety of self-limiting structures, including anisotropic shells with\ncontrolled inter-subunit interactions and curvature, and a toroid with globally\nvarying curvature. Our strategy is both cost-effective and versatile, providing\na promising and efficient solution for the synthetic fabrication of complex\nnanostructures."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10827"
    ],
    "c_title":[
      "E-3DGS: Event-Based Novel View Rendering of Large-Scale Scenes Using 3D\n  Gaussian Splatting"
    ],
    "c_abstract":[
      "Novel view synthesis techniques predominantly utilize RGB cameras, inheriting\ntheir limitations such as the need for sufficient lighting, susceptibility to\nmotion blur, and restricted dynamic range. In contrast, event cameras are\nsignificantly more resilient to these limitations but have been less explored\nin this domain, particularly in large-scale settings. Current methodologies\nprimarily focus on front-facing or object-oriented (360-degree view) scenarios.\nFor the first time, we introduce 3D Gaussians for event-based novel view\nsynthesis. Our method reconstructs large and unbounded scenes with high visual\nquality. We contribute the first real and synthetic event datasets tailored for\nthis setting. Our method demonstrates superior novel view synthesis and\nconsistently outperforms the baseline EventNeRF by a margin of 11-25% in PSNR\n(dB) while being orders of magnitude faster in reconstruction and rendering."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-626",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03077"
    ],
    "b_title":[
      "MochiSwarm: A testbed for robotic blimps in realistic environments"
    ],
    "b_abstract":[
      "Testing aerial robots in tasks such as pickup-and-delivery and surveillance\nsignificantly benefits from high energy efficiency and scalability of the\ndeployed robotic system. This paper presents MochiSwarm, an open-source testbed\nof light-weight robotic blimps, ready for multi-robot operation without\nexternal localization. We introduce the system design in hardware, software,\nand perception, which capitalizes on modularity, low cost, and light weight.\nThe hardware allows for rapid modification, which enables the integration of\nadditional sensors to enhance autonomy for different scenarios. The software\nframework supports different actuation models and communication between the\nbase station and multiple blimps. The detachable perception module allows\nindependent blimps to perform tasks that involve detection and autonomous\nactuation. We showcase a differential-drive module as an example, of which the\nautonomy is enabled by visual servoing using the perception module. A case\nstudy of pickup-and-delivery tasks with up to 12 blimps highlights the autonomy\nof the MochiSwarm without external infrastructures."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17477"
    ],
    "c_title":[
      "Bayesian generative models can flag performance loss, bias, and\n  out-of-distribution image content"
    ],
    "c_abstract":[
      "Generative models are popular for medical imaging tasks such as anomaly\ndetection, feature extraction, data visualization, or image generation. Since\nthey are parameterized by deep learning models, they are often sensitive to\ndistribution shifts and unreliable when applied to out-of-distribution data,\ncreating a risk of, e.g. underrepresentation bias. This behavior can be flagged\nusing uncertainty quantification methods for generative models, but their\navailability remains limited. We propose SLUG: A new UQ method for VAEs that\ncombines recent advances in Laplace approximations with stochastic trace\nestimators to scale gracefully with image dimensionality. We show that our UQ\nscore -- unlike the VAE's encoder variances -- correlates strongly with\nreconstruction error and racial underrepresentation bias for dermatological\nimages. We also show how pixel-wise uncertainty can detect out-of-distribution\nimage content such as ink, rulers, and patches, which is known to induce\nlearning shortcuts in predictive models."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-627",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13676"
    ],
    "b_title":[
      "Certified Robustness Under Bounded Levenshtein Distance"
    ],
    "b_abstract":[
      "Text classifiers suffer from small perturbations, that if chosen\nadversarially, can dramatically change the output of the model. Verification\nmethods can provide robustness certificates against such adversarial\nperturbations, by computing a sound lower bound on the robust accuracy.\nNevertheless, existing verification methods incur in prohibitive costs and\ncannot practically handle Levenshtein distance constraints. We propose the\nfirst method for computing the Lipschitz constant of convolutional classifiers\nwith respect to the Levenshtein distance. We use these Lipschitz constant\nestimates for training 1-Lipschitz classifiers. This enables computing the\ncertified radius of a classifier in a single forward pass. Our method, LipsLev,\nis able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and\n$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude\nfaster than existing approaches. We believe our work can open the door to more\nefficient verification in the text domain."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03588"
    ],
    "c_title":[
      "Complementary Probes of Warped Extra Dimension: Colliders, Gravitational\n  Waves and Primordial Black Holes from Phase Transitions"
    ],
    "c_abstract":[
      "We study the formation of primordial black holes (PBHs) and stochastic\ngravitational waves background (SGWB) produced by the supercooled radion phase\ntransition (PT) in warped extra-dimension models solving the gauge hierarchy\nproblem. We first determine how the SGWB and the produced PBH mass and\nabundance depend on the warped model's infrared energy scale $\\rho$, and the\nnumber of holographic colors $N$. With this finding, we recast on the plane\n$\\{\\rho, N\\}$ the current SGWB and PBH constraints, as well as the expected\nparameter reaches of GW detectors, as LISA and ET, and the gravitational\nlensing ones, such as NGRST. On the same plane, we also map the collider bounds\non massive graviton production, and cosmological bounds on the radion\nphenomenology. We find that, for $N \\sim 10-50$, the considered PT predicts a\nPBH population mass in the range $M_{\\rm PBH}\\sim(10^{-1} - 10^{-25})\nM_{\\odot}$ for $\\rho \\sim (10^{-4} - 10^{8})\\textrm{ TeV}$. In the range $\\rho\n\\simeq (0.05 - 0.5)$ GeV, it can explain the recent SGWB hint at nHz\nfrequencies and generate PBH binaries with mass $M_{\\rm PBH}\\sim(0.1 - 1 )\nM_\\odot$ detectable at LISA and ET. The experimentally allowed mass region\nwhere PBHs can account for the whole dark matter abundance, and are produced\nwith a tuning $\\lesssim 10^{-4}$, corresponds to $10$ TeV $\\lesssim\n\\rho\\lesssim$ $10^4$ TeV. These PBHs can compensate the lack of natural\ncandidates for dark matter in warped extra dimensional models. Such a region\nrepresents a great science case where forthcoming and future colliders like\nHE-LHC and FCC-hh, gravitational-wave observatories and other PBHs probes play\na key complementary role."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-628",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15171"
    ],
    "b_title":[
      "Charging dynamics of electric double layer capacitors including\n  beyond-mean-field electrostatic correlations"
    ],
    "b_abstract":[
      "Electric double layer (EDL) formation underlies the functioning of\nsupercapacitors and several other electrochemical technologies. Here, we study\nhow the EDL formation near two flat blocking electrodes separated by $2L$ is\naffected by beyond-mean-field Coulombic interactions, which can be substantial\nfor electrolytes of high salt concentration or with multivalent ions. Our model\ncombines the Nernst-Planck and Bazant-Storey-Kornyshev (BSK) equations; the\nlatter is a modified Poisson equation with a correlation length $\\ell_c$. In\nresponse to a voltage step, the system charges exponentially with a\ncharacteristic timescale $\\tau$ that depends nonmonotonically on $\\ell_c$. For\nsmall $\\ell_c$, $\\tau$ is given by the BSK capacitance times a dilute\nelectrolyte's resistance, in line with [Zhao, Phys. Rev. E 84, 051504 (2011)];\nhere, $\\tau$ decreases with increasing $\\ell_c$. Increasing the correlation\nlength beyond $\\ell_c\\approx L^{2\/3}\\lambda_D^{1\/3}$, with $\\lambda_D$ the\nDebye length, $\\tau$ reaches a minimum, rises as $\\tau\\propto\n\\lambda_D\\ell_c\/D$, and plateaus at $\\tau=4L^2\/(\\pi^2 D)$. Our results imply\nthat strongly correlated, strongly confined electrolytes - ionic liquids in the\nsurface force balance apparatus, say - move slower than predicted so far."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08254"
    ],
    "c_title":[
      "UniCoRN: Unified Commented Retrieval Network with LMMs"
    ],
    "c_abstract":[
      "Multimodal retrieval methods have limitations in handling complex,\ncompositional queries that require reasoning about the visual content of both\nthe query and the retrieved entities. On the other hand, Large Multimodal\nModels (LMMs) can answer with language to more complex visual questions, but\nwithout the inherent ability to retrieve relevant entities to support their\nanswers. We aim to address these limitations with UniCoRN, a Unified Commented\nRetrieval Network that combines the strengths of composed multimodal retrieval\nmethods and generative language approaches, going beyond Retrieval-Augmented\nGeneration (RAG). We introduce an entity adapter module to inject the retrieved\nmultimodal entities back into the LMM, so it can attend to them while\ngenerating answers and comments. By keeping the base LMM frozen, UniCoRN\npreserves its original capabilities while being able to perform both retrieval\nand text generation tasks under a single integrated framework. To assess these\nnew abilities, we introduce the Commented Retrieval task (CoR) and a\ncorresponding dataset, with the goal of retrieving an image that accurately\nanswers a given question and generate an additional textual response that\nprovides further clarification and details about the visual information. We\ndemonstrate the effectiveness of UniCoRN on several datasets showing\nimprovements of +4.5% recall over the state of the art for composed multimodal\nretrieval and of +14.9% METEOR \/ +18.4% BEM over RAG for commenting in CoR."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-629",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14039"
    ],
    "b_title":[
      "AtomProNet: Data flow to and from machine learning interatomic\n  potentials in materials science"
    ],
    "b_abstract":[
      "As the atomistic simulations of materials science move from traditional\npotentials to machine learning interatomic potential (MLIP), the field is\nentering the second phase focused on discovering and explaining new material\nphenomena. While MLIP development relies on curated data and flexible datasets\nfrom ab-initio simulations, transitioning seamlessly between ab-initio\nworkflows and MLIP frameworks remains challenging. A global survey was\nconducted to understand the current standing (progress and bottleneck) of the\nmachine learning-guided materials science research. The survey responses have\nbeen implemented to design an open-source software to reduce the access\nbarriers of MLIP models for the global scientific community. Here, we present\nAtomProNet, an open-source Python package that automates obtaining atomic\nstructures, prepares and submits ab-initio jobs, and efficiently collects\nbatch-processed data for streamlined neural network (NN) training. Finally, we\ncompared empirical and start-of-the-art machine learning potential, showing the\npracticality of using MLIPs based on computational time and resources."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.01317"
    ],
    "c_title":[
      "DietGlance: Dietary Monitoring and Personalized Analysis at a Glance\n  with Knowledge-Empowered AI Assistant"
    ],
    "c_abstract":[
      "Growing awareness of wellness has prompted people to consider whether their\ndietary patterns align with their health and fitness goals. In response,\nresearchers have introduced various wearable dietary monitoring systems and\ndietary assessment approaches. However, these solutions are either limited to\nidentifying foods with simple ingredients or insufficient in providing analysis\nof individual dietary behaviors with domain-specific knowledge. In this paper,\nwe present DietGlance, a system that automatically monitors dietary in daily\nroutines and delivers personalized analysis from knowledge sources. DietGlance\nfirst detects ingestive episodes from multimodal inputs using eyeglasses,\ncapturing privacy-preserving meal images of various dishes being consumed.\nBased on the inferred food items and consumed quantities from these images,\nDietGlance further provides nutritional analysis and personalized dietary\nsuggestions, empowered by the retrieval augmentation generation module on a\nreliable nutrition library. A short-term user study (N=33) and a four-week\nlongitudinal study (N=16) demonstrate the usability and effectiveness of\nDietGlance, offering insights and implications for future AI-assisted dietary\nmonitoring and personalized healthcare intervention systems using eyewear."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-630",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01474"
    ],
    "b_title":[
      "Interactive Navigation for Legged Manipulators with Learned Arm-Pushing\n  Controller"
    ],
    "b_abstract":[
      "Interactive navigation is crucial in scenarios where proactively interacting\nwith objects can yield shorter paths, thus significantly improving traversal\nefficiency. Existing methods primarily focus on using the robot body to\nrelocate large obstacles (which could be comparable to the size of a robot).\nHowever, they prove ineffective in narrow or constrained spaces where the\nrobot's dimensions restrict its manipulation capabilities. This paper\nintroduces a novel interactive navigation framework for legged manipulators,\nfeaturing an active arm-pushing mechanism that enables the robot to reposition\nmovable obstacles in space-constrained environments. To this end, we develop a\nreinforcement learning-based arm-pushing controller with a two-stage reward\nstrategy for large-object manipulation. Specifically, this strategy first\ndirects the manipulator to a designated pushing zone to achieve a kinematically\nfeasible contact configuration. Then, the end effector is guided to maintain\nits position at appropriate contact points for stable object displacement while\npreventing toppling. The simulations validate the robustness of the arm-pushing\ncontroller, showing that the two-stage reward strategy improves policy\nconvergence and long-term performance. Real-world experiments further\ndemonstrate the effectiveness of the proposed navigation framework, which\nachieves shorter paths and reduced traversal time. The open-source project can\nbe found at\nhttps:\/\/github.com\/Zhihaibi\/Interactive-Navigation-for-legged-manipulator.git."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10578"
    ],
    "c_title":[
      "Benchmarking low-power flopping-mode spin qubit fidelities in Si\/SiGe\n  devices with alloy disorder"
    ],
    "c_abstract":[
      "In the \"flopping-mode\" regime of electron spin resonance, a single electron\nconfined in a double quantum dot is electrically driven in the presence of a\nmagnetic field gradient. The increased dipole moment of the charge in the\nflopping mode significantly reduces the amount of power required to drive spin\nrotations. However, the susceptibility of flopping-mode spin qubits to charge\nnoise, and consequently their overall performance, has not been examined in\ndetail. In this work, we simulate single-qubit gate fidelities of electrically\ndriven spin rotations in an ensemble of devices configured to operate in both\nthe single-dot and flopping-mode regimes. Our model accounts for the valley\nphysics of conduction band electrons in silicon and realistic alloy disorder in\nthe SiGe barrier layers, allowing us to investigate device-to-device\nvariability. We include charge and magnetic noise, as well as spin relaxation\nprocesses arising from charge noise and electron-phonon coupling. We find that\nthe two operating modes exhibit significantly different susceptibilities to the\nvarious noise sources, with valley splitting and spin relaxation times also\nplaying a role in their relative performance. For realistic noise strengths, we\nfind that single-dot gate fidelities are limited by magnetic noise while\nflopping-mode fidelities are primarily limited by charge noise and spin\nrelaxation. For sufficiently long spin relaxation times, flopping-mode spin\noperation is feasible with orders-of-magnitude lower drive power and gate\nfidelities that are on par with conventional single-dot electric dipole spin\nresonance."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-631",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19921"
    ],
    "b_title":[
      "Shifting the Paradigm: A Diffeomorphism Between Time Series Data\n  Manifolds for Achieving Shift-Invariancy in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning models lack shift invariance, making them sensitive to input\nshifts that cause changes in output. While recent techniques seek to address\nthis for images, our findings show that these approaches fail to provide\nshift-invariance in time series, where the data generation mechanism is more\nchallenging due to the interaction of low and high frequencies. Worse, they\nalso decrease performance across several tasks. In this paper, we propose a\nnovel differentiable bijective function that maps samples from their\nhigh-dimensional data manifold to another manifold of the same dimension,\nwithout any dimensional reduction. Our approach guarantees that samples -- when\nsubjected to random shifts -- are mapped to a unique point in the manifold\nwhile preserving all task-relevant information without loss. We theoretically\nand empirically demonstrate that the proposed transformation guarantees\nshift-invariance in deep learning models without imposing any limits to the\nshift. Our experiments on six time series tasks with state-of-the-art methods\nshow that our approach consistently improves the performance while enabling\nmodels to achieve complete shift-invariance without modifying or imposing\nrestrictions on the model's topology. The source code is available on\n\\href{https:\/\/github.com\/eth-siplab\/Shifting-the-Paradigm}{GitHub}."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03057"
    ],
    "c_title":[
      "Interacting mesons as degrees of freedom in a chiral model"
    ],
    "c_abstract":[
      "We study the equation of state of hot and dense hadronic matter using an\nextended Chiral Mean Field (CMF) model framework where the addition is the\ninclusion of interactions of thermally excited mesons. This is implemented by\ncalculating the in-medium masses of pseudoscalar and vector mesons, obtained\nthrough the explicit chiral symmetry-breaking and vector interaction terms in\nthe Lagrangian, respectively, prior to applying the mean-field approximation.\nAs a result, the in-medium meson contributions generate a feedback term to the\nCMF's equations of motion, which then modifies the equation of state. With this\nimprovement, we quantify the effect on the equation of state of strongly\ninteracting matter through comparisons with state-of-the-art lattice QCD\nresults and other hadronic models like the Hadron Resonance Gas model. We find\nthat the results of the updated hadronic CMF model with an improved meson\ndescription (mCMF) provide a better agreement with lattice-QCD data for\nthermodynamic state variables across a wide range of temperatures and baryon\nchemical potentials."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-632",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12178"
    ],
    "b_title":[
      "Public Sector Efficiency in Delivering Social Services and Its Impact on\n  Human Development: A Comparative Study of Healthcare and Education Spending\n  in India, Pakistan, and Bangladesh"
    ],
    "b_abstract":[
      "The research investigates the effects of public spending on health and\neducation in shaping the human development in south Asian three countries:\nIndia, Pakistan and Bangladesh. The study uses the VAR (Vector Auto regression)\nmodel to estimate the effects on government spending on these sectors to\nevaluate the human development. The findings state that there are different\ndegrees of impact in these three countries. In Bangladesh and India, health\nspending increases the human development in short term. On the other hand\neducation spending shows the significance on the HDI.Moreover, the study also\nhighlights that there are different levels of effectiveness of government\nspending across these three countries. In order to maximize the human\ndevelopment an optimum country specific strategies should be adopted."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "2501.12243"
    ],
    "c_title":[
      "FOCUS: First Order Concentrated Updating Scheme"
    ],
    "c_abstract":[
      "Large language models (LLMs) demonstrate remarkable performance, and\nimproving their pre-training process appears to be key to enhancing their\ncapabilities further. Based on the documented success of Adam, learning rate\ndecay, and weight decay, we hypothesize that the pre-training loss landscape\nfeatures a narrowing valley structure. Through experiments with synthetic loss\nfunctions, we discover that when gradient query noise is high relative to the\nvalley's sharpness, Adam's performance falls behind that of Signum because Adam\nreduces the effective step size too drastically. This observation led us to\ndevelop FOCUS, an optimizer that enhances Signum by incorporating attraction\ntoward moving averaged parameters, allowing it to handle noise better while\nmaintaining larger step sizes. In training GPT-2, FOCUS proves to be more\nstable than Signum and faster than Adam. These results suggest that gradient\nnoise may be an underappreciated limiting factor in LLM training, and FOCUS\noffers promising solutions."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-633",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14344"
    ],
    "b_title":[
      "Towards Accurate Binary Spiking Neural Networks: Learning with Adaptive\n  Gradient Modulation Mechanism"
    ],
    "b_abstract":[
      "Binary Spiking Neural Networks (BSNNs) inherit the eventdriven paradigm of\nSNNs, while also adopting the reduced storage burden of binarization\ntechniques. These distinct advantages grant BSNNs lightweight and\nenergy-efficient characteristics, rendering them ideal for deployment on\nresource-constrained edge devices. However, due to the binary synaptic weights\nand non-differentiable spike function, effectively training BSNNs remains an\nopen question. In this paper, we conduct an in-depth analysis of the challenge\nfor BSNN learning, namely the frequent weight sign flipping problem. To\nmitigate this issue, we propose an Adaptive Gradient Modulation Mechanism\n(AGMM), which is designed to reduce the frequency of weight sign flipping by\nadaptively adjusting the gradients during the learning process. The proposed\nAGMM can enable BSNNs to achieve faster convergence speed and higher accuracy,\neffectively narrowing the gap between BSNNs and their full-precision\nequivalents. We validate AGMM on both static and neuromorphic datasets, and\nresults indicate that it achieves state-of-the-art results among BSNNs. This\nwork substantially reduces storage demands and enhances SNNs' inherent energy\nefficiency, making them highly feasible for resource-constrained environments."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.16663"
    ],
    "c_title":[
      "Arecibo Multi-frequency IPS Observations: Solar Wind Density Turbulence\n  Scale Sizes and their Anisotropy"
    ],
    "c_abstract":[
      "We present an analysis of interplanetary scintillation (IPS) observations\nconducted with the Arecibo 305-m radio telescope during the minimum phase at\nthe end of solar cycle 24 and the onset of solar cycle 25. These observations\nspan a broad frequency range of ~300 to 3100 MHz, encompassing the P-, L-, and\nS-bands, and covered heliocentric distances from ~5 to 200 solar radii. The\ndynamic spectrum of the scintillations obtained at L-band shows a systematic\ndecrease in the scintillation index from the lowest to the highest frequency,\noffering valuable insight into the influence of the solar wind density\nmicrostructures responsible for scintillation. Analyses of the scintillation\nindex ($m$) for multiple sources at L-band, along with near-simultaneous\nobservations of selected sources covering the P-, L-, and S-bands, clearly\ndemonstrate a wavelength dependence of $m \\propto \\lambda^\\omega$, which\ninherently leads to a dependence of $m$ on the Fresnel scale, when considering\nthe effective distance to the scattering screen, $z$. The index $\\omega$ ranges\nbetween $\\sim$1 and 1.8. The average $\\omega$ value of a source, determined\nfrom observations made on different days, exhibits variability across sources.\nThe results on the radial dependence of scintillation agree with earlier IPS\nmeasurements. The temporal power spectra obtained over the wide frequency range\nexhibit a power-level evolution in accordance with the wavelength dependence,\nand a broadening with increasing observation frequency. Furthermore, the\nincreased temporal-frequency rounding of the `Fresnel knee' in the spectrum\nwith the observing frequency suggests a novel phenomenon: an increase in\nanisotropy as the scale size of the density-turbulence structure decreases."
    ],
    "c_categories":[
      [
        "astro-ph.SR",
        "physics.plasm-ph",
        "physics.space-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-634",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11071"
    ],
    "b_title":[
      "Generalization of the Gibbs algorithm with high probability at low\n  temperatures"
    ],
    "b_abstract":[
      "The paper gives a bound on the generalization error of the Gibbs algorithm,\nwhich recovers known data-independent bounds for the high temperature range and\nextends to the low-temperature range, where generalization depends critically\non the data-dependent loss-landscape. It is shown, that with high probability\nthe generalization error of a single hypothesis drawn from the Gibbs posterior\ndecreases with the total prior volume of all hypotheses with similar or smaller\nempirical error. This gives theoretical support to the belief in the benefit of\nflat minima. The zero temperature limit is discussed and the bound is extended\nto a class of similar stochastic algorithms."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21166"
    ],
    "c_title":[
      "Autonomous Curriculum Design via Relative Entropy Based Task\n  Modifications"
    ],
    "c_abstract":[
      "Curriculum learning is a training method in which an agent is first trained\non a curriculum of relatively simple tasks related to a target task in an\neffort to shorten the time required to train on the target task. Autonomous\ncurriculum design involves the design of such curriculum with no reliance on\nhuman knowledge and\/or expertise. Finding an efficient and effective way of\nautonomously designing curricula remains an open problem. We propose a novel\napproach for automatically designing curricula by leveraging the learner's\nuncertainty to select curricula tasks. Our approach measures the uncertainty in\nthe learner's policy using relative entropy, and guides the agent to states of\nhigh uncertainty to facilitate learning. Our algorithm supports the generation\nof autonomous curricula in a self-assessed manner by leveraging the learner's\npast and current policies but it also allows the use of teacher guided design\nin an instructive setting. We provide theoretical guarantees for the\nconvergence of our algorithm using two time-scale optimization processes.\nResults show that our algorithm outperforms randomly generated curriculum, and\nlearning directly on the target task as well as the curriculum-learning\ncriteria existing in literature. We also present two additional heuristic\ndistance measures that could be combined with our relative-entropy approach for\nfurther performance improvements."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-635",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12408"
    ],
    "b_title":[
      "On the Robust Approximation of ASR Metrics"
    ],
    "b_abstract":[
      "Recent advances in speech foundation models are largely driven by scaling\nboth model size and data, enabling them to perform a wide range of tasks,\nincluding speech recognition. Traditionally, ASR models are evaluated using\nmetrics like Word Error Rate (WER) and Character Error Rate (CER), which depend\non ground truth labels. As a result of limited labeled data from diverse\ndomains and testing conditions, the true generalization capabilities of these\nmodels beyond standard benchmarks remain unclear. Moreover, labeling data is\nboth costly and time-consuming. To address this, we propose a novel label-free\napproach for approximating ASR performance metrics, eliminating the need for\nground truth labels. Our method utilizes multimodal embeddings in a unified\nspace for speech and transcription representations, combined with a\nhigh-quality proxy model to compute proxy metrics. These features are used to\ntrain a regression model to predict key ASR metrics like Word Error Rate (WER)\nand Character Error Rate (CER). We experiment with over 40 models across 14\ndatasets representing both standard and in-the-wild testing conditions. Our\nresults show that we approximate the metrics within a single-digit absolute\ndifference across all experimental configurations, outperforming the most\nrecent baseline by more than 50\\%."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02109"
    ],
    "c_title":[
      "Structural Transitions and Melting of Two-Dimensional Ion Crystals in RF\n  Traps"
    ],
    "c_abstract":[
      "We investigate the structural properties and melting behavior of\ntwo-dimensional ion crystals in an RF trap, focusing on the effects of ion\ntemperature and trap potential symmetry. We identify distinct crystal\nstructures that form under varying trapping conditions and temperatures through\nexperimental observations and theoretical analyses. As the temperature\nincreases or the trap potential becomes more symmetric, we observe a transition\nfrom a lattice arrangement to elongated ring-like formations aligned along the\ntrap axes. Our experimental and theoretical efforts enhance our understanding\nof phase transitions in low-dimensional, confined systems, offering insights\ninto the controlled formation of quantum crystals for applications in quantum\nsimulations and many-body physics."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-636",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09594"
    ],
    "b_title":[
      "SimLingo: Vision-Only Closed-Loop Autonomous Driving with\n  Language-Action Alignment"
    ],
    "b_abstract":[
      "Integrating large language models (LLMs) into autonomous driving has\nattracted significant attention with the hope of improving generalization and\nexplainability. However, existing methods often focus on either driving or\nvision-language understanding but achieving both high driving performance and\nextensive language understanding remains challenging. In addition, the dominant\napproach to tackle vision-language understanding is using visual question\nanswering. However, for autonomous driving, this is only useful if it is\naligned with the action space. Otherwise, the model's answers could be\ninconsistent with its behavior. Therefore, we propose a model that can handle\nthree different tasks: (1) closed-loop driving, (2) vision-language\nunderstanding, and (3) language-action alignment. Our model SimLingo is based\non a vision language model (VLM) and works using only camera, excluding\nexpensive sensors like LiDAR. SimLingo obtains state-of-the-art performance on\nthe widely used CARLA simulator on the Bench2Drive benchmark and is the winning\nentry at the CARLA challenge 2024. Additionally, we achieve strong results in a\nwide variety of language-related tasks while maintaining high driving\nperformance."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13005"
    ],
    "c_title":[
      "Hyperinvariant subspaces of block-triangular operators on Hilbert space"
    ],
    "c_abstract":[
      "We show that if a nonscalar operator on a separable Hilbert space has a\nnontrivial invariant subspace, then it has also a nontrivial hyperinvariant\nsubspace. Thus the hyperinvariant subspace problem is equivalent to the\ninvariant subspace problem. As a consequence we obtain that every bilateral\nweighted shift has a proper hyprinvariant subspace. Our proof is based on a\nrecent structure theorem in \\cite{HP}, originated in the approach to almost\ninvariant half-spaces in \\cite{APTT} (see also \\cite{Tc}).\n  The idea that such a result would be possible came from the paper\n\\cite{Pearcy} by the second author which was submitted to Acta Szeged for\npublication. The manuscript contained the construction we use herein and also\nset forth the rank inequality that we use to obtain the contradiction that\nyields the desired theorem. The proof given in \\cite{Pearcy} of that theorem\nwas incorrect, however, and it's proof turned out to be rather difficult, and\nwas eventually found by the first author of this paper."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-637",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12485"
    ],
    "b_title":[
      "Safe at the Margins: A General Approach to Safety Alignment in\n  Low-Resource English Languages -- A Singlish Case Study"
    ],
    "b_abstract":[
      "To ensure safe usage, Large Language Models (LLMs) typically undergo\nalignment with human-defined values. However, this alignment often relies on\nprimarily English data and is biased towards Western-centric values, limiting\nits effectiveness in low-resource language settings. In this paper, we describe\nour approach for aligning SEA-Lion-v2.1-Instruct (a Llama3-8B variant) to\nminimize toxicity in Singlish, an English creole specific to Singapore. We find\nthat supervised fine-tuning and Kahneman-Tversky Optimization (KTO) on paired\nand unpaired preferences is more sample efficient and yields significantly\nbetter results than Direct Preference Optimization (DPO). Our analysis reveals\nthat DPO implicitly enforces a weaker safety objective than KTO, and that SFT\ncomplements KTO by improving training stability. Finally, we introduce a simple\nbut novel modification to KTO, KTO-S, which improves training stability through\nbetter gradient exploitation. Overall, we present a general approach for safety\nalignment conducive to low-resource English languages, successfully reducing\ntoxicity by 99\\% on our Singlish benchmark, with gains generalizing to the\nbroader TOXIGEN dataset while maintaining strong performance across standard\nLLM benchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02853"
    ],
    "c_title":[
      "BaTiO$_3$ -- SrTiO$_3$ composites: a microscopic study on paraelectric\n  cubic inclusions"
    ],
    "c_abstract":[
      "Composites of ferroelectric and paraelectric perovskites have attracted a lot\nof attention due to their application potential in energy storage as well as\nnovel computing and memory devices. So far the main focus of research has been\non superlattices and ferroelectric particles in a paraelectric matrix, while\nthe impact of paraelectric inclusions on the ferroelectric matrix is\nsurprisingly underrepresented. To close this gap in knowledge we perform\nmolecular dynamics simulations using an $ab\\ initio$ derived effective\nHamiltonian for BaTiO$_3$--SrTiO$_3$ and reveal the dependency of phase\nstability and phase transitions on the size and distances of paraelectric\ninclusions. We discuss how the combination of compressive strain and\ndepolarization fields at the SrTiO$_3$ interfaces induces large local\npolarization, complex domain structures and coexisting phases as well as\ndiffuse phase transitions and reduced coercive fields."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-638",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20034"
    ],
    "b_title":[
      "Vision-Encoders (Already) Know What They See: Mitigating Object\n  Hallucination via Simple Fine-Grained CLIPScore"
    ],
    "b_abstract":[
      "Recently, Large Vision-Language Models (LVLMs) show remarkable performance\nacross various domains. However, these models suffer from object hallucination.\nThis study revisits the previous claim that the primary cause of such\nhallucination lies in the limited representational capacity of the vision\nencoder. Our analysis reveals that the capacity of the vision encoder itself is\nalready enough for detecting object hallucination. Based on this insight, we\npropose a Fine-grained CLIPScore (F-CLIPScore), a simple yet effective\nevaluation metric that enhances object-level granularity by incorporating text\nembeddings at the noun phrase level. Evaluations on the OHD-Caps benchmark show\nthat F-CLIPScore significantly outperforms conventional CLIPScore in accuracy\nby a large margin of 39.6% without additional training. We further validate\nF-CLIPScore by showing that LVLM trained with the data filtered using\nF-CLIPScore exhibits reduced hallucination."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11178"
    ],
    "c_title":[
      "Formation of a Single Bioconvection Spot in Euglena Suspension Induced\n  by Negative Phototaxis"
    ],
    "c_abstract":[
      "Microorganisms are known to alter their motility in response to external\nstimuli. A typical example is the responseknown as taxis, which includes\nbehaviors such as moving toward a light source (positive phototaxis) or away\nfrom it(negative phototaxis). In this study, we focused on bioconvection\ninduced by the negative phototaxis of a Euglenasuspension exposed to strong\nlight from the bottom. Recent studies have revealed that Euglena\nbioconvectioninduced by negative phototaxis exhibits localized structure. In a\nprevious study, we found that a single Euglenabioconvection spot (EBC spot)\nmaintains its structure in a cylindrical container. Such a localized structure\nis notexclusive to Euglena, but has also reported in red tide algae, suggesting\nthat this is a universal feature ofbioconvection phenomena. In this paper, we\ninvestigated the formation conditions of EBC spot phenomena throughexperiments\nand numerical simulations. In the experiments, we examined the variation in EBC\nspot formation as afunction of suspension height and average cell density,\nrevealing that the critical average cell density increases withsuspension\nheight. In the numerical simulations, we conducted bioconvection simulations\nbased on a model ofEuglena motility that incorporated three types of behavior:\nthe negative gravitaxis, negative phototaxis, andbehavior of moving toward\ndarker areas. Our model successfully reproduced the localized state of a\ntwo-dimensional EBC spot. Furthermore, calculations corresponding to the\nexperimental conditions of suspension heightand average cell density revealed\nthat the critical average cell density for bioconvection decreases as\nthesuspension height increases."
    ],
    "c_categories":[
      [
        "physics.bio-ph",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-639",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07369"
    ],
    "b_title":[
      "Uniform Kernel Prober"
    ],
    "b_abstract":[
      "The ability to identify useful features or representations of the input data\nbased on training data that achieves low prediction error on test data across\nmultiple prediction tasks is considered the key to multitask learning success.\nIn practice, however, one faces the issue of the choice of prediction tasks and\nthe availability of test data from the chosen tasks while comparing the\nrelative performance of different features. In this work, we develop a class of\npseudometrics called Uniform Kernel Prober (UKP) for comparing features or\nrepresentations learned by different statistical models such as neural networks\nwhen the downstream prediction tasks involve kernel ridge regression. The\nproposed pseudometric, UKP, between any two representations, provides a uniform\nmeasure of prediction error on test data corresponding to a general class of\nkernel ridge regression tasks for a given choice of a kernel without access to\ntest data. Additionally, desired invariances in representations can be\nsuccessfully captured by UKP only through the choice of the kernel function and\nthe pseudometric can be efficiently estimated from $n$ input data samples with\n$O(\\frac{1}{\\sqrt{n}})$ estimation error. We also experimentally demonstrate\nthe ability of UKP to discriminate between different types of features or\nrepresentations based on their generalization performance on downstream kernel\nridge regression tasks."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12448"
    ],
    "c_title":[
      "Survey of Radiative, Two-Temperature Magnetically Arrested Simulations\n  of the Black Hole M87* I: Turbulent Electron Heating"
    ],
    "c_abstract":[
      "We present a set of eleven two-temperature, radiative, general relativistic\nmagnetohydrodynamic (2TGRRMHD) simulations of the black hole M87* in the\nmagnetically arrested (MAD) state, surveying different values of the black hole\nspin $a_*$. Our 3D simulations self-consistently evolve the temperatures of\nseparate electron and ion populations under the effects of adiabatic\ncompression\/expansion, viscous heating, Coulomb coupling, and synchrotron,\nbremsstrahlung, and inverse Compton radiation. We adopt a sub-grid heating\nprescription from gyrokinetic simulations of plasma turbulence. Our simulations\nhave accretion rates $\\dot{M}=(0.5-1.5)\\times10^{-6}\\dot{M}_{\\rm Edd}$ and\nradiative efficiencies $\\epsilon_{\\rm rad}=3-35\\%$. We compare our simulations\nto a fiducial set of otherwise identical single-fluid GRMHD simulations and\nfind no significant changes in the outflow efficiency or black hole spindown\nparameter. Our simulations produce an effective adiabatic index for the\ntwo-temperature plasma of $\\Gamma_{\\rm gas}\\approx1.55$, larger than the\n$\\Gamma_{\\rm gas}=13\/9$ value often adopted in single-fluid GRMHD simulations.\nWe find moderate ion-to-electron temperature ratios in the 230 GHz emitting\nregion of $R=T_{\\rm i}\/T_{\\rm e}{\\approx}5$. While total intensity 230 GHz\nimages from our simulations are consistent with Event Horizon Telescope (EHT)\nresults, our images have significantly more beam-scale linear polarization\n($\\langle|m|\\rangle\\approx 30\\%$) than is observed in EHT images of M87*\n($\\langle|m|\\rangle<10\\%$). We find a trend of the average linear polarization\npitch angle $\\angle\\beta_2$ with black hole spin consistent with what is seen\nin single-fluid GRMHD simulations, and we provide a simple fitting function for\n$\\angle\\beta_2(a_*)$ motivated by the wind-up of magnetic field lines by black\nhole spin in the Blandford-Znajek mechanism."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-640",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17727"
    ],
    "b_title":[
      "Can Score-Based Generative Modeling Effectively Handle Medical Image\n  Classification?"
    ],
    "b_abstract":[
      "The remarkable success of deep learning in recent years has prompted\napplications in medical image classification and diagnosis tasks. While\nclassification models have demonstrated robustness in classifying simpler\ndatasets like MNIST or natural images such as ImageNet, this resilience is not\nconsistently observed in complex medical image datasets where data is more\nscarce and lacks diversity. Moreover, previous findings on natural image\ndatasets have indicated a potential trade-off between data likelihood and\nclassification accuracy. In this study, we explore the use of score-based\ngenerative models as classifiers for medical images, specifically mammographic\nimages. Our findings suggest that our proposed generative classifier model not\nonly achieves superior classification results on CBIS-DDSM, INbreast and Vin-Dr\nMammo datasets, but also introduces a novel approach to image classification in\na broader context. Our code is publicly available at\nhttps:\/\/github.com\/sushmitasarker\/sgc_for_medical_image_classification"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17541"
    ],
    "c_title":[
      "The Koszul Property for Truncations of Nonstandard Graded Polynomial\n  Rings"
    ],
    "c_abstract":[
      "We prove that truncations of nonstandard graded polynomial rings are\n(nonstandard) Koszul modules in the sense of Herzog and Iyengar. This provides\nan analogue of the fact that such truncations have linear resolutions in the\nstandard graded case."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-641",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15287"
    ],
    "b_title":[
      "Distributed Generalized Linear Models: A Privacy-Preserving Approach"
    ],
    "b_abstract":[
      "This paper presents a novel approach to classical linear regression, enabling\nmodel computation from data streams or in a distributed setting while\npreserving data privacy in federated environments. We extend this framework to\ngeneralized linear models (GLMs), ensuring scalability and adaptability to\ndiverse data distributions while maintaining privacy-preserving properties. To\nassess the effectiveness of our approach, we conduct numerical studies on both\nsimulated and real datasets, comparing our method with conventional maximum\nlikelihood estimation for GLMs using iteratively reweighted least squares. Our\nresults demonstrate the advantages of the proposed method in distributed and\nfederated settings."
    ],
    "b_categories":[
      [
        "cs.DC",
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05614"
    ],
    "c_title":[
      "Watermarking Graph Neural Networks via Explanations for Ownership\n  Protection"
    ],
    "c_abstract":[
      "Graph Neural Networks (GNNs) are the mainstream method to learn pervasive\ngraph data and are widely deployed in industry, making their intellectual\nproperty valuable. However, protecting GNNs from unauthorized use remains a\nchallenge. Watermarking, which embeds ownership information into a model, is a\npotential solution. However, existing watermarking methods have two key\nlimitations: First, almost all of them focus on non-graph data, with\nwatermarking GNNs for complex graph data largely unexplored. Second, the de\nfacto backdoor-based watermarking methods pollute training data and induce\nownership ambiguity through intentional misclassification. Our\nexplanation-based watermarking inherits the strengths of backdoor-based methods\n(e.g., robust to watermark removal attacks), but avoids data pollution and\neliminates intentional misclassification. In particular, our method learns to\nembed the watermark in GNN explanations such that this unique watermark is\nstatistically distinct from other potential solutions, and ownership claims\nmust show statistical significance to be verified. We theoretically prove that,\neven with full knowledge of our method, locating the watermark is an NP-hard\nproblem. Empirically, our method manifests robustness to removal attacks like\nfine-tuning and pruning. By addressing these challenges, our approach marks a\nsignificant advancement in protecting GNN intellectual property."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-642",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11092"
    ],
    "b_title":[
      "Storing quantum coherence in a quantum dot nuclear spin ensemble for\n  over 100 milliseconds"
    ],
    "b_abstract":[
      "States with long coherence are a crucial requirement for qubits and quantum\nmemories. Nuclear spins in epitaxial quantum dots are a great candidate,\noffering excellent isolation from external environments and on-demand coupling\nto optical flying qubits. However, coherence times are limited to $\\lesssim1$\nms by the dipole-dipole interactions between the nuclei and their quadrupolar\ncoupling to inhomogeneous crystal strain. Here, we combine strain engineering\nof the nuclear spin ensemble and tailored dynamical decoupling sequences to\nachieve nuclear spin coherence times exceeding 100 ms. Recently, a reversible\ntransfer of quantum information into nuclear spin ensembles has been\ndemonstrated in quantum dots. Our results provide a path to develop this\nconcept into a functioning solid-state quantum memory suitable for quantum\nrepeaters in optical quantum communication networks."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17061"
    ],
    "c_title":[
      "Replay4NCL: An Efficient Memory Replay-based Methodology for\n  Neuromorphic Continual Learning in Embedded AI Systems"
    ],
    "c_abstract":[
      "Neuromorphic Continual Learning (NCL) paradigm leverages Spiking Neural\nNetworks (SNNs) to enable continual learning (CL) capabilities for AI systems\nto adapt to dynamically changing environments. Currently, the state-of-the-art\nemploy a memory replay-based method to maintain the old knowledge. However,\nthis technique relies on long timesteps and compression-decompression steps,\nthereby incurring significant latency and energy overheads, which are not\nsuitable for tightly-constrained embedded AI systems (e.g., mobile\nagents\/robotics). To address this, we propose Replay4NCL, a novel efficient\nmemory replay-based methodology for enabling NCL in embedded AI systems.\nSpecifically, Replay4NCL compresses the latent data (old knowledge), then\nreplays them during the NCL training phase with small timesteps, to minimize\nthe processing latency and energy consumption. To compensate the information\nloss from reduced spikes, we adjust the neuron threshold potential and learning\nrate settings. Experimental results on the class-incremental scenario with the\nSpiking Heidelberg Digits (SHD) dataset show that Replay4NCL can preserve old\nknowledge with Top-1 accuracy of 90.43% compared to 86.22% from the\nstate-of-the-art, while effectively learning new tasks, achieving 4.88x latency\nspeed-up, 20% latent memory saving, and 36.43% energy saving. These results\nhighlight the potential of our Replay4NCL methodology to further advances NCL\ncapabilities for embedded AI systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-643",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04908"
    ],
    "b_title":[
      "HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned\n  with HDL Engineers"
    ],
    "b_abstract":[
      "Recently, the use of large language models (LLMs) for Verilog code generation\nhas attracted great research interest to enable hardware design automation.\nHowever, previous works have shown a gap between the ability of LLMs and the\npractical demands of hardware description language (HDL) engineering. This gap\nincludes differences in how engineers phrase questions and hallucinations in\nthe code generated. To address these challenges, we introduce HaVen, a novel\nLLM framework designed to mitigate hallucinations and align Verilog code\ngeneration with the practices of HDL engineers. HaVen tackles hallucination\nissues by proposing a comprehensive taxonomy and employing a chain-of-thought\n(CoT) mechanism to translate symbolic modalities (e.g. truth tables, state\ndiagrams, etc.) into accurate natural language descriptions. Furthermore, HaVen\nbridges this gap by using a data augmentation strategy. It synthesizes\nhigh-quality instruction-code pairs that match real HDL engineering practices.\nOur experiments demonstrate that HaVen significantly improves the correctness\nof Verilog code generation, outperforming state-of-the-art LLM-based Verilog\ngeneration methods on VerilogEval and RTLLM benchmark. HaVen is publicly\navailable at https:\/\/github.com\/Intelligent-Computing-Research-Group\/HaVen."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13015"
    ],
    "c_title":[
      "High-performance and reliable probabilistic Ising machine based on\n  simulated quantum annealing"
    ],
    "c_abstract":[
      "Probabilistic computing with pbits is emerging as a computational paradigm\nfor machine learning and for facing combinatorial optimization problems (COPs)\nwith the so-called probabilistic Ising machines (PIMs). From a hardware point\nof view, the key elements that characterize a PIM are the random number\ngeneration, the nonlinearity, the network of coupled pbits, and the energy\nminimization algorithm. Regarding the latter, in this work we show that PIMs\nusing the simulated quantum annealing (SQA) schedule exhibit better performance\nas compared to simulated annealing and parallel tempering in solving a number\nof COPs, such as maximum satisfiability problems, planted Ising problem, and\ntravelling salesman problem. Additionally, we design and simulate the\narchitecture of a fully connected CMOS based PIM able to run the SQA algorithm\nhaving a spin-update time of 8 ns with a power consumption of 0.22 mW. Our\nresults also show that SQA increases the reliability and the scalability of\nPIMs by compensating for device variability at an algorithmic level enabling\nthe development of their implementation combining CMOS with different\ntechnologies such as spintronics. This work shows that the characteristics of\nthe SQA are hardware agnostic and can be applied in the co-design of any hybrid\nanalog digital Ising machine implementation. Our results open a promising\ndirection for the implementation of a new generation of reliable and scalable\nPIMs."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-644",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08892"
    ],
    "b_title":[
      "Fast, Accurate Numerical Evaluation of Incomplete Planck Integrals"
    ],
    "b_abstract":[
      "Methods for computing the integral of the Planck blackbody function over a\nfinite spectral range, the so-called incomplete Planck integral, are necessary\nto perform multigroup radiative transfer calculations. We present a comparison,\nin terms of speed and accuracy, of a wide array of approaches to numerically\nevaluating these integrals. Our results indicate that a direct rational\npolynomial approximation to these integrals has the best combination of\naccuracy and efficiency. We also present for the first time a derivation of the\npolylogarithm form of these integrals and show that modern approaches to\npolylogarithm evaluation are suitable for numerically evaluating incomplete\nPlanck integrals. This article is dedicated to Prof. B.D. Ganapol, the\nTransport Cowboy, on the occasion of his retirement."
    ],
    "b_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.04408"
    ],
    "c_title":[
      "Transforming Multimodal Models into Action Models for Radiotherapy"
    ],
    "c_abstract":[
      "Radiotherapy is a crucial cancer treatment that demands precise planning to\nbalance tumor eradication and preservation of healthy tissue. Traditional\ntreatment planning (TP) is iterative, time-consuming, and reliant on human\nexpertise, which can potentially introduce variability and inefficiency. We\npropose a novel framework to transform a large multimodal foundation model\n(MLM) into an action model for TP using a few-shot reinforcement learning (RL)\napproach. Our method leverages the MLM's extensive pre-existing knowledge of\nphysics, radiation, and anatomy, enhancing it through a few-shot learning\nprocess. This allows the model to iteratively improve treatment plans using a\nMonte Carlo simulator. Our results demonstrate that this method outperforms\nconventional RL-based approaches in both quality and efficiency, achieving\nhigher reward scores and more optimal dose distributions in simulations on\nprostate cancer data. This proof-of-concept suggests a promising direction for\nintegrating advanced AI models into clinical workflows, potentially enhancing\nthe speed, quality, and standardization of radiotherapy treatment planning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-645",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02582"
    ],
    "b_title":[
      "Carleman-lattice-Boltzmann quantum circuit with matrix access oracles"
    ],
    "b_abstract":[
      "We apply Carleman linearization of the Lattice Boltzmann (CLB) representation\nof fluid flows to quantum emulate the dynamics of a 2D Kolmogorov-like flow. We\nassess the accuracy of the result and find a relative error of the order of\n$10^{-3}$ with just two Carleman iterates, for a range of the Reynolds number\nup to a few hundreds. We first define a gate-based quantum circuit for the\nimplementation of the CLB method and then exploit the sparse nature of the CLB\nmatrix to build a quantum circuit based on block-encoding techniques which\nmakes use of matrix oracles. It is shown that the gate complexity of the\nalgorithm is thereby dramatically reduced, from exponential to quadratic.\nHowever, due to the need of employing up to seven ancilla qubits, the\nprobability of success of the corresponding circuit for a single time step is\ntoo low to enable multi-step time evolution. Several possible directions to\ncircumvent this problem are briefly outlined."
    ],
    "b_categories":[
      [
        "physics.comp-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.15889"
    ],
    "c_title":[
      "Adaptive Width Neural Networks"
    ],
    "c_abstract":[
      "For almost 70 years, researchers have mostly relied on hyper-parameter tuning\nto pick the width of neural networks' layers out of many possible choices. This\npaper challenges the status quo by introducing an easy-to-use technique to\nlearn an unbounded width of a neural network's layer during training. The\ntechnique does not rely on alternate optimization nor hand-crafted gradient\nheuristics; rather, it jointly optimizes the width and the parameters of each\nlayer via simple backpropagation. We apply the technique to a broad range of\ndata domains such as tables, images, texts, and graphs, showing how the width\nadapts to the task's difficulty. By imposing a soft ordering of importance\namong neurons, it is possible to truncate the trained network at virtually zero\ncost, achieving a smooth trade-off between performance and compute resources in\na structured way. Alternatively, one can dynamically compress the network with\nno performance degradation. In light of recent foundation models trained on\nlarge datasets, believed to require billions of parameters and where\nhyper-parameter tuning is unfeasible due to huge training costs, our approach\nstands as a viable alternative for width learning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-646",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18056"
    ],
    "b_title":[
      "RL-based Query Rewriting with Distilled LLM for online E-Commerce\n  Systems"
    ],
    "b_abstract":[
      "Query rewriting (QR) is a critical technique in e-commerce search, addressing\nthe lexical gap between user queries and product descriptions to enhance search\nperformance. Existing QR approaches typically fall into two categories:\ndiscriminative models and generative methods leveraging large language models\n(LLMs). Discriminative models often struggle with natural language\nunderstanding and offer limited flexibility in rewriting, while generative\nLLMs, despite producing high-quality rewrites, face high inference latency and\ncost in online settings. These limitations force offline deployment, making\nthem vulnerable to issues like information staleness and semantic drift. To\novercome these challenges, we propose a novel hybrid pipeline for QR that\nbalances efficiency and effectiveness. Our approach combines offline knowledge\ndistillation to create a lightweight but efficient student model with online\nreinforcement learning (RL) to refine query rewriting dynamically using\nreal-time feedback. A key innovation is the use of LLMs as simulated human\nfeedback, enabling scalable reward signals and cost-effective evaluation\nwithout manual annotations. Experimental results on Amazon ESCI dataset\ndemonstrate significant improvements in query relevance, diversity, and\nadaptability, as well as positive feedback from the LLM simulation. This work\ncontributes to advancing LLM capabilities for domain-specific applications,\noffering a robust solution for dynamic and complex e-commerce search\nenvironments."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.19246"
    ],
    "c_title":[
      "Computational Assessment of Hemodynamics in Asymmetric-type Lesion of\n  Idealized Coronary Stenoses"
    ],
    "c_abstract":[
      "Coronary artery stenosis, characterized by the narrowing of the lumen,\nsignificantly affects blood flow and contributes to the progression of\ncardiovascular diseases. This study investigates the hemodynamics of coronary\nartery models with varying stenosis configurations, all maintaining an 80%\nlumen reduction, to determine how differences in morphology influence flow\nbehavior and mechanical stresses. We employed computational fluid dynamics to\nanalyze five idealized geometries with (10% & 70%), (20% & 60%), (30% & 50%),\n(40% & 40%), and (0% & 80%) stenosis configurations. Through physiological\npulsatile flow conditions, we evaluated key hemodynamic pattern including\nvelocity profiles, wall shear stress, and pressure distribution. Our results\nreveal that despite the same degree of lumen reduction, each stenosis\nconfiguration produced distinct flow patterns and hemodynamic profiles.\nAsymmetric configurations, such as 10% & 70% and 20% & 60%, exhibited\npronounced flow disruptions and higher wall shear stress at the stenosis\nthroats, while symmetric configurations, such as 40% & 40%, demonstrated more\nuniform flow and reduced vortex. Our findings challenge the practice of\ngeneralizing results across stenosis configurations without accounting for\nmorphological variations, which is prevalent in many CFD studies using\nidealized models. This study emphasizes the importance of considering\nstenosis-specific morphology in CFD analyses and clinical interpretations to\nenhance the accuracy of diagnostic tools, improve personalized treatment\nplanning, and guide the design of medical devices such as stents."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-647",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00275"
    ],
    "b_title":[
      "Simultaneous Estimation of Manipulation Skill and Hand Grasp Force from\n  Forearm Ultrasound Images"
    ],
    "b_abstract":[
      "Accurate estimation of human hand configuration and the forces they exert is\ncritical for effective teleoperation and skill transfer in robotic\nmanipulation. A deeper understanding of human interactions with objects can\nfurther enhance teleoperation performance. To address this need, researchers\nhave explored methods to capture and translate human manipulation skills and\napplied forces to robotic systems. Among these, biosignal-based approaches,\nparticularly those using forearm ultrasound data, have shown significant\npotential for estimating hand movements and finger forces. In this study, we\npresent a method for simultaneously estimating manipulation skills and applied\nhand force using forearm ultrasound data. Data collected from seven\nparticipants were used to train deep learning models for classifying\nmanipulation skills and estimating grasp force. Our models achieved an average\nclassification accuracy of 94.87 percent plus or minus 10.16 percent for\nmanipulation skills and an average root mean square error (RMSE) of 0.51 plus\nor minus 0.19 Newtons for force estimation, as evaluated using five-fold\ncross-validation. These results highlight the effectiveness of forearm\nultrasound in advancing human-machine interfacing and robotic teleoperation for\ncomplex manipulation tasks. This work enables new and effective possibilities\nfor human-robot skill transfer and tele-manipulation, bridging the gap between\nhuman dexterity and robotic control."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.ET",
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12519"
    ],
    "c_title":[
      "Simple Proofs of the Summation and Connectivity Theorems in Metabolic\n  Control Analysis"
    ],
    "c_abstract":[
      "In the early 1970s, the Kacser\/Burns and the Heinrich\/Rapoport groups\nindependently discovered the important summation and connectivity theorems in\nmetabolic control analysis. These theorems were derived originally by using\nthought experiments and proved mathematically later. The mathematical proofs\nare not easy for me to read and follow. But the proofs actually can be very\nsimple and need only a couple of lines as I give here."
    ],
    "c_categories":[
      [
        "q-bio.MN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-648",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02323"
    ],
    "b_title":[
      "Hybrid Resolver Model Generalization for Fault Condition Modeling: A\n  Promising Tool for Reliability Study"
    ],
    "b_abstract":[
      "Resolvers, like all electromagnetic devices, are constantly under\ninvestigation, both operationally and structurally. In this regard, proposing a\nmodeling methodology that can save significant time without compromising\naccuracy is a big honor. In this study, a generalized hybrid model is suggested\nthat, in addition to the above benefits, has sufficient capability to ease\nreliability study in the field of resolvers, where a large number of faulty\nconditions must be investigated under different operating conditions, including\nchanges in angular velocity, voltage, and frequency of excitation; all of which\nare highlighted in the context of fault coverage. This model also serves as a\npromising tool for generating large datasets, which is advantageous for fault\ndiagnosis. A resolver with a non-uniform air gap is chosen as a case study to\nchallenge the suggested model, particularly in relation to eccentricity faults.\nWe generalize the suggested model to account for the most common faulty\nconditions of resolvers: in-turn short circuits in signal and excitation\nwindings, as well as static and dynamic eccentricity faults. The close\nagreement between the results of the suggested model and those from\nTime-Stepping Finite Element Analysis (TS-FEA), along with significant time\nsavings in both healthy and faulty conditions, highlights the generality and\nproficiency of the suggested model. Finally, the case study is prototyped, and\nwe verify the accuracy of the suggested model experimentally."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.10661"
    ],
    "c_title":[
      "Enumeration of consecutive patterns in flattened Catalan words"
    ],
    "c_abstract":[
      "A Catalan word $w$ is said to be flattened if the subsequence of $w$ obtained\nby taking the first letter of each weakly increasing run is nondecreasing. Let\n$\\mathcal{F}_n$ denote the set of flattened Catalan words of length $n$, which\nhas cardinality $\\frac{3^{n-1}+1}{2}$ for all $n \\geq 1$. In this paper, we\nconsider the distribution of several consecutive patterns on $\\mathcal{F}_n$.\nIndeed, we find explicit formulas for the generating functions of the joint\ndistribution on $\\mathcal{F}_n$ of several trios of patterns, along with an\nauxiliary parameter. As special cases of these formulas, we obtain the\ngenerating function for the distribution of all consecutive patterns of length\ntwo or three. The following equivalences with regard to being identically\ndistributed on $\\mathcal{F}_n$ arise when comparing the various generating\nfunctions and may be explained bijectively: $112\\approx122$ and\n$211\\approx221\\approx231$. In addition, explicit expressions are found for the\ntotal number of occurrences on $\\mathcal{F}_n$ of each pattern of length two or\nthree as well as for the number of avoiders of each pattern. These results can\nbe obtained as special cases of our more general formulas for the generating\nfunctions, but may be explained combinatorially as well, the arguments of which\nare featured herein."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-649",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10662"
    ],
    "b_title":[
      "Analyzing the Higgs-confinement transition with non-local operators on\n  the lattice"
    ],
    "b_abstract":[
      "We study non-local operators for analyzing the Higgs-confinement phase\ntransition in lattice gauge theory. Since the nature of the Higgs-confinement\nphase transition is topological, its order parameter is the expectation value\nof non-local operators, such as loop and surface operators. There exist several\ncandidates for the non-local operators. Adopting the charge-2 Abelian Higgs\nmodel, we test numerical simulation of conventional ones, the Polyakov loop and\nthe 't Hooft loop, and an unconventional one, the Aharonov-Bohm phase defined\nby the Wilson loop wrapping around a vortex line."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02553"
    ],
    "c_title":[
      "Upper and lower bounds on TVD and KLD between centered elliptical\n  distributions in high-dimensional setting"
    ],
    "c_abstract":[
      "In this paper, we derive some upper and lower bounds and inequalities for the\ntotal variation distance (TVD) and the Kullback-Leibler divergence (KLD), also\nknown as the relative entropy, between two probability measures $\\mu$ and $\\nu$\ndefined by $$\n  D_{\\mathrm{TV}} ( \\mu, \\nu ) = \\sup_{B \\in \\mathcal{B} (\\mathbb{R}^n)}\n  \\left| \\mu(B) - \\nu(B) \\right|\n  \\quad \\text{and} \\quad\n  D_{\\mathrm{KL}} ( \\mu \\, \\| \\, \\nu ) = \\int_{\\mathbb{R}^n}\n  \\ln \\left( \\frac{d\\mu(x)}{d\\nu(x)} \\right) \\, \\mu(dx) $$ correspondingly when\nthe dimension $n$ is high. We begin with some elementary bounds for centered\nelliptical distributions admitting densities and showcase how these bounds may\nbe used by estimating the TVD and KLD between multivariate Student and\nmultivariate normal distribution in the high-dimensional setting. Next, we show\nhow the same approach simplifies when we apply it to multivariate Gamma\ndistributions with independent components (in the latter case, we only study\nthe TVD, because KLD may be calculated explicitly, see [1]). Our approach is\nmotivated by the recent contribution by Barabesi and Pratelli [2]."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-650",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08884"
    ],
    "b_title":[
      "Improved Compression Bounds for Scenario Decision Making"
    ],
    "b_abstract":[
      "Scenario decision making offers a flexible way of making decision in an\nuncertain environment while obtaining probabilistic guarantees on the risk of\nfailure of the decision. The idea of this approach is to draw samples of the\nuncertainty and make a decision based on the samples, called \"scenarios\". The\nprobabilistic guarantees take the form of a bound on the probability of\nsampling a set of scenarios that will lead to a decision whose risk of failure\nis above a given maximum tolerance. This bound can be expressed as a function\nof the number of sampled scenarios, the maximum tolerated risk, and some\nintrinsic property of the problem called the \"compression size\". Several such\nbounds have been proposed in the literature under various assumptions on the\nproblem. We propose new bounds that improve upon the existing ones without\nrequiring stronger assumptions on the problem."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10621"
    ],
    "c_title":[
      "RoMu4o: A Robotic Manipulation Unit For Orchard Operations Automating\n  Proximal Hyperspectral Leaf Sensing"
    ],
    "c_abstract":[
      "Driven by the need to address labor shortages and meet the demands of a\nrapidly growing population, robotic automation has become a critical component\nin precision agriculture. Leaf-level hyperspectral spectroscopy is shown to be\na powerful tool for phenotyping, monitoring crop health, identifying essential\nnutrients within plants as well as detecting diseases and water stress. This\nwork introduces RoMu4o, a robotic manipulation unit for orchard operations\noffering an automated solution for proximal hyperspectral leaf sensing. This\nground robot is equipped with a 6DOF robotic arm and vision system for\nreal-time deep learning-based image processing and motion planning. We\ndeveloped robust perception and manipulation pipelines that enable the robot to\nsuccessfully grasp target leaves and perform spectroscopy. These frameworks\noperate synergistically to identify and extract the 3D structure of leaves from\nan observed batch of foliage, propose 6D poses, and generate collision-free\nconstraint-aware paths for precise leaf manipulation. The end-effector of the\narm features a compact design that integrates an independent lighting source\nwith a hyperspectral sensor, enabling high-fidelity data acquisition while\nstreamlining the calibration process for accurate measurements. Our ground\nrobot is engineered to operate in unstructured orchard environments. However,\nthe performance of the system is evaluated in both indoor and outdoor plant\nmodels. The system demonstrated reliable performance for 1-LPB hyperspectral\nsampling, achieving 95% success rate in lab trials and 79% in field trials.\nField experiments revealed an overall success rate of 70% for autonomous leaf\ngrasping and hyperspectral measurement in a pistachio orchard. The open-source\nrepository is available at: https:\/\/github.com\/mehradmrt\/UCM-AgBot-ROS2"
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-651",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03121"
    ],
    "b_title":[
      "The Littlewood decomposition via colored Frobenius partitions"
    ],
    "b_abstract":[
      "The Littlewood decomposition for partitions is a well-known bijection between\npartitions and pairs of $t$-core and $t$-quotient partitions. This\ndecomposition can be described in several ways, such as the $t$-abacus method\nof James or the biinfinite word method of Garvan, Kim, and Stanton. In a recent\nstudy, Frobenius partitions have proven to be a highly useful tool in dealing\nwith partition statistics related to $t$-core partitions. Motivated by this\nstudy, in this paper, we present an alternative description of the Littlewood\ndecomposition using Frobenius partitions. We also apply our approach to\nself-conjugate partitions and doubled distinct partitions, and give new\ncharacterizations of their $t$-cores and $t$-quotients."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.10728"
    ],
    "c_title":[
      "DarkBench: Benchmarking Dark Patterns in Large Language Models"
    ],
    "c_abstract":[
      "We introduce DarkBench, a comprehensive benchmark for detecting dark design\npatterns--manipulative techniques that influence user behavior--in interactions\nwith large language models (LLMs). Our benchmark comprises 660 prompts across\nsix categories: brand bias, user retention, sycophancy, anthropomorphism,\nharmful generation, and sneaking. We evaluate models from five leading\ncompanies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs\nare explicitly designed to favor their developers' products and exhibit\nuntruthful communication, among other manipulative behaviors. Companies\ndeveloping LLMs should recognize and mitigate the impact of dark design\npatterns to promote more ethical AI."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-652",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13997"
    ],
    "b_title":[
      "Characterizing Beam Profiles in Accelerator Neutrino Experiments through\n  Off-Axis Neutrino Interactions"
    ],
    "b_abstract":[
      "We introduce a novel approach that utilizes neutrino events from the off-axis\nnear detector to investigate the beam profile in long-baseline neutrino\nexperiments. Understanding the dynamics of the neutrino beam is crucial for\nimproving the precision of neutrino oscillation measurements. We demonstrate\nthat certain observables related to the azimuthal angle of the neutrino\ndirection are useful for determining the average neutrino production point from\nexperimental data, providing a valuable cross-check against Monte Carlo\nsimulations. Additionally, these observables can help identify potential\nalignment issues between the detector and the decay volume. In future neutrino\nexperiments with significantly higher statistics, these observables will become\nessential to ensure the accuracy and stability of the beam profile."
    ],
    "b_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.13737"
    ],
    "c_title":[
      "Point Cloud Surface Parametrization with HAND and LEG: Hausdorff\n  Approximation from Node-wise Distances and Localized Energy for Geometry"
    ],
    "c_abstract":[
      "Surface parametrization plays a crucial role in various fields, such as\ncomputer graphics and medical imaging, and computational science and\nengineering. However, most existing techniques rely on the discretization of\nthe surface into a triangular mesh. This paper addresses the problem of point\ncloud surface parametrization and presents two novel loss functions and a\nframework for point cloud surface parametrization based on deep neural\nnetworks. The first loss function aims to provide a soft constraint on\nparameter domain, allowing the handling of parameter domains with complex\nshapes or geometries. This loss function can also be used in generalizing\nlandmark matching. The second loss function focuses on minimizing local\ndistortion on the point cloud surface, demonstrating effectiveness in\npreserving the surface's local shape characteristics. We parametrized the\nfunctions involved using neural networks, and developed an algorithm for the\nminimization. Numerical experiments for shape matching, free-boundary and\nfixed-boundary surface parametrization and landmark matching, along with\napplications including surface reconstruction and boundary detection, are\npresented to demonstrate the effectiveness of our proposed methods."
    ],
    "c_categories":[
      [
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-653",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03432"
    ],
    "b_title":[
      "A formalization of Borel determinacy in Lean"
    ],
    "b_abstract":[
      "We present a formalization of Borel determinacy in the Lean 4 theorem prover.\nThe formalization includes a definition of Gale-Stewart games and a proof of\nMartin's theorem stating that Borel games are determined. The proof closely\nfollows Martin's \"A purely inductive proof of Borel determinacy\"."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.00579"
    ],
    "c_title":[
      "Abel's Functional Equation and Interrelations"
    ],
    "c_abstract":[
      "Convex solutions $A,B,I,J$ of four Abel equations are numerically studied. We\ndo not know exact formulas for any of these functions, but conjecture that\n$A,B$ and $I,J$ are closely related. [Corrigendum at end.]"
    ],
    "c_categories":[
      [
        "cs.DM",
        "math.CA",
        "math.CO",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-654",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06018"
    ],
    "b_title":[
      "Evolution of the pseudogap band structure in a system of\n  electron-correlated lattice polarons"
    ],
    "b_abstract":[
      "The evolution of the role of lattice vibrations in the formation of the\npseudogap state in strongly correlated electron systems has been investigated\nconcerning changes in the electron-phonon coupling parameters and the\nconcentration of doped charge carriers. We apply the polaronic version of the\ngeneralized tight-binding method to analyze the band structure of a realistic\nmultiband two-dimensional model that incorporates the electron-lattice\ncontributions of both Holstein and Peierls types. It has been demonstrated that\nthe emergence of polaronic effects begins with the modulation of spectral\nfunction intensity. However, within a specific region of the phase diagram, a\nsignificant transformation of the electron band structure and pseudogap state\noccurs. It results from coherent polaron excitations that create a partially\nflat band near the Fermi level. This process leads to a change in the topology\nof the Fermi surface and the emergence of corresponding features in the density\nof states."
    ],
    "b_categories":[
      [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.02118"
    ],
    "c_title":[
      "BRIDLE: Generalized Self-supervised Learning with Quantization"
    ],
    "c_abstract":[
      "Self-supervised learning has been a powerful approach for learning meaningful\nrepresentations from unlabeled data across various domains, reducing the\nreliance on large labeled datasets. Inspired by BERT's success in capturing\ndeep bidirectional contexts in natural language processing, similar frameworks\nhave been adapted to other modalities such as audio, with models like BEATs\nextending the bidirectional training paradigm to audio signals using vector\nquantization (VQ). However, these frameworks face challenges, notably their\ndependence on a single codebook for quantization, which may not capture the\ncomplex, multifaceted nature of signals. In addition, inefficiencies in\ncodebook utilization lead to underutilized code vectors. To address these\nlimitations, we introduce BRIDLE (Bidirectional Residual Quantization\nInterleaved Discrete Learning Encoder), a self-supervised encoder pretraining\nframework that incorporates residual quantization (RQ) into the bidirectional\ntraining process, and is generalized for pretraining with audio, image, and\nvideo. Using multiple hierarchical codebooks, RQ enables fine-grained\ndiscretization in the latent space, enhancing representation quality. BRIDLE\ninvolves an interleaved training procedure between the encoder and tokenizer.\nWe evaluate BRIDLE on audio understanding tasks using classification\nbenchmarks, achieving state-of-the-art results, and demonstrate competitive\nperformance on image classification and video classification tasks, showing\nconsistent improvements over traditional VQ methods in downstream performance."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-655",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06121"
    ],
    "b_title":[
      "Automorphism group schemes of lattice vertex operator algebras"
    ],
    "b_abstract":[
      "Given a positive definite even lattice and a commutative ring, there is a\nstandard construction of a lattice vertex algebra over the commutative ring,\nand this is promoted to a vertex operator algebra when the determinant of the\nlattice is invertible. We describe the groups of automorphisms of these vertex\nalgebras and vertex operator algebras as affine group schemes, showing in\nparticular that each is an extension of an explicitly described split reductive\ngroup of ADE type by the outer automorphism group of the lattice."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.GR",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.13251"
    ],
    "c_title":[
      "Catalytic Nanoparticles: An Introduction"
    ],
    "c_abstract":[
      "This study explores the transformative potential of nanocatalysts,\nemphasizing their pivotal role in catalysis and material science. Key synthesis\ntechniques, including chemical reduction and hybrid methods, are highlighted\nfor their ability to control particle size and enhance stability. Applications\nin environmental remediation, fuel quality improvement, and renewable energy\nshowcase the broad impact of nanocatalysts. Despite challenges in scalability\nand stabilization, advancements in bimetallic configurations and electro-steric\napproaches demonstrate significant progress. This research underscores\nnanocatalysts' promise for sustainable industrial processes and global\nchallenges."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-656",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07166"
    ],
    "b_title":[
      "Natural Language-Assisted Multi-modal Medication Recommendation"
    ],
    "b_abstract":[
      "Combinatorial medication recommendation(CMR) is a fundamental task of\nhealthcare, which offers opportunities for clinical physicians to provide more\nprecise prescriptions for patients with intricate health conditions,\nparticularly in the scenarios of long-term medical care. Previous research\nefforts have sought to extract meaningful information from electronic health\nrecords (EHRs) to facilitate combinatorial medication recommendations. Existing\nlearning-based approaches further consider the chemical structures of\nmedications, but ignore the textual medication descriptions in which the\nfunctionalities are clearly described. Furthermore, the textual knowledge\nderived from the EHRs of patients remains largely underutilized. To address\nthese issues, we introduce the Natural Language-Assisted Multi-modal Medication\nRecommendation(NLA-MMR), a multi-modal alignment framework designed to learn\nknowledge from the patient view and medication view jointly. Specifically,\nNLA-MMR formulates CMR as an alignment problem from patient and medication\nmodalities. In this vein, we employ pretrained language models(PLMs) to extract\nin-domain knowledge regarding patients and medications, serving as the\nfoundational representation for both modalities. In the medication modality, we\nexploit both chemical structures and textual descriptions to create medication\nrepresentations. In the patient modality, we generate the patient\nrepresentations based on textual descriptions of diagnosis, procedure, and\nsymptom. Extensive experiments conducted on three publicly accessible datasets\ndemonstrate that NLA-MMR achieves new state-of-the-art performance, with a\nnotable average improvement of 4.72% in Jaccard score. Our source code is\npublicly available on https:\/\/github.com\/jtan1102\/NLA-MMR_CIKM_2024."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06456"
    ],
    "c_title":[
      "A scaling invariance of the perturbations in $k$-inflation models"
    ],
    "c_abstract":[
      "We study the background and perturbations in two classes of $k$-inflation\nmodels with the potential characterized by an inflection point. We demonstrate\nthat these models enjoy scaling properties which could be used to redefine\ninput parameters so that the perturbations spectra satisfy correct\nnormalization at the CMB pivot scale. The background and perturbation equations\nare integrated numerically for two specific models."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-657",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14077"
    ],
    "b_title":[
      "The effect of a band gap gradient on the radiative losses in the open\n  circuit voltage of solar cells"
    ],
    "b_abstract":[
      "The radiative open circuit voltage loss in a solar cell occurs because the\nabsorptance spectrum near the band gap shows gradual increase rather than sharp\nstep function like transition. This broadening effect has been attributed to\nband gap fluctuations and or to Urbach tails. In this report, we use modelling\nbased on Planck s generalized law to distinguish between these two effects. Our\nresults demonstrate that Urbach tails have only a minimal effect on the\nabsorptance edge broadening and clarify that even an ideal direct semiconductor\nwith no band gap fluctuations shows broadening at the absorptance onset.\nFurthermore, state of the art inorganic thin film solar cells often incorporate\na band gap gradient across their thickness, which can further contribute to\nabsorptance broadening. Using Cu(In,Ga)Se2 (CIGSe) absorbers as a case study,\nwe perform a comprehensive analysis of voltage losses through absolute\nphotoluminescence and electroluminescence spectroscopy, combined with\nphotospectrometry and high-spatial-resolution cathodoluminescence measurements.\nWe find that the loss analysis based on the combination of radiative,\ngeneration and non-radiative losses is complete. Samples with a graded band gap\nprofile show more pronounced broadening of the absorptance onset and up to 16\nmV higher radiative losses compared to the samples with uniform band gap. There\nis indication, that band gap-graded samples also have larger lateral band gap\ninhomogeneity."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10068"
    ],
    "c_title":[
      "Proportional Clustering, the $\\beta$-Plurality Problem, and Metric\n  Distortion"
    ],
    "c_abstract":[
      "We show that the proportional clustering problem using the Droop quota for $k\n= 1$ is equivalent to the $\\beta$-plurality problem. We also show that the\nPlurality Veto rule can be used to select ($\\sqrt{5} - 2$)-plurality points\nusing only ordinal information about the metric space and resolve an open\nquestion of Kalayci et al. (AAAI 2024) by proving that\n$(2+\\sqrt{5})$-proportionally fair clusterings can be found using purely\nordinal information."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-658",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12637"
    ],
    "b_title":[
      "DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet\n  Transform"
    ],
    "b_abstract":[
      "Neural Radiance Fields (NeRF) has achieved superior performance in novel view\nsynthesis and 3D scene representation, but its practical applications are\nhindered by slow convergence and reliance on dense training views. To this end,\nwe present DWTNeRF, a unified framework based on Instant-NGP's fast-training\nhash encoding. It is coupled with regularization terms designed for few-shot\nNeRF, which operates on sparse training views. Our DWTNeRF additionally\nincludes a novel Discrete Wavelet loss that allows explicit prioritization of\nlow frequencies directly in the training objective, reducing few-shot NeRF's\noverfitting on high frequencies in earlier training stages. We also introduce a\nmodel-based approach, based on multi-head attention, that is compatible with\nINGP, which are sensitive to architectural changes. On the 3-shot LLFF\nbenchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM\nand 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot\napproaches for fast-converging implicit representations like INGP or 3DGS."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.21060"
    ],
    "c_title":[
      "Efficient Transformer-based Decoder for Varshamov-Tenengolts Codes"
    ],
    "c_abstract":[
      "In recent years, the rise of DNA data storage technology has brought\nsignificant attention to the challenge of correcting insertion, deletion, and\nsubstitution (IDS) errors. Among various coding methods for IDS correction,\nVarshamov-Tenengolts (VT) codes, primarily designed for single-error\ncorrection, have emerged as a central research focus. While existing decoding\nmethods achieve high accuracy in correcting a single error, they often fail to\ncorrect multiple IDS errors. In this work, we observe that VT codes retain some\ncapability for addressing multiple errors by introducing a transformer-based VT\ndecoder (TVTD) along with symbol- and statistic-based codeword embedding.\nExperimental results demonstrate that the proposed TVTD achieves perfect\ncorrection of a single error. Furthermore, when decoding multiple errors across\nvarious codeword lengths, the bit error rate and frame error rate are\nsignificantly improved compared to existing hard decision and soft-in soft-out\nalgorithms. Additionally, through model architecture optimization, the proposed\nmethod reduces time consumption by an order of magnitude compared to other soft\ndecoders."
    ],
    "c_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-659",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03420"
    ],
    "b_title":[
      "Hydrodynamic memory and Quincke rotation"
    ],
    "b_abstract":[
      "The spontaneous (so-called Quincke) rotation of an uncharged, solid,\ndielectric, spherical particle under a steady electric field is analyzed,\naccounting for the inertia of the particle and the transient fluid inertia, or\n``hydrodynamic memory,'' due to the unsteady Stokes flow around the particle.\nThe dynamics of the particle are encapsulated in three coupled nonlinear\nintegro-differential equations for the evolution of the angular velocity of the\nparticle, and the components of the induced dipole of the particle that are\nparallel and transverse to the applied field. These equations represent a\ngeneralization of the celebrated Lorenz system. A numerical solution of these\n`modified Lorenz equations' (MLE) shows that hydrodynamic memory leads to an\nincrease in the threshold field strength for chaotic particle rotation, which\nis in qualitative agreement with experimental observations. Furthermore,\nhydrodynamic memory leads to an increase in the range of field strengths where\nmulti-stability between steady and chaotic rotation occurs. At large field\nstrengths, chaos ceases and the particle is predicted to execute periodic\nrotational motion."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.03469"
    ],
    "c_title":[
      "One inequality inspired by Erd\\H{o}s"
    ],
    "c_abstract":[
      "Inspired by the proof of the Bertrand postulate given by P. Erd\\H{o}S, we\ncarefully examine and solve one less usual inequality in positive integers\nwhich could help to find an arithmetically pure proof that for every positive\ninteger $n\\ge2$ there is a prime $p$ such that $n<p<2n$."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-660",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04313"
    ],
    "b_title":[
      "Episodes from the history of infinitesimals"
    ],
    "b_abstract":[
      "Infinitesimals have seen ups and downs in their tumultuous history. In the\n18th century, d'Alembert set the tone by describing infinitesimals as chimeras.\nSome adversaries of infinitesimals, including Moigno and Connes, picked up on\nthe term. We highlight the work of Cauchy, No\\\"el, Poisson and Riemann. We also\nchronicle reactions by Moigno, Lamarle and Cantor, and signal the start of a\nrevival with Peano."
    ],
    "b_categories":[
      [
        "math.HO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.01525"
    ],
    "c_title":[
      "Archiving and Replaying Current Web Advertisements: Challenges and\n  Opportunities"
    ],
    "c_abstract":[
      "Although web advertisements represent an inimitable part of digital cultural\nheritage, serious archiving and replay challenges persist. To explore these\nchallenges, we created a dataset of 279 archived ads. We encountered five\nproblems in archiving and replaying them. For one, prior to August 2023,\nInternet Archive's Save Page Now service excluded not only well-known ad\nservices' ads, but also URLs with ad related file and directory names. Although\nafter August 2023, Save Page Now still blocked the archiving of ads loaded on a\nweb page, it permitted the archiving of an ad's resources if the user directly\narchived the URL(s) associated with the ad. Second, Brozzler's incompatibility\nwith Chrome prevented ads from being archived. Third, during crawling and\nreplay sessions, Google's and Amazon's ad scripts generated URLs with different\nrandom values. This precluded archived ads' replay. Updating replay systems'\nfuzzy matching approach should enable the replay of these ads. Fourth, when\nloading Flashtalking web page ads outside of ad iframes, the ad script\nrequested a non-existent URL. This, prevented the replay of ad resources. But\nas was the case with Google and Amazon ads, updating replay systems' fuzzy\nmatching approach should enable Flashtalking ads' replay. Finally, successful\nreplay of ads loaded in iframes with the src attribute of \"about:blank\"\ndepended upon a given browser's service worker implementation. A Chromium bug\nstopped service workers from accessing resources inside of this type of iframe,\nwhich in turn prevented replay. Replacing the \"about:blank\" value for the\niframe's src attribute with a blob URL before an ad was loaded solved this\nproblem. Resolving these replay problems will improve the replay of ads and\nother dynamically loaded embedded web resources that use random values or\n\"about:blank\" iframes."
    ],
    "c_categories":[
      [
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-661",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04279"
    ],
    "b_title":[
      "OpenIN: Open-Vocabulary Instance-Oriented Navigation in Dynamic Domestic\n  Environments"
    ],
    "b_abstract":[
      "In daily domestic settings, frequently used objects like cups often have\nunfixed positions and multiple instances within the same category, and their\ncarriers frequently change as well. As a result, it becomes challenging for a\nrobot to efficiently navigate to a specific instance. To tackle this challenge,\nthe robot must capture and update scene changes and plans continuously.\nHowever, current object navigation approaches primarily focus on the semantic\nlevel and lack the ability to dynamically update scene representation. In\ncontrast, this paper captures the relationships between frequently used objects\nand their static carriers. It constructs an open-vocabulary\nCarrier-Relationship Scene Graph (CRSG) and updates the carrying status during\nrobot navigation to reflect the dynamic changes of the scene. Based on the\nCRSG, we further propose an instance navigation strategy that models the\nnavigation process as a Markov Decision Process. At each step, decisions are\ninformed by the Large Language Model's commonsense knowledge and\nvisual-language feature similarity. We designed a series of long-sequence\nnavigation tasks for frequently used everyday items in the Habitat simulator.\nThe results demonstrate that by updating the CRSG, the robot can efficiently\nnavigate to moved targets. Additionally, we deployed our algorithm on a real\nrobot and validated its practical effectiveness. The project page can be found\nhere: https:\/\/OpenIN-nav.github.io."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08479"
    ],
    "c_title":[
      "How does the restriction of representations change under translations? A\n  story for the general linear groups and the unitary groups"
    ],
    "c_abstract":[
      "We present a new approach to symmetry breaking for pairs of real forms of\n$(GL(n, \\mathbb{C}), GL(n-1, \\mathbb{C}))$. While translation functors are a\nuseful tool for studying a family of representations of a single reductive\ngroup $G$, when applied to a pair of groups $G \\supset G'$,translation functors\ncan significantly alter the nature of symmetry breaking between the\nrepresentations of $G$ and $G'$, even within the same Weyl chamber of the\ndirect product group $G \\times G'$. We introduce the concept of \\lq\\lq{fences\nfor the interlacing pattern}\\rq\\rq,which provides a refinement of the usual\nnotion of \\lq\\lq{walls for Weyl chambers}\\rq\\rq. We then present a theorem that\nstates that multiplicity is constant unless these \\lq\\lq{fences}\\rq\\rq\\ are\ncrossed. This general theorem is illustrated with examples of both tempered and\nnon-tempered representations. Additionally,we provide a new non-vanishing\ntheorem of period integrals for pairs of reductive symmetric spaces,which is\nfurther strengthened through this approach."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-662",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02292"
    ],
    "b_title":[
      "Optimal Control for Remote Patient Monitoring with Multidimensional\n  Health States"
    ],
    "b_abstract":[
      "Selecting the right monitoring level in Remote Patient Monitoring (RPM)\nsystems for e-healthcare is crucial for balancing patient outcomes, various\nresources, and patient's quality of life. A prior work has used one-dimensional\nhealth representations, but patient health is inherently multidimensional and\ntypically consists of many measurable physiological factors. In this paper, we\nintroduce a multidimensional health state model within the RPM framework and\nuse dynamic programming to study optimal monitoring strategies. Our analysis\nreveals that the optimal control is characterized by switching curves (for\ntwo-dimensional health states) or switching hyper-surfaces (in general):\npatients switch to intensive monitoring when health measurements cross a\nspecific multidimensional surface. We further study how the optimal switching\ncurve varies for different medical conditions and model parameters. This\nfinding of the optimal control structure provides actionable insights for\nclinicians and aids in resource planning. The tunable modeling framework\nenhances the applicability and effectiveness of RPM services across various\nmedical conditions."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03712"
    ],
    "c_title":[
      "SDEs with subcritical Lebesgue--H\\\"{o}lder drifts and driven by\n  $\\alpha$-stable processes"
    ],
    "c_abstract":[
      "We obtain the unique weak and strong solvability for time inhomogeneous\nstochastic differential equations with the drifts in subcritical\nLebesgue--H\\\"{o}lder spaces $L^p([0,T];{\\mathcal C}_b^{\\beta}({\\mathbb\nR}^d;{\\mathbb R}^d))$ and driven by $\\alpha$-stable processes for $\\alpha\\in\n(0,2)$. The weak well-posedness is derived for $\\beta\\in (0,1)$,\n$\\alpha+\\beta>1$ and $p>\\alpha\/(\\alpha+\\beta-1)$ through the Prohorov theorem,\nSkorohod representation and the regularity estimates of solutions for a class\nof fractional parabolic partial differential equations. The pathwise uniqueness\nand Davie's type uniqueness are proved for $\\beta>1- \\alpha\/2$ by using\nIt\\^{o}--Tanaka's trick. Moreover, we give a counterexample to the pathwise\nuniqueness for the supercritical Lebesgue--H\\\"{o}lder drifts to explain the\npresent result is sharp."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-663",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06367"
    ],
    "b_title":[
      "Observing the exponential growth of the eigenmodes in the absence of\n  coalescence for a non-Hermitian circuit with an unavoidable inductor\n  dissipation"
    ],
    "b_abstract":[
      "We investigate, both experimentally and theoretically, the eigenmodes of an\nelectronic circuit in which gain and loss $RLC$ resonators are coupled through\na capacitor. Due to the unavoidable magnetic loss in the inductors, we find\nthat the eigenmode coalescence no longer emerges in contrast to the\nconventional non-Hermitian systems with the spontaneous $\\cal{PT}$-symmetry\nbreaking. In particular, we find a transition from the exponential decay to\nexponential growth in the amplitude of the periodic voltage oscillations of the\nresonators. The transition occurs near the exceptional points of the\nnon-Hermitian circuit without considering the dissipations in inductors. We\nintroduce a small resistor of three orders of magnitude smaller than that of\nthe $RLC$ resonators to mimic the energy dissipation in inductors and\nnumerically solve the equivalent non-Hermitian Schr{\\\" o}dinger equation. The\nnumerical results can well reproduce experimental observations. Our above\nfindings unambiguously indicate that the exponential growth behavior beyond the\nexceptional points is robust against some unavoidable dissipative\nperturbations."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08501"
    ],
    "c_title":[
      "Better Together? A Field Experiment on Human-Algorithm Interaction in\n  Child Protection"
    ],
    "c_abstract":[
      "Algorithm tools have the potential to improve public service efficiency, but\nour understanding of how experts use algorithms is limited, and concerns about\nresulting bias are widespread. We randomize access to algorithm support for\nworkers allocating Child Protective Services (CPS) investigations. Access to\nthe algorithm reduced maltreatment-related hospitalizations, especially for\ndisadvantaged groups, while reducing CPS surveillance of Black children. Child\ninjuries fell by 29 percent. Workers improved their scrutiny of complementary\ninformation emphasized by the algorithm, and targeted investigations to\nchildren at greater risk of harm irrespective of algorithm-predicted risk.\nAlgorithm-only counterfactuals confirm human-algorithm complementarity for both\nefficiency and equity."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-664",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07432"
    ],
    "b_title":[
      "Quadratic quasinormal modes at null infinity on a Schwarzschild\n  spacetime"
    ],
    "b_abstract":[
      "The ringdown of perturbed black holes has been studied since the 1970s, but\nuntil recently, studies have focused on linear perturbations. There is now\nburgeoning interest in nonlinear perturbative effects during ringdown. Here,\nusing a hyperboloidal framework, we provide a complete treatment of linear and\nquadratic quasinormal modes (QNMs and QQNMs) in second-order perturbation\ntheory, in Schwarzschild spacetime. We include novel methods for extracting\nQNMs and QQNMs amplitudes using a Laplace transform treatment, allowing for the\ninclusion of arbitrary initial data. We produce both time- and frequency-domain\ncodes. From these codes, we present new results further exploring the\nunforeseen dependence of QQNMs amplitudes on the parity of the progenitor\nsystem, as demonstrated in our letter [Phys. Rev. Lett. 134, 061401 (2025)].\nOur numerical results are restricted to perturbations of a Schwarzschild black\nhole, but our methods extend straightforwardly to the astrophysically realistic\ncase of a Kerr black hole."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.19883"
    ],
    "c_title":[
      "Behind the Tip of Efficiency: Uncovering the Submerged Threats of\n  Jailbreak Attacks in Small Language Models"
    ],
    "c_abstract":[
      "Small language models (SLMs) have become increasingly prominent in the\ndeployment on edge devices due to their high efficiency and low computational\ncost. While researchers continue to advance the capabilities of SLMs through\ninnovative training strategies and model compression techniques, the security\nrisks of SLMs have received considerably less attention compared to large\nlanguage models (LLMs).To fill this gap, we provide a comprehensive empirical\nstudy to evaluate the security performance of 13 state-of-the-art SLMs under\nvarious jailbreak attacks. Our experiments demonstrate that most SLMs are quite\nsusceptible to existing jailbreak attacks, while some of them are even\nvulnerable to direct harmful prompts.To address the safety concerns, we\nevaluate several representative defense methods and demonstrate their\neffectiveness in enhancing the security of SLMs. We further analyze the\npotential security degradation caused by different SLM techniques including\narchitecture compression, quantization, knowledge distillation, and so on. We\nexpect that our research can highlight the security challenges of SLMs and\nprovide valuable insights to future work in developing more robust and secure\nSLMs."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-665",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10346"
    ],
    "b_title":[
      "Normal forms and geometric structures on Hopf manifolds"
    ],
    "b_abstract":[
      "We prove that Hopf manifolds admit holomorphic $(G,X)$-structures, extending\nto any dimension a result of McKay and Pokrovskiy. For this, we revisit\nGuysinsky-Katok's group of invertible sub-resonant polynomials, and\nBertheloot's approach of Poincar\\'e-Dulac normal form theory."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.07164"
    ],
    "c_title":[
      "Effects of the built-in electric field on free and bound excitons in a\n  polar GaN\/AlGaN\/GaN based heterostructure"
    ],
    "c_abstract":[
      "Low-temperature luminescence spectra reveal the presence of two independant\npopulations of GaN excitons within a $\\mathrm{GaN\/AlGaN\/GaN\/Al_2O_3}$\nheterostructure in which a thick (1.5 $\\mathrm{\\mu m}$) AlGaN layer separates a\nthin (150 nm) top GaN layer and a thick (3.5 $\\mathrm{\\mu m}$) bottom GaN layer\ngrown on sapphire. The presence of these two spectrally-distinct families of\nexcitons in each GaN layer of the heterostructure is demonstrated using three\ndifferent experimental methods: (i) low-power $\\mathrm{\\mu}$-photoluminescence\n($\\mathrm{\\mu PL}$) using laser excitation sources with wavelengths above and\nbelow the AlGaN bandgap, (ii) $\\mathrm{\\mu PL}$ as a function of optically\ninjected free carrier density, and (iii) quantitative numerical simulation of\nthe $\\mathrm{\\mu}$-Reflectivity ($\\mathrm{\\mu R}$). One major impact of the\nbuilt-in electric field is the reduction of the excitonic lifetime in the GaN\nsurface layer, which transitions from less than 10 ps in the presence of the\nbuilt-in electric field to the bulk lifetime (90 ps) when the field is\nscreened. This increase in the excitonic lifetime is related to the\nmodification of the band structure in the presence of optically injected free\ncarriers. The effect of these lifetime variations on the luminescence spectra\nis analyzed. Lastly, we provide an estimate of the Mott density in GaN as\n$n_{\\mathrm{Mott}} = 4\\times 10^{17}\\, \\mathrm{cm^{-3}}$ at 130 K, consistent\nwith values reported in the literature and accounting for the free carrier\ndensity required to screen the electric field."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-666",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06429"
    ],
    "b_title":[
      "Reliable Imputed-Sample Assisted Vertical Federated Learning"
    ],
    "b_abstract":[
      "Vertical Federated Learning (VFL) is a well-known FL variant that enables\nmultiple parties to collaboratively train a model without sharing their raw\ndata. Existing VFL approaches focus on overlapping samples among different\nparties, while their performance is constrained by the limited number of these\nsamples, leaving numerous non-overlapping samples unexplored. Some previous\nwork has explored techniques for imputing missing values in samples, but often\nwithout adequate attention to the quality of the imputed samples. To address\nthis issue, we propose a Reliable Imputed-Sample Assisted (RISA) VFL framework\nto effectively exploit non-overlapping samples by selecting reliable imputed\nsamples for training VFL models. Specifically, after imputing non-overlapping\nsamples, we introduce evidence theory to estimate the uncertainty of imputed\nsamples, and only samples with low uncertainty are selected. In this way,\nhigh-quality non-overlapping samples are utilized to improve VFL model.\nExperiments on two widely used datasets demonstrate the significant performance\ngains achieved by the RISA, especially with the limited overlapping samples,\ne.g., a 48% accuracy gain on CIFAR-10 with only 1% overlapping samples."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11005"
    ],
    "c_title":[
      "Anisotropic Schottky-barrier-height in high-symmetry 2D WSe$_2$:\n  Momentum-space anisotropy"
    ],
    "c_abstract":[
      "It is usually supposed that only low-symmetry two-dimensional (2D) materials\nexhibit anisotropy, here we show that high-symmetry 2D semiconductors can show\nsignificant anisotropy in momentum space due to the band structure anisotropy\nin k-space. The basic reason is that different k-points in the Brillouin zone\nhave different symmetry. Using 2D semiconductor WSe$_2$ as the example, we\nconstruct lateral heterostructures with zigzag and armchair connections to 2D\nmetal NbSe$_2$, and the electronic structure and contact characteristics of\nthese two connections are analyzed. It is found that both connections exhibit\np-type Schottky barrier height (SBH) but the sizes of SBH are very different\n(of 0.03 eV and 0.50 eV), mainly because the band-edge energies of WSe$_2$ are\ndifferent along the two mutually perpendicular directions in momentum space.\nThere are two factors contributing to the SBH anisotropy: one is the different\ninterface structure and the other is the band edge anisotropy of the 2D\nsemiconductor WSe$_2$. Since the two interface structures give only a\ndifference in interface potential change by less than 0.1 eV, the SBH variation\nof ~0.47 eV is mainly from the band structure anisotropy in momentum-space. So,\nhigh-symmetry 2D materials may exhibit highly anisotropic electronic states in\nmomentum space and this affects the transport properties. Our current work\nextends the research field of 2D material anisotropy to 2D materials with high\nreal-space symmetry, thus greatly expands the candidate materials for\nanisotropic studies and provides new guidance for optimizing the performance of\n2D material devices via controlling transport directions."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-667",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11981"
    ],
    "b_title":[
      "DecompDreamer: Advancing Structured 3D Asset Generation with\n  Multi-Object Decomposition and Gaussian Splatting"
    ],
    "b_abstract":[
      "Text-to-3D generation saw dramatic advances in recent years by leveraging\nText-to-Image models. However, most existing techniques struggle with\ncompositional prompts, which describe multiple objects and their spatial\nrelationships. They often fail to capture fine-grained inter-object\ninteractions. We introduce DecompDreamer, a Gaussian splatting-based training\nroutine designed to generate high-quality 3D compositions from such complex\nprompts. DecompDreamer leverages Vision-Language Models (VLMs) to decompose\nscenes into structured components and their relationships. We propose a\nprogressive optimization strategy that first prioritizes joint relationship\nmodeling before gradually shifting toward targeted object refinement. Our\nqualitative and quantitative evaluations against state-of-the-art text-to-3D\nmodels demonstrate that DecompDreamer effectively generates intricate 3D\ncompositions with superior object disentanglement, offering enhanced control\nand flexibility in 3D generation. Project page :\nhttps:\/\/decompdreamer3d.github.io"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17422"
    ],
    "c_title":[
      "SIGN: A Statistically-Informed Gaze Network for Gaze Time Prediction"
    ],
    "c_abstract":[
      "We propose a first version of SIGN, a Statistically-Informed Gaze Network, to\npredict aggregate gaze times on images. We develop a foundational statistical\nmodel for which we derive a deep learning implementation involving CNNs and\nVisual Transformers, which enables the prediction of overall gaze times. The\nmodel enables us to derive from the aggregate gaze times the underlying gaze\npattern as a probability map over all regions in the image, where each region's\nprobability represents the likelihood of being gazed at across all possible\nscan-paths. We test SIGN's performance on AdGaze3500, a dataset of images of\nads with aggregate gaze times, and on COCO-Search18, a dataset with\nindividual-level fixation patterns collected during search. We demonstrate that\nSIGN (1) improves gaze duration prediction significantly over state-of-the-art\ndeep learning benchmarks on both datasets, and (2) can deliver plausible gaze\npatterns that correspond to empirical fixation patterns in COCO-Search18. These\nresults suggest that the first version of SIGN holds promise for gaze-time\npredictions and deserves further development."
    ],
    "c_categories":[
      [
        "cs.CV",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-668",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08308"
    ],
    "b_title":[
      "prunAdag: an adaptive pruning-aware gradient method"
    ],
    "b_abstract":[
      "A pruning-aware adaptive gradient method is proposed which classifies the\nvariables in two sets before updating them using different strategies. This\ntechnique extends the ``relevant\/irrelevant\" approach of Ding (2019) and Zimmer\net al. (2022) and allows a posteriori sparsification of the solution of model\nparameter fitting problems. The new method is proved to be convergent with a\nglobal rate of decrease of the averaged gradient's norm of the form\n$\\calO(\\log(k)\/\\sqrt{k+1})$. Numerical experiments on several applications show\nthat it is competitive."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.15826"
    ],
    "c_title":[
      "MADP: Multi-Agent Deductive Planning for Enhanced Cognitive-Behavioral\n  Mental Health Question Answer"
    ],
    "c_abstract":[
      "The Mental Health Question Answer (MHQA) task requires the seeker and\nsupporter to complete the support process in one-turn dialogue. Given the\nrichness of help-seeker posts, supporters must thoroughly understand the\ncontent and provide logical, comprehensive, and well-structured responses.\nPrevious works in MHQA mostly focus on single-agent approaches based on the\ncognitive element of Cognitive Behavioral Therapy (CBT), but they overlook the\ninteractions among various CBT elements, such as emotion and cognition. This\nlimitation hinders the models' ability to thoroughly understand the distress of\nhelp-seekers. To address this, we propose a framework named Multi-Agent\nDeductive Planning (MADP), which is based on the interactions between the\nvarious psychological elements of CBT. This method guides Large Language Models\n(LLMs) to achieve a deeper understanding of the seeker's context and provide\nmore personalized assistance based on individual circumstances. Furthermore, we\nconstruct a new dataset based on the MADP framework and use it to fine-tune\nLLMs, resulting in a specialized model named MADP-LLM. We conduct extensive\nexperiments, including comparisons with multiple LLMs, human evaluations, and\nautomatic evaluations, to validate the effectiveness of the MADP framework and\nMADP-LLM."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-669",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04988"
    ],
    "b_title":[
      "CMamba: Learned Image Compression with State Space Models"
    ],
    "b_abstract":[
      "Learned Image Compression (LIC) has explored various architectures, such as\nConvolutional Neural Networks (CNNs) and transformers, in modeling image\ncontent distributions in order to achieve compression effectiveness. However,\nachieving high rate-distortion performance while maintaining low computational\ncomplexity (\\ie, parameters, FLOPs, and latency) remains challenging. In this\npaper, we propose a hybrid Convolution and State Space Models (SSMs) based\nimage compression framework, termed \\textit{CMamba}, to achieve superior\nrate-distortion performance with low computational complexity. Specifically,\nCMamba introduces two key components: a Content-Adaptive SSM (CA-SSM) module\nand a Context-Aware Entropy (CAE) module. First, we observed that SSMs excel in\nmodeling overall content but tend to lose high-frequency details. In contrast,\nCNNs are proficient at capturing local details. Motivated by this, we propose\nthe CA-SSM module that can dynamically fuse global content extracted by SSM\nblocks and local details captured by CNN blocks in both encoding and decoding\nstages. As a result, important image content is well preserved during\ncompression. Second, our proposed CAE module is designed to reduce spatial and\nchannel redundancies in latent representations after encoding. Specifically,\nour CAE leverages SSMs to parameterize the spatial content in latent\nrepresentations. Benefiting from SSMs, CAE significantly improves spatial\ncompression efficiency while reducing spatial content redundancies. Moreover,\nalong the channel dimension, CAE reduces inter-channel redundancies of latent\nrepresentations via an autoregressive manner, which can fully exploit prior\nknowledge from previous channels without sacrificing efficiency. Experimental\nresults demonstrate that CMamba achieves superior rate-distortion performance."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00197"
    ],
    "c_title":[
      "Unveiling sex dimorphism in the healthy cardiac anatomy: fundamental\n  differences between male and female heart shapes"
    ],
    "c_abstract":[
      "Sex-based differences in cardiovascular disease are well documented, yet the\nprecise nature and extent of these discrepancies in cardiac anatomy remain\nincompletely understood. Traditional scaling models often fail to capture the\ninterplay of age, blood pressure, and body size, prompting a more nuanced\ninvestigation. Here, we employ statistical shape modeling in a healthy subset\n(n=456) of the UK Biobank to explore sex-specific variations in biventricular\nanatomy. We reconstruct 3D meshes and perform multivariate analyses of shape\ncoefficients, controlling for age, blood pressure, and various body size\nmetrics. Our findings reveal that sex alone explains at least 25 percent of\nmorphological variability, with strong discrimination between men and women\n(AUC=0.96-0.71) persisting even after correction for confounders. Notably, the\nmost discriminative modes highlight pronounced differences in cardiac chamber\nvolumes, the anterior-posterior width of the right ventricle, and the relative\npositioning of the cardiac chambers. These results underscore that sex has a\nfundamental influence on cardiac morphology, which may have important clinical\nimplications for differing cardiac structural assessments in men and women.\nFuture work should investigate how these anatomical differences manifest in\nvarious cardiovascular conditions, ultimately paving the way for more precise\nrisk stratification and personalized therapeutic strategies for both men and\nwomen."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-670",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01149"
    ],
    "b_title":[
      "A3: Android Agent Arena for Mobile GUI Agents"
    ],
    "b_abstract":[
      "AI agents have become increasingly prevalent in recent years, driven by\nsignificant advancements in the field of large language models (LLMs). Mobile\nGUI agents, a subset of AI agents, are designed to autonomously perform tasks\non mobile devices. While numerous studies have introduced agents, datasets, and\nbenchmarks to advance mobile GUI agent research, many existing datasets focus\non static frame evaluations and fail to provide a comprehensive platform for\nassessing performance on real-world, in-the-wild tasks. To address this gap, we\npresent Android Agent Arena (A3), a novel evaluation platform. Unlike existing\nin-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as\nreal-time online information retrieval and operational instructions; (2) a\nlarger, more flexible action space, enabling compatibility with agents trained\non any dataset; and (3) automated business-level LLM-based evaluation process.\nA3 includes 21 widely used general third-party apps and 201 tasks\nrepresentative of common user scenarios, providing a robust foundation for\nevaluating mobile GUI agents in real-world situations and a new autonomous\nevaluation process for less human labor and coding expertise. The project is\navailable at https:\/\/yuxiangchai.github.io\/Android-Agent-Arena\/."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15116"
    ],
    "c_title":[
      "Uniform mean estimation via generic chaining"
    ],
    "c_abstract":[
      "We introduce an empirical functional $\\Psi$ that is an optimal uniform mean\nestimator: Let $F\\subset L_2(\\mu)$ be a class of mean zero functions, $u$ is a\nreal valued function, and $X_1,\\dots,X_N$ are independent, distributed\naccording to $\\mu$. We show that under minimal assumptions, with $\\mu^{\\otimes\nN}$ exponentially high probability, \\[ \\sup_{f\\in F} |\\Psi(X_1,\\dots,X_N,f) -\n\\mathbb{E} u(f(X))| \\leq c R(F) \\frac{ \\mathbb{E} \\sup_{f\\in F } |G_f| }{\\sqrt\nN}, \\] where $(G_f)_{f\\in F}$ is the gaussian processes indexed by $F$ and\n$R(F)$ is an appropriate notion of `diameter' of the class $\\{u(f(X)) : f\\in\nF\\}$.\n  The fact that such a bound is possible is surprising, and it leads to the\nsolution of various key problems in high dimensional probability and high\ndimensional statistics. The construction is based on combining Talagrand's\ngeneric chaining mechanism with optimal mean estimation procedures for a single\nreal-valued random variable."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-671",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11801"
    ],
    "b_title":[
      "Diffuse-CLoC: Guided Diffusion for Physics-based Character Look-ahead\n  Control"
    ],
    "b_abstract":[
      "We present Diffuse-CLoC, a guided diffusion framework for physics-based\nlook-ahead control that enables intuitive, steerable, and physically realistic\nmotion generation. While existing kinematics motion generation with diffusion\nmodels offer intuitive steering capabilities with inference-time conditioning,\nthey often fail to produce physically viable motions. In contrast, recent\ndiffusion-based control policies have shown promise in generating physically\nrealizable motion sequences, but the lack of kinematics prediction limits their\nsteerability. Diffuse-CLoC addresses these challenges through a key insight:\nmodeling the joint distribution of states and actions within a single diffusion\nmodel makes action generation steerable by conditioning it on the predicted\nstates. This approach allows us to leverage established conditioning techniques\nfrom kinematic motion generation while producing physically realistic motions.\nAs a result, we achieve planning capabilities without the need for a high-level\nplanner. Our method handles a diverse set of unseen long-horizon downstream\ntasks through a single pre-trained model, including static and dynamic obstacle\navoidance, motion in-betweening, and task-space control. Experimental results\nshow that our method significantly outperforms the traditional hierarchical\nframework of high-level motion diffusion and low-level tracking."
    ],
    "b_categories":[
      [
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11935"
    ],
    "c_title":[
      "A quantitative general Nullstellensatz for Jacobson rings"
    ],
    "c_abstract":[
      "The general Nullstellensatz states that if $A$ is a Jacobson ring, $A[X]$ is\nJacobson. We introduce the notion of an $\\alpha$-Jacobson ring for an ordinal\n$\\alpha$ and prove a quantitative version of the general Nullstellensatz: if\n$A$ is an $\\alpha$-Jacobson ring, $A[X]$ is $(\\alpha+1)$-Jacobson. The\nquantitative general Nullstellensatz implies that $K[X_1,\\ldots,X_n]$ is not\nonly Jacobson but also $(1+n)$-Jacobson for any field $K$. It also implies that\n$\\mathbb{Z}[X_1,\\ldots,X_n]$ is $(2+n)$-Jacobson."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-672",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02301"
    ],
    "b_title":[
      "Towards Large Language Model Guided Kernel Direct Fuzzing"
    ],
    "b_abstract":[
      "Direct kernel fuzzing is a targeted approach that focuses on specific areas\nof the kernel, effectively addressing the challenges of frequent updates and\nthe inherent complexity of operating systems, which are critical\ninfrastructure. This paper introduces SyzAgent, a framework that integrates\nLLMs with the state-of-the-art kernel fuzzer Syzkaller, where the LLMs are used\nto guide the mutation and generation of test cases in real-time. We present\npreliminary results demonstrating that this method is effective on around 67\\%\ncases in our benchmark during the experiment."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16100"
    ],
    "c_title":[
      "Topological Kleene Field Theories: A new model of computation"
    ],
    "c_abstract":[
      "In this article, we establish the foundations of a computational field\ntheory, which we term Topological Kleene Field Theory (TKFT), inspired by\nStephen Kleene's seminal work on partial recursive functions. Our central\nresult shows that any computable function can be simulated by the flow on a\nsmooth bordism of a vector field with good local properties. More precisely, we\nprove that reaching functions on clean dynamical bordisms are exactly\nequivalent to computable functions, setting an alternative model of computation\nto Turing machines. The use of non-trivial topologies for the bordisms involved\nis essential for this equivalence, suggesting interesting connections between\nthe topological structure of these flows and the computational complexity\ninherent in the functions. We emphasize that TKFT has the potential to surpass\nthe computational complexity of both Turing machines and quantum computation."
    ],
    "c_categories":[
      [
        "cs.FL",
        "math.CT",
        "math.DG",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-673",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11260"
    ],
    "b_title":[
      "To Assess the Impact of Smart Cities on Urbanization Patterns in the\n  United States"
    ],
    "b_abstract":[
      "This paper investigates the relationship between smart city initiatives and\nevolving urbanization trends in the United States. The research addresses the\ncritical issue of rapid urban growth in the U.S. and explores how innovations\nwithin the smart city paradigm influence urban development. Utilizing\nprinciples from Urban Complexity Theory, this study identifies four key\nvariables relevant to smart cities and their impact on urbanization: smart city\ntechnology, government policy, environmental sustainability, and socioeconomic\nfactors. A mixed-method approach, combining quantitative and qualitative\nmethodologies, was employed. A web-based survey (n=50) utilizing a five-point\nLikert scale was conducted among residents of Manhattan, New York, and Capitol\nHill, Seattle. Results indicate that the implementation of smart city\ntechnologies is significantly associated with shifts in population density,\nland use diversification, and enhanced infrastructure dynamics. Additionally,\nresidents demonstrated preferences for smart cities based on efficient urban\nmobility, environmental sustainability, and personal socioeconomic\nimprovements. The findings highlight essential considerations for urban\nplanners, policymakers, and employers. This study concludes that incorporating\nthe identified influential factors into strategic urban planning optimizes city\ndevelopment to better accommodate growing urban populations."
    ],
    "b_categories":[
      [
        "cs.CY",
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15479"
    ],
    "c_title":[
      "Measurement of the Forward Shock Velocities of the Supernova Remnant\n  N132D Based on the Thermal X-ray Emission"
    ],
    "c_abstract":[
      "Measuring shock velocities is crucial for understanding the energy transfer\nprocesses at the shock fronts of supernova remnants (SNRs), including\nacceleration of cosmic rays. Here we present shock velocity measurements on the\nSNR N132D, based on the thermal properties of the shock-heated interstellar\nmedium. We apply a self-consistent model developed in our previous work to\nX-ray data from deep Chandra observations with an effective exposure of $\\sim$\n900 ks. In our model, both temperature and ionization relaxation processes in\npost-shock plasmas are simultaneously calculated, so that we can trace back to\nthe initial condition of the shock-heated plasma to constrain the shock\nvelocity. We reveal that the shock velocity ranges from 800 to 1500\n$\\rm{km~s^{-1}}$ with moderate azimuthal dependence. Although our measurement\nis consistent with the velocity determined by independent proper motion\nmeasurements in the south rim regions, a large discrepancy between the two\nmeasurements (up to a factor of 4) is found in the north rim regions. This\nimplies that a substantial amount of the kinetic energy has been transferred to\nthe nonthermal component through highly efficient particle acceleration. Our\nresults are qualitatively consistent with the $\\gamma$-ray observations of this\nSNR."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-674",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11343"
    ],
    "b_title":[
      "SPLD polynomial optimization and bounded degree SOS hierarchies"
    ],
    "b_abstract":[
      "In this paper, a new class of structured polynomials, which we dub the {\\it\nseparable plus lower degree {\\rm (SPLD in short)} polynomials}, is introduced.\nThe formal definition of an SPLD polynomial, which extends the concept of the\nSPQ polynomial (Ahmadi et al. in Math Oper Res 48:1316--1343, 2023), is\ndefined. A type of bounded degree SOS hierarchy (BSOS-SPLD) is proposed to\nefficiently solve the optimization problems with SPLD polynomials, and several\nnumerical examples are performed much better than the bounded degree SOS\nhierarchy (Lasserre et al. in EURO J Comput Optim 5:87--117, 2017). An exact\nSOS relaxation for a class of convex SPLD polynomial optimization problems is\nproposed. Finally, an application of SPLD polynomials to polynomial regression\nproblems in statistics is presented."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.11141"
    ],
    "c_title":[
      "Kilometer-Scale E3SM Land Model Simulation over North America"
    ],
    "c_abstract":[
      "The development of a kilometer-scale E3SM Land Model (km-scale ELM) is an\nintegral part of the E3SM project, which seeks to advance energy-related Earth\nsystem science research with state-of-the-art modeling and simulation\ncapabilities on exascale computing systems. Through the utilization of\nhigh-fidelity data products, such as atmospheric forcing and soil properties,\nthe km-scale ELM plays a critical role in accurately modeling geographical\ncharacteristics and extreme weather occurrences. The model is vital for\nenhancing our comprehension and prediction of climate patterns, as well as\ntheir effects on ecosystems and human activities.\n  This study showcases the first set of full-capability, km-scale ELM\nsimulations over various computational domains, including simulations\nencompassing 21.6 million land gridcells, reflecting approximately 21.5 million\nsquare kilometers of North America at a 1 km x 1 km resolution. We present the\nlargest km-scale ELM simulation using up to 100,800 CPU cores across 2,400\nnodes. This continental-scale simulation is 300 times larger than any previous\nstudies, and the computational resources used are about 400 times larger than\nthose used in prior efforts. Both strong and weak scaling tests have been\nconducted, revealing exceptional performance efficiency and resource\nutilization.\n  The km-scale ELM uses the common E3SM modeling infrastructure and a general\ndata toolkit known as KiloCraft. Consequently, it can be readily adapted for\nboth fully-coupled E3SM simulations and data-driven simulations over specific\nareas, ranging from a single gridcell to the entire North America."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-675",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17201"
    ],
    "b_title":[
      "Towards Carbon Footprint-Aware Recommender Systems for Greener Item\n  Recommendation"
    ],
    "b_abstract":[
      "The commodity and widespread use of online shopping are having an\nunprecedented impact on climate, with emission figures from key actors that are\neasily comparable to those of a large-scale metropolis. Despite online shopping\nbeing fueled by recommender systems (RecSys) algorithms, the role and potential\nof the latter in promoting more sustainable choices is little studied. One of\nthe main reasons for this could be attributed to the lack of a dataset\ncontaining carbon footprint emissions for the items. While building such a\ndataset is a rather challenging task, its presence is pivotal for opening the\ndoors to novel perspectives, evaluations, and methods for RecSys research. In\nthis paper, we target this bottleneck and study the environmental role of\nRecSys algorithms. First, we mine a dataset that includes carbon footprint\nemissions for its items. Then, we benchmark conventional RecSys algorithms in\nterms of accuracy and sustainability as two faces of the same coin. We find\nthat RecSys algorithms optimized for accuracy overlook greenness and that\nlonger recommendation lists are greener but less accurate. Then, we show that a\nsimple reranking approach that accounts for the item's carbon footprint can\nestablish a better trade-off between accuracy and greenness. This reranking\napproach is modular, ready to use, and can be applied to any RecSys algorithm\nwithout the need to alter the underlying mechanisms or retrain models. Our\nresults show that a small sacrifice of accuracy can lead to significant\nimprovements of recommendation greenness across all algorithms and list\nlengths. Arguably, this accuracy-greenness trade-off could even be seen as an\nenhancement of user satisfaction, particularly for purpose-driven users who\nprioritize the environmental impact of their choices. We anticipate this work\nwill serve as the starting point for studying RecSys for more sustainable\nrecommendations."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.19334"
    ],
    "c_title":[
      "The Value of Prediction in Identifying the Worst-Off"
    ],
    "c_abstract":[
      "Machine learning is increasingly used in government programs to identify and\nsupport the most vulnerable individuals, prioritizing assistance for those at\ngreatest risk over optimizing aggregate outcomes. This paper examines the\nwelfare impacts of prediction in equity-driven contexts, and how they compare\nto other policy levers, such as expanding bureaucratic capacity. Through\nmathematical models and a real-world case study on long-term unemployment\namongst German residents, we develop a comprehensive understanding of the\nrelative effectiveness of prediction in surfacing the worst-off. Our findings\nprovide clear analytical frameworks and practical, data-driven tools that\nempower policymakers to make principled decisions when designing these systems."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-676",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04085"
    ],
    "b_title":[
      "The Cosmic Evolution Early Release Science Survey (CEERS)"
    ],
    "b_abstract":[
      "We present the Cosmic Evolution Early Release Science (CEERS) Survey, a 77.2\nhour Director's Discretionary Early Release Science Program. CEERS\ndemonstrates, tests, and validates efficient extragalactic surveys using\ncoordinated, overlapping parallel observations with the JWST instrument suite,\nincluding NIRCam and MIRI imaging, NIRSpec low (R~100) and medium (R~1000)\nresolution spectroscopy, and NIRCam slitless grism (R~1500) spectroscopy. CEERS\ntargets the Hubble Space Telescope-observed region of the Extended Groth Strip\n(EGS) field, supported by a rich set of multiwavelength data. CEERS facilitated\nimmediate community science in both of the extragalactic core JWST science\ndrivers ``First Light\" and ``Galaxy Assembly,\" including: 1) The discovery and\ncharacterization of large samples of galaxies at z >~ 10 from ~90 arcmin^2 of\nNIRCam imaging, constraining their abundance and physical nature; 2) Deep\nspectra of >1000 galaxies, including dozens of galaxies at 6<z<10, enabling\nredshift measurements and constraints on the physical conditions of\nstar-formation and black hole growth via line diagnostics; 3) Quantifying the\nfirst bulge, bar and disk structures at z>3; and 4) Characterizing galaxy\nmid-IR emission with MIRI to study dust-obscured star-formation and\nsupermassive black hole growth at z~1-3. As a legacy product for the community,\nthe CEERS team has provided several data releases, accompanied by detailed\nnotes on the data reduction procedures and notebooks to aid in reproducibility.\nIn addition to an overview of the survey and quality of the data, we provide\nscience highlights from the first two years with CEERS data."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10136"
    ],
    "c_title":[
      "The radius capture number"
    ],
    "c_abstract":[
      "In the classic cop and robber game, two players--the cop and the robber--take\nturns moving to a neighboring vertex or staying at their current position. The\ncop aims to capture the robber, while the robber tries to evade capture. A\ngraph $G$ is called a cop-win graph if the cop can always capture the robber in\na finite number of moves. In the cop and robber game with radius of capture\n$k$, the cop wins if he can come within distance $k$ of the robber. The radius\ncapture number $\\rc(G)$ of a graph $G$ is the smallest $k$ for which the cop\nhas a winning strategy in this variant of the game.\n  In this paper, we establish that $\\rc(H) \\leq \\rc(G)$ for any retract $H$ of\n$G$. We derive sharp upper and lower bounds for the radius capture number in\nterms of the graph's radius and girth, respectively. Additionally, we\ninvestigate the radius capture number in vertex-transitive graphs and identify\nseveral families $\\cal{F}$ of vertex-transitive graphs with $\\rc(G)=\\rad(G)-1$\nfor any $G \\in \\cal{F}$. We further study the radius capture number in\nouterplanar graphs, Sierpi\\'nski graphs, harmonic even graphs, and graph\nproducts. Specifically, we show that for any outerplanar graph $G$, $\\rc(G)$\ndepends on the size of its largest inner face. For harmonic even graphs and\nSierpi\\'nski graphs $S(n,3)$, we prove that $\\rc(G)=\\rad(G)-1$. Regarding graph\nproducts, we determine exact values of the radius capture number for strong and\nlexicographic products, showing that they depend on the radius capture numbers\nof their factors. Lastly, we establish both lower and upper bounds for the\nradius capture number of the Cartesian product of two graphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-677",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13260"
    ],
    "b_title":[
      "Field induced density wave in a kagome superconductor"
    ],
    "b_abstract":[
      "On the kagome lattice, electrons benefit from the simultaneous presence of\nband topology, flat electronic bands, and van Hove singularities, forming\ncompeting or cooperating orders. Understanding the interrelation between these\ndistinct order parameters remains a significant challenge, leaving much of the\nassociated physics unexplored. In the kagome superconductor KV3Sb5, which\nexhibits a charge density wave (CDW) state below T = 78 K, we uncover an\nunpredicted field-induced phase transition below 6 K. The observed transition\nis marked by a hysteretic anomaly in the resistivity, nonlinear electrical\ntransport, and a change in the symmetry of the electronic response as probed\nvia the angular dependence of the magnetoresistivity. These observations\nsurprisingly suggest the emergence of an unanticipated broken symmetry state\ncoexisting with the original CDW. To understand this experimental observation,\nwe developed a theoretical minimal model for the normal state inside the\nhigh-temperature parent CDW phase where an incommensurate CDW order emerges as\nan instability sub-leading to superconductivity. The incommensurate CDW emerges\nwhen superconducting fluctuations become fully suppressed by large magnetic\nfields. Our results suggest that, in kagome superconductors, quantum states can\neither coexist or are nearly degenerate in energy, indicating that these are\nrich platforms to expose new correlated phenomena."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03439"
    ],
    "c_title":[
      "On the anti-Ramsey threshold"
    ],
    "c_abstract":[
      "We say that a graph $G$ is anti-Ramsey for a graph $H$ if any proper\nedge-colouring of $G$ yields a rainbow copy of $H$, i.e. a copy of $H$ whose\nedges all receive different colours. In this work we determine the threshold at\nwhich the binomial random graph becomes anti-Ramsey for any fixed graph $H$,\ngiven that $H$ is sufficiently dense. Our proof employs a graph decomposition\nlemma in the style of the Nine Dragon Tree theorem that may be of independent\ninterest."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-678",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16779"
    ],
    "b_title":[
      "Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of\n  Frozen Language Models"
    ],
    "b_abstract":[
      "Tool learning can further broaden the usage scenarios of large language\nmodels (LLMs). However most of the existing methods either need to finetune\nthat the model can only use tools seen in the training data, or add tool\ndemonstrations into the prompt with lower efficiency. In this paper, we present\na new Tool Learning method Chain-of-Tools. It makes full use of the powerful\nsemantic representation capability of frozen LLMs to finish tool calling in CoT\nreasoning with a huge and flexible tool pool which may contain unseen tools.\nEspecially, to validate the effectiveness of our approach in the massive unseen\ntool scenario, we construct a new dataset SimpleToolQuestions. We conduct\nexperiments on two numerical reasoning benchmarks (GSM8K-XL and FuncQA) and two\nknowledge-based question answering benchmarks (KAMEL and SimpleToolQuestions).\nExperimental results show that our approach performs better than the baseline.\nWe also identify dimensions of the model output that are critical in tool\nselection, enhancing the model interpretability. Our code and data are\navailable at: https:\/\/github.com\/fairyshine\/Chain-of-Tools ."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05370"
    ],
    "c_title":[
      "Free energy profiles for chemical reactions in solution from\n  high-dimensional neural network potentials: The case of the Strecker\n  synthesis"
    ],
    "c_abstract":[
      "Machine learning potentials (MLPs) have become a popular tool in chemistry\nand materials science as they combine the accuracy of electronic structure\ncalculations with the high computational efficiency of analytic potentials.\nMLPs are particularly useful for computationally demanding simulations such as\nthe determination of free energy profiles governing chemical reactions in\nsolution, but to date such applications are still rare. In this work we show\nhow umbrella sampling simulations can be combined with active learning of\nhigh-dimensional neural network potentials (HDNNPs) to construct free energy\nprofiles in a systematic way. For the example of the first step of Strecker\nsynthesis of glycine in aqueous solution we provide a detailed analysis of the\nimproving quality of HDNNPs for datasets of increasing size. We find that next\nto the typical quantification of energy and force errors with respect to the\nunderlying density functional theory data also the long-term stability of the\nsimulations and the convergence of physical properties should be rigorously\nmonitored to obtain reliable and converged free energy profiles of chemical\nreactions in solution."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-679",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00322"
    ],
    "b_title":[
      "MODS: Moderating a Mixture of Document Speakers to Summarize Debatable\n  Queries in Document Collections"
    ],
    "b_abstract":[
      "Query-focused summarization (QFS) gives a summary of documents to answer a\nquery. Past QFS work assumes queries have one answer, ignoring debatable ones\n(Is law school worth it?). We introduce Debatable QFS (DQFS), a task to create\nsummaries that answer debatable queries via documents with opposing\nperspectives; summaries must comprehensively cover all sources and balance\nperspectives, favoring no side. These goals elude LLM QFS systems, which: 1)\nlack structured content plans, failing to guide LLMs to write balanced\nsummaries, and 2) use the same query to retrieve contexts across documents,\nfailing to cover all perspectives specific to each document's content. To\novercome this, we design MODS, a multi-LLM framework mirroring human panel\ndiscussions. MODS treats documents as individual Speaker LLMs and has a\nModerator LLM that picks speakers to respond to tailored queries for planned\ntopics. Speakers use tailored queries to retrieve relevant contexts from their\ndocuments and supply perspectives, which are tracked in a rich outline,\nyielding a content plan to guide the final summary. Experiments on\nConflictingQA with controversial web queries and DebateQFS, our new dataset of\ndebate queries from Debatepedia, show MODS beats SOTA by 38-59% in topic\nparagraph coverage and balance, based on new citation metrics. Users also find\nMODS's summaries to be readable and more balanced."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15914"
    ],
    "c_title":[
      "Orbital Depot Location Optimization for Satellite Constellation\n  Servicing with Low-Thrust Transfers"
    ],
    "c_abstract":[
      "This paper addresses the critical problem of co-optimizing the optimal\nlocations for orbital depots and the sequence of in-space servicing for a\nsatellite constellation. While most traditional studies used network\noptimization for this problem, assuming a fixed set of discretized nodes in the\nnetwork (i.e., a limited number of depot location candidates), this work is\nunique in that it develops a method to optimize the depot location in\ncontinuous space. The problem is formulated as mixed-integer nonlinear\nprogramming, and we propose a solution methodology that iteratively solves two\ndecoupled problems: one using mixed-integer linear programming and the other\nusing nonlinear programming with an analytic transfer solution. To demonstrate\nthe effectiveness of our approach, we apply this methodology to a case study\ninvolving a GPS satellite constellation. Numerical experiments confirm the\nstability of our proposed solutions."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-680",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11567"
    ],
    "b_title":[
      "Microfacet projected area-based correction for unified model of Geant4\n  for rough surfaces"
    ],
    "b_abstract":[
      "A modification of the optical model for rough surfaces, implemented in Geant4\nas a part of the unified model, is suggested. The modified model takes into\naccount the variation of the interaction probability of the photon with the\nmicrofacet based on the relative orientation of the photon and the sampled\nmicrofacet's normal. The implementation is using a rejection algorithm and\nassumes the interaction probability to be proportional to the projection of the\nmicrofacet area on the plane perpendicular to the photon direction. A\ncomparison of the results obtained with the original and the modified models,\nas well as obtained in direct Monte Carlo simulations are presented for several\ntest surfaces constructed using a pattern of elementary geometrical shapes."
    ],
    "b_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.04697"
    ],
    "c_title":[
      "Multi-Agent Coverage Control in Non-Convex Annulus Region with Conformal\n  Mapping"
    ],
    "c_abstract":[
      "Efficiently fulfilling coverage tasks in non-convex regions has long been a\nsignificant challenge for multi-agent systems (MASs). By leveraging conformal\nmapping, this paper introduces a novel sectorial coverage formulation to\ntransform a non-convex annulus region into a topologically equivalent one. This\napproach enables the deployment of MASs in a non-star-shaped region while\noptimizing coverage performance and achieving load balance among sub-regions.\nIt provides a unique perspective on the partitioned sub-regions to highlight\nthe geodesic convex property of the non-star-shaped region. By utilizing the\nsectorial partition mechanism and the diffeomorphism property of conformal\nmapping, a decentralized control law is designed to drive MASs towards a\ndesired configuration, which not only optimizes the global coverage cost but\nalso ensures exponential convergence of equitable workload. Moreover, an\niterative search algorithm is developed to identify the optimal approximation\nof multi-agent deployment in the non-star-shaped region. Theoretical analysis\nis conducted to confirm the asymptotic stability and global convergence with\narbitrary small tolerance of the closed-loop system. Finally, numerical\nsimulations demonstrate the practicality of the proposed coverage formulation\nwith conformal mapping."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-681",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13616"
    ],
    "b_title":[
      "Fragile Unconventional Magnetism in RuO$_2$ by Proximity to\n  Landau-Pomeranchuk Instability"
    ],
    "b_abstract":[
      "Altermagnetism has attracted considerable attention for its remarkable\ncombination of spin-polarized band structures and zero net magnetization,\nmaking it a promising candidate for spintronics applications. We demonstrate\nthat this magnetic phase represents a case of ``unconventional magnetism,\"\nfirst proposed nearly two decades ago by one of the present authors as part of\na broader framework for understanding Landau-Pomeranchuk instabilities in the\nspin channel, driven by many-body interactions. By systematically analyzing the\naltermagnetism in RuO$_2$ with first-principles calculations, we reconcile\nconflicting experimental and theoretical reports by attributing it to RuO$_2$'s\nproximity to a quantum phase transition. We emphasize the critical role of\ntuning parameters, such as the Hubbard $U$, hole doping, and epitaxial strain,\nin modulating quasiparticle interactions near the Fermi surface. This work\nprovides fresh insights into the origin and tunability of altermagnetism in\nRuO$_2$, highlighting its potential as a platform for investigating quantum\nphase transitions and the broader realm of unconventional magnetism."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16476"
    ],
    "c_title":[
      "Directional polynomial wavelets on spheres"
    ],
    "c_abstract":[
      "In this article, we construct discrete tight frames for\n$L^2(\\mathbb{S}^{d-1})$, $d\\geq3$, which consist of localized polynomial\nwavelets with adjustable degrees of directionality. In contrast to the well\nstudied isotropic case, these systems are well suited for the direction\nsensitive analysis of anisotropic features such as edges. The price paid for\nthis is the fact that at each scale the wavelet transform lives on the rotation\ngroup $SO(d)$, and not on $\\mathbb{S}^{d-1}$ as in the zonal setting. Thus, the\nstandard approach of building discrete frames by sampling the continuous\nwavelet transform requires a significantly larger amount of sample points.\nHowever, by keeping the directionality limited, this number can be greatly\nreduced to the point where it is comparable to the number of samples needed in\nthe isotropic case. Moreover, the limited directionality is reflected in the\nwavelets being steerable and their great localization in space leads to a fast\nconvergence of the wavelet expansion in the spaces $L^p(\\mathbb{S}^{d-1})$,\n$1\\leq p \\leq \\infty$."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-682",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18182"
    ],
    "b_title":[
      "Exploring Topic Trends in COVID-19 Research Literature using\n  Non-Negative Matrix Factorization"
    ],
    "b_abstract":[
      "In this work, we apply topic modeling using Non-Negative Matrix Factorization\n(NMF) on the COVID-19 Open Research Dataset (CORD-19) to uncover the underlying\nthematic structure and its evolution within the extensive body of COVID-19\nresearch literature. NMF factorizes the document-term matrix into two\nnon-negative matrices, effectively representing the topics and their\ndistribution across the documents. This helps us see how strongly documents\nrelate to topics and how topics relate to words. We describe the complete\nmethodology which involves a series of rigorous pre-processing steps to\nstandardize the available text data while preserving the context of phrases,\nand subsequently feature extraction using the term frequency-inverse document\nfrequency (tf-idf), which assigns weights to words based on their frequency and\nrarity in the dataset. To ensure the robustness of our topic model, we conduct\na stability analysis. This process assesses the stability scores of the NMF\ntopic model for different numbers of topics, enabling us to select the optimal\nnumber of topics for our analysis. Through our analysis, we track the evolution\nof topics over time within the CORD-19 dataset. Our findings contribute to the\nunderstanding of the knowledge structure of the COVID-19 research landscape,\nproviding a valuable resource for future research in this field."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02908"
    ],
    "c_title":[
      "On semicommutativity of rings relative to hypercenter"
    ],
    "c_abstract":[
      "Armendariz and semicommutative rings are generalizations of reduced rings. In\n\\cite{IN}, I.N. Herstein introduced the notion of a hypercenter of a ring to\ngeneralize the center subclass. For a ring $R$, an element $a \\in R$ is called\nhypercentral if $ax^{n}=x^{n}a$ for all $x \\in R$ and for some $n=n(x,a) \\in\n\\mathbb{N}$. Motivated by this definition, we introduce\n$\\mathscr{H}$-Semicommutative rings as a generalization of semicommutative\nrings and investigate their relations with other classes of rings. We have\nproven that the class of $\\mathscr{H}$-Semicommutative rings lies strictly\nbetween Zero-Insertive rings (ZI) and Abelian rings. Additionally, we have\ndemonstrated that if $R$ is $\\mathscr{H}$-semicommutative, then for any $n \\in\n\\mathbb{N}$, the matrix subring $S_{n}^{'}(R)$ is also\n$\\mathscr{H}$-semicommutative. Among other significant results, we have\nestablished that if $R$ is $\\mathscr{H}$-semicommutative and left $SF$, then\n$R$ is strongly regular. We have also shown that $\\mathscr{H}$-semicommutative\nrings are 2-primal, providing sufficient conditions for a ring $R$ to be\nnil-singular. Additionally, we have proven that if every simple singular module\nover $R$ is wnil-injective and $R$ is $\\mathscr{H}$-semicommutative, then $R$\nis reduced. Furthermore, we have studied the relationship of\n$\\mathscr{H}$-semicommutative rings with the classes of Baer, Quasi-Baer, p.p.\nrings, and p.q. rings in this article, and we have provided some more relevant\nresults."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-683",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13535"
    ],
    "b_title":[
      "Unlocking Learning Potentials: The Transformative Effect of Generative\n  AI in Education Across Grade Levels"
    ],
    "b_abstract":[
      "The advent of generative artificial intelligence (GAI) has brought about a\nnotable surge in the field of education. The use of GAI to support learning is\nbecoming increasingly prevalent among students. However, the manner and extent\nof its utilisation vary considerably from one individual to another. And\nresearches about student's utilisation and perceptions of GAI remains\nrelatively scarce. To gain insight into the issue, this paper proposed a\nhybrid-survey method to examine the impact of GAI on students across four\ndifferent grades in six key areas (LIPSAL): learning interest, independent\nlearning, problem solving, self-confidence, appropriate use, and learning\nenjoyment. Firstly, through questionnaire, we found that among LIPSAL, GAI has\nthe greatest impact on the concept of appropriate use, the lowest level of\nlearning interest and self-confidence. Secondly, a comparison of four grades\nrevealed that the high and low factors of LIPSAL exhibited grade-related\nvariation, and college students exhibited a higher level than high school\nstudents across LIPSAL. Thirdly, through interview, the students demonstrated a\ncomprehensive understanding of the application of GAI. We found that students\nhave a positive attitude towards GAI and are very willing to use it, which is\nwhy GAI has grown so rapidly in popularity. They also told us prospects and\nchallenges in using GAI. In the future, as GAI matures technologically, it will\nhave an greater impact on students. These findings may help better understand\nusage by different students and inform future research in digital education."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03499"
    ],
    "c_title":[
      "Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and\n  Multi-Task Learning"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) demonstrate remarkable generalizability across\ndiverse tasks, yet genomic foundation models (GFMs) still require separate\nfinetuning for each downstream application, creating significant overhead as\nmodel sizes grow. Moreover, existing GFMs are constrained by rigid output\nformats, limiting their applicability to various genomic tasks. In this work,\nwe revisit the transformer-based auto-regressive models and introduce Omni-DNA,\na family of cross-modal multi-task models ranging from 20 million to 1 billion\nparameters. Our approach consists of two stages: (i) pretraining on DNA\nsequences with next token prediction objective, and (ii) expanding the\nmulti-modal task-specific tokens and finetuning for multiple downstream tasks\nsimultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks,\nOmni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Through\nmulti-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasks\nat once, surpassing models trained on each task individually. Finally, we\ndesign two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNA\nsequences to textual functional descriptions and images, respectively,\nindicating Omni-DNA's cross-modal capabilities to broaden the scope of genomic\napplications. All the models are available through\nhttps:\/\/huggingface.co\/collections\/zehui127"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-684",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18601"
    ],
    "b_title":[
      "Tighten The Lasso: A Convex Hull Volume-based Anomaly Detection Method"
    ],
    "b_abstract":[
      "The rapid advancements in data-driven methodologies have underscored the\ncritical importance of ensuring data quality. Consequently, detecting\nout-of-distribution (OOD) data has emerged as an essential task to maintain the\nreliability and robustness of data-driven models, in general, and machine and\ndeep learning models, in particular. In this study, we leveraged the convex\nhull property of a dataset and the fact that anomalies highly contribute to the\nincrease of the CH's volume to propose a novel anomaly detection algorithm. Our\nalgorithm computes the CH's volume as an increasing number of data points are\nremoved from the dataset to define a decision line between OOD and\nin-distribution data points. We compared the proposed algorithm to seven widely\nused anomaly detection algorithms over ten datasets, showing comparable results\nfor state-of-the-art (SOTA) algorithms. Moreover, we show that with a\ncomputationally cheap and simple check, one can detect datasets that are\nwell-suited for the proposed algorithm which outperforms the SOTA anomaly\ndetection algorithms."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12533"
    ],
    "c_title":[
      "Ultrasound measurement technique for the single-turn-coil magnets"
    ],
    "c_abstract":[
      "Ultrasound is a powerful means to study numerous phenomena of\ncondensed-matter physics as acoustic waves couple strongly to structural,\nmagnetic, orbital, and charge degrees of freedom. In this paper, we present\nsuch technique combined with single-turn coils (STC) which generate magnetic\nfields beyond 100 T with the typical pulse duration of 6 us. As a benchmark of\nthis technique, the ultrasound results for MnCr2S4, Cu6[Si6O18]6H2O, and liquid\noxygen are shown. The resolution for the relative sound-velocity change in the\nSTC is estimated as Delta v\/v~10^-3, which is sufficient to study various\nfield-induced phase transitions and critical phenomena."
    ],
    "c_categories":[
      [
        "cond-mat.other"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-685",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16120"
    ],
    "b_title":[
      "A Fenchel-Young Loss Approach to Data-Driven Inverse Optimization"
    ],
    "b_abstract":[
      "Data-driven inverse optimization seeks to estimate unknown parameters in an\noptimization model from observations of optimization solutions. Many existing\nmethods are ineffective in handling noisy and suboptimal solution observations\nand also suffer from computational challenges. In this paper, we build a\nconnection between inverse optimization and the Fenchel-Young (FY) loss\noriginally designed for structured prediction, proposing a FY loss approach to\ndata-driven inverse optimization. This new approach is amenable to efficient\ngradient-based optimization, hence much more efficient than existing methods.\nWe provide theoretical guarantees for the proposed method and use extensive\nsimulation and real-data experiments to demonstrate its significant advantage\nin parameter estimation accuracy, decision error and computational speed."
    ],
    "b_categories":[
      [
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.14199"
    ],
    "c_title":[
      "Coordinating Ride-Pooling with Public Transit using Reward-Guided\n  Conservative Q-Learning: An Offline Training and Online Fine-Tuning\n  Reinforcement Learning Framework"
    ],
    "c_abstract":[
      "This paper introduces a novel reinforcement learning (RL) framework, termed\nReward-Guided Conservative Q-learning (RG-CQL), to enhance coordination between\nride-pooling and public transit within a multimodal transportation network. We\nmodel each ride-pooling vehicle as an agent governed by a Markov Decision\nProcess (MDP) and propose an offline training and online fine-tuning RL\nframework to learn the optimal operational decisions of the multimodal\ntransportation systems, including rider-vehicle matching, selection of drop-off\nlocations for passengers, and vehicle routing decisions, with improved data\nefficiency. During the offline training phase, we develop a Conservative Double\nDeep Q Network (CDDQN) as the action executor and a supervised learning-based\nreward estimator, termed the Guider Network, to extract valuable insights into\naction-reward relationships from data batches. In the online fine-tuning phase,\nthe Guider Network serves as an exploration guide, aiding CDDQN in effectively\nand conservatively exploring unknown state-action pairs. The efficacy of our\nalgorithm is demonstrated through a realistic case study using real-world data\nfrom Manhattan. We show that integrating ride-pooling with public transit\noutperforms two benchmark cases solo rides coordinated with transit and\nride-pooling without transit coordination by 17% and 22% in the achieved system\nrewards, respectively. Furthermore, our innovative offline training and online\nfine-tuning framework offers a remarkable 81.3% improvement in data efficiency\ncompared to traditional online RL methods with adequate exploration budgets,\nwith a 4.3% increase in total rewards and a 5.6% reduction in overestimation\nerrors. Experimental results further demonstrate that RG-CQL effectively\naddresses the challenges of transitioning from offline to online RL in\nlarge-scale ride-pooling systems integrated with transit."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-686",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14331"
    ],
    "b_title":[
      "Cosmic ray transport and acceleration in an evolving shock landscape"
    ],
    "b_abstract":[
      "The sources of cosmic rays between the knee and the ankle are still debated.\nThe Galactic wind and its termination shock have been proposed to contribute to\nthis transition between Galactic and extragalactic origin, but another\npossibility is large-scale shock structures from local sources in the Milky\nWay. In this paper, we investigate CR transport in a time-dependent landscape\nof shocks in the Galactic halo. These shocks could result from local outbursts,\ne.g. starforming regions and superbubbles. CRs re-accelerated at such shocks\ncan reach energies above the knee. Since the shocks are closer to the Galaxy\nthan a termination shock and CRs escape downstream, they can propagate back\nmore easily. With such outbursts happening frequently, shocks will interact.\nThis interaction could adjust the CR spectrum, particularly for the particles\nthat are able to be accelerated at two shocks simultaneously. The transport and\nacceleration of CRs at the shock is modeled by Stochastic Differential\nEquations (SDEs) within the public CR propagation framework CRPropa. We\ndeveloped extensions for time-dependent wind profiles and for the first time\nconnected the code to hydrodynamic simulations, which were run with the public\nAthena++ code. We find that, depending on the concrete realization of the\ndiffusion tensor, a significant fraction of CRs can make it back to the Galaxy.\nThese could contribute to the observed spectrum around and above the CR knee\n($E \\gtrsim 10\\,\\mathrm{PeV}$). In contrast to simplified models, a simple\npower-law does not describe the energy spectra well. Instead, for single\nshocks, we find a flat spectrum ($E^{-2}$) at low energies, which steepens\ngradually until it reaches an exponential decline. When shocks collide, the\nenergy spectra transiently become harder than $E^{-2}$ at high energies."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.06992"
    ],
    "c_title":[
      "Bridge Frame and Event: Common Spatiotemporal Fusion for High-Dynamic\n  Scene Optical Flow"
    ],
    "c_abstract":[
      "High-dynamic scene optical flow is a challenging task, which suffers spatial\nblur and temporal discontinuous motion due to large displacement in frame\nimaging, thus deteriorating the spatiotemporal feature of optical flow.\nTypically, existing methods mainly introduce event camera to directly fuse the\nspatiotemporal features between the two modalities. However, this direct fusion\nis ineffective, since there exists a large gap due to the heterogeneous data\nrepresentation between frame and event modalities. To address this issue, we\nexplore a common-latent space as an intermediate bridge to mitigate the\nmodality gap. In this work, we propose a novel common spatiotemporal fusion\nbetween frame and event modalities for high-dynamic scene optical flow,\nincluding visual boundary localization and motion correlation fusion.\nSpecifically, in visual boundary localization, we figure out that frame and\nevent share the similar spatiotemporal gradients, whose similarity distribution\nis consistent with the extracted boundary distribution. This motivates us to\ndesign the common spatiotemporal gradient to constrain the reference boundary\nlocalization. In motion correlation fusion, we discover that the frame-based\nmotion possesses spatially dense but temporally discontinuous correlation,\nwhile the event-based motion has spatially sparse but temporally continuous\ncorrelation. This inspires us to use the reference boundary to guide the\ncomplementary motion knowledge fusion between the two modalities. Moreover,\ncommon spatiotemporal fusion can not only relieve the cross-modal feature\ndiscrepancy, but also make the fusion process interpretable for dense and\ncontinuous optical flow. Extensive experiments have been performed to verify\nthe superiority of the proposed method."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-687",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02762"
    ],
    "b_title":[
      "The hot corino-like chemistry of four FUor-like protostars"
    ],
    "b_abstract":[
      "Context: Compared to Class 0 protostars, the higher densities and lower\ntemperatures of the disk midplanes of Class I young stellar objects (YSOs)\nlimit the detectability of complex organic molecules (COMs). The elevated\nluminosities of eruptive YSOs increase disk temperatures sublimating frozen\nmolecules and easing their detection.\n  Aims: Our aim is to investigate the chemical composition of four FUor-like\nClass I YSOs: L1551 IRS 5, Haro 5a IRS, V346 Nor, and OO Ser, and to compare\ntheir abundances of COMs with other YSOs in the literature.\n  Methods: We search for COMs line emission in ALMA Band 6 observations. We use\nthe CASSIS software to determine their column densities (N) and excitation\ntemperatures (T_ex) assuming local thermodynamical equilibrium.\n  Results: We detect 249 transitions from 12 COMs. In L1551 IRS 5 we identified\nCH3OH, 13CH3OH, CH318OH, CH2DOH, CH3CHO, CH3OCH3, CH3OCHO, CH3COCH3, C2H5OH,\nC2H5CN, 13CH3CN, and CH3C15)N. Haro 5a IRS and OO Ser have emission from CH3OH,\nCH3CHO, CH3OCH3, and CH3OCHO. CH3COCH3 is also detected in OO Ser. In V346 Nor\nwe found CH3OH, CH2DOH, CH3CHO, CH3OCH3, CH3OCHO, and C2H5CN. The emission of\nCOMs is compact in all targets. The analysis indicates their temperatures are\nabove 100K. The abundance ratios of COMs derived for these eruptive YSOs, as\nwell as for other protostars in the literature, span several orders of\nmagnitude without any clear differentiation between the eruptive and quiescent\nYSOs. The column density of the main isotopologue of CH3OH should not be used\nas a reference, as most of the lines are optically thick.\n  Conclusions: The hot and compact emission of COMs indicates that the four\nFUor-like targets are hot corino-like. Spectral studies of such objects can be\nuseful to investigate the complex organic chemistry at later evolutionary\nstages than the usual Class 0 stage."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03806"
    ],
    "c_title":[
      "Should Code Models Learn Pedagogically? A Preliminary Evaluation of\n  Curriculum Learning for Real-World Software Engineering Tasks"
    ],
    "c_abstract":[
      "Learning-based techniques, especially advanced pre-trained models for code\nhave demonstrated capabilities in code understanding and generation, solving\ndiverse software engineering (SE) tasks. Despite the promising results, current\ntraining approaches may not fully optimize model performance, as they typically\ninvolve learning from randomly shuffled training data. Recent work shows that\nCurriculum Learning (CL) can improve performance on code-related tasks through\nincremental learning based on the difficulty of synthetic code. Yet, the\neffectiveness of CL with conventional difficulty measures in SE tasks remains\nlargely unexplored. In this study, we explore two conventional code metrics:\ncode length and cyclomatic complexity to determine the difficulty levels. We\ninvestigate how the pre-trained code model (CodeT5) learns under CL, through\nthe tasks of code clone detection and code summarization. Our empirical study\non the CodeXGLUE benchmark showed contrasting results to prior studies, where\nthe model exhibited signs of catastrophic forgetting and shortcut learning.\nSurprisingly, model performance saturates after only the first quartile of\ntraining, potentially indicating a limit in the model's representation capacity\nand\/or the task's inherent difficulty. Future work should further explore\nvarious CL strategies with different code models across a wider range of SE\ntasks for a more holistic understanding."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-688",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11846"
    ],
    "b_title":[
      "Neural Network Reconstruction of Non-Gaussian Initial Conditions from\n  Dark Matter Halos"
    ],
    "b_abstract":[
      "We develop a machine learning approach to reconstructing the cosmological\ninitial conditions from late-time dark matter halo number density fields in\nredshift space, with the goal of improving sensitivity to cosmological\nparameters, and in particular primordial non-Gaussianity. Using an U-Net\narchitecture, our model achieves a cross-correlation accuracy of 44% for scales\nout to $k = 0.4 \\text{ h}\/\\text{Mpc}$ between reconstructed and true initial\nconditions of Quijote 1 Gpc$^3$ simulation boxes with an average halo number\ndensity of $\\bar{n} = 4\\times 10^{-4}$ (h\/Mpc)$^{3}$ in the tracer field at\n$z=0$ . We demonstrate that our reconstruction is likely to be optimal for this\nsetup and that it is highly effective at reducing redshift-space distortions.\nUsing a Fisher analysis, we show that reconstruction improves cosmological\nparameter constraints derived from the power spectrum and bispectrum. By\ncombining the power spectrum monopole, quadrupole, and bispectrum monopole up\nto $k_{\\rm{max}} = 0.52 \\text{ h}\/\\text{Mpc}$, our joint analysis of pre- and\npost-reconstructed fields from the Quijote simulation suite finds improved\nmarginalized errors on all cosmological parameters. In particular,\nreconstruction improves constraints on $f_{\\rm{NL}}$ by factors of 1.33, 1.88,\nand 1.57 for local, equilateral, and orthogonal shapes. Our findings\ndemonstrate the effectiveness of reconstruction in decoupling modes, mitigating\nredshift-space distortions and maximizing information on cosmology. The results\nprovide important insights into the amount of cosmological information that can\nbe extracted from small scales, and can potentially be used to complement\nstandard analysis of observational data, upon further development."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.10394"
    ],
    "c_title":[
      "A Coordination-based Approach for Focused Learning in Knowledge-Based\n  Systems"
    ],
    "c_abstract":[
      "Recent progress in Learning by Reading and Machine Reading systems has\nsignificantly increased the capacity of knowledge-based systems to learn new\nfacts. In this work, we discuss the problem of selecting a set of learning\nrequests for these knowledge-based systems which would lead to maximum Q\/A\nperformance. To understand the dynamics of this problem, we simulate the\nproperties of a learning strategy, which sends learning requests to an external\nknowledge source. We show that choosing an optimal set of facts for these\nlearning systems is similar to a coordination game, and use reinforcement\nlearning to solve this problem. Experiments show that such an approach can\nsignificantly improve Q\/A performance."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-689",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07102"
    ],
    "b_title":[
      "Coordinated Energy-Trajectory Economic Model Predictive Control for\n  Autonomous Surface Vehicles under Disturbances"
    ],
    "b_abstract":[
      "The paper proposes a novel Economic Model Predictive Control (EMPC) scheme\nfor Autonomous Surface Vehicles (ASVs) to simultaneously address path following\naccuracy and energy constraints under environmental disturbances. By\nformulating lateral deviations as energy-equivalent penalties in the cost\nfunction, our method enables explicit trade-offs between tracking precision and\nenergy consumption. Furthermore, a motion-dependent decomposition technique is\nproposed to estimate terminal energy costs based on vehicle dynamics. Compared\nwith the existing EMPC method, simulations with real-world ocean disturbance\ndata demonstrate the controller's energy consumption with a 0.06 energy\nincrease while reducing cross-track errors by up to 18.61. Field experiments\nconducted on an ASV equipped with an Intel N100 CPU in natural lake\nenvironments validate practical feasibility, achieving 0.22 m average\ncross-track error at nearly 1 m\/s and 10 Hz control frequency. The proposed\nscheme provides a computationally tractable solution for ASVs operating under\nresource constraints."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13088"
    ],
    "c_title":[
      "General soliton solutions to the coupled Hirota equation via the\n  Kadomtsev-Petviashvili reduction"
    ],
    "c_abstract":[
      "In this paper, we are concerned with various soliton solutions to the coupled\nHirota equation, as well as to the Sasa-Satsuma equation which can be viewed as\none reduction case of the coupled Hirota equation. First, we derive\nbright-bright, dark-dark, and bright-dark soliton solutions of the coupled\nHirota equation by using the Kadomtsev-Petviashvili reduction method. Then, we\npresent the bright and dark soliton solutions to the Sasa-Satsuma equation\nwhich are expressed by determinants of $N \\times N$ instead of $2N \\times 2N$\nin the literature. The dynamics of first-, second-order solutions are\ninvestigated in detail. It is intriguing that, for the SS equation, the bright\nsoliton for \\(N=1\\) is also the soliton to the complex mKdV equation while the\namplitude and velocity of dark soliton for \\(N=1\\) are determined by the\nbackground plane wave. For \\(N=2\\), the bright soliton can be classified into\nthree types: oscillating, single-hump, and two-hump ones while the dark soliton\ncan be classified into five types: dark (single-hole), anti-dark, Mexican hat,\nanti-Mexican hat and double-hole. Moreover, the types of bright solitons for\nthe Sasa-Satsuma equation can be changed due to collision."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-690",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12379"
    ],
    "b_title":[
      "Constant Weight Polar Codes through Periodic Markov Processes"
    ],
    "b_abstract":[
      "Constant weight codes can arise from an input process sampled from a periodic\nMarkov chain. A previous result showed that, in general, polarization does not\noccur for input-output processes with an underlying periodic Markov chain. In\nthis work, we show that if we fix the initial state of an underlying periodic\nMarkov chain, polarization does occur. Fixing the initial state is aligned with\nensuring a constant weight code."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03841"
    ],
    "c_title":[
      "OmniManip: Towards General Robotic Manipulation via Object-Centric\n  Interaction Primitives as Spatial Constraints"
    ],
    "c_abstract":[
      "The development of general robotic systems capable of manipulating in\nunstructured environments is a significant challenge. While Vision-Language\nModels(VLM) excel in high-level commonsense reasoning, they lack the\nfine-grained 3D spatial understanding required for precise manipulation tasks.\nFine-tuning VLM on robotic datasets to create Vision-Language-Action\nModels(VLA) is a potential solution, but it is hindered by high data collection\ncosts and generalization issues. To address these challenges, we propose a\nnovel object-centric representation that bridges the gap between VLM's\nhigh-level reasoning and the low-level precision required for manipulation. Our\nkey insight is that an object's canonical space, defined by its functional\naffordances, provides a structured and semantically meaningful way to describe\ninteraction primitives, such as points and directions. These primitives act as\na bridge, translating VLM's commonsense reasoning into actionable 3D spatial\nconstraints. In this context, we introduce a dual closed-loop, open-vocabulary\nrobotic manipulation system: one loop for high-level planning through primitive\nresampling, interaction rendering and VLM checking, and another for low-level\nexecution via 6D pose tracking. This design ensures robust, real-time control\nwithout requiring VLM fine-tuning. Extensive experiments demonstrate strong\nzero-shot generalization across diverse robotic manipulation tasks,\nhighlighting the potential of this approach for automating large-scale\nsimulation data generation."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-691",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16039"
    ],
    "b_title":[
      "Complexity of Minimal Faithful Permutation Degree for Fitting-free\n  Groups"
    ],
    "b_abstract":[
      "In this paper, we investigate the complexity of computing the minimal\nfaithful permutation degree for groups without abelian normal subgroups. When\nour groups are given as quotients of permutation groups, we establish that this\nproblem is in $\\textsf{P}$. Furthermore, in the setting of permutation groups,\nwe obtain an upper bound of $\\textsf{NC}$ for this problem. This improves upon\nthe work of Das and Thakkar (STOC 2024), who established a Las Vegas\npolynomial-time algorithm for this class in the setting of permutation groups."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.DS",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13562"
    ],
    "c_title":[
      "Are Large Language Models In-Context Graph Learners?"
    ],
    "c_abstract":[
      "Large language models (LLMs) have demonstrated remarkable in-context\nreasoning capabilities across a wide range of tasks, particularly with\nunstructured inputs such as language or images. However, LLMs struggle to\nhandle structured data, such as graphs, due to their lack of understanding of\nnon-Euclidean structures. As a result, without additional fine-tuning, their\nperformance significantly lags behind that of graph neural networks (GNNs) in\ngraph learning tasks. In this paper, we show that learning on graph data can be\nconceptualized as a retrieval-augmented generation (RAG) process, where\nspecific instances (e.g., nodes or edges) act as queries, and the graph itself\nserves as the retrieved context. Building on this insight, we propose a series\nof RAG frameworks to enhance the in-context learning capabilities of LLMs for\ngraph learning tasks. Comprehensive evaluations demonstrate that our proposed\nRAG frameworks significantly improve LLM performance on graph-based tasks,\nparticularly in scenarios where a pretrained LLM must be used without\nmodification or accessed via an API."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-692",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02096"
    ],
    "b_title":[
      "Effects of Galaxy Cluster Structure on Lensed Transients"
    ],
    "b_abstract":[
      "Strong gravitational lenses come in many forms, but are typically divided\ninto two populations: galaxies, and groups and clusters of galaxies. When\ncalculating the properties of the images we expect to see from these lenses, it\nis typically assumed that each lens is roughly a singular isothermal sphere. In\nreality, the largest objects in the Universe (i.e. galaxy clusters) are highly\nirregular and composed of many components due to a history of (or active)\nhierarchical mergers. In this work, we analyze the discrepancies in the\nobservables of strongly lensed transients in both scenarios, namely relative\nmagnifications, time delays, and image multiplicities. Focusing on\ngravitational waves, we compare the detection rates between the single\nspherical dark matter halo models found in the literature, and publicly\navailable state-of-the-art cluster lens models. We find there to be\napproximately an order of magnitude fewer detection of strongly lensed\ntransients in the realistic model case, likely caused by their loss of overall\nstrong lensing optical depth. We also report detection rates in the weak\nlensing or single-image regime. Additionally, we find a systemic shift towards\nlower time delays between the brightest image pairs in the cases of the\nrealistic models, as well as higher fractions of positive versus negative\nparity images, as seen elsewhere in the literature. This significant deviation\nin the joint relative magnification factor-time delay distribution will hinder\nthe feasibility of the reconstruction of lenses through time domain transients\nalone, but can still provide a lower limit on the lens mass."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.16707"
    ],
    "c_title":[
      "Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D\n  Scene Understanding"
    ],
    "c_abstract":[
      "The lack of a large-scale 3D-text corpus has led recent works to distill\nopen-vocabulary knowledge from vision-language models (VLMs). owever, these\nmethods typically rely on a single VLM to align the feature spaces of 3D models\nwithin a common language space, which limits the potential of 3D models to\nleverage the diverse spatial and semantic capabilities encapsulated in various\nfoundation models. In this paper, we propose Cross-modal and Uncertainty-aware\nAgglomeration for Open-vocabulary 3D Scene Understanding dubbed CUA-O3D, the\nfirst model to integrate multiple foundation models-such as CLIP, DINOv2, and\nStable Diffusion-into 3D scene understanding. We further introduce a\ndeterministic uncertainty estimation to adaptively distill and harmonize the\nheterogeneous 2D feature embeddings from these models. Our method addresses two\nkey challenges: (1) incorporating semantic priors from VLMs alongside the\ngeometric knowledge of spatially-aware vision foundation models, and (2) using\na novel deterministic uncertainty estimation to capture model-specific\nuncertainties across diverse semantic and geometric sensitivities, helping to\nreconcile heterogeneous representations during training. Extensive experiments\non ScanNetV2 and Matterport3D demonstrate that our method not only advances\nopen-vocabulary segmentation but also achieves robust cross-domain alignment\nand competitive spatial perception capabilities. The code will be available at\n\\href{https:\/\/github.com\/TyroneLi\/CUA_O3D}{CUA_O3D}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-693",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15009"
    ],
    "b_title":[
      "Contextualizing Search Queries In-Context Learning for Conversational\n  Rewriting with LLMs"
    ],
    "b_abstract":[
      "Conversational query rewriting is crucial for effective conversational\nsearch, yet traditional supervised methods require substantial labeled data,\nwhich is scarce in low-resource settings. This paper introduces Prompt-Guided\nIn-Context Learning, a novel approach that leverages the in-context learning\ncapabilities of Large Language Models (LLMs) for few-shot conversational query\nrewriting. Our method employs carefully designed prompts, incorporating task\ndescriptions, input\/output format specifications, and a small set of\nillustrative examples, to guide pre-trained LLMs to generate\ncontext-independent queries without explicit fine-tuning. Extensive experiments\non benchmark datasets, TREC and Taskmaster-1, demonstrate that our approach\nsignificantly outperforms strong baselines, including supervised models and\ncontrastive co-training methods, across various evaluation metrics such as\nBLEU, ROUGE-L, Success Rate, and MRR. Ablation studies confirm the importance\nof in-context examples, and human evaluations further validate the superior\nfluency, relevance, and context utilization of our generated rewrites. The\nresults highlight the potential of prompt-guided in-context learning as an\nefficient and effective paradigm for low-resource conversational query\nrewriting, reducing the reliance on extensive labeled data and complex training\nprocedures."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07723"
    ],
    "c_title":[
      "Total acoustic transmission between fluids using a solid material with\n  emphasis on the air-water interface"
    ],
    "c_abstract":[
      "Total acoustic transmission between water and air is modeled using a purely\nsolid interface comprising two elastic plates separated by periodically spaced\nribs. The frequency of full transmission depends only on, and is inversely\nproportional to, the areal density of the plate facing the air. Total\ntransmission also requires a specific dependence of the rib spacing on the\nbending stiffness of the two plates. These relations are the result of an\nexplicit analytical solution for the transmitted and reflected acoustic waves\ncombined with asymptotic approximations based on the small parameter defined by\nthe air-to-water impedance ratio. Surprisingly, the total transmission effect\nis almost independent of the angle of incidence, even though the transmission\nconditions are predicated on normal incidence. Parametric studies are performed\nto examine the effect on the frequency bandwidth and Q-factor of the acoustic\ntransmissivity. A lower bound for the Q-factor of $30.6$ is simply related to\nthe water-air impedance ratio."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-694",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08064"
    ],
    "b_title":[
      "Continual Learning for Multiple Modalities"
    ],
    "b_abstract":[
      "Continual learning aims to learn knowledge of tasks observed in sequential\ntime steps while mitigating the forgetting of previously learned knowledge.\nExisting methods were proposed under the assumption of learning a single\nmodality (e.g., image) over time, which limits their applicability in scenarios\ninvolving multiple modalities. In this work, we propose a novel continual\nlearning framework that accommodates multiple modalities (image, video, audio,\ndepth, and text). We train a model to align various modalities with text,\nleveraging its rich semantic information. However, this increases the risk of\nforgetting previously learned knowledge, exacerbated by the differing input\ntraits of each task. To alleviate the overwriting of the previous knowledge of\nmodalities, we propose a method for aggregating knowledge within and across\nmodalities. The aggregated knowledge is obtained by assimilating new\ninformation through self-regularization within each modality and associating\nknowledge between modalities by prioritizing contributions from relevant\nmodalities. Furthermore, we propose a strategy that re-aligns the embeddings of\nmodalities to resolve biased alignment between modalities. We evaluate the\nproposed method in a wide range of continual learning scenarios using multiple\ndatasets with different modalities. Extensive experiments demonstrate that ours\noutperforms existing methods in the scenarios, regardless of whether the\nidentity of the modality is given."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08154"
    ],
    "c_title":[
      "Artificial and Eddy Viscosity in Large Eddy Simulation Part 1: Temporal\n  and Spatial Schemes"
    ],
    "c_abstract":[
      "We propose a novel method to quantify artificial dissipation in large eddy\nsimulation. Here, artificial dissipation is defined as the residual of the\ndiscrete turbulent kinetic energy (TKE) equation. This method is applied to\nturbulent channel flow at Reynolds number 180 and 550 using a\nminimum-dissipation model within the OpenFOAM framework, employing both\nsymmetry-preserving and standard OpenFOAM discretizations. Our analysis reveals\nthat artificial viscosity can both produce and dissipate TKE. To quantify the\ninteraction between sub-grid-scale model contributions and numerical error, we\nintroduce viscous activity parameters, which also allow for evaluating the\nbalance between molecular and non-molecular viscosity. Examining temporal\ndiscretization schemes, we find that all methods can deliver accurate flow\npredictions if an appropriate time step is used. For very small time steps,\nForward-Euler is more efficient and accurate than Crank-Nicolson, though a\nbetter balance of accuracy and computational efficiency for larger time steps,\nmaking it preferable for large-scale applications. On collocated meshes, Van\nKan's pressure correction method predicts better results than Chorin's. Our\nspatial discretization study shows that the symmetry-preserving scheme\noutperforms standard OpenFOAM schemes, as excessive artificial errors from\nspatial discretization can suppress the LES model. For the symmetry-preserving\nscheme, both eddy and artificial viscosities vary similarly, with eddy\nviscosity being dominant. The role of artificial viscosity changes with mesh\nrefinement: on coarse meshes, it mainly dissipates TKE, while on finer meshes,\nit can produce TKE, counteracting eddy viscosity. The most accurate Reynolds\nshear stress predictions occur when non-molecular dissipation is nearly zero.\nFor accurate mean flow kinetic energy, larger non-molecular dissipation is\nneeded on finer meshes."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-695",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19538"
    ],
    "b_title":[
      "Multi-Language Probabilistic Programming"
    ],
    "b_abstract":[
      "There are many different probabilistic programming languages that are\nspecialized to specific kinds of probabilistic programs. From a usability and\nscalability perspective, this is undesirable: today, probabilistic programmers\nare forced up-front to decide which language they want to use and cannot\nmix-and-match different languages for handling heterogeneous programs. To\nrectify this, we seek a foundation for sound interoperability for probabilistic\nprogramming languages: just as today's Python programmers can resort to\nlow-level C programming for performance, we argue that probabilistic\nprogrammers should be able to freely mix different languages for meeting the\ndemands of heterogeneous probabilistic programming environments. As a first\nstep towards this goal, we introduce \\textsc{MultiPPL}, a probabilistic\nmulti-language that enables programmers to interoperate between two different\nprobabilistic programming languages: one that leverages a high-performance\nexact discrete inference strategy, and one that uses approximate importance\nsampling. We give a syntax and semantics for \\textsc{MultiPPL}, prove soundness\nof its inference algorithm, and provide empirical evidence that it enables\nprogrammers to perform inference on complex heterogeneous probabilistic\nprograms and flexibly exploits the strengths and weaknesses of two languages\nsimultaneously.%"
    ],
    "b_categories":[
      [
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08899"
    ],
    "c_title":[
      "Controlled Shifts of X-ray Emission Lines Measured with Transition Edge\n  Sensors at the Advanced Photon Source"
    ],
    "c_abstract":[
      "The measurement of shifts in the energy of X-ray emission lines is important\nfor understanding the electronic structure and physical properties of\nmaterials. In this study, we demonstrate a method using a synchrotron source to\nintroduce controlled eV-scale shifts of a narrow line in between fixed-energy\nfluorescence lines. We use this to characterize the ability of a hard X-ray\nsuperconducting Transition Edge Sensor (TES) array to measure line shifts.\nFixed fluorescence lines excited by higher harmonics of the monochromatic X-ray\nbeam are used for online energy calibration, while elastic scattering from the\nprimary harmonic acts as the variable energy emission line under study. We use\nthis method to demonstrate the ability to track shifts in the energy of the\nelastic scattering line of magnitude smaller than the TES energy resolution,\nand find we are ultimately limited by our calibration procedure. The method can\nbe applied over a wide X-ray energy range and provides a robust approach for\nthe characterization of the ability of high-resolution detectors to detect\nX-ray emission line shifts, and the quantitative comparison of energy\ncalibration procedures."
    ],
    "c_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-696",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05246"
    ],
    "b_title":[
      "Domain-Incremental Semantic Segmentation for Autonomous Driving under\n  Adverse Driving Conditions"
    ],
    "b_abstract":[
      "Semantic segmentation for autonomous driving is an even more challenging task\nwhen faced with adverse driving conditions. Standard models trained on data\nrecorded under ideal conditions show a deteriorated performance in unfavorable\nweather or illumination conditions. Fine-tuning on the new task or condition\nwould lead to overwriting the previously learned information resulting in\ncatastrophic forgetting. Adapting to the new conditions through traditional\ndomain adaption methods improves the performance on the target domain at the\nexpense of the source domain. Addressing these issues, we propose an\narchitecture-based domain-incremental learning approach called Progressive\nSemantic Segmentation (PSS). PSS is a task-agnostic, dynamically growing\ncollection of domain-specific segmentation models. The task of inferring the\ndomain and subsequently selecting the appropriate module for segmentation is\ncarried out using a collection of convolutional autoencoders. We extensively\nevaluate our proposed approach using several datasets at varying levels of\ngranularity in the categorization of adverse driving conditions. Furthermore,\nwe demonstrate the generalization of the proposed approach to similar and\nunseen domains."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14839"
    ],
    "c_title":[
      "Bayesian hierarchical non-stationary hybrid modeling for threshold\n  estimation in peak over threshold approach"
    ],
    "c_abstract":[
      "Extreme value theory (EVT) has been utilized to estimate crash risk from\ntraffic conflicts with the peak over threshold approach. However, it's\nchallenging to determine a suitable threshold to distinguish extreme conflicts\nin an objective way. The subjective and arbitrary selection of the threshold in\nthe peak over threshold approach can result in biased estimation outcomes. This\nstudy proposes a Bayesian hierarchical hybrid modeling (BHHM) framework for the\nthreshold estimation in the peak over threshold approach. Specifically, BHHM is\nbased on a piecewise function to model the general conflicts with specific\ndistribution while model the extreme conflicts with generalized Pareto\ndistribution (GPD). The Bayesian hierarchical structure is used to combine\ntraffic conflicts from different sites, incorporating covariates and\nsite-specific unobserved heterogeneity. Five non-stationary BHHM models,\nincluding Normal-GPD, Cauchy-GPD, Logistic-GPD, Gamma-GPD, and Lognormal-GPD\nmodels, were developed and compared. Traditional graphical diagnostic and\nquantile regression approaches were also used for comparison. Traffic conflicts\ncollected from three signalized intersections in the city of Surrey, British\nColumbia were used for the study. The results show that the proposed BHHM\napproach could estimate the threshold parameter objectively. The Lognormal-GPD\nmodel is superior to the other four BHHM models in terms of crash estimation\naccuracy and model fit. The crash estimates using the threshold determined by\nthe BHHM outperform those estimated based on the graphical diagnostic and\nquantile regression approaches, indicating the superiority of the proposed\nthreshold determination approach. The findings of this study contribute to\nenhancing the existing EVT methods for providing a threshold determination\napproach as well as producing reliable crash estimations."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-697",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04041"
    ],
    "b_title":[
      "A stabilized finite element method for steady Darcy-Brinkman-Forchheimer\n  flow model with different viscous and inertial resistances in porous media"
    ],
    "b_abstract":[
      "We implement a stabilized finite element method for steady\nDarcy-Brinkman-Forchheimer model within the continuous Galerkin framework. The\nnonlinear fluid model is first linearized using a standard \\textit{Newton's\nmethod. The sequence of linear problems is then discretized utilizing a stable\n\\textit{inf-sup} type continuous finite elements based on the\n\\textit{Taylor-Hood} pair to approximate the primary variables: velocity and\npressure}. Such a pair is known to be optimal for the approximation of the\nisotropic Navier-Stokes equation. To overcome the well-known numerical\ninstability in the convection-dominated problems, the Grad-Div stabilization is\nemployed with an efficient \\textit{augmented Lagrangian-type} penalty method.\nWe use the penalty term to develop the \\textit{block Schur complement}\npreconditioner, which is later coupled with a Krylov-space-based iterative\nlinear solver. In addition, the Kelly error estimator for the adaptive mesh\nrefinement is employed to achieve better numerical results with less\ncomputational cost. Performance of the proposed algorithm is verified for a\nclassical benchmark problem. Particularly for the Forchheimer parameter, we\npresent some interesting flow patterns with the velocity components and their\nstreamlines along the mid-lines in the computational domain. The role of the\nForchheimer term is highlighted for different porous medium scenarios. This\nstudy can offer an attractive setting for discretizing many multi-physics\nproblems along with the fluid flow having inertial effects in porous media."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.14479"
    ],
    "c_title":[
      "Modelling the term-structure of default risk under IFRS 9 within a\n  multistate regression framework"
    ],
    "c_abstract":[
      "The lifetime behaviour of loans is notoriously difficult to model, which can\ncompromise a bank's financial reserves against future losses, if modelled\npoorly. Therefore, we present a data-driven comparative study amongst three\ntechniques in modelling a series of default risk estimates over the lifetime of\neach loan, i.e., its term-structure. The behaviour of loans can be described\nusing a nonstationary and time-dependent semi-Markov model, though we model its\nelements using a multistate regression-based approach. As such, the transition\nprobabilities are explicitly modelled as a function of a rich set of input\nvariables, including macroeconomic and loan-level inputs. Our modelling\ntechniques are deliberately chosen in ascending order of complexity: 1) a\nMarkov chain; 2) beta regression; and 3) multinomial logistic regression. Using\nresidential mortgage data, our results show that each successive model\noutperforms the previous, likely as a result of greater sophistication. This\nfinding required devising a novel suite of simple model diagnostics, which can\nitself be reused in assessing sampling representativeness and the performance\nof other modelling techniques. These contributions surely advance the current\npractice within banking when conducting multistate modelling. Consequently, we\nbelieve that the estimation of loss reserves will be more timeous and accurate\nunder IFRS 9."
    ],
    "c_categories":[
      [
        "q-fin.RM",
        "q-fin.ST",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-698",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16500"
    ],
    "b_title":[
      "The Impact of VR and 2D Interfaces on Human Feedback in Preference-Based\n  Robot Learning"
    ],
    "b_abstract":[
      "Aligning robot navigation with human preferences is essential for ensuring\ncomfortable and predictable robot movement in shared spaces, facilitating\nseamless human-robot coexistence. While preference-based learning methods, such\nas reinforcement learning from human feedback (RLHF), enable this alignment,\nthe choice of the preference collection interface may influence the process.\nTraditional 2D interfaces provide structured views but lack spatial depth,\nwhereas immersive VR offers richer perception, potentially affecting preference\narticulation. This study systematically examines how the interface modality\nimpacts human preference collection and navigation policy alignment. We\nintroduce a novel dataset of 2,325 human preference queries collected through\nboth VR and 2D interfaces, revealing significant differences in user\nexperience, preference consistency, and policy outcomes. Our findings highlight\nthe trade-offs between immersion, perception, and preference reliability,\nemphasizing the importance of interface selection in preference-based robot\nlearning. The dataset will be publicly released to support future research."
    ],
    "b_categories":[
      [
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18075"
    ],
    "c_title":[
      "Orbital Fulde-Ferrell State versus Orbital Larkin-Ovchinnikov State"
    ],
    "c_abstract":[
      "Orbital Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) states are analyzed within\nmean-field theory, where orbital FF state is layer-polarized with inversion\nsymmetry broken, while orbital LO state is Josephson vortex array with\ntranslation symmetry reduced. Phase diagrams of orbital FFLO states are\nobtained, and properties such as induced orders, superconducting diode effects,\nFraunhofer pattern and topological defects are studied for the probe of FF\nversus LO states."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-699",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13846"
    ],
    "b_title":[
      "Identifying and Mitigating Machine Learning Biases for the\n  Gravitational-wave Detection Problem"
    ],
    "b_abstract":[
      "Matched-filtering is a long-standing technique for the optimal detection of\nknown signals in stationary Gaussian noise. However, it has known departures\nfrom optimality when operating on unknown signals in real noise and suffers\nfrom computational inefficiencies in its pursuit to near-optimality. A\ncompelling alternative that has emerged in recent years to address this problem\nis deep learning. Although it has shown significant promise when applied to the\nsearch for gravitational-waves in detector noise, we demonstrate the existence\nof a multitude of learning biases that hinder generalisation and detection\nperformance. Our work identifies the sources of a set of 11 interconnected\nbiases present in the supervised learning of the gravitational-wave detection\nproblem, and contributes mitigation tactics and training strategies to\nconcurrently address them. We introduce, Sage, a machine-learning based binary\nblack hole search pipeline. We evaluate our pipeline on the injection study\npresented in the Machine Learning Gravitational-Wave Search Challenge and show\nthat Sage detects ~11.2% more signals than the benchmark PyCBC analysis at a\nfalse alarm rate of one per month in O3a noise. Moreover, we also show that it\ncan detect ~48.29% more signals than the previous best performing\nmachine-learning pipeline on the same dataset. We empirically prove that our\npipeline has the capability to effectively handle out-of-distribution noise\npower spectral densities and reject non-Gaussian transient noise artefacts. By\nstudying machine-learning biases and conducting empirical investigations to\nunderstand the reasons for performance improvement\/degradation, we aim to\naddress the need for interpretability of machine-learning methods for\ngravitational-wave detection. All code and implementations are available at\nhttps:\/\/github.com\/nnarenraju\/sage."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10295"
    ],
    "c_title":[
      "On the $k$-linkage problem for generalizations of semicomplete digraphs"
    ],
    "c_abstract":[
      "A directed graph (digraph) $ D $ is $ k $-linked if $ |D| \\geq 2k $, and for\nany $ 2k $ distinct vertices $ x_1, \\ldots, x_k, y_1, \\ldots, y_k $ of $ D $,\nthere exist vertex-disjoint paths $ P_1, \\ldots, P_k $ such that $ P_i $ is a\npath from $ x_i $ to $ y_i $ for each $ i \\in [k] $. In 1980, Thomassen\nconjectured that there exists a function $ f(k) $ such that every $ f(k)\n$-strong digraph is $ k $-linked. He later disproved this conjecture by showing\nthat $ f(2) $ does not exist for general digraphs and proved that the function\n$f(k)$ exists for the class of tournaments. In this paper we consider a large\nclass $\\mathcal{ D} $ of digraphs which includes all semicomplete digraphs\n(digraphs with no pair of non-adjacent vertices) and all quasi-transitive\ndigraphs (a digraph $D$ is quasi-transitive if for any three vertices $x, y, z$\nof $D$, whenever $xy$ and $yz$ are arcs, then $x$ and $z$ are adjacent). We\nprove that every $ 3k $-strong digraph $D\\in \\mathcal{D}$ with minimum\nout-degree at least $ 23k $ is $ k $-linked. A digraph $D$ is\n$l$-quasi-transitive if whenever there is a path of length $l$ between vertices\n$u$ and $v$ in $D$ the vertices $u$ and $v$ are adjacent. Hence\n2-quasi-transitive digraphs are exactly the quasi-transitive digraphs. We prove\nthat there is a function $f(k,l)$ so that every $f(k,l)$-strong\n$l$-quasi-transitive digraph is $k$-linked. The main new tool in our proofs\nsignificantly strengthens an important property of vertices with maximum\nin-degree in a tournament. While Landau in 1953 already proved that such a\nvertex $v$ is reachable by all other vertices by paths of length at most 2, we\nshow that, in fact, the structure of these paths is much richer. In general\nthere are many such paths for almost all out-neighbours of $v$ and this\nproperty is crucial in our proofs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-700",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19303"
    ],
    "b_title":[
      "Operando XPS in Reactive Plasmas: The Importance of The Wall Reactions"
    ],
    "b_abstract":[
      "Advancements in differential pumping and electron optics over the past few\ndecades have enabled x-ray photoelectron spectroscopy (XPS) measurements at\n(near-)ambient pressures, bridging the pressure gap for characterizing\nrealistic sample chemistries. Recently, we demonstrated the capabilities of an\nambient pressure XPS (APXPS) setup for in-situ plasma environment measurements,\nallowing plasma-surface interactions to be studied in operando rather than\nusing the traditional before-and-after analysis approach. This new plasma-XPS\ntechnique facilitates the identification of reaction intermediates critical for\nunderstanding plasma-assisted surface processes relevant to semiconductor\nnanomanufacturing, such as physical vapor deposition, etching, atomic layer\ndeposition, etc. In this report, we apply the plasma-XPS approach to monitor\nreal-time surface chemical changes on a model Ag(111) single crystal exposed to\noxidizing and reducing plasmas. We correlate surface-sensitive data with\nconcurrent gas-phase XPS measurements and residual gas mass-spectra analysis of\nspecies generated during plasma exposure, highlighting the significant role of\nplasma-induced chamber wall reactions. Ultimately, we demonstrate that\nplasma-XPS provides comprehensive insights into both surface and gas-phase\nchemistry, establishing it as a versatile and dynamic characterization tool\nwith broad applications in microelectronics research."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.09162"
    ],
    "c_title":[
      "Experimental Analysis of a Self-Coherent M-QAM Receiver by Means of\n  Recurrent Optical Spectrum Slicing and Direct Detection"
    ],
    "c_abstract":[
      "High order modulation formats constitute the most prominent way for\nincreasing spectral efficiency in transmission systems. Coherent transceivers\nthat support such higher order formats require heavy digital signal processing\n(DSP), which increases the power consumption of coherent pluggables, well above\nthe intensity modulation and direct detection (IM\/DD) counterparts.\nSelf-coherent or phase retrieval methods have emerged as potential solutions,\ntrying to combine the merits of coherent technology with the simplicity of\ndirect detection. In this work, we experimentally demonstrate the reception of\nquadrature amplitude modulation (QAM) modulation formats based on direct\ndetection aided by the recurrent optical spectrum slicing (ROSS) photonic\naccelerator, utilizing minimal DSP and low modulator driving voltages. We\nexperimentally demonstrate 32 Gbaud QAM-4\/16 for 25 km, 50 km and 75 km in the\nC-band aided by a linear digital equalization and the use of programmable\nphotonics as recurrent optical spectrum slicers. We showcase successful\ndetection with driving swings below V{\\pi}\/3 in contrast to the full swing\nrequired by conventional coherent transceivers. We further improve the system\nperformance utilizing geometric constellation shaping. Finally, we explore the\npotential power consumption improvement for the next-generation 1.6T\npluggables, showcasing over 40% reduction with respect to the most lightweight\nstate of the art coherent solutions reported in literature"
    ],
    "c_categories":[
      [
        "cs.NI",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-701",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11036"
    ],
    "b_title":[
      "Bimeron Crystals by a Linearly Polarized AC Electric Field in Frustrated\n  Magnets"
    ],
    "b_abstract":[
      "We theoretically propose a method to generate topological spin textures by\nirradiating a classical spin system with a linearly polarized AC electric\nfield. To this end, we investigate non-equilibrium steady states in a classical\nHeisenberg model with frustrated exchange interactions on a two-dimensional\ntriangular lattice by numerically solving the Landau-Lifshitz-Gilbert equation\nat zero temperature. Our results reveal that the linearly polarized AC\nelectric-field irradiation induces a topological phase transition from a\nsingle-Q spiral state to a bimeron crystal with the skyrmion number of one in\nthe low-frequency regime. Furthermore, we show that the obtained bimeron\ncrystal remains relatively stable against both easy-axis and easy-plane\nsingle-ion anisotropies."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.14827"
    ],
    "c_title":[
      "MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation\n  Models"
    ],
    "c_abstract":[
      "Multimodal foundation models (MMFMs) play a crucial role in various\napplications, including autonomous driving, healthcare, and virtual assistants.\nHowever, several studies have revealed vulnerabilities in these models, such as\ngenerating unsafe content by text-to-image models. Existing benchmarks on\nmultimodal models either predominantly assess the helpfulness of these models,\nor only focus on limited perspectives such as fairness and privacy. In this\npaper, we present the first unified platform, MMDT (Multimodal DecodingTrust),\ndesigned to provide a comprehensive safety and trustworthiness evaluation for\nMMFMs. Our platform assesses models from multiple perspectives, including\nsafety, hallucination, fairness\/bias, privacy, adversarial robustness, and\nout-of-distribution (OOD) generalization. We have designed various evaluation\nscenarios and red teaming algorithms under different tasks for each perspective\nto generate challenging data, forming a high-quality benchmark. We evaluate a\nrange of multimodal models using MMDT, and our findings reveal a series of\nvulnerabilities and areas for improvement across these perspectives. This work\nintroduces the first comprehensive and unique safety and trustworthiness\nevaluation platform for MMFMs, paving the way for developing safer and more\nreliable MMFMs and systems. Our platform and benchmark are available at\nhttps:\/\/mmdecodingtrust.github.io\/."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-702",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00133"
    ],
    "b_title":[
      "Exploring Transfer Learning for Deep Learning Polyp Detection in\n  Colonoscopy Images Using YOLOv8"
    ],
    "b_abstract":[
      "Deep learning methods have demonstrated strong performance in objection\ntasks; however, their ability to learn domain-specific applications with\nlimited training data remains a significant challenge. Transfer learning\ntechniques address this issue by leveraging knowledge from pre-training on\nrelated datasets, enabling faster and more efficient learning for new tasks.\nFinding the right dataset for pre-training can play a critical role in\ndetermining the success of transfer learning and overall model performance. In\nthis paper, we investigate the impact of pre-training a YOLOv8n model on seven\ndistinct datasets, evaluating their effectiveness when transferred to the task\nof polyp detection. We compare whether large, general-purpose datasets with\ndiverse objects outperform niche datasets with characteristics similar to\npolyps. In addition, we assess the influence of the size of the dataset on the\nefficacy of transfer learning. Experiments on the polyp datasets show that\nmodels pre-trained on relevant datasets consistently outperform those trained\nfrom scratch, highlighting the benefit of pre-training on datasets with shared\ndomain-specific features."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15075"
    ],
    "c_title":[
      "Abelian and monopole dominance in SU(3) gluodynamics and Gribov copy\n  effects"
    ],
    "c_abstract":[
      "We continue our study of the Gribov copies effrcts in the Maximal Abelian\ngauge in lattice $SU(3)$ gluodynamics. Our computations were completed for four\nvalues of the lattice spacing with physical lattice size $L \\approx 2$ fm. It\nis demonstrated that when one uses the effective simulated annealing algorithm\nto fix the gauge the obtained Gribov copies produce low abelian string tension\nwhich is below 90% of the physical value independent of the lattice spacing.\nThese Gribov copies produce also low value (about 86%) for the monopole string\ntension. It is further shown that in case of less effective relaxation\nalgorithm it is possible to obtain Gribov copies which produce both Abelian and\nmonopole string tension in good agreement with the physical one."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-703",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04472"
    ],
    "b_title":[
      "Challenges and Opportunities for time-delay cosmography with\n  multi-messenger gravitational lensing"
    ],
    "b_abstract":[
      "Strong gravitational lensing of variable sources, such as quasars or\nsupernovae, can be used to constrain cosmological parameters through a\ntechnique known as \"time-delay cosmography''. Competitive constraints on the\nHubble constant have been achieved with electromagnetic observations of lensed\nquasars and lensed supernovae. Gravitational wave (GW) astronomy may open up a\nnew channel for time-delay cosmography with GW signal replacing the\nelectromagnetic (EM) one. We highlight the similarities of using GW signals to\nbe applied to time-delay cosmography compared to EM signal. We then discuss key\ndifferences between GW and EM signals and their resulting advantages and\ninconveniences from the angle of the current state-of-the-art using quasars and\nlensed supernovae for time-delay cosmography. We identify the astrometric\nprecision requirement of the images as a key challenge to overcome and\nhighlight the potentially significant impact that near-perfect time-delay\nmeasurements of lensed GWs can bring to the table."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.09271"
    ],
    "c_title":[
      "LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via\n  Subgraph Injection"
    ],
    "c_abstract":[
      "Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in\nmodeling data with graph structures, yet recent research reveals their\nsusceptibility to adversarial attacks. Traditional attack methodologies, which\nrely on manipulating the original graph or adding links to artificially created\nnodes, often prove impractical in real-world settings. This paper introduces a\nnovel adversarial scenario involving the injection of an isolated subgraph to\ndeceive both the link recommender and the node classifier within a GNN system.\nSpecifically, the link recommender is mislead to propose links between targeted\nvictim nodes and the subgraph, encouraging users to unintentionally establish\nconnections and that would degrade the node classification accuracy, thereby\nfacilitating a successful attack. To address this, we present the LiSA\nframework, which employs a dual surrogate model and bi-level optimization to\nsimultaneously meet two adversarial objectives. Extensive experiments on\nreal-world datasets demonstrate the effectiveness of our method."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-704",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04390"
    ],
    "b_title":[
      "In Praise of Stubbornness: The Case for Cognitive-Dissonance-Aware\n  Knowledge Updates in LLMs"
    ],
    "b_abstract":[
      "Despite remarkable capabilities, large language models (LLMs) struggle to\ncontinually update their knowledge without catastrophic forgetting. In\ncontrast, humans effortlessly integrate new information, detect conflicts with\nexisting beliefs, and selectively update their mental models. This paper\nintroduces a cognitive-inspired investigation paradigm to study continual\nknowledge updating in LLMs. We implement two key components inspired by human\ncognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior\nto classify information as novel, familiar, or dissonant; and (2) Targeted\nNetwork Updates, which track neural activity to identify frequently used\n(stubborn) and rarely used (plastic) neurons. Through carefully designed\nexperiments in controlled settings, we uncover a number of empirical findings\ndemonstrating the potential of this approach. First, dissonance detection is\nfeasible using simple activation and gradient features, suggesting potential\nfor cognitive-inspired training. Second, we find that non-dissonant updates\nlargely preserve prior knowledge regardless of targeting strategy, revealing\ninherent robustness in LLM knowledge integration. Most critically, we discover\nthat dissonant updates prove catastrophically destructive to the model's\nknowledge base, indiscriminately affecting even information unrelated to the\ncurrent updates. This suggests fundamental limitations in how neural networks\nhandle contradictions and motivates the need for new approaches to knowledge\nupdating that better mirror human cognitive mechanisms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19027"
    ],
    "c_title":[
      "Plebanski complex"
    ],
    "c_abstract":[
      "As is very well-known, linearisation of the instanton equations on a\n4-manifold gives rise to an elliptic complex of differential operators, the\ntruncated (twisted) Hodge complex $\\Lambda^0(\\mathfrak{g}) \\to\n\\Lambda^1(\\mathfrak{g})\\to \\Lambda^2_+(\\mathfrak{g})$. Moreover, the\nlinearisation of the full YM equations also fits into this framework, as it is\ngiven by the second map followed by its adjoint. We define and study properties\nof what we call the Pleba\\'nski complex. This is a differential complex that\narises by linearisation of the equations implying that a Riemannian 4-manifold\nis hyper-K\\\"ahler. We recall that these are most naturally stated as the\ncondition that there exists a perfect $\\Sigma^i\\wedge \\Sigma^j\\sim\\delta^{ij}$\ntriple $\\Sigma^i, i=1,2,3$ of 2-forms that are closed $d\\Sigma^i=0$. The\nRiemannian metric is encoded by the 2-forms $\\Sigma^i$. We show that what\nresults is an elliptic differential complex $TM \\to S\\to E\\times \\Lambda^1 \\to\nE$, where $S$ is the tangent space to the space of perfect triples, and\n$E=\\mathbb{R}^3$. We also show that, as in the case with instanton equations,\nthe full Einstein equations $Ric=0$ also fit into this framework, their\nlinearisation being given by the second map followed by its adjoint. Our second\nresult concerns the elliptic operator that the Pleba\\'nski complex defines. In\nthe case of the instanton complex, operators appearing in the complex\nsupplemented with their adjoints assemble to give the Dirac operator. We show\nhow the same holds true for the Pleba\\'nski complex. Supplemented by suitable\nadjoints, operators assemble into an elliptic operator that squares to the\nLaplacian and is given by the direct sum of two Dirac operators."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-705",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01815"
    ],
    "b_title":[
      "Tautological characteristic classes III: the Witt class for PSL(2)"
    ],
    "b_abstract":[
      "We explain the relation between the Witt class and the universal\nequicommutative class for PSL(2,K). We discuss an analogue of the Milnor-Wood\ninequality."
    ],
    "b_categories":[
      [
        "math.GR",
        "math.KT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.01346"
    ],
    "c_title":[
      "Effect of Al2O3 on the operation of SiNX-based MIS RRAMs"
    ],
    "c_abstract":[
      "The role of a 3 nm Al2O3 layer on top of stoichiometric LPCVD SiNx MIS RRAM\ncells is investigated by using various electrical characterization techniques.\nThe conductive filament formation is explained, and a compact model is used to\nfit the current voltage curves and find its evolution during each operation\ncycle. The conduction in SiNx is also studied."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-706",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03500"
    ],
    "b_title":[
      "Efficient Image Restoration via Latent Consistency Flow Matching"
    ],
    "b_abstract":[
      "Recent advances in generative image restoration (IR) have demonstrated\nimpressive results. However, these methods are hindered by their substantial\nsize and computational demands, rendering them unsuitable for deployment on\nedge devices. This work introduces ELIR, an Efficient Latent Image Restoration\nmethod. ELIR operates in latent space by first predicting the latent\nrepresentation of the minimum mean square error (MMSE) estimator and then\ntransporting this estimate to high-quality images using a latent consistency\nflow-based model. Consequently, ELIR is more than 4x faster compared to the\nstate-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also\nmore than 4x smaller, making it well-suited for deployment on\nresource-constrained edge devices. Comprehensive evaluations of various image\nrestoration tasks show that ELIR achieves competitive results, effectively\nbalancing distortion and perceptual quality metrics while offering improved\nefficiency in terms of memory and computation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "eess.IV",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12768"
    ],
    "c_title":[
      "A Bayesian Modelling Framework with Model Comparison for Epidemics with\n  Super-Spreading"
    ],
    "c_abstract":[
      "The transmission dynamics of an epidemic are rarely homogeneous.\nSuper-spreading events and super-spreading individuals are two types of\nheterogeneous transmissibility. Inference of super-spreading is commonly\ncarried out on secondary case data, the expected distribution of which is known\nas the offspring distribution. However, this data is seldom available. Here we\nintroduce a multi-model framework fit to incidence time-series, data that is\nmuch more readily available. The framework consists of five discrete-time,\nstochastic, branching-process models of epidemics spread through a susceptible\npopulation. The framework includes a baseline model of homogeneous\ntransmission, a unimodal and a bimodal model for super-spreading events, as\nwell as a unimodal and a bimodal model for super-spreading individuals.\nBayesian statistics is used to infer model parameters using Markov Chain\nMonte-Carlo. Model comparison is conducted by computing Bayes factors, with\nimportance sampling used to estimate the marginal likelihood of each model.\nThis estimator is selected for its consistency and lower variance compared to\nalternatives. Application to simulated data from each model identifies the\ncorrect model for the majority of simulations and accurately infers the true\nparameters, such as the basic reproduction number. We also apply our methods to\nincidence data from the 2003 SARS outbreak and the Covid-19 pandemic. Model\nselection consistently identifies the same model and mechanism for a given\ndisease, even when using different time series. Our estimates are consistent\nwith previous studies based on secondary case data. Quantifying the\ncontribution of super-spreading to disease transmission has important\nimplications for infectious disease management and control. Our modelling\nframework is disease-agnostic and implemented as an R package, with potential\nto be a valuable tool for public health."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-707",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07037"
    ],
    "b_title":[
      "Liquid crystalline structures formed by sphere-rod amphiphilic molecules\n  in solvents"
    ],
    "b_abstract":[
      "Self-assembly of amphiphilic molecules is an important phenomenon attracting\na broad range of research. In this work, we study the self-assembly of KTOF4\nsphere-rod amphiphilic molecules in mixed water-dioxane solvents. The molecules\nare of a T-shaped geometry, comprised of a hydrophilic spherical Keggin-type\ncluster attached by a flexible bridge to the center of a hydrophobic rod-like\noligodialkylfluorene (OF), which consists of four OF units. Transmission\nelectron microscopy (TEM) uncovers self-assembled spherical structures of KTOF4\nin dilute solutions. These spheres are filled with smectic-like layers of KTOF4\nseparated by layers of the solution. There are two types of layer packings: (i)\nconcentric spheres and (ii) flat layers. The concentric spheres form when the\ndioxane volume fraction in the solution is 35-50 vol%. The flat layers are\nformed when the dioxane volume fraction is either below (20 and 30 vol%.) or\nabove (55 and 60 vol%.) the indicated range. The layered structures show no\nin-plane orientational order and thus resemble thermotropic smectic A liquid\ncrystals and their lyotropic analogs. The layered packings reveal edge and\nscrew dislocations. Evaporation of the solvent produces a bulk birefringent\nliquid crystal phase with textures resembling the ones of uniaxial nematic\nliquid crystals. These findings demonstrate that sphere-rod molecules produce a\nvariety of self-assembled structures that are controlled by the solvent\nproperties."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08298"
    ],
    "c_title":[
      "Q-Sets, \\Delta-Sets, and L-Spaces"
    ],
    "c_abstract":[
      "The question whether there is a Lindelof Q-set space or Lindelof $\\Delta$-set\nspace is considered. We show that J. Moore's ZFC $L$-space is not a Q-set space\nin ZFC and, assuming all Aronszajn trees are special, it is not a $\\Delta$-set\nspace."
    ],
    "c_categories":[
      [
        "math.GN"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-708",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14693"
    ],
    "b_title":[
      "I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree\n  Search"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have shown remarkable\npotential in automating machine learning tasks. However, existing LLM-based\nagents often struggle with low-diversity and suboptimal code generation. While\nrecent work has introduced Monte Carlo Tree Search (MCTS) to address these\nissues, limitations persist in the quality and diversity of thoughts generated,\nas well as in the scalar value feedback mechanisms used for node selection. In\nthis study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a\nnovel approach that iteratively expands tree nodes through an introspective\nprocess that meticulously analyzes solutions and results from parent and\nsibling nodes. This facilitates a continuous refinement of the node in the\nsearch tree, thereby enhancing the overall decision-making process.\nFurthermore, we integrate a Large Language Model (LLM)-based value model to\nfacilitate direct evaluation of each node's solution prior to conducting\ncomprehensive computational rollouts. A hybrid rewarding mechanism is\nimplemented to seamlessly transition the Q-value from LLM-estimated scores to\nactual performance scores. This allows higher-quality nodes to be traversed\nearlier. Applied to the various ML tasks, our approach demonstrates a 6%\nabsolute improvement in performance compared to the strong open-source AutoML\nagents, showcasing its effectiveness in enhancing agentic AutoML systems.\nResource available at https:\/\/github.com\/jokieleung\/I-MCTS"
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13291"
    ],
    "c_title":[
      "Contribution to the Radio Light Curves of a Core-Collapse Supernova due\n  to the Off-axis Gamma-Ray Burst Afterglow"
    ],
    "c_abstract":[
      "We present the first comprehensive theoretical predictions of radio emission\nfrom a Type Ic-BL supernova (SN) associated with a gamma-ray burst (GRB) jet.\nIt is naturally supposed that the expected radio light curve consists of two\ncomponents of emitting source: radio emission from a non-relativistic SN shock\nand afterglow emitted from the head of the relativistic GRB jet. We calculate\neach component of radio emission, placing an emphasis on surveying wide ranges\nof isotropic explosion energy and viewing angle in our GRB afterglow modeling.\nWe show that in particular parameter space, the composite radio light curve\nwould be characterized by a double-peaked shape. The condition for the clear\nappearance of the double-peaked radio light curve is either (1) the isotropic\nexplosion energy is small (low-luminosity GRB) or (2) the viewing angle is\nlarge (off-axis GRB). Our results highlight that follow-up radio observations\nconducted within a few years after the optical discovery of nearby Type Ic-BL\nsupernovae ($\\sim$100~Mpc) can serve as a unique diagnostic for off-axis GRBs\nundiscovered in Type IcBL SNe. This will be a step toward uncovering the nature\nof long GRB progenitors and clarifying their connection to Type IcBL SNe."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-709",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09425"
    ],
    "b_title":[
      "Quasianalytic algebras with weakly smooth germs generate o-minimal\n  structures"
    ],
    "b_abstract":[
      "In arXiv:1303.3724, the authors provide an axiomatic way of constructing new\npolynomially bounded o-minimal structures. However, all of the structures\nsatisfying these axioms must also have smooth cell-decomposition. In this\npaper, we generalize their approach by allowing weakly smooth germs into the\nconstruction. In particular, we showed in arXiv:2501.17583 that the o-minimal\nstructure constructed in [O. Le Gal, J.-P. Rolin. \"An o-minimal structure which\ndoes not admit $C^\\infty$ cellular decomposition\" Ann. Inst. Fourier 59 (2009),\npp 543-562] satisfies the assumptions of our theorem."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07509"
    ],
    "c_title":[
      "Interference-Aware Super-Constellation Design for NOMA"
    ],
    "c_abstract":[
      "Non-orthogonal multiple access (NOMA) has gained significant attention as a\npotential next-generation multiple access technique. However, its\nimplementation with finite-alphabet inputs faces challenges. Particularly, due\nto inter-user interference, superimposed constellations may have overlapping\nsymbols leading to high bit error rates when successive interference\ncancellation (SIC) is applied. To tackle the issue, this paper employs\nautoencoders to design interference-aware super-constellations. Unlike\nconventional methods where superimposed constellation may have overlapping\nsymbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design\nsuper-constellations with distinguishable symbols at receivers, regardless of\nchannel gains. The proposed architecture removes the need for SIC, allowing\nmaximum likelihood-based approaches to be used instead. The paper presents the\nconceptual architecture, loss functions, and training strategies for AE-NOMA.\nVarious test results are provided to demonstrate the effectiveness of\ninterference-aware constellations in improving the bit error rate, indicating\nthe adaptability of AE-NOMA to different channel scenarios and its promising\npotential for implementing NOMA systems"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-710",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10682"
    ],
    "b_title":[
      "Hybrid Deepfake Image Detection: A Comprehensive Dataset-Driven Approach\n  Integrating Convolutional and Attention Mechanisms with Frequency Domain\n  Features"
    ],
    "b_abstract":[
      "Effective deepfake detection tools are becoming increasingly essential over\nthe last few years due to the growing usage of deepfakes in unethical\npractices. There exists a diverse range of deepfake generation techniques,\nwhich makes it challenging to develop an accurate universal detection\nmechanism. The 2025 Signal Processing Cup (DFWild-Cup competition) provided a\ndiverse dataset of deepfake images, which are generated from multiple deepfake\nimage generators, for training machine learning model(s) to emphasize the\ngeneralization of deepfake detection. To this end, we proposed an\nensemble-based approach that employs three different neural network\narchitectures: a ResNet-34-based architecture, a data-efficient image\ntransformer (DeiT), and an XceptionNet with Wavelet Transform to capture both\nlocal and global features of deepfakes. We visualize the specific regions that\nthese models focus for classification using Grad-CAM, and empirically\ndemonstrate the effectiveness of these models in grouping real and fake images\ninto cohesive clusters using t-SNE plots. Individually, the ResNet-34\narchitecture has achieved 88.9% accuracy, whereas the Xception network and the\nDeiT architecture have achieved 87.76% and 89.32% accuracy, respectively. With\nthese networks, our weighted ensemble model achieves an excellent accuracy of\n93.23% on the validation dataset of the SP Cup 2025 competition. Finally, the\nconfusion matrix and an Area Under the ROC curve of 97.44% further confirm the\nstability of our proposed method."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03318"
    ],
    "c_title":[
      "Electronic properties and transport in metal\/2D material\/metal vertical\n  junctions"
    ],
    "c_abstract":[
      "We simulate the electronic and transport properties of metal\/two-dimensional\nmaterial\/metal vertical heterostructures, with a focus on graphene, hexagonal\nboron nitride and two phases of molybdenum diselenide. Using density functional\ntheory and non-equilibrium Green's function, we assess how stacking\nconfigurations and material thickness impact important properties, such as\ndensity of states, potential barriers and conductivity. For monolayers, strong\norbital hybridization with the metallic electrodes significantly alters the\nelectronic characteristics, with the formation of states within the gap of the\nsemiconducting 2D materials. Trilayers reveal the critical role of interlayer\ncoupling, where the middle layer retains its intrinsic properties, thus\ninfluencing the overall conductivity. Our findings highlight the potential for\ncustomized multilayer designs to optimize electronic device performance based\non two-dimensional materials."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-711",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14187"
    ],
    "b_title":[
      "Non-convergence of the Navier-Stokes equations toward the Euler\n  equations in weak Besov spaces"
    ],
    "b_abstract":[
      "In this paper, we consider the inviscid limit problem to the higher\ndimensional incompressible Navier-Stokes equations in the whole space. It was\nproved in \\cite[J. Funct. Anal., 276 (2019)]{GZ} that given initial data\n$u_0\\in B^{s}_{p,r}$ with $1\\leq r<\\infty$, the solutions of the Navier-Stokes\nequations converge strongly in $B^{s}_{p,r}$ to the Euler equations as the\nviscosity parameter tends to zero. In the case when $r=\\infty$, we prove the\nfailure of the $B^{s}_{p,\\infty}$-convergence of the Navier-Stokes equations\ntoward the Euler equations in the inviscid limit."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.11537"
    ],
    "c_title":[
      "$\\text{M}^{\\text{3}}$: A Modular World Model over Streams of Tokens"
    ],
    "c_abstract":[
      "Token-based world models emerged as a promising modular framework, modeling\ndynamics over token streams while optimizing tokenization separately. While\nsuccessful in visual environments with discrete actions (e.g., Atari games),\ntheir broader applicability remains uncertain. In this paper, we introduce\n$\\text{M}^{\\text{3}}$, a $\\textbf{m}$odular $\\textbf{w}$orld $\\textbf{m}$odel\nthat extends this framework, enabling flexible combinations of observation and\naction modalities through independent modality-specific components.\n$\\text{M}^{\\text{3}}$ integrates several improvements from existing literature\nto enhance agent performance. Through extensive empirical evaluation across\ndiverse benchmarks, $\\text{M}^{\\text{3}}$ achieves state-of-the-art sample\nefficiency for planning-free world models. Notably, among these methods, it is\nthe first to reach a human-level median score on Atari 100K, with superhuman\nperformance on 13 games. Our code and model weights are publicly available at\nhttps:\/\/github.com\/leor-c\/M3."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-712",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14266"
    ],
    "b_title":[
      "Divisibility Relations Between Ring Homomorphisms and Surjective Group\n  Homomorphisms in Finite Cyclic Structures"
    ],
    "b_abstract":[
      "In this article, we delve into the intricate relationship between the number\nof ring homomorphisms and surjective group homomorphisms between two finite\ncyclic structures, specifically $\\mathbb{Z}_m$ and $\\mathbb{Z}_n$. We\ndemonstrate that the number of ring homomorphisms from $\\mathbb{Z}_m$ to\n$\\mathbb{Z}_n$ is a divisor of the number of surjective group homomorphisms\nfrom $\\mathbb{Z}_m$ to $\\mathbb{Z}_n$, provided that $n$ is not of the form $2\n\\cdot \\alpha$, where each prime factor $p$ of $\\alpha$ satisfies $p \\equiv 3\n\\pmod{4}$."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.01968"
    ],
    "c_title":[
      "Token Cleaning: Fine-Grained Data Selection for LLM Supervised\n  Fine-Tuning"
    ],
    "c_abstract":[
      "Recent studies show that in supervised fine-tuning (SFT) of large language\nmodels (LLMs), data quality matters more than quantity. While most data\ncleaning methods concentrate on filtering entire samples, the quality of\nindividual tokens within a sample can vary significantly. After pre-training,\neven in high-quality samples, patterns or phrases that are not task-related can\nbe redundant or uninformative. Continuing to fine-tune on these patterns may\noffer limited benefit and even degrade downstream task performance. In this\npaper, we investigate token quality from a noisy-label perspective and propose\na generic token cleaning pipeline for SFT tasks. Our method filters out\nuninformative tokens while preserving those carrying key task-specific\ninformation. Specifically, we first evaluate token quality by examining the\ninfluence of model updates on each token, then apply a threshold-based\nseparation. The token influence can be measured in a single pass with a fixed\nreference model or iteratively with self-evolving reference models. The\nbenefits and limitations of both methods are analyzed theoretically by error\nupper bounds. Extensive experiments show that our framework consistently\nimproves performance across multiple downstream tasks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-713",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18157"
    ],
    "b_title":[
      "Monitoring snow avalanches from SAR data with deep learning"
    ],
    "b_abstract":[
      "Snow avalanches present significant risks to human life and infrastructure,\nparticularly in mountainous regions, making effective monitoring crucial.\nTraditional monitoring methods, such as field observations, are limited by\naccessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture\nRadar (SAR) data has become an important tool for large-scale avalanche\ndetection, as it can capture data in all weather conditions and across remote\nareas. However, traditional processing methods struggle with the complexity and\nvariability of avalanches. This chapter reviews the application of deep\nlearning for detecting and segmenting snow avalanches from SAR data. Early\nefforts focused on the binary classification of SAR images, while recent\nadvances have enabled pixel-level segmentation, providing greater accuracy and\nspatial resolution. A case study using Sentinel-1 SAR data demonstrates the\neffectiveness of deep learning models for avalanche segmentation, achieving\nsuperior results over traditional methods. We also present an extension of this\nwork, testing recent state-of-the-art segmentation architectures on an expanded\ndataset of over 4,500 annotated SAR images. The best-performing model among\nthose tested was applied for large-scale avalanche detection across the whole\nof Norway, revealing important spatial and temporal patterns over several\nwinter seasons."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03375"
    ],
    "c_title":[
      "The dipolar Aleppo lattice: Ground state ordering and ergodic dynamics\n  in the absence of vertex frustration"
    ],
    "c_abstract":[
      "We introduce the Aleppo spin ice geometry, another variation of decimated\nsquare ice patterns, which in contrast to similar systems previously studied,\ndoes not exhibit vertex frustration. Using synchrotron-based photoemission\nelectron microscopy, we directly visualize low-energy states achieved after\nthermal annealing, in addition to temperature-dependent moment fluctuations.\nThe results reveal the observation of ground state patterns and the absence of\nergodicity-breaking dynamics. Our observations further confirm vertex\nfrustration to be an important criterion for the emergence of ergodicity\ntransitions."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-714",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09495"
    ],
    "b_title":[
      "Calibration of Solid State Nuclear Track Detectors for Rare Event\n  Searches"
    ],
    "b_abstract":[
      "The calibration of the CR39 and Makrofol Nuclear Track Detectors of the\nMoEDAL experiment at the CERN-LHC was performed by exposing stacks of detector\nfoils to heavy ion beams with energies ranging from 340 MeV\/nucleon to 150\nGeV\/nucleon. After chemical etching, the base areas and lengths of etch-pit\ncones were measured using automatic and manual optical microscopes. The\nresponse of the detectors, as measured by the ratio of the track-etching rate\nover the bulk-etching rate, was determined over a range extending from their\nthreshold at Z\/$\\beta\\sim7$ and $\\sim50$ for CR39 and Makrofol, respectively,\nup to Z\/$\\beta\\sim92$"
    ],
    "b_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.01057"
    ],
    "c_title":[
      "Sparse Randomized Approximation of Normal Cycles"
    ],
    "c_abstract":[
      "We develop a compression algorithm for the Normal-Cycles representations of\nshape, using the Nystrom approximation in Reproducing Kernel Hilbert Spaces and\nRidge Leverage Score sampling. Our method has theoretical guarantees on the\nrate of convergence of the compression error, and the obtained approximations\nare shown to be useful for down-line tasks such as nonlinear shape registration\nin the Large Deformation Metric Mapping (LDDMM) framework, even for very high\ncompression ratios. The performance of our algorithm is demonstrated on\nlarge-scale shape data from modern geometry processing datasets, and is shown\nto be fast and scalable with rapid error decay."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-715",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05880"
    ],
    "b_title":[
      "TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV\n  systems in Emergency Response Scenarios"
    ],
    "b_abstract":[
      "Designing efficient neural networks for embedded devices is a critical\nchallenge, particularly in applications requiring real-time performance, such\nas aerial imaging with drones and UAVs for emergency responses. In this work,\nwe introduce TakuNet, a novel light-weight architecture which employs\ntechniques such as depth-wise convolutions and an early downsampling stem to\nreduce computational complexity while maintaining high accuracy. It leverages\ndense connections for fast convergence during training and uses 16-bit\nfloating-point precision for optimization on embedded hardware accelerators.\nExperimental evaluation on two public datasets shows that TakuNet achieves\nnear-state-of-the-art accuracy in classifying aerial images of emergency\nsituations, despite its minimal parameter count. Real-world tests on embedded\ndevices, namely Jetson Orin Nano and Raspberry Pi, confirm TakuNet's\nefficiency, achieving more than 650 fps on the 15W Jetson board, making it\nsuitable for real-time AI processing on resource-constrained platforms and\nadvancing the applicability of drones in emergency scenarios. The code and\nimplementation details are publicly released."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.PF"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05897"
    ],
    "c_title":[
      "Revealing Actual Viscoelastic Relaxation Times in Capillary Breakup"
    ],
    "c_abstract":[
      "We use experiments and theory to elucidate the size effect in capillary\nbreakup rheometry, where pre-stretching in the visco-capillary stage causes the\napparent relaxation time to be consistently smaller than the actual value. We\npropose a method accounting for both the experimental size and the finite\nextensibility of polymers to extract the actual relaxation time. A phase\ndiagram characterizes the expected measurement variability and delineates\nscaling law conditions. The results refine capillary breakup rheometry for\nviscoelastic fluids and advance the understanding of breakup dynamics across\nscales."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-716",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15420"
    ],
    "b_title":[
      "Visual Generation Without Guidance"
    ],
    "b_abstract":[
      "Classifier-Free Guidance (CFG) has been a default technique in various visual\ngenerative models, yet it requires inference from both conditional and\nunconditional models during sampling. We propose to build visual models that\nare free from guided sampling. The resulting algorithm, Guidance-Free Training\n(GFT), matches the performance of CFG while reducing sampling to a single\nmodel, halving the computational cost. Unlike previous distillation-based\napproaches that rely on pretrained CFG networks, GFT enables training directly\nfrom scratch. GFT is simple to implement. It retains the same maximum\nlikelihood objective as CFG and differs mainly in the parameterization of\nconditional models. Implementing GFT requires only minimal modifications to\nexisting codebases, as most design choices and hyperparameters are directly\ninherited from CFG. Our extensive experiments across five distinct visual\nmodels demonstrate the effectiveness and versatility of GFT. Across domains of\ndiffusion, autoregressive, and masked-prediction modeling, GFT consistently\nachieves comparable or even lower FID scores, with similar diversity-fidelity\ntrade-offs compared with CFG baselines, all while being guidance-free. Code\nwill be available at https:\/\/github.com\/thu-ml\/GFT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02315"
    ],
    "c_title":[
      "K3 surfaces associated to varieties of generalized Kummer type"
    ],
    "c_abstract":[
      "To any hyper-K\\\"ahler variety $K$ of generalized Kummer type is associated\nvia Hodge theory a K3 surface $S_K$. We show how they are related geometrically\nthrough a moduli space of sheaves on $S_K$. As a consequence, building\nfundamentally on the works of O'Grady, Markman, Voisin, Varesco, we establish\nthe Hodge conjecture for all powers of any of these K3 surfaces as well as for\nall abelian fourfolds of Weil type with discriminant 1 and their powers,\nstrenghtening a result of Markman."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-717",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05812"
    ],
    "b_title":[
      "Intolerable Risk Threshold Recommendations for Artificial Intelligence"
    ],
    "b_abstract":[
      "Frontier AI models -- highly capable foundation models at the cutting edge of\nAI development -- may pose severe risks to public safety, human rights,\neconomic stability, and societal value in the coming years. These risks could\narise from deliberate adversarial misuse, system failures, unintended cascading\neffects, or simultaneous failures across multiple models.\n  In response to such risks, at the AI Seoul Summit in May 2024, 16 global AI\nindustry organizations signed the Frontier AI Safety Commitments, and 27\nnations and the EU issued a declaration on their intent to define these\nthresholds. To fulfill these commitments, organizations must determine and\ndisclose ``thresholds at which severe risks posed by a model or system, unless\nadequately mitigated, would be deemed intolerable.''\n  To assist in setting and operationalizing intolerable risk thresholds, we\noutline key principles and considerations; for example, to aim for ``good, not\nperfect'' thresholds in the face of limited data on rapidly advancing AI\ncapabilities and consequently evolving risks. We also propose specific\nthreshold recommendations, including some detailed case studies, for a subset\nof risks across eight risk categories: (1) Chemical, Biological, Radiological,\nand Nuclear (CBRN) Weapons, (2) Cyber Attacks, (3) Model Autonomy, (4)\nPersuasion and Manipulation, (5) Deception, (6) Toxicity, (7) Discrimination,\nand (8) Socioeconomic Disruption. Our goal is to serve as a starting point or\nsupplementary resource for policymakers and industry leaders, encouraging\nproactive risk management that prioritizes preventing intolerable risks (ex\nante) rather than merely mitigating them after they occur (ex post)."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20842"
    ],
    "c_title":[
      "A Laplace duality for integration"
    ],
    "c_abstract":[
      "We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\\in$ R d :\ng(x) $\\le$ y}, where g is nonnegative and Ky is compact for all y $\\in$ [0,\n+$\\infty$). Under some assumptions, we show that for every y $\\in$ (0,\n$\\infty$) there exists a distinguished scalar $\\lambda$y $\\in$ (0, +$\\infty$)\nsuch that which is the counterpart analogue for integration of Lagrangian\nduality for optimization. A crucial ingredient is the Laplace transform, the\nanalogue for integration of Legendre-Fenchel transform in optimization. In\nparticular, if both f and g are positively homogeneous then $\\lambda$y is a\nsimple explicitly rational function of y. In addition if g is quadratic form\nthen computing v(y) reduces to computing the integral of f with respect to a\nspecific Gaussian measure for which exact and approximate numerical methods\n(e.g. cubatures) are available."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-718",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18993"
    ],
    "b_title":[
      "Visual Autoregressive Modeling for Image Super-Resolution"
    ],
    "b_abstract":[
      "Image Super-Resolution (ISR) has seen significant progress with the\nintroduction of remarkable generative models. However, challenges such as the\ntrade-off issues between fidelity and realism, as well as computational\ncomplexity, have also posed limitations on their application. Building upon the\ntremendous success of autoregressive models in the language domain, we propose\n\\textbf{VARSR}, a novel visual autoregressive modeling for ISR framework with\nthe form of next-scale prediction. To effectively integrate and preserve\nsemantic information in low-resolution images, we propose using prefix tokens\nto incorporate the condition. Scale-aligned Rotary Positional Encodings are\nintroduced to capture spatial structures and the diffusion refiner is utilized\nfor modeling quantization residual loss to achieve pixel-level fidelity.\nImage-based Classifier-free Guidance is proposed to guide the generation of\nmore realistic images. Furthermore, we collect large-scale data and design a\ntraining process to obtain robust generative priors. Quantitative and\nqualitative results show that VARSR is capable of generating high-fidelity and\nhigh-realism images with more efficiency than diffusion-based methods. Our\ncodes will be released at https:\/\/github.com\/qyp2000\/VARSR."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01751"
    ],
    "c_title":[
      "Clustered unified dark sector cosmology: Background evolution and linear\n  perturbations in light of observations"
    ],
    "c_abstract":[
      "We consider unified dark sector models in which the fluid can collapse and\ncluster into halos, allowing for hierarchical structure formation to proceed as\nin standard cosmology. We show that both background evolution and linear\nperturbations tend towards those in $\\LCDM$ as the clustered fraction $f\n\\rightarrow 1$. We confront such models with various observational datasets,\nwith emphasis on the relatively well motivated standard Chaplygin gas. We show\nthat the strongest constraints come from secondary anisotropies in the CMB\nspectrum, which prefer models with $f \\rightarrow 1$. However, as a larger\nHubble constant is allowed for smaller $f$, values of $f \\simeq 0.99$ (rather\nthan tending to exact unity) are favored when late universe expansion data is\nincluded, with $f \\simeq 0.97$ and $H_0 \\simeq 70 {\\rm km\/s\/Mpc}$ allowed at\nthe 2-$\\sigma$ level. Such values of $f$ imply extremely efficient clustering\ninto nonlinear structures. They may nevertheless be compatible with clustered\nfractions in warm dark matter based cosmologies, which have similar minimal\nhalo mass scales as the models considered here. Tight CMB constraints on $f$\nalso apply to the generalized Chaplygin gas, except for models that are already\nquite close to $\\LCDM$, in which case all values of $0 \\le f \\le 1$ are\nallowed. In contrast to the CMB, large scale structure data, which were\ninitially used to rule out unclustered unified dark matter models, are far less\nconstraining. Indeed, late universe data, including the large scale galaxy\ndistribution, prefer models that are far from $\\LCDM$. But these are in tension\nwith the CMB data."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-719",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05793"
    ],
    "b_title":[
      "MedSimAI: Simulation and Formative Feedback Generation to Enhance\n  Deliberate Practice in Medical Education"
    ],
    "b_abstract":[
      "Medical education faces challenges in scalability, accessibility, and\nconsistency, particularly in clinical skills training for physician-patient\ncommunication. Traditional simulation-based learning, while effective, is\nresource-intensive, difficult to schedule, and often highly variable in\nfeedback quality. Through a collaboration between AI, learning science, and\nmedical education experts, we co-developed MedSimAI, an AI-powered simulation\nplatform that enables deliberate practice, self-regulated learning (SRL), and\nautomated assessment through interactive patient encounters. Leveraging large\nlanguage models (LLMs), MedSimAI generates realistic clinical interactions and\nprovides immediate, structured feedback using established medical evaluation\nframeworks such as the Master Interview Rating Scale (MIRS). In a pilot study\nwith 104 first-year medical students, we examined engagement, conversation\npatterns, and user perceptions. Students found MedSimAI beneficial for\nrepeated, realistic patient-history practice. Conversation analysis revealed\nthat certain higher-order skills were often overlooked, though students\ngenerally performed systematic histories and empathic listening. By integrating\nunlimited practice opportunities, real-time AI assessment, and SRL principles,\nMedSimAI addresses key limitations of traditional simulation-based training,\nmaking high-quality clinical education more accessible and scalable."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13596"
    ],
    "c_title":[
      "Wavefunction coefficients from Amplitubes"
    ],
    "c_abstract":[
      "Given a graph its set of connected subgraphs (tubes) can be defined in two\nways: either by considering subsets of edges, or by considering subsets of\nvertices. We refer to these as binary tubes and unary tubes respectively. Both\nnotions come with a natural compatibility condition between tubes which differ\nby a simple adjacency constraint. Compatible sets of tubes are refered to as\ntubings. By considering the set of binary tubes, and summing over all maximal\nbinary-tubings, one is lead to an expression for the flat space wavefunction\ncoefficients relevant for computing cosmological correlators. On the other\nhand, considering the set of unary tubes, and summing over all maximal\nunary-tubings, one is lead to expressions recently referred to as amplitubes\nwhich resemble the scattering amplitudes of $\\text{tr}(\\phi^3)$ theory. In this\npaper we study the two definitions of tubing in order to provide a new formula\nfor the flat space wavefunction coefficient for a single graph as a sum over\nproducts of amplitubes. Motivated by our rewriting of the wavefunction\ncoefficient we introduce a new definition of tubing which makes use of both the\nbinary and unary tubes which we refer to as cut tubings. We explain how each\ncut tubing induces a decorated orientation of the underlying graph satisfying\nan acyclic condition and demonstrate how the set of all acyclic decorated\norientations for a given graph count the number of basis functions appearing in\nthe kinematic flow."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-720",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14087"
    ],
    "b_title":[
      "On the scalar sector of 2HDM: ring of basis invariants, syzygies, and\n  six-loop renormalization-group equations"
    ],
    "b_abstract":[
      "We consider a generating set of reparametrization invariants that can be\nconstructed from the couplings and masses entering the scalar potential of the\ngeneral Two-Higgs-Doublet Model (2HDM). Being independent of higgs-basis\nrotations, they generate a polynomial ring of basis invariants that represent\nthe physical content of the model. Ignoring for the moment gauge and Yukawa\ninteractions, we derive six-loop renormalization group equations (RGE) for all\nthe invariants entering the set. We do not compute a single Feynman diagram but\nrely heavily on the general RGE results for scalar theories. We use linear\nalgebra together with techniques from Invariant Theory. The latter not only\nallow one to compute the number of linearly independent invariants entering\nbeta functions at a certain loop order (via Hilbert series) but also provide a\nconvenient tool for dealing with polynomial relations (so-called syzygies)\nbetween invariants from the generating set."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05884"
    ],
    "c_title":[
      "Study of Robust Multiuser Scheduling and Power Allocation in Cell-Free\n  MIMO Networks"
    ],
    "c_abstract":[
      "This paper introduces a robust resource allocation framework for the downlink\nof cell-free massive multi-input multi-output (CF-mMIMO) networks to address\nthe effects caused by imperfect channel state information (CSI). In particular,\nthe proposed robust resource allocation framework includes a robust user\nscheduling algorithm to optimize the network's sum-rate and a robust power\nallocation technique aimed at minimizing the mean square error (MSE) for a\nnetwork with a linear precoder. Unlike non-robust resource allocation\ntechniques, the proposed robust strategies effectively counteract the effects\nof imperfect CSI, enhancing network efficiency and reliability. Simulation\nresults show a significant improvement in network performance obtained by the\nproposed approaches, highlighting the impact of robust resource allocation in\nwireless networks."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-721",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14965"
    ],
    "b_title":[
      "Lost in Translation: How Does Bilingualism Shape Reader Preferences for\n  Annotated Charts?"
    ],
    "b_abstract":[
      "Visualizations are powerful tools for conveying information but often rely on\naccompanying text for essential context and guidance. This study investigates\nthe impact of annotation patterns on reader preferences and comprehension\naccuracy among multilingual populations, addressing a gap in visualization\nresearch. We conducted experiments with two groups fluent in English and either\nTamil (n = 557) or Arabic (n = 539) across six visualization types, each\nvarying in annotation volume and semantic content. Full-text annotations\nyielded the highest comprehension accuracy across all languages, while\npreferences diverged: English readers favored highly annotated charts, whereas\nTamil\/Arabic readers preferred full-text or minimally annotated versions.\nSemantic variations in annotations (L1-L4) did not significantly affect\ncomprehension, demonstrating the robustness of text comprehension across\nlanguages. English annotations were generally preferred, with a tendency to\nthink technically in English linked to greater aversion to non-English\nannotations, though this diminished among participants who regularly switched\nlanguages internally. Non-English annotations incorporating visual or external\nknowledge were less favored, particularly in titles. Our findings highlight\ncultural and educational factors influencing perceptions of visual information,\nunderscoring the need for inclusive annotation practices for diverse linguistic\naudiences. All data and materials are available at: https:\/\/osf.io\/ckdb4\/."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14046"
    ],
    "c_title":[
      "Linear quadratic control of parabolic-like evolutions with memory of the\n  inputs"
    ],
    "c_abstract":[
      "A study of the linear quadratic (LQ) control problem on a finite time\ninterval for a model equation in Hilbert spaces which comprehends the memory of\nthe inputs was performed recently by the authors. The outcome included a\nclosed-loop representation of the unique optimal control, along with the\nderivation of a related coupled system of three quadratic (operator) equations\nwhich is shown to be well-posed. Notably, in the absence of memory the above\nelements -- namely, formula and system -- reduce to the known feedback formula\nand single differential Riccati equation, respectively. In this work we take\nthe next natural step, and prove the said results for a class of evolutions\nwhere the control operator is no longer bounded. These findings appear to be\nthe first ones of their kind; furthermore, they extend the classical theory of\nthe LQ problem and Riccati equations for parabolic partial differential\nequations."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-722",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17882"
    ],
    "b_title":[
      "Think Before Refusal : Triggering Safety Reflection in LLMs to Mitigate\n  False Refusal Behavior"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have demonstrated that\nfine-tuning and human alignment can render LLMs harmless. In practice, such\n\"harmlessness\" behavior is mainly achieved by training models to reject harmful\nrequests, such as \"Explain how to burn down my neighbor's house\", where the\nmodel appropriately declines to respond. However, this approach can\ninadvertently result in false refusal, where models reject benign queries as\nwell, such as \"Tell me how to kill a Python process\". In this work, we\ndemonstrate that prompting safety reflection before generating a response can\nmitigate false refusal behavior. Building on this finding, we introduce the\nThink-Before-Refusal (TBR) schema and conduct safety-aware instruction\nfine-tuning incorporating safety reflection. In an ablation study across 15\npre-trained models, we show that models fine-tuned with safety reflection\nsignificantly reduce false refusal behavior while maintaining safety and\noverall performance compared to those fine-tuned without safety reflection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04922"
    ],
    "c_title":[
      "Lateral Exchange Bias for N\\'eel-Vector Control in Atomically Thin\n  Antiferromagnets"
    ],
    "c_abstract":[
      "Atomically thin van der Waals (vdW) magnets have emerged as a fascinating\nplatform for the exploration of novel physical phenomena arising from their\nreduced dimensionality and exceptional material properties. Their\nsingle-crystalline nature and ultimate miniaturization position them as leading\ncandidates for next-generation spintronic applications. Antiferromagnetic (AF)\nvdW magnets are of particular interest, as they combine the advantages of vdW\nmagnets with the functionality of AF spintronics, offering unique opportunities\nfor ultrafast and robust spintronic devices. However, the lack of approaches to\nlocally and deterministically manipulate their order parameter -- the\nN\\'eel-vector -- remains a key limitation. Here, we introduce a fundamentally\nnew paradigm in nanomagnetism, which we term lateral exchange bias (LEB), to\nachieve N\\'eel vector control in bilayers of the vdW AF CrSBr. We exploit the\nsingle-crystalline registry formed by terraced CrSBr samples, where the bilayer\nN\\'eel vector is controlled by LEB from neighboring, odd-layered flakes, whose\nnonzero magnetization we manipulate using magnetic fields. Using this control,\nwe achieve nonvolatile manipulation of magnetic domains and domain walls (DWs)\nin AF CrSBr bilayers, establishing a powerful toolkit for controlling\natomically thin AFs at the nanoscale. Our results challenge conventional views\non exchange bias and provide a previously unexplored mechanism for achieving\natomic-scale control of AFic order. Our findings pave the way for the\ndevelopment of advanced spintronic architectures and quantum technologies based\non vdW magnets."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-723",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12674"
    ],
    "b_title":[
      "Boundary Conditions for the Entanglement Cut in 2D Conformal Field\n  Theories"
    ],
    "b_abstract":[
      "The entanglement spectra for a subsystem in a spin chain fine-tuned to a\nquantum-critical point contains signatures of the underlying quantum field\ntheory that governs its low-energy properties. For an open chain with given\nboundary conditions described by a 2D conformal field theory~(CFT), the\nentanglement spectrum of the left\/right half of the system coincides with a\nboundary CFT spectrum, where one of the boundary conditions arise due to the\n`entanglement cut'. The latter has been argued to be conformal and has been\nnumerically found to be the `free' boundary condition for Ising, Potts and free\nboson theories. For these models, the `free' boundary condition for the lattice\ndegree of freedom has a counterpart in the continuum theory. However, this is\nnot true in general. Here, this question is analyzed for the unitary minimal\nmodels of 2D CFTs using the density matrix renormalization group technique. The\nentanglement spectra are computed for blocks of spins in open chains of A-type\nrestricted solid-on-solid models with identical boundary conditions at the\nends. The imposed boundary conditions are realized exactly for these lattice\nmodels due to their integrable nature. The obtained entanglement spectra are in\ngood agreement with certain boundary CFT spectra. The boundary condition for\nthe entanglement cut is found to be conformal and to coincide with the one with\nthe highest boundary entropy. This identification enables determination of the\nexponents governing the unusual corrections to the entanglement entropy from\nthe CFT partition functions. These are compared with numerical results."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.11453"
    ],
    "c_title":[
      "Do Comments and Expertise Still Matter? An Experiment on Programmers'\n  Adoption of AI-Generated JavaScript Code"
    ],
    "c_abstract":[
      "This paper investigates the factors influencing programmers' adoption of\nAI-generated JavaScript code recommendations. It extends prior research by (1)\nutilizing objective (as opposed to the typically self-reported) measurements\nfor programmers' adoption of AI-generated code and (2) examining whether\nAI-generated comments added to code recommendations and development expertise\ndrive AI-generated code adoption. We tested these potential drivers in an\nonline experiment with 173 programmers. Participants were asked to answer some\nquestions to demonstrate their level of development expertise. Then, they were\nasked to solve a LeetCode problem without AI support. After attempting to solve\nthe problem on their own, they received an AI-generated solution to assist them\nin refining their solutions. The solutions provided were manipulated to include\nor exclude AI-generated comments (a between-subjects factor). Programmers'\nadoption of AI-generated code was gauged by code similarity between\nAI-generated solutions and participants' submitted solutions, providing a more\nreliable and objective measurement of code adoption behaviors. Our findings\nrevealed that the presence of comments significantly influences programmers'\nadoption of AI-generated code regardless of the participants' development\nexpertise."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-724",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05100"
    ],
    "b_title":[
      "Hands vs. Controllers: Comparing User Interactions in Virtual Reality\n  Shopping Environments"
    ],
    "b_abstract":[
      "Virtual reality enables users to experience real-life situations in immersive\nenvironments. Interaction methods significantly shape user experience,\nparticularly in high fidelity simulations mimicking real world tasks. This\nstudy evaluates two primary VR interaction techniques, hand based and\ncontroller based, through virtual shopping tasks in a simulated supermarket\nwith 40 participants. Hand-based interaction was preferred for its natural,\nimmersive qualities and alignment with real-world gestures but faced usability\nchallenges, including limited haptic feedback and grasping inefficiencies. In\ncontrast, controller-based interaction offered greater precision and\nreliability, making it more suitable for tasks requiring fine motor skills."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07201"
    ],
    "c_title":[
      "An Enhanced Zeroth-Order Stochastic Frank-Wolfe Framework for\n  Constrained Finite-Sum Optimization"
    ],
    "c_abstract":[
      "We propose an enhanced zeroth-order stochastic Frank-Wolfe framework to\naddress constrained finite-sum optimization problems, a structure prevalent in\nlarge-scale machine-learning applications. Our method introduces a novel double\nvariance reduction framework that effectively reduces the gradient\napproximation variance induced by zeroth-order oracles and the stochastic\nsampling variance from finite-sum objectives. By leveraging this framework, our\nalgorithm achieves significant improvements in query efficiency, making it\nparticularly well-suited for high-dimensional optimization tasks. Specifically,\nfor convex objectives, the algorithm achieves a query complexity of O(d\n\\sqrt{n}\/\\epsilon ) to find an epsilon-suboptimal solution, where d is the\ndimensionality and n is the number of functions in the finite-sum objective.\nFor non-convex objectives, it achieves a query complexity of\nO(d^{3\/2}\\sqrt{n}\/\\epsilon^2 ) without requiring the computation ofd partial\nderivatives at each iteration. These complexities are the best known among\nzeroth-order stochastic Frank-Wolfe algorithms that avoid explicit gradient\ncalculations. Empirical experiments on convex and non-convex machine learning\ntasks, including sparse logistic regression, robust classification, and\nadversarial attacks on deep networks, validate the computational efficiency and\nscalability of our approach. Our algorithm demonstrates superior performance in\nboth convergence rate and query complexity compared to existing methods."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-725",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11089"
    ],
    "b_title":[
      "Advancing Atom Probe Tomography of SrTiO$_3$: Measurement Methodology\n  and Impurity Detection Limits"
    ],
    "b_abstract":[
      "Strontium titanate (STO) possesses promising properties for applications in\nthermoelectricity, catalysis, fuel cells, and more, but its performance is\nhighly dependent on stoichiometry and impurity levels. While atom probe\ntomography (APT) can provide detailed three-dimensional atomic-scale chemical\ninformation, STO specimens have been challenging to analyze due to premature\nspecimen fracture. In this study, we show that by applying a thin metal coating\nto atom probe tips, STO specimens can be analyzed with nearly 100% success.\nUsing this approach, we investigate both undoped STO and 1 at% Nb-doped STO,\nachieving sufficient sensitivity to detect Nb concentrations as low as 0.7 at%.\nThis work establishes a reliable APT method for high-resolution chemical\nanalysis of STO at the nanoscale."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.05344"
    ],
    "c_title":[
      "Higher rank prioritary bundles on ruled surfaces and their global\n  sections"
    ],
    "c_abstract":[
      "Let $X$ be a ruled surface over a nonsingular curve $C$ of genus $g\\geq0$.\nThe main goal of this paper is to construct simple prioritary vector bundles of\nany rank $r$ on $X$ and to give effective bounds for the dimension of their\nmodule of global sections."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-726",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12075"
    ],
    "b_title":[
      "The large mass limit of $G_2$ and Calabi-Yau monopoles"
    ],
    "b_abstract":[
      "We develop a structure theory for the limit of $SU(2)$ $G_2$-monopoles (resp.\nCalabi-Yau monopoles) on a principal $SU(2)$-bundle over an asymptotically\nconical $G_2$-manifolds (resp. Calabi-Yau 3-folds) as the mass parameter tends\nto infinity, while the topologial data for the bundle stays fixed. We show how\nto extract a singular abelian $G_2$-monopole (resp. Calabi-Yau monopole) with\nDirac singularity along a calibrated cycle in the large mass limit, and we\nprove an energy identity for monopole bubbles."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.13368"
    ],
    "c_title":[
      "Exploring new variational quantum circuit ansatzes for solving $SU(2)$\n  matrix models"
    ],
    "c_abstract":[
      "In this work, we explored and experimented with new forms of parameterized\nquantum circuits to be used as variational ansatzes for solving the bosonic and\nsupersymmetric $SU(2)$ matrix models at different couplings using the\nVariational Quantum Eigensolver (VQE) algorithm. Working with IBM Qiskit\nquantum computing platform, we show that two types of quantum circuits named\n\\texttt{TwoLocal} and \\texttt{EvolvedOperatorAnsatz} can outperform the popular\n\\texttt{EfficientSU2} circuits which have been routinely used in the recent\nquantum physics literature to run VQE. With their more customizable\nconstructions that allow for more flexibility beyond choosing the types of\nparameterized rotation gates, both types of new circuit ansatzes used in this\nwork have led to performances that are either better than or at least\ncomparable to \\texttt{EfficientSU2} in the setting of $SU(2)$ matrix models. In\nparticular, in the strong coupling regimes of the bosonic model, both\n\\texttt{TwoLocal} and \\texttt{EvolvedOperatorAnsatz} circuits provided a better\napproximation to the exact ground states, while in the supersymmetric model,\nshallow \\texttt{EvolvedOperatorAnsatz} circuits with small a number of\nparameters, attained a comparable albeit not as good performance as the much\ndeeper \\texttt{EfficientSU2} circuits with around 8 to 9 times more parameters.\nThe results of this work demonstrate conclusively the potential of\n\\texttt{TwoLocal} and \\texttt{EvolvedOperatorAnsatz} quantum circuits as\nefficient new types of variational ansatzes that should be considered more\nfrequently in future VQE studies of quantum physics systems."
    ],
    "c_categories":[
      [
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-727",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08298"
    ],
    "b_title":[
      "Improving Existing Optimization Algorithms with LLMs"
    ],
    "b_abstract":[
      "The integration of Large Language Models (LLMs) into optimization has created\na powerful synergy, opening exciting research opportunities. This paper\ninvestigates how LLMs can enhance existing optimization algorithms. Using their\npre-trained knowledge, we demonstrate their ability to propose innovative\nheuristic variations and implementation strategies. To evaluate this, we\napplied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt\n(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that\nincorporates a heuristic in the solution construction phase. Our results show\nthat an alternative heuristic proposed by GPT-4o outperforms the\nexpert-designed heuristic of CMSA, with the performance gap widening on larger\nand denser graphs. Project URL: https:\/\/imp-opt-algo-llms.surge.sh\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07180"
    ],
    "c_title":[
      "Soliton microcombs in X-cut LiNbO3 microresonators"
    ],
    "c_abstract":[
      "Chip-scale integration of optical frequency combs, particularly soliton\nmicrocombs, enables miniaturized instrumentation for timekeeping, ranging, and\nspectroscopy. Although soliton microcombs have been demonstrated on various\nmaterial platforms, realizing complete comb functionality on photonic chips\nrequires the co-integration of high-speed modulators and efficient frequency\ndoublers, features that are available in a monolithic form on X-cut thin-film\nlithium niobate (TFLN). However, the pronounced Raman nonlinearity associated\nwith extraordinary light in this platform has so far precluded soliton\nmicrocomb generation. Here, we report the generation of\ntransverse-electric-polarized soliton microcombs with a 25 GHz repetition rate\nin high-Q microresonators on X-cut TFLN chips. By precisely orienting the\nracetrack microresonator relative to the optical axis, we mitigate Raman\nnonlinearity and enable soliton formation under continuous-wave laser pumping.\nMoreover, the soliton microcomb spectra are extended to 350 nm with pulsed\nlaser pumping. This work expands the capabilities of TFLN photonics and paves\nthe way for the monolithic integration of fast-tunable, self-referenced\nmicrocombs."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-728",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14137"
    ],
    "b_title":[
      "A variational formulation of the governing equations of ideal quantum\n  fluids"
    ],
    "b_abstract":[
      "Applying the least action principle to the motion of an ideal gas, we find\nBernoulli's equation where the local velocity is expressed as the gradient of a\nvelocity potential, while the internal energy depends on the interaction among\nthe particles of the gas. Then, assuming that the internal energy is\nproportional non-locally to the logarithm of the mass density and truncating\nthe resulting sum of density gradients after the second term, we find an\nadditional Bohm's quantum potential term in the internal energy. Therefore, the\nBernoulli equation reduces to the Madelung equation, revealing a novel\nclassical description of quantum fluids that does not require to postulate\nquantum mechanics. Finally, non-locality can be removed by introducing a\nretarded potential, thus leading to a covariant formulation of the quantum\npotential and of the equation of motion of an ideal quantum fluid."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.08979"
    ],
    "c_title":[
      "Agentic AI for Scientific Discovery: A Survey of Progress, Challenges,\n  and Future Directions"
    ],
    "c_abstract":[
      "The integration of Agentic AI into scientific discovery marks a new frontier\nin research automation. These AI systems, capable of reasoning, planning, and\nautonomous decision-making, are transforming how scientists perform literature\nreview, generate hypotheses, conduct experiments, and analyze results. This\nsurvey provides a comprehensive overview of Agentic AI for scientific\ndiscovery, categorizing existing systems and tools, and highlighting recent\nprogress across fields such as chemistry, biology, and materials science. We\ndiscuss key evaluation metrics, implementation frameworks, and commonly used\ndatasets to offer a detailed understanding of the current state of the field.\nFinally, we address critical challenges, such as literature review automation,\nsystem reliability, and ethical concerns, while outlining future research\ndirections that emphasize human-AI collaboration and enhanced system\ncalibration."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-729",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03276"
    ],
    "b_title":[
      "High-precision numerical evaluation of Lauricella functions"
    ],
    "b_abstract":[
      "We present a method for high-precision numerical evaluations of Lauricella\nfunctions, whose indices are linearly dependent on some parameter\n$\\varepsilon$, in terms of their Laurent series expansions at zero. This method\nis based on finding analytic continuations of these functions in terms of\nFrobenius generalized power series. Being one-dimensional, these series are\nmuch more suited for high-precision numerical evaluations than\nmulti-dimensional sums arising in approaches to analytic continuations based on\nre-expansions of hypergeometric series or Mellin--Barnes integral\nrepresentations. To accelerate the calculation procedure further, the\n$\\varepsilon$ dependence of the result is reconstructed from the evaluations of\ngiven Lauricella functions at specific numerical values of $\\varepsilon$,\nwhich, in addition, allows for efficient parallel implementation. The method\nhas been implemented in the $\\texttt{PrecisionLauricella}$ package, written in\nWolfram Mathematica language."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.03679"
    ],
    "c_title":[
      "The relationship between galaxy size and halo properties: Insights from\n  the IllustrisTNG simulations and differential clustering"
    ],
    "c_abstract":[
      "The physical origin of the radial sizes of galaxies and how galaxy sizes are\ncorrelated with the properties of their host dark matter halos is an open\nquestion in galaxy formation. In observations, the large-scale clustering of\ngalaxies selected by stellar mass is significantly different for large and\nsmall galaxies, and Behroozi et al. (2022) showed that these results are in\ntension with some of the correlations between galaxy size and halo properties\nin the literature. We analyze the IllustrisTNG suite of large volume\ncosmological hydrodynamic simulations along with dark matter only simulations\nwith matched initial conditions. We investigate correlations between the ratio\nof galaxy size to halo virial radius ($r_{\\rm gal}\/R_{\\rm vir}$) and halo spin,\nconcentration, and formation time at redshift 0-3. We find a significant\ncorrelation between $r_{\\rm gal}\/R_{\\rm vir}$ and concentration, but only above\na critical value $c \\simeq 16$, and we also find a correlation between $r_{\\rm\ngal}\/R_{\\rm vir}$ and halo formation time. We suggest that galaxy formation\nhistory and environment, in addition to halo properties at a given output time,\nplay an important role in shaping galaxy size. In addition, we directly measure\nsize-based differential clustering in the TNG300 simulation and compare\ndirectly with the observational results. We find significant scale-dependent\nsize-based differential clustering in TNG, in qualitative agreement with\nobservations. However, correlations between $r_{\\rm gal}\/R_{\\rm vir}$ and\nsecondary halo properties are not the drivers of the differential clustering in\nthe simulations; instead, we find that most of this signal in TNG arises from\nsatellite galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-730",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07744"
    ],
    "b_title":[
      "Hydrodynamic stresses in a multi-species suspension of active Janus\n  colloids"
    ],
    "b_abstract":[
      "A realistic description of active particles should include interactions with\nthe medium, commonly a momentum-conserving simple fluid, in which they are\nsuspended. In this work, we consider a multi-species suspension of\nself-diffusiophoretic Janus colloids interacting via chemical and hydrodynamic\nfields. Through a systematic coarse-graining of the microscopic dynamics, we\ncalculate the multi-component contribution to the hydrodynamic stress tensor of\nthe incompressible Stokesian fluid in which the particles are immersed. For a\nsingle species, we find that the strength of the stress produced by the\ngradients of the number density field is determined by the particles'\nself-propulsion and chemotactic alignment, and can be tuned to be either\ncontractile or extensile. For a multi-species system, we unveil how different\nforms of activity modify the stress tensor, and how non-reciprocity in\nhydrodynamic interactions emerges in an active binary mixture."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10611"
    ],
    "c_title":[
      "Characterization of geodesic completeness for landmark space"
    ],
    "c_abstract":[
      "We provide a full characterization of geodesic completeness for spaces of\nconfigurations of landmarks with smooth Riemannian metrics that satisfy a\nrotational and translation invariance and which are induced from metrics on\nsubgroups of the diffeomorphism group for the shape domain. These spaces are\nwidely used for applications in shape analysis, for example, for measuring\nshape changes in medical imaging and morphometrics in biology. For statistics\nof such data to be well-defined, it is imperative to know if geodesics exist\nfor all times. We extend previously known sufficient conditions for geodesic\ncompleteness based on the regularity of the metric to give a full\ncharacterization for smooth Riemannian metrics with a rotational and\ntranslation invariance by means of an integrability criterion that involves\nonly the behavior of the cometric kernel as landmarks approach collision. We\nfurther use the integrability criterion for geodesic completeness and previous\nwork on stochastic completeness to construct a family of Riemannian landmark\nmanifolds that are geodesically complete but stochastically incomplete."
    ],
    "c_categories":[
      [
        "math.DG",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-731",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05159"
    ],
    "b_title":[
      "A Lightweight Method to Disrupt Memorized Sequences in LLM"
    ],
    "b_abstract":[
      "Large language models (LLMs) demonstrate impressive capabilities across many\ntasks yet risk reproducing copyrighted content verbatim, raising legal and\nethical concerns. Although methods like differential privacy or neuron editing\ncan reduce memorization, they typically require costly retraining or direct\naccess to model weights and may degrade performance. To address these\nchallenges, we propose TokenSwap, a lightweight, post-hoc approach that\nreplaces the probabilities of grammar-related tokens with those from a small\nauxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercial\ngrade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our method\neffectively reduces well-known cases of memorized generation by upto 10x with\nlittle to no impact on downstream tasks. Our approach offers a uniquely\naccessible and effective solution to users of real-world systems."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15327"
    ],
    "c_title":[
      "Processing the 2D and 3D Fresnel experimental databases via topological\n  derivative methods"
    ],
    "c_abstract":[
      "This paper presents reconstructions of homogeneous targets from the 2D and 3D\nFresnel databases by one-step imaging methods based on the computation of\ntopological derivative and topological energy fields. The electromagnetic\ninverse scattering problem is recast as a constrained optimization problem, in\nwhich we seek to minimize the error when comparing experimental microwave\nmeasurements with computer-generated synthetic data for arbitrary targets by\napproximating a Maxwell forward model. The true targets are then characterized\nby combining the topological derivatives or energies of such shape functionals\nfor all available receivers and emitters at different frequencies. Our\napproximations are comparable to the best approximations already obtained by\nother methods. However, these topological fields admit easy to evaluate\nclosed-form expressions, which speeds up the process."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-732",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07366"
    ],
    "b_title":[
      "RITHMS : An advanced stochastic framework for the simulation of\n  transgenerational hologenomic data"
    ],
    "b_abstract":[
      "A holobiont is made up of a host organism together with its microbiota. In\nthe context of animal breeding, as the holobiont can be viewed as the single\nunit upon which selection operates, integrating microbiota data into genomic\nprediction models may be a promising approach to improve predictions of\nphenotypic and genetic values. Nevertheless, there is a paucity of hologenomic\ntransgenerational data to address this hypothesis, and thus to fill this gap,\nwe propose a new simulation framework. Our approach, an R Implementation of a\nTransgenerational Hologenomic Model-based Simulator (RITHMS) is an open-source\npackage, builds upon the MoBPS package and incorporates distinctive\ncharacteristics of the microbiota, notably vertical and horizontal transmission\nas well as modulation due to the environment and host genetics. In addition,\nRITHMS can account for a variety of selection strategies and is adaptable to\ndifferent genetic architectures. We simulated transgenerational hologenomic\ndata using RITHMS under a wide variety of scenarios, varying heritability,\nmicrobiability, and microbiota heritability. We found that simulated data\naccurately reflected expected characteristics, notably based on microbial\ndiversity metrics, correlation between taxa, modulation of vertical and\nhorizontal transmission, response to environmental effects and the evolution of\nphenotypic values depending on selection strategy. Our results support the\nrelevance of our simulation framework and illustrate its possible use for\nbuilding a selection index balancing genetic gain and microbial diversity.\nRITHMS is an advanced, flexible tool for generating transgenerational\nhologenomic data that incorporate the complex interplay between genetics,\nmicrobiota and environment."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.06135"
    ],
    "c_title":[
      "Phase structure analysis of CP(1) model with $\\theta$ term by tensor\n  renormalization group"
    ],
    "c_abstract":[
      "We analyze the phase structure of 2d lattice CP(1) model with $\\theta$ term\nby using the bond-weighted tensor renormalization group method. We propose a\nnew tensor network representation for the model using the quadrature scheme and\nconfirm that its accuracy is better than that of the conventional\ncharacter-like expansion. As a probe to study the phase structure, we adopt the\ncentral charge and the scaling dimensions. The numerical results indicate an\nexistence of critical point at $\\theta=\\pi$, which is consistent with the\nHaldane's conjecture."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-733",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07087"
    ],
    "b_title":[
      "iManip: Skill-Incremental Learning for Robotic Manipulation"
    ],
    "b_abstract":[
      "The development of a generalist agent with adaptive multiple manipulation\nskills has been a long-standing goal in the robotics community. In this paper,\nwe explore a crucial task, skill-incremental learning, in robotic manipulation,\nwhich is to endow the robots with the ability to learn new manipulation skills\nbased on the previous learned knowledge without re-training. First, we build a\nskill-incremental environment based on the RLBench benchmark, and explore how\ntraditional incremental methods perform in this setting. We find that they\nsuffer from severe catastrophic forgetting due to the previous methods on\nclassification overlooking the characteristics of temporality and action\ncomplexity in robotic manipulation tasks. Towards this end, we propose an\nincremental Manip}ulation framework, termed iManip, to mitigate the above\nissues. We firstly design a temporal replay strategy to maintain the integrity\nof old skills when learning new skill. Moreover, we propose the extendable\nPerceiverIO, consisting of an action prompt with extendable weight to adapt to\nnew action primitives in new skill. Extensive experiments show that our\nframework performs well in Skill-Incremental Learning. Codes of the\nskill-incremental environment with our framework will be open-source."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17511"
    ],
    "c_title":[
      "Game of grounds"
    ],
    "c_abstract":[
      "In this paper, we propose to connect Prawitz's theory of grounds with\nGirard's Ludics. This connection is carried out on two levels. On a more\nphilosophical one, we highlight some differences between Prawitz's and Girard's\napproaches, but we also argue that they share some basic ideas about proofs and\ndeduction. On a more formal one, we sketch an indicative translation of\nPrawitz's theory grounds into Girard's Ludics relative to the implicational\nfragment of propositional intuitionistic logic. This may allow for a dialogical\nreading of Prawitz's ground-theoretic approach. Moreover, it becomes possible\nto provide a formal definition of a notion of ground-candidate introduced by\nCozzo."
    ],
    "c_categories":[
      [
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-734",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09329"
    ],
    "b_title":[
      "Energy Optimized Piecewise Polynomial Approximation Utilizing Modern\n  Machine Learning Optimizers"
    ],
    "b_abstract":[
      "This work explores an extension of ML-optimized piecewise polynomial\napproximation by incorporating energy optimization as an additional objective.\nTraditional closed-form solutions enable continuity and approximation targets\nbut lack flexibility in accommodating complex optimization goals. By leveraging\nmodern gradient descent optimizers within TensorFlow, we introduce a framework\nthat minimizes total curvature in cam profiles, leading to smoother motion and\nreduced energy consumption for input data that is unfavorable for sole\napproximation and continuity optimization. Experimental results confirm the\neffectiveness of this approach, demonstrating its potential to improve\nefficiency in scenarios where input data is noisy or suboptimal for\nconventional methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06844"
    ],
    "c_title":[
      "REML Implementations of Kernel-based Multi-environment Genomic\n  Prediction Models"
    ],
    "c_abstract":[
      "High-throughput pheno-, geno-, and envirotyping allows routine\ncharacterization of plant varieties and the trials they are evaluated in. These\ndatasets can be integrated into statistical models for genomic prediction in\nseveral ways. One approach is to create linear or non-linear kernels which are\nsubsequently used in reproducing kernel hilbert spaces (RKHS) regression.\nSoftware packages implementing a Bayesian approach are typically used for these\nRKHS models. However, they often lack some of the flexibility offered by\ndedicated linear mixed model software such as ASReml-R. Furthermore, a Bayesian\napproach is often computationally more demanding than a frequentist model. Here\nwe show how frequentist RKHS models can be implemented in ASReml-R and extend\nthese models to allow for heterogeneous (i.e., trial-specific) genetic\nvariances. We also show how an alternative to the typically Bayesian kernel\naveraging approach can be implemented by treating the bandwidth associated with\nthe non-linear kernel as a parameter to be estimated using restricted maximum\nlikelihood. We show that these REML implementations with homo- or heterogeneous\nvariances perform similarly or better than the Bayesian models. We also show\nthat the REML implementation comes with a significant increase in computational\nefficiency, being up to 12 times faster than the Bayesian models while using\nless memory. Finally, we discuss the significant flexibility provided by this\napproach and the options regarding further customization of variance models."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-735",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10074"
    ],
    "b_title":[
      "SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and\n  Chain-of-Thought for Embodied Task Planning"
    ],
    "b_abstract":[
      "Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10273"
    ],
    "c_title":[
      "Modelling subsonic turbulence with SPH-EXA"
    ],
    "c_abstract":[
      "The numerical simulation of subsonic turbulence with SPH has traditionally\nbeen hindered by E0 errors, inaccurate gradient evaluations, and excessive\ndissipation. In this work, we present numerical results of SPH simulations of\nsubsonic turbulence and compare to state-of-the-art codes such as AREPO and\nGIZMO. For the first time, SPH can reproduce the results of such codes, showing\na similar interval of wavenumber in the inertial range of the Kolmogorov\ncascade in the subsonic regime. We use the SPH-EXA code to perform these\nsimulations, a GPU-based state-of-the-art SPH code with high performance and\nextreme scalability at its core. SPH-EXA is coupled with a modern SPH solver\nbased on methods such as an integral approach to gradient calculation,\nartificial viscosity switches that include a linear field cleaner, a flexible\nfamily of pairing-resistant interpolation kernels, generalized volume elements,\nand a controlled handling of density jumps which maximizes Lagrangian\ncompatibility. In addition, it includes a novel and extremely scalable gravity\nsolver for astrophysical applications."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-736",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07969"
    ],
    "b_title":[
      "7ABAW-Compound Expression Recognition via Curriculum Learning"
    ],
    "b_abstract":[
      "With the advent of deep learning, expression recognition has made significant\nadvancements. However, due to the limited availability of annotated compound\nexpression datasets and the subtle variations of compound expressions, Compound\nEmotion Recognition (CE) still holds considerable potential for exploration. To\nadvance this task, the 7th Affective Behavior Analysis in-the-wild (ABAW)\ncompetition introduces the Compound Expression Challenge based on C-EXPR-DB, a\nlimited dataset without labels. In this paper, we present a curriculum\nlearning-based framework that initially trains the model on single-expression\ntasks and subsequently incorporates multi-expression data. This design ensures\nthat our model first masters the fundamental features of basic expressions\nbefore being exposed to the complexities of compound emotions. Specifically,\nour designs can be summarized as follows: 1) Single-Expression Pre-training:\nThe model is first trained on datasets containing single expressions to learn\nthe foundational facial features associated with basic emotions. 2) Dynamic\nCompound Expression Generation: Given the scarcity of annotated compound\nexpression datasets, we employ CutMix and Mixup techniques on the original\nsingle-expression images to create hybrid images exhibiting characteristics of\nmultiple basic emotions. 3) Incremental Multi-Expression Integration: After\nperforming well on single-expression tasks, the model is progressively exposed\nto multi-expression data, allowing the model to adapt to the complexity and\nvariability of compound expressions. The official results indicate that our\nmethod achieves the \\textbf{best} performance in this competition track with an\nF-score of 0.6063. Our code is released at https:\/\/github.com\/YenanLiu\/ABAW7th."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13601"
    ],
    "c_title":[
      "Probing the ideal limit of interfacial thermal conductance in\n  two-dimensional van der Waals heterostructures"
    ],
    "c_abstract":[
      "Probing the ideal limit of interfacial thermal conductance (ITC) in\ntwo-dimensional (2D) heterointerfaces is of paramount importance for assessing\nheat dissipation in 2D-based nanoelectronics. Using graphene\/hexagonal boron\nnitride (Gr\/$h$-BN), a structurally isomorphous heterostructure with minimal\nmass contrast, as a prototype, we develop an accurate yet highly efficient\nmachine-learned potential (MLP) model, which drives nonequilibrium molecular\ndynamics (NEMD) simulations on a realistically large system with over 300,000\natoms, enabling us to report the ideal limit range of ITC for 2D\nheterostructures at room temperature. We further unveil an intriguing\nstacking-sequence-dependent ITC hierarchy in the Gr\/$h$-BN heterostructure,\nwhich can be connected to moir\\'e patterns and is likely universal in van der\nWaals layered materials. The underlying atomic-level mechanisms can be\nsuccinctly summarized as energy-favorable stacking sequences facilitating\nout-of-plane phonon energy transmission. This work demonstrates that MLP-driven\nMD simulations can serve as a new paradigm for probing and understanding\nthermal transport mechanisms in 2D heterostructures and other layered\nmaterials."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-737",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12119"
    ],
    "b_title":[
      "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free\n  Multimodal Data Selection"
    ],
    "b_abstract":[
      "Visual instruction tuning refines pre-trained Multimodal Large Language\nModels (MLLMs) to enhance their real-world task performance. However, the rapid\nexpansion of visual instruction datasets introduces significant data\nredundancy, leading to excessive computational costs. Existing data selection\nmethods predominantly rely on proxy models or loss-based metrics, both of which\nimpose substantial computational overheads due to the necessity of model\ninference and backpropagation. To address this challenge, we propose PRISM, a\nnovel training-free approach for efficient multimodal data selection. Unlike\nexisting methods, PRISM eliminates the reliance on proxy models, warm-up\npretraining, and gradient-based optimization. Instead, it leverages Pearson\ncorrelation analysis to quantify the intrinsic visual encoding properties of\nMLLMs, computing a task-specific correlation score to identify high-value\ninstances. This not only enbles data-efficient selection,but maintains the\noriginal performance. Empirical evaluations across multiple MLLMs demonstrate\nthat PRISM reduces the overall time required for visual instruction tuning and\ndata selection to just 30% of conventional methods, while surpassing fully\nfine-tuned models across eight multimodal and three language understanding\nbenchmarks, achieving a 101.7% relative improvement in final performance."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12770"
    ],
    "c_title":[
      "Large CP Asymmetries from Final-State Interactions in Charmful Baryonic\n  Decays of $B^0 \\to \\Xi_c^+ \\overline{\\Xi}_c^-$ and $B_s^0 \\to \\Lambda_c^+\n  \\overline{\\Lambda}_c^-$"
    ],
    "c_abstract":[
      "We study the direct CP asymmetries in the decays of $B^0 \\to \\Xi_c^+\n\\overline{\\Xi}_c^-$ and $B_s^0 \\to \\Lambda_c^+ \\overline{\\Lambda}_c^-$,\nemphasizing the critical role of final-state interactions (FSIs). In these\nchannels, the small energy release suppresses short-distance contributions\nwhile enhancing long-distance effects. By separating the decay amplitudes into\nS and P waves, we show that the P-wave component, carrying only a single weak\nphase, contributes negligibly to CP asymmetries. In contrast, the S-wave\namplitude, strongly modified by FSIs, acquires a substantial strong phase that\nenables interference among multiple weak phases, producing large CP-violating\neffects. Numerically, we find sizable asymmetries of $a_{CP}^{\\text{dir}}=\n0.65_{-0.34}^{+0.33}$ for $B^0 \\to \\Xi_c^+ \\overline{\\Xi}_c^-$ and\n$a_{CP}^{\\text{dir}}= 0.26_{-0.15}^{+0.31}$ for $B_s^0 \\to \\Lambda_c^+\n\\overline{\\Lambda}_c^-$, where the main uncertainties stem from poorly measured\nhadron couplings. These results, combined with the relatively large branching\nfractions, make these modes prime targets for experimental searches at LHCb and\nBelle II, potentially offering new insights into strong dynamics and\nnonperturbative QCD in heavy-hadron decays."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-738",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03282"
    ],
    "b_title":[
      "Two-loop helicity amplitudes for diphoton production with massive quark\n  loop"
    ],
    "b_abstract":[
      "We compute two-loop helicity amplitudes in QCD for diphoton production\nthrough quark- and gluon-initiated channels, accounting for a massive internal\nquark loop by keeping its full mass dependence. Using physical projectors, we\ndirectly decompose the amplitude into its helicity components. By renormalising\nthe heavy quark mass in on-shell, and other quantities in $\\overline{\\rm MS}$\nschemes, we obtain finite remainders. This work paves the way for calculating\nthe cross-section for diphoton production at higher orders in QCD with a\nmassive quark loop, employing different subtraction schemes. The effect of a\nheavy quark is expected to play a crucial role in high-luminosity LHC."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.08583"
    ],
    "c_title":[
      "The density of elliptic curves over $\\mathbb{Q}_p$ with a rational\n  3-torsion point or a rational 3-isogeny"
    ],
    "c_abstract":[
      "We determine the probability that a random Weierstrass equation with\ncoefficients in the $p$-adic integers defines an elliptic curve with a\nnon-trivial $3$-torsion point, or with a degree $3$ isogeny, defined over the\nfield of $p$-adic numbers. We determine these densities by calculating the\ncorresponding $p$-adic volume integrals and analyzing certain modular curves.\nAdditionally, we explore the case of $\\ell$-torsion for $\\ell>3$."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-739",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04706"
    ],
    "b_title":[
      "Enhancing Impression Change Prediction in Speed Dating Simulations Based\n  on Speakers' Personalities"
    ],
    "b_abstract":[
      "This paper focuses on simulating text dialogues in which impressions between\nspeakers improve during speed dating. This simulation involves selecting an\nutterance from multiple candidates generated by a text generation model that\nreplicates a specific speaker's utterances, aiming to improve the impression of\nthe speaker. Accurately selecting an utterance that improves the impression is\ncrucial for the simulation. We believe that whether an utterance improves a\ndialogue partner's impression of the speaker may depend on the personalities of\nboth parties. However, recent methods for utterance selection do not consider\nthe impression per utterance or the personalities. To address this, we propose\na method that predicts whether an utterance improves a partner's impression of\nthe speaker, considering the personalities. The evaluation results showed that\npersonalities are useful in predicting impression changes per utterance.\nFurthermore, we conducted a human evaluation of simulated dialogues using our\nmethod. The results showed that it could simulate dialogues more favorably\nreceived than those selected without considering personalities."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17662"
    ],
    "c_title":[
      "Resonant Energy Transfer and Collectively Driven Emitters in Waveguide\n  QED"
    ],
    "c_abstract":[
      "Waveguide quantum electrodynamics (QED) has opened a new frontier in quantum\noptics, which enables the radiative coupling of distantly located emitters via\nthe spatially extended waveguide mode. This coupling leads to modified emission\ndynamics and previous work has reported the observation of increased intensity\ncorrelations (an antidip) when probing the resonance response of multiple\nemitters. However, the interference between independent emitters has been shown\nto lead to a similar response. Here, we directly observe resonant energy\ntransfer between two distant quantum emitters by recording an antidip in the\nintensity correlations, $g^{(2)}(\\tau)$, while driving only one of the\nemitters. Under the condition that only a single emitter is driven, the antidip\nin photon coincidences is a distinctive signature of emitter-emitter coupling,\nwhich enables the transfer of energy from the driven to the undriven emitter.\nInterestingly, the observed mechanism is a long-range and waveguide-engineered\nversion of resonant F\\\"orster transfer, which is responsible for the transport\nof energy between chlorophylls in the photosynthesis. Building on the\nestablished coupling, we demonstrate collective driving of the coupled emitter\npair. Specifically, we control the relative driving phase and amplitude of the\nemitters and apply this collective excitation scheme to selectively populate\nthe long-lived subradiant state. This results in suppressed emission, i.e. the\npeculiar situation where driving two emitters as opposed to one effectively\nreduces the probability of photon emission. Our work presents novel emission\nregimes and excitation schemes for a multi-emitter waveguide QED system. These\ncan be exploited to deterministically generate emitter-emitter entanglement and\nadvanced photonic states providing robustness against losses for photonic\nquantum computation and quantum communication."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-740",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00693"
    ],
    "b_title":[
      "DPBloomfilter: Securing Bloom Filters with Differential Privacy"
    ],
    "b_abstract":[
      "The Bloom filter is a simple yet space-efficient probabilistic data structure\nthat supports membership queries for dramatically large datasets. It is widely\nutilized and implemented across various industrial scenarios, often handling\nmassive datasets that include sensitive user information necessitating privacy\npreservation. To address the challenge of maintaining privacy within the Bloom\nfilter, we have developed the DPBloomfilter. This innovation integrates the\nclassical differential privacy mechanism, specifically the Random Response\ntechnique, into the Bloom filter, offering robust privacy guarantees under the\nsame running complexity as the standard Bloom filter. Through rigorous\nsimulation experiments, we have demonstrated that our DPBloomfilter algorithm\nmaintains high utility while ensuring privacy protections. To the best of our\nknowledge, this is the first work to provide differential privacy guarantees\nfor the Bloom filter for membership query problems."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03014"
    ],
    "c_title":[
      "Chiral dynamics: Quo vadis?"
    ],
    "c_abstract":[
      "I review the status of chiral dynamics. Topics include pion-pion scattering,\ndynamically generated states in the hadron spectrum and the emergence of\ntwo-pole structures, chiral symmetry in nuclear physics and chiral dynamics in\nthe Big Bang."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-lat",
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-741",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04365"
    ],
    "b_title":[
      "AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case\n  Study on Detecting Time of Birth"
    ],
    "b_abstract":[
      "Approximately 10% of newborns need some assistance to start breathing and 5\\%\nproper ventilation. It is crucial that interventions are initiated as soon as\npossible after birth. Accurate documentation of Time of Birth (ToB) is thereby\nessential for documenting and improving newborn resuscitation performance.\nHowever, current clinical practices rely on manual recording of ToB, typically\nwith minute precision. In this study, we present an AI-driven, video-based\nsystem for automated ToB detection using thermal imaging, designed to preserve\nthe privacy of healthcare providers and mothers by avoiding the use of\nidentifiable visual data. Our approach achieves 91.4% precision and 97.4%\nrecall in detecting ToB within thermal video clips during performance\nevaluation. Additionally, our system successfully identifies ToB in 96% of test\ncases with an absolute median deviation of 1 second compared to manual\nannotations. This method offers a reliable solution for improving ToB\ndocumentation and enhancing newborn resuscitation outcomes."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00439"
    ],
    "c_title":[
      "Testing Multipole Moments of compact objects beyond Kerr paradigm"
    ],
    "c_abstract":[
      "Multipole moments are related to the physical properties of compact\ngravitating objects; therefore, understanding their structure is useful in\naccessing the nature of compact objects. We look into gravitational wave\nobservables for black holes with charge, black holes on the brane, black holes\nwith torsion, and regular black holes to see if and how they are correlated to\nthe black hole hairs, which are related to the multipole moments. We find that\nthe gravitational wave observables are indeed related to the hairs of\nnon-vacuum spacetimes (for instance, charge $Q$ in the case of Kerr-Newman\nblack holes). We also constrain the black hole hairs for change in\ngravitational wave phasing to see if the dependencies are significant and can\nbe observed. The results from the analysis imply that the charge $Q$ in\nKerr-Newman black holes should be detectable; thus, we provide a constraint to\n$Q^2\/M^2$ given the spin and mass ratio of an ideal EMRI system for which\nfuture detectors like LISA can detect the change in gravitational wave\nobservables. We also look into an analytical approach to find multipole moments\nof non-vacuum black hole spacetimes, mainly using the Improved Twist Vector\napproach for the Geroch-Hansen multipole moments and the Thorne formalism. The\nnecessary analytics are computed, and the multipole moments are obtained for\nvarious non-vacuum spacetimes. However, the multipole moments don't contain any\ninformation about the black hole hairs, and we have commented on this\nobservation in our paper."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-742",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03529"
    ],
    "b_title":[
      "Stellar population synthesis models with a physically varying IMF"
    ],
    "b_abstract":[
      "Interpreting galactic luminosity requires assumptions about the galaxy-wide\ninitial mass function (gwIMF), often assumed invariant in most stellar\npopulation synthesis (SPS) models. If stars form in clusters with metallicity-\nand density-dependent \\textit{stellar IMFs}, the integrated galaxy-wide IMF\n(IGIMF) can be calculated, with its shape depending on the star formation rate\n(SFR) and metallicity. The shape of the IGIMF thus depends on the star\nformation rate (SFR) and metallicity. We develop the \\texttt{SPS-VarIMF} code\nwhich enables us for the first time to compute the spectra, luminosities, and\nremnant populations of galaxies in the context of the varying gwIMF with time,\nSFR, and an assumed metallicity. Using the \\texttt{SPS-VarIMF} code one can\ncalculate how the interpretation from the integrated galactic light may change\nif the underlying galaxy-wide IMF is assumed to be environmentally dependent\ninstead of being invariant. In particular, we compare the time evolution of the\ngalaxy color and the stellar mass-to-light ratio in different bands for the\nIGIMF and invariant canonical gwIMF assuming constant and delayed-$\\tau$ star\nformation histories. We show that the underlying gwIMF can be determined by\nexamining the colors and luminosities of late-type galaxies in UV and optical\nbands. On the other hand, for early-type galaxies, it is difficult to\ndistinguish which gwIMF is valid since adopting the different gwIMFs yields\nalmost identical colors. However, their gwIMF-dependent $M\/L$ ratios differ by\nup to an order of magnitude. Massive present-day elliptical galaxies would have\nbeen $10^4$ times as bright as at present when they were forming."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.01873"
    ],
    "c_title":[
      "Latent Mutants: A large-scale study on the Interplay between mutation\n  testing and software evolution"
    ],
    "c_abstract":[
      "In this paper we apply mutation testing in an in-time fashion, i.e., across\nmultiple project releases. Thus, we investigate how the mutants of the current\nversion behave in the future versions of the programs. We study the\ncharacteristics of what we call latent mutants, i.e., the mutants that are live\nin one version and killed in later revisions, and explore whether they are\npredictable with these properties. We examine 131,308 mutants generated by\nPitest on 13 open-source projects. Around 11.2% of these mutants are live, and\n3.5% of them are latent, manifesting in 104 days on average. Using the mutation\noperators and change-related features we successfully demonstrate that these\nlatent mutants are identifiable, predicting them with an accuracy of 86% and a\nbalanced accuracy of 67% using a simple random forest classifier."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-743",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08623"
    ],
    "b_title":[
      "Dimensional Reduction and K\\\"ahler Metric for Metric Moduli in Imaginary\n  Self-Dual Flux"
    ],
    "b_abstract":[
      "Understanding which effective field theories are consistent with an\nultraviolet completion in quantum gravity is an important theoretical question.\nTherefore, it is important to know the structure of the 4D effective theory\nassociated with a given compactification of string theory. We present a\nfirst-principles derivation of the low-energy 4D effective theory of geometric\nmoduli in a warped Calabi-Yau compactification of type IIB string theory with\nimaginary self-dual 3-form flux. This completes the derivation of the metric on\nK\\\"ahler moduli space from the 10D equations of motion. We also give the first\nderivation of an effective action for flat directions in the complex structure\nmoduli space of the Calabi-Yau (which generically mix with the axiodilaton)."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15615"
    ],
    "c_title":[
      "PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample\n  Efficient MARL"
    ],
    "c_abstract":[
      "Equivariant Graph Neural Networks (EGNNs) have emerged as a promising\napproach in Multi-Agent Reinforcement Learning (MARL), leveraging symmetry\nguarantees to greatly improve sample efficiency and generalization. However,\nreal-world environments often exhibit inherent asymmetries arising from factors\nsuch as external forces, measurement inaccuracies, or intrinsic system biases.\nThis paper introduces \\textit{Partially Equivariant Graph NeUral Networks\n(PEnGUiN)}, a novel architecture specifically designed to address these\nchallenges. We formally identify and categorize various types of partial\nequivariance relevant to MARL, including subgroup equivariance, feature-wise\nequivariance, regional equivariance, and approximate equivariance. We\ntheoretically demonstrate that PEnGUiN is capable of learning both fully\nequivariant (EGNN) and non-equivariant (GNN) representations within a unified\nframework. Through extensive experiments on a range of MARL problems\nincorporating various asymmetries, we empirically validate the efficacy of\nPEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both\nEGNNs and standard GNNs in asymmetric environments, highlighting their\npotential to improve the robustness and applicability of graph-based MARL\nalgorithms in real-world scenarios."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-744",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07790"
    ],
    "b_title":[
      "Sampling from Density power divergence-based Generalized posterior\n  distribution via Stochastic optimization"
    ],
    "b_abstract":[
      "Robust Bayesian inference using density power divergence (DPD) has emerged as\na promising approach for handling outliers in statistical estimation. While the\nDPD-based posterior offers theoretical guarantees for robustness, its practical\nimplementation faces significant computational challenges, particularly for\ngeneral parametric models with intractable integral terms. These challenges\nbecome especially pronounced in high-dimensional settings where traditional\nnumerical integration methods prove inadequate and computationally expensive.\nWe propose a novel sampling methodology that addresses these limitations by\nintegrating the loss-likelihood bootstrap with a stochastic gradient descent\nalgorithm specifically designed for DPD-based estimation. Our approach enables\nefficient and scalable sampling from DPD-based posteriors for a broad class of\nparametric models, including those with intractable integrals, and we further\nextend it to accommodate generalized linear models. Through comprehensive\nsimulation studies, we demonstrate that our method efficiently samples from\nDPD-based posteriors, offering superior computational scalability compared to\nconventional methods, particularly in high-dimensional settings. The results\nalso highlight its ability to handle complex parametric models with intractable\nintegral terms."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.10911"
    ],
    "c_title":[
      "Nanowire design by deep learning for energy efficient photonic\n  technologies"
    ],
    "c_abstract":[
      "This work describes our vision and proposal for the design of next generation\nphotonic devices based on custom-designed semiconductor nanowires. The\nintegration of multi-million-atom electronic structure and optical simulations\nwith the supervised machine learning models will pave the way for\ntransformative nanowire-based technologies, offering opportunities for the next\ngeneration energy-efficient greener photonics."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-745",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12705"
    ],
    "b_title":[
      "2D Layered Heterojunctions for Photoelectrocatalysis"
    ],
    "b_abstract":[
      "Two-dimensional (2D) layered nanomaterials heterostructures, arising from the\ncombination of 2D materials with other low-dimensional species, feature large\nsurface area to volume ratio, which provides a high density of active sites for\ncatalytic ap-plications and in particular for (photo)electrocatalysis (PEC).\nMeanwhile, their unique electronic band structure and high electrical\nconductivity enable efficient charge transfer (CT) between the active material\nand the substrate, which is essential for catalytic activity. In recent years,\nresearchers have demonstrated the potential of a range of 2D material\ninterfaces, such as graphene, graphitic carbon nitride (g-C3N4), metal\nchalcogenides (MCs), and MXenes, for (photo)electrocatalytic applica-tions. For\ninstance, MCs such as MoS2 and WS2 have shown excellent catalytic activity for\nhydrogen evolution, while gra-phene and MXenes have been used for the reduction\nof carbon dioxide to higher value chemicals. However, despite their great\npotential, there are still major challenges that need to be addressed in order\nto fully realize the potential of 2D materials for PEC. For example, their\nstability under harsh reaction conditions, as well as their scalability for\nlarge-scale production are important factors to be considered. Generating\nheterojunctions (HJs) by combining 2D layered structures with other\nna-nomaterials is a promising method to improve the photoelectrocatalytic\nproperties of the former. In this review, we inspect thoroughly the recent\nliterature, to demonstrate the significant potential that arises from utilizing\n2D layered heterostructures in PEC processes across a broad spectrum of\napplications, from energy conversion and storage to environmental remediation.\nWith the ongoing research and development, it is likely that the potential of\nthese materials will be fully expressed in the near future."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10041"
    ],
    "c_title":[
      "NumScout: Unveiling Numerical Defects in Smart Contracts using\n  LLM-Pruning Symbolic Execution"
    ],
    "c_abstract":[
      "In recent years, the Ethereum platform has witnessed a proliferation of smart\ncontracts, accompanied by exponential growth in total value locked (TVL).\nHigh-TVL smart contracts often require complex numerical computations,\nparticularly in mathematical financial models used by many decentralized\napplications (DApps). Improper calculations can introduce numerical defects,\nposing potential security risks. Existing research primarily focuses on\ntraditional numerical defects like integer overflow, and there is currently a\nlack of systematic research and effective detection methods targeting new types\nof numerical defects. In this paper, we identify five new types of numerical\ndefects through the analysis of 1,199 audit reports by utilizing the open card\nmethod. Each defect is defined and illustrated with a code example to highlight\nits features and potential consequences. We also propose NumScout, a symbolic\nexecution-based tool designed to detect these five defects. Specifically, the\ntool combines information from source code and bytecode, analyzing key\noperations such as comparisons and transfers, to effectively locate defects and\nreport them based on predefined detection patterns. Furthermore, NumScout uses\na large language model (LLM) to prune functions which are unrelated to\nnumerical operations. This step allows symbolic execution to quickly enter the\ntarget function and improve runtime speed by 28.4%. We run NumScout on 6,617\nreal-world contracts and evaluated its performance based on manually labeled\nresults. We find that 1,774 contracts contained at least one of the five\ndefects, and the tool achieved an overall precision of 89.7%."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-746",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14005"
    ],
    "b_title":[
      "Device-aware Optical Adversarial Attack for a Portable Projector-camera\n  System"
    ],
    "b_abstract":[
      "Deep-learning-based face recognition (FR) systems are susceptible to\nadversarial examples in both digital and physical domains. Physical attacks\npresent a greater threat to deployed systems as adversaries can easily access\nthe input channel, allowing them to provide malicious inputs to impersonate a\nvictim. This paper addresses the limitations of existing projector-camera-based\nadversarial light attacks in practical FR setups. By incorporating device-aware\nadaptations into the digital attack algorithm, such as resolution-aware and\ncolor-aware adjustments, we mitigate the degradation from digital to physical\ndomains. Experimental validation showcases the efficacy of our proposed\nalgorithm against real and spoof adversaries, achieving high physical\nsimilarity scores in FR models and state-of-the-art commercial systems. On\naverage, there is only a 14% reduction in scores from digital to physical\nattacks, with high attack success rate in both white- and black-box scenarios."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03692"
    ],
    "c_title":[
      "Capturing methane in a barn environment: the CH4 Livestock Emission\n  (CH4rLiE) project"
    ],
    "c_abstract":[
      "The CH4 Livestock Emission (CH4rLiE) project aims at developing a prototype\nfor methane emissions capture in a barn environment. Methane has a higher\nglobal warming potential (GWP) with respect to CO2, and methane emissions of\nhuman origin contribute about 23% to global warming. Emissions from livestock\nfarms play a non-negligible role, as a single cow is capable of emitting about\n110 kg of methane in a year. Several projects have tried to mitigate the\nproblem by intervening on animal feed: CH4rLiE, in contrast, proposes to act on\nthe methane already produced and diffused in the air, using a specially\ndeveloped recovery system. The idea arose from the expertise acquired in the\nLarge Hadron Collider experiments at CERN, where special gas recuperation\nsystems are being developed to extract CF4 from gaseous detectors' exhausted\ngas mixture. The project focuses on the study of gas adsorption by porous\nmaterials and on the development of a prototype system for methane capture,\nwhich will be installed in a real barn. This study is being supported by an\ninitial phase of gas diffusion simulations and by a campaign of measurements of\ngas concentrations in different barn areas. CH4rLiE will also provide an\nopportunity to explore, for the first time, the feasibility of methane recovery\nfrom the farm environment without affecting the animals' feeding or living\nconditions. The social benefits are extremely interesting both in terms of\ndeveloping and implementing low-impact farming production processes, but also\nin terms of recycling expensive or environmentally unfriendly gasses."
    ],
    "c_categories":[
      [
        "physics.ao-ph",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-747",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06222"
    ],
    "b_title":[
      "Vision-based 3D Semantic Scene Completion via Capture Dynamic\n  Representations"
    ],
    "b_abstract":[
      "The vision-based semantic scene completion task aims to predict dense\ngeometric and semantic 3D scene representations from 2D images. However, the\npresence of dynamic objects in the scene seriously affects the accuracy of the\nmodel inferring 3D structures from 2D images. Existing methods simply stack\nmultiple frames of image input to increase dense scene semantic information,\nbut ignore the fact that dynamic objects and non-texture areas violate\nmulti-view consistency and matching reliability. To address these issues, we\npropose a novel method, CDScene: Vision-based Robust Semantic Scene Completion\nvia Capturing Dynamic Representations. First, we leverage a multimodal\nlarge-scale model to extract 2D explicit semantics and align them into 3D\nspace. Second, we exploit the characteristics of monocular and stereo depth to\ndecouple scene information into dynamic and static features. The dynamic\nfeatures contain structural relationships around dynamic objects, and the\nstatic features contain dense contextual spatial information. Finally, we\ndesign a dynamic-static adaptive fusion module to effectively extract and\naggregate complementary features, achieving robust and accurate semantic scene\ncompletion in autonomous driving scenarios. Extensive experimental results on\nthe SemanticKITTI, SSCBench-KITTI360, and SemanticKITTI-C datasets demonstrate\nthe superiority and robustness of CDScene over existing state-of-the-art\nmethods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17803"
    ],
    "c_title":[
      "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With\n  Causal Discovery And Inference"
    ],
    "c_abstract":[
      "Causal reasoning is increasingly used in Reinforcement Learning (RL) to\nimprove the learning process in several dimensions: efficacy of learned\npolicies, efficiency of convergence, generalisation capabilities, safety and\ninterpretability of behaviour. However, applications of causal reasoning to\nMulti-Agent RL (MARL) are still mostly unexplored. In this paper, we take the\nfirst step in investigating the opportunities and challenges of applying causal\nreasoning in MARL. We measure the impact of a simple form of causal\naugmentation in state-of-the-art MARL scenarios increasingly requiring\ncooperation, and with state-of-the-art MARL algorithms exploiting various\ndegrees of collaboration between agents. Then, we discuss the positive as well\nas negative results achieved, giving us the chance to outline the areas where\nfurther research may help to successfully transfer causal RL to the multi-agent\nsetting."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-748",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13068"
    ],
    "b_title":[
      "Beyond the Lungs: Extending the Field of View in Chest CT with Latent\n  Diffusion Models"
    ],
    "b_abstract":[
      "The interconnection between the human lungs and other organs, such as the\nliver and kidneys, is crucial for understanding the underlying risks and\neffects of lung diseases and improving patient care. However, most research\nchest CT imaging is focused solely on the lungs due to considerations of cost\nand radiation dose. This restricted field of view (FOV) in the acquired images\nposes challenges to comprehensive analysis and hinders the ability to gain\ninsights into the impact of lung diseases on other organs. To address this, we\npropose SCOPE (Spatial Coverage Optimization with Prior Encoding), a novel\napproach to capture the inter-organ relationships from CT images and extend the\nFOV of chest CT images. Our approach first trains a variational autoencoder\n(VAE) to encode 2D axial CT slices individually, then stacks the latent\nrepresentations of the VAE to form a 3D context for training a latent diffusion\nmodel. Once trained, our approach extends the FOV of CT images in the\nz-direction by generating new axial slices in a zero-shot manner. We evaluated\nour approach on the National Lung Screening Trial (NLST) dataset, and results\nsuggest that it effectively extends the FOV to include the liver and kidneys,\nwhich are not completely covered in the original NLST data acquisition.\nQuantitative results on a held-out whole-body dataset demonstrate that the\ngenerated slices exhibit high fidelity with acquired data, achieving an SSIM of\n0.81."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01374"
    ],
    "c_title":[
      "Towards Stable Second-Kind Boundary Integral Equations for Transient\n  Wave Problems"
    ],
    "c_abstract":[
      "In this paper, we discuss the stable discretisation of the double layer\nboundary integral operator for the wave equation in $1d$. For this, we show\nthat the boundary integral formulation is $L^2$-elliptic and also inf-sup\nstable in standard energy spaces. This turns out to be a particular case of a\nrecent result on the inf-sup stability of boundary integral operators for the\nwave equation and contributes to its further understanding. Moreover, we\npresent the first BEM discretisations of second-kind operators for the wave\nequation for which stability is guaranteed and a complete numerical analysis is\noffered. We validate our theoretical findings with numerical experiments."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-749",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11967"
    ],
    "b_title":[
      "Floquet topological state induced by light-driven band inversion in SnTe"
    ],
    "b_abstract":[
      "High intensity coherent light can dress matter, realizing new hybrid phases\nthat are not accessible in equilibrium. This effect results from the coherent\ninteraction between Bloch states inside the solid and the periodic field of\nimpinging photons which produces hybrid light-matter states called\nFloquet-Bloch states that can alter properties of the solid. Optically inducing\na topological state in a semiconductor using so-called Floquet engineering is\nan exciting prospect. However, it has not been realized, despite its\ntheoretical prediction more than 10 years ago. Here we show that an\nultrashort-lived topological state that is absent at equilibrium in the ground\nstate of SnTe can be created with femtosecond light pulses. This occurs when\nthe photoexcitation is similar in energy with the band gap of this polar\nsemiconductor. We observe a concomitant renormalization of the band dispersions\nthat reveals the generation of Floquet states connecting to the topological\nstate. We therefore provide the first direct experimental observation of a\nFloquet topological state and propose that it is driven by a light-induced band\ninversion in SnTe. Our discovery opens the way for controlling optically\non-demand the topological properties of semiconductors."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17847"
    ],
    "c_title":[
      "NVBleed: Covert and Side-Channel Attacks on NVIDIA Multi-GPU\n  Interconnect"
    ],
    "c_abstract":[
      "Multi-GPU systems are becoming increasingly important in highperformance\ncomputing (HPC) and cloud infrastructure, providing acceleration for\ndata-intensive applications, including machine learning workloads. These\nsystems consist of multiple GPUs interconnected through high-speed networking\nlinks such as NVIDIA's NVLink. In this work, we explore whether the\ninterconnect on such systems can offer a novel source of leakage, enabling new\nforms of covert and side-channel attacks. Specifically, we reverse engineer the\noperations of NVlink and identify two primary sources of leakage: timing\nvariations due to contention and accessible performance counters that disclose\ncommunication patterns. The leakage is visible remotely and even across VM\ninstances in the cloud, enabling potentially dangerous attacks. Building on\nthese observations, we develop two types of covert-channel attacks across two\nGPUs, achieving a bandwidth of over 70 Kbps with an error rate of 4.78% for the\ncontention channel. We develop two end-to-end crossGPU side-channel attacks:\napplication fingerprinting (including 18 high-performance computing and deep\nlearning applications) and 3D graphics character identification within Blender,\na multi-GPU rendering application. These attacks are highly effective,\nachieving F1 scores of up to 97.78% and 91.56%, respectively. We also discover\nthat leakage surprisingly occurs across Virtual Machines on the Google Cloud\nPlatform (GCP) and demonstrate a side-channel attack on Blender, achieving F1\nscores exceeding 88%. We also explore potential defenses such as managing\naccess to counters and reducing the resolution of the clock to mitigate the two\nsources of leakage."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-750",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06782"
    ],
    "b_title":[
      "The Rainbow Saturation Number of Cycles"
    ],
    "b_abstract":[
      "An edge-coloring of a graph $H$ is a function $\\mathcal{C}: E(H) \\rightarrow\n\\mathbb{N}$. We say that $H$ is rainbow if all edges of $H$ have different\ncolors. Given a graph $F$, an edge-colored graph $G$ is $F$-rainbow saturated\nif $G$ does not contain a rainbow copy of $F$, but the addition of any nonedge\nwith any color on it would create a rainbow copy of $F$. The rainbow saturation\nnumber $rsat(n,F)$ is the minimum number of edges in an $F$-rainbow saturated\ngraph with order $n$. In this paper we proved several results on cycle rainbow\nsaturation. For $n \\geq 5$, we determined the exact value of $rsat(n,C_4)$. For\n$ n \\geq 15$, we proved that $\\frac{3}{2}n-\\frac{5}{2} \\leq rsat(n,C_{5}) \\leq\n2n-6$. For $r \\geq 6$ and $n \\geq r+3$, we showed that $ \\frac{6}{5}n \\leq\nrsat(n,C_r) \\leq 2n+O(r^2)$. Moreover, we establish better lower bound on\n$C_r$-rainbow saturated graph $G$ while $G$ is rainbow."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.02860"
    ],
    "c_title":[
      "Seeing the Whole in the Parts in Self-Supervised Representation Learning"
    ],
    "c_abstract":[
      "Recent successes in self-supervised learning (SSL) model spatial\nco-occurrences of visual features either by masking portions of an image or by\naggressively cropping it. Here, we propose a new way to model spatial\nco-occurrences by aligning local representations (before pooling) with a global\nimage representation. We present CO-SSL, a family of instance discrimination\nmethods and show that it outperforms previous methods on several datasets,\nincluding ImageNet-1K where it achieves 71.5% of Top-1 accuracy with 100\npre-training epochs. CO-SSL is also more robust to noise corruption, internal\ncorruption, small adversarial attacks, and large training crop sizes. Our\nanalysis further indicates that CO-SSL learns highly redundant local\nrepresentations, which offers an explanation for its robustness. Overall, our\nwork suggests that aligning local and global representations may be a powerful\nprinciple of unsupervised category learning."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-751",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.15687"
    ],
    "b_title":[
      "Joint Cell Selection and Resource Allocation Games with Backhaul\n  Constraints"
    ],
    "b_abstract":[
      "In this work we study the problem of user association and resource allocation\nto maximize the proportional fairness of a wireless network with limited\nbackhaul capacity. The optimal solution of this problem requires solving a\nmixed integer non-linear programming problem which generally cannot be solved\nin real time. We propose instead to model the problem as a potential game,\nwhich decreases dramatically the computational complexity and obtains a user\nassociation and resource allocation close to the optimal solution.\nAdditionally, the use of a game-theoretic approach allows an efficient\ndistribution of the computational burden among the computational resources of\nthe network."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17884"
    ],
    "c_title":[
      "The fractional Riesz transform and their commutator in Dunkl setting"
    ],
    "c_abstract":[
      "In this paper, we study the boundedness of the fractional Riesz transforms in\nthe Dunkl setting. Moreover, we establish the necessary and sufficient\nconditions for the boundedness of their commutator with respect to the central\nBMO space associated with Euclidean metric and the BMO space associated with\nDunkl metric, respectively. Based on this, we further characterize the\ncompactness of the commutator in terms of the corresponding types of VMO\nspaces."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-752",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09630"
    ],
    "b_title":[
      "Chern-Simons gravitational term coupled to an isocurvature field"
    ],
    "b_abstract":[
      "The Chern-Simons gravitational term during inflation is usually coupled to\nthe inflaton field. The resulting theory suffers from ghost-field formation in\nthe tensor sector, which limits the observational effects of P-violation on\ncosmological correlators. In this work, we consider the Chern-Simons term\ncoupled to an isocurvature component in a multi-field model of inflation. Since\nthe resulting theory does not affect the quadratic action of tensor\nperturbations, ghost fields do not appear. This operator provides (P-violating)\ninteractions between the isocurvature perturbation and the curvature and tensor\nperturbations. We show that combining these couplings with interactions between\nthe curvature and isocurvature components coming from a turning trajectory, the\nresulting $\\langle sst \\rangle_{PV}$ non-Gaussianities can reach $f^{sst,\nPV}_{\\rm NL}=B_{PV}^{\\zeta\\zeta h}(k,k,k)\/P^2_{\\zeta}(k)\\sim \\mathcal O(1)$\nwithin the parameter space of the theory. Our result motivates the systematic\nstudy of the Chern-Simons gravitational term coupled to isocurvature fields in\nmulti-field models of inflation with couplings between the curvature and\nisocurvature fields or other mechanisms that transfer effects on the\nisocurvature field into the curvature field."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.06168"
    ],
    "c_title":[
      "Dynamic Pricing with Adversarially-Censored Demands"
    ],
    "c_abstract":[
      "We study an online dynamic pricing problem where the potential demand at each\ntime period $t=1,2,\\ldots, T$ is stochastic and dependent on the price.\nHowever, a perishable inventory is imposed at the beginning of each time $t$,\ncensoring the potential demand if it exceeds the inventory level. To address\nthis problem, we introduce a pricing algorithm based on the optimistic\nestimates of derivatives. We show that our algorithm achieves\n$\\tilde{O}(\\sqrt{T})$ optimal regret even with adversarial inventory series.\nOur findings advance the state-of-the-art in online decision-making problems\nwith censored feedback, offering a theoretically optimal solution against\nadversarial observations."
    ],
    "c_categories":[
      [
        "cs.LG",
        "econ.EM",
        "math.OC",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-753",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18719"
    ],
    "b_title":[
      "Enhancing Subject-Independent Accuracy in fNIRS-based Brain-Computer\n  Interfaces with Optimized Channel Selection"
    ],
    "b_abstract":[
      "Achieving high subject-independent accuracy in functional near-infrared\nspectroscopy (fNIRS)-based brain-computer interfaces (BCIs) remains a\nchallenge, particularly when minimizing the number of channels. This study\nproposes a novel feature extraction scheme and a Pearson correlation-based\nchannel selection algorithm to enhance classification accuracy while reducing\nhardware complexity. Using an open-access fNIRS dataset, our method improved\naverage accuracy by 28.09% compared to existing approaches, achieving a peak\nsubject-independent accuracy of 95.98% with only two channels. These results\ndemonstrate the potential of our optimized feature extraction and channel\nselection methods for developing efficient, subject-independent fNIRS-based BCI\nsystems."
    ],
    "b_categories":[
      [
        "cs.HC",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18335"
    ],
    "c_title":[
      "Quintessential Implications of the presence of AdS in the Dark Energy\n  sector"
    ],
    "c_abstract":[
      "We explore the implications of incorporating an Anti-de Sitter (AdS) vacua in\nthe Dark Energy (DE) sector using the recent DESI BAO measurements in\ncombination with Planck-2018 CMB, Pantheon-Plus(+SH0ES) supernovae and KiDS\nweak lensing data. We show that the presence of a {\\it Negative Cosmological\nConstant} ($\\Lambda < 0$, nCC) together with an evolving part (modelled by the\nCPL parametrisation) in DE sector allows a {\\it non-phantom} region for the DE\nin the constrained parameter space consistent with different observational\ndata. This essentially solves the problem of {\\it phantom} behaviour in the DE\nsector which is difficult to obtain through reasonable field theory. The\nimplications nCC in the DE sector for different cosmological tensions are also\nstudied. Our findings highlight the importance of the presence of AdS in the DE\nsector for theoretical model building, especially in the context of quantum\ngravity theories, e.g. string theory."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-754",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09580"
    ],
    "b_title":[
      "An Intermediate-mass Black Hole Lurking in A Galactic Halo Caught Alive\n  during Outburst"
    ],
    "b_abstract":[
      "Stellar-mass and supermassive black holes abound in the Universe, whereas\nintermediate-mass black holes (IMBHs) of ~10^2-10^5 solar masses in between are\nlargely missing observationally, with few cases found only. Here we report the\nreal-time discovery of a long-duration X-ray transient, EP240222a, accompanied\nby an optical flare with prominent H and He emission lines revealed by prompt\nfollow-up observations. Its observed properties evidence an IMBH located\nunambiguously in the halo of a nearby galaxy and flaring by tidally disrupting\na star -- the only confirmed off-nucleus IMBH-tidal disruption event so far.\nThis work demonstrates the potential of sensitive time-domain X-ray surveys,\ncomplemented by timely multi-wavelength follow-ups, in probing IMBHs, their\nenvironments, demographics, origins and connections to stellar-mass and\nsupermassive black holes."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17884"
    ],
    "c_title":[
      "A Galois-Theoretic Complexity Measure for Solving Systems of Algebraic\n  Equations"
    ],
    "c_abstract":[
      "Motivated by applications of algebraic geometry, we introduce the Galois\nwidth, a quantity characterizing the complexity of solving algebraic equations\nin a restricted model of computation allowing only field arithmetic and\nadjoining polynomial roots. We explain why practical heuristics such as\nmonodromy give (at least) lower bounds on this quantity, and discuss problems\nin geometry, optimization, statistics, and computer vision for which knowledge\nof the Galois width either leads to improvements over standard solution\ntechniques or rules out this possibility entirely."
    ],
    "c_categories":[
      [
        "cs.CC",
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-755",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03661"
    ],
    "b_title":[
      "A k-Hessian equation with a power nonlinearity source and\n  self-similarity"
    ],
    "b_abstract":[
      "We study existence and uniqueness of spherically symmetric solutions of\nS_k(D^2v)+beta xi\\cdot\\nabla v+\\alpha v+\\abs{v}^{q-1}v=0 in R^n, where\n\\alpha,\\beta are real parameters, n>2,\\, q>k\\geq 1 and S_k(D^2v) stands for the\nk-Hessian operator of v. Our results are based mainly on the analysis of an\nassociated dynamical system and energy methods. We derive some properties of\nthe solutions of the above equation for different ranges of the parameters\n\\alpha and \\beta. In particular, we describe with precision its asymptotic\nbehavior at infinity. Further, according to the position of q with respect to\nthe first critical exponent \\frac{(n+2)k}{n} and the Tso critical exponent\n\\frac{(n+2)k}{n-2k} we study the existence of three classes of solutions:\ncrossing, slow decay or fast decay solutions. In particular, if k>1 all the\nfast decay solutions have a compact support in R^n. The results also apply to\nconstruct self-similar solutions of type I to a related nonlinear evolution\nequation. These are self-similar functions of the form\nu(t,x)=t^{-\\alpha}v(xt^{-\\beta}) with suitable \\alpha and \\beta."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.08409"
    ],
    "c_title":[
      "Thermodynamic stability from Lorentzian path integrals and\n  codimension-two singularities"
    ],
    "c_abstract":[
      "It has previously been shown how the gravitational thermal partition function\ncan be obtained from a Lorentzian path integral. Unlike the Euclidean case, the\nintegration contour over Lorentzian metrics is not immediately ruled out by the\nconformal factor problem. One can then ask whether this contour can be deformed\nto pick up nontrivial contributions from various saddle points. In\nEinstein-Maxwell theory, we argue that the relevance of each black hole saddle\nto the thermal partition function depends on its thermodynamic stability\nagainst variations in energy, angular momentum, and charge. The argument\ninvolves consideration of constrained saddles where area and quantities\nassociated with angular momentum and charge are fixed on a codimension-two\nsurface. Consequently, this surface possesses not only a conical singularity,\nbut two other types of singularities. The latter are characterized by shifts\nalong the surface and along the Maxwell gauge group acquired as one winds\naround near the surface in a metric-orthogonal and connection-horizontal\nmanner. We first study this enlarged class of codimension-two singularities in\ngenerality and propose an action for singular configurations. We then\nincorporate these configurations into the path integral calculation of the\npartition function, focusing on three-dimensional spacetimes to simplify the\ntreatment of angular momentum."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-756",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18244"
    ],
    "b_title":[
      "CustomKD: Customizing Large Vision Foundation for Edge Model Improvement\n  via Knowledge Distillation"
    ],
    "b_abstract":[
      "We propose a novel knowledge distillation approach, CustomKD, that\neffectively leverages large vision foundation models (LVFMs) to enhance the\nperformance of edge models (e.g., MobileNetV3). Despite recent advancements in\nLVFMs, such as DINOv2 and CLIP, their potential in knowledge distillation for\nenhancing edge models remains underexplored. While knowledge distillation is a\npromising approach for improving the performance of edge models, the\ndiscrepancy in model capacities and heterogeneous architectures between LVFMs\nand edge models poses a significant challenge. Our observation indicates that\nalthough utilizing larger backbones (e.g., ViT-S to ViT-L) in teacher models\nimproves their downstream task performances, the knowledge distillation from\nthe large teacher models fails to bring as much performance gain for student\nmodels as for teacher models due to the large model discrepancy. Our simple yet\neffective CustomKD customizes the well-generalized features inherent in LVFMs\nto a given student model in order to reduce model discrepancies. Specifically,\nbeyond providing well-generalized original knowledge from teachers, CustomKD\naligns the features of teachers to those of students, making it easy for\nstudents to understand and overcome the large model discrepancy overall.\nCustomKD significantly improves the performances of edge models in scenarios\nwith unlabeled data such as unsupervised domain adaptation (e.g., OfficeHome\nand DomainNet) and semi-supervised learning (e.g., CIFAR-100 with 400 labeled\nsamples and ImageNet with 1% labeled samples), achieving the new\nstate-of-the-art performances."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17626"
    ],
    "c_title":[
      "Preconditioned normal equations for solving discretised partial\n  differential equations"
    ],
    "c_abstract":[
      "This paper explores preconditioning the normal equation for non-symmetric\nsquare linear systems arising from PDE discretization, focusing on methods like\nCGNE and LSQR. The concept of ``normal'' preconditioning is introduced and a\nstrategy to construct preconditioners studying the associated ``normal'' PDE is\npresented. Numerical experiments on convection-diffusion problems demonstrate\nthe effectiveness of this approach in achieving fast and stable convergence."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-757",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01425"
    ],
    "b_title":[
      "The Batch Complexity of Bandit Pure Exploration"
    ],
    "b_abstract":[
      "In a fixed-confidence pure exploration problem in stochastic multi-armed\nbandits, an algorithm iteratively samples arms and should stop as early as\npossible and return the correct answer to a query about the arms distributions.\nWe are interested in batched methods, which change their sampling behaviour\nonly a few times, between batches of observations. We give an\ninstance-dependent lower bound on the number of batches used by any sample\nefficient algorithm for any pure exploration task. We then give a general\nbatched algorithm and prove upper bounds on its expected sample complexity and\nbatch complexity. We illustrate both lower and upper bounds on best-arm\nidentification and thresholding bandits."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15519"
    ],
    "c_title":[
      "Lattice calculation of the $D_s\\mapsto X \\ell \\bar{\\nu}_\\ell$ inclusive\n  decay rate: an overview"
    ],
    "c_abstract":[
      "In this talks, on behalf of our collaboration we present an overview of our\nfirst-principle lattice QCD calculation of the $D_s\\mapsto X \\ell\n\\bar{\\nu}_\\ell$ inclusive decay rate. Here we introduce the theoretical\nbackground and focus on the methodological aspects of the calculation. A\ndetailed discussion of our results, including the comparison with the\ncorresponding experimental measurements will soon be presented in a forthcoming\npublication."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-758",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04459"
    ],
    "b_title":[
      "Rapid Automated Mapping of Clouds on Titan With Instance Segmentation"
    ],
    "b_abstract":[
      "Despite widespread adoption of deep learning models to address a variety of\ncomputer vision tasks, planetary science has yet to see extensive utilization\nof such tools to address its unique problems. On Titan, the largest moon of\nSaturn, tracking seasonal trends and weather patterns of clouds provides\ncrucial insights into one of the most complex climates in the Solar System, yet\nmuch of the available image data are still analyzed in a conventional way. In\nthis work, we apply a Mask R-CNN trained via transfer learning to perform\ninstance segmentation of clouds in Titan images acquired by the Cassini\nspacecraft - a previously unexplored approach to a big data problem in\nplanetary science. We demonstrate that an automated technique can provide\nquantitative measures for clouds, such as areas and centroids, that may\notherwise be prohibitively time-intensive to produce by human mapping.\nFurthermore, despite Titan specific challenges, our approach yields accuracy\ncomparable to contemporary cloud identification studies on Earth and other\nworlds. We compare the efficiencies of human-driven versus algorithmic\napproaches, showing that transfer learning provides speed-ups that may open new\nhorizons for data investigation for Titan. Moreover, we suggest that such\napproaches have broad potential for application to similar problems in\nplanetary science where they are currently under-utilized. Future planned\nmissions to the planets and remote sensing initiatives for the Earth promise to\nprovide a deluge of image data in the coming years that will benefit strongly\nfrom leveraging machine learning approaches to perform the analysis."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07425"
    ],
    "c_title":[
      "CATPlan: Loss-based Collision Prediction in End-to-End Autonomous\n  Driving"
    ],
    "c_abstract":[
      "In recent years, there has been increased interest in the design, training,\nand evaluation of end-to-end autonomous driving (AD) systems. One often\noverlooked aspect is the uncertainty of planned trajectories predicted by these\nsystems, despite awareness of their own uncertainty being key to achieve safety\nand robustness. We propose to estimate this uncertainty by adapting loss\nprediction from the uncertainty quantification literature. To this end, we\nintroduce a novel light-weight module, dubbed CATPlan, that is trained to\ndecode motion and planning embeddings into estimates of the collision loss used\nto partially supervise end-to-end AD systems. During inference, these estimates\nare interpreted as collision risk. We evaluate CATPlan on the safety-critical,\nnerf-based, closed-loop benchmark NeuroNCAP and find that it manages to detect\ncollisions with a $54.8\\%$ relative improvement to average precision over a\nGMM-based baseline in which the predicted trajectory is compared to the\nforecasted trajectories of other road users. Our findings indicate that the\naddition of CATPlan can lead to safer end-to-end AD systems and hope that our\nwork will spark increased interest in uncertainty quantification for such\nsystems."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-759",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17085"
    ],
    "b_title":[
      "Deterministic AI Agent Personality Expression through Standard\n  Psychological Diagnostics"
    ],
    "b_abstract":[
      "Artificial intelligence (AI) systems powered by large language models have\nbecome increasingly prevalent in modern society, enabling a wide range of\napplications through natural language interaction. As AI agents proliferate in\nour daily lives, their generic and uniform expressiveness presents a\nsignificant limitation to their appeal and adoption. Personality expression\nrepresents a key prerequisite for creating more human-like and distinctive AI\nsystems. We show that AI models can express deterministic and consistent\npersonalities when instructed using established psychological frameworks, with\nvarying degrees of accuracy depending on model capabilities. We find that more\nadvanced models like GPT-4o and o1 demonstrate the highest accuracy in\nexpressing specified personalities across both Big Five and Myers-Briggs\nassessments, and further analysis suggests that personality expression emerges\nfrom a combination of intelligence and reasoning capabilities. Our results\nreveal that personality expression operates through holistic reasoning rather\nthan question-by-question optimization, with response-scale metrics showing\nhigher variance than test-scale metrics. Furthermore, we find that model\nfine-tuning affects communication style independently of personality expression\naccuracy. These findings establish a foundation for creating AI agents with\ndiverse and consistent personalities, which could significantly enhance\nhuman-AI interaction across applications from education to healthcare, while\nadditionally enabling a broader range of more unique AI agents. The ability to\nquantitatively assess and implement personality expression in AI systems opens\nnew avenues for research into more relatable, trustworthy, and ethically\ndesigned AI."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08256"
    ],
    "c_title":[
      "Convergence of projected stochastic approximation algorithm"
    ],
    "c_abstract":[
      "We study the Robbins-Monro stochastic approximation algorithm with\nprojections on a hyperrectangle and prove its convergence. This work fills a\ngap in the convergence proof of the classic book by Kushner and Yin. Using the\nODE method, we show that the algorithm converges to stationary points of a\nrelated projected ODE. Our results provide a better theoretical foundation for\nstochastic optimization techniques, including stochastic gradient descent and\nits proximal version. These results extend the algorithm's applicability and\nrelax some assumptions of previous research."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-760",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01550"
    ],
    "b_title":[
      "Dynamic realization of emergent high-dimensional optical vortices"
    ],
    "b_abstract":[
      "The dimensionality of vortical structures has recently been extended beyond\ntwo dimensions, providing higher-order topological characteristics and\nrobustness for high-capacity information processing and turbulence control. The\ngeneration of high-dimensional vortical structures has mostly been demonstrated\nin classical systems through the complex interference of fluidic, acoustic, or\nelectromagnetic waves. However, natural materials rarely support three- or\nhigher-dimensional vortical structures and their physical interactions. Here,\nwe present a high-dimensional gradient thickness optical cavity (GTOC) in which\nthe optical coupling of planar metal-dielectric multilayers implements\ntopological interactions across multiple dimensions. Topological interactions\nin high-dimensional GTOC construct non-trivial topological phases, which induce\nhigh-dimensional vortical structures in generalized parameter space in three,\nfour dimensions, and beyond. These emergent high-dimensional vortical\nstructures are observed under electro-optic tomography as optical vortex\ndynamics in two-dimensional real-space, employing the optical thicknesses of\nthe dielectric layers as synthetic dimensions. We experimentally demonstrate\nemergent vortical structures, optical vortex lines and vortex rings, in a\nthree-dimensional generalized parameter space and their topological\ntransitions. Furthermore, we explore four-dimensional vortical structures,\ntermed optical vortex sheets, which provide the programmability of real-space\noptical vortex dynamics. Our findings hold significant promise for emulating\nhigh-dimensional physics and developing active topological photonic devices."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00084"
    ],
    "c_title":[
      "A uniform rate of convergence for the entropic potentials in the\n  quadratic Euclidean setting"
    ],
    "c_abstract":[
      "We bound the rate of uniform convergence in compact sets for both entropic\npotentials and their gradients towards the Brenier potential and its gradient,\nrespectively. Both results hold in the quadratic Euclidean setting for\nabsolutely continuous measures satisfying some convexity assumptions."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.CA",
        "math.OC",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-761",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12040"
    ],
    "b_title":[
      "On the distribution of $t$-hooks of doubled distinct partitions"
    ],
    "b_abstract":[
      "Recently, Griffin, Ono, and Tsai examined the distribution of the number of\n$t$-hooks in partitions of $n$, which was later followed by the work of Craig,\nOno, and Singh on the distribution of the number of $t$-hooks in self-conjugate\npartitions of $n$. Motivated by these studies, in this paper, we further\ninvestigate the number of $t$-hooks in some subsets of partitions. More\nspecifically, we obtain the generating functions for the number of $t$-hooks in\ndoubled distinct partitions and the number of $t$-shifted hooks in strict\npartitions. Based on these generating functions, we prove that the number of\n$t$-hooks in doubled distinct partitions and the number of $t$-shifted hooks in\nstrict partitions are both asymptotically normally distributed."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.06865"
    ],
    "c_title":[
      "Deep Ritz method with Fourier feature mapping: A deep learning approach\n  for solving variational models of microstructure"
    ],
    "c_abstract":[
      "This paper presents a novel approach that combines the Deep Ritz Method (DRM)\nwith Fourier feature mapping to solve minimization problems comprised of\nmulti-well, non-convex energy potentials. These problems present computational\nchallenges as they lack a global minimum. Through an investigation of three\nbenchmark problems in both 1D and 2D, we observe that DRM suffers from spectral\nbias pathology, limiting its ability to learn solutions with high frequencies.\nTo overcome this limitation, we modify the method by introducing Fourier\nfeature mapping. This modification involves applying a Fourier mapping to the\ninput layer before it passes through the hidden and output layers. Our results\ndemonstrate that Fourier feature mapping enables DRM to generate\nhigh-frequency, multiscale solutions for the benchmark problems in both 1D and\n2D, offering a promising advancement in tackling complex non-convex energy\nminimization problems."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-762",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12987"
    ],
    "b_title":[
      "Solving unbounded optimal control problems with the moment-SOS hierarchy\n  *"
    ],
    "b_abstract":[
      "The behaviour of the moment-sums-of-squares (moment-SOS) hierarchy for\npolynomial optimal control problems on compact sets has been explored to a\nlarge extent. Our contribution focuses on the case of non-compact control sets.\nWe describe a new approach to optimal control problems with unbounded controls,\nusing compactification by partial homogenization, leading to an equivalent\ninfinite dimensional linear program with compactly supported measures. Our\nresults are closely related to the results of a previous approach using\nDiPerna-Majda measures. However, our work provides a sound proof of the absence\nof relaxation gap, which was conjectured in the previous work, and thereby\nenables the design of a moment-sum-of-squares relaxation with guaranteed\nconvergence."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.11570"
    ],
    "c_title":[
      "Additive Manufacturing for Advanced Quantum Technologies"
    ],
    "c_abstract":[
      "The development of quantum technology has opened up exciting opportunities to\nrevolutionize computing and communication, timing and navigation systems,\nenable non-invasive imaging of the human body, and probe fundamental physics\nwith unprecedented precision. Alongside these advancements has come an increase\nin experimental complexity and a correspondingly greater dependence on compact,\nefficient and reliable hardware. The drive to move quantum technologies from\nlaboratory prototypes to portable, real-world instruments has incentivized\nminiaturization of experimental systems relating to a strong demand for\nsmaller, more robust and less power-hungry quantum hardware and for\nincreasingly specialized and intricate components. Additive manufacturing,\nalready heralded as game-changing for many manufacturing sectors, is especially\nwell-suited to this task owing to the comparatively large amount of design\nfreedom it enables and its ability to produce intricate three-dimensional forms\nand specialized components. Herein we review work conducted to date on the\napplication of additive manufacturing to quantum technologies, discuss the\ncurrent state of the art in additive manufacturing in optics, optomechanics,\nmagnetic components and vacuum equipment, and consider pathways for future\nadvancement. We also give an overview of the research and application areas\nmost likely to be impacted by the deployment of additive manufacturing\ntechniques within the quantum technology sector."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-763",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13481"
    ],
    "b_title":[
      "LLM4Tag: Automatic Tagging System for Information Retrieval via Large\n  Language Models"
    ],
    "b_abstract":[
      "Tagging systems play an essential role in various information retrieval\napplications such as search engines and recommender systems. Recently, Large\nLanguage Models (LLMs) have been applied in tagging systems due to their\nextensive world knowledge, semantic understanding, and reasoning capabilities.\nDespite achieving remarkable performance, existing methods still have\nlimitations, including difficulties in retrieving relevant candidate tags\ncomprehensively, challenges in adapting to emerging domain-specific knowledge,\nand the lack of reliable tag confidence quantification. To address these three\nlimitations above, we propose an automatic tagging system LLM4Tag. First, a\ngraph-based tag recall module is designed to effectively and comprehensively\nconstruct a small-scale highly relevant candidate tag set. Subsequently, a\nknowledge-enhanced tag generation module is employed to generate accurate tags\nwith long-term and short-term knowledge injection. Finally, a tag confidence\ncalibration module is introduced to generate reliable tag confidence scores.\nExtensive experiments over three large-scale industrial datasets show that\nLLM4Tag significantly outperforms the state-of-the-art baselines and LLM4Tag\nhas been deployed online for content tagging to serve hundreds of millions of\nusers."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.15347"
    ],
    "c_title":[
      "Nonstandard Large and Moderate Deviations for the Laguerre Ensemble"
    ],
    "c_abstract":[
      "In this paper, we show limit theorems for the weighted spectral measure of\nthe Laguerre ensemble under a nonstandard scaling, when the parameter grows\nfaster than the matrix size. For this parameter scaling, the limit behavior is\nsimilar to the case of the Gaussian ensemble. We show a large deviation\nprinciple, moderate deviations and a CLT for the spectral measure. For the\nmoderate deviations and the CLT, we observe a particular dependence on the rate\nof the parameter and a corrective shift by a signed measure. The proofs are\nbased on the tridiagonal representation of the Laguerre ensemble."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-764",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.21288"
    ],
    "b_title":[
      "The Grothendieck construction for delta lenses"
    ],
    "b_abstract":[
      "Delta lenses are functors equipped with a functorial choice of lifts,\ngeneralising the notion of split opfibration. In this paper, we introduce a\nGrothendieck construction (or category of elements) for delta lenses, thus\ndemonstrating a correspondence between delta lenses and certain lax double\nfunctors into the double category of sets, functions, and split multivalued\nfunctions. We show that the double category of split multivalued functions\nadmits a universal property as a certain kind of limit, and inherits many nice\nproperties from the double category of spans. Applications of this construction\nto the theory of delta lenses are explored in detail."
    ],
    "b_categories":[
      [
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.04594"
    ],
    "c_title":[
      "VLBA Detections in the Oph-S1 Binary System near Periastron Confirmation\n  of its Orbital Elements and Mass"
    ],
    "c_abstract":[
      "Oph-S1 is the most luminous and massive stellar member of the nearby\nOphiuchus star-forming region. Previous Very Long Baseline Array (VLBA)\nobservations have shown it to be an intermediate-mass binary system ($\\sim\n5\\,{\\rm M}_\\odot$) with an orbital period of about 21 months, but a paucity of\nradio detections of the secondary near periastron could potentially have\naffected the determination of its orbital parameters. Here, we present nine new\nVLBA observations of Oph-S1 focused on its periastron passage in early 2024. We\ndetect the primary in all observations and the secondary at five epochs,\nincluding three within about a month of periastron passage. The updated orbit,\ndetermined by combining our new data with 35 previous observations, agrees well\nwith previous calculations and yields masses of $4.115 \\pm0.039 \\,{\\rm\nM}_\\odot$ and $0.814\\pm0.006 \\,{\\rm M}_\\odot$ for the two stars in the system."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-765",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08671"
    ],
    "b_title":[
      "Color Universal Design Neural Network for the Color Vision Deficiencies"
    ],
    "b_abstract":[
      "Information regarding images should be visually understood by anyone,\nincluding those with color deficiency. However, such information is not\nrecognizable if the color that seems to be distorted to the color deficiencies\nmeets an adjacent object. The aim of this paper is to propose a color universal\ndesign network, called CUD-Net, that generates images that are visually\nunderstandable by individuals with color deficiency. CUD-Net is a convolutional\ndeep neural network that can preserve color and distinguish colors for input\nimages by regressing the node point of a piecewise linear function and using a\nspecific filter for each image. To generate CUD images for color deficiencies,\nwe follow a four-step process. First, we refine the CUD dataset based on\nspecific criteria by color experts. Second, we expand the input image\ninformation through pre-processing that is specialized for color deficiency\nvision. Third, we employ a multi-modality fusion architecture to combine\nfeatures and process the expanded images. Finally, we propose a conjugate loss\nfunction based on the composition of the predicted image through the model to\naddress one-to-many problems that arise from the dataset. Our approach is able\nto produce high-quality CUD images that maintain color and contrast stability.\nThe code for CUD-Net is available on the GitHub repository"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12299"
    ],
    "c_title":[
      "Dual Murnaghan-Nakayama rule for Hecke algebras in Type $A$"
    ],
    "c_abstract":[
      "Let $\\chi^{\\lambda}_{\\mu}$ be the value of the irreducible character\n$\\chi^{\\lambda}$ of the Hecke algebra of the symmetric group on the conjugacy\nclass of type $\\mu$. The usual Murnaghan-Nakayama rule provides an iterative\nalgorithm based on reduction of the lower partition $\\mu$. In this paper, we\nestablish a dual Murnaghan-Nakayama rule for Hecke algebras of type $A$ using\nvertex operators by applying reduction to the upper partition $\\lambda$. We\nformulate an explicit recursion of the dual Murnaghan-Nakayama rule by\nemploying the combinatorial model of ``brick tabloids\", which refines a\nprevious result by two of us (J. Algebra 598 (2022), 24--47)."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.QA",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-766",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08234"
    ],
    "b_title":[
      "Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement\n  Learning"
    ],
    "b_abstract":[
      "This paper addresses a critical challenge in the high-speed passenger railway\nindustry: designing effective dynamic pricing strategies in the context of\ncompeting and cooperating operators. To address this, a multi-agent\nreinforcement learning (MARL) framework based on a non-zero-sum Markov game is\nproposed, incorporating random utility models to capture passenger decision\nmaking. Unlike prior studies in areas such as energy, airlines, and mobile\nnetworks, dynamic pricing for railway systems using deep reinforcement learning\nhas received limited attention. A key contribution of this paper is a\nparametrisable and versatile reinforcement learning simulator designed to model\na variety of railway network configurations and demand patterns while enabling\nrealistic, microscopic modelling of user behaviour, called RailPricing-RL. This\nenvironment supports the proposed MARL framework, which models heterogeneous\nagents competing to maximise individual profits while fostering cooperative\nbehaviour to synchronise connecting services. Experimental results validate the\nframework, demonstrating how user preferences affect MARL performance and how\npricing policies influence passenger choices, utility, and overall system\ndynamics. This study provides a foundation for advancing dynamic pricing\nstrategies in railway systems, aligning profitability with system-wide\nefficiency, and supporting future research on optimising pricing policies."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17942"
    ],
    "c_title":[
      "Hybridization of colloidal handlebodies with singular defects and\n  topological solitons in chiral liquid crystals"
    ],
    "c_abstract":[
      "Topology can manifest itself in colloids when quantified by invariants like\nEuler characteristics of nonzero-genus colloidal surfaces, albeit spherical\ncolloidal particles are most often studied, and colloidal particles with\ncomplex topology are rarely considered. On the other hand, singular defects and\ntopological solitons often define the physical behavior of the molecular\nalignment director fields in liquid crystals. Interestingly, nematic liquid\ncrystalline dispersions of colloidal particles allow for probing the interplay\nbetween topologies of surfaces and fields, but only a limited number of such\ncases have been explored so far. Here, we study the hybridization of\ntopological solitons, singular defects, and topologically nontrivial colloidal\nparticles with the genus of surfaces different from zero in a chiral nematic\nliquid crystal phase. Hybridization occurs when distortions separately induced\nby colloidal particles and LC solitons overlap, leading to energy\nminimization-driven redistribution of director field deformations and defects.\nAs a result, hybrid director configurations emerge, combining topological\nfeatures from both components. We uncover a host of director field\nconfigurations complying with topological theorems, which can be controlled by\napplying electric fields. Rotational and translational dynamics arise due to\nthe nonreciprocal evolution of the director fields in response to alternating\nelectric fields of different frequencies. These findings help define a platform\nfor controlling topologically hyper-complex colloidal structures and dynamics\nwith electrically reconfigurable singular defects and topological solitons\ninduced by colloidal handlebodies."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-767",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07856"
    ],
    "b_title":[
      "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE\n  Solvers"
    ],
    "b_abstract":[
      "In applications of diffusion models, controllable generation is of practical\nsignificance, but is also challenging. Current methods for controllable\ngeneration primarily focus on modifying the score function of diffusion models,\nwhile Mean Reverting (MR) Diffusion directly modifies the structure of the\nstochastic differential equation (SDE), making the incorporation of image\nconditions simpler and more natural. However, current training-free fast\nsamplers are not directly applicable to MR Diffusion. And thus MR Diffusion\nrequires hundreds of NFEs (number of function evaluations) to obtain\nhigh-quality samples. In this paper, we propose a new algorithm named MaRS (MR\nSampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time\nSDE and the probability flow ordinary differential equation (PF-ODE) associated\nwith MR Diffusion, and derive semi-analytical solutions. The solutions consist\nof an analytical function and an integral parameterized by a neural network.\nBased on this solution, we can generate high-quality samples in fewer steps.\nOur approach does not require training and supports all mainstream\nparameterizations, including noise prediction, data prediction and velocity\nprediction. Extensive experiments demonstrate that MR Sampler maintains high\nsampling quality with a speedup of 10 to 20 times across ten different image\nrestoration tasks. Our algorithm accelerates the sampling procedure of MR\nDiffusion, making it more practical in controllable generation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.16580"
    ],
    "c_title":[
      "Procrustes Wasserstein Metric: A Modified Benamou-Brenier Approach with\n  Applications to Latent Gaussian Distributions"
    ],
    "c_abstract":[
      "We introduce a modified Benamou-Brenier type approach leading to a\nWasserstein type distance that allows global invariance, specifically,\nisometries, and we show that the problem can be summarized to orthogonal\ntransformations. This distance is defined by penalizing the action with a\ncostless movement of the particle that does not change the direction and speed\nof its trajectory. We show that for Gaussian distribution resume to measuring\nthe Euclidean distance between their ordered vector of eigenvalues and we show\na direct application in recovering Latent Gaussian distributions."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC",
        "math.PR",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-768",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02414"
    ],
    "b_title":[
      "InfoGNN: End-to-end deep learning on mesh via graph neural networks"
    ],
    "b_abstract":[
      "3D models are widely used in various industries, and mesh data has become an\nindispensable part of 3D modeling because of its unique advantages. Mesh data\ncan provide an intuitive and practical expression of rich 3D information.\nHowever, its disordered, irregular data structure and complex surface\ninformation make it challenging to apply with deep learning models directly.\nTraditional mesh data processing methods often rely on mesh models with many\nlimitations, such as manifold, which restrict their application scopes in\nreality and do not fully utilize the advantages of mesh models. This paper\nproposes a novel end-to-end framework for addressing the challenges associated\nwith deep learning in mesh models centered around graph neural networks (GNN)\nand is titled InfoGNN. InfoGNN treats the mesh model as a graph, which enables\nit to handle irregular mesh data efficiently. Moreover, we propose InfoConv and\nInfoMP modules, which utilize the position information of the points and fully\nuse the static information such as face normals, dihedral angles, and dynamic\nglobal feature information to fully use all kinds of data. In addition, InfoGNN\nis an end-to-end framework, and we simplify the network design to make it more\nefficient, paving the way for efficient deep learning of complex 3D models. We\nconducted experiments on several publicly available datasets, and the results\nshow that InfoGNN achieves excellent performance in mesh classification and\nsegmentation tasks."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08747"
    ],
    "c_title":[
      "Every group is the automorphism group of a graph with arbitrarily large\n  genus"
    ],
    "c_abstract":[
      "We prove that, to every abstract group $G$, we can associate a sequence of\ngraphs $\\Gamma_n$ such that the automorphism group of $\\Gamma_n$ is isomorphic\nto $G$ and the genus of $\\Gamma_n$ is an unbounded function of $n$."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-769",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06830"
    ],
    "b_title":[
      "OrderFusion: Encoding Orderbook for Probabilistic Intraday Price\n  Prediction"
    ],
    "b_abstract":[
      "Efficient and reliable probabilistic prediction of intraday electricity\nprices is essential to manage market uncertainties and support robust trading\nstrategies. However, current methods often suffer from parameter\ninefficiencies, as they fail to fully exploit the potential of modeling\ninterdependencies between bids and offers in the orderbook, requiring a large\nnumber of parameters for representation learning. Furthermore, these methods\nface the quantile crossing issue, where upper quantiles fall below the lower\nquantiles, resulting in unreliable probabilistic predictions. To address these\ntwo challenges, we propose an encoding method called OrderFusion and design a\nhierarchical multi-quantile head. The OrderFusion encodes the orderbook into a\n2.5D representation, which is processed by a tailored jump cross-attention\nbackbone to capture the interdependencies of bids and offers, enabling\nparameter-efficient learning. The head sets the median quantile as an anchor\nand predicts multiple quantiles hierarchically, ensuring reliability by\nenforcing monotonicity between quantiles through non-negative functions.\nExtensive experiments and ablation studies are conducted on four price indices:\n60-min ID3, 60-min ID1, 15-min ID3, and 15-min ID1 using the German orderbook\nover three years to ensure a fair evaluation. The results confirm that our\ndesign choices improve overall performance, offering a parameter-efficient and\nreliable solution for probabilistic intraday price prediction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.06060"
    ],
    "c_title":[
      "Training Language Models for Social Deduction with Multi-Agent\n  Reinforcement Learning"
    ],
    "c_abstract":[
      "Communicating in natural language is a powerful tool in multi-agent settings,\nas it enables independent agents to share information in partially observable\nsettings and allows zero-shot coordination with humans. However, most prior\nworks are limited as they either rely on training with large amounts of human\ndemonstrations or lack the ability to generate natural and useful communication\nstrategies. In this work, we train language models to have productive\ndiscussions about their environment in natural language without any human\ndemonstrations. We decompose the communication problem into listening and\nspeaking. Our key idea is to leverage the agent's goal to predict useful\ninformation about the world as a dense reward signal that guides communication.\nSpecifically, we improve a model's listening skills by training them to predict\ninformation about the environment based on discussions, and we simultaneously\nimprove a model's speaking skills with multi-agent reinforcement learning by\nrewarding messages based on their influence on other agents. To investigate the\nrole and necessity of communication in complex social settings, we study an\nembodied social deduction game based on Among Us, where the key question to\nanswer is the identity of an adversarial imposter. We analyze emergent\nbehaviors due to our technique, such as accusing suspects and providing\nevidence, and find that it enables strong discussions, doubling the win rates\ncompared to standard RL. We release our code and models at\nhttps:\/\/socialdeductionllm.github.io\/"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-770",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11864"
    ],
    "b_title":[
      "LLM-Agents Driven Automated Simulation Testing and Analysis of small\n  Uncrewed Aerial Systems"
    ],
    "b_abstract":[
      "Thorough simulation testing is crucial for validating the correct behavior of\nsmall Uncrewed Aerial Systems (sUAS) across multiple scenarios, including\nadverse weather conditions (such as wind, and fog), diverse settings (hilly\nterrain, or urban areas), and varying mission profiles (surveillance,\ntracking). While various sUAS simulation tools exist to support developers, the\nentire process of creating, executing, and analyzing simulation tests remains a\nlargely manual and cumbersome task. Developers must identify test scenarios,\nset up the simulation environment, integrate the System under Test (SuT) with\nsimulation tools, formulate mission plans, and collect and analyze results.\nThese labor-intensive tasks limit the ability of developers to conduct\nexhaustive testing across a wide range of scenarios. To alleviate this problem,\nin this paper, we propose AutoSimTest, a Large Language Model (LLM)-driven\nframework, where multiple LLM agents collaborate to support the sUAS simulation\ntesting process. This includes: (1) creating test scenarios that subject the\nSuT to unique environmental contexts; (2) preparing the simulation environment\nas per the test scenario; (3) generating diverse sUAS missions for the SuT to\nexecute; and (4) analyzing simulation results and providing an interactive\nanalytics interface. Further, the design of the framework is flexible for\ncreating and testing scenarios for a variety of sUAS use cases, simulation\ntools, and SuT input requirements. We evaluated our approach by (a) conducting\nsimulation testing of PX4 and ArduPilot flight-controller-based SuTs, (b)\nanalyzing the performance of each agent, and (c) gathering feedback from sUAS\ndevelopers. Our findings indicate that AutoSimTest significantly improves the\nefficiency and scope of the sUAS testing process, allowing for more\ncomprehensive and varied scenario evaluations while reducing the manual effort."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18599"
    ],
    "c_title":[
      "The NANOGrav 15-year Data Set: Search for Gravitational Wave Memory"
    ],
    "c_abstract":[
      "We present the results of a search for nonlinear gravitational wave memory in\nthe NANOGrav 15-year data set. We find no significant evidence for memory\nsignals in the dataset, with a maximum Bayes factor of 3.1 in favor of a model\nincluding memory. We therefore place upper limits on the strain of potential\ngravitational wave memory events as a function of sky location and observing\nepoch. We find upper limits that are not always more constraining than previous\nNANOGrav results. We show that it is likely due to the increase in common red\nnoise between the 12.5-year and 15-year NANOGrav datasets."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-771",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18422"
    ],
    "b_title":[
      "Quantum States from Minimal Surfaces"
    ],
    "b_abstract":[
      "Apart from relating interesting quantum mechanical systems to equations\ndescribing a parabolic discrete minimal surface, the quantization of a cubic\nminimal surface in $\\mathbb{R}^4$ is considered."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.03563"
    ],
    "c_title":[
      "Page Curve and Entanglement Dynamics in an Interacting Fermionic Chain"
    ],
    "c_abstract":[
      "Generic non-equilibrium many-body systems display a linear growth of\nbipartite entanglement entropy in time, followed by a volume law saturation. In\nstark contrast, the Page curve dynamics of black hole physics shows that the\nentropy peaks at the Page time $t_{\\text{Page}}$ and then decreases to zero.\nHere, we investigate such Page-like behavior of the von Neumann entropy in a\nmodel of strongly correlated spinless fermions in a typical system-environment\nsetup, and characterize the properties of the Page curve dynamics in the\npresence of interactions using numerically exact matrix product states methods.\nThe two phases of growth, namely the linear growth and the bending down, are\nshown to be separated by a non-analyticity in the min-entropy before\n$t_{\\text{Page}}$, which separates two different quantum phases, realized as\nthe respective ground states of the corresponding entanglement (or\nequivalently, modular) Hamiltonian. We confirm and generalize, by introducing\ninteractions, the findings of\n\\href{https:\/\/journals.aps.org\/prb\/abstract\/10.1103\/PhysRevB.109.224308}{Phys.\nRev. B 109, 224308 (2024)} for a free spinless fermionic chain where the\ncorresponding entanglement Hamiltonian undergoes a quantum phase transition at\nthe point of non-analyticity. However, in the presence of interactions, a\nscaling analysis gives a non-zero critical time for the non-analyticity in the\nthermodynamic limit only for weak to intermediate interaction strengths, while\nthe dynamics leading to the non-analyticity becomes \\textit{instantaneous} for\ninteractions large enough. We present a physical picture explaining these\nfindings."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-772",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08007"
    ],
    "b_title":[
      "MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped\n  Vision-Language-Action Models"
    ],
    "b_abstract":[
      "Developing versatile quadruped robots that can smoothly perform various\nactions and tasks in real-world environments remains a significant challenge.\nThis paper introduces a novel vision-language-action (VLA) model, mixture of\nrobotic experts (MoRE), for quadruped robots that aim to introduce\nreinforcement learning (RL) for fine-tuning large-scale VLA models with a large\namount of mixed-quality data. MoRE integrates multiple low-rank adaptation\nmodules as distinct experts within a dense multi-modal large language model\n(MLLM), forming a sparse-activated mixture-of-experts model. This design\nenables the model to effectively adapt to a wide array of downstream tasks.\nMoreover, we employ a reinforcement learning-based training objective to train\nour model as a Q-function after deeply exploring the structural properties of\nour tasks. Effective learning from automatically collected mixed-quality data\nenhances data efficiency and model performance. Extensive experiments\ndemonstrate that MoRE outperforms all baselines across six different skills and\nexhibits superior generalization capabilities in out-of-distribution scenarios.\nWe further validate our method in real-world scenarios, confirming the\npracticality of our approach and laying a solid foundation for future research\non multi-task learning in quadruped robots."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20966"
    ],
    "c_title":[
      "Post-Hoc Uncertainty Quantification in Pre-Trained Neural Networks via\n  Activation-Level Gaussian Processes"
    ],
    "c_abstract":[
      "Uncertainty quantification in neural networks through methods such as\nDropout, Bayesian neural networks and Laplace approximations is either prone to\nunderfitting or computationally demanding, rendering these approaches\nimpractical for large-scale datasets. In this work, we address these\nshortcomings by shifting the focus from uncertainty in the weight space to\nuncertainty at the activation level, via Gaussian processes. More specifically,\nwe introduce the Gaussian Process Activation function (GAPA) to capture\nneuron-level uncertainties. Our approach operates in a post-hoc manner,\npreserving the original mean predictions of the pre-trained neural network and\nthereby avoiding the underfitting issues commonly encountered in previous\nmethods. We propose two methods. The first, GAPA-Free, employs empirical kernel\nlearning from the training data for the hyperparameters and is highly efficient\nduring training. The second, GAPA-Variational, learns the hyperparameters via\ngradient descent on the kernels, thus affording greater flexibility. Empirical\nresults demonstrate that GAPA-Variational outperforms the Laplace approximation\non most datasets in at least one of the uncertainty quantification metrics."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-773",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10722"
    ],
    "b_title":[
      "PMU-Data: Data Traces Could be Distinguished"
    ],
    "b_abstract":[
      "Modern processors widely equip the Performance Monitoring Unit (PMU) to\ncollect various architecture and microarchitecture events. Software developers\noften utilize the PMU to enhance program's performance, but the potential side\neffects that arise from its activation are often disregarded. In this paper, we\nfind that the PMU can be employed to retrieve instruction operands. Based on\nthis discovery, we introduce PMU-Data, a novel category of side-channel attacks\naimed at leaking secret by identifying instruction operands with PMU.\n  To achieve the PMU-Data attack, we develop five gadgets to encode the\nconfidential data into distinct data-related traces while maintaining the\ncontrol-flow unchanged. We then measure all documented PMU events on three\nphysical machines with different processors while those gadgets are performing.\nWe successfully identify two types of vulnerable gadgets caused by DIV and MOV\ninstructions. Additionally, we discover 40 vulnerable PMU events that can be\nused to carry out the PMU-Data attack. We through real experiments to\ndemonstrate the perniciousness of the PMU-Data attack by implementing three\nattack goals: (1) leaking the kernel data illegally combined with the transient\nexecution vulnerabilities including Meltdown, Spectre, and Zombieload; (2)\nbuilding a covert-channel to secretly transfer data; (3) extracting the secret\ndata protected by the Trusted Execution Environment (TEE) combined with the\nZombieload vulnerability."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05938"
    ],
    "c_title":[
      "Uncertainty Quantification From Scaling Laws in Deep Neural Networks"
    ],
    "c_abstract":[
      "Quantifying the uncertainty from machine learning analyses is critical to\ntheir use in the physical sciences. In this work we focus on uncertainty\ninherited from the initialization distribution of neural networks. We compute\nthe mean $\\mu_{\\mathcal{L}}$ and variance $\\sigma_{\\mathcal{L}}^2$ of the test\nloss $\\mathcal{L}$ for an ensemble of multi-layer perceptrons (MLPs) with\nneural tangent kernel (NTK) initialization in the infinite-width limit, and\ncompare empirically to the results from finite-width networks for three example\ntasks: MNIST classification, CIFAR classification and calorimeter energy\nregression. We observe scaling laws as a function of training set size\n$N_\\mathcal{D}$ for both $\\mu_{\\mathcal{L}}$ and $\\sigma_{\\mathcal{L}}$, but\nfind that the coefficient of variation $\\epsilon_{\\mathcal{L}} \\equiv\n\\sigma_{\\mathcal{L}}\/\\mu_{\\mathcal{L}}$ becomes independent of $N_\\mathcal{D}$\nat both infinite and finite width for sufficiently large $N_\\mathcal{D}$. This\nimplies that the coefficient of variation of a finite-width network may be\napproximated by its infinite-width value, and may in principle be calculable\nusing finite-width perturbation theory."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "hep-ex",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-774",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13664"
    ],
    "b_title":[
      "Dynamics of defects and interfaces for interacting quantum hard disks"
    ],
    "b_abstract":[
      "Defects and interfaces are essential to understand the properties of matter.\nHowever, studying their dynamics in the quantum regime remains a challenge in\nparticular concerning the regime of two spatial dimensions. Recently, it has\nbeen shown that a quantum counterpart of the hard-disk problem on a lattice\nyields defects and interfaces, which are stable just due to quantum effects\nwhile they delocalize and dissolve classically. Here, we study in more detail\nthe properties of defects and interfaces in this quantum hard-disk problem with\na particular emphasis on the stability of these quantum effects upon including\nperturbations. Specifically, we introduce short-range soft-core interactions\nbetween the hard disks. From both analytical arguments and numerical\nsimulations we find that large classes of defects and interfaces remain stable\neven under such perturbations suggesting that the quantum nature of the\ndynamics exhibits a large range of robustness. Our findings demonstrate the\nstability and non-classical behavior of quantum interface dynamics, offering\ninsights into the dynamics of two-dimensional quantum matter and establishing\nthe quantum hard-disk model as a platform for studying unconventional\nconstrained quantum dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.09592"
    ],
    "c_title":[
      "Parsing the Language of Expression: Enhancing Symbolic Regression with\n  Domain-Aware Symbolic Priors"
    ],
    "c_abstract":[
      "Symbolic regression is essential for deriving interpretable expressions that\nelucidate complex phenomena by exposing the underlying mathematical and\nphysical relationships in data. In this paper, we present an advanced symbolic\nregression method that integrates symbol priors from diverse scientific domains\n- including physics, biology, chemistry, and engineering - into the regression\nprocess. By systematically analyzing domain-specific expressions, we derive\nprobability distributions of symbols to guide expression generation. We propose\nnovel tree-structured recurrent neural networks (RNNs) that leverage these\nsymbol priors, enabling domain knowledge to steer the learning process.\nAdditionally, we introduce a hierarchical tree structure for representing\nexpressions, where unary and binary operators are organized to facilitate more\nefficient learning. To further accelerate training, we compile characteristic\nexpression blocks from each domain and include them in the operator dictionary,\nproviding relevant building blocks. Experimental results demonstrate that\nleveraging symbol priors significantly enhances the performance of symbolic\nregression, resulting in faster convergence and higher accuracy."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-775",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04742"
    ],
    "b_title":[
      "Meta-learning-based percussion transcription and $t\\bar{a}la$\n  identification from low-resource audio"
    ],
    "b_abstract":[
      "This study introduces a meta-learning-based approach for low-resource Tabla\nStroke Transcription (TST) and $t\\bar{a}la$ identification in Hindustani\nclassical music. Using Model-Agnostic Meta-Learning (MAML), we address the\nchallenge of limited annotated datasets, enabling rapid adaptation to new tasks\nwith minimal data. The method is validated across various datasets, including\ntabla solo and concert recordings, demonstrating robustness in polyphonic audio\nscenarios. We propose two novel $t\\bar{a}la$ identification techniques based on\nstroke sequences and rhythmic patterns. Additionally, the approach proves\neffective for Automatic Drum Transcription (ADT), showcasing its flexibility\nfor Indian and Western percussion music. Experimental results show that the\nproposed method outperforms existing techniques in low-resource settings,\nsignificantly contributing to music transcription and studying musical\ntraditions through computational tools."
    ],
    "b_categories":[
      [
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01047"
    ],
    "c_title":[
      "An unoriented skein exact triangle in unoriented link Floer homology"
    ],
    "c_abstract":[
      "We define band maps in unoriented link Floer homology and show that they form\nan unoriented skein exact triangle. These band maps are similar to the band\nmaps in equivariant Khovanov homology given by the Lee deformation.\n  As a key tool, we use a Heegaard Floer analogue of Bhat's recent 2-surgery\nexact triangle in instanton Floer homology, which may be of independent\ninterest. Unoriented knot Floer homology corresponds to $I^{\\sharp}$ of the\nknot in our 2-surgery exact triangle."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-776",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14232"
    ],
    "b_title":[
      "Bolide infrasound signal morphology and yield estimates: A case study of\n  two events detected by a dense acoustic sensor network"
    ],
    "b_abstract":[
      "Two bolides (2 June 2016 and 4 April 2019) were detected at multiple regional\ninfrasound stations with many of the locations receiving multiple detections.\nAnalysis of the received signals was used to estimate the yield, location and\ntrajectory, and the type of shock that produced the received signal. The\nresults from the infrasound analysis were compared with ground truth\ninformation that was collected through other sensing modalities. This\nmulti-modal framework offers an expanded perspective on the processes governing\nbolide shock generation and propagation. The majority of signal features showed\nreasonable agreement between the infrasound-based interpretation and the other\nobservational modalities, though the yield estimate from the 2019 bolide was\nsignificantly lower using the infrasound detections. There was also evidence\nsuggesting that one of the detections was from a cylindrical shock that was\ninitially propagating upward, which is unusual though not impossible."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "physics.ao-ph",
        "physics.geo-ph",
        "physics.ins-det",
        "physics.space-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.06126"
    ],
    "c_title":[
      "Limit of quasilinear equations and related extremal problems"
    ],
    "c_abstract":[
      "We perform a complete analysis of the limiting behaviour of a class of\nquasilinear problems with Dirichlet boundary data g. We show that the Lipschitz\nconstant of g plays a role in controlling the Gamma-convergence of the natural\nenergies. However the solutions converge uniformly to solution of a limiting\nequation irrelevant to the Lipschitz constant of g. The limiting equation has\nno coercivity in u. We prove that the limiting equation admits a weak\ncomparison principle and has a unique viscosity solution. We also obtain a\nPoincare inequality in the Sobolev-Orlicz space for discontinuous operator,\nwhich paves the way for our study of an extremal problem where its operator\nbecomes unbounded in a subdomain. Upon giving proper meaning to its solution,\nwe show that the extremal problem has a unique solution. It turns out the\nsolution has sufficient continuity, although operator is discontinuous. In the\nappendix we provide some technical inequalities which play crucial roles in the\nproof of uniqueness and we believe will be of independent interest."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-777",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12108"
    ],
    "b_title":[
      "Using the Path of Least Resistance to Explain Deep Networks"
    ],
    "b_abstract":[
      "Integrated Gradients (IG), a widely used axiomatic path-based attribution\nmethod, assigns importance scores to input features by integrating model\ngradients along a straight path from a baseline to the input. While effective\nin some cases, we show that straight paths can lead to flawed attributions. In\nthis paper, we identify the cause of these misattributions and propose an\nalternative approach that treats the input space as a Riemannian manifold,\ncomputing attributions by integrating gradients along geodesics. We call this\nmethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we\nintroduce two techniques: a k-Nearest Neighbours-based approach for smaller\nmodels and a Stochastic Variational Inference-based method for larger ones.\nAdditionally, we propose a new axiom, Strong Completeness, extending the axioms\nsatisfied by IG. We show that this property is desirable for attribution\nmethods and that GIG is the only method that satisfies it. Through experiments\non both synthetic and real-world data, we demonstrate that GIG outperforms\nexisting explainability methods, including IG."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07269"
    ],
    "c_title":[
      "SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion Detection"
    ],
    "c_abstract":[
      "We present our shared task on text-based emotion detection, covering more\nthan 30 languages from seven distinct language families. These languages are\npredominantly low-resource and spoken across various continents. The data\ninstances are multi-labeled into six emotional classes, with additional\ndatasets in 11 languages annotated for emotion intensity. Participants were\nasked to predict labels in three tracks: (a) emotion labels in monolingual\nsettings, (b) emotion intensity scores, and (c) emotion labels in cross-lingual\nsettings. The task attracted over 700 participants. We received final\nsubmissions from more than 200 teams and 93 system description papers. We\nreport baseline results, as well as findings on the best-performing systems,\nthe most common approaches, and the most effective methods across various\ntracks and languages. The datasets for this task are publicly available."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-778",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16491"
    ],
    "b_title":[
      "The Impact of Generative AI Coding Assistants on Developers Who Are\n  Visually Impaired"
    ],
    "b_abstract":[
      "The rapid adoption of generative AI in software development has impacted the\nindustry, yet its effects on developers with visual impairments remain largely\nunexplored. To address this gap, we used an Activity Theory framework to\nexamine how developers with visual impairments interact with AI coding\nassistants. For this purpose, we conducted a study where developers who are\nvisually impaired completed a series of programming tasks using a generative AI\ncoding assistant. We uncovered that, while participants found the AI assistant\nbeneficial and reported significant advantages, they also highlighted\naccessibility challenges. Specifically, the AI coding assistant often\nexacerbated existing accessibility barriers and introduced new challenges. For\nexample, it overwhelmed users with an excessive number of suggestions, leading\ndevelopers who are visually impaired to express a desire for ``AI timeouts.''\nAdditionally, the generative AI coding assistant made it more difficult for\ndevelopers to switch contexts between the AI-generated content and their own\ncode. Despite these challenges, participants were optimistic about the\npotential of AI coding assistants to transform the coding experience for\ndevelopers with visual impairments. Our findings emphasize the need to apply\nactivity-centered design principles to generative AI assistants, ensuring they\nbetter align with user behaviors and address specific accessibility needs. This\napproach can enable the assistants to provide more intuitive, inclusive, and\neffective experiences, while also contributing to the broader goal of enhancing\naccessibility in software development."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10126"
    ],
    "c_title":[
      "An LiGME Regularizer of Designated Isolated Minimizers -- An Application\n  to Discrete-Valued Signal Estimation"
    ],
    "c_abstract":[
      "For a regularized least squares estimation of discrete-valued signals, we\npropose an LiGME regularizer, as a nonconvex regularizer, of designated\nisolated minimizers. The proposed regularizer is designed as a Generalized\nMoreau Enhancement (GME) of the so-called SOAV convex regularizer. Every\ncandidate vector in the discrete-valued set is aimed to be assigned to an\nisolated local minimizer of the proposed regularizer while the overall\nconvexity of the regularized least squares model is maintained. Moreover, a\nglobal minimizer of the proposed model can be approximated iteratively by using\na variant of cLiGME algorithm. To enhance the accuracy of the proposed\nestimation, we also propose a pair of simple modifications, called respectively\nan iterative reweighting and a generalized superiorization. Numerical\nexperiments demonstrate the effectiveness of the proposed model and algorithms\nin a scenario of MIMO signal detection."
    ],
    "c_categories":[
      [
        "eess.SP",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-779",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17072"
    ],
    "b_title":[
      "Multi-Span Optical Power Spectrum Evolution Modeling using ML-based\n  Multi-Decoder Attention Framework"
    ],
    "b_abstract":[
      "We implement a ML-based attention framework with component-specific decoders,\nimproving optical power spectrum prediction in multi-span networks. By reducing\nthe need for in-depth training on each component, the framework can be scaled\nto multi-span topologies with minimal data collection, making it suitable for\nbrown-field scenarios."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.00887"
    ],
    "c_title":[
      "Integral equations for flexural-gravity waves: analysis and numerical\n  methods"
    ],
    "c_abstract":[
      "In this work, we develop a fast and accurate method for the scattering of\nflexural-gravity waves by a thin plate of varying thickness overlying a fluid\nof infinite depth. This problem commonly arises in the study of sea ice and ice\nshelves, which can have complicated heterogeneities that include ridges and\nrolls. With certain natural assumptions on the thickness, we present an\nintegral equation formulation for solving this class of problems and analyze\nits mathematical properties. The integral equation is then discretized and\nsolved using a high-order-accurate, FFT-accelerated algorithm. The speed,\naccuracy, and scalability of this approach are demonstrated through a variety\nof illustrative examples."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "physics.geo-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-780",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02212"
    ],
    "b_title":[
      "A mixed-precision quantum-classical algorithm for solving linear systems"
    ],
    "b_abstract":[
      "We address the problem of solving a system of linear equations via the\nQuantum Singular Value Transformation (QSVT). One drawback of the QSVT\nalgorithm is that it requires huge quantum resources if we want to achieve an\nacceptable accuracy. To reduce the quantum cost, we propose a hybrid\nquantum-classical algorithm that improves the accuracy and reduces the cost of\nthe QSVT by adding iterative refinement in mixed-precision A first quantum\nsolution is computed using the QSVT, in low precision, and then refined in\nhigher precision until we get a satisfactory accuracy. For this solver, we\npresent an error and complexity analysis, and first experiments using the\nquantum software stack myQLM."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.12210"
    ],
    "c_title":[
      "Infinite-dimensional dynamical instabilities of noncompact stationary\n  Ricci flow solutions"
    ],
    "c_abstract":[
      "Regarding Ricci flow as a dynamical system, we derive sufficient conditions\nfor noncompact stationary (Ricci-flat) solutions to possess\ninfinite-dimensional unstable manifolds, and provide examples satisfying those\ncriteria that have uncountably many unstable perturbations."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-781",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13968"
    ],
    "b_title":[
      "Betsu-Betsu: Multi-View Separable 3D Reconstruction of Two Interacting\n  Objects"
    ],
    "b_abstract":[
      "Separable 3D reconstruction of multiple objects from multi-view RGB images --\nresulting in two different 3D shapes for the two objects with a clear\nseparation between them -- remains a sparsely researched problem. It is\nchallenging due to severe mutual occlusions and ambiguities along the objects'\ninteraction boundaries. This paper investigates the setting and introduces a\nnew neuro-implicit method that can reconstruct the geometry and appearance of\ntwo objects undergoing close interactions while disjoining both in 3D, avoiding\nsurface inter-penetrations and enabling novel-view synthesis of the observed\nscene. The framework is end-to-end trainable and supervised using a novel\nalpha-blending regularisation that ensures that the two geometries are well\nseparated even under extreme occlusions. Our reconstruction method is\nmarkerless and can be applied to rigid as well as articulated objects. We\nintroduce a new dataset consisting of close interactions between a human and an\nobject and also evaluate on two scenes of humans performing martial arts. The\nexperiments confirm the effectiveness of our framework and substantial\nimprovements using 3D and novel view synthesis metrics compared to several\nexisting approaches applicable in our setting."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.18252"
    ],
    "c_title":[
      "Restoration of residual gauge symmetries due to topological defects and\n  color confinement in the Lorenz gauge"
    ],
    "c_abstract":[
      "The RGS is the local gauge symmetry remaining even after imposing the gauge\nfixing condition. Although this symmetry is ``spontaneously broken'' in the\nperturbative vacuum, it can be restored in the true confining vacuum of QCD.\nTherefore, a color confinement criterion is obtained as the condition of\nrestoration of the RGS, namely, disappearance of the massless Nambu-Goldstone\npole associated with this spontaneous breaking, provided that the color\nconfinement phase is a disordered phase where all internal symmetries remain\nunbroken. In the Lorenz gauge, indeed, it was shown by Hata that the\nrestoration condition is identical to the Kugo-Ojima color confinement\ncriterion, if the gauge transformation function $\\omega (x)$ for the residual\ngauge symmetry is taken to be linear in $x$. However, this result was obtained\nwithout regard to topological configurations. In this talk, we reconsider this\nissue by taking into account topological defects that are expected to play the\ndominant role for realizing confinement in the non-perturbative way."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-782",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13533"
    ],
    "b_title":[
      "The Status Quo and Future of AI-TPACK for Mathematics Teacher Education\n  Students: A Case Study in Chinese Universities"
    ],
    "b_abstract":[
      "As artificial intelligence (AI) technology becomes increasingly prevalent in\nthe filed of education, there is a growing need for mathematics teacher\neducation students (MTES) to demonstrate proficiency in the integration of AI\nwith the technological pedagogical content knowledge (AI-TPACK). To study the\nissue, we firstly devised an systematic AI-TPACK scale and test on 412 MTES\nfrom seven universities. Through descriptive statistical analyses, we found\nthat the current status of AI-TPACK for MTES in China is at a basic,\npreliminary stage. Secondly, we compared MTES between three different grades on\nthe six variables and found that there is no discernible difference, which\nsuggested that graduate studies were observed to have no promotion in the\ndevelopment of AI-TPACK competencies. Thirdly, we proposed a new AI-TPACK\nstructural equation model (AI-TPACK-SEM) to explore the impact of self-efficacy\nand teaching beliefs on AI-TPACK. Our findings indicate a positive correlation\nbetween self-efficacy and AI-TPACK. We also come to a conclusion that may be\ncontrary to common perception, excessive teaching beliefs may impede the\nadvancement of AI-TPACK. Overall, this paper revealed the current status of\nAI-TPACK for MTES in China for the first time, designed a dedicated SEM to\nstudy the effect of specific factors on AI-TPACK, and proposed some suggestions\non future developments."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03762"
    ],
    "c_title":[
      "Dynamic structure factor of Calogero-Sutherland fluids"
    ],
    "c_abstract":[
      "The effective extended conformal field theory with symmetry W_infinity*{bar\nW_infinity} that describes the thermodynamic limit of the Calogero-Sutherland\nmodel is considered. The dynamic structure factor of the chiral component in\nthe repulsive regime is determined and compared with the corresponding one of\nthe free bosonic theory, given that both share isomorphic Hilbert spaces but\ndiffer in the time evolution of quantum states. In either case, a sharp\nresponse function peaked at only one resonant frequency is found, and the\nphysical implications of this outcome are addressed. Furthermore, a detailed\ncomparison between this result and the corresponding one obtained in the first\nquantized formulation of the Calogero-Sutherland model is provided. Complete\nagreement in the parameter region in which both results overlap is found. This\noutcome provides further support to the equivalence between the first and\nsecond quantized treatments of the Calogero-Sutherland model, in which the\ncomputational advantages from integrability in the first formulation are\nparalleled by those from the algebraic structure of the second."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-783",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15168"
    ],
    "b_title":[
      "mStyleDistance: Multilingual Style Embeddings and their Evaluation"
    ],
    "b_abstract":[
      "Style embeddings are useful for stylistic analysis and style transfer;\nhowever, only English style embeddings have been made available. We introduce\nMultilingual StyleDistance (mStyleDistance), a multilingual style embedding\nmodel trained using synthetic data and contrastive learning. We train the model\non data from nine languages and create a multilingual STEL-or-Content benchmark\n(Wegmann et al., 2022) that serves to assess the embeddings' quality. We also\nemploy our embeddings in an authorship verification task involving different\nlanguages. Our results show that mStyleDistance embeddings outperform existing\nmodels on these multilingual style benchmarks and generalize well to unseen\nfeatures and languages. We make our model publicly available at\nhttps:\/\/huggingface.co\/StyleDistance\/mstyledistance ."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07618"
    ],
    "c_title":[
      "Future collider sensitivities to $\\nu$SMEFT interactions"
    ],
    "c_abstract":[
      "The discovery of neutrino oscillations and masses provides strong motivation\nto extend the Standard Model by including right-handed neutrinos, which lead to\nheavy neutrino states that could exist at the electroweak scale. These states\nmay also be influenced by new high-scale, weakly interacting physics.\nIncorporating right-handed neutrinos into an effective field theory framework\n-- the $\\nu$SMEFT -- offers a systematic approach to study the phenomenology of\nheavy neutrinos in current and upcoming experiments. In this work, we present\nthe first prospective 95\\% exclusion plots achievable at a future lepton\ncollider operating at a center-of-mass energy of $\\sqrt{s}=0.5 ~\\rm{TeV}$ for\nwhat we term the agnostic $\\nu$SMEFT scenario. This study focuses on the\nhigh-mass regime where the heavy neutrino $N$ decays promptly into leptons and\njets. Specifically, we analyze the processes $e^+e^- \\to \\nu N \\to \\nu \\mu^{-}\n\\mu^{+} \\nu$ and $e^+e^- \\to \\nu N \\to \\nu \\mu^{-} \\mathrm{j} \\mathrm{j}$,\nderiving the exclusion regions in the $\\frac{\\alpha}{\\Lambda^2}$ vs. $m_N$\nparameter space. When compared to prospective limits for the LHeC, we find that\nthe semi-leptonic process with final jets in a lepton collider offers the\ngreatest sensitivity, even with a straightforward cut-based analysis. The\nexpected bounds are as stringent as those considered in recent studies for the\nlow-mass regime where the $N$ may be long-lived and detectable via displaced\ndecay searches, both at the LHC and future colliders."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-784",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02345"
    ],
    "b_title":[
      "CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for\n  Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented\n  3D MRI"
    ],
    "b_abstract":[
      "The detection of Alzheimer disease (AD) from clinical MRI data is an active\narea of research in medical imaging. Recent advances in quantum computing,\nparticularly the integration of parameterized quantum circuits (PQCs) with\nclassical machine learning architectures, offer new opportunities to develop\nmodels that may outperform traditional methods. However, quantum machine\nlearning (QML) remains in its early stages and requires further experimental\nanalysis to better understand its behavior and limitations. In this paper, we\npropose an end to end hybrid classical quantum convolutional neural network (CQ\nCNN) for AD detection using clinically formatted 3D MRI data. Our approach\ninvolves developing a framework to make 3D MRI data usable for machine\nlearning, designing and training a brain tissue segmentation model (Skull Net),\nand training a diffusion model to generate synthetic images for the minority\nclass. Our converged models exhibit potential quantum advantages, achieving\nhigher accuracy in fewer epochs than classical models. The proposed beta8 3\nqubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA)\nmodels while requiring significantly fewer computational resources. In\nparticular, the architecture employs only 13K parameters (0.48 MB), reducing\nthe parameter count by more than 99.99% compared to current SOTA models.\nFurthermore, the diffusion-generated data used to train our quantum models, in\nconjunction with real samples, preserve clinical structural standards,\nrepresenting a notable first in the field of QML. We conclude that CQCNN\narchitecture like models, with further improvements in gradient optimization\ntechniques, could become a viable option and even a potential alternative to\nclassical models for AD detection, especially in data limited and resource\nconstrained clinical settings."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01222"
    ],
    "c_title":[
      "Retrieval-Augmented Perception: High-Resolution Image Perception Meets\n  Visual RAG"
    ],
    "c_abstract":[
      "High-resolution (HR) image perception remains a key challenge in multimodal\nlarge language models (MLLMs). To overcome the limitations of existing methods,\nthis paper shifts away from prior dedicated heuristic approaches and revisits\nthe most fundamental idea to HR perception by enhancing the long-context\ncapability of MLLMs, driven by recent advances in long-context techniques like\nretrieval-augmented generation (RAG) for general LLMs. Towards this end, this\npaper presents the first study exploring the use of RAG to address HR\nperception challenges. Specifically, we propose Retrieval-Augmented Perception\n(RAP), a training-free framework that retrieves and fuses relevant image crops\nwhile preserving spatial context using the proposed Spatial-Awareness Layout.\nTo accommodate different tasks, the proposed Retrieved-Exploration Search\n(RE-Search) dynamically selects the optimal number of crops based on model\nconfidence and retrieval scores. Experimental results on HR benchmarks\ndemonstrate the significant effectiveness of RAP, with LLaVA-v1.5-13B achieving\na 43% improvement on $V^*$ Bench and 19% on HR-Bench."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-785",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04338"
    ],
    "b_title":[
      "Inference of noise intensity and phase response from noisy synchronous\n  oscillators"
    ],
    "b_abstract":[
      "Numerous biological and microscale systems exhibit synchronization in noisy\nenvironments. The theory of such noisy oscillators and their synchronization\nhas been developed and experimentally demonstrated, but inferring the noise\nintensity and phase response is not always straightforward. In this study, we\npropose a useful formula that enables us to infer the noise intensity and phase\nresponse of a noisy oscillator synchronized with periodic external forcing.\nThrough asymptotic approximations for small noise, we show that noisy\nsynchronous oscillators satisfy a simple relationship among the noise intensity\nand measurable quantities, i.e., the stationary distribution of the oscillation\nphase and stationary probability current obtained as the average phase\nvelocity, which is verified through systematic numerical analysis. The proposed\nformula facilitates a unified analysis and design of synchronous oscillators in\nweakly noisy environments."
    ],
    "b_categories":[
      [
        "nlin.AO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.17379"
    ],
    "c_title":[
      "Stable Tree Labelling for Accelerating Distance Queries on Dynamic Road\n  Networks"
    ],
    "c_abstract":[
      "Finding the shortest-path distance between two arbitrary vertices is an\nimportant problem in road networks. Due to real-time traffic conditions, road\nnetworks undergo dynamic changes all the time. Current state-of-the-art methods\nincrementally maintain a distance labelling based on a hierarchy among vertices\nto support efficient distance computation. However, their labelling sizes are\noften large and cannot be efficiently maintained. To combat these issues, we\npresent a simple yet efficient labelling method, namely \\emph{Stable Tree\nLabelling} (STL), for answering distance queries on dynamic road networks. We\nobserve that the properties of an underlying hierarchy play an important role\nin improving and balancing query and update performance. Thus, we introduce the\nnotion of \\emph{stable tree hierarchy} which lays the ground for developing\nefficient maintenance algorithms on dynamic road networks. Based on stable tree\nhierarchy, STL can be efficiently constructed as a 2-hop labelling. A crucial\ningredient of STL is to only store distances within subgraphs in labels, rather\nthan distances in the entire graph, which restricts the labels affected by\ndynamic changes. We further develop two efficient maintenance algorithms upon\nSTL: \\emph{Label Search algorithm} and \\emph{Pareto Search algorithm}. Label\nSearch algorithm identifies affected ancestors in a stable tree hierarchy and\nperforms efficient searches to update labels from those ancestors. Pareto\nSearch algorithm explores the interaction between search spaces of different\nancestors, and combines searches from multiple ancestors into only two searches\nfor each update, eliminating duplicate graph traversals. The experiments show\nthat our algorithms significantly outperform state-of-the-art dynamic methods\nin maintaining the labelling and query processing, while requiring an order of\nmagnitude less space."
    ],
    "c_categories":[
      [
        "cs.DB",
        "cs.DS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-786",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16941"
    ],
    "b_title":[
      "Gaussian Difference: Find Any Change Instance in 3D Scenes"
    ],
    "b_abstract":[
      "Instance-level change detection in 3D scenes presents significant challenges,\nparticularly in uncontrolled environments lacking labeled image pairs,\nconsistent camera poses, or uniform lighting conditions. This paper addresses\nthese challenges by introducing a novel approach for detecting changes in\nreal-world scenarios. Our method leverages 4D Gaussians to embed multiple\nimages into Gaussian distributions, enabling the rendering of two coherent\nimage sequences. We segment each image and assign unique identifiers to\ninstances, facilitating efficient change detection through ID comparison.\nAdditionally, we utilize change maps and classification encodings to categorize\n4D Gaussians as changed or unchanged, allowing for the rendering of\ncomprehensive change maps from any viewpoint. Extensive experiments across\nvarious instance-level change detection datasets demonstrate that our method\nsignificantly outperforms state-of-the-art approaches like C-NERF and CYWS-3D,\nespecially in scenarios with substantial lighting variations. Our approach\noffers improved detection accuracy, robustness to lighting changes, and\nefficient processing times, advancing the field of 3D change detection."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02155"
    ],
    "c_title":[
      "ItsDEAL: Inexact two-level smoothing descent algorithms for weakly\n  convex optimization"
    ],
    "c_abstract":[
      "This paper deals with nonconvex optimization problems via a two-level\nsmoothing framework in which the high-order Moreau envelope (HOME) is applied\nto generate a smooth approximation of weakly convex cost functions. As such,\nthe differentiability and weak smoothness of HOME are further studied, as is\nnecessary for developing inexact first-order methods for finding its critical\npoints. Building on the concept of the inexact two-level smoothing optimization\n(ItsOPT), the proposed scheme offers a versatile setting, called Inexact\ntwo-level smoothing DEscent ALgorithm (ItsDEAL), for developing inexact\nfirst-order methods: (i) solving the proximal subproblem approximately to\nprovide an inexact first-order oracle of HOME at the lower-level; (ii)\ndeveloping an upper inexact first-order method at the upper-level. In\nparticular, parameter-free inexact descent methods (i.e., dynamic step-sizes\nand an inexact nonmonotone Armijo line search) are studied that effectively\nleverage the weak smooth property of HOME. Although the subsequential\nconvergence of these methods is investigated under some mild inexactness\nassumptions, the global convergence and the linear rates are studied under the\nextra Kurdyka-\\L{}ojasiewicz (KL) property. In order to validate the\ntheoretical foundation, preliminary numerical experiments for robust sparse\nrecovery problems are provided which reveal a promising behavior of the\nproposed methods."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-787",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02019"
    ],
    "b_title":[
      "Benchmarking Constraint-Based Bayesian Structure Learning Algorithms:\n  Role of Network Topology"
    ],
    "b_abstract":[
      "Modeling the associations between real world entities from their multivariate\ncross-sectional profiles can provide cues into the concerted working of these\nentities as a system. Several techniques have been proposed for deciphering\nthese associations including constraint-based Bayesian structure learning (BSL)\nalgorithms that model them as directed acyclic graphs. Benchmarking these\nalgorithms have typically focused on assessing the variation in performance\nmeasures such as sensitivity as a function of the dimensionality represented by\nthe number of nodes in the DAG, and sample size. The present study elucidates\nthe importance of network topology in benchmarking exercises. More\nspecifically, it investigates variations in sensitivity across distinct network\ntopologies while constraining the nodes, edges, and sample-size to be\nidentical, eliminating these as potential confounders. Sensitivity of three\npopular constraint-based BSL algorithms (Peter-Clarke, Grow-Shrink, Incremental\nAssociation Markov Blanket) in learning the network structure from multivariate\ncross-sectional profiles sampled from network models with sub-linear, linear,\nand super-linear DAG topologies generated using preferential attachment is\ninvestigated. Results across linear and nonlinear models revealed statistically\nsignificant $(\\alpha=0.05)$ decrease in sensitivity estimates from sub-linear\nto super-linear topology constitutively across the three algorithms. These\nresults are demonstrated on networks with nodes $(N_{nods}=48,64)$, noise\nstrengths $(\\sigma =3,6)$ and sample size $(N = 2^{10})$. The findings\nelucidate the importance of accommodating the network topology in\nconstraint-based BSL benchmarking exercises."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.11591"
    ],
    "c_title":[
      "Pathology Image Compression with Pre-trained Autoencoders"
    ],
    "c_abstract":[
      "The growing volume of high-resolution Whole Slide Images in digital\nhistopathology poses significant storage, transmission, and computational\nefficiency challenges. Standard compression methods, such as JPEG, reduce file\nsizes but often fail to preserve fine-grained phenotypic details critical for\ndownstream tasks. In this work, we repurpose autoencoders (AEs) designed for\nLatent Diffusion Models as an efficient learned compression framework for\npathology images. We systematically benchmark three AE models with varying\ncompression levels and evaluate their reconstruction ability using pathology\nfoundation models. We introduce a fine-tuning strategy to further enhance\nreconstruction fidelity that optimizes a pathology-specific learned perceptual\nmetric. We validate our approach on downstream tasks, including segmentation,\npatch classification, and multiple instance learning, showing that replacing\nimages with AE-compressed reconstructions leads to minimal performance\ndegradation. Additionally, we propose a K-means clustering-based quantization\nmethod for AE latents, improving storage efficiency while maintaining\nreconstruction quality. We provide the weights of the fine-tuned autoencoders\nat\nhttps:\/\/huggingface.co\/collections\/StonyBrook-CVLab\/pathology-fine-tuned-aes-67d45f223a659ff2e3402dd0."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-788",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08830"
    ],
    "b_title":[
      "Binary quadratic forms: modern developments"
    ],
    "b_abstract":[
      "In this work, we offer a historical stroll through the vast topic of binary\nquadratic forms. We begin with a quick review of their history and then an\noverview of contemporary algebraic developments on the subject."
    ],
    "b_categories":[
      [
        "math.HO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.07594"
    ],
    "c_title":[
      "Distributed Non-Interactive Zero-Knowledge Proofs"
    ],
    "c_abstract":[
      "Distributed certification is a set of mechanisms that allows an all-knowing\nprover to convince the units of a communication network that the network's\nstate has some desired property, such as being 3-colorable or triangle-free.\nClassical mechanisms, such as proof labeling schemes (PLS), consist of a\nmessage from the prover to each unit, followed by one round of communication\nbetween each unit and its neighbors. Later works consider extensions, called\ndistributed interactive proofs, where the prover and the units can have\nmultiple rounds of communication before the communication among the units.\n  Recently, Bick, Kol, and Oshman (SODA '22) defined a zero-knowledge version\nof distributed interactive proofs, where the prover convinces the units of the\nnetwork's state without revealing any other information about the network's\nstate or structure. In their work, they propose different variants of this\nmodel and show that many graph properties of interest can be certified with\nthem.\n  In this work, we define and study distributed non-interactive zero-knowledge\nproofs (dNIZK); these can be seen as a non-interactive version of the\naforementioned model, and also as a zero-knowledge version of PLS. We prove the\nfollowing:\n  - There exists a dNIZK protocol for 3-coloring with O(log n)-bit messages\nfrom the prover and O(log n)-size messages among neighbors.\n  - There exists a family of dNIZK protocols for triangle-freeness, that\npresents a trade-off between the size of the messages from the prover and the\nsize of the messages among neighbors.\n  - There exists a dNIZK protocol for any graph property in NP in the random\noracle models, which is secure against an arbitrary number of malicious\nparties."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-789",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13345"
    ],
    "b_title":[
      "Controllability scores of linear time-varying network systems"
    ],
    "b_abstract":[
      "For large-scale network systems, network centrality based on control theory\nplays a crucial role in understanding their properties and controlling them\nefficiently. The controllability score is such a centrality index and can give\na physically meaningful measure. Nevertheless, the existing work is limited to\nlinear time-invariant (LTI) systems and the controllability score cannot be\napplied to linear time-varying (LTV) systems, which include essential models\nsuch as temporal networks for real application. This paper extends it to apply\nto LTV systems. Since it is defined as an optimal solution to some optimization\nproblem, it is not necessarily uniquely determined. Its uniqueness must be\nguaranteed for reproducibility and interpretability. This paper also shows its\nuniqueness in most practical cases, which guarantees its use as a network\ncentrality. In addition, we propose a data-driven method to compute it for its\npractical use. Finally, in numerical experiments, we compare controllability\nscores between LTI and LTV systems and assess the performance of the proposed\ndata-driven method."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.03835"
    ],
    "c_title":[
      "Neutrino quantum kinetics in three flavors"
    ],
    "c_abstract":[
      "The impact of neutrino flavor conversion on the supernova mechanism is yet to\nbe fully understood. We present multi-energy and multi-angle solutions of the\nneutrino quantum kinetic equations in three flavors, taking into account\nneutrino advection and non-forward collisions with the background medium.\nFlavor evolution is explored within a spherically symmetric shell surrounding\nthe region of neutrino decoupling in the interior of a core-collapse supernova,\nrelying on the outputs of a spherically symmetric core-collapse supernova model\nwith a mass of $18.6 M_\\odot$. We select two representative post-bounce times:\n$t_{\\rm pb} = 0.25$ s (no angular crossings are present and flavor conversion\nis triggered by slow collective effects) and $t_{\\rm pb} = 1$ s (angular\ncrossings trigger fast flavor instabilities). We find that flavor equipartition\nis achieved in the antineutrino sector between $\\bar\\nu_e$ and $\\bar\\nu_x =\n(\\bar\\nu_\\mu + \\bar\\nu_\\tau)\/2$ for both post-bounce times. In the neutrino\nsector, flavor equipartition between $\\nu_e$ and $\\nu_x$ seems more likely at\nlater post-bounce times, where the neutrino emission properties among different\nflavors tend to approach each other, but it is not a generic feature. The\nexponential growth of the $\\nu_\\mu$--$\\nu_\\tau$ asymmetry due to three-flavor\neffects is responsible for differences between the quasi-steady configurations\nobtained in the three-flavor solution and in the two-flavor approximation. This\nhas consequences on the neutrino heating rate, which is generally larger when\nall three flavors are taken into account and can increase up to $30\\%$ with\nrespect to the case where flavor conversion is neglected."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-790",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20506"
    ],
    "b_title":[
      "Surveying the Giant HII Regions of the Milky Way with SOFIA: VII.\n  Galactic Center Regions Sgr B1, Sgr B2, and Sgr C"
    ],
    "b_abstract":[
      "This study examines the mid-infrared properties of Giant HII (GHII) regions\nin the Milky Way's Central Molecular Zone (CMZ) -- Sgr B1, Sgr B2, and Sgr C --\nusing SOFIA-FORCAST imaging at 25 and 37 microns. It compares these\nmid-infrared data with previous multi-wavelength observations to explore their\npresent star formation activity and global properties. The study identifies 77\nmassive young stellar object (MYSO) candidates in and around the three regions.\nSgr B2 appears to host the youngest MYSOs and have much higher extinction than\nthe other regions, containing several radio sources not detected in the\nmid-infrared even at 37 microns. Meanwhile, cm radio continuum regions of Sgr\nB1 shows remarkable correspondence to its mid-infrared emission. Sgr C has\nfewer confirmed MYSOs, and seems to have a higher fraction of low-mass young\nstellar objects and contamination from more evolved interloper\/foreground\nstars. Derived MYSO densities are consistent with GHII regions elsewhere in the\nGalactic plane, though the CMZ GHII regions appear to have less prolific\npresent star formation overall. Unlike Sgr B2, the cm continuum emission in Sgr\nB1 and Sgr C GHII regions appears to be absent cold dust and molecular gas,\nsuggesting environmental differences, possibly driven by turbulence and rapid\ndynamical changes near the Galactic Center. Furthermore, unlike typical GHII\nregions, Sgr B1 and Sgr C are significantly ionized by evolved interloper\nstars, which likely did not form within these regions. In these ways, Sgr B1\nand Sgr C deviate from classical GHII region behavior, thus potentially\nrepresenting a new category of GHII region or challenging their classification\nas GHII regions."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.05770"
    ],
    "c_title":[
      "Path Planning for Multi-Copter UAV Formation Employing a Generalized\n  Particle Swarm Optimization"
    ],
    "c_abstract":[
      "The paper investigates the problem of path planning techniques for\nmulti-copter uncrewed aerial vehicles (UAV) cooperation in a formation shape to\nexamine surrounding surfaces. We first describe the problem as a joint\nobjective cost for planning a path of the formation centroid working in a\ncomplicated space. The path planning algorithm, named the generalized particle\nswarm optimization algorithm, is then presented to construct an optimal,\nflyable path while avoiding obstacles and ensuring the flying mission\nrequirements. A path-development scheme is then incorporated to generate a\nrelevant path for each drone to maintain its position in the formation\nconfiguration. Simulation, comparison, and experiments have been conducted to\nverify the proposed approach. Results show the feasibility of the proposed\npath-planning algorithm with GEPSO."
    ],
    "c_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-791",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14378"
    ],
    "b_title":[
      "Extremal Self-Dual Codes and Linear Complementary Dual Codes from Double\n  Circulant Codes"
    ],
    "b_abstract":[
      "This paper explores extremal self-dual double circulant (DC) codes and linear\ncomplementary dual (LCD) codes of arbitrary length over the Galois field\n$\\mathbb F_2$. We establish the sufficient and necessary conditions for DC\ncodes and bordered DC codes to be self-dual and identify the conditions for\nself-dual DC codes of length up to 44 to be extremal or non-extremal.\nAdditionally, The self-duality and extremality between DC codes and bordered DC\ncodes are also examined. Finally, sufficient conditions for bordered DC codes\nto be LCD codes over $\\mathbb F_2$ under Euclidean inner product are presented."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18436"
    ],
    "c_title":[
      "Composite M{\\o}lmer-S{\\o}rensen gate"
    ],
    "c_abstract":[
      "The M{\\o}lmer-S{\\o}rensen (MS) gate is a two-qubit controlled-phase gate in\nion traps that is highly valued due to its ability to preserve the motional\nstate of the ions. However, its fidelity is obstructed by errors affecting the\nmotion of the ions as well as the rotation of the qubits. In this work, we\npropose an amplitude-modulated composite MS gate which features high fidelity\nrobust to gate timing, detuning and coupling errors."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-792",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10537"
    ],
    "b_title":[
      "Divisi: Interactive Search and Visualization for Scalable Exploratory\n  Subgroup Analysis"
    ],
    "b_abstract":[
      "Analyzing data subgroups is a common data science task to build intuition\nabout a dataset and identify areas to improve model performance. However,\nsubgroup analysis is prohibitively difficult in datasets with many features,\nand existing tools limit unexpected discoveries by relying on user-defined or\nstatic subgroups. We propose exploratory subgroup analysis as a set of tasks in\nwhich practitioners discover, evaluate, and curate interesting subgroups to\nbuild understanding about datasets and models. To support these tasks we\nintroduce Divisi, an interactive notebook-based tool underpinned by a fast\napproximate subgroup discovery algorithm. Divisi's interface allows data\nscientists to interactively re-rank and refine subgroups and to visualize their\noverlap and coverage in the novel Subgroup Map. Through a think-aloud study\nwith 13 practitioners, we find that Divisi can help uncover surprising patterns\nin data features and their interactions, and that it encourages more thorough\nexploration of subtypes in complex data."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02677"
    ],
    "c_title":[
      "Canonical treatment of strangeness and light nuclei production"
    ],
    "c_abstract":[
      "The canonical effects on strangeness and light nuclei production in high\nenergy collisions are investigated, with a particular focus on low multiplicity\nevents observed in small collision systems at the Large Hadron Collider (LHC),\nand also in low energy collisions at the Relativistic Heavy Ion Collider\n(RHIC). We analyzed the yields of various particles, such as pions, protons,\nlambdas, multi-strange hadrons and light nuclei, and their dependencies on the\nproduced charged particle multiplicities using the Statistical Hadronization\nModel (SHM). Our findings indicate that the canonical treatment of strange and\nbaryon quantum numbers are essential for describing the particle production in\nthese collisions, particularly in small collision systems."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-793",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09440"
    ],
    "b_title":[
      "A multi-class non-local macroscopic model with time delay for mixed\n  autonomous \/ human-driven traffic"
    ],
    "b_abstract":[
      "In this paper, we present a class of systems of non-local conservation laws\nin one space-dimension incorporating time delay, which can be used to\ninvestigate the interaction between autonomous and human-driven vehicles, each\ncharacterized by a different reaction time and interaction range. We construct\napproximate solutions using a Hilliges-Weidlich scheme and we provide uniform L\n$\\infty$ and BV estimates which ensure the convergence of the scheme, thus\nobtaining existence of entropy weak solutions of bounded variation. Uniqueness\nfollows from an L 1 stability result derived from the entropy condition.\nAdditionally, we provide numerical simulations to illustrate applications to\nmixed autonomous \/ human-driven traffic flow modeling. In particular, we show\nthat the presence of autonomous vehicles improves overall traffic flow and\nstability."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03574"
    ],
    "c_title":[
      "Olympus: A Jumping Quadruped for Planetary Exploration Utilizing\n  Reinforcement Learning for In-Flight Attitude Control"
    ],
    "c_abstract":[
      "Exploring planetary bodies with lower gravity, such as the moon and Mars,\nallows legged robots to utilize jumping as an efficient form of locomotion thus\ngiving them a valuable advantage over traditional rovers for exploration.\nMotivated by this fact, this paper presents the design, simulation, and\nlearning-based \"in-flight\" attitude control of Olympus, a jumping legged robot\ntailored to the gravity of Mars. First, the design requirements are outlined\nfollowed by detailing how simulation enabled optimizing the robot's design -\nfrom its legs to the overall configuration - towards high vertical jumping,\nforward jumping distance, and in-flight attitude reorientation. Subsequently,\nthe reinforcement learning policy used to track desired in-flight attitude\nmaneuvers is presented. Successfully crossing the sim2real gap, extensive\nexperimental studies of attitude reorientation tests are demonstrated."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-794",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04866"
    ],
    "b_title":[
      "Identifying Flare Locations Through Exoplanet Transit Occultations"
    ],
    "b_abstract":[
      "M dwarfs are the most common stars in the galaxy, with long lifespans, a high\noccurrence rate of rocky planets, and close-in habitable zones. However, high\nstellar activity in the form of frequent flaring and any associated coronal\nmass ejections may drive atmospheric escape with the bombardment of radiation\nand high-energy particles, drastically impacting the habitability of these\nsystems. The stellar latitude where flares and coronal mass ejections occur\ndetermines the space weather that exoplanets are subject to, with high-energy\nparticle events associated with equatorial flares producing significant\natmospheric erosion. However, the flaring latitudes for M dwarfs remain largely\nunconstrained. To aid in the effort to locate these flaring regions we explore\nthe applicability of flare occultations using optical photometry to identify\nthe latitudes of flares. As a planet transits in front of an ongoing flare the\ntiming and geometry of the transit can be used to constrain the latitude and\nlongitude of the flare. We predict the probability of detecting an occultation\nfor known transiting planets and eclipsing binaries. From this, we estimate\n3-22 detectable occultations exist within the TESS primary mission photometry,\nwith the majority occurring in eclipsing binary observations. To demonstrate\nthis technique, we analyze a candidate flare occultation event for the\neclipsing binary CM Draconis."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16754"
    ],
    "c_title":[
      "Non-reductive cycles and twisted arithmetic transfers for Shimura curves"
    ],
    "c_abstract":[
      "In this largely expository note, we explain some recent progress on new\ncycles on Shimura varieties and Rapoport-Zink spaces, (twisted) arithmetic\nfundamental lemma, and arithmetic analogs of relative Langlands program. We\nexplain related formulations of arithmetic twisted Gan-Gross-Prasad conjecture,\nthe proof of twisted AFL and certain arithmetic transfers."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-795",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10559"
    ],
    "b_title":[
      "SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in\n  3D MRIs of the Knee Joint"
    ],
    "b_abstract":[
      "Accurate morphometric assessment of cartilage-such as thickness\/volume-via\nMRI is essential for monitoring knee osteoarthritis. Segmenting cartilage\nremains challenging and dependent on extensive expert-annotated datasets, which\nare heavily subjected to inter-reader variability. Recent advancements in\nVisual Foundational Models (VFM), especially memory-based approaches, offer\nopportunities for improving generalizability and robustness. This study\nintroduces a deep learning (DL) method for cartilage and meniscus segmentation\nfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awareness\nand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) during\ntraining and applied a segmentation mask propagation technique to enhance\nannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, two\nautomatic transformer-based models (SaMRI2D and SaMRI3D), and a\ntransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from\n270 patients using public and internal datasets and evaluated on 57 external\ncases, including multi-radiologist annotations and different data acquisitions.\nModel performance was assessed against reference standards using Dice Score\n(DSC) and Intersection over Union (IoU), with additional morphometric\nevaluations to further quantify segmentation accuracy. SAMRI-2 model, trained\nwith HSS, outperformed all other models, achieving an average DSC improvement\nof 5 points, with a peak improvement of 12 points for tibial cartilage. It also\ndemonstrated the lowest cartilage thickness errors, reducing discrepancies by\nup to threefold. Notably, SAMRI-2 maintained high performance with as few as\nthree user clicks per volume, reducing annotation effort while ensuring\nanatomical precision. This memory-based VFM with spatial awareness offers a\nnovel approach for reliable AI-assisted knee MRI segmentation, advancing DL in\nmusculoskeletal imaging."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11444"
    ],
    "c_title":[
      "On the concept of center for geometric objects and related problems"
    ],
    "c_abstract":[
      "In this work, we review the concept of center of a geometric object as an\nequivariant map, unifying and generalizing different approaches followed by\nauthors such as C. Kimberling or A. Edmonds. We provide examples to illustrate\nthat this general approach encompasses many interesting spaces of geometric\nobjects arising from different settings. Additionally, we discuss two results\nthat characterize centers for some particular spaces of geometric objects, and\nwe pose five open questions related to the generalization of these\ncharacterizations to other spaces. Finally, we conclude this article by briefly\ndiscussing other central objects and their relation to this concept of center."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-796",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06785"
    ],
    "b_title":[
      "3DCoMPaT200: Language-Grounded Compositional Understanding of Parts and\n  Materials of 3D Shapes"
    ],
    "b_abstract":[
      "Understanding objects in 3D at the part level is essential for humans and\nrobots to navigate and interact with the environment. Current datasets for\npart-level 3D object understanding encompass a limited range of categories. For\ninstance, the ShapeNet-Part and PartNet datasets only include 16, and 24 object\ncategories respectively. The 3DCoMPaT dataset, specifically designed for\ncompositional understanding of parts and materials, contains only 42 object\ncategories. To foster richer and fine-grained part-level 3D understanding, we\nintroduce 3DCoMPaT200, a large-scale dataset tailored for compositional\nunderstanding of object parts and materials, with 200 object categories with\n$\\approx$5 times larger object vocabulary compared to 3DCoMPaT and $\\approx$ 4\ntimes larger part categories. Concretely, 3DCoMPaT200 significantly expands\nupon 3DCoMPaT, featuring 1,031 fine-grained part categories and 293 distinct\nmaterial classes for compositional application to 3D object parts.\nAdditionally, to address the complexities of compositional 3D modeling, we\npropose a novel task of Compositional Part Shape Retrieval using ULIP to\nprovide a strong 3D foundational model for 3D Compositional Understanding. This\nmethod evaluates the model shape retrieval performance given one, three, or six\nparts described in text format. These results show that the model's performance\nimproves with an increasing number of style compositions, highlighting the\ncritical role of the compositional dataset. Such results underscore the\ndataset's effectiveness in enhancing models' capability to understand complex\n3D shapes from a compositional perspective. Code and Data can be found at\nhttp:\/\/github.com\/3DCoMPaT200\/3DCoMPaT200"
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09140"
    ],
    "c_title":[
      "Active Learning Methodology applied to a remote projectile launch\n  experiment: students' first impressions"
    ],
    "c_abstract":[
      "This study examines the impact of a remote laboratory experiment on Physics\nlearning, using a case study approach. Societal advancements over the past\ncentury have spurred discussions regarding restructuring the current\neducational system, with active learning methodologies proposed as alternatives\nto conventional models. These active methods empower students to develop new\nskills and competencies beyond the academic knowledge imparted in lectures. To\nimprove student learning outcomes in Physics, this research will develop an\nexperimental model for application in engineering classes. This involves\ncreating a laboratory experiment procedure for oblique projectile motion,\nconstructing the necessary apparatus, recording the experiment on a film,\npresenting the video for a remote student's audience, and evaluating the model\nusing questionnaires focusing on conceptual understanding and related\nquestions."
    ],
    "c_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-797",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11098"
    ],
    "b_title":[
      "AI-assisted hyper-dimensional broadband quantum memory with efficiency\n  above 90% in warm atoms"
    ],
    "b_abstract":[
      "High-dimensional broadband quantum memory significantly expands quantum\ninformation processing capabilities, but the memory efficiency becomes\ninsufficient when extended to high dimensions. We demonstrate an efficient\nquantum memorize for hyper-dimensional photons encoded with orbital angular\nmomentum (OAM) and spin angular momentum (SAM). OAM information is encoded from\n-5 to +5, combined with spin angular momentum encoding, enabling up to 22\ndimensions. To ensure high memory efficiency, an artificial intelligent\nalgorithm, a modified Differential Evolution (DE) algorithm using Chebyshev\nsampling, is developed to obtain a perfect signal-control waveform matching.\nMemory efficiency is experimentally achieved 92% for single-mode Gaussian\nsignal, 91% for information dimension of 6 and 80% for dimensional number to\n22. The fidelity is achieved up to 99% for single-mode Gaussian signal, 96% for\nOAM information and 97% for SAM one, which is far beyond no-cloning limitation.\nOur results demonstrate superior performance and potential applications in\nhigh-dimensional quantum information processing. This achievement provides a\ncrucial foundation for future quantum communication and quantum computing."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.10075"
    ],
    "c_title":[
      "Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and\n  MModalCC Framework"
    ],
    "c_abstract":[
      "Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps:\/\/github.com\/ChangeCapsInRS\/SecondCC"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-798",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19107"
    ],
    "b_title":[
      "The Shady Light of Art Automation"
    ],
    "b_abstract":[
      "Generative artificial intelligence (generative AI) has entered the mainstream\nculture and become a subject of extensive academic investigation. However, the\ncharacter and background of its impact on art require subtler scrutiny and more\nnuanced contextualization. This paper summarizes a broader study of the roles\nthat AI's conceptual and ideological substrata play in influencing art notions.\nThe focus is on divergent but coalescing and often questionable ideas, values,\nand political views that generative AI and other art-related AI technologies\npropagate from the computer science and AI\/tech industry to the contemporary\nart and culture. The paper maps the main areas of this complex relationship and\nconcisely critiques their key aspects."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08285"
    ],
    "c_title":[
      "Sorting permutations using a pop stack with a bypass"
    ],
    "c_abstract":[
      "We introduce a new sorting device for permutations which makes use of a pop\nstack augmented with a bypass operation. This results in a sorting machine,\nwhich is more powerful than the usual Popstacksort algorithm and seems to have\nnever been investigated previously. In the present paper, we give a\ncharacterization of sortable permutations in terms of forbidden patterns and\nreinterpret the resulting enumerating sequence using a class of restricted\nMotzkin paths. Moreover, we describe an algorithm to compute the set of all\npreimages of a given permutation, thanks to which we characterize permutations\nhaving a small number of preimages. Finally, we provide a full description of\nthe preimages of principal classes of permutations, and we discuss the device\nconsisting of two pop stacks in parallel, again with a bypass operation."
    ],
    "c_categories":[
      [
        "cs.DM",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-799",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16011"
    ],
    "b_title":[
      "MEL: Legal Spanish Language Model"
    ],
    "b_abstract":[
      "Legal texts, characterized by complex and specialized terminology, present a\nsignificant challenge for Language Models. Adding an underrepresented language,\nsuch as Spanish, to the mix makes it even more challenging. While pre-trained\nmodels like XLM-RoBERTa have shown capabilities in handling multilingual\ncorpora, their performance on domain specific documents remains underexplored.\nThis paper presents the development and evaluation of MEL, a legal language\nmodel based on XLM-RoBERTa-large, fine-tuned on legal documents such as BOE\n(Bolet\\'in Oficial del Estado, the Spanish oficial report of laws) and congress\ntexts. We detail the data collection, processing, training, and evaluation\nprocesses. Evaluation benchmarks show a significant improvement over baseline\nmodels in understanding the legal Spanish language. We also present case\nstudies demonstrating the model's application to new legal texts, highlighting\nits potential to perform top results over different NLP tasks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18399"
    ],
    "c_title":[
      "Global Structure in the Presence of a Topological Defect"
    ],
    "c_abstract":[
      "We investigate the global structure of topological defects which wrap a\nsubmanifold $F\\subset M$ in a quantum field theory defined on a closed manifold\n$M$. The Pontryagin-Thom construction oversees the interplay between the global\nstructure of $F$ and the global structure of $M$. We will employ this\nconstruction to two distinct mathematical frameworks with physical\napplications. The first framework is the concept of a characteristic structure,\nconsisting of the data of pairs of manifolds $(M,F)$ where $F$ is Poincar\\'e\ndual to some characteristic class. This concept is discussed in the mathematics\nliterature, and shown here to have meaningful physical interpretations related\nto defects. In our examples we will mainly focus on the case where $M$ is\n4-dimensional and $F$ has codimension 2. The second framework uses obstruction\ntheory and the fact that spontaneously broken finite symmetries leave behind\ndomain walls, to determine the conditions on which dimensions a higher-form\nfinite symmetry can spontaneously break. We explicitly study the cases of\nhigher-form $\\mathbb Z\/2$ symmetry, but the method can be generalized to other\ngroups."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "hep-th",
        "math-ph",
        "math.AT",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-800",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00447"
    ],
    "b_title":[
      "Resolving the Problem of Multiple Control Parameters in Optimized\n  Borel-Type Summation"
    ],
    "b_abstract":[
      "One of the most often used methods of summing divergent series in physics is\nthe Borel-type summation with control parameters improving convergence, which\nare defined by some optimization conditions. The well known annoying problem in\nthis procedure is the occurrence of multiple solutions for control parameters.\nWe suggest a method for resolving this problem, based on the minimization of\ncost functional. Control parameters can be introduced by employing the\nBorel-Leroy or Mittag-Leffler transforms. Also, two novel transformations are\nproposed using fractional integrals and fractional derivatives. New cost\nfunctionals are advanced, based on lasso and ridge selection criteria, and\ntheir performance is studied for a number of models. The developed method is\nshown to provide good accuracy for the calculated quantities."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "hep-ph",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.15984"
    ],
    "c_title":[
      "Loop space of a K\\\"ahler manifold"
    ],
    "c_abstract":[
      "We prove that the loop space of a K\\\"ahler manifold inherits a K\\\"ahler\nstructure. Then we prove that equipped with this natural metric the loop space\nis complete and unbounded. Additionally, we show that a geodesic on the loop\nspace can be constructed by piecing together geodesics from each individual\nleaf."
    ],
    "c_categories":[
      [
        "math.CV",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-801",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05544"
    ],
    "b_title":[
      "Quantum kinetic theory of semiclassical Boltzmann equation with side\n  jump and skew scattering"
    ],
    "b_abstract":[
      "The semiclassical Boltzmann equation is widely used to study transport\neffects. It is usually introduced in an intuitive fashion, which could cause\nconfusion, e.g., over the collision integral with skew scattering. Actually,\nthe Boltzmann equation is closely linked to the quantum density matrix,\nalthough term-by-term correspondence between the two is yet to be established.\nHere we start from the quantum Liouville equation in the interactive picture\nand show that the diagonal components of the equation yield the Boltzmann\nequation in homogeneous systems in an applied uniform electric field in the\nsemiclassical limit, while the off-diagonal components give the anomalous\nvelocity induced by Berry curvature and the side-jump velocity. The\nskew-scattering contribution is obtained when we include corrections beyond the\nfirst-Born approximation. The result derived from the denstiy matrix agrees\nwith the semiclassical one from wave-packet analysis, showing that the\nsemiclassical Boltzmann equation is more than an equation built from intuition,\nand it can be derived with the density matrix. Our work further clarifies the\norigin of the equation and eliminates the puzzles surrounding it."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03802"
    ],
    "c_title":[
      "MXMap: A Multivariate Cross Mapping Framework for Causal Discovery in\n  Dynamical Systems"
    ],
    "c_abstract":[
      "Convergent Cross Mapping (CCM) is a powerful method for detecting causality\nin coupled nonlinear dynamical systems, providing a model-free approach to\ncapture dynamic causal interactions. Partial Cross Mapping (PCM) was introduced\nas an extension of CCM to address indirect causality in three-variable systems\nby comparing cross-mapping quality between direct cause-effect mapping and\nindirect mapping through an intermediate conditioning variable. However, PCM\nremains limited to univariate delay embeddings in its cross-mapping processes.\nIn this work, we extend PCM to the multivariate setting, introducing multiPCM,\nwhich leverages multivariate embeddings to more effectively distinguish\nindirect causal relationships. We further propose a multivariate cross-mapping\nframework (MXMap) for causal discovery in dynamical systems. This two-phase\nframework combines (1) pairwise CCM tests to establish an initial causal graph\nand (2) multiPCM to refine the graph by pruning indirect causal connections.\nThrough experiments on simulated data and the ERA5 Reanalysis weather dataset,\nwe demonstrate the effectiveness of MXMap. Additionally, MXMap is compared\nagainst several baseline methods, showing advantages in accuracy and causal\ngraph refinement."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.DS",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-802",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09358"
    ],
    "b_title":[
      "RetSTA: An LLM-Based Approach for Standardizing Clinical Fundus Image\n  Reports"
    ],
    "b_abstract":[
      "Standardization of clinical reports is crucial for improving the quality of\nhealthcare and facilitating data integration. The lack of unified standards,\nincluding format, terminology, and style, is a great challenge in clinical\nfundus diagnostic reports, which increases the difficulty for large language\nmodels (LLMs) to understand the data. To address this, we construct a bilingual\nstandard terminology, containing fundus clinical terms and commonly used\ndescriptions in clinical diagnosis. Then, we establish two models,\nRetSTA-7B-Zero and RetSTA-7B. RetSTA-7B-Zero, fine-tuned on an augmented\ndataset simulating clinical scenarios, demonstrates powerful standardization\nbehaviors. However, it encounters a challenge of limitation to cover a wider\nrange of diseases. To further enhance standardization performance, we build\nRetSTA-7B, which integrates a substantial amount of standardized data generated\nby RetSTA-7B-Zero along with corresponding English data, covering diverse\ncomplex clinical scenarios and achieving report-level standardization for the\nfirst time. Experimental results demonstrate that RetSTA-7B outperforms other\ncompared LLMs in bilingual standardization task, which validates its superior\nperformance and generalizability. The checkpoints are available at\nhttps:\/\/github.com\/AB-Story\/RetSTA-7B."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10909"
    ],
    "c_title":[
      "Fabrication of Metal Air Bridges for Superconducting Circuits using\n  Two-photon Lithography"
    ],
    "c_abstract":[
      "Extraneous high frequency chip modes parasitic to superconducting quantum\ncircuits can result in decoherence when these modes are excited. To suppress\nthese modes, superconducting air bridges (AB) are commonly used to electrically\nconnect ground planes together when interrupted by transmission lines. Here, we\ndemonstrate the use of two-photon photolithography to build a supporting 3D\nresist structure in conjunction with a lift-off process to create AB. The\nresulting aluminum AB, have a superconducting transition temperature $T_{c} =\n1.08$ K and exhibit good mechanical strength up to lengths of 100 $\\mu$m. A\nmeasurable amount of microwave loss is observed when 35 AB were placed over a\nhigh-$Q$ Ta quarter-wave coplanar waveguide resonator."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-803",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17164"
    ],
    "b_title":[
      "Leading-order deflection of particles by a moving Schwarzschild lens\n  with a two-dimensional velocity"
    ],
    "b_abstract":[
      "The gravitational deflection effect of relativistic massive and massless\nparticles up to the first post-Minkowskian order caused by a moving\nSchwarzschild black hole with a two-dimensional equatorial velocity, which\ncontains the radial and transversal components, is studied analytically, and a\nnew unified formula for the deflection angle is achieved. The expression of the\nangle matches well with the results of the weak deflection of relativistic\nparticles induced by a radially moving Schwarzschild source given in the\nliterature, when the transversal component of the lens velocity vanishes. The\njoint velocity effect, which consists of the influences of the transversal and\nradial motions of the lens on the leading-order Schwarzschild deflection of the\nmassive particles and light, is then discussed in the context of general\nrelativity. We analyze the order of magnitude of this kinematical effect and\nevaluate the possibility of its astronomical detection subsequently."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00530"
    ],
    "c_title":[
      "Generic Multimodal Spatially Graph Network for Spatially Embedded\n  Network Representation Learning"
    ],
    "c_abstract":[
      "Spatially embedded networks (SENs) represent a special type of complex graph,\nwhose topologies are constrained by the networks' embedded spatial\nenvironments. The graph representation of such networks is thereby influenced\nby the embedded spatial features of both nodes and edges. Accurate network\nrepresentation of the graph structure and graph features is a fundamental task\nfor various graph-related tasks. In this study, a Generic Multimodal Spatially\nGraph Convolutional Network (GMu-SGCN) is developed for efficient\nrepresentation of spatially embedded networks. The developed GMu-SGCN model has\nthe ability to learn the node connection pattern via multimodal node and edge\nfeatures. In order to evaluate the developed model, a river network dataset and\na power network dataset have been used as test beds. The river network\nrepresents the naturally developed SENs, whereas the power network represents a\nman-made network. Both types of networks are heavily constrained by the spatial\nenvironments and uncertainties from nature. Comprehensive evaluation analysis\nshows the developed GMu-SGCN can improve accuracy of the edge existence\nprediction task by 37.1\\% compared to a GraphSAGE model which only considers\nthe node's position feature in a power network test bed. Our model demonstrates\nthe importance of considering the multidimensional spatial feature for\nspatially embedded network representation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-804",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17618"
    ],
    "b_title":[
      "Periodic Boundary Conditions for Bosonic Path Integral Molecular\n  Dynamics"
    ],
    "b_abstract":[
      "We develop an algorithm for bosonic path integral molecular dynamics (PIMD)\nsimulations with periodic boundary conditions (PBC) that scales quadratically\nwith the number of particles. Path integral methods are a powerful tool to\nsimulate bosonic condensed phases, which exhibit fundamental physical phenomena\nsuch as Bose--Einstein condensation and superfluidity. Recently, we developed a\nquadratic scaling algorithm for bosonic PIMD, but employed an ad hoc treatment\nof PBC. Here we rigorously enforce PBC in bosonic PIMD. It requires summing\nover the spring energies of all periodic images in the partition function, and\na naive implementation scales exponentially with the system size. We present an\nalgorithm for bosonic PIMD simulations of periodic systems that scales only\nquadratically. We benchmark our implementation on the free Bose gas and a model\nsystem of cold atoms in optical lattices. We also study an approximate\ntreatment of PBC based on the minimum-image convention, and derive a numerical\ncriterion to determine when it is valid."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11280"
    ],
    "c_title":[
      "High-Dimensional Interlingual Representations of Large Language Models"
    ],
    "c_abstract":[
      "Large language models (LLMs) trained on massive multilingual datasets hint at\nthe formation of interlingual constructs--a shared subspace in the\nrepresentation space. However, evidence regarding this phenomenon is mixed,\nleaving it unclear whether these models truly develop unified interlingual\nrepresentations, or present a partially aligned constructs. We explore 31\ndiverse languages varying on their resource-levels, typologies, and\ngeographical regions; and find that multilingual LLMs exhibit inconsistent\ncross-lingual alignments. To address this, we propose an interlingual\nrepresentation framework identifying both the shared interlingual semantic\nsubspace and fragmented components, existed due to representational\nlimitations. We introduce Interlingual Local Overlap (ILO) score to quantify\ninterlingual alignment by comparing the local neighborhood structures of\nhigh-dimensional representations. We utilize ILO to investigate the impact of\nsingle-language fine-tuning on the interlingual representations in multilingual\nLLMs. Our results indicate that training exclusively on a single language\ndisrupts the alignment in early layers, while freezing these layers preserves\nthe alignment of interlingual representations, leading to improved\ncross-lingual generalization. These results validate our framework and metric\nfor evaluating interlingual representation, and further underscore that\ninterlingual alignment is crucial for scalable multilingual learning."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-805",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17101"
    ],
    "b_title":[
      "Numerical study of synaptic behavior in amorphous HfO2-based\n  ferroelectric-like FETs generated by voltage-driven ion migration"
    ],
    "b_abstract":[
      "The continuous effort in making artificial neural networks more alike to\nhuman brain calls for the hardware elements to implement biological\nsynapse-like functionalities. The recent experimental demonstration of\nferroelectric-like FETs promises low-power operation as compared to the\nconventional ferroelectric switching devices. This work presents an in-house\nnumerical tool, which self-consistently solves the electrostatics and\ntime-dependent electronic and ionic transport. The tool is exploited to analyze\nthe effect that various physical parameters such as mobility and ion\nconcentration could have on the design of the ferroelectric-like FETs. Their\nsuitability in emulating different functions of the biological synapses is also\ndemonstrated."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14534"
    ],
    "c_title":[
      "Poststroke rehabilitative mechanisms in individualized fatigue\n  level-controlled treadmill training -- a Rat Model Study"
    ],
    "c_abstract":[
      "Individualized training improved post-stroke motor function rehabilitation\nefficiency. However, the mechanisms of how individualized training facilitates\nrecovery is not clear. This study explored the cortical and corticomuscular\nrehabilitative effects in post-stroke motor function recovery during\nindividualized training. Sprague-Dawley rats with intracerebral hemorrhage\n(ICH) were randomly distributed into two groups: forced training (FOR-T, n=13)\nand individualized fatigue-controlled training (FAT-C, n=13) to receive\ntraining respectively from day 2 to day 14 post-stroke. The FAT-C group\nexhibited superior motor function recovery and less central fatigue compared to\nthe FOR-T group. EEG PSD slope analysis demonstrated a better inter-hemispheric\nbalance in FAT-C group compare to the FOR-T group. The dCMC analysis indicated\nthat training-induced fatigue led to a short-term down-regulation of descending\ncorticomuscular coherence (dCMC) and an up-regulation of ascending dCMC. In the\nlong term, excessive fatigue hindered the recovery of descending control in the\naffected hemisphere. The individualized strategy of peripheral\nfatigue-controlled training achieved better motor function recovery, which\ncould be attributed to the mitigation of central fatigue, optimization of\ninter-hemispheric balance and enhancement of descending control in the affected\nhemisphere."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-806",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14825"
    ],
    "b_title":[
      "Search for a heavy pseudoscalar Higgs boson decaying to a 125 GeV Higgs\n  boson and a Z boson in final states with two tau and two light leptons in\n  proton-proton collisions at $\\sqrt{s}$ = 13 TeV"
    ],
    "b_abstract":[
      "A search for a heavy pseudoscalar Higgs boson, A, decaying to a 125 GeV Higgs\nboson h and a Z boson is presented. The h boson is identified via its decay to\na pair of tau leptons, while the Z boson is identified via its decay to a pair\nof electrons or muons. The search targets the production of the A boson via the\ngluon-gluon fusion process, gg $\\to$ A, and in association with bottom quarks,\n$\\mathrm{b\\bar{b}}$A. The analysis uses a data sample corresponding to an\nintegrated luminosity of 138 fb$^{-1}$ collected with the CMS detector at the\nCERN LHC in proton-proton collisions at a centre-of-mass energy of $\\sqrt{s}$ =\n13 TeV. Constraints are set on the product of the cross sections of the A\nproduction mechanisms and the A $\\to$ Zh decay branching fraction. The observed\n(expected) upper limit at 95% confidence level ranges from 0.049 (0.060) pb to\n1.02 (0.79) pb for the gg $\\to$ A process and from 0.053 (0.059) pb to 0.79\n(0.61) pb for the $\\text{b}\\bar{\\text{b}}$A process in the probed range of the\nA boson mass, $m_\\text{A}$, from 225 GeV to 1 TeV. The results of the search\nare used to constrain parameters within the\n${\\text{M}_{\\text{h,EFT}}^{\\text{125}}}$ benchmark scenario of the minimal\nsupersymmetric extension of the standard model. Values of $\\tan\\beta$ below 2.2\nare excluded in this scenario at 95% confidence level for all $m_\\text{A}$\nvalues in the range from 225 to 350 GeV."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.01665"
    ],
    "c_title":[
      "Entropy-based measure of rock sample heterogeneity derived from micro-CT\n  images"
    ],
    "c_abstract":[
      "This study presents an automated method for objectively measuring rock\nheterogeneity via raw X-ray micro-computed tomography (micro-CT) images,\nthereby addressing the limitations of traditional methods, which are\ntime-consuming, costly, and subjective. Unlike approaches that rely on image\nsegmentation, the proposed method processes micro-CT images directly,\nidentifying textural heterogeneity. The image is partitioned into subvolumes,\nwhere attributes are calculated for each one, with entropy serving as a measure\nof uncertainty. This method adapts to varying sample characteristics and\nenables meaningful comparisons across distinct sets of samples. It was applied\nto a dataset consisting of 4,935 images of cylindrical plug samples derived\nfrom Brazilian reservoirs. The results showed that the selected attributes play\na key role in producing desirable outcomes, such as strong correlations with\nstructural heterogeneity. To assess the effectiveness of our method, we used\nevaluations provided by four experts who classified 175 samples as either\nheterogeneous or homogeneous, where each expert assessed a different number of\nsamples. One of the presented attributes demonstrated a statistically\nsignificant difference between the homogeneous and heterogeneous samples\nlabelled by all the experts, whereas the other two attributes yielded\nnonsignificant differences for three out of the four experts. The method was\nshown to better align with the expert choices than traditional textural\nattributes known for extracting heterogeneous properties from images. This\ntextural heterogeneity measure provides an additional parameter that can assist\nin rock characterization, and the automated approach ensures easy reproduction\nand high cost-effectiveness."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-807",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13005"
    ],
    "b_title":[
      "Bipolaron dynamics in the one-dimensional SSH model"
    ],
    "b_abstract":[
      "Characterizing bipolaron binding, and understanding how it depends on\nelectron-phonon interaction, is crucial to unraveling the nature of emergent\nmany-body states in strongly interacting electron-phonon systems. So far, most\nstudies of bipolarons have been limited to the Holstein model, in which the\ncoupling constant is momentum-independent. The paradigmatic example of\nmomentum-dependent electron-phonon interaction comes from the system in which\nphonon distortions modify electron hopping, the SSH model. Already individual\npolarons in the SSH model are richer than the Holstein model counterparts, and\nfeature a phase transition into the finite momentum ground state with\nincreasing electron-phonon interaction. In this paper, we use a variational\napproach to study bipolarons in the one-dimensional SSH model and discuss their\nground state, dispersion, and excitation spectra. We explore the full parameter\nrange of the system, including the adiabatic regime of slow phonons, which was\ninaccessible to previous theoretical studies. In agreement with earlier\nstudies, we find that in the anti-adiabatic strongly interacting regime,\nbipolarons have low effective mass. By contrast, in the adiabatic case, we find\nthat increasing electron-phonon interactions results in an exponential increase\nof the bipolaron mass. We establish the existence of multiple branches of bound\nexcited states of SSH bipolaron and discuss the signatures of these bound\nstates in dynamics. We show that in the anti-adiabatic regime, response\nfunctions obey a parity selection rule, that imposes symmetry constraints on\nthe excitation spectra and provides a clear signature of SSH bipolarons."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.02820"
    ],
    "c_title":[
      "Rydberg Atomic Quantum Receivers for Multi-Target DOA Estimation"
    ],
    "c_abstract":[
      "Quantum sensing technologies have experienced rapid progresses since entering\nthe `second quantum revolution'. Among various candidates, schemes relying on\nRydberg atoms exhibit compelling advantages for detecting radio frequency\nsignals. Based on this, Rydberg atomic quantum receivers (RAQRs) have emerged\nas a promising solution to classical wireless communication and sensing. To\nharness the advantages and exploit the potential of RAQRs in wireless sensing,\nwe investigate the realization of the direction of arrival (DOA) estimation by\nRAQRs. Specifically, we first conceive a Rydberg atomic quantum uniform linear\narray (RAQ-ULA) aided receiver for multi-target detection and propose the\ncorresponding signal model of this sensing system. Furthermore, we propose the\nRydberg atomic quantum estimation of signal parameters by designing a\nrotational invariance based technique termed as RAQ-ESPRIT relying on our\nmodel. The proposed algorithm solves the sensor gain mismatch problem, which is\ndue to the presence of the RF local oscillator in the RAQ-ULA and cannot be\nwell addressed by using the conventional ESPRIT. Lastly, we characterize our\nscheme through numerical simulations."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-808",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14754"
    ],
    "b_title":[
      "Kharitonov's Theorem with Degree Drop: a Wronskian Approach"
    ],
    "b_abstract":[
      "In this paper, we present a simplified proof of Kharitonov's Theorem, an\nimportant result on determining the Hurwitz stability of interval polynomials.\nOur new approach to the proof, which is based on the Wronskian of a pair of\npolynomials, is not only more elementary in comparison to known methods, but is\nable to handle the degree drop case with ease."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.CV",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.16046"
    ],
    "c_title":[
      "Revisiting Projection-Free Online Learning with Time-Varying Constraints"
    ],
    "c_abstract":[
      "We investigate constrained online convex optimization, in which decisions\nmust belong to a fixed and typically complicated domain, and are required to\napproximately satisfy additional time-varying constraints over the long term.\nIn this setting, the commonly used projection operations are often\ncomputationally expensive or even intractable. To avoid the time-consuming\noperation, several projection-free methods have been proposed with an\n$\\mathcal{O}(T^{3\/4} \\sqrt{\\log T})$ regret bound and an $\\mathcal{O}(T^{7\/8})$\ncumulative constraint violation (CCV) bound for general convex losses. In this\npaper, we improve this result and further establish \\textit{novel} regret and\nCCV bounds when loss functions are strongly convex. The primary idea is to\nfirst construct a composite surrogate loss, involving the original loss and\nconstraint functions, by utilizing the Lyapunov-based technique. Then, we\npropose a parameter-free variant of the classical projection-free method,\nnamely online Frank-Wolfe (OFW), and run this new extension over the\nonline-generated surrogate loss. Theoretically, for general convex losses, we\nachieve an $\\mathcal{O}(T^{3\/4})$ regret bound and an $\\mathcal{O}(T^{3\/4} \\log\nT)$ CCV bound, both of which are order-wise tighter than existing results. For\nstrongly convex losses, we establish new guarantees of an\n$\\mathcal{O}(T^{2\/3})$ regret bound and an $\\mathcal{O}(T^{5\/6})$ CCV bound.\nMoreover, we also extend our methods to a more challenging setting with bandit\nfeedback, obtaining similar theoretical findings. Empirically, experiments on\nreal-world datasets have demonstrated the effectiveness of our methods."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-809",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09003"
    ],
    "b_title":[
      "RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach\n  for Large Language Models"
    ],
    "b_abstract":[
      "Supervised fine-tuning is a standard method for adapting pre-trained large\nlanguage models (LLMs) to downstream tasks. Quantization has been recently\nstudied as a post-training technique for efficient LLM deployment. To obtain\nquantized fine-tuned LLMs, conventional pipelines would first fine-tune the\npre-trained models, followed by post-training quantization. This often yields\nsuboptimal performance as it fails to leverage the synergy between fine-tuning\nand quantization. To effectively realize low-bit quantization of weights,\nactivations, and KV caches in LLMs, we propose an algorithm named Rotated\nStraight-Through-Estimator (RoSTE), which combines quantization-aware\nsupervised fine-tuning (QA-SFT) with an adaptive rotation strategy that\nidentifies an effective rotation configuration to reduce activation outliers.\nWe provide theoretical insights on RoSTE by analyzing its prediction error when\napplied to an overparameterized least square quantized training problem. Our\nfindings reveal that the prediction error is directly proportional to the\nquantization error of the converged weights, which can be effectively managed\nthrough an optimized rotation configuration. Experiments on Pythia, Qwen and\nLlama models of different sizes demonstrate the effectiveness of RoSTE.\nCompared to existing post-SFT quantization baselines, our method consistently\nachieves superior performances across various tasks and different LLM\narchitectures."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06542"
    ],
    "c_title":[
      "Revisiting ancient noncollapsed flows in $\\mathbb{R}^3$"
    ],
    "c_abstract":[
      "In this short paper, we give a new proof of the classification theorem for\nnoncompact ancient noncollapsed flows in $\\mathbb{R}^3$ originally due to\nBrendle-Choi (Inventiones 2019). Our new proof directly establishes\nselfsimilarity by combining the fine neck theorem from our joint work with\nHershkovits and the rigidity case of Hamilton's Harnack inequality."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-810",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05797"
    ],
    "b_title":[
      "Self-generated time crystal in hybrid Josephson junctions"
    ],
    "b_abstract":[
      "Time crystals represent a non-equilibrium state of matter with broken\ntime-translation symmetry that repeats itself at regular time intervals. Though\ninitially envisioned as a self-generated and self-sustained periodic motion,\ntheir realization has usually required the utilization of external periodic\ninputs or modulations. While at first it looked like, for a time crystal to\nexist, the initial proposal had to be abandoned, the recent evidence of\ninherent time crystals is bringing back the idea of self-generated time crystal\nunder the spotlight. In this work, we demonstrate the appearance of a\nself-generated space-time crystalline order in hybrid Josephson junctions with\nthe ferromagnet interface without any external influence. The presence of the\nexchange and the Dzyaloshinskii-Moriya interactions in a ferromagnet with\nbroken structural inversion symmetry modifies the current phase relation and\nthe critical current due to the coupling between the magnetic moment and\nJosephson phase. This breaks the time translation symmetry leading to the\nappearance of the time-crystalline order in the spatiotemporal dependence of\nsuperconducting current, which evolves with the double of the modulation\nfrequency. Due to its unique origin and properties, this inherent time\ncrystalline order stands out from the commonly known classification of time\ncrystals into discrete and continuous ones. A self-generated time crystal is\ndemonstrated in two types of hybrid Josephson junctions: the\nsuperconductor-ferromagnet-superconductor on a topological insulator and the\nsuperconductor-three layer ferromagnet-superconductor. Further, we also show\nthat a recently developed magnetometry device that visualizes a supercurrent\nflow in the Josephson junction at the nanoscale can be used as a platform for\nexperimental detection of space-time crystalline order in hybrid Josephson\njunctions."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16869"
    ],
    "c_title":[
      "Successive Refinement for Lossy Compression of Individual Sequences"
    ],
    "c_abstract":[
      "We consider the problem of successive-refinement coding for lossy compression\nof individual sequences, namely, compression in two stages, where in the first\nstage, a coarse description at a relatively low rate is sent from the encoder\nto the decoder, and in the second stage, additional coding rate is allocated in\norder to refine the description and thereby improve the reproduction. Our main\nresult is in establishing outer bounds (converse theorems) for the rate region\nwhere we limit the encoders to be finite-state machines in the spirit of Ziv\nand Lempel's 1978 model.The matching achievability scheme is conceptually\nstraightforward. We also consider the more general multiple description coding\nproblem on a similar footing and propose achievability schemes that are\nanalogous to the well-known El Gamal-Cover and the Zhang-Berger achievability\nschemes of memoryless sources and additive distortion measures."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-811",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05366"
    ],
    "b_title":[
      "An effective estimation of multivariate density functions using\n  extended-beta kernels with Bayesian adaptive bandwidths"
    ],
    "b_abstract":[
      "Multivariate kernel density estimations have received much spate of interest.\nIn addition to conventional methods of (non-)classical associated-kernels for\n(un)bounded densities and bandwidth selections, the multiple extended-beta\nkernel (MEBK) estimators with Bayesian adaptive bandwidths are invested to gain\na deeper and better insight into the estimation of multivariate density\nfunctions. Being unimodal, the univariate extended-beta smoother has an\nadaptable compact support which is suitable for each dataset, always limited.\nThe support of the density MBEK estimator can be known or estimated by extreme\nvalues. Thus, asymptotical properties for the (non-)normalized estimators are\nestablished. Explicit and general choices of bandwidths using the flexible\nBayesian adaptive method are provided. Behavioural analyses, specifically\nundertaken on the sensitive edges of the estimator support, are studied and\ncompared to Gaussian and gamma kernel estimators. Finally, simulation studies\nand three applications on original and usual real-data sets of the proposed\nmethod yielded very interesting advantages with respect to its flexibility as\nwell as its universality."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.07164"
    ],
    "c_title":[
      "Microscopic Calculations of Stellar Weak Rates for sd- and fp-Shell\n  Nuclei for Astrophysical Applications"
    ],
    "c_abstract":[
      "Proton neutron quasiparticle RPA is used for the first time to calculate weak\ninteraction rates for sd and fp shell nuclei at high temperatures and\ndensities. The calculated rates take into consideration the latest experimental\nenergy levels and ft value compilations. Particle emission processes from\nexcited states are taken into account. The calculation is done for 700 nuclei\nwith mass number ranging from 18 to 100. The astrophysical applications of the\ncalculated rates are highlighted."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-812",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04675"
    ],
    "b_title":[
      "Enhancing Financial VQA in Vision Language Models using Intermediate\n  Structured Representations"
    ],
    "b_abstract":[
      "Chart interpretation is crucial for visual data analysis, but accurately\nextracting information from charts poses significant challenges for automated\nmodels. This study investigates the fine-tuning of DEPLOT, a modality\nconversion module that translates the image of a plot or chart to a linearized\ntable, on a custom dataset of 50,000 bar charts. The dataset comprises simple,\nstacked, and grouped bar charts, targeting the unique structural features of\nthese visualizations. The finetuned DEPLOT model is evaluated against its base\nversion using a test set of 1,000 images and two metrics: Relative Mapping\nSimilarity (RMS), which measures categorical mapping accuracy, and Relative\nNumber Set Similarity (RNSS), which evaluates numerical interpretation\naccuracy. To further explore the reasoning capabilities of large language\nmodels (LLMs), we curate an additional set of 100 bar chart images paired with\nquestion answer sets. Our findings demonstrate that providing a structured\nintermediate table alongside the image significantly enhances LLM reasoning\nperformance compared to direct image queries."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10771"
    ],
    "c_title":[
      "Analysis and numerical analysis of the Helmholtz-Korteweg equation"
    ],
    "c_abstract":[
      "We analyze the Helmholtz--Korteweg and nematic Helmholtz--Korteweg equations,\nvariants of the classical Helmholtz equation for time-harmonic wave propagation\nfor Korteweg and nematic Korteweg fluids. Korteweg fluids are ones where the\nstress tensor depends on density gradients; nematic Korteweg fluids further\ndepend on a nematic director describing the orientation of the (anisotropic)\nmolecules. We prove existence and uniqueness of solutions to these equations\nfor suitable (nonresonant) wave numbers and propose convergent discretizations\nfor their numerical solution. The discretization of these equations is\nnontrivial as they demand high regularity and involve unfamiliar boundary\nconditions; we address these challenges by using high-order conforming finite\nelements, and enforcing the boundary conditions with Nitsche's method. We\nillustrate our analysis with numerical simulations in two dimensions."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-813",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08367"
    ],
    "b_title":[
      "Embodied Crowd Counting"
    ],
    "b_abstract":[
      "Occlusion is one of the fundamental challenges in crowd counting. In the\ncommunity, various data-driven approaches have been developed to address this\nissue, yet their effectiveness is limited. This is mainly because most existing\ncrowd counting datasets on which the methods are trained are based on passive\ncameras, restricting their ability to fully sense the environment. Recently,\nembodied navigation methods have shown significant potential in precise object\ndetection in interactive scenes. These methods incorporate active camera\nsettings, holding promise in addressing the fundamental issues in crowd\ncounting. However, most existing methods are designed for indoor navigation,\nshowing unknown performance in analyzing complex object distribution in large\nscale scenes, such as crowds. Besides, most existing embodied navigation\ndatasets are indoor scenes with limited scale and object quantity, preventing\nthem from being introduced into dense crowd analysis. Based on this, a novel\ntask, Embodied Crowd Counting (ECC), is proposed. We first build up an\ninteractive simulator, Embodied Crowd Counting Dataset (ECCD), which enables\nlarge scale scenes and large object quantity. A prior probability distribution\nthat approximates realistic crowd distribution is introduced to generate\ncrowds. Then, a zero-shot navigation method (ZECC) is proposed. This method\ncontains a MLLM driven coarse-to-fine navigation mechanism, enabling active\nZ-axis exploration, and a normal-line-based crowd distribution analysis method\nfor fine counting. Experimental results against baselines show that the\nproposed method achieves the best trade-off between counting accuracy and\nnavigation cost."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03423"
    ],
    "c_title":[
      "On $2$-elusive primitive permutation groups"
    ],
    "c_abstract":[
      "Let $G$ be a nontrivial transitive permutation group on a finite set\n$\\Omega$. By a classical theorem of Jordan, $G$ contains a derangement, which\nis an element with no fixed points on $\\Omega$. Given a prime divisor $r$ of\n$|\\Omega|$, we say that $G$ is $r$-elusive if it does not contain a derangement\nof order $r$. In a paper from 2011, Burness, Giudici and Wilson essentially\nreduce the classification of the $r$-elusive primitive groups to the case where\n$G$ is an almost simple group of Lie type. The classical groups with an\n$r$-elusive socle have been determined by Burness and Giudici, and in this\npaper we consider the analogous problem for the exceptional groups of Lie type,\nfocussing on the special case $r=2$. Our main theorem describes all the almost\nsimple primitive exceptional groups with a $2$-elusive socle. In other words,\nwe determine the pairs $(G,M)$, where $G$ is an almost simple exceptional group\nof Lie type with socle $T$ and $M$ is a core-free maximal subgroup that\nintersects every conjugacy class of involutions in $T$. Our results are\nconclusive, with the exception of a finite list of undetermined cases for $T =\nE_8(q)$, which depend on the existence (or otherwise) of certain almost simple\nmaximal subgroups of $G$ that have not yet been completely classified."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-814",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07031"
    ],
    "b_title":[
      "Negative Local Partial Density of States"
    ],
    "b_abstract":[
      "Real quantum systems can exhibit a local object called local partial density\nof states (LPDOS) that cannot be proved within the axiomatic approach of\nquantum mechanics. We demonstrate that real mesoscopic system that can exhibit\nFano resonances will show this object and also very counterintuitively it can\nbecome negative, resulting in the enhancement of coherent currents."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.17606"
    ],
    "c_title":[
      "Combining longitudinal cohort studies to examine cardiovascular risk\n  factor trajectories across the adult lifespan"
    ],
    "c_abstract":[
      "We introduce a statistical framework for combining data from multiple large\nlongitudinal cardiovascular cohorts to enable the study of long-term\ncardiovascular health starting in early adulthood. Using data from seven\ncohorts belonging to the Lifetime Risk Pooling Project (LRPP), we present a\nBayesian hierarchical multivariate approach that jointly models multiple\nlongitudinal risk factors over time and across cohorts. Because few cohorts in\nour project cover the entire adult lifespan, our strategy uses information from\nall risk factors to increase precision for each risk factor trajectory and\nborrows information across cohorts to fill in unobserved risk factors. We\ndevelop novel diagnostic testing and model validation methods to ensure that\nour model robustly captures and maintains critical relationships over time and\nacross risk factors."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-815",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18525"
    ],
    "b_title":[
      "Magnetically-assisted vorticity production in decaying acoustic\n  turbulence"
    ],
    "b_abstract":[
      "We study vorticity production in isothermal, subsonic, acoustic\n(nonvortical), decaying turbulence due to the presence of magnetic fields.\nUsing three-dimensional numerical simulations, we always find that the\nresulting turbulent kinetic energy cascade follows the ordinary Kolmogorov\nphenomenology involving a constant spectral energy flux. For acoustic\nturbulence, the corresponding nondimensional prefactor is larger than the\nstandard Kolmogorov constant due to an inefficiency in dissipating kinetic\nenergy. We find that the Lorentz force can not only drive the direct production\nof vortical motions, but it can also facilitate the conversion of acoustic\nenergy into vortical energy. This conversion is shown to be quadratic in the\nmagnetic field strength and linear in the acoustic flow speed. By contrast, the\ndirect production of vortical motions by the magnetic field is linear in the\nfield strength. Our results suggest that magnetic fields play a crucial role in\nvorticity production in cosmological flows, particularly in scenarios where\nsignificant acoustic turbulence is prevalent. We also discuss the implications\nof our findings for the early universe, where magnetic fields may convert\nacoustic turbulence generated during cosmological phase transitions into\nvortical turbulence."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.06050"
    ],
    "c_title":[
      "Results and open questions on the boundary control of moving sets"
    ],
    "c_abstract":[
      "These notes provide a survey of recent results and open problems on the\nboundary control of moving sets. Motivated by the control of an invasive\nbiological species, we consider a class of optimization problems for a moving\nset $t\\mapsto \\Omega(t)$, where the goal is to minimize the area of the\ncontaminated set $\\Omega(t)$ over time, plus a cost related to the control\neffort. Here the control function is the inward normal speed, assigned along\nthe boundary $\\partial \\Omega(t)$. We also consider problems with geographical\nconstraints, where the invasive population is restricted within an island.\nExistence and structure of eradication strategies, which entirely remove the\ninvasive population in minimum time, is also discussed."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-816",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12432"
    ],
    "b_title":[
      "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel\n  Tool Invocation"
    ],
    "b_abstract":[
      "Although current Large Language Models (LLMs) exhibit impressive\ncapabilities, performing complex real-world tasks still requires tool learning.\nMainstream methods, such as CoT\/ReAct, rely on step-by-step tool invocation to\ninteract with external environments, but they are limited in perceptual scope\nand lack adequate task-planning capability. To address these limitations, other\nstudies introduce the first Search-based Decision Tree (DFSDT), which still\nsuffers from the high computational cost. In this paper, we introduce a novel\nparallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).\nFirst, we transform traditional tree-based tool search paths into Directed\nAcyclic Graph (DAG) structure, generating a high-quality parallel tool\ninvocation dataset. The DTA-Llama is then trained on the dataset to learn to\niteratively divide the current task into several parallel tool invocation\nsub-tasks and aggregate the invocation results to decide the next actions.\nFurthermore, we introduce an efficient inference framework inspired by the\nProcess\/Threads mechanism when applying the DTA-Llama to practical tasks.\nExperimental results show that our approach substantially enhances task\nperformance while reducing token consumption and inference time. Llama2-7B,\nusing our method, is comparable to the official parallel function calling\nmethod of GPT-3.5. The relevant code, dataset, and model weights are available\nat https:\/\/corn0205.github.io\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05359"
    ],
    "c_title":[
      "On the Orbit of the Binary Brown Dwarf Companion GL229 Ba and Bb"
    ],
    "c_abstract":[
      "The companion GL229B was recently resolved by Xuan et al. (2024) as a tight\nbinary of two brown dwarfs (Ba and Bb) through VLTI-GRAVITY interferometry and\nVLT-CRIRES+ RV measurements. Here, we present Bayesian models of the\ninterferometric and RV data in additional detail, along with an updated outer\norbit of the brown dwarf pair about the primary. To create a model of the inner\norbit with robust uncertainties, we apply kernel phases to the GRAVITY data to\naddress baseline redundancy in the raw closure phases. Using parallel\ntempering, we constrain the binary's orbit using only VLTI-GRAVITY data,\ndespite each epoch having low visibility-plane coverage and\/or SNR. We\ndemonstrate very agreement the VLTI-GRAVITY and CRIRES+ datasets and find that\nthe inner binary has a period of 12.1346$\\pm$0.0011 days, eccentricity of\n0.2317$\\pm$0.0025, and total mass of 71.0$\\pm$0.4 Mjup, with Ba and Bb having\nmasses of 37.7$\\pm$1.1Mjup and 33.4$\\pm$1.0Mjup respectively. With new\nKeck\/NIRC2 astrometry, we update the outer orbit GL229B around the primary. We\nfind a semi-major axis of 42.9+3.0-2.4AU, eccentricity of 0.736$\\pm$0.014, and\na total mass for B of 71.7$\\pm$0.6Mjup, consistent with that derived from the\ninner orbit. We find a mutual inclination of 31$\\pm$2.5deg, below the threshold\nfor Kozai-Lidov oscillations. The agreement on the mass of Ba+Bb between the\ninner and outer orbits is an important test of our ability to model RV,\nastrometry, and Hipparcos-Gaia proper motion anomaly. Our methodological\nadvances in handling interferometric data with low SNR and sparse UV-coverage\nwill benefit future observations of rapidly-orbiting companions with\nVLTI-GRAVITY."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-817",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13336"
    ],
    "b_title":[
      "Gradient-Free Adversarial Purification with Diffusion Models"
    ],
    "b_abstract":[
      "Adversarial training and adversarial purification are two effective and\npractical defense methods to enhance a model's robustness against adversarial\nattacks. However, adversarial training necessitates additional training, while\nadversarial purification suffers from low time efficiency. More critically,\ncurrent defenses are designed under the perturbation-based adversarial threat\nmodel, which is ineffective against the recently proposed unrestricted\nadversarial attacks. In this paper, we propose an effective and efficient\nadversarial defense method that counters both perturbation-based and\nunrestricted adversarial attacks. Our defense is inspired by the observation\nthat adversarial attacks are typically located near the decision boundary and\nare sensitive to pixel changes. To address this, we introduce adversarial\nanti-aliasing to mitigate adversarial modifications. Additionally, we propose\nadversarial super-resolution, which leverages prior knowledge from clean\ndatasets to benignly recover images. These approaches do not require additional\ntraining and are computationally efficient without calculating gradients.\nExtensive experiments against both perturbation-based and unrestricted\nadversarial attacks demonstrate that our defense method outperforms\nstate-of-the-art adversarial purification methods."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.04830"
    ],
    "c_title":[
      "Quantum Supremacy in Tomographic Imaging: Advances in Quantum Tomography\n  Algorithms"
    ],
    "c_abstract":[
      "Quantum computing has emerged as a transformative paradigm, capable of\ntackling complex computational problems that are infeasible for classical\nmethods within a practical timeframe. At the core of this advancement lies the\nconcept of quantum supremacy, which signifies the ability of quantum processors\nto surpass classical systems in specific tasks. In the context of tomographic\nimage reconstruction, quantum optimization algorithms enable faster processing\nand clearer imaging than conventional methods. This study further substantiates\nquantum supremacy by reducing the required projection angles for tomographic\nreconstruction while enhancing robustness against image artifacts. Notably, our\nexperiments demonstrated that the proposed algorithm accurately reconstructed\ntomographic images without artifacts, even when up to 50% error was introduced\ninto the sinogram to induce ring artifacts. Furthermore, it achieved precise\nreconstructions using only 50% of the projection angles from the original\nsinogram spanning 0{\\deg} to 180{\\deg}. These findings highlight the potential\nof quantum algorithms to revolutionize tomographic imaging by enabling\nefficient and accurate reconstructions under challenging conditions, paving the\nway for broader applications in medical imaging, material science, and advanced\ntomography systems as quantum computing technologies continue to advance."
    ],
    "c_categories":[
      [
        "eess.IV",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-818",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02839"
    ],
    "b_title":[
      "Contaminating Electromagnetic Transients in LISA Gravitational Wave\n  Localization Volumes. I: The Intrinsic Rates"
    ],
    "b_abstract":[
      "The Laser Interferometer Space Antenna (LISA) will soon detect gravitational\nwaves (GWs) emitted by massive black hole (MBH) mergers. Some theoretical\nmodels have predicted transient electromagnetic (EM) emission from these\nmergers, enabling the association of LISA GW sources with their EM counterparts\nvia telescope follow-up. However, the number of unrelated EM transients that\nmight contaminate telescope searches for the true transient counterparts of\nLISA MBH mergers is unknown. We investigate the expected numbers of unrelated\nEM transients that will coincide with simulated LISA localization volumes of\nMBH mergers, as a function of the merger total mass and redshift. We find that\nthe number of potential contaminants in LISA localization volumes drops to\nunity for mergers at $z \\lesssim 0.8$ and at 1 hour before coalescence. After\ncoalescence, the parameter space corresponding to a maximum of one potential\ncontaminant expands to $z \\lesssim 1.5$. In contrast, if the redshifts for all\ntransients detected in LISA sky localization regions are not available, the\nnumber of potential contaminants increases by an average factor of $\\sim100$,\nand never drops below unity. Overall, we expect the average number of\ncontaminating transients in telescope follow-up of LISA MBH mergers to be\nnon-negligible, especially without redshift information for the detected\ntransients. We recommend that endeavors designing follow-up strategies of LISA\nevents should focus on: (1) building large redshift catalogs for host galaxies,\n(2) developing robust real-time transient classification algorithms, (3) and\ncoordinating telescope resources to obtain redshifts for candidate transient EM\ncounterparts in a timely manner."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.08765"
    ],
    "c_title":[
      "Designing and evaluating advanced adaptive randomised clinical trials: a\n  practical guide"
    ],
    "c_abstract":[
      "Background\n  Advanced adaptive randomised clinical trials are increasingly used. Compared\nto their conventional counterparts, their flexibility may make them more\nefficient, increase the probability of obtaining conclusive results without\nlarger samples than necessary, and increase the probability that individual\nparticipants are allocated to more promising interventions. However, limited\nguidance is available on designing and evaluating the performance of advanced\nadaptive trials.\n  Methods\n  We summarise the methodological considerations and provide practical guidance\non the entire workflow of planning and evaluating advanced adaptive trials\nusing adaptive stopping, adaptive arm dropping, and response-adaptive\nrandomisation within a Bayesian statistical framework.\n  Results\n  This comprehensive practical guide covers the key methodological decisions\nfor advanced adaptive trials and their specification and evaluation using\nstatistical simulation. These considerations include interventions and common\ncontrol use; outcome type and generation; analysis timing and outcome-data lag;\nallocation rules; analysis model; adaptation rules for stopping and arm\ndropping; clinical scenarios assessed; performance metrics; calibration;\nsensitivity analyses; and reporting. The considerations are covered in the\ncontext of realistic examples, along with simulation code using the adaptr R\npackage.\n  Conclusions\n  This practical guide will help clinical trialists, methodologists, and\nbiostatisticians design and evaluate advanced adaptive trials."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-819",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01335"
    ],
    "b_title":[
      "ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D\n  Echocardiographies"
    ],
    "b_abstract":[
      "While traditional self-supervised learning methods improve performance and\nrobustness across various medical tasks, they rely on single-vector embeddings\nthat may not capture fine-grained concepts such as anatomical structures or\norgans. The ability to identify such concepts and their characteristics without\nsupervision has the potential to improve pre-training methods, and enable novel\napplications such as fine-grained image retrieval and concept-based outlier\ndetection. In this paper, we introduce ConceptVAE, a novel pre-training\nframework that detects and disentangles fine-grained concepts from their style\ncharacteristics in a self-supervised manner. We present a suite of loss terms\nand model architecture primitives designed to discretise input data into a\npreset number of concepts along with their local style. We validate ConceptVAE\nboth qualitatively and quantitatively, demonstrating its ability to detect\nfine-grained anatomical structures such as blood pools and septum walls from 2D\ncardiac echocardiographies. Quantitatively, ConceptVAE outperforms traditional\nself-supervised methods in tasks such as region-based instance retrieval,\nsemantic segmentation, out-of-distribution detection, and object detection.\nAdditionally, we explore the generation of in-distribution synthetic data that\nmaintains the same concepts as the training data but with distinct styles,\nhighlighting its potential for more calibrated data generation. Overall, our\nstudy introduces and validates a promising new pre-training technique based on\nconcept-style disentanglement, opening multiple avenues for developing models\nfor medical image analysis that are more interpretable and explainable than\nblack-box approaches."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19583"
    ],
    "c_title":[
      "Rootfinding and Optimization Techniques for Solving Nonlinear Systems of\n  Equations Arising from Cohesive Zone Models"
    ],
    "c_abstract":[
      "While approaches to model the progression of fracture have received\nsignificant attention, methods to find the solution to the associated nonlinear\nequations have not. In general, nonlinear solution methods and optimization\nmethods have a rich body of work spanning back to at least the first century,\nproviding the opportunity for advancement in the field of computational\ndiscrete damage modeling. In this paper, we explore the performance of\nestablished methods when applied to problems involving cohesive zone models to\nidentify promising methods for further improvement in this specialized\napplication. We first use a simple 1D example problem with low degrees of\nfreedom (DoF) to compare nonlinear solution methods, thereby allowing for both\nstraightforward and intuitive visualization of the residual space and reasoning\nabout the cause for each method's performance. We then explore the impact of\nhigher DoF discretizations of the same problem on the performance of the\nsolution methods. Finally, we discuss techniques to improve performance or to\novercome limitations of the various methods."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-820",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11758"
    ],
    "b_title":[
      "A Review Paper of the Effects of Distinct Modalities and ML Techniques\n  to Distracted Driving Detection"
    ],
    "b_abstract":[
      "Distracted driving remains a significant global challenge with severe human\nand economic repercussions, demanding improved detection and intervention\nstrategies. While previous studies have extensively explored single-modality\napproaches, recent research indicates that these systems often fall short in\nidentifying complex distraction patterns, particularly cognitive distractions.\nThis systematic review addresses critical gaps by providing a comprehensive\nanalysis of machine learning (ML) and deep learning (DL) techniques applied\nacross various data modalities - visual,, sensory, auditory, and multimodal. By\ncategorizing and evaluating studies based on modality, data accessibility, and\nmethodology, this review clarifies which approaches yield the highest accuracy\nand are best suited for specific distracted driving detection goals. The\nfindings offer clear guidance on the advantages of multimodal versus\nsingle-modal systems and capture the latest advancements in the field.\nUltimately, this review contributes valuable insights for developing robust\ndistracted driving detection frameworks, supporting enhanced road safety and\nmitigation strategies."
    ],
    "b_categories":[
      [
        "cs.CV",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19654"
    ],
    "c_title":[
      "Latent Space Mapping: Revolutionizing Predictive Models for Divertor\n  Plasma Detachment Control"
    ],
    "c_abstract":[
      "The inherent complexity of boundary plasma, characterized by multi-scale and\nmulti-physics challenges, has historically restricted high-fidelity simulations\nto scientific research due to their intensive computational demands.\nConsequently, routine applications such as discharge control and scenario\ndevelopment have relied on faster, but less accurate empirical methods. This\nwork introduces DivControlNN, a novel machine-learning-based surrogate model\ndesigned to address these limitations by enabling quasi-real-time predictions\n(i.e., $\\sim0.2$ ms) of boundary and divertor plasma behavior. Trained on over\n70,000 2D UEDGE simulations from KSTAR tokamak equilibria, DivControlNN employs\nlatent space mapping to efficiently represent complex divertor plasma states,\nachieving a computational speed-up of over $10^8$ compared to traditional\nsimulations while maintaining a relative error below 20% for key plasma\nproperty predictions. During the 2024 KSTAR experimental campaign, a prototype\ndetachment control system powered by DivControlNN successfully demonstrated\ndetachment control on its first attempt, even for a new tungsten divertor\nconfiguration and without any fine-tuning. These results highlight the\ntransformative potential of DivControlNN in overcoming diagnostic challenges in\nfuture fusion reactors by providing fast, robust, and reliable predictions for\nadvanced integrated control systems."
    ],
    "c_categories":[
      [
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-821",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05920"
    ],
    "b_title":[
      "IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative\n  Language Model Pretraining"
    ],
    "b_abstract":[
      "Recent advancements in large language models have intensified the need for\nefficient and deployable models within limited inference budgets. Structured\npruning pipelines have shown promise in token efficiency compared to training\ntarget-size models from scratch. In this paper, we advocate incorporating\nenlarged model pretraining, which is often ignored in previous works, into\npruning. We study the enlarge-and-prune pipeline as an integrated system to\naddress two critical questions: whether it is worth pretraining an enlarged\nmodel even when the model is never deployed, and how to optimize the entire\npipeline for better pruned models. We propose an integrated enlarge-and-prune\npipeline, which combines enlarge model training, pruning, and recovery under a\nsingle cosine annealing learning rate schedule. This approach is further\ncomplemented by a novel iterative structured pruning method for gradual\nparameter removal. The proposed method helps to mitigate the knowledge loss\ncaused by the rising learning rate in naive enlarge-and-prune pipelines and\nenable effective redistribution of model capacity among surviving neurons,\nfacilitating smooth compression and enhanced performance. We conduct\ncomprehensive experiments on compressing 2.8B models to 1.3B with up to 2T\ntokens in pretraining. It demonstrates the integrated approach not only\nprovides insights into the token efficiency of enlarged model pretraining but\nalso achieves superior performance of pruned models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.13580"
    ],
    "c_title":[
      "Multivariable $(\\varphi_q,\\mathcal{O}_K^{\\times})$-modules associated to\n  $p$-adic representations of $\\mathrm{Gal}(\\overline{K}\/K)$"
    ],
    "c_abstract":[
      "Let $K$ be an unramified extension of $\\mathbb{Q}_p$, and $E$ a finite\nextension of $K$ with ring of integers $\\mathcal{O}_E$. We associate to every\nfinite type continuous $\\mathcal{O}_E$-representation $\\rho$ of\n$\\mathrm{Gal}(\\overline{K}\/K)$ an \\'etale\n$(\\varphi_q,\\mathcal{O}_K^{\\times})$-module $D_{A_{\\mathrm{mv},E}}^{(0)}(\\rho)$\nover $A_{\\mathrm{mv},E}$, where $A_{\\mathrm{mv},E}$ is the $p$-adic completion\nof a completed localization of the Iwasawa algebra\n$\\mathcal{O}_E[\\negthinspace[\\mathcal{O}_K]\\negthinspace]$. Furthermore, we\nprove that the functor $D_{A_{\\mathrm{mv},E}}^{(0)}$ is fully faithful and\nexact. This functor is a $p$-adic analogue of $D_A^{(0)}$ in the recent work of\nBreuil, Herzig, Hu, Morra and Schraen."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-822",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10411"
    ],
    "b_title":[
      "TrueReason: An Exemplar Personalised Learning System Integrating\n  Reasoning with Foundational Models"
    ],
    "b_abstract":[
      "Personalised education is one of the domains that can greatly benefit from\nthe most recent advances in Artificial Intelligence (AI) and Large Language\nModels (LLM). However, it is also one of the most challenging applications due\nto the cognitive complexity of teaching effectively while personalising the\nlearning experience to suit independent learners. We hypothesise that one\npromising approach to excelling in such demanding use cases is using a\n\\emph{society of minds}. In this chapter, we present TrueReason, an exemplar\npersonalised learning system that integrates a multitude of specialised AI\nmodels that can mimic micro skills that are composed together by a LLM to\noperationalise planning and reasoning. The architecture of the initial\nprototype is presented while describing two micro skills that have been\nincorporated in the prototype. The proposed system demonstrates the first step\nin building sophisticated AI systems that can take up very complex cognitive\ntasks that are demanded by domains such as education."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.IR",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03708"
    ],
    "c_title":[
      "Aggregate and conquer: detecting and steering LLM concepts by combining\n  nonlinear predictors over multiple layers"
    ],
    "c_abstract":[
      "A trained Large Language Model (LLM) contains much of human knowledge. Yet,\nit is difficult to gauge the extent or accuracy of that knowledge, as LLMs do\nnot always ``know what they know'' and may even be actively misleading. In this\nwork, we give a general method for detecting semantic concepts in the internal\nactivations of LLMs. Furthermore, we show that our methodology can be easily\nadapted to steer LLMs toward desirable outputs. Our innovations are the\nfollowing: (1) we use a nonlinear feature learning method to identify important\nlinear directions for predicting concepts from each layer; (2) we aggregate\nfeatures across layers to build powerful concept detectors and steering\nmechanisms. We showcase the power of our approach by attaining state-of-the-art\nresults for detecting hallucinations, harmfulness, toxicity, and untruthful\ncontent on seven benchmarks. We highlight the generality of our approach by\nsteering LLMs towards new concepts that, to the best of our knowledge, have not\nbeen previously considered in the literature, including: semantic\ndisambiguation, human languages, programming languages, hallucinated responses,\nscience subjects, poetic\/Shakespearean English, and even multiple concepts\nsimultaneously. Moreover, our method can steer concepts with numerical\nattributes such as product reviews. We provide our code (including a simple API\nfor our methods) at https:\/\/github.com\/dmbeaglehole\/neural_controllers ."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-823",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10573"
    ],
    "b_title":[
      "The Geometry of Tokens in Internal Representations of Large Language\n  Models"
    ],
    "b_abstract":[
      "We investigate the relationship between the geometry of token embeddings and\ntheir role in the next token prediction within transformer models. An important\naspect of this connection uses the notion of empirical measure, which encodes\nthe distribution of token point clouds across transformer layers and drives the\nevolution of token representations in the mean-field interacting picture. We\nuse metrics such as intrinsic dimension, neighborhood overlap, and cosine\nsimilarity to observationally probe these empirical measures across layers. To\nvalidate our approach, we compare these metrics to a dataset where the tokens\nare shuffled, which disrupts the syntactic and semantic structure. Our findings\nreveal a correlation between the geometric properties of token embeddings and\nthe cross-entropy loss of next token predictions, implying that prompts with\nhigher loss values have tokens represented in higher-dimensional spaces."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08594"
    ],
    "c_title":[
      "Observation of Impurity-Induced Scale-Free Localization in a Disordered\n  Non-Hermitian Electrical Circuit"
    ],
    "c_abstract":[
      "One of unique features of non-Hermitian systems is the extreme sensitive to\ntheir boundary conditions, e.g., the emergence of non-Hermitian skin effect\n(NHSE) under the open boundary conditions, where most of bulk states become\nlocalized at the boundaries. In the presence of impurities, the scale-free\nlocalization can appear, which is qualitatively distinct from the NHSE. Here,\nwe experimentally design a disordered non-Hermitian electrical circuits in the\npresence of a single non-Hermitian impurity and the nonreciprocal hopping. We\nobserve the anomalous scale-free accumulation of eigenstates, opposite to the\nbulk hopping direction. The experimental results open the door to further\nexplore the anomalous skin effects in non-Hermitian electrical circuits."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-824",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06030"
    ],
    "b_title":[
      "Towards Universal Text-driven CT Image Segmentation"
    ],
    "b_abstract":[
      "Computed tomography (CT) is extensively used for accurate visualization and\nsegmentation of organs and lesions. While deep learning models such as\nconvolutional neural networks (CNNs) and vision transformers (ViTs) have\nsignificantly improved CT image analysis, their performance often declines when\napplied to diverse, real-world clinical data. Although foundation models offer\na broader and more adaptable solution, their potential is limited due to the\nchallenge of obtaining large-scale, voxel-level annotations for medical images.\nIn response to these challenges, prompting-based models using visual or text\nprompts have emerged. Visual-prompting methods, such as the Segment Anything\nModel (SAM), still require significant manual input and can introduce ambiguity\nwhen applied to clinical scenarios. Instead, foundation models that use text\nprompts offer a more versatile and clinically relevant approach. Notably,\ncurrent text-prompt models, such as the CLIP-Driven Universal Model, are\nlimited to text prompts already encountered during training and struggle to\nprocess the complex and diverse scenarios of real-world clinical applications.\nInstead of fine-tuning models trained from natural imaging, we propose\nOpenVocabCT, a vision-language model pretrained on large-scale 3D CT images for\nuniversal text-driven segmentation. Using the large-scale CT-RATE dataset, we\ndecompose the diagnostic reports into fine-grained, organ-level descriptions\nusing large language models for multi-granular contrastive learning. We\nevaluate our OpenVocabCT on downstream segmentation tasks across nine public\ndatasets for organ and tumor segmentation, demonstrating the superior\nperformance of our model compared to existing methods. All code, datasets, and\nmodels will be publicly released at https:\/\/github.com\/ricklisz\/OpenVocabCT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01046"
    ],
    "c_title":[
      "MAPS: Multi-Fidelity AI-Augmented Photonic Simulation and Inverse Design\n  Infrastructure"
    ],
    "c_abstract":[
      "Inverse design has emerged as a transformative approach for photonic device\noptimization, enabling the exploration of high-dimensional, non-intuitive\ndesign spaces to create ultra-compact devices and advance photonic integrated\ncircuits (PICs) in computing and interconnects. However, practical challenges,\nsuch as suboptimal device performance, limited manufacturability, high\nsensitivity to variations, computational inefficiency, and lack of\ninterpretability, have hindered its adoption in commercial hardware. Recent\nadvancements in AI-assisted photonic simulation and design offer transformative\npotential, accelerating simulations and design generation by orders of\nmagnitude over traditional numerical methods. Despite these breakthroughs, the\nlack of an open-source, standardized infrastructure and evaluation benchmark\nlimits accessibility and cross-disciplinary collaboration. To address this, we\nintroduce MAPS, a multi-fidelity AI-augmented photonic simulation and inverse\ndesign infrastructure designed to bridge this gap. MAPS features three\nsynergistic components: (1) MAPS-Data: A dataset acquisition framework for\ngenerating multi-fidelity, richly labeled devices, providing high-quality data\nfor AI-for-optics research. (2) MAPS-Train: A flexible AI-for-photonics\ntraining framework offering a hierarchical data loading pipeline, customizable\nmodel construction, support for data- and physics-driven losses, and\ncomprehensive evaluations. (3) MAPS-InvDes: An advanced adjoint inverse design\ntoolkit that abstracts complex physics but exposes flexible optimization steps,\nintegrates pre-trained AI models, and incorporates fabrication variation\nmodels. This infrastructure MAPS provides a unified, open-source platform for\ndeveloping, benchmarking, and advancing AI-assisted photonic design workflows,\naccelerating innovation in photonic hardware optimization and scientific\nmachine learning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.ET",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-825",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03137"
    ],
    "b_title":[
      "Distributionally Robust Control Synthesis for Stochastic Systems with\n  Safety and Reach-Avoid Specifications"
    ],
    "b_abstract":[
      "We investigate the problem of synthesizing distributionally robust control\npolicies for stochastic systems under safety and reach-avoid specifications.\nUsing a game-theoretical framework, we consider the setting where the\nprobability distribution of the disturbance at each time step is selected from\nan ambiguity set defined by the Wasserstein distance. The goal is to synthesize\na distributionally robust control policy that ensures the satisfaction\nprobability exceeds a specified threshold under any distribution within the\nambiguity set. First, for both safety and reach-avoid specifications, we\nestablish the existence of optimal policies by leveraging the dynamic\nprogramming principles. Then we demonstrate how the associated optimization\nproblem can be efficiently solved using the dual representation of Wasserstein\ndistributionally robust optimization. Furthermore, for safety specifications in\nparticular, we introduce a novel concept of distributionally robust control\nbarrier certificates and show how these enable the efficient synthesis of\ncontrollers through sum-of-squares programming techniques. Finally, our\nexperimental results reveal that incorporating distributional robustness during\nthe synthesis phase significantly improves the satisfaction probability during\nonline execution, even with limited statistical knowledge of the disturbance\ndistribution."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12163"
    ],
    "c_title":[
      "Non-Hermitian wave-packet dynamics and its realization within a\n  non-Hermitian chiral cavity"
    ],
    "c_abstract":[
      "Topological wave-packet dynamics provide a powerful framework for studying\nquantum transport in topological materials. However, extending this approach to\nnon-Hermitian quantum systems presents several important challenges, primarily\ndue to ambiguities in defining the Berry phase and the non-unitary evolution of\nthe wave-packets when $\\mathcal{P}\\mathcal{T}$ symmetry is broken. In this\nwork, we adopt the complex Berry phase definition using the bi-orthogonal\nformalism and derive the semiclassical equations of motion (EOM) for a\nwave-packet in a non-Hermitian topological system. Interestingly, we find that\nthe complex Berry curvature introduces both an anomalous velocity and an\nanomalous force into the semiclassical EOM. To validate the derived EOM, we\ndesign a non-Hermitian Haldane model featuring non-reciprocal\nnext-nearest-neighbor (NNN) hopping, where the imbalance in the NNN hopping\namplitudes gives rise to an emergent `complex chirality'. We reveal that the\nreal and imaginary components of the complex chirality dictate the signs of\nboth the real and imaginary parts of the complex Berry curvature, as well as\nthe direction and dissipation rate of the edge states. Our analytical findings\nare confirmed by direct numerical simulations of the wave-packet dynamics.\nFinally, we suggest a potential experimental realization of this complex\nHaldane model using a non-Hermitian optical chiral cavity, providing a\npromising platform for testing our theoretical predictions."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-826",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15504"
    ],
    "b_title":[
      "Jeffrey's update rule as a minimizer of Kullback-Leibler divergence"
    ],
    "b_abstract":[
      "In this paper, we show a more concise and high level proof than the original\none, derived by researcher Bart Jacobs, for the following theorem: in the\ncontext of Bayesian update rules for learning or updating internal states that\nproduce predictions, the relative entropy between the observations and the\npredictions is reduced when applying Jeffrey's update rule to update the\ninternal state."
    ],
    "b_categories":[
      [
        "cs.CR",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12346"
    ],
    "c_title":[
      "Ring or no ring -- Revisiting the Multiphase Nuclear Environment in M31"
    ],
    "c_abstract":[
      "Nuclear rings, prevalent in barred galaxies, are essential to understanding\ngas transport toward galactic nuclei. However, the peculiar nuclear ring in our\nneighboring galaxy M31 remains poorly understood. Here we present a\ncomprehensive study of this multiphase gas structure, originally revealed by\nits dust emission, based on newly acquired CO mappings and archival\nspectroscopic imaging of atomic hydrogen and warm ionized gas, along with\ncustom numerical simulations. These multi-wavelength data offer an\nunprecedented view of the surface mass density and kinematics of the nuclear\nring, challenging the notion of it being a single coherent structure. In\nparticular, the ring shows significant asymmetry in its azimuthal mass\ndistribution, with neutral gas concentrated in the northeast and ionized gas\nprominent in the southwest. The observed off-centered and lopsided morphology\ndisfavors an interpretation of gas streamers or resonance rings driven solely\nby a barred potential known to exist in M31. Furthermore, the ring's\nline-of-sight velocity distribution suggests circular motion in a plane\ninclined by $\\sim 30^\\circ$ relative to M31's outer disk, implying external\ntorque likely from M32's recent close-in passage. Our hydrodynamical\nsimulations tracking the evolution of nuclear gas of M31 influenced by both a\nbarred potential and an oblique collision with M32, reveal the natural\nformation of asymmetric spiral arms several hundred Myr after the collision,\nwhich could appear ring-like under appropriate viewing angles. Therefore, we\nsuggest that M31's nuclear gas structure, instead of being a persisting\nrotating ring, comprises recently formed, asymmetric spirals with a substantial\ntilt."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-827",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13205"
    ],
    "b_title":[
      "Non-local high-$p_t$ transport in anisotropic QCD matter"
    ],
    "b_abstract":[
      "We perform a numerical study of non-local partonic transport in anisotropic\nQCD matter, relevant to the evolution of hard probes in the aftermath of\nhigh-energy nuclear scattering events. The recently derived master equation,\nobtained from QFT considerations, differs from Boltzmann transport by\nincorporating a non-local elastic scattering kernel arising from density\ngradients. After rewriting the master equation in a form suitable for numerical\nimplementation and assuming a static density profile, we compare the non-local\nevolution to Boltzmann transport, demonstrating that the new interaction kernel\nis essential for accurately describing the azimuthal structure of the\nfinal-state momentum distribution. We further study the non-local partonic\ntransport in the case of a matter profile governed by two-dimensional\nhydrodynamics, accounting for its flow and generalizing the evolution equation.\nOur results demonstrate the necessity of going beyond classical transport at\nhigh-$p_t$ to accurately capture the structure of jets propagating through\nstructured QCD matter. The master equation used in the numerical simulations\ncan be seamlessly integrated into state-of-the-art transport codes."
    ],
    "b_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05116"
    ],
    "c_title":[
      "Piccolo: Large-Scale Graph Processing with Fine-Grained In-Memory\n  Scatter-Gather"
    ],
    "c_abstract":[
      "Graph processing requires irregular, fine-grained random access patterns\nincompatible with contemporary off-chip memory architecture, leading to\ninefficient data access. This inefficiency makes graph processing an extremely\nmemory-bound application. Because of this, existing graph processing\naccelerators typically employ a graph tiling-based or processing-in-memory\n(PIM) approach to relieve the memory bottleneck. In the tiling-based approach,\na graph is split into chunks that fit within the on-chip cache to maximize data\nreuse. In the PIM approach, arithmetic units are placed within memory to\nperform operations such as reduction or atomic addition. However, both\napproaches have several limitations, especially when implemented on current\nmemory standards (i.e., DDR). Because the access granularity provided by DDR is\nmuch larger than that of the graph vertex property data, much of the bandwidth\nand cache capacity are wasted. PIM is meant to alleviate such issues, but it is\ndifficult to use in conjunction with the tiling-based approach, resulting in a\nsignificant disadvantage. Furthermore, placing arithmetic units inside a memory\nchip is expensive, thereby supporting multiple types of operation is thought to\nbe impractical. To address the above limitations, we present Piccolo, an\nend-to-end efficient graph processing accelerator with fine-grained in-memory\nrandom scatter-gather. Instead of placing expensive arithmetic units in\noff-chip memory, Piccolo focuses on reducing the off-chip traffic with\nnon-arithmetic function-in-memory of random scatter-gather. To fully benefit\nfrom in-memory scatter-gather, Piccolo redesigns the cache and MHA of the\naccelerator such that it can enjoy both the advantage of tiling and in-memory\noperations. Piccolo achieves a maximum speedup of 3.28$\\times$ and a geometric\nmean speedup of 1.62$\\times$ across various and extensive benchmarks."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-828",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16243"
    ],
    "b_title":[
      "EP240414a: A Gamma-Ray Burst Jet Weakened by an Extended Circumstellar\n  Material"
    ],
    "b_abstract":[
      "The recent Einstein Probe (EP) event EP240414a exhibits several unusual\nobservational features. Its prompt and afterglow emissions place it between\nlong gamma-ray bursts (LGRBs) and low-luminosity GRBs (LLGRBs). The event is\nfollowed by a fast optical transient (AT~2024gsa), initially exhibiting a\nthermal-like spectrum but later evolving into an unusually red peak at $\\sim\n3-5$ days, which is difficult to explain with thermal emission. Using our\ngeneralized analytic framework for jet propagation in a circumstellar material\n(CSM; Hamidani et al. 2025), we explore a scenario in which a conventional LGRB\njet is launched in a progenitor surrounded by a dense CSM. For a CSM of $\\sim\n0.03 M_\\odot$ extending to $\\sim 3\\times 10^{13}$ cm, we find that the jet is\nsignificantly weakened before breaking out, becoming ``barely failed'', an\nintermediate state between successful (LGRB) and completely failed (LLGRB)\njets. This scenario naturally explains EP240414a's multi-wavelength\nobservations, with the early thermal component produced by cocoon cooling\nemission, and the red peak explained by non-thermal afterglow emission from the\nmildly relativistic barely failed jet (and its inner cocoon). Our work\ndemonstrates the important role of extended CSM in shaping GRB jets and\nillustrates how early multi-wavelength follow-up observations can reveal the\nphysically diverse nature of jet-driven transients."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.09504"
    ],
    "c_title":[
      "HydraMix: Multi-Image Feature Mixing for Small Data Image Classification"
    ],
    "c_abstract":[
      "Training deep neural networks requires datasets with a large number of\nannotated examples. The collection and annotation of these datasets is not only\nextremely expensive but also faces legal and privacy problems. These factors\nare a significant limitation for many real-world applications. To address this,\nwe introduce HydraMix, a novel architecture that generates new image\ncompositions by mixing multiple different images from the same class. HydraMix\nlearns the fusion of the content of various images guided by a\nsegmentation-based mixing mask in feature space and is optimized via a\ncombination of unsupervised and adversarial training. Our data augmentation\nscheme allows the creation of models trained from scratch on very small\ndatasets. We conduct extensive experiments on ciFAIR-10, STL-10, and\nciFAIR-100. Additionally, we introduce a novel text-image metric to assess the\ngenerality of the augmented datasets. Our results show that HydraMix\noutperforms existing state-of-the-art methods for image classification on small\ndatasets."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-829",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08222"
    ],
    "b_title":[
      "Data-driven Spatial Classification using Multi-Arm Bandits for\n  Monitoring with Energy-Constrained Mobile Robots"
    ],
    "b_abstract":[
      "We consider the spatial classification problem for monitoring using data\ncollected by a coordinated team of mobile robots. Such classification problems\narise in several applications including search-and-rescue and precision\nagriculture. Specifically, we want to classify the regions of a search\nenvironment into interesting and uninteresting as quickly as possible using a\nteam of mobile sensors and mobile charging stations. We develop a data-driven\nstrategy that accommodates the noise in sensed data and the limited energy\ncapacity of the sensors, and generates collision-free motion plans for the\nteam. We propose a bi-level approach, where a high-level planner leverages a\nmulti-armed bandit framework to determine the potential regions of interest for\nthe drones to visit next based on the data collected online. Then, a low-level\npath planner based on integer programming coordinates the paths for the team to\nvisit the target regions subject to the physical constraints. We characterize\nseveral theoretical properties of the proposed approach, including anytime\nguarantees and task completion time. We show the efficacy of our approach in\nsimulation, and further validate these observations in physical experiments\nusing mobile robots."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10531"
    ],
    "c_title":[
      "Growing Spines Ad Infinitum"
    ],
    "c_abstract":[
      "We show that every non-trivial ordered abelian group $G$ is augmentable by\ninfinite elements, i.e., we have $G\\preccurlyeq H\\oplus G$ for some non-trivial\nordered abelian group $H$. As an application, we show that when $k$ is a field\nof characteristic 0, then $k$ is not $t$-henselian if and only if all henselian\nvaluations with residue field $k$ are ($\\emptyset$-)definable."
    ],
    "c_categories":[
      [
        "math.GR",
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-830",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.11676"
    ],
    "b_title":[
      "Cosmic Large-Scale Structure Formation from Newtonian Particle Dynamics"
    ],
    "b_abstract":[
      "We present results for the cosmic non-linear density-fluctuation power\nspectrum based on the analytical formalism developed in [1] which allows us to\nstudy cosmic structure formation based on Newtonian particle dynamics in\nphase-space. This framework provides a field-theory approach to a perturbative\nsolution of the BBGKY-hierarchy where the resulting loop-expansion of the\ntheory introduces a natural truncation criterion. We show that we are able to\nreproduce structure growth on large scales $k \\leq 0.2\n\\mathrm{h}\\,\\mathrm{Mpc}^{-1}$ to very high precision while on small and\nintermediate scales we find deviations of the order of $10\\%$ from current\nnumerical simulations. The results strongly suggest that a significant\nimprovement may be achieved by restructuring the perturbation theory."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03894"
    ],
    "c_title":[
      "Robust Moving-horizon Estimation for Nonlinear Systems: From Perfect to\n  Imperfect Optimization"
    ],
    "c_abstract":[
      "Robust stability of moving-horizon estimators is investigated for nonlinear\ndiscrete-time systems that are detectable in the sense of incremental\ninput\/output-to-state stability and are affected by disturbances. The estimate\nof a moving-horizon estimator stems from the on-line solution of a\nleast-squares minimization problem at each time instant. The resulting\nstability guarantees depend on the optimization tolerance in solving such\nminimization problems. Specifically, two main contributions are established:\n(i) the robust stability of the estimation error, while supposing to solve\nexactly the on-line minimization problem; (ii) the practical robust stability\nof the estimation error with state estimates obtained by an imperfect\nminimization. Finally, the construction of such robust moving-horizon\nestimators and the performances resulting from the design based on the\ntheoretical findings are showcased with two numerical examples."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-831",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00941"
    ],
    "b_title":[
      "C2S-AE: CSI to Sensing enabled by an Auto-Encoder-based Framework"
    ],
    "b_abstract":[
      "Next-generation mobile networks are set to utilize integrated sensing and\ncommunication (ISAC) as a critical technology, providing significant support\nfor sectors like the industrial Internet of Things (IIoT), extended reality\n(XR), and smart home applications. A key challenge in ISAC implementation is\nthe extraction of sensing parameters from radio signals, a task that\nconventional methods struggle to achieve due to the complexity of acquiring\nsensing channel data. In this paper, we introduce a novel auto-encoder\n(AE)-based framework to acquire sensing information using channel state\ninformation (CSI). Specifically, our framework, termed C2S (CSI to sensing)-AE,\nlearns the relationship between CSI and the delay power spectrum (DPS), from\nwhich the range information can be readily accessed. To validate our\nframework's performance, we conducted measurements of DPS and CSI in real-world\nscenarios and introduced the dataset 'SHU7'. Our extensive experiments\ndemonstrate that the framework excels in C2S extrapolation, surpassing existing\nmethods in terms of accuracy for both delay and signal strength of individual\npaths. This innovative approach holds the potential to greatly enhance sensing\ncapabilities in future mobile networks, paving the way for more robust and\nversatile ISAC applications."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09704"
    ],
    "c_title":[
      "Infinity norm bounds for the inverse of Nekrasov matrices using scaling\n  matrices"
    ],
    "c_abstract":[
      "For many applications, it is convenient to have good upper bounds for the\nnorm of the inverse of a given matrix. In this paper, we obtain such bounds\nwhen A is a Nekrasov matrix, by means of a scaling matrix transforming A into a\nstrictly diagonally dominant matrix. Numerical examples and comparisons with\nother bounds are included. The scaling matrices are also used to derive new\nerror bounds for the linear complementarity problems when the involved matrix\nis a Nekrasov matrix. These error bounds can improve considerably other\nprevious bounds."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-832",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16603"
    ],
    "b_title":[
      "Superadditivity at Large Charge"
    ],
    "b_abstract":[
      "The weak gravity conjecture has been invoked to conjecture that the\ndimensions of charged operators in a CFT should obey a superadditivity relation\n(sometimes referred to as convexity). In this paper, we study superadditivity\nof the operator spectrum in theories expanded about the semi-classical saddle\npoint that dominates correlators of large charge operators. We explore this in\ntwo contexts. The first is a model with two scalar fields that carry different\ncharges, at a non-trivial Wilson-Fisher fixed point. A careful analysis of the\nsemi-classics for this two field model demonstrates that 'quantum' violations\nof superadditivity (those not forbidden by the conjecture) persist in the large\ncharge regime. We then turn to study the general properties of CFTs at large\ncharge as bottom-up EFTs. By a trial and error procedure we come up with a\nseemingly consistent family of examples violating the conjecture. In so doing\nthe presence of a genuine dilaton field appears necessary. On the one hand our\nresult demonstrates that the superadditivity conjecture cannot be proven purely\non the basis of a bottom-up analysis. On the other hand, the need for a\ndilaton, with the corresponding infinite fine tuning, indicates the\nconjecture-violating EFTs are unlikely to be UV completable."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.12383"
    ],
    "c_title":[
      "Locally-Deployed Chain-of-Thought (CoT) Reasoning Model in Chemical\n  Engineering: Starting from 30 Experimental Data"
    ],
    "c_abstract":[
      "In the field of chemical engineering, traditional data-processing and\nprediction methods face significant challenges. Machine-learning and\nlarge-language models (LLMs) also have their respective limitations. This paper\nexplores the application of the Chain-of-Thought (CoT) reasoning model in\nchemical engineering, starting from 30 experimental data points. By integrating\ntraditional surrogate models like Gaussian processes and random forests with\npowerful LLMs such as DeepSeek-R1, a hierarchical architecture is proposed. Two\nCoT-building methods, Large Language Model-Chain of Thought (LLM-CoT) and\nMachine Learning-Large Language Model-Chain of Thought (ML-LLM-CoT), are\nstudied. The LLM-CoT combines local models DeepSeek-r1:14b and Qwen2:7b with\nOllama. The ML-LLM-CoT integrates a pre-trained Gaussian ML model with the\nLLM-based CoT framework. Our results show that during construction, ML-LLM-CoT\nis more efficient. It only has 2 points that require rethink and a total of 4\nrethink times, while LLM-CoT has 5 points that need to be re-thought and 34\ntotal rethink times. In predicting the solubility of 20 molecules with\ndissimilar structures, the number of molecules with a prediction deviation\nhigher than 100\\% for the Gaussian model, LLM-CoT, and ML-LLM-CoT is 7, 6, and\n4 respectively. These results indicate that ML-LLM-CoT performs better in\ncontrolling the number of high-deviation molecules, optimizing the average\ndeviation, and achieving a higher success rate in solubility judgment,\nproviding a more reliable method for chemical engineering and molecular\nproperty prediction. This study breaks through the limitations of traditional\nmethods and offers new solutions for rapid property prediction and process\noptimization in chemical engineering."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-833",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14893"
    ],
    "b_title":[
      "Incorporating Sustainability in Electronics Design: Obstacles and\n  Opportunities"
    ],
    "b_abstract":[
      "Life cycle assessment (LCA) is a methodology for holistically measuring the\nenvironmental impact of a product from initial manufacturing to end-of-life\ndisposal. However, the extent to which LCA informs the design of computing\ndevices remains unclear. To understand how this information is collected and\napplied, we interviewed 17 industry professionals with experience in LCA or\nelectronics design, systematically coded the interviews, and investigated\ncommon themes. These themes highlight the challenge of LCA data collection and\nreveal distributed decision-making processes where responsibility for\nsustainable design choices, and their associated costs, is often ambiguous. Our\nanalysis identifies opportunities for HCI technologies to support LCA\ncomputation and its integration into the design process to facilitate\nsustainability-oriented decision-making. While this work provides a nuanced\ndiscussion about sustainable design in the information and communication\ntechnologies (ICT) hardware industry, we hope our insights will also be\nvaluable to other sectors."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14261"
    ],
    "c_title":[
      "An Inverse Design Wavelength Demultiplexer for On-Chip Photoluminescence\n  Sorting in TMDC Heterostructures"
    ],
    "c_abstract":[
      "Emerging two-dimensional transition metal dichalcogenides (TMDCs) offer a\npromising platform for on-chip integrated photonics because of their unique\noptical and electronic properties. Their naturally passivated surfaces make\nthem highly tolerant to lattice mismatch, enabling seamless heterogeneous\nintegration by stacking different van der Waals materials, a crucial step in\nthe development of advanced photonic devices. Here, we demonstrate the use of\nan inverse design wavelength demultiplexing waveguides for on-chip sorting and\nrouting of distinct photoluminescence from the heterojunction formed by WS2 and\nWSe2 monolayers. The integrated nanophotonic chip splits and sorts excitonic\nemission into individual waveguides at room temperature. Our demonstration\nopens up new perspectives for integrating light sources in van der Waals\nmaterials with functional integrated photonics, offering a versatile platform\nfor both fundamental research and practical applications."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-834",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14097"
    ],
    "b_title":[
      "A comprehensive study of bound-states for the nonlinear Schr\\\"odinger\n  equation on single-knot metric graphs"
    ],
    "b_abstract":[
      "We study the existence and qualitative properties of action ground-states\n(that is, bound-states with minimal action) {of the nonlinear Schr\\\"odinger\nequation} over single-knot metric graphs -- which are made of half-lines, loops\nand pendants, all connected at a single vertex. First, we prove existence of\naction ground-state for generic single-knot graphs, even in the absence of an\nassociated variational problem. Second, for regular single-knot graphs of\nlength $\\ell$, we perform a complete analysis of positive monotone\nbound-states. Furthermore, we characterize all positive bound-states when\n$\\ell$ is small and prove some symmetry-breaking results for large $\\ell$.\nFinally, we apply the results to some particular graphs to illustrate the\ncomplex relation between action ground-states and the topological {and metric}\nfeatures of the underlying metric graph.\n  The proofs are nonvariational, using a careful phase-plane analysis, the\nstudy of sections of period functions, asymptotic estimates and blowup\narguments. We show, in particular, how nonvariational techniques are\ncomplementary to variational ones in order to deeply understand bound-states of\nthe nonlinear Schr\\\"odinger equation on metric graphs."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.08651"
    ],
    "c_title":[
      "Hydrogenlike molecules composed of $D_1D_1$, $D_1D^*_2$ and $D^*_2D^*_2$"
    ],
    "c_abstract":[
      "We systematically explore the S-wave $D_1D_1$, $D_1D^*_2$ and $D^*_2D^*_2$\nstates with various isospin-spin-orbit ($ISL$) configurations in the quark\nmodel. We propose nine stable dimeson states with the $ISL$ configurations,\n$ISL=001$, $010$, $012$, $100$, $102$, $110$, $112$, $120$, and $122$, against\ndissociation into their constituent mesons. Those bound states are hydrogenlike\nmolecular states, where the two subclusters are moderately overlapped and the\nQCD covalent bond is formed due to the delocalization of light quarks. The QCD\ncovalent bond serves as the primary binding mechanism in the bound states with\n$I=1$. However, the exchange of $\\pi$ and $\\sigma$-meson plays a pivotal role\nin the bound states with $I=0$. The coupled-channel effect is essential in the\nformation of the bound states with $ISL=001$, $010$, $012$, $100$, and $102$."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-835",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18689"
    ],
    "b_title":[
      "The initial mass-remnant mass relation for core collapse supernovae"
    ],
    "b_abstract":[
      "The first direct detection of gravitational waves in 2015 marked the\nbeginning of a new era for the study of compact objects. Upcoming detectors,\nsuch as the Einstein Telescope, are expected to add thousands of binary\ncoalescences to the list. However, from a theoretical perspective, our\nunderstanding of compact objects is hindered by many uncertainties, and a\ncomprehensive study of the nature of stellar remnants from core-collapse\nsupernovae is still lacking. In this work, we investigate the properties of\nstellar remnants using a homogeneous grid of rotating and non-rotating massive\nstars at various metallicities from Limongi and Chieffi 2018. We simulate the\nsupernova explosion of the evolved progenitors using the HYdrodynamic Ppm\nExplosion with Radiation diffusION (HYPERION) code (Limongi and Chieffi 2020),\nassuming a thermal bomb model calibrated to match the main properties of\nSN1987A. We find that the heaviest black hole that can form depends on the\ninitial stellar rotation, metallicity, and the assumed criterion for the onset\nof pulsational pair-instability supernovae. Non-rotating progenitors at\n$\\big[\\rm Fe\/H \\big]=-3$ can form black holes up to $\\sim 87 M_\\odot$, falling\nwithin the theorized pair-instability mass gap. Conversely, enhanced wind mass\nloss prevents the formation of BHs more massive than $\\sim 41.6 M_\\odot$ from\nrotating progenitors. We use our results to study the black hole mass\ndistribution from a population of $10^6$ isolated massive stars following a\nKroupa initial mass function. Finally, we provide fitting formulas to compute\nthe mass of compact remnants as a function of stellar progenitor properties.\nOur up-to-date prescriptions can be easily implemented in rapid population\nsynthesis codes."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.03897"
    ],
    "c_title":[
      "UniForm: A Unified Diffusion Transformer for Audio-Video Generation"
    ],
    "c_abstract":[
      "As a natural multimodal content, audible video delivers an immersive sensory\nexperience. Consequently, audio-video generation systems have substantial\npotential. However, existing diffusion-based studies mainly employ relatively\nindependent modules for generating each modality, which lack exploration of\nshared-weight generative modules. This approach may under-use the intrinsic\ncorrelations between audio and visual modalities, potentially resulting in\nsub-optimal generation quality. To address this, we propose UniForm, a unified\ndiffusion transformer designed to enhance cross-modal consistency. By\nconcatenating auditory and visual information, UniForm learns to generate audio\nand video simultaneously within a unified latent space, facilitating the\ncreation of high-quality and well-aligned audio-visual pairs. Extensive\nexperiments demonstrate the superior performance of our method in joint\naudio-video generation, audio-guided video generation, and video-guided audio\ngeneration tasks. Our demos are available at https:\/\/uniform-t2av.github.io\/."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-836",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08040"
    ],
    "b_title":[
      "On Constructing Finite Automata by Relational Programming"
    ],
    "b_abstract":[
      "We consider ways to construct a transducer for a given set of input word to\noutput symbol pairs. This is motivated by the need for representing game\nplaying programs in a low-level mathematical format that can be analyzed by\nalgebraic tools. This is different from the classical applications of finite\nstate automata, thus the usual optimization techniques are not directly\napplicable. Therefore, we use relational programming tools to find minimal\ntransducers realizing a given set of input-output pairs."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09272"
    ],
    "c_title":[
      "Relating electrodynamics and gravity in two Euclidean dimensions"
    ],
    "c_abstract":[
      "Two-dimensional electrodynamics coupled to Dirac fermions is mapped onto\ntwo-dimensional gravity in the first-order formalism, also including fermions.\nHowever, the resulting fermion-gravity coupling deviates from the conventional\nform, explicitly violating parity and time-reversal symmetries. Additionally,\nthese fermions exhibit an unconventional transformation behavior under $SO(2)$\ntransformations. Furthermore, we analyze the consistency of this mapping at the\nquantum level using the path integral formalism and Becchi-Rouet-Stora-Tyutin\ntechniques. Our findings demonstrate that quantum electrodynamics and quantum\ngravity remain equivalent at the quantum level."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-837",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08540"
    ],
    "b_title":[
      "Knowledge prompt chaining for semantic modeling"
    ],
    "b_abstract":[
      "The task of building semantics for structured data such as CSV, JSON, and XML\nfiles is highly relevant in the knowledge representation field. Even though we\nhave a vast of structured data on the internet, mapping them to domain\nontologies to build semantics for them is still very challenging as it requires\nthe construction model to understand and learn graph-structured knowledge.\nOtherwise, the task will require human beings' effort and cost. In this paper,\nwe proposed a novel automatic semantic modeling framework: Knowledge Prompt\nChaining. It can serialize the graph-structured knowledge and inject it into\nthe LLMs properly in a Prompt Chaining architecture. Through this knowledge\ninjection and prompting chaining, the model in our framework can learn the\nstructure information and latent space of the graph and generate the semantic\nlabels and semantic graphs following the chains' insturction naturally. Based\non experimental results, our method achieves better performance than existing\nleading techniques, despite using reduced structured input data."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20591"
    ],
    "c_title":[
      "Encodings of Observable Subalgebras"
    ],
    "c_abstract":[
      "Simulating complex systems remains an ongoing challenge for classical\ncomputers, while being recognised as a task where a quantum computer has a\nnatural advantage. In both digital and analogue quantum simulations the system\ndescription is first mapped onto qubits or the physical system of the analogue\nsimulator by an encoding. Previously mathematical definitions and\ncharacterisations of encodings have focused on preserving the full physics of\nthe system. In this work, we consider encodings that only preserve a subset of\nthe observables of the system. We motivate that such encodings are best\ndescribed as maps between formally real Jordan algebras describing the subset\nof observables. Our characterisation of encodings is general, but notably holds\nfor maps between finite-dimensional and semisimple $C^{*}$-algebras. Fermionic\nencodings are a pertinent example where a mathematical characterisation was\nabsent. Our work applies to encodings of the the full CAR algebra, but also to\nencodings of just the even parity sector, corresponding to the physically\nrelevant fermionic operators."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-838",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11144"
    ],
    "b_title":[
      "Consistency of heritability estimation from summary statistics in\n  high-dimensional linear models"
    ],
    "b_abstract":[
      "In Genome-Wide Association Studies (GWAS), heritability is defined as the\nfraction of variance of an outcome explained by a large number of genetic\npredictors in a high-dimensional polygenic linear model. This work studies the\nasymptotic properties of the most common estimator of heritability from summary\nstatistics called linkage disequilibrium score (LDSC) regression, together with\na simpler and closely related estimator called GWAS heritability (GWASH). These\nestimators are analyzed in their basic versions and under various modifications\nused in practice including weighting and standardization. We show that, with\nsome variations, two conditions which we call weak dependence (WD) and\nbounded-kurtosis effects (BKE) are sufficient for consistency of both the basic\nLDSC with fixed intercept and GWASH estimators, for both Gaussian and\nnon-Gaussian predictors. For Gaussian predictors it is shown that these\nconditions are also necessary for consistency of GWASH (with truncation) and\nsimulations suggest that necessity holds too when the predictors are\nnon-Gaussian. We also show that, with properly truncated weights, weighting\ndoes not change the consistency results, but standardization of the predictors\nand outcome, as done in practice, introduces bias in both LDSC and GWASH if the\ntwo essential conditions are violated. Finally, we show that, when population\nstratification is present, all the estimators considered are biased, and the\nbias is not remedied by using the LDSC regression estimator with free\nintercept, as originally suggested by the authors of that estimator."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.05298"
    ],
    "c_title":[
      "Coreference as an indicator of context scope in multimodal narrative"
    ],
    "c_abstract":[
      "We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-839",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01193"
    ],
    "b_title":[
      "Leibniz's contested infinitesimals: Further depictions"
    ],
    "b_abstract":[
      "We contribute to the lively debate in current scholarship on the Leibnizian\ncalculus. In a recent text, Arthur and Rabouin argue that non-Archimedean\ncontinua are incompatible with Leibniz's concepts of number, quantity and\nmagnitude.\n  They allege that Leibniz viewed infinitesimals as contradictory, and claim to\ndeduce such a conclusion from an analysis of the Leibnizian definition of\nquantity. However, their argument is marred by numerous errors, deliberate\nomissions, and misrepresentations, stemming in a number of cases from flawed\nanalyses in their earlier publications.\n  We defend the thesis, traceable to the classic study by Henk Bos, that\nLeibniz used genuine infinitesimals, which he viewed as fictional mathematical\nentities (and not merely shorthand for talk about more ordinary quantities) on\npar with negatives and imaginaries."
    ],
    "b_categories":[
      [
        "math.HO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.14718"
    ],
    "c_title":[
      "Entity Framing and Role Portrayal in the News"
    ],
    "c_abstract":[
      "We introduce a novel multilingual hierarchical corpus annotated for entity\nframing and role portrayal in news articles. The dataset uses a unique taxonomy\ninspired by storytelling elements, comprising 22 fine-grained roles, or\narchetypes, nested within three main categories: protagonist, antagonist, and\ninnocent. Each archetype is carefully defined, capturing nuanced portrayals of\nentities such as guardian, martyr, and underdog for protagonists; tyrant,\ndeceiver, and bigot for antagonists; and victim, scapegoat, and exploited for\ninnocents. The dataset includes 1,378 recent news articles in five languages\n(Bulgarian, English, Hindi, European Portuguese, and Russian) focusing on two\ncritical domains of global significance: the Ukraine-Russia War and Climate\nChange. Over 5,800 entity mentions have been annotated with role labels. This\ndataset serves as a valuable resource for research into role portrayal and has\nbroader implications for news analysis. We describe the characteristics of the\ndataset and the annotation process, and we report evaluation results on\nfine-tuned state-of-the-art multilingual transformers and hierarchical\nzero-shot learning using LLMs at the level of a document, a paragraph, and a\nsentence."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-840",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16450"
    ],
    "b_title":[
      "Make Literature-Based Discovery Great Again through Reproducible\n  Pipelines"
    ],
    "b_abstract":[
      "By connecting disparate sources of scientific literature, literature\\-\/based\ndiscovery (LBD) methods help to uncover new knowledge and generate new research\nhypotheses that cannot be found from domain-specific documents alone. Our work\nfocuses on bisociative LBD methods that combine bisociative reasoning with LBD\ntechniques. The paper presents LBD through the lens of reproducible science to\nensure the reproducibility of LBD experiments, overcome the inconsistent use of\nbenchmark datasets and methods, trigger collaboration, and advance the LBD\nfield toward more robust and impactful scientific discoveries. The main novelty\nof this study is a collection of Jupyter Notebooks that illustrate the steps of\nthe bisociative LBD process, including data acquisition, text preprocessing,\nhypothesis formulation, and evaluation. The contributed notebooks implement a\nselection of traditional LBD approaches, as well as our own ensemble-based,\noutlier-based, and link prediction-based approaches. The reader can benefit\nfrom hands-on experience with LBD through open access to benchmark datasets,\ncode reuse, and a ready-to-run Docker recipe that ensures reproducibility of\nthe selected LBD methods."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05785"
    ],
    "c_title":[
      "Altermagnetism in parallel-assembled single-atomic magnetic chains"
    ],
    "c_abstract":[
      "Altermagnetism has recently attracted significant interest in three- and\ntwo-dimensional materials, yet its realization in quasi-one-dimensional (Q1D)\nmaterials remains largely unexplored due to stringent symmetry constraints.\nHere, we systematically investigated the emergence of altermagnetism in 30 Q1D\nmonolayer prototypes, self-assembled from intra-chain anti-ferrimagnetically\ncoupled \\(XY_n\\) single-atomic magnetic chains, using symmetry analysis and\nhigh-throughput density functional theory calculations. Symmetry analysis\nidentifies four structural prototypes capable of hosting altermagnetism, which\nexpand to 192 monolayers upon materialization. Our calculations further reveal\neight dynamically stable Q1D altermagnets, all belonging to the AA-stacked\nintra-chain AFM coupled \\(\\beta\\)-\\(XY_3\\) prototype, exhibiting\n\\(d\\)-wave-like spin splitting. Furthermore, we demonstrate the tunability of\naltermagnetic properties by varying inter-chain spacing and applying external\nelectric fields. By optimizing these parameters, altermagnetism can be\nsignificantly enhanced, with spin splitting reaching several hundred meV in\nCoTe\\(_3\\), or substantially suppressed, leading to a transition to a\nnodal-line semiconducting state in CrCl\\(_3\\). These findings establish a\ndiverse and highly tunable family of Q1D altermagnetic candidate materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-841",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09328"
    ],
    "b_title":[
      "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against\n  Model Extraction Attacks"
    ],
    "b_abstract":[
      "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from $12,000$ to $200$ with zero training cost."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09273"
    ],
    "c_title":[
      "Non-parametric estimation of net survival under dependence between death\n  causes"
    ],
    "c_abstract":[
      "Relative survival methodology deals with a competing risks survival model\nwhere the cause of death is unknown. This lack of information occurs regularly\nin population-based cancer studies. Non-parametric estimation of the net\nsurvival is possible through the Pohar Perme estimator. Derived similarly to\nKaplan-Meier, it nevertheless relies on an untestable independence assumption.\nWe propose here to relax this assumption and provide a generalized\nnon-parametric estimator that works for other dependence structures, by\nleveraging the underlying stochastic processes and martingales. We formally\nderive asymptotics of this estimator, providing variance estimation and\nlog-rank-type tests. Our approach provides a new perspective on the Pohar Perme\nestimator and the acceptability of the underlying independence assumption. We\nhighlight the impact of this dependence structure assumption on simulation\nstudies, and illustrate them through an application on registry data relative\nto colorectal cancer, before discussing potential extensions of our\nmethodology."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-842",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08114"
    ],
    "b_title":[
      "Change Captioning in Remote Sensing: Evolution to SAT-Cap -- A\n  Single-Stage Transformer Approach"
    ],
    "b_abstract":[
      "Change captioning has become essential for accurately describing changes in\nmulti-temporal remote sensing data, providing an intuitive way to monitor\nEarth's dynamics through natural language. However, existing change captioning\nmethods face two key challenges: high computational demands due to multistage\nfusion strategy, and insufficient detail in object descriptions due to limited\nsemantic extraction from individual images. To solve these challenges, we\npropose SAT-Cap based on the transformers model with a single-stage feature\nfusion for remote sensing change captioning. In particular, SAT-Cap integrates\na Spatial-Channel Attention Encoder, a Difference-Guided Fusion module, and a\nCaption Decoder. Compared to typical models that require multi-stage fusion in\ntransformer encoder and fusion module, SAT-Cap uses only a simple cosine\nsimilarity-based fusion module for information integration, reducing the\ncomplexity of the model architecture. By jointly modeling spatial and channel\ninformation in Spatial-Channel Attention Encoder, our approach significantly\nenhances the model's ability to extract semantic information from objects in\nmulti-temporal remote sensing images. Extensive experiments validate the\neffectiveness of SAT-Cap, achieving CIDEr scores of 140.23% on the LEVIR-CC\ndataset and 97.74% on the DUBAI-CC dataset, surpassing current state-of-the-art\nmethods. The code and pre-trained models will be available online."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.06054"
    ],
    "c_title":[
      "Small Angle Neutron Scattering in McStas: optimization for high\n  throughput virtual experiments"
    ],
    "c_abstract":[
      "In this work we present the development of small angle scattering components\nin McStas that describe the neutron interaction with 70 different form and\nstructure factors. We describe the considerations taken into account for the\ngeneration of these components, such as the incorporation of polydispersity and\norientational distribution effects in the Monte Carlo simulation. These models\ncan be parallelized by means of multi-core simulations and graphical processing\nunits (GPUs). The acceleration schemes for the aforementioned models are\nbenchmarked, and the resulting performance is presented. This allows for the\nestimation of computation times in high-throughput virtual experiments. The\npresented work enables the generation of large datasets of virtual experiments\nthat can be explored and used by machine learning algorithms."
    ],
    "c_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-843",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09318"
    ],
    "b_title":[
      "FpgaHub: Fpga-centric Hyper-heterogeneous Computing Platform for Big\n  Data Analytics"
    ],
    "b_abstract":[
      "Modern data analytics requires a huge amount of computing power and processes\na massive amount of data. At the same time, the underlying computing platform\nis becoming much more heterogeneous on both hardware and software. Even though\nspecialized hardware, e.g., FPGA- or GPU- or TPU-based systems, often achieves\nbetter performance than a CPU-only system due to the slowing of Moore's law,\nsuch systems are limited in what they can do. For example, GPU-only approaches\nsuffer from severe IO limitations. To truly exploit the potential of hardware\nheterogeneity, we present FpgaHub, an FPGA-centric hyper-heterogeneous\ncomputing platform for big data analytics. The key idea of FpgaHub is to use\nreconfigurable computing to implement a versatile hub complementing other\nprocessors (CPUs, GPUs, DPUs, programmable switches, computational storage,\netc.). Using an FPGA as the basis, we can take advantage of its highly\nreconfigurable nature and rich IO interfaces such as PCIe, networking, and\non-board memory, to place it at the center of the architecture and use it as a\ndata and control plane for data movement, scheduling, pre-processing, etc.\nFpgaHub enables architectural flexibility to allow exploring the rich design\nspace of heterogeneous computing platforms."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07619"
    ],
    "c_title":[
      "A mathematical model for the progression of dental caries"
    ],
    "c_abstract":[
      "A model for the progression of dental caries is derived. The analysis starts\nat the microscopic reaction and diffusion process. The local equations are\naveraged to derive a set of macroscopic equations. The global system includes\nfeatures such as anisotropic diffusion and local changes in the geometry due to\nthe enamel melting. The equations are then solved numerically. The simulations\nhighlight the effect of anisotropy. In addition we draw conclusions on the\nprogression rate of caries, and discuss them in light of a number of\nexperiments."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-844",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18423"
    ],
    "b_title":[
      "Retrieval Dexterity: Efficient Object Retrieval in Clutters with\n  Dexterous Hand"
    ],
    "b_abstract":[
      "Retrieving objects buried beneath multiple objects is not only challenging\nbut also time-consuming. Performing manipulation in such environments presents\nsignificant difficulty due to complex contact relationships. Existing methods\ntypically address this task by sequentially grasping and removing each\noccluding object, resulting in lengthy execution times and requiring\nimpractical grasping capabilities for every occluding object. In this paper, we\npresent a dexterous arm-hand system for efficient object retrieval in\nmulti-object stacked environments. Our approach leverages large-scale parallel\nreinforcement learning within diverse and carefully designed cluttered\nenvironments to train policies. These policies demonstrate emergent\nmanipulation skills (e.g., pushing, stirring, and poking) that efficiently\nclear occluding objects to expose sufficient surface area of the target object.\nWe conduct extensive evaluations across a set of over 10 household objects in\ndiverse clutter configurations, demonstrating superior retrieval performance\nand efficiency for both trained and unseen objects. Furthermore, we\nsuccessfully transfer the learned policies to a real-world dexterous\nmulti-fingered robot system, validating their practical applicability in\nreal-world scenarios. Videos can be found on our project website\nhttps:\/\/ChangWinde.github.io\/RetrDex."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00275"
    ],
    "c_title":[
      "Path Subgoupoids of Weyl Groupoids, Rainbow Boomerang Graphs and Verma\n  Modules for Nichols Algebras of Diagonal Type"
    ],
    "c_abstract":[
      "We extend the exchange property of Weyl groupoids, as formulated by\nHeckenberger and Yamane, to a newly introduced class called path subgroupoids\nof Weyl groupoids. This extension provides a combinatorial interpretation of\nwhy the odd reflections of basic Lie superalgebras satisfy the exchange\nproperty, viewing it as a consequence of the underlying Weyl groupoid\nstructure.\n  Furthermore, we establish an analogous result within this framework for\nNichols algebras of diagonal type, thereby generalizing our previous findings\non homomorphisms between Verma modules with the same character but associated\nwith different Borel subalgebras in the case of basic Lie superalgebras."
    ],
    "c_categories":[
      [
        "math.QA",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-845",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14511"
    ],
    "b_title":[
      "Strong coupling quantum electrodynamics Hartree-Fock response theory"
    ],
    "b_abstract":[
      "The development of reliable ab initio methods for light-matter strong\ncoupling is necessary for a deeper understanding of molecular polaritons. The\nrecently developed strong coupling quantum electrodynamics Hartree-Fock model\n(SC-QED-HF) provides cavity-consistent molecular orbitals, overcoming several\ndifficulties related to the simpler QED-HF wave function. In this paper, we\nfurther develop this method by implementing the response theory for SC-QED-HF.\nWe compare the derived linear response equations with the time-dependent QED-HF\ntheory and discuss the validity of equivalence relations connecting matter and\nelectromagnetic observables. Our results show that electron-photon correlation\ninduces an excitation redshift compared to the time-dependent QED-HF energies,\nand we discuss the effect of the dipole self-energy on the ground and excited\nstate properties with different basis sets."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.06891"
    ],
    "c_title":[
      "AKF-LIO: LiDAR-Inertial Odometry with Gaussian Map by Adaptive Kalman\n  Filter"
    ],
    "c_abstract":[
      "Existing LiDAR-Inertial Odometry (LIO) systems typically use sensor-specific\nor environment-dependent measurement covariances during state estimation,\nleading to laborious parameter tuning and suboptimal performance in challenging\nconditions (e.g., sensor degeneracy and noisy observations). Therefore, we\npropose an Adaptive Kalman Filter (AKF) framework that dynamically estimates\ntime-varying noise covariances of LiDAR and Inertial Measurement Unit (IMU)\nmeasurements, enabling context-aware confidence weighting between sensors.\nDuring LiDAR degeneracy, the system prioritizes IMU data while suppressing\ncontributions from unreliable inputs like moving objects or noisy point clouds.\nFurthermore, a compact Gaussian-based map representation is introduced to model\nenvironmental planarity and spatial noise. A correlated registration strategy\nensures accurate plane normal estimation via pseudo-merge, even in unstructured\nenvironments like forests. Extensive experiments validate the robustness of the\nproposed system across diverse environments, including dynamic scenes and\ngeometrically degraded scenarios. Our method achieves reliable localization\nresults across all MARS-LVIG sequences and ranks 8th on the KITTI Odometry\nBenchmark. The code will be released at https:\/\/github.com\/xpxie\/AKF-LIO.git."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-846",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02509"
    ],
    "b_title":[
      "Facial Attractiveness Prediction in Live Streaming: A New Benchmark and\n  Multi-modal Method"
    ],
    "b_abstract":[
      "Facial attractiveness prediction (FAP) has long been an important computer\nvision task, which could be widely applied in live streaming for facial\nretouching, content recommendation, etc. However, previous FAP datasets are\neither small, closed-source, or lack diversity. Moreover, the corresponding FAP\nmodels exhibit limited generalization and adaptation ability. To overcome these\nlimitations, in this paper we present LiveBeauty, the first large-scale\nlive-specific FAP dataset, in a more challenging application scenario, i.e.,\nlive streaming. 10,000 face images are collected from a live streaming platform\ndirectly, with 200,000 corresponding attractiveness annotations obtained from a\nwell-devised subjective experiment, making LiveBeauty the largest open-access\nFAP dataset in the challenging live scenario. Furthermore, a multi-modal FAP\nmethod is proposed to measure the facial attractiveness in live streaming.\nSpecifically, we first extract holistic facial prior knowledge and multi-modal\naesthetic semantic features via a Personalized Attractiveness Prior Module\n(PAPM) and a Multi-modal Attractiveness Encoder Module (MAEM), respectively,\nthen integrate the extracted features through a Cross-Modal Fusion Module\n(CMFM). Extensive experiments conducted on both LiveBeauty and other\nopen-source FAP datasets demonstrate that our proposed method achieves\nstate-of-the-art performance. Dataset will be available soon."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.07031"
    ],
    "c_title":[
      "R-equivalence classes of $\\mathrm{Rot} \\mathbb{E}^{2}$-colorings of\n  torus knots"
    ],
    "c_abstract":[
      "We introduce a new equivalence relation, named R-equivalence relation, on the\nset of colorings of an oriented knot diagram by a quandle. We determine the\nR-equivalence classes of colorings of a diagram of a torus knot by a quandle,\ncalled $\\mathrm{Rot} \\mathbb{E}^{2}$, under a certain condition."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-847",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15798"
    ],
    "b_title":[
      "Mixture of Lookup Experts"
    ],
    "b_abstract":[
      "Mixture-of-Experts (MoE) activates only a subset of experts during inference,\nallowing the model to maintain low inference FLOPs and latency even as the\nparameter count scales up. However, since MoE dynamically selects the experts,\nall the experts need to be loaded into VRAM. Their large parameter size still\nlimits deployment, and offloading, which load experts into VRAM only when\nneeded, significantly increase inference latency. To address this, we propose\nMixture of Lookup Experts (MoLE), a new MoE architecture that is efficient in\nboth communication and VRAM usage. In MoLE, the experts are Feed-Forward\nNetworks (FFNs) during training, taking the output of the embedding layer as\ninput. Before inference, these experts can be re-parameterized as lookup tables\n(LUTs) that retrieves expert outputs based on input ids, and offloaded to\nstorage devices. Therefore, we do not need to perform expert computations\nduring inference. Instead, we directly retrieve the expert's computation\nresults based on input ids and load them into VRAM, and thus the resulting\ncommunication overhead is negligible. Experiments show that, with the same\nFLOPs and VRAM usage, MoLE achieves inference speeds comparable to dense models\nand significantly faster than MoE with experts offloading, while maintaining\nperformance on par with MoE."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.05306"
    ],
    "c_title":[
      "Shedding Light on Naked Singularities"
    ],
    "c_abstract":[
      "Electromagnetic waves propagating in the background provided by a spacetime\nhosting a strong curvature, naked singularity, are fully studied. The analysis\nis performed not only in the realm of geometrical optics -- which, not\nsurprisingly, proves to be inadequate in the strong field regime characterizing\nthe vicinity of the singularity -- but also in the physical one in which the\nfield amplitudes must necessarily be incorporated into the description. In\naddition to the expected divergent outcome with regard to the field amplitudes\nand power flux as the waves approach the singularity, we found a number of\nregular (bounded) solutions which seem to coexist with the unbridled effects of\nthe spacetime curvature. In some of them, the singularity operates as a perfect\nmirror reflecting the surrounding fields. Strikingly, other solutions exhibit a\nperfectly well behaved, bounded power flux as they propagate towards the\nsingularity, suggesting thus the possibility of having electromagnetic energy\ntransference through it."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-848",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20897"
    ],
    "b_title":[
      "Beyond Demographics: Fine-tuning Large Language Models to Predict\n  Individuals' Subjective Text Perceptions"
    ],
    "b_abstract":[
      "People naturally vary in their annotations for subjective questions and some\nof this variation is thought to be due to the person's sociodemographic\ncharacteristics. LLMs have also been used to label data, but recent work has\nshown that models perform poorly when prompted with sociodemographic\nattributes, suggesting limited inherent sociodemographic knowledge. Here, we\nask whether LLMs can be trained to be accurate sociodemographic models of\nannotator variation. Using a curated dataset of five tasks with standardized\nsociodemographics, we show that models do improve in sociodemographic prompting\nwhen trained but that this performance gain is largely due to models learning\nannotator-specific behaviour rather than sociodemographic patterns. Across all\ntasks, our results suggest that models learn little meaningful connection\nbetween sociodemographics and annotation, raising doubts about the current use\nof LLMs for simulating sociodemographic variation and behaviour."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10669"
    ],
    "c_title":[
      "Role of Random Interaction Connection in the Order Transition of Active\n  Matter Based on the Vicsek Model"
    ],
    "c_abstract":[
      "Randomness plays a key role in the order transition of active matter but has\nnot yet been explicitly considered in pairwise interaction connection. In this\nletter, we introduce the perception rate P into the Vicsek model as the\nprobability of the interaction connections and model the connections as\nsuperposition states. We show that with increasing P, the polar order number\nundergoes an order transition and then saturation. The order transition is a\nfirst-order phase transition with band formation, and the effect of P is\ndifferent from density. The change of the order number is linked with the\ninteraction structure. The order transition, order saturation, and phase\nseparation correspond to different critical changes in the local interaction\nnumber. The global interaction structure is further analyzed as a network. The\ndecrease of P is comparable to random edge removal, under which the network\nexperiences modal transitions near the critical points of the order number, and\nthe network exhibits surprising robustness. Our results suggest that random\ninteraction can be a new important factor in active matter models, with\npotential applications in robotic swarms and social activities."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-849",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07042"
    ],
    "b_title":[
      "Building networks of shared research interests by embedding words into a\n  representation space"
    ],
    "b_abstract":[
      "Departments within a university are not only administrative units, but also\nan effort to gather investigators around common fields of academic study. A\npervasive challenge is connecting members with shared research interests both\nwithin and between departments. Here I describe a workflow that adapts methods\nfrom natural language processing to generate a network connecting $n=79$\nmembers of a university department, or multiple departments within a faculty\n($n=278$), based on common topics in their research publications. After\nextracting and processing terms from $n=16,901$ abstracts in the PubMed\ndatabase, the co-occurrence of terms is encoded in a sparse document-term\nmatrix. Based on the angular distances between the presence-absence vectors for\nevery pair of terms, I use the uniform manifold approximation and projection\n(UMAP) method to embed the terms into a representational space such that terms\nthat tend to appear in the same documents are closer together. Each author's\ncorpus defines a probability distribution over terms in this space. Using the\nWasserstein distance to quantify the similarity between these distributions, I\ngenerate a distance matrix among authors that can be analyzed and visualized as\na graph. I demonstrate that this nonparametric method produces clusters with\ndistinct themes that are consistent with some academic divisions, while\nidentifying untapped connections among members. A documented workflow\ncomprising Python and R scripts is available under the MIT license at\nhttps:\/\/github.com\/PoonLab\/tragula."
    ],
    "b_categories":[
      [
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17833"
    ],
    "c_title":[
      "Efficient implementation of randomized quantum algorithms with dynamic\n  circuits"
    ],
    "c_abstract":[
      "Randomized algorithms are crucial subroutines in quantum computing, but the\nrequirement to execute many types of circuits on a real quantum device has been\nchallenging to their extensive implementation. In this study, we propose an\nengineering method to reduce the executing time for randomized algorithms using\ndynamic circuits, i.e., quantum circuits involving intermediate measurement and\nfeedback processes. The main idea is to generate the probability distribution\ndefining a target randomized algorithm on a quantum computer, instead of a\nclassical computer, which enables us to implement a variety of static circuits\non a single dynamic circuit with many measurements. We applied the proposed\nmethod to the task of random Pauli measurement for one qubit on an IBM\nsuperconducting device, showing that a 14,000-fold acceleration of executing\ntime was observed compared with a conventional method using static circuits.\nAdditionally, for the problem of estimating expectation values of 28- and\n40-qubit hydrogen chain models, we successfully applied the proposed method to\nrealize the classical shadow with 10 million random circuits, which is the\nlargest demonstration of classical shadow. This work significantly simplifies\nthe execution of randomized algorithms on real quantum hardware."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-850",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16320"
    ],
    "b_title":[
      "The Integral Chow Rings of the Moduli Stacks of Hyperelliptic Prym Pairs\n  I"
    ],
    "b_abstract":[
      "This paper is the first in a series dedicated to computing the integral Chow\nrings of the moduli stacks of Prym pairs. In this work, we compute the Chow\nring for Prym pairs arising from a single pair of Weierstrass points and from\nat most $(g-1)\/2 $ pairs when the genus $g$ of the curve is odd."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.07849"
    ],
    "c_title":[
      "Understanding Classifier-Free Guidance: High-Dimensional Theory and\n  Non-Linear Generalizations"
    ],
    "c_abstract":[
      "Recent studies have raised concerns about the effectiveness of\nClassifier-Free Guidance (CFG), indicating that in low-dimensional settings, it\ncan lead to overshooting the target distribution and reducing sample diversity.\nIn this work, we demonstrate that in infinite and sufficiently high-dimensional\ncontexts CFG effectively reproduces the target distribution, revealing a\nblessing-of-dimensionality result. Additionally, we explore finite-dimensional\neffects, precisely characterizing overshoot and variance reduction. Based on\nour analysis, we introduce non-linear generalizations of CFG. Through numerical\nsimulations on Gaussian mixtures and experiments on class-conditional and\ntext-to-image diffusion models, we validate our analysis and show that our\nnon-linear CFG offers improved flexibility and generation quality without\nadditional computation cost."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-851",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15024"
    ],
    "b_title":[
      "Low degree conjecture implies sharp computational thresholds in\n  stochastic block model"
    ],
    "b_abstract":[
      "We investigate implications of the (extended) low-degree conjecture (recently\nformalized in [MW23]) in the context of the symmetric stochastic block model.\nAssuming the conjecture holds, we establish that no polynomial-time algorithm\ncan weakly recover community labels below the Kesten-Stigum (KS) threshold. In\nparticular, we rule out polynomial-time estimators that, with constant\nprobability, achieve correlation with the true communities that is\nsignificantly better than random. Whereas, above the KS threshold,\npolynomial-time algorithms are known to achieve constant correlation with the\ntrue communities with high probability[Mas14,AS15].\n  To our knowledge, we provide the first rigorous evidence for the sharp\ntransition in recovery rate for polynomial-time algorithms at the KS threshold.\nNotably, under a stronger version of the low-degree conjecture, our lower bound\nremains valid even when the number of blocks diverges. Furthermore, our results\nprovide evidence of a computational-to-statistical gap in learning the\nparameters of stochastic block models.\n  In contrast to prior work, which either (i) rules out polynomial-time\nalgorithms for hypothesis testing with 1-o(1) success probability [Hopkins18,\nBBK+21a] under the low-degree conjecture, or (ii) rules out low-degree\npolynomials for learning the edge connection probability matrix [LG23], our\napproach provides stronger lower bounds on the recovery and learning problem.\n  Our proof combines low-degree lower bounds from [Hopkins18, BBK+21a] with\ngraph splitting and cross-validation techniques. In order to rule out general\nrecovery algorithms, we employ the correlation preserving projection method\ndeveloped in [HS17]."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.LG",
        "math.ST",
        "stat.CO",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07198"
    ],
    "c_title":[
      "The Affine Tamari Lattice"
    ],
    "c_abstract":[
      "Given a fixed integer $n\\geq 2$, we construct two new finite lattices that we\ncall the cyclic Tamari lattice and the affine Tamari lattice. The cyclic Tamari\nlattice is a sublattice and a quotient lattice of the cyclic Dyer lattice,\nwhich is the infinite lattice of translation-invariant total orders under\ncontainment of inversion sets. The affine Tamari lattice is a quotient of the\nDyer lattice, which in turn is a quotient of the cyclic Dyer lattice and is\nisomorphic to the collection of biclosed sets of the root system of type\n$\\widetilde{A}_{n-1}$ under inclusion. We provide numerous combinatorial and\nalgebraic descriptions of these lattices using translation-invariant total\norders, translation-invariant binary in-ordered trees, noncrossing arc\ndiagrams, torsion classes, triangulations, and translation-invariant\nnoncrossing partitions. The cardinalities of the cyclic and affine Tamari\nlattices are the Catalan numbers of types $B_n$ and $D_n$, respectively. We\nshow that these lattices are self-dual and semidistributive, and we describe\ntheir decompositions coming from the Fundamental Theorem of Finite\nSemidistributive Lattices. We also show that the rowmotion operators on these\nlattices have well-behaved orbit structures, which we describe via the cyclic\nsieving phenomenon. Our new combinatorial framework allows us to prove that the\nlengths of maximal green sequences for the completed path algebra of the\noriented $n$-cycle are precisely the integers in the interval\n$[2n-1,\\binom{n+1}{2}]$."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.RA",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-852",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14314"
    ],
    "b_title":[
      "ODVerse33: Is the New YOLO Version Always Better? A Multi Domain\n  benchmark from YOLO v5 to v11"
    ],
    "b_abstract":[
      "You Look Only Once (YOLO) models have been widely used for building real-time\nobject detectors across various domains. With the increasing frequency of new\nYOLO versions being released, key questions arise. Are the newer versions\nalways better than their previous versions? What are the core innovations in\neach YOLO version and how do these changes translate into real-world\nperformance gains? In this paper, we summarize the key innovations from YOLOv1\nto YOLOv11, introduce a comprehensive benchmark called ODverse33, which\nincludes 33 datasets spanning 11 diverse domains (Autonomous driving,\nAgricultural, Underwater, Medical, Videogame, Industrial, Aerial, Wildlife,\nRetail, Microscopic, and Security), and explore the practical impact of model\nimprovements in real-world, multi-domain applications through extensive\nexperimental results. We hope this study can provide some guidance to the\nextensive users of object detection models and give some references for future\nreal-time object detector development."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.00786"
    ],
    "c_title":[
      "Periodic FPU system: Continuum limit to KdV via regularization and\n  Fourier analysis"
    ],
    "c_abstract":[
      "The Fermi-Pasta-Ulam (FPU) system, initially introduced by Fermi for\nnumerical simulations, models vibrating chains with fixed endpoints, where\nparticles interact weakly, nonlinearly with their nearest neighbors. Contrary\nto the anticipated ergodic behavior, the simulation revealed nearly periodic\n(quasi-periodic) motion of the solutions, a phenomenon later referred to as the\nFPU paradox. A partial but remarkable explanation was provided by Zabusky and\nKruskal [36], who formally derived the continuum limit of the FPU system,\nconnecting it to the Korteweg-de Vries (KdV) equation. This formal derivation\nwas later rigorously justified by Bambusi and Ponno [4].\n  In this paper, we revisit the problem studied in [4], specifically focusing\non the continuum limit of the periodic FPU system for a broader class of\ninitial data, as the number of particles N tends to infinity within a fixed\ndomain. Unlike the non-periodic case discussed in [15], periodic FPU solutions\nlack a (local) smoothing effect, posing a significant challenge in controlling\none derivative in the nonlinearity. This control is crucial not only for\nproving the (uniform in N) well-posedness for rough data but also for deriving\nthe continuum limit. The main strategies to resolve this issue involve deriving\nL4-Strichartz estimates for FPU solutions, analogous to those previously\nderived for KdV solutions in [7], and regularizing the system via the normal\nform method introduced in [1]."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-853",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.12181"
    ],
    "b_title":[
      "3D ReX: Causal Explanations in 3D Neuroimaging Classification"
    ],
    "b_abstract":[
      "Explainability remains a significant problem for AI models in medical\nimaging, making it challenging for clinicians to trust AI-driven predictions.\nWe introduce 3D ReX, the first causality-based post-hoc explainability tool for\n3D models. 3D ReX uses the theory of actual causality to generate\nresponsibility maps which highlight the regions most crucial to the model's\ndecision. We test 3D ReX on a stroke detection model, providing insight into\nthe spatial distribution of features relevant to stroke."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03411"
    ],
    "c_title":[
      "Deterministic generation of multi-qubit entangled states among distant\n  parties using indefinite causal order"
    ],
    "c_abstract":[
      "Quantum entanglement plays an irreplaceable role in various remote quantum\ninformation processing tasks. Here we present protocols for generating\ndeterministic and heralded $N$-qubit entangled states across multiple network\nnodes. By utilizing a pre-shared maximally entangled state and single-qubit\noperations within an indefinite causal order framework, the multi-qubit\nentangled state between distant parties can be generated deterministically. The\ncomplex entangled state measurements and multiple pre-shared entangled states,\nare essential in conventional entanglement swapping technique, but are not\nrequired in our approach. This greatly reduces the complexity of the quantum\ncircuit and makes it more experimentally feasible. Furthermore, we develop\noptical architectures to implement these protocols by encoding qubits in\npolarization degree of freedom. The results indicate that our protocols\nsignificantly improve the efficiency of long-distance entanglement generation\nand provide a practical framework for establishing large-scale quantum\nnetworks."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-854",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02248"
    ],
    "b_title":[
      "On Concentration Inequality of the Laplacian Matrix of Erd\\H{o}s-R\\'enyi\n  Graphs"
    ],
    "b_abstract":[
      "This paper focuses on the concentration properties of the spectral norm of\nthe normalized Laplacian matrix for Erd\\H{o}s-R\\'enyi random graphs. First, We\nachieve the optimal bound that can be attained in the further question posed by\nLe et al. [24] for the regularized Laplacian matrix. Beyond that, we also\nestablish a uniform concentration inequality for the spectral norm of the\nLaplacian matrix in the homogeneous case, relying on a key tool: the uniform\nconcentration property of degrees, which may be of independent interest.\nAdditionally, we prove that after normalizing the eigenvector corresponding to\nthe largest eigenvalue, the spectral norm of the Laplacian matrix concentrates\naround 1, which may be useful in special cases."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.12933"
    ],
    "c_title":[
      "Electric Polarizability of Charged Kaons from Lattice QCD Four-Point\n  Functions"
    ],
    "c_abstract":[
      "We study the electric polarizability of a charged kaon from four-point\nfunctions in lattice QCD as an alternative to the background field method.\nLattice four-point correlation functions are constructed from quark and gluon\nfields to be used in Monte Carlo simulations. The elastic form factor (charge\nradius) is needed in the method which can be obtained from the same four-point\nfunctions at large current separations. Preliminary results from the connected\nquark-line diagrams are presented."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-855",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14604"
    ],
    "b_title":[
      "Noisy Test-Time Adaptation in Vision-Language Models"
    ],
    "b_abstract":[
      "Test-time adaptation (TTA) aims to address distribution shifts between source\nand target data by relying solely on target data during testing. In open-world\nscenarios, models often encounter noisy samples, i.e., samples outside the\nin-distribution (ID) label space. Leveraging the zero-shot capability of\npre-trained vision-language models (VLMs), this paper introduces Zero-Shot\nNoisy TTA (ZS-NTTA), focusing on adapting the model to target data with noisy\nsamples during test-time in a zero-shot manner. We find existing TTA methods\nunderperform under ZS-NTTA, often lagging behind even the frozen model. We\nconduct comprehensive experiments to analyze this phenomenon, revealing that\nthe negative impact of unfiltered noisy data outweighs the benefits of clean\ndata during model updating. Also, adapting a classifier for ID classification\nand noise detection hampers both sub-tasks. Built on this, we propose a\nframework that decouples the classifier and detector, focusing on developing an\nindividual detector while keeping the classifier frozen. Technically, we\nintroduce the Adaptive Noise Detector (AdaND), which utilizes the frozen\nmodel's outputs as pseudo-labels to train a noise detector. To handle clean\ndata streams, we further inject Gaussian noise during adaptation, preventing\nthe detector from misclassifying clean samples as noisy. Beyond the ZS-NTTA,\nAdaND can also improve the zero-shot out-of-distribution (ZS-OOD) detection\nability of VLMs. Experiments show that AdaND outperforms in both ZS-NTTA and\nZS-OOD detection. On ImageNet, AdaND achieves a notable improvement of $8.32\\%$\nin harmonic mean accuracy ($\\text{Acc}_\\text{H}$) for ZS-NTTA and $9.40\\%$ in\nFPR95 for ZS-OOD detection, compared to SOTA methods. Importantly, AdaND is\ncomputationally efficient and comparable to the model-frozen method. The code\nis publicly available at: https:\/\/github.com\/tmlr-group\/ZS-NTTA."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.07247"
    ],
    "c_title":[
      "A Relativistic Theory of Consciousness (shortened version)"
    ],
    "c_abstract":[
      "This paper is a shortened version of the full paper that was published in the\njournal Frontiers of Psychology in May 2022. In recent decades, the scientific\nstudy of consciousness has significantly increased our understanding of this\nelusive phenomenon. Yet, despite critical development in our understanding of\nthe functional side of consciousness, we still lack a fundamental theory\nregarding its phenomenal aspect. The phenomenal aspect of consciousness is the\nfirst-person answer to what it is like question, and it has thus far proved\nrecalcitrant to direct scientific investigation. The question of how the brain,\nor any cognitive system, can create conscious experience out of neural\nrepresentations poses a great conundrum to science. Naturalistic dualists argue\nthat it is composed of a primitive, private, nonreductive element of reality.\nIllusionists, on the other hand, argue that it is merely a cognitive illusion.\nWe contend that both the dualist and illusionist positions are flawed because\nthey tacitly assume consciousness to be an absolute property that does not\ndepend on the observer. We developed a conceptual and a mathematical argument\nfor a relativistic theory of consciousness in which a system either has or does\nnot have phenomenal consciousness with respect to some observer. According to\nthe theory, Phenomenal consciousness is neither private nor delusional, just\nrelativistic. In the frame of reference of the cognitive system, it will be\nobservable (first-person perspective) and in other frame of reference it will\nnot (third-person perspective). These two cognitive frames of reference are\nboth correct, just as in the case of an observer that claims to be at rest\nwhile another will claim that the observer has constant velocity. Neither\nobserver position can be privileged, as they both describe the same underlying\nreality."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-856",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13826"
    ],
    "b_title":[
      "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline\n  Professional Videos"
    ],
    "b_abstract":[
      "Humans acquire knowledge through three cognitive stages: perceiving\ninformation, comprehending knowledge, and adapting knowledge to solve novel\nproblems. Videos serve as an effective medium for this learning process,\nfacilitating a progression through these cognitive stages. However, existing\nvideo benchmarks fail to systematically evaluate the knowledge acquisition\ncapabilities in Large Multimodal Models (LMMs). To address this gap, we\nintroduce Video-MMMU, a multi-modal, multi-disciplinary benchmark designed to\nassess LMMs' ability to acquire and utilize knowledge from videos. Video-MMMU\nfeatures a curated collection of 300 expert-level videos and 900\nhuman-annotated questions across six disciplines, evaluating knowledge\nacquisition through stage-aligned question-answer pairs: Perception,\nComprehension, and Adaptation. A proposed knowledge gain metric,\n{\\Delta}knowledge, quantifies improvement in performance after video viewing.\nEvaluation of LMMs reveals a steep decline in performance as cognitive demands\nincrease and highlights a significant gap between human and model knowledge\nacquisition, underscoring the need for methods to enhance LMMs' capability to\nlearn and adapt from videos."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12365"
    ],
    "c_title":[
      "Efficient Algorithm for Sparse Fourier Transform of Generalized q-ary\n  Functions"
    ],
    "c_abstract":[
      "Computing the Fourier transform of a $q$-ary function\n$f:\\mathbb{Z}_{q}^n\\rightarrow \\mathbb{R}$, which maps $q$-ary sequences to\nreal numbers, is an important problem in mathematics with wide-ranging\napplications in biology, signal processing, and machine learning. Previous\nstudies have shown that, under the sparsity assumption, the Fourier transform\ncan be computed efficiently using fast and sample-efficient algorithms.\nHowever, in many practical settings, the function is defined over a more\ngeneral space -- the space of generalized $q$-ary sequences $\\mathbb{Z}_{q_1}\n\\times \\mathbb{Z}_{q_2} \\times \\cdots \\times \\mathbb{Z}_{q_n}$ -- where each\n$\\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. A naive approach\ninvolves setting $q=\\max_i{q_i}$ and treating the function as $q$-ary, which\nresults in heavy computational overheads. Herein, we develop GFast, an\nalgorithm that computes the $S$-sparse Fourier transform of $f$ with a sample\ncomplexity of $O(Sn)$, computational complexity of $O(Sn \\log N)$, and a\nfailure probability that approaches zero as $N=\\prod_{i=1}^n q_i \\rightarrow\n\\infty$ with $S = N^\\delta$ for some $0 \\leq \\delta < 1$. In the presence of\nnoise, we further demonstrate that a robust version of GFast computes the\ntransform with a sample complexity of $O(Sn^2)$ and computational complexity of\n$O(Sn^2 \\log N)$ under the same high probability guarantees. Using large-scale\nsynthetic experiments, we demonstrate that GFast computes the sparse Fourier\ntransform of generalized $q$-ary functions using $16\\times$ fewer samples and\nrunning $8\\times$ faster than existing algorithms. In real-world protein\nfitness datasets, GFast explains the predictive interactions of a neural\nnetwork with $>25\\%$ smaller normalized mean-squared error compared to existing\nalgorithms."
    ],
    "c_categories":[
      [
        "cs.CC",
        "cs.DM",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-857",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08206"
    ],
    "b_title":[
      "SAT-Based Techniques for Lexicographically Smallest Finite Models"
    ],
    "b_abstract":[
      "This paper proposes SAT-based techniques to calculate a specific normal form\nof a given finite mathematical structure (model). The normal form is obtained\nby permuting the domain elements so that the representation of the structure is\nlexicographically smallest possible. Such a normal form is of interest to\nmathematicians as it enables easy cataloging of algebraic structures. In\nparticular, two structures are isomorphic precisely when their normal forms are\nthe same. This form is also natural to inspect as mathematicians have been\nusing it routinely for many decades.\n  We develop a novel approach where a SAT solver is used in a black-box fashion\nto compute the smallest representative. The approach constructs the\nrepresentative gradually and searches the space of possible isomorphisms,\nrequiring a small number of variables. However, the approach may lead to a\nlarge number of SAT calls and therefore we devise propagation techniques to\nreduce this number. The paper focuses on finite structures with a single binary\noperation (encompassing groups, semigroups, etc.). However, the approach is\ngeneralizable to arbitrary finite structures. We provide an implementation of\nthe proposed algorithm and evaluate it on a variety of algebraic structures."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11676"
    ],
    "c_title":[
      "Iterative Procedure for Non-Linear Fractional Integro-Differential\n  Equations via Daftardar--Jafari Polynomials"
    ],
    "c_abstract":[
      "In this paper, we introduce a novel approach called the Iterative Aboodh\nTransform Method (IATM) which utilizes Daftardar--Jafari polynomials for\nsolving non-linear problems. Such method is employed to derive solutions for\nnon-linear fractional partial integro-differential equations (FPIDEs). The key\nnovelty of the suggested method is that it can be used for handling solutions\nof non-linear FPIDEs in a very simple and effective way. {More precisely, we\nshow that Daftardar--Jafari polynomials have simple calculations as compared to\nAdomian polynomials with higher accuracy}. The results obtained within the\nDaftardar--Jafari polynomials are demonstrated with graphs and tables, and the\nIATM's absolute error confirms the higher accuracy of the suggested method."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-858",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14723"
    ],
    "b_title":[
      "LeakageDetector: An Open Source Data Leakage Analysis Tool in Machine\n  Learning Pipelines"
    ],
    "b_abstract":[
      "Code quality is of paramount importance in all types of software development\nsettings. Our work seeks to enable Machine Learning (ML) engineers to write\nbetter code by helping them find and fix instances of Data Leakage in their\nmodels. Data Leakage often results from bad practices in writing ML code. As a\nresult, the model effectively ''memorizes'' the data on which it trains,\nleading to an overly optimistic estimate of the model performance and an\ninability to make generalized predictions. ML developers must carefully\nseparate their data into training, evaluation, and test sets to avoid\nintroducing Data Leakage into their code. Training data should be used to train\nthe model, evaluation data should be used to repeatedly confirm a model's\naccuracy, and test data should be used only once to determine the accuracy of a\nproduction-ready model. In this paper, we develop LEAKAGEDETECTOR, a Python\nplugin for the PyCharm IDE that identifies instances of Data Leakage in ML code\nand provides suggestions on how to remove the leakage."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13517"
    ],
    "c_title":[
      "Generalised Morrey sequence spaces"
    ],
    "c_abstract":[
      "Generalised Morrey (function) spaces enjoyed some interest recently and found\napplications to PDE. Here we turn our attention to their discrete counterparts.\nWe define generalised Morrey sequence spaces\n$m_{\\varphi,p}=m_{\\varphi,p}(\\mathbb{Z}^d)$. They are natural generalisations\nof the classical Morrey sequence spaces $m_{u,p}$, $0<p\\le u<\\infty$, which\nwere studied earlier. We consider some basic features of the spaces as well as\nembedding properties such as continuity, compactness and strict singularity."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-859",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08772"
    ],
    "b_title":[
      "Persistent Sheaf Laplacian Analysis of Protein Flexibility"
    ],
    "b_abstract":[
      "Protein flexibility, measured by the B-factor or Debye-Waller factor, is\nessential for protein functions such as structural support, enzyme activity,\ncellular communication, and molecular transport. Theoretical analysis and\nprediction of protein flexibility are crucial for protein design, engineering,\nand drug discovery. In this work, we introduce the persistent sheaf Laplacian\n(PSL), an effective tool in topological data analysis, to model and analyze\nprotein flexibility. By representing the local topology and geometry of protein\natoms through the multiscale harmonic and non-harmonic spectra of PSLs, the\nproposed model effectively captures protein flexibility and provides accurate,\nrobust predictions of protein B-factors. Our PSL model demonstrates an increase\nin accuracy of 32% compared to the classical Gaussian network model (GNM) in\npredicting B-factors for a dataset of 364 proteins. Additionally, we construct\na blind machine learning prediction method utilizing global and local protein\nfeatures. Extensive computations and comparisons validate the effectiveness of\nthe proposed PSL model for B-factor predictions."
    ],
    "b_categories":[
      [
        "q-bio.BM",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "2502.15216"
    ],
    "c_title":[
      "Approximate weighted 3-coloring"
    ],
    "c_abstract":[
      "The paper considers the NP-hard graph vertex coloring problem, which differs\nfrom traditional problems in which it is required to color vertices with a\ngiven (or minimal) number of colors so that adjacent vertices have different\ncolors. In the problem under consideration, a simple edge-weighted graph is\ngiven. It is required to color its vertices in 3 colors to minimize the total\nweight of monochromatic (one-color) edges, i.e. edges with the same colors of\ntheir end vertices. This problem is poorly investigated. Previously, we\ndeveloped graph decomposition algorithms that, in particular, allowed us to\nconstruct lower bounds for the optimum, as well as several greedy algorithms.\nIn this paper, several new approximation algorithms are proposed. Among them\nare variable neighborhood search, simulated annealing, genetic algorithm and\ngraph clustering with further finding the optimal coloring in each cluster. A\nnumerical experiment was conducted on random graphs, as well as on real\ncommunication graphs. The characteristics of the algorithms are presented both\nin tables and graphically. The developed algorithms have shown high efficiency."
    ],
    "c_categories":[
      [
        "cs.DM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-860",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16855"
    ],
    "b_title":[
      "Stack Transformer Based Spatial-Temporal Attention Model for Dynamic\n  Multi-Culture Sign Language Recognition"
    ],
    "b_abstract":[
      "Hand gesture-based Sign Language Recognition (SLR) serves as a crucial\ncommunication bridge between deaf and non-deaf individuals. Existing SLR\nsystems perform well for their cultural SL but may struggle with multi-cultural\nsign languages (McSL). To address these challenges, this paper proposes a Stack\nSpatial-Temporal Transformer Network that leverages multi-head attention\nmechanisms to capture both spatial and temporal dependencies with hierarchical\nfeatures using the Stack Transfer concept. In the proceed, firstly, we applied\na fully connected layer to make a embedding vector which has high expressive\npower from the original dataset, then fed them a stack newly proposed\ntransformer to achieve hierarchical features with short-range and long-range\ndependency. The network architecture is composed of several stages that process\nspatial and temporal relationships sequentially, ensuring effective feature\nextraction. After making the fully connected layer, the embedding vector is\nprocessed by the Spatial Multi-Head Attention Transformer, which captures\nspatial dependencies between joints. In the next stage, the Temporal Multi-Head\nAttention Transformer captures long-range temporal dependencies, and again, the\nfeatures are concatenated with the output using another skip connection. The\nprocessed features are then passed to the Feed-Forward Network (FFN), which\nrefines the feature representations further. After the FFN, additional skip\nconnections are applied to combine the output with earlier layers, followed by\na final normalization layer to produce the final output feature tensor. This\nprocess is repeated for 10 transformer blocks. The extensive experiment shows\nthat the JSL, KSL and ASL datasets achieved good performance accuracy. Our\napproach demonstrates improved performance in McSL, and it will be consider as\na novel work in this domain."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.02281"
    ],
    "c_title":[
      "Bounce solutions with quantum vacuum effects of massive fields and\n  subsequent Starobinsky inflation"
    ],
    "c_abstract":[
      "We extend the previous work about the cosmological solutions with bounce\nwithout modifications of gravity or introducing an extra scalar field. The main\nfinding was that the bounce is possible in the initially contracting Universe\nfilled with matter. After a strong contraction, matter gains the equation of\nstate close to the one of radiation, such that the effect on matter on the\nevolution of the FLRW metric disappears at the classical level. However, this\neffect comes back owing to the quantum trace anomaly in the matter\/radiation\nsector. In the present contribution, we explore the weak impact of massive\nfields on the anomaly-driven bounce solution and discuss the role of the vacuum\nterms. The masses are assumed small and regarded as small perturbations, which\nenables using trace anomaly even in this case. On the other hand, by adding the\n$R^2$ term to the action, we arrive at the model with the trans-Planckian\nbounce and subsequent Starobinsky inflation. In such a framework, using the\nnumerical analysis, we consider three scenarios providing bounce solutions."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-861",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01513"
    ],
    "b_title":[
      "Out-of-equilibrium dynamical properties of Bose-Einstein condensates in\n  a ramped up weak disorder"
    ],
    "b_abstract":[
      "We theoretically study how the superfluid and condensate deformation of a\nweakly interacting ultracold Bose gas evolve during the ramp-up of an external\nweak disorder potential. Both resulting deformations turn out to consist of two\ndistinct contributions, namely a reversible equilibrium one, already predicted\nby Huang and Meng in 1992, and a nonequilibrium dynamical one, whose magnitude\ndepends on the details of the ramping protocol. For the specific case of the\nexponential ramp-up protocol, we are able to derive analytical time-dependent\nexpressions for the above quantities. After a sufficiently long time, a steady\nstate emerges that is generically out of equilibrium. We take the first step in\ninvestigating its properties by studying its relaxation dynamics. In addition,\nwe analyze the two-time correlation function and elucidate its relation to the\nequilibrium and the dynamical part of the condensate deformation."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.03664"
    ],
    "c_title":[
      "Local Compositional Complexity: How to Detect a Human-readable Messsage"
    ],
    "c_abstract":[
      "Data complexity is an important concept in the natural sciences and related\nareas, but lacks a rigorous and computable definition. In this paper, we focus\non a particular sense of complexity that is high if the data is structured in a\nway that could serve to communicate a message. In this sense, human speech,\nwritten language, drawings, diagrams and photographs are high complexity,\nwhereas data that is close to uniform throughout or populated by random values\nis low complexity. We describe a general framework for measuring data\ncomplexity based on dividing the shortest description of the data into a\nstructured and an unstructured portion, and taking the size of the former as\nthe complexity score. We outline an application of this framework in\nstatistical mechanics that may allow a more objective characterisation of the\nmacrostate and entropy of a physical system. Then, we derive a more precise and\ncomputable definition geared towards human communication, by proposing local\ncompositionality as an appropriate specific structure. We demonstrate\nexperimentally that this method can distinguish meaningful signals from noise\nor repetitive signals in auditory, visual and text domains, and could\npotentially help determine whether an extra-terrestrial signal contained a\nmessage."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-862",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.07338"
    ],
    "b_title":[
      "Ultrafast 4D scanning transmission electron microscopy for imaging of\n  localized optical fields"
    ],
    "b_abstract":[
      "Ultrafast electron microscopy aims for imaging transient phenomena occurring\non nanoscale. One of its goals is to visualize localized optical and plasmonic\nmodes generated by coherent excitation in the vicinity of various types of\nnanostructures. Such imaging capability was enabled by photon-induced\nnear-field optical microscopy, which is based on spectral filtering of\nelectrons inelastically scattered due to the stimulated interaction with the\nnear-field. Here we report on the development of ultrafast 4D scanning\ntransmission electron microscopy, which allows us to image the transverse\ncomponents of the optical near-field while avoiding the need of electron\nspectral filtering. We demonstrate that this method is capable of imaging\noptical near-fields of a tungsten nanotip and ponderomotive potential of an\noptical standing wave with a spatial resolution of 21 nm."
    ],
    "b_categories":[
      [
        "physics.ins-det",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.16033"
    ],
    "c_title":[
      "PRISMe: A Novel LLM-Powered Tool for Interactive Privacy Policy\n  Assessment"
    ],
    "c_abstract":[
      "Protecting online privacy requires users to engage with and comprehend\nwebsite privacy policies, but many policies are difficult and tedious to read.\nWe present PRISMe (Privacy Risk Information Scanner for Me), a novel Large\nLanguage Model (LLM)-driven privacy policy assessment tool, which helps users\nto understand the essence of a lengthy, complex privacy policy while browsing.\nThe tool, a browser extension, integrates a dashboard and an LLM chat. One\nmajor contribution is the first rigorous evaluation of such a tool. In a\nmixed-methods user study (N=22), we evaluate PRISMe's efficiency, usability,\nunderstandability of the provided information, and impacts on awareness. While\nour tool improves privacy awareness by providing a comprehensible quick\noverview and a quality chat for in-depth discussion, users note issues with\nconsistency and building trust in the tool. From our insights, we derive\nimportant design implications to guide future policy analysis tools."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-863",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14876"
    ],
    "b_title":[
      "Strong CWoLa: Binary Classification Without Background Simulation"
    ],
    "b_abstract":[
      "Supervised deep learning methods have been successful in the field of high\nenergy physics, and the trend within the field is to move away from high level\nreconstructed variables to lower level, higher dimensional features. Supervised\nmethods require labelled data, which is typically provided by a simulator. As\nthe number of features increases, simulation accuracy decreases, leading to\ngreater domain shift between training and testing data when using lower-level\nfeatures. This work demonstrates that the classification without labels\nparadigm can be used to remove the need for background simulation when training\nsupervised classifiers. This can result in classifiers with higher performance\non real data than those trained on simulated data."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.08564"
    ],
    "c_title":[
      "MoE-Loco: Mixture of Experts for Multitask Locomotion"
    ],
    "c_abstract":[
      "We present MoE-Loco, a Mixture of Experts (MoE) framework for multitask\nlocomotion for legged robots. Our method enables a single policy to handle\ndiverse terrains, including bars, pits, stairs, slopes, and baffles, while\nsupporting quadrupedal and bipedal gaits. Using MoE, we mitigate the gradient\nconflicts that typically arise in multitask reinforcement learning, improving\nboth training efficiency and performance. Our experiments demonstrate that\ndifferent experts naturally specialize in distinct locomotion behaviors, which\ncan be leveraged for task migration and skill composition. We further validate\nour approach in both simulation and real-world deployment, showcasing its\nrobustness and adaptability."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-864",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14584"
    ],
    "b_title":[
      "Search for dark matter subhalos among unassociated Fermi-LAT sources in\n  presence of dataset shift"
    ],
    "b_abstract":[
      "We search for dark matter (DM) annihilating subhalos of the Milky Way halo\namong the Fermi Large Area Telescope (LAT) unassociated sources. We construct,\nfor the first time, a statistical model of the unassociated sources at\nlatitudes above 10 degrees. The latter is built as a combination of both DM\nannihilation subhalos as well as Galactic and extragalactic astrophysical\ncomponents. The astrophysical components are constructed based on distributions\nof associated sources, while the distribution of DM subhalos is derived from\nMonte Carlo simulations. In this model we take into account the differences in\nthe distributions of associated and unassociated sources including both\ncovariate and prior probability shifts (both being forms of ``dataset\nshifts''). Previous searches of DM subhalos were based on classify-and-count\nstrategies, while the approach adopted in this work is based on quantification\nlearning, which allows one to determine a well-defined statistical\ninterpretation of the contribution of a population of DM subhalos to the\nunassociated Fermi-LAT sources. In the $b\\bar{b}$ annihilation channel and for\na range of DM masses from 10 GeV to 1 TeV, we don't find a significant\ncontribution from DM subhalos and derive a statistical 95% confidence upper\nlimit on the DM annihilation cross section in this channel. While the derived\nlimits are consistent with previous classify-and-count approaches, our\ngenerative statistical model opens new avenues for population studies of\nFermi-LAT sources and, more generally, for searches of anomalies on top of\nbackgrounds in presence of statistical and systematic uncertainties."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.15446"
    ],
    "c_title":[
      "Quantized Coulomb branch of 4d $\\mathcal{N}=2$ $Sp(N)$ gauge theory and\n  spherical DAHA of $(C_N^{\\vee}, C_N)$-type"
    ],
    "c_abstract":[
      "We study BPS loop operators in a 4d $\\mathcal{N}=2$ $Sp(N)$ gauge theory with\nfour hypermultiplets in the fundamental representation and one hypermultiplet\nin the anti-symmetric representation. The algebra of BPS loop operators in the\n$\\Omega$-background provides a deformation quantization of the Coulomb branch,\nwhich is expected to coincide with the quantized K-theoretic Coulomb branch in\nthe mathematical literature. For the rank-one case, i.e., $Sp(1) \\simeq SU(2)$,\nwe show that the quantization of the Coulomb branch, evaluated using the\nsupersymmetric localization formula, agrees with the polynomial representation\nof the spherical part of the double affine Hecke algebra (spherical DAHA) of\n$(C_1^{\\vee}, C_1)$-type. For higher-rank cases, where $N \\geq 2$, we\nconjecture that the quantized Coulomb branch of the 4d $\\mathcal{N}=2$ $Sp(N)$\ngauge theory is isomorphic to the spherical DAHA of $(C_N^{\\vee}, C_N)$-type .\nAs evidence for this conjecture, we demonstrate that the quantization of an 't\nHooft loop agrees with the Koornwinder operator in the polynomial\nrepresentation of the spherical DAHA."
    ],
    "c_categories":[
      [
        "hep-th",
        "math-ph",
        "math.AG",
        "math.MP",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-865",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04667"
    ],
    "b_title":[
      "An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding"
    ],
    "b_abstract":[
      "This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16661"
    ],
    "c_title":[
      "Jupybara: Operationalizing a Design Space for Actionable Data Analysis\n  and Storytelling with LLMs"
    ],
    "c_abstract":[
      "Mining and conveying actionable insights from complex data is a key challenge\nof exploratory data analysis (EDA) and storytelling. To address this challenge,\nwe present a design space for actionable EDA and storytelling. Synthesizing\ntheory and expert interviews, we highlight how semantic precision, rhetorical\npersuasion, and pragmatic relevance underpin effective EDA and storytelling. We\nalso show how this design space subsumes common challenges in actionable EDA\nand storytelling, such as identifying appropriate analytical strategies and\nleveraging relevant domain knowledge. Building on the potential of LLMs to\ngenerate coherent narratives with commonsense reasoning, we contribute\nJupybara, an AI-enabled assistant for actionable EDA and storytelling\nimplemented as a Jupyter Notebook extension. Jupybara employs two strategies --\ndesign-space-aware prompting and multi-agent architectures -- to operationalize\nour design space. An expert evaluation confirms Jupybara's usability,\nsteerability, explainability, and reparability, as well as the effectiveness of\nour strategies in operationalizing the design space framework with LLMs."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-866",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16906"
    ],
    "b_title":[
      "AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning\n  Abilities of Large Language Models"
    ],
    "b_abstract":[
      "While logical reasoning evaluation of Large Language Models (LLMs) has\nattracted significant attention, existing benchmarks predominantly rely on\nmultiple-choice formats that are vulnerable to random guessing, leading to\noverestimated performance and substantial performance fluctuations. To obtain\nmore accurate assessments of models' reasoning capabilities, we propose an\nautomated method for synthesizing open-ended logic puzzles, and use it to\ndevelop a bilingual benchmark, AutoLogi. Our approach features program-based\nverification and controllable difficulty levels, enabling more reliable\nevaluation that better distinguishes models' reasoning abilities. Extensive\nevaluation of eight modern LLMs shows that AutoLogi can better reflect true\nmodel capabilities, with performance scores spanning from 35% to 73% compared\nto the narrower range of 21% to 37% on the source multiple-choice dataset.\nBeyond benchmark creation, this synthesis method can generate high-quality\ntraining data by incorporating program verifiers into the rejection sampling\nprocess, enabling systematic enhancement of LLMs' reasoning capabilities across\ndiverse datasets."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07024"
    ],
    "c_title":[
      "Anomalous behaviour of the temperature dependencies of the upper\n  critical fields in (Dy1-xErx)Rh3.8Ru0.2B4 (x=0, 0.2, 0.4)"
    ],
    "c_abstract":[
      "For the first time, a detailed analysis of the behaviour of the temperature\ndependences of the upper critical fields Hc2(T) has been carried out in the\ncompounds (Dy1-xErx)Rh3.8Ru0.2B4 (x = 0, 0.2, 0.4). It is found that the Hc2(T)\nin (Dy0.8Er0.2)Rh3.8Ru0.2B4 has an inflection point at 3 kOe, which may be\nrelated to the low-temperature magnetic ordering, while a more exotic mechanism\ncaused by the transition from ordinary singlet to triplet superconductivity is\nnot excluded. For the first time, the experimental Hc2(T) dependences of\n(Dy1-xErx)Rh3.8Ru0.2B4 (x = 0, 0.2, 0.4) compounds have been fitted within the\nframework of Werthamer-Helfand-Hohenberg theory (WHH) with the Maki parameter\nalpha > 0, indicating that spin-paramagnetic effects due to magnetic exchange\ninteractions play an essential role in suppressing superconductivity in these\ncompounds."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-867",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14258"
    ],
    "b_title":[
      "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal\n  System"
    ],
    "b_abstract":[
      "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https:\/\/github.com\/oneal2000\/JuDGE."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16055"
    ],
    "c_title":[
      "Random Reshuffling for Stochastic Gradient Langevin Dynamics"
    ],
    "c_abstract":[
      "We examine the use of different randomisation policies for stochastic\ngradient algorithms used in sampling, based on first-order (or overdamped)\nLangevin dynamics, the most popular of which is known as Stochastic Gradient\nLangevin Dynamics. Conventionally, this algorithm is combined with a specific\nstochastic gradient strategy, called Robbins-Monro. In this work, we study an\nalternative strategy, Random Reshuffling, and show convincingly that it leads\nto improved performance via: a) a proof of reduced bias in the Wasserstein\nmetric for strongly convex, gradient Lipschitz potentials; b) an analytical\ndemonstration of reduced bias for a Gaussian model problem; and c) an empirical\ndemonstration of reduced bias in numerical experiments for some logistic\nregression problems. This is especially important since Random Reshuffling is\ntypically more efficient due to memory access and cache reasons. Such\nacceleration for the Random Reshuffling policy is familiar from the\noptimisation literature on stochastic gradient descent."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.PR",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-868",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17892"
    ],
    "b_title":[
      "Object Detection with Deep Learning for Rare Event Search in the GADGET\n  II TPC"
    ],
    "b_abstract":[
      "In the pursuit of identifying rare two-particle events within the GADGET II\nTime Projection Chamber (TPC), this paper presents a comprehensive approach for\nleveraging Convolutional Neural Networks (CNNs) and various data processing\nmethods. To address the inherent complexities of 3D TPC track reconstructions,\nthe data is expressed in 2D projections and 1D quantities. This approach\ncapitalizes on the diverse data modalities of the TPC, allowing for the\nefficient representation of the distinct features of the 3D events, with no\nloss in topology uniqueness. Additionally, it leverages the computational\nefficiency of 2D CNNs and benefits from the extensive availability of\npre-trained models. Given the scarcity of real training data for the rare\nevents of interest, simulated events are used to train the models to detect\nreal events. To account for potential distribution shifts when predominantly\ndepending on simulations, significant perturbations are embedded within the\nsimulations. This produces a broad parameter space that works to account for\npotential physics parameter and detector response variations and uncertainties.\nThese parameter-varied simulations are used to train sensitive 2D CNN object\ndetectors. When combined with 1D histogram peak detection algorithms, this\nmulti-modal detection framework is highly adept at identifying rare,\ntwo-particle events in data taken during experiment 21072 at the Facility for\nRare Isotope Beams (FRIB), demonstrating a 100% recall for events of interest.\nWe present the methods and outcomes of our investigation and discuss the\npotential future applications of these techniques."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "physics.data-an",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16610"
    ],
    "c_title":[
      "AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive\n  Adversarial VAEs"
    ],
    "c_abstract":[
      "Ensuring the quality and integrity of medical images is crucial for\nmaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosis\nand Computer-Aided Detection (CAD) systems. Covariate shifts are subtle\nvariations in the data distribution caused by different imaging devices or\nsettings and can severely degrade model performance, similar to the effects of\nadversarial attacks. Therefore, it is vital to have a lightweight and fast\nmethod to assess the quality of these images prior to using CAD models.\nAdverX-Ray addresses this need by serving as an image-quality assessment layer,\ndesigned to detect covariate shifts effectively. This Adversarial Variational\nAutoencoder prioritizes the discriminator's role, using the suboptimal outputs\nof the generator as negative samples to fine-tune the discriminator's ability\nto identify high-frequency artifacts. Images generated by adversarial networks\noften exhibit severe high-frequency artifacts, guiding the discriminator to\nfocus excessively on these components. This makes the discriminator ideal for\nthis approach. Trained on patches from X-ray images of specific machine models,\nAdverX-Ray can evaluate whether a scan matches the training distribution, or if\na scan from the same machine is captured under different settings. Extensive\ncomparisons with various OOD detection methods show that AdverX-Ray\nsignificantly outperforms existing techniques, achieving a 96.2% average AUROC\nusing only 64 random patches from an X-ray. Its lightweight and fast\narchitecture makes it suitable for real-time applications, enhancing the\nreliability of medical imaging systems. The code and pretrained models are\npublicly available."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-869",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14082"
    ],
    "b_title":[
      "Communicating Activations Between Language Model Agents"
    ],
    "b_abstract":[
      "Communication between multiple language model (LM) agents has been shown to\nscale up the reasoning ability of LMs. While natural language has been the\ndominant medium for inter-LM communication, it is not obvious this should be\nthe standard: not only does natural language communication incur high inference\ncosts that scale quickly with the number of both agents and messages, but also\nthe decoding process abstracts away too much rich information that could be\notherwise accessed from the internal activations. In this work, we propose a\nsimple technique whereby LMs communicate via activations; concretely, we pause\nan LM $\\textit{B}$'s computation at an intermediate layer, combine its current\nactivation with another LM $\\textit{A}$'s intermediate activation via some\nfunction $\\textit{f}$, then pass $\\textit{f}$'s output into the next layer of\n$\\textit{B}$ and continue the forward pass till decoding is complete. This\napproach scales up LMs on new tasks with zero additional parameters and data,\nand saves a substantial amount of compute over natural language communication.\nWe test our method with various functional forms $\\textit{f}$ on two\nexperimental setups--multi-player coordination games and reasoning\nbenchmarks--and find that it achieves up to $27.0\\%$ improvement over natural\nlanguage communication across datasets with $<$$1\/4$ the compute, illustrating\nthe superiority and robustness of activations as an alternative \"language\" for\ncommunication between LMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19254"
    ],
    "c_title":[
      "Set and functional prediction: randomness, exchangeability, and\n  conformal"
    ],
    "c_abstract":[
      "This paper continues the study of the efficiency of conformal prediction as\ncompared with more general randomness prediction and exchangeability\nprediction. It does not restrict itself to the case of classification, and our\nresults will also be applicable to the case of regression. The price to pay is\nthat efficiency will be attained only on average, albeit with respect to a wide\nrange of probability measures on the label space."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-870",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03683"
    ],
    "b_title":[
      "Ruling out AGNs as the dominant source of cosmic reionization with JWST"
    ],
    "b_abstract":[
      "Cosmic reionization represents the latest phase transition of the\nintergalactic medium (IGM) in the Universe. It has long been debated whether\ngalaxies or active galactic nuclei (AGNs) are the major source of Lyman\ncontinuum (LyC) photons responsible for reionization. Previous observations\nslightly favored galaxies as the major ionizing source. However, the James Webb\nSpace Telescope (JWST) recently discovered an unexpectedly high density of AGN\ncandidates at high redshift, which has largely enhanced the influence of AGNs.\nHere we derive a definitive upper bound on the AGN contribution to reionization\nusing the latest JWST data, and conclusively rule out AGNs as the dominant\nionizing source during the epoch of reionization (EoR). We build a sample of\nobjects (including galaxies and AGNs) in a specific redshift range between 7.15\nand 7.75 that has a high completeness. Each object is then decomposed into a\npoint-source component and an extended component in their rest-frame far-UV\nJWST images. Assuming all point-source components are AGNs, we obtain an\nabsolute upper limit for the density of the AGN population. This fiducial AGN\nsample reaches an unprecedentedly low luminosity of $M_{\\rm UV} \\approx -15$\nmag. Based on this sample, we find that AGNs can contribute at most one third\nof the LyC photons required to ionize the Universe in this redshift range. Our\nresult implies that galaxies dominate the ionizing source during the EoR."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.17419"
    ],
    "c_title":[
      "From System 1 to System 2: A Survey of Reasoning Large Language Models"
    ],
    "c_abstract":[
      "Achieving human-level intelligence requires refining the transition from the\nfast, intuitive System 1 to the slower, more deliberate System 2 reasoning.\nWhile System 1 excels in quick, heuristic decisions, System 2 relies on logical\nreasoning for more accurate judgments and reduced biases. Foundational Large\nLanguage Models (LLMs) excel at fast decision-making but lack the depth for\ncomplex reasoning, as they have not yet fully embraced the step-by-step\nanalysis characteristic of true System 2 thinking. Recently, reasoning LLMs\nlike OpenAI's o1\/o3 and DeepSeek's R1 have demonstrated expert-level\nperformance in fields such as mathematics and coding, closely mimicking the\ndeliberate reasoning of System 2 and showcasing human-like cognitive abilities.\nThis survey begins with a brief overview of the progress in foundational LLMs\nand the early development of System 2 technologies, exploring how their\ncombination has paved the way for reasoning LLMs. Next, we discuss how to\nconstruct reasoning LLMs, analyzing their features, the core methods enabling\nadvanced reasoning, and the evolution of various reasoning LLMs. Additionally,\nwe provide an overview of reasoning benchmarks, offering an in-depth comparison\nof the performance of representative reasoning LLMs. Finally, we explore\npromising directions for advancing reasoning LLMs and maintain a real-time\n\\href{https:\/\/github.com\/zzli2022\/Awesome-Slow-Reason-System}{GitHub\nRepository} to track the latest developments. We hope this survey will serve as\na valuable resource to inspire innovation and drive progress in this rapidly\nevolving field."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-871",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13967"
    ],
    "b_title":[
      "FlexTok: Resampling Images into 1D Token Sequences of Flexible Length"
    ],
    "b_abstract":[
      "Image tokenization has enabled major advances in autoregressive image\ngeneration by providing compressed, discrete representations that are more\nefficient to process than raw pixels. While traditional approaches use 2D grid\ntokenization, recent methods like TiTok have shown that 1D tokenization can\nachieve high generation quality by eliminating grid redundancies. However,\nthese methods typically use a fixed number of tokens and thus cannot adapt to\nan image's inherent complexity. We introduce FlexTok, a tokenizer that projects\n2D images into variable-length, ordered 1D token sequences. For example, a\n256x256 image can be resampled into anywhere from 1 to 256 discrete tokens,\nhierarchically and semantically compressing its information. By training a\nrectified flow model as the decoder and using nested dropout, FlexTok produces\nplausible reconstructions regardless of the chosen token sequence length. We\nevaluate our approach in an autoregressive generation setting using a simple\nGPT-style Transformer. On ImageNet, this approach achieves an FID<2 across 8 to\n128 tokens, outperforming TiTok and matching state-of-the-art methods with far\nfewer tokens. We further extend the model to support to text-conditioned image\ngeneration and examine how FlexTok relates to traditional 2D tokenization. A\nkey finding is that FlexTok enables next-token prediction to describe images in\na coarse-to-fine \"visual vocabulary\", and that the number of tokens to generate\ndepends on the complexity of the generation task."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12731"
    ],
    "c_title":[
      "Form and function in biological filaments: A physicist's review"
    ],
    "c_abstract":[
      "Nature uses elongated shapes and filaments to build stable structures,\ngenerate motion, and allow complex geometric interactions. In this Review, we\nexamine the role of biological filaments across different length scales. From\nthe molecular scale, where cytoskeletal filaments provides a robust but dynamic\ncellular scaffolding, over the scale of cellular appendages like cilia and\nflagella, to the scale of filamentous microorganisms like cyanobacteria which\nare among the most successful genera on Earth, and even to the scale of\nelongated animals like worms and snakes, whose motility modes inspire robotic\nanalogues. We highlight the general mechanisms that couple form and function.\nPhysical principles, such as classical elasticity and the non-reciprocity of\nactive matter can be used to trace unifying themes linking these systems\nspanning about six orders of magnitude in length."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.bio-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-872",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17356"
    ],
    "b_title":[
      "On the Coexistence and Ensembling of Watermarks"
    ],
    "b_abstract":[
      "Watermarking, the practice of embedding imperceptible information into media\nsuch as images, videos, audio, and text, is essential for intellectual property\nprotection, content provenance and attribution. The growing complexity of\ndigital ecosystems necessitates watermarks for different uses to be embedded in\nthe same media. However, to detect and decode all watermarks, they need to\ncoexist well with one another. We perform the first study of coexistence of\ndeep image watermarking methods and, contrary to intuition, we find that\nvarious open-source watermarks can coexist with only minor impacts on image\nquality and decoding robustness. The coexistence of watermarks also opens the\navenue for ensembling watermarking methods. We show how ensembling can increase\nthe overall message capacity and enable new trade-offs between capacity,\naccuracy, robustness and image quality, without needing to retrain the base\nmodels."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.13543"
    ],
    "c_title":[
      "Advancing ATLAS DCS Data Analysis with a Modern Data Platform"
    ],
    "c_abstract":[
      "This paper presents a modern and scalable framework for analyzing Detector\nControl System (DCS) data from the ATLAS experiment at CERN. The DCS data,\nstored in an Oracle database via the WinCC OA system, is optimized for\ntransactional operations, posing challenges for large-scale analysis across\nextensive time periods and devices. To address these limitations, we developed\na data pipeline using Apache Spark, CERN's Hadoop service, and the CERN SWAN\nplatform. This framework integrates seamlessly with Python notebooks, providing\nan accessible and efficient environment for data analysis using\nindustry-standard tools. The approach has proven effective in troubleshooting\nData Acquisition (DAQ) links for the ATLAS New Small Wheel (NSW) detector,\ndemonstrating the value of modern data platforms in enabling detector experts\nto quickly identify and resolve critical issues."
    ],
    "c_categories":[
      [
        "cs.DC",
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-873",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03990"
    ],
    "b_title":[
      "Data-Driven Probabilistic Air-Sea Flux Parameterization"
    ],
    "b_abstract":[
      "Accurately quantifying air-sea fluxes is important for understanding air-sea\ninteractions and improving coupled weather and climate systems. This study\nintroduces a probabilistic framework to represent the highly variable nature of\nair-sea fluxes, which is missing in deterministic bulk algorithms. Assuming\nGaussian distributions conditioned on the input variables, we use artificial\nneural networks and eddy-covariance measurement data to estimate the mean and\nvariance by minimizing negative log-likelihood loss. The trained neural\nnetworks provide alternative mean flux estimates to existing bulk algorithms,\nand quantify the uncertainty around the mean estimates. Stochastic\nparameterization of air-sea turbulent fluxes can be constructed by sampling\nfrom the predicted distributions. Tests in a single-column forced upper-ocean\nmodel suggest that changes in flux algorithms influence sea surface temperature\nand mixed layer depth seasonally. The ensemble spread in stochastic runs is\nmost pronounced during spring restratification."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.ao-ph",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18483"
    ],
    "c_title":[
      "A Global Existence Theorem for a Fourth-Order Crystal Surface Model with\n  Gradient Dependent Mobility"
    ],
    "c_abstract":[
      "In this article we study the existence of solutions to a fourth-order\nnonlinear PDE related to crystal surface growth. The key difficulty in the\nequations comes from the mobility matrix, which depends on the gradient of the\nsolution. When the mobility matrix is the identity matrix there are now many\nexistence results, however when it is allowed to depend on the solution we lose\ncrucial estimates in the time direction. In this work we are able to prove the\nglobal existence of weak solutions despite this lack of estimates in the time\ndirection."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-874",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.14891"
    ],
    "b_title":[
      "CoDiff: Conditional Diffusion Model for Collaborative 3D Object\n  Detection"
    ],
    "b_abstract":[
      "Collaborative 3D object detection holds significant importance in the field\nof autonomous driving, as it greatly enhances the perception capabilities of\neach individual agent by facilitating information exchange among multiple\nagents. However, in practice, due to pose estimation errors and time delays,\nthe fusion of information across agents often results in feature\nrepresentations with spatial and temporal noise, leading to detection errors.\nDiffusion models naturally have the ability to denoise noisy samples to the\nideal data, which motivates us to explore the use of diffusion models to\naddress the noise problem between multi-agent systems. In this work, we propose\nCoDiff, a novel robust collaborative perception framework that leverages the\npotential of diffusion models to generate more comprehensive and clearer\nfeature representations. To the best of our knowledge, this is the first work\nto apply diffusion models to multi-agent collaborative perception.\nSpecifically, we project high-dimensional feature map into the latent space of\na powerful pre-trained autoencoder. Within this space, individual agent\ninformation serves as a condition to guide the diffusion model's sampling. This\nprocess denoises coarse feature maps and progressively refines the fused\nfeatures. Experimental study on both simulated and real-world datasets\ndemonstrates that the proposed framework CoDiff consistently outperforms\nexisting relevant methods in terms of the collaborative object detection\nperformance, and exhibits highly desired robustness when the pose and delay\ninformation of agents is with high-level noise."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17129"
    ],
    "c_title":[
      "A model of full thermodynamic stabilization of nanocrystalline alloys"
    ],
    "c_abstract":[
      "We propose a model of a polycrystalline alloy combining the Potts model for\ngrain orientations with a lattice-gas model for solute thermodynamics and\ndiffusion. The alloy evolution with this model is implemented by kinetic Monte\nCarlo simulations with nonlinear transition barriers between the states. The\nmodel is applied to investigate the long-standing question of whether grain\nboundary (GB) segregation of an appropriate solute can drive the GB free energy\nto zero, creating a fully stabilized polycrystalline state with a finite grain\nsize. The model reproduces stable polycrystalline states under certain\nconditions, provided the solute-solute interactions are repulsive. The\nstructure minimizing the total free energy is not static. It exists in a state\nof dynamic equilibrium between the competing processes of grain growth and\ngrain refinement. The alloy eliminates triple junctions by forming a set of\nsmaller grains embedded into a larger matrix grain. It is predicted that, if a\nfully stabilized nanocrystalline state is implemented experimentally, it will\nlook very different from the conventional (unstable) nanocrystalline materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-875",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13677"
    ],
    "b_title":[
      "Value-Oriented Forecast Combinations for Unit Commitment"
    ],
    "b_abstract":[
      "Value-oriented forecasts for two-stage power system operational problems have\nbeen demonstrated to reduce cost, but prove to be computationally challenging\nfor large-scale systems because the underlying optimization problem must be\ninternalized into the forecast model training. Therefore, existing approaches\ntypically scale poorly in the usable training data or require relaxations of\nthe underlying optimization. This paper presents a method for value-oriented\nforecast combinations using progressive hedging, which unlocks high-fidelity,\nat-scale models and large-scale datasets in training. We also derive a direct\none-shot training model for reference and study how different modifications of\nthe training model impact the solution quality. Our method reduces operation\ncost by 1.8% on average and trains forecast combinations for a 2736-bus test\nsystem with one year of data within 20 hours."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04697"
    ],
    "c_title":[
      "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement\n  Learning"
    ],
    "c_abstract":[
      "Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps:\/\/www.cmu-l3.github.io\/l1"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-876",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12937"
    ],
    "b_title":[
      "R1-VL: Learning to Reason with Multimodal Large Language Models via\n  Step-wise Group Relative Policy Optimization"
    ],
    "b_abstract":[
      "Recent studies generally enhance MLLMs' reasoning capabilities via supervised\nfine-tuning on high-quality chain-of-thought reasoning data, which often leads\nmodels to merely imitate successful reasoning paths without understanding what\nthe wrong reasoning paths are. In this work, we aim to enhance the MLLMs'\nreasoning ability beyond passively imitating positive reasoning paths. To this\nend, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new\nonline reinforcement learning framework that enables MLLMs to self-improve\nreasoning ability via simple, effective and dense step-wise rewarding.\nSpecifically, StepGRPO introduces two novel rule-based reasoning rewards:\nStep-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity\nReward (StepRVR). StepRAR rewards the reasoning paths that contain necessary\nintermediate reasoning steps via a soft key-step matching technique, while\nStepRAR rewards reasoning paths that follow a well-structured and logically\nconsistent reasoning process through a reasoning completeness and logic\nevaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series\nof MLLMs with outstanding capabilities in step-by-step reasoning. Extensive\nexperiments over 8 benchmarks demonstrate the superiority of our methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14448"
    ],
    "c_title":[
      "Pauli Network Circuit Synthesis with Reinforcement Learning"
    ],
    "c_abstract":[
      "We introduce a Reinforcement Learning (RL)-based method for re-synthesis of\nquantum circuits containing arbitrary Pauli rotations alongside Clifford\noperations. By collapsing each sub-block to a compact representation and then\nsynthesizing it step-by-step through a learned heuristic, we obtain circuits\nthat are both shorter and compliant with hardware connectivity constraints. We\nfind that the method is fast enough and good enough to work as an optimization\nprocedure: in direct comparisons on 6-qubit random Pauli Networks against\nstate-of-the-art heuristic methods, our RL approach yields over 2x reduction in\ntwo-qubit gate count, while executing in under 10 milliseconds per circuit. We\nfurther integrate the method into a collect-and-re-synthesize pipeline, applied\nas a Qiskit transpiler pass, where we observe average improvements of 20% in\ntwo-qubit gate count and depth, reaching up to 60% for many instances, across\nthe Benchpress benchmark. These results highlight the potential of RL-driven\nsynthesis to significantly improve circuit quality in realistic, large-scale\nquantum transpilation workloads."
    ],
    "c_categories":[
      [
        "cs.AI",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-877",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05021"
    ],
    "b_title":[
      "Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for\n  Interpretable LLM Safety"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit\nweaknesses in traditional safety alignment, which often relies on rigid refusal\nheuristics or representation engineering to block harmful outputs. While they\nare effective for direct adversarial attacks, they fall short of broader safety\nchallenges requiring nuanced, context-aware decision-making. To address this,\nwe propose Reasoning-enhanced Finetuning for interpretable LLM Safety\n(Rational), a novel framework that trains models to engage in explicit safe\nreasoning before response. Fine-tuned models leverage the extensive pretraining\nknowledge in self-generated reasoning to bootstrap their own safety through\nstructured reasoning, internalizing context-sensitive decision-making. Our\nfindings suggest that safety extends beyond refusal, requiring context\nawareness for more robust, interpretable, and adaptive responses. Reasoning is\nnot only a core capability of LLMs but also a fundamental mechanism for LLM\nsafety. Rational employs reasoning-enhanced fine-tuning, allowing it to reject\nharmful prompts while providing meaningful and context-aware responses in\ncomplex scenarios."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10281"
    ],
    "c_title":[
      "$\\Omega_{bbb}\\Omega_{bbb}\\Omega_{bbb}$ tribaryons"
    ],
    "c_abstract":[
      "We study the possible existence of bound states of three $\\Omega_{bbb}$\nbaryons. We consider only $S$ wave interactions and we start from recent\nlattice QCD results which give a strongly attractive potential between two\n$\\Omega_{bbb}$ baryons in the $^1S_0$ channel. We analyze different scenarios.\nAt baryonic level, the $\\Omega_{bbb}\\Omega_{bbb}$ interaction could be\nunderstood to be basically spin-independent, so that the two contributing\nchannels, $^1S_0$ and $^5S_2$, would have a very similar interaction. This\nbaryonic analysis leads to the existence of bound states in the three-body\nsystem. At the quark level, repulsive effects would appear in the $^5S_2$\nchannel, making it more repulsive than the $^1S_0$ channel. We study the effect\nof such repulsion in terms of its range."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-878",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06082"
    ],
    "b_title":[
      "A Fair and Optimal Approach to Sequential Health Rationing"
    ],
    "b_abstract":[
      "The COVID-19 pandemic underscored the urgent need for fair and effective\nallocation of scarce resources, from hospital beds to vaccine distribution. In\nthis paper, we study a healthcare rationing problem where identical units of a\nresource are divided into different categories, and agents are assigned based\non priority rankings. % We first introduce a simple and efficient algorithm\nthat satisfies four fundamental axioms critical to practical applications:\neligible compliance, non-wastefulness, respect for priorities, and maximum\ncardinality. This new algorithm is not only conceptually simpler but also\ncomputationally faster than the Reverse Rejecting rules proposed in recent\nwork. % We then extend our analysis to a more general sequential setting, where\ncategories can be processed both sequentially and simultaneously. For this\nbroader framework, we introduce a novel algorithm that preserves the four\nfundamental axioms while achieving additional desirable properties that\nexisting rules fail to satisfy. Furthermore, we prove that when a strict\nprecedence order over categories is imposed, this rule is the unique mechanism\nthat satisfies these properties."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01693"
    ],
    "c_title":[
      "Correlated study on some $B_{c}\\rightarrow \\text{ }P$ and\n  $B_{c}\\rightarrow\\text{ }S$ wave channels in light of new inputs"
    ],
    "c_abstract":[
      "This study investigates the decay modes of the $B_c$ meson, focusing on\nsemileptonic and nonleptonic decay into S and P wave charmonia. The primary\nobjective is to extract the shape parameter of the $B_{c}$ meson distribution\namplitude through a data-driven approach, utilizing the lattice results on\n$B_{c}\\rightarrow\\eta_{c},J\/\\psi$ semileptonic form factors and yielding an\nestimate of ${\\omega_B}_c = 0.998(34)$ for the same. We use the form factors\nderived from the modified perturbative QCD framework in the analysis. This\nresult and various other inputs on the radiative decays of the P wave charmonia\nenable us to estimate the $q^2$ shapes of the\n$B_{c}\\rightarrow\\chi_{c0},\\chi_{c1}$ and $h_{c}$ form factors using pole\nexpansion parametrization. Using these results, we have obtained predictions of\nLFUV observables $R(\\chi_{c0})=0.169(11)$, $R(\\chi_{c1})=0.126(2)$ and\n$R(h_{c})=0.113(3)$. Finally, we have presented predictions for branching\nratios of some nonleptonic decay modes of the $B_{c}$ meson into S and P wave\ncharmonia in the same modified perturbative QCD framework."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-879",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.10638"
    ],
    "b_title":[
      "Studying Classifier(-Free) Guidance From a Classifier-Centric\n  Perspective"
    ],
    "b_abstract":[
      "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19164"
    ],
    "c_title":[
      "Design of Cavity Backed Slotted Antenna using Machine Learning\n  Regression Model"
    ],
    "c_abstract":[
      "In this paper, a regression-based machine learning model is used for the\ndesign of cavity backed slotted antenna. This type of antenna is commonly used\nin military and aviation communication systems. Initial reflection coefficient\ndata of cavity backed slotted antenna is generated using electromagnetic\nsolver. These reflection coefficient data is then used as input for training\nregression-based machine learning model. The model is trained to predict the\ndimensions of cavity backed slotted antenna based on the input reflection\ncoefficient for a wide frequency band varying from 1 GHz to 8 GHz. This\napproach allows for rapid prediction of optimal antenna configurations,\nreducing the need for repeated physical testing and manual adjustments, may\nlead to significant amount of design and development cost saving. The proposed\nmodel also demonstrates its versatility in predicting multi frequency resonance\nacross 1 GHz to 8 GHz. Also, the proposed approach demonstrates the potential\nfor leveraging machine learning in advanced antenna design, enhancing\nefficiency and accuracy in practical applications such as radar, military\nidentification systems and secure communication networks."
    ],
    "c_categories":[
      [
        "cs.LG",
        "eess.SP",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-880",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17005"
    ],
    "b_title":[
      "Phase coherence of charge-$6e$ superconductors via a frustrated Kagome\n  XY antiferromagnet"
    ],
    "b_abstract":[
      "Recent experimental evidence for the charge-$6e$ condensed phase in kagome\nsuperconductors has generated significant interest. We investigate the\nunconventional superconductivity in the kagome superconductor\n$\\mathrm{CsV_3Sb_5}$, focusing on the emergence of charge-$6e$\nsuperconductivity (SC) at temperatures higher than the conventional charge-$2e$\nSC state. By modeling the phase coherence of the SC order parameter using a\nfrustrated antiferromagnetic XY model on an emergent kagome lattice, we show\nthat the condensation of fractional vortices with $1\/3$ vorticity stabilizes\nphase coherence in $\\exp(i3\\theta)$, giving rise to the charge-$6e$ SC state.\nUsing a tensor network approach tailored for frustrated spin systems, we\nidentify a Berezinskii-Kosterlitz-Thouless transition at $T_c\/J \\simeq 0.075$,\nwhere the unbinding of $1\/3$ fractional vortex-antivortex pairs transforms the\nsystem from the charge-$6e$ SC phase to the normal phase. Below $T_c$, the\n$1\/3$ fractional vortex correlations exhibit power-law decay, while the integer\nvortex correlations decay exponentially, reflecting the dominance of\ncharge-$6e$ SC in the absence of charge-$2e$ SC. Our results provide a\ntheoretical understanding of the charge-$6e$ SC in two-dimensional kagome\nsuperconductors, emphasizing the interplay between fractional vortices,\nfrustration, and topology in stabilizing this exotic SC phase."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.13918"
    ],
    "c_title":[
      "Playing Hex and Counter Wargames using Reinforcement Learning and\n  Recurrent Neural Networks"
    ],
    "c_abstract":[
      "Hex and Counter Wargames are adversarial two-player simulations of real\nmilitary conflicts requiring complex strategic decision-making. Unlike\nclassical board games, these games feature intricate terrain\/unit interactions,\nunit stacking, large maps of varying sizes, and simultaneous move and combat\ndecisions involving hundreds of units. This paper introduces a novel system\ndesigned to address the strategic complexity of Hex and Counter Wargames by\nintegrating cutting-edge advancements in Recurrent Neural Networks with\nAlphaZero, a reliable modern Reinforcement Learning algorithm. The system\nutilizes a new Neural Network architecture developed from existing research,\nincorporating innovative state and action representations tailored to these\nspecific game environments. With minimal training, our solution has shown\npromising results in typical scenarios, demonstrating the ability to generalize\nacross different terrain and tactical situations. Additionally, we explore the\nsystem's potential to scale to larger map sizes. The developed system is openly\naccessible, facilitating continued research and exploration within this\nchallenging domain."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-881",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.18075"
    ],
    "b_title":[
      "Variational inference for hierarchical models with conditional scale and\n  skewness corrections"
    ],
    "b_abstract":[
      "Gaussian variational approximations are widely used for summarizing posterior\ndistributions in Bayesian models, especially in high-dimensional settings.\nHowever, a drawback of such approximations is the inability to capture skewness\nor more complex features of the posterior. Recent work suggests applying\nskewness corrections to existing Gaussian or other symmetric approximations to\naddress this limitation. We propose to incorporate the skewness correction into\nthe definition of an approximating variational family. We consider\napproximating the posterior for hierarchical models, in which there are\n``global'' and ``local'' parameters. A baseline variational approximation is\ndefined as the product of a Gaussian marginal posterior for global parameters\nand a Gaussian conditional posterior for local parameters given the global\nones. Skewness corrections are then considered. The adjustment of the\nconditional posterior term for local variables is adaptive to the global\nparameter value. Optimization of baseline variational parameters is performed\njointly with the skewness correction. Our approach allows the location, scale\nand skewness to be captured separately, without using additional parameters for\nskewness adjustments. The proposed method substantially improves accuracy for\nonly a modest increase in computational cost compared to state-of-the-art\nGaussian approximations. Good performance is demonstrated in generalized linear\nmixed models and multinomial logit discrete choice models."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.14976"
    ],
    "c_title":[
      "A review of annotation classification tools in the educational domain"
    ],
    "c_abstract":[
      "An annotation consists of a portion of information that is associated with a\npiece of content in order to explain something about the content or to add more\ninformation. The use of annotations as a tool in the educational field has\npositive effects on the learning process. The usual way to use this instrument\nis to provide students with contents, usually textual, with which they must\nassociate annotations. In most cases this task is performed in groups of\nstudents who work collaboratively. This process encourages analysis and\nunderstanding of the contents since they have to understand them in order to\nannotate them, and also encourages teamwork. To facilitate its use, computer\napplications have been devel-oped in recent decades that implement the\nannotation process and offer a set of additional functionalities. One of these\nfunctionalities is the classification of the annotations made. This\nfunctionality can be exploited in various ways in the learning process, such as\nguiding the students in the annotation process, providing information to the\nstudent about how the annotation process is done and to the teacher about how\nthe students write and how they understand the content, as well as implementing\nother innovative educational processes. In this sense, the classification of\nannotations plays a critical role in the application of the annotation in the\neducational field. There are many studies of annotations, but most of them\nconsider the classification aspect marginally only. This paper presents an\ninitial study of the classification mech-anisms used in the annotation tools,\nidentifying four types of cases: absence of classification mechanisms,\nclassification based on pre-established vocabularies, classification based on\nextensible vocabularies, and classification based on struc-tured vocabularies."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-882",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01824"
    ],
    "b_title":[
      "Digital quantum simulation of bosonic systems and quantum\n  complementarity"
    ],
    "b_abstract":[
      "Digital quantum simulation has emerged as a powerful approach to investigate\ncomplex quantum systems using digital quantum computers. Many-particle bosonic\nsystems and intricate optical experimental setups pose significant challenges\nfor classical simulation methods. Utilizing a recently developed formalism that\nmaps bosonic operators to Pauli operators via the Gray code, we digitally\nsimulate interferometric variants of Afshar's experiment on IBM's quantum\ncomputers. We investigate the analogous experiments of Unruh and Pessoa\nJ\\'unior, exploring discussions on the apparent violation of Bohr's\ncomplementarity principle when considering the entire experimental setup.\nFurthermore, we analyze these experiments within the framework of an updated\nquantum complementarity principle, which applies to specific quantum state\npreparations and remains consistent with the foundational principles of quantum\nmechanics. Our quantum computer demonstration results are in good agreement\nwith the theoretical predictions and underscore the potential of quantum\ncomputers as effective simulators for bosonic systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.18891"
    ],
    "c_title":[
      "CAAT-EHR: Cross-Attentional Autoregressive Transformer for Multimodal\n  Electronic Health Record Embeddings"
    ],
    "c_abstract":[
      "Electronic health records (EHRs) provide a comprehensive source of\nlongitudinal patient data, encompassing structured modalities such as\nlaboratory results, imaging data, and vital signs, and unstructured clinical\nnotes. These datasets, after necessary preprocessing to clean and format the\ndata for analysis, often remain in their raw EHR form, representing numerical\nor categorical values without further transformation into task-agnostic\nembeddings. While such raw EHR data enables predictive modeling, its reliance\non manual feature engineering or downstream task-specific optimization limits\nits utility for general-purpose applications. Deep learning (DL) techniques,\nsuch as recurrent neural networks (RNNs) and Transformers, have facilitated\npredictive tasks like disease progression and diagnosis prediction. However,\nthese methods often struggle to fully exploit the temporal and multimodal\ndependencies inherent in EHR data due to their reliance on pre-processed but\nuntransformed raw EHR inputs. In this study, we introduce CAAT-EHR, a novel\narchitecture designed to bridge this gap by generating robust, task-agnostic\nlongitudinal embeddings from raw EHR data. CAAT-EHR leverages self- and\ncross-attention mechanisms in its encoder to integrate temporal and contextual\nrelationships across multiple modalities, transforming the data into enriched\nembeddings that capture complex dependencies. An autoregressive decoder\ncomplements the encoder by predicting future time points data during\npre-training, ensuring that the resulting embeddings maintain temporal\nconsistency and alignment. CAAT-EHR eliminates the need for manual feature\nengineering and enables seamless transferability across diverse downstream\ntasks. Extensive evaluations on benchmark datasets, demonstrate the superiority\nof CAAT-EHR-generated embeddings over pre-processed raw EHR data and other\nbaseline approaches."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-883",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.02235"
    ],
    "b_title":[
      "Survey on Question Answering over Visually Rich Documents: Methods,\n  Challenges, and Trends"
    ],
    "b_abstract":[
      "The field of visually-rich document understanding, which involves interacting\nwith visually-rich documents (whether scanned or born-digital), is rapidly\nevolving and still lacks consensus on several key aspects of the processing\npipeline. In this work, we provide a comprehensive overview of state-of-the-art\napproaches, emphasizing their strengths and limitations, pointing out the main\nchallenges in the field, and proposing promising research directions."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.03150"
    ],
    "c_title":[
      "Quantifying the detection likelihood of faint peaks in interferometric\n  data through jackknifing: Test application on finding $z>10$ galaxy\n  candidates"
    ],
    "c_abstract":[
      "False-positive emission-line detections bias our understanding of\nastronomical sources; for example, falsely identifying $z\\sim3-4$ passive\ngalaxies as $z>10$ galaxies leads to incorrect number counts and flawed tests\nof cosmology. In this work, we provide a novel but simple tool to better\nquantify the detection of faint lines in interferometric data sets and properly\ncharacterize the underlying noise distribution. We demonstrate the method on\nthree sets of archival observations of $z>10$ galaxy candidates, taken with the\nAtacama Large Millimeter\/Submillimeter Array (ALMA). By jackknifing the\nvisibilities using our tool, $jackknify$, we create observation-specific noise\nrealizations of the interferometric measurement set. We apply a line-finding\nalgorithm to both the noise cubes and the real data and determine the\nlikelihood that any given positive peak is a real signal by taking the ratio of\nthe two sampled probability distributions. We show that the previously\nreported, tentative emission-line detections of these $z>10$ galaxy candidates\nare consistent with noise. We further expand upon the technique and demonstrate\nhow to properly incorporate prior information on the redshift of the candidate\nfrom auxiliary data, such as from JWST. Our work highlights the need to achieve\na significance of $\\gtrsim 5\\sigma$ to confirm an emission line when searching\nin broad 30 GHz bandwidths. Using our publicly available method enables the\nquantification of false detection likelihoods, which are crucial for accurately\ninterpreting line detections."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-884",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18652"
    ],
    "b_title":[
      "Classical Information Exchange Between Particles"
    ],
    "b_abstract":[
      "The flow of information within many-body systems is a fundamental feature of\nphysical interaction. Given an underlying classical physics model for the\ninteraction between a particle and its environment, we give meaning to and\nquantify the information passed between them over time. We show that the\nmaximum information exchange rate is proportional to the ratio of\ninter-particle energy flow and initial particle energy -- a sort of\nsignal-to-noise ratio. In addition, a single time-point (as opposed to\ntrajectory) observability relation emerges."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.11271"
    ],
    "c_title":[
      "OctoTools: An Agentic Framework with Extensible Tools for Complex\n  Reasoning"
    ],
    "c_abstract":[
      "Solving complex reasoning tasks may involve visual understanding, domain\nknowledge retrieval, numerical calculation, and multi-step reasoning. Existing\nmethods augment large language models (LLMs) with external tools but are\nrestricted to specialized domains, limited tool types, or require additional\ntraining data. In this paper, we introduce OctoTools, a training-free,\nuser-friendly, and easily extensible open-source agentic framework designed to\ntackle complex reasoning across diverse domains. OctoTools introduces\nstandardized tool cards to encapsulate tool functionality, a planner for both\nhigh-level and low-level planning, and an executor to carry out tool usage. We\nvalidate OctoTools' generality across 16 diverse tasks (including MathVista,\nMMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains\nof 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions\nand LangChain by up to 10.6% when given the same set of tools. Through\ncomprehensive analysis and ablations, OctoTools demonstrates advantages in task\nplanning, effective tool usage, and multi-step problem solving."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-885",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03592"
    ],
    "b_title":[
      "Solar Panel Mapping via Oriented Object Detection"
    ],
    "b_abstract":[
      "Maintaining the integrity of solar power plants is a vital component in\ndealing with the current climate crisis. This process begins with analysts\ncreating a detailed map of a plant with the coordinates of every solar panel,\nmaking it possible to quickly locate and mitigate potential faulty solar\npanels. However, this task is extremely tedious and is not scalable for the\never increasing capacity of solar power across the globe. Therefore, we propose\nan end-to-end deep learning framework for detecting individual solar panels\nusing a rotated object detection architecture. We evaluate our approach on a\ndiverse dataset of solar power plants collected from across the United States\nand report a mAP score of 83.3%."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09576"
    ],
    "c_title":[
      "Interpolating chromatic and homomorphism thresholds"
    ],
    "c_abstract":[
      "The problem of chromatic thresholds seeks for minimum degree conditions that\nensure $H$-free graphs to have a bounded chromatic number, or equivalently a\nbounded size homomorphic image. The strengthened homomorphism thresholds\nproblem further requires that the homomorphic image itself is $H$-free. The\npurpose of this paper is two-fold. First, we define a generalized notion of\nthreshold which encapsulates and interpolates chromatic and homomorphism\nthresholds via the theory of VC-dimension. Our first result shows a smooth\ntransition between these two thresholds when varying the restrictions on\nhomomorphic images. In particular, we proved that for $t \\ge s \\ge 3$ and\n$\\epsilon>0$, if $G$ is an $n$-vertex $K_s$-free graph with VC-dimension $d$\nand $\\delta(G) \\ge (\\frac{(s-3)(t-s+2)+1}{(s-2)(t-s+2)+1} + \\epsilon)n$, then\n$G$ is homomorphic to a $K_t$-free graph $H$ with $|H| = O(1)$. Moreover, we\nconstruct graphs showing that this minimum degree condition is optimal. This\nextends and unifies the results of Thomassen, {\\L}uczak and Thomass\\'e, and\nGoddard, Lyle and Nikiforov, and provides a deeper insight into the cause of\nexistences of homomorphic images with various properties.\n  Second, we introduce the blowup threshold $\\delta_B(H)$ as the infimum\n$\\alpha$ such that every $n$-vertex maximal $H$-free graph $G$ with\n$\\delta(G)\\ge\\alpha n$ is a blowup of some $F$ with $|F|=O(1)$. This notion\nstrengthens homomorphism threshold. While the homomorphism thresholds for odd\ncycles remain unknown, we prove that $\\delta_B(C_{2k-1})=1\/(2k-1)$ for any\ninteger $k\\ge 2$. This strengthens the result of Ebsen and Schacht and answers\na question of Schacht and shows that, in sharp contrast to the chromatic\nthresholds, 0 is an accumulation point for blowup thresholds. Our proofs mix\ntools from VC-dimension theory and an iterative refining process, and draw\nconnection to a problem concerning codes on graphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-886",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.03087"
    ],
    "b_title":[
      "Propagation of chaos for multi-species moderately interacting particle\n  systems up to Newtonian singularity"
    ],
    "b_abstract":[
      "We derive a class of multi-species aggregation-diffusion systems from\nstochastic interacting particle systems via relative entropy method with\nquantitative bounds. We show an algebraic $L^1$-convergence result using\nmoderately interacting particle systems approximating attractive\/repulsive\nsingular potentials up to Newtonian\/Coulomb singularities without additional\ncut-off on the particle level. The first step is to make use of the relative\nentropy between the joint distribution of the particle system and an\napproximated limiting aggregation-diffusion system. A crucial argument in the\nproof is to show convergence in probability by a stopping time argument. The\nsecond step is to obtain a quantitative convergence rate to the limiting\naggregation-diffusion system from the approximated PDE system. This is shown by\nevaluating a combination of relative entropy and $L^2$-distance."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.16427"
    ],
    "c_title":[
      "On the Holographic Dual of a Symmetry Operator at Finite Temperature"
    ],
    "c_abstract":[
      "Topological symmetry operators of holographic large $N$ CFT$_D$'s are dual to\ndynamical branes in the gravity dual AdS$_{D+1}$. We use this correspondence to\nestablish a dictionary between thermal expectation values of symmetry operators\nin the Euclidean CFT$_D$ and the evaluation of gravitational saddles in the\npresence of a dynamical brane. Expectation values of $0$-form symmetry\noperators in the CFT$_D$ are then related to branes wrapped on volume\nminimizing cycles in the bulk, i.e., the Euclidean continuation of a black hole\nhorizon. We illustrate with some representative examples, including gravity in\nAdS$_3$, duality \/ triality defects in 4D $\\mathcal{N} = 4$ Super Yang-Mills\ntheory, and the dual of R-symmetry operators probing 5D BPS black holes."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-887",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05581"
    ],
    "b_title":[
      "Constraining the Scattered Light properties of LTT 9779 b Using HST\/WFC3\n  UVIS"
    ],
    "b_abstract":[
      "A planet's albedo is a fundamental property that sets its energy budget by\ndictating the fraction of incident radiation absorbed versus reflected back to\nspace. Generally, optical eclipse observations have revealed the majority of\nhot, giant planets to have low albedos, indicating dayside atmospheres\ndominated by absorption instead of reflection. However, there are several\nexceptions to this rule, including the ultra-hot-Neptune LTT 9779b, which have\nbeen found to have high geometric albedos. We observed four eclipses of LTT\n9779b with the G280 grism of the Hubble Space Telescope's WFC3 UVIS mode;\ntargeting the scattering signatures of the cloud condensate species causing the\nplanet's elevated reflectivity. However, we do not definitively detect the\nplanet's eclipse in our observations, with injection-recovery tests yielding a\n3-$\\sigma$ upper limit of 113 ppm on the eclipse depth of LTT 9779b in the\n0.2-0.8$\\mu$m waveband. We create reflectance spectrum grids for LTT 9779b's\ndayside using VIRGA\/PICASO and compare to our UVIS limit, as well as previously\npublished CHEOPS and TESS eclipse photometry. We find that silicate condensates\nare best able to explain LTT 9779b's highly-reflective dayside. Our forward\nmodel grids only enable weak constraints on vertical mixing efficiency, and\nsuggest that, regardless of their particular composition, the clouds are likely\ncomposed of smaller and more reflective particles. Our work facilitates a\ndeeper understanding of the reflectance properties of LTT 9779b as well as the\nUVIS spectroscopic mode itself, which will remain the community's primary\naccess to UV wavelengths until next-generation telescopes like the Habitable\nWorlds Observatory."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.14471"
    ],
    "c_title":[
      "Integrating Extra Modality Helps Segmentor Find Camouflaged Objects Well"
    ],
    "c_abstract":[
      "Camouflaged Object Segmentation (COS) remains a challenging problem due to\nthe subtle visual differences between camouflaged objects and backgrounds.\nOwing to the exceedingly limited visual cues available from visible spectrum,\nprevious RGB single-modality approaches often struggle to achieve satisfactory\nresults, prompting the exploration of multimodal data to enhance detection\naccuracy. In this work, we present UniCOS, a novel framework that effectively\nleverages diverse data modalities to improve segmentation performance. UniCOS\ncomprises two key components: a multimodal segmentor, UniSEG, and a cross-modal\nknowledge learning module, UniLearner. UniSEG employs a state space fusion\nmechanism to integrate cross-modal features within a unified state space,\nenhancing contextual understanding and improving robustness to integration of\nheterogeneous data. Additionally, it includes a fusion-feedback mechanism that\nfacilitate feature extraction. UniLearner exploits multimodal data unrelated to\nthe COS task to improve the segmentation ability of the COS models by\ngenerating pseudo-modal content and cross-modal semantic associations.\nExtensive experiments demonstrate that UniSEG outperforms existing Multimodal\nCOS (MCOS) segmentors, regardless of whether real or pseudo-multimodal COS data\nis available. Moreover, in scenarios where multimodal COS data is unavailable\nbut multimodal non-COS data is accessible, UniLearner effectively exploits\nthese data to enhance segmentation performance. Our code will be made publicly\navailable on \\href{https:\/\/github.com\/cnyvfang\/UniCOS}{GitHub}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-888",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11246"
    ],
    "b_title":[
      "MemeSense: An Adaptive In-Context Framework for Social Commonsense\n  Driven Meme Moderation"
    ],
    "b_abstract":[
      "Memes present unique moderation challenges due to their subtle, multimodal\ninterplay of images, text, and social context. Standard systems relying\npredominantly on explicit textual cues often overlook harmful content\ncamouflaged by irony, symbolism, or cultural references. To address this gap,\nwe introduce MemeSense, an adaptive in-context learning framework that fuses\nsocial commonsense reasoning with visually and semantically related reference\nexamples. By encoding crucial task information into a learnable cognitive shift\nvector, MemeSense effectively balances lexical, visual, and ethical\nconsiderations, enabling precise yet context-aware meme intervention. Extensive\nevaluations on a curated set of implicitly harmful memes demonstrate that\nMemeSense substantially outperforms strong baselines, paving the way for safer\nonline communities. Code and data available at:\nhttps:\/\/github.com\/sayantan11995\/MemeSense"
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10575"
    ],
    "c_title":[
      "Second harmonic generation in silicon nitride waveguides integrated with\n  MoS$_2$ monolayers: the importance of a full vectorial modeling"
    ],
    "c_abstract":[
      "Integrating 2D materials into on-chip photonic devices holds significant\npotential for nonlinear frequency conversion across various applications. The\nlack of inversion symmetry in monolayers of transition metal dichalcogenides\n(TMD), such as MoS$_2$ and WS$_2$, is particularly attractive for enabling\nnonlinear phenomena based on $\\chi^{(2)}$ in silicon photonic devices\nincorporated with these materials. Previous studies have demonstrated\nsecond-order nonlinearities in on-chip silicon-based devices integrated with\ntransition metal dichalcogenides (TMDs). However, they have largely overlooked\nthe nonlinear modal interaction that considers both the tensorial nature of the\nTMD's second-order susceptibility and the full vectorial nature of the\nelectromagnetic fields. In this work, we investigate second-harmonic generation\n(SHG) in silicon nitride (SiN) waveguides integrated with a monolayer of\nMoS$_2$. We experimentally observed an enhancement in second-harmonic\ngeneration (SHG) in MoS$_2$-loaded waveguides compared to those without the\nmonolayer. Notably, this enhancement occurred even when the primary electric\nfield component of the pump and\/or signal mode was orthogonal to the TMD plane,\nhighlighting co- and cross-polarized SHG interactions. This phenomenon cannot\nbe predicted by the traditionally used scalar models.In addition, we provide\nimportant guidelines for the design of MoS$_2$-loaded waveguides, taking into\naccount phase-matching, interaction length and the MoS$_2$ crystal orientation\nwith respect to the waveguide axis."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-889",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14716"
    ],
    "b_title":[
      "Functions and operators of the polyharmonic and polyanalytic Clifford\n  fine structures on the $S$-spectrum"
    ],
    "b_abstract":[
      "The spectral theory on the $S$-spectrum originated to give quaternionic\nquantum mechanics a precise mathematical foundation and as a spectral theory\nfor linear operators in vector analysis.\n  This theory has proven to be significantly more general than initially\nanticipated, naturally extending to fully Clifford operators and revealing\nunexpected connections with the spectral theory based on the monogenic\nspectrum, developed over forty years ago by A. McIntosh and collaborators.\n  In recent years, we have combined slice hyperholomorphic functions with the\nFueter-Sce mapping theorem, also called Fueter-Sce extension theorem, to\nbroaden the class of functions and operators to which the theory can be\napplied. This generalization has led to the definition of what we call the {\\em\nfine structures on the $S$-spectrum}, consisting of classes of functions that\nadmit an integral representation and their associated functional calculi.\n  In this paper, we focus on the fine structures within the Clifford algebra\nsetting, particularly addressing polyharmonic functions, polyanalytic\nfunctions, holomorphic Cliffordian functions and their associated functional\ncalculi defined via integral representation formulas.\n  Moreover, we demonstrate that the monogenic functional calculus, defined via\nthe monogenic Cauchy formula, and the $F$-functional calculus of the fine\nstructures, defined via the Fueter-Sce mapping theorem in integral form, yield\nthe same operator."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.01748"
    ],
    "c_title":[
      "Fast Expectation Value Calculation Speedup of Quantum Approximate\n  Optimization Algorithm: HoLCUs QAOA"
    ],
    "c_abstract":[
      "In this paper, we present a new method for calculating expectation values of\noperators that can be expressed as a linear combination of unitary (LCU)\noperators. This method allows to perform this calculation in a single quantum\ncircuit measuring a single qubit, which speeds up the computation process. This\nmethod is general for any quantum algorithm and is of particular interest in\nthe acceleration of variational quantum algorithms, both in real devices and in\nsimulations. We analyze its application to the parameter optimization process\nof the Quantum Approximate Optimization Algorithm (QAOA) and the case of having\ndegenerate values in the matrix of the Ising problem. Finally, we apply it to\nseveral Quadratic Unconstrained Binary Optimization (QUBO) problems to analyze\nthe speedup of the method in circuit simulators."
    ],
    "c_categories":[
      [
        "cs.ET",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-890",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12349"
    ],
    "b_title":[
      "General Field Evaluation in High-Order Meshes on GPUs"
    ],
    "b_abstract":[
      "Robust and scalable function evaluation at any arbitrary point in the\nfinite\/spectral element mesh is required for querying the partial differential\nequation solution at points of interest, comparison of solution between\ndifferent meshes, and Lagrangian particle tracking. This is a challenging\nproblem, particularly for high-order unstructured meshes partitioned in\nparallel with MPI, as it requires identifying the element that overlaps a given\npoint and computing the corresponding reference space coordinates. We present a\nrobust and efficient technique for general field evaluation in large-scale\nhigh-order meshes with quadrilaterals and hexahedra. In the proposed method, a\ncombination of globally partitioned and processor-local maps are used to first\ndetermine a list of candidate MPI ranks, and then locally candidate elements\nthat could contain a given point. Next, element-wise bounding boxes further\nreduce the list of candidate elements. Finally, Newton's method with trust\nregion is used to determine the overlapping element and corresponding reference\nspace coordinates. Since GPU-based architectures have become popular for\naccelerating computational analyses using meshes with tensor-product elements,\nspecialized kernels have been developed to utilize the proposed methodology on\nGPUs. The method is also extended to enable general field evaluation on surface\nmeshes. The paper concludes by demonstrating the use of proposed method in\nvarious applications ranging from mesh-to-mesh transfer during r-adaptivity to\nLagrangian particle tracking."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.MS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20893"
    ],
    "c_title":[
      "Constraining Anisotropic Universe Through Big Bang Nucleosynthesis: A\n  Case Study of The Bianchi Type-I Universe"
    ],
    "c_abstract":[
      "The isotropy and homogeneity of our Universe are the cardinal principles of\nmodern cosmology built on the definition of metric through the prescription by\nFriedmann-Lema$\\hat{i}$tre-Robertson-Walker (FLRW). From the aspects of\ngeometry, the presence of anisotropy, inhomogeneity, or both are allowed in the\nmetrics defined as the Bianchi type I and V metrics. In this letter, the Big\nBang Nucleosynthesis (BBN) formalism, and the latest observational constraints\non nuclear abundances are being used to put bounds on the global anisotropy\noffered in the Bianchi type I metrics, providing a new path to explore in the\nbackground of global anisotropy."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-891",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14308"
    ],
    "b_title":[
      "A novel method for quantifying enzyme immobilization in porous carriers\n  using simple NMR relaxometry"
    ],
    "b_abstract":[
      "Enzyme immobilization plays a crucial role in enhancing the stability and\nrecyclability of enzymes for industrial applications. However, traditional\nmethods for quantifying enzyme loading within porous carriers are limited by\ntime-consuming workflows, cumulative errors, and the inability to probe enzymes\nadsorbed inside the pores. In this study, we introduce Time-Domain Nuclear\nMagnetic Resonance (TD-NMR) relaxometry as a novel, non-invasive technique for\ndirectly quantifying enzyme adsorption within porous carriers. Focusing on\nepoxy methyl acrylate carriers, commonly used in biocatalysis, we correlate\nchanges in T2 relaxation times with enzyme concentration, leading to the\ndevelopment of an NMR-based pore-filling ratio that quantifies enzyme loading.\nValidation experiments demonstrate that TD-NMR-derived adsorption curves align\nclosely with traditional photometric measurements, offering a reliable and\nreproducible alternative for enzyme quantification. The accessibility of\ntabletop TD-NMR spectrometers makes this technique a practical and\ncost-effective tool for optimizing biocatalytic processes. Furthermore, the\nmethod holds promise for real-time monitoring of adsorption dynamics and could\nbe adapted for a wider range of carrier materials and enzymes."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.20311"
    ],
    "c_title":[
      "Adapting Automatic Speech Recognition for Accented Air Traffic Control\n  Communications"
    ],
    "c_abstract":[
      "Effective communication in Air Traffic Control (ATC) is critical to\nmaintaining aviation safety, yet the challenges posed by accented English\nremain largely unaddressed in Automatic Speech Recognition (ASR) systems.\nExisting models struggle with transcription accuracy for Southeast\nAsian-accented (SEA-accented) speech, particularly in noisy ATC environments.\nThis study presents the development of ASR models fine-tuned specifically for\nSoutheast Asian accents using a newly created dataset. Our research achieves\nsignificant improvements, achieving a Word Error Rate (WER) of 0.0982 or 9.82%\non SEA-accented ATC speech. Additionally, the paper highlights the importance\nof region-specific datasets and accent-focused training, offering a pathway for\ndeploying ASR systems in resource-constrained military operations. The findings\nemphasize the need for noise-robust training techniques and region-specific\ndatasets to improve transcription accuracy for non-Western accents in ATC\ncommunications."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-892",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08945"
    ],
    "b_title":[
      "COADVISE: Covariate Adjustment with Variable Selection in Randomized\n  Controlled Trials"
    ],
    "b_abstract":[
      "Adjusting for covariates in randomized controlled trials can enhance the\ncredibility and efficiency of treatment effect estimation. However, handling\nnumerous covariates and their complex (non-linear) transformations poses a\nchallenge. Motivated by the case study of the Best Apnea Interventions for\nResearch (BestAIR) trial data from the National Sleep Research Resource (NSRR),\nwhere the number of covariates (p=114) is comparable to the sample size\n(N=196), we propose a principled Covariate Adjustment with Variable Selection\n(COADVISE) framework. COADVISE enables variable selection for covariates most\nrelevant to the outcome while accommodating both linear and nonlinear\nadjustments. This framework ensures consistent estimates with improved\nefficiency over unadjusted estimators and provides robust variance estimation,\neven under outcome model misspecification. We demonstrate efficiency gains\nthrough theoretical analysis, extensive simulations, and a re-analysis of the\nBestAIR trial data to compare alternative variable selection strategies,\noffering cautionary recommendations. A user-friendly R package, Coadvise, is\navailable to facilitate practical implementation."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.11338"
    ],
    "c_title":[
      "Driver Behavior Soft-Sensor Based on Neurofuzzy Systems and Weighted\n  Projection on Principal Components"
    ],
    "c_abstract":[
      "This work has as main objective the development of a soft-sensor to classify,\nin real time, the behaviors of drivers when they are at the controls of a\nvehicle. Efficient classification of drivers' behavior while driving, using\nonly the measurements of the sensors already incorporated in the vehicles and\nwithout the need to add extra hardware (smart phones, cameras, etc.), is a\nchallenge. The main advantage of using only the data center signals of modern\nvehicles is economical. The classification of the driving behavior and the\nwarning to the driver of dangerous behaviors without the need to add extra\nhardware (and their software) to the vehicle, would allow the direct\nintegration of these classifiers into the current vehicles without incurring a\ngreater cost in the manufacture of the vehicles and therefore be an added\nvalue. In this work, the classification is obtained based only on speed,\nacceleration and inertial measurements which are already present in many modern\nvehicles. The proposed algorithm is based on a structure made by several\nNeurofuzzy systems with the combination of projected data in components of\nvarious Principal Component Analysis. A comparison with several types of\nclassical classifying algorithms has been made."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-893",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18250"
    ],
    "b_title":[
      "Dynamic Model Fine-Tuning For Extreme MIMO CSI Compression"
    ],
    "b_abstract":[
      "Efficient channel state information (CSI) compression is crucial in frequency\ndivision duplexing (FDD) massive multiple-input multiple-output (MIMO) systems\ndue to excessive feedback overhead. Recently, deep learning-based compression\ntechniques have demonstrated superior performance across various data types,\nincluding CSI. However, these approaches often experience performance\ndegradation when the data distribution changes due to their limited\ngeneralization capabilities. To address this challenge, we propose a model\nfine-tuning approach for CSI feedback in massive MIMO systems. The idea is to\nfine-tune the encoder\/decoder network models in a dynamic fashion using the\nrecent CSI samples. First, we explore encoder-only fine-tuning, where only the\nencoder parameters are updated, leaving the decoder and latent parameters\nunchanged. Next, we consider full-model fine-tuning, where the encoder and\ndecoder models are jointly updated. Unlike encoder-only fine-tuning, full-model\nfine-tuning requires the updated decoder and latent parameters to be\ntransmitted to the decoder side. To efficiently handle this, we propose\ndifferent prior distributions for model updates, such as uniform and truncated\nGaussian to entropy code them together with the compressed CSI and account for\nadditional feedback overhead imposed by conveying the model updates. Moreover,\nwe incorporate quantized model updates during fine-tuning to reflect the impact\nof quantization in the deployment phase. Our results demonstrate that\nfull-model fine-tuning significantly enhances the rate-distortion (RD)\nperformance of neural CSI compression. Furthermore, we analyze how often the\nfull-model fine-tuning should be applied in a new wireless environment and\nidentify an optimal period interval for achieving the best RD trade-off."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.10610"
    ],
    "c_title":[
      "Searching for strong lensing by late-type galaxies in UNIONS"
    ],
    "c_abstract":[
      "Recent wide-field galaxy surveys have led to an explosion in numbers of\ngalaxy-scale strong gravitational lens candidates. However, the vast majority\nfeature massive luminous red galaxies as the main deflectors, with late-type\ngalaxies being vastly under-represented. This work presents a dedicated search\nfor lensing by edge-on late-type galaxies in the Ultraviolet Near Infrared\nOptical Northern Survey (UNIONS). The search covers $3600$ deg$^2$ of $r$-band\nobservations taken from the Canada-France-Hawaii Telescope. We consider all\nsources with magnitudes in the range $17 < r < 20.5$, without any colour\npreselection, yielding a parent sample of seven million sources. We\ncharacterise our parent sample via the visual inspection of $120\\,000$ sources\nselected at random. From it, we estimate, with a 68\\% confidence interval, that\n1 in every $30\\,000$ sources is an edge-on lens candidate, with at least eight\nhigh-quality candidates in the parent sample. This corresponds to 1 candidate\nper $17\\,000$ edge-on late-type galaxies. Our search relies on a convolutional\nneural network (CNN) to select a reduced sample of candidates, followed by a\nvisual inspection to curate the final sample. The CNN is trained from scratch\nusing simulated $r$-band observations of edge-on lenses, and real observations\nof non-lenses. We find 61 good edge-on lens candidates using the CNN. Moreover,\ncombining the CNN candidates with those found serendipitously, and those\nidentified while characterising the parent sample, we discovered 4 grade A, 20\ngrade B, and 58 grade C edge-on lens candidates; effectively doubling the known\nsample of these systems. We also discovered 16 grade A, 16 grade B, and 18\ngrade C lens candidates of other types. Finally, based on the characterisation\nof the parent sample, we estimate that our search found around 60\\% of the\nbright grade A and B edge-on lens candidates within the parent sample."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-894",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10930"
    ],
    "b_title":[
      "Reduced Order Modeling with Shallow Recurrent Decoder Networks"
    ],
    "b_abstract":[
      "Reduced Order Modeling is of paramount importance for efficiently inferring\nhigh-dimensional spatio-temporal fields in parametric contexts, enabling\ncomputationally tractable parametric analyses, uncertainty quantification and\ncontrol. However, conventional dimensionality reduction techniques are\ntypically limited to known and constant parameters, inefficient for nonlinear\nand chaotic dynamics, and uninformed to the actual system behavior. In this\nwork, we propose sensor-driven SHallow REcurrent Decoder networks for Reduced\nOrder Modeling (SHRED-ROM). Specifically, we consider the composition of a long\nshort-term memory network, which encodes the temporal dynamics of limited\nsensor data in multiple scenarios, and a shallow decoder, which reconstructs\nthe corresponding high-dimensional states. SHRED-ROM is a robust decoding-only\nstrategy that circumvents the numerically unstable approximation of an inverse\nwhich is required by encoding-decoding schemes. To enhance computational\nefficiency and memory usage, the full-order state snapshots are reduced by,\ne.g., proper orthogonal decomposition, allowing for compressive training of the\nnetworks with minimal hyperparameter tuning. Through applications on chaotic\nand nonlinear fluid dynamics, we show that SHRED-ROM (i) accurately\nreconstructs the state dynamics for new parameter values starting from limited\nfixed or mobile sensors, independently on sensor placement, (ii) can cope with\nboth physical, geometrical and time-dependent parametric dependencies, while\nbeing agnostic to their actual values, (iii) can accurately estimate unknown\nparameters, and (iv) can deal with different data sources, such as\nhigh-fidelity simulations, coupled fields and videos."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.13595"
    ],
    "c_title":[
      "Is there a tilt in the fundamental (hyper)plane?"
    ],
    "c_abstract":[
      "We investigate the fundamental plane (FP) of selected early-type (ETG) member\ngalaxies of the galaxy cluster PLCK G287.0+32.9 ($ z_c = 0.3833 $), exploring\nalso four-dimensional hyperplane extensions. We measure ETGs structural\nparameters and photometry from Hubble Space Telescope (HST) observations. We\nuse high-quality spectroscopic data from the Multi Unit Spectroscopic Explorer\n(MUSE) to measure the galaxy central stellar velocity dispersions and stellar\npopulation properties. With this data, we construct the FP through a robust\nfitting procedure and analyze its tilt and scatter. We then introduce two\nhyperplane extensions, one including the stellar mass ($M^\\star$-HP) and\nanother including the stellar over total mass fraction\n($f_{\\mathrm{e}}^\\star$-HP), and compare their coefficients and scatter to\nthose of the FP. The FP of PLCK G287.0+32.9 is found to have best-fit parameter\nvalues consistent with those in the literature ($\\alpha = 1.2 \\pm 0.1$ and\n$\\beta = -0.75 \\pm 0.05$), with a scatter of $0.09$ dex. The\n($f_{\\mathrm{e}}^\\star$-HP) shows no tilt compared to the theoretical plane\n($\\alpha = 2.1 \\pm 0.2$ and $\\beta = -1.12 \\pm 0.07$), with a scatter of\n$0.042$ dex, and the ($M^\\star$-HP) reveals an even tighter relation, with a\nscatter of only $0.023$. Our findings support the idea that the FP is a\nlower-dimensional projection of a more complex hyperplane and confirm that the\nvariations in the dark matter content contribute significantly to the tilt of\nthe FP. Future studies incorporating larger samples of galaxies and additional\nphysical parameters may further refine our understanding of the FP and its\nhigher-dimensional extensions."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-895",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03070"
    ],
    "b_title":[
      "The bilinear Hessian for large scale optimization"
    ],
    "b_abstract":[
      "Second order information is useful in many ways in smooth optimization\nproblems, including for the design of step size rules and descent directions,\nor the analysis of the local properties of the objective functional. However,\nthe computation and storage of the Hessian matrix using second order partial\nderivatives is prohibitive in many contexts, and in particular in large scale\nproblems. In this work, we propose a new framework for computing and presenting\nsecond order information in analytic form. The key novel insight is that the\nHessian for a problem can be worked with efficiently by computing its bilinear\nform or operator form using Taylor expansions, instead of introducing a basis\nand then computing the Hessian matrix. Our new framework is suited for\nhigh-dimensional problems stemming e.g. from imaging applications, where\ncomputation of the Hessian matrix is unfeasible. We also show how this can be\nused to implement Newton's step rule, Daniel's Conjugate Gradient rule, or\nQuasi-Newton schemes, without explicit knowledge of the Hessian matrix, and\nillustrate our findings with a simple numerical experiment."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19075"
    ],
    "c_title":[
      "Incomplete Information Robustness"
    ],
    "c_abstract":[
      "Consider an analyst who models a strategic situation using an incomplete\ninformation game. The true game may involve correlated, duplicated belief\nhierarchies, but the analyst lacks knowledge of the correlation structure and\ncan only approximate each belief hierarchy. To make predictions in this\nsetting, the analyst uses belief-invariant Bayes correlated equilibria (BIBCE)\nand seeks to determine which one is justifiable. We address this question by\nintroducing the notion of robustness: a BIBCE is robust if, for every nearby\nincomplete information game, there exists a BIBCE close to it. Our main result\nprovides a sufficient condition for robustness using a generalized potential\nfunction. In a supermodular potential game, a robust BIBCE is a Bayes Nash\nequilibrium, whereas this need not hold in other classes of games."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-896",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.16318"
    ],
    "b_title":[
      "Direct Numerical Simulation of Hydrogen Combustion in a Real-Size IC\n  Engine"
    ],
    "b_abstract":[
      "This study presents the first Direct Numerical Simulation (DNS) of hydrogen\ncombustion in a real-size internal combustion engine, investigating the complex\ndynamics of ignition, flame propagation, and flame-wall interaction under\nengine-relevant conditions. The simulation focuses on ultra-lean hydrogen\noperation at equivalence ratio $\\phi=0.4$ and 800 rpm, utilizing a\nstate-of-the-art spectral element solver optimized for GPU architectures. The\ncomputational domain encompasses the full engine geometry. Results highlight\nthe strong coupling between the flame dynamics and the coherent flow structures\nduring early flame kernel development, while differential diffusion effects\nlead to increased reactivity at positive flame curvatures, a phenomenon that\nhas only been studied in canonical configurations of freely propagating\nhydrogen\/air flames. As the flame approaches the walls, distinct behavior is\nobserved during head-on and side-wall quenching scenarios, characterized by\ndifferent spatial distributions of wall heat flux. The findings provide\ninsights into hydrogen combustion in real engines, essential for the\ndevelopment of clean and efficient hydrogen-fueled powertrains."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.05623"
    ],
    "c_title":[
      "Limits of specifiability for sensor-based robotic planning tasks"
    ],
    "c_abstract":[
      "There is now a large body of techniques, many based on formal methods, for\ndescribing and realizing complex robotics tasks, including those involving a\nvariety of rich goals and time-extended behavior. This paper explores the\nlimits of what sorts of tasks are specifiable, examining how the precise\ngrounding of specifications, that is, whether the specification is given in\nterms of the robot's states, its actions and observations, its knowledge, or\nsome other information,is crucial to whether a given task can be specified.\nWhile prior work included some description of particular choices for this\ngrounding, our contribution treats this aspect as a first-class citizen: we\nintroduce notation to deal with a large class of problems, and examine how the\ngrounding affects what tasks can be posed. The results demonstrate that certain\nclasses of tasks are specifiable under different combinations of groundings."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-897",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19770"
    ],
    "b_title":[
      "TAPE: Tailored Posterior Difference for Auditing of Machine Unlearning"
    ],
    "b_abstract":[
      "With the increasing prevalence of Web-based platforms handling vast amounts\nof user data, machine unlearning has emerged as a crucial mechanism to uphold\nusers' right to be forgotten, enabling individuals to request the removal of\ntheir specified data from trained models. However, the auditing of machine\nunlearning processes remains significantly underexplored. Although some\nexisting methods offer unlearning auditing by leveraging backdoors, these\nbackdoor-based approaches are inefficient and impractical, as they necessitate\ninvolvement in the initial model training process to embed the backdoors. In\nthis paper, we propose a TAilored Posterior diffErence (TAPE) method to provide\nunlearning auditing independently of original model training. We observe that\nthe process of machine unlearning inherently introduces changes in the model,\nwhich contains information related to the erased data. TAPE leverages\nunlearning model differences to assess how much information has been removed\nthrough the unlearning operation. Firstly, TAPE mimics the unlearned posterior\ndifferences by quickly building unlearned shadow models based on first-order\ninfluence estimation. Secondly, we train a Reconstructor model to extract and\nevaluate the private information of the unlearned posterior differences to\naudit unlearning. Existing privacy reconstructing methods based on posterior\ndifferences are only feasible for model updates of a single sample. To enable\nthe reconstruction effective for multi-sample unlearning requests, we propose\ntwo strategies, unlearned data perturbation and unlearned influence-based\ndivision, to augment the posterior difference. Extensive experimental results\nindicate the significant superiority of TAPE over the state-of-the-art\nunlearning verification methods, at least 4.5$\\times$ efficiency speedup and\nsupporting the auditing for broader unlearning scenarios."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20923"
    ],
    "c_title":[
      "Spinning boson stars in nonlinear sigma models and Universal Relations"
    ],
    "c_abstract":[
      "Boson stars are hypothetical compact objects derived from solutions of a\nself-gravitating complex scalar field. In this study, we extend the traditional\nmodels by generalizing the kinetic term of the scalar field to that of a\nnonlinear sigma model. Concretely, we obtain spinning boson star solutions for\na family of models parametrized by the curvature of their two-dimensional\ntarget manifold, as well as for various self-interaction potentials. We derive\nthe global properties and multipolar structure of these solutions as a function\nof both the curvature of the target space and the strength of\nself-interactions. Our results suggest that a nonzero curvature in the target\nmanifold can have a significant impact on the structure of the solutions,\nallowing for a range of notably different masses and degrees of compactness.\nHowever, we find that the relations between different multipoles are consistent\nwith those for the standard complex scalar stars, and hence the universality of\nsuch relations is extended to curved target spaces."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-898",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06274"
    ],
    "b_title":[
      "HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational\n  Pharmacovigilance"
    ],
    "b_abstract":[
      "Drug-side effect research is vital for understanding adverse reactions\narising in complex multi-drug therapies. However, the scarcity of higher-order\ndatasets that capture the combinatorial effects of multiple drugs severely\nlimits progress in this field. Existing resources such as TWOSIDES primarily\nfocus on pairwise interactions. To fill this critical gap, we introduce HODDI,\nthe first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S.\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\nrecords spanning the past decade, to advance computational pharmacovigilance.\nHODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique\nside effects, specifically curated to capture multi-drug interactions and their\ncollective impact on adverse effects. Comprehensive statistical analyses\ndemonstrate HODDI's extensive coverage and robust analytical metrics, making it\na valuable resource for studying higher-order drug relationships. Evaluating\nHODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP)\ncan outperform graph models, while hypergraph models demonstrate superior\nperformance in capturing complex multi-drug interactions, further validating\nHODDI's effectiveness. Our findings highlight the inherent value of\nhigher-order information in drug-side effect prediction and position HODDI as a\nbenchmark dataset for advancing research in pharmacovigilance, drug safety, and\npersonalized medicine. The dataset and codes are available at\nhttps:\/\/github.com\/TIML-Group\/HODDI."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02610"
    ],
    "c_title":[
      "Primordial Black Hole stellar microlensing constraints: understanding\n  their dependence on the density and velocity distributions"
    ],
    "c_abstract":[
      "Microlensing surveys of stars in the Large Magellanic Cloud constrain the\nfraction of the Milky Way halo in Primordial Black Holes (PBHs) with mass\n$10^{-9} \\lesssim M\/M_{\\odot} \\lesssim 10^{4}$. Various studies have reached\ndifferent conclusions on the uncertainties in these constraints due to\nuncertainties in the Dark Matter (DM) distribution. We therefore revisit the\ndependence of the microlensing differential event rate, and hence exclusion\nlimits, on the DM density and velocity distributions. The constraints on the\nabundance of low- and high-mass PBHs depend, respectively, on the long- and\nshort-duration tails of the differential event rate distribution. Long-duration\nevents are due to PBHs moving close to the line of sight and their rate (and\nhence the constraints on low-mass PBHs) has a fairly weak ($\\sim 10\\%$)\ndependence on the DM density and velocity distributions. Short-duration events\nare due to PBHs close to the observer and their rate (and hence the constraints\non moderate- and high-mass PBHs) depends much more strongly on the DM velocity\ndistribution. An accurate calculation of the local DM velocity distribution is\ntherefore crucial for accurately calculating PBH stellar microlensing\nconstraints."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-899",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03828"
    ],
    "b_title":[
      "Observation of $D^+\\to \\bar K_1(1270)^0\\mu^+\\nu_\\mu$ and $D^0\\to\n  K_1(1270)^-\\mu^+\\nu_\\mu$"
    ],
    "b_abstract":[
      "By analyzing 7.93 $\\rm fb^{-1}$ of $e^+e^-$ collision data collected at the\ncenter-of-mass energy of 3.773 GeV with the BESIII detector operated at the\nBEPCII collider, we report the observation of the semimuonic decays of $D^+\\to\n\\bar K_1(1270)^0\\mu^+\\nu_\\mu$ and $D^0\\to K_1(1270)^-\\mu^+\\nu_\\mu$ with\nstatistical significances of $12.5\\sigma$ and $6.0\\sigma$, respectively. Their\ndecay branching fractions are determined to be ${\\mathcal B}[D^{+}\\to\n\\bar{K}_1(1270)^0 \\mu^{+}\\nu_{\\mu}]=(2.36\\pm0.20^{+0.18}_{-0.27}\\pm\n0.48)\\times10^{-3}$ and ${\\mathcal B}[D^{0}\\to K_1(1270)^{-}\n\\mu^{+}\\nu_{\\mu}]=(0.78\\pm0.11^{+0.05}_{-0.09}\\pm 0.15)\\times10^{-3}$, where\nthe first and second uncertainties are statistical and systematic,\nrespectively, and the third originates from the input branching fraction of\n$\\bar K_{1}(1270)^0\\to K^- \\pi^+\\pi^0$ or $K_1(1270)^-\\to K^-\\pi^+\\pi^-$.\nCombining our branching fractions with the previous measurements of ${\\mathcal\nB}[D^+\\to \\bar K_1(1270)^0e^+\\nu_{e}]$ and ${\\mathcal B}[D^0\\to\nK_1(1270)^-e^+\\nu_{e}]$, we determine the branching fraction ratios to be\n${\\mathcal B}[D^+\\to \\bar K_1(1270)^0\\mu^+\\nu_{\\mu}]\/{\\mathcal B}[D^+\\to \\bar\nK_1(1270)^0e^+\\nu_{e}]=1.03 \\pm 0.14 \\substack{+0.11\\\\-0.15}$ and ${\\mathcal\nB}[D^0\\to K_1(1270)^-\\mu^+\\nu_{\\mu}]\/{\\mathcal B}[D^0\\to\nK_1(1270)^-e^+\\nu_{e}]=0.74\\pm 0.13 \\substack{+0.08\\\\-0.13}$. Using the\nbranching fractions measured in this work and the world-average lifetimes of\nthe $D^+$ and $D^0$ mesons, we determine the semimuonic partial decay width\nratio to be $\\Gamma [D^+\\to \\bar K_1(1270)^0 \\mu^+\\nu_\\mu]\/\\Gamma [D^0\\to\nK_1(1270)^- \\mu^+\\nu_\\mu]=1.22\\pm 0.10\\substack{+0.06\\\\-0.09}$, which is\nconsistent with unity as predicted by isospin conservation."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.10527"
    ],
    "c_title":[
      "How Should We Evaluate Uncertainty in Accelerated MRI Reconstruction?"
    ],
    "c_abstract":[
      "Reconstructing accelerated MRI is an ill-posed problem. Machine learning has\nrecently shown great promise at this task, but current approaches to\nquantifying uncertainty focus on measuring the variability in pixelwise\nintensity variation. Although these provide interpretable maps, they lack\nstructural understanding and they do not have a clear relationship to how the\ndata will be analysed subsequently. In this paper, we propose a new approach to\nevaluating reconstruction variability based on apparent anatomical changes in\nthe reconstruction, which is more tightly related to common downstream tasks.\nWe use image registration and segmentation to evaluate several common MRI\nreconstruction approaches, where uncertainty is measured via ensembling, for\naccelerated imaging. We demonstrate the intrinsic variability in reconstructed\nimages and show that models with high scores on often used quality metrics such\nas SSIM and PSNR, can nonetheless display high levels of variance and bias in\nanatomical measures."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV",
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-900",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04201"
    ],
    "b_title":[
      "Nonreciprocal ballistic transport in multi-layer Weyl Semimetal films\n  with surface engineering"
    ],
    "b_abstract":[
      "Weyl semimetal (WSM) thin films possess unique electronic properties that\ndiffer from bulk materials. In this article, we study the nonreciprocal\nballistic transport of the WSM thin films caused by surface modification. We\nfind that the surface states contribute predominantly to the nonreciprocity,\nwhile the bulk states provide a negative correction. Our calculation shows a\nkind of quantum size effect that the nonreciprocal signal decreases as the WSM\nfilm becomes thicker, and diverges when the Fermi energy is near the bottom of\na sub-band. On the other hand, it is found that the density of states in\nmulti-layer systems possesses some properties roughly independent of thickness.\nA single-variable theory is developed to explain it"
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.11197"
    ],
    "c_title":[
      "Q-RESTORE: Quantum-Driven Framework for Resilient and Equitable\n  Transportation Network Restoration"
    ],
    "c_abstract":[
      "Efficient and socially equitable restoration of transportation networks post\ndisasters is crucial for community resilience and access to essential services.\nThe ability to rapidly recover critical infrastructure can significantly\nmitigate the impacts of disasters, particularly in underserved communities\nwhere prolonged isolation exacerbates vulnerabilities. Traditional restoration\nmethods prioritize functionality over computational efficiency and equity,\nleaving low-income communities at a disadvantage during recovery. To address\nthis gap, this research introduces a novel framework that combines quantum\ncomputing technology with an equity-focused approach to network restoration.\nOptimization of road link recovery within budget constraints is achieved by\nleveraging D Wave's hybrid quantum solver, which targets the connectivity needs\nof low, average, and high income communities. This framework combines\ncomputational speed with equity, ensuring priority support for underserved\npopulations. Findings demonstrate that this hybrid quantum solver achieves near\ninstantaneous computation times of approximately 8.7 seconds across various\nbudget scenarios, significantly outperforming the widely used genetic\nalgorithm. It offers targeted restoration by first aiding low-income\ncommunities and expanding aid as budgets increase, aligning with equity goals.\nThis work showcases quantum computing's potential in disaster recovery\nplanning, providing a rapid and equitable solution that elevates urban\nresilience and social sustainability by aiding vulnerable populations in\ndisasters."
    ],
    "c_categories":[
      [
        "cs.ET",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-901",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12330"
    ],
    "b_title":[
      "The Gap Between Principle and Practice of Lossy Image Coding"
    ],
    "b_abstract":[
      "Lossy image coding is the art of computing that is principally bounded by the\nimage's rate-distortion function. This bound, though never accurately\ncharacterized, has been approached practically via deep learning technologies\nin recent years. Indeed, learned image coding schemes allow direct optimization\nof the joint rate-distortion cost, thereby outperforming the handcrafted image\ncoding schemes by a large margin. Still, it is observed that there is room for\nfurther improvement in the rate-distortion performance of learned image coding.\nIn this article, we identify the gap between the ideal rate-distortion function\nforecasted by Shannon's information theory and the empirical rate-distortion\nfunction achieved by the state-of-the-art learned image coding schemes,\nrevealing that the gap is incurred by five different effects: modeling effect,\napproximation effect, amortization effect, digitization effect, and asymptotic\neffect. We design simulations and experiments to quantitively evaluate the last\nthree effects, which demonstrates the high potential of future lossy image\ncoding technologies."
    ],
    "b_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.17406"
    ],
    "c_title":[
      "IRef-VLA: A Benchmark for Interactive Referential Grounding with\n  Imperfect Language in 3D Scenes"
    ],
    "c_abstract":[
      "With the recent rise of large language models, vision-language models, and\nother general foundation models, there is growing potential for multimodal,\nmulti-task robotics that can operate in diverse environments given natural\nlanguage input. One such application is indoor navigation using natural\nlanguage instructions. However, despite recent progress, this problem remains\nchallenging due to the 3D spatial reasoning and semantic understanding\nrequired. Additionally, the language used may be imperfect or misaligned with\nthe scene, further complicating the task. To address this challenge, we curate\na benchmark dataset, IRef-VLA, for Interactive Referential Vision and\nLanguage-guided Action in 3D Scenes with imperfect references. IRef-VLA is the\nlargest real-world dataset for the referential grounding task, consisting of\nover 11.5K scanned 3D rooms from existing datasets, 7.6M heuristically\ngenerated semantic relations, and 4.7M referential statements. Our dataset also\ncontains semantic object and room annotations, scene graphs, navigable free\nspace annotations, and is augmented with statements where the language has\nimperfections or ambiguities. We verify the generalizability of our dataset by\nevaluating with state-of-the-art models to obtain a performance baseline and\nalso develop a graph-search baseline to demonstrate the performance bound and\ngeneration of alternatives using scene-graph knowledge. With this benchmark, we\naim to provide a resource for 3D scene understanding that aids the development\nof robust, interactive navigation systems. The dataset and all source code is\npublicly released at https:\/\/github.com\/HaochenZ11\/IRef-VLA."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-902",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04271"
    ],
    "b_title":[
      "On Fact and Frequency: LLM Responses to Misinformation Expressed with\n  Uncertainty"
    ],
    "b_abstract":[
      "We study LLM judgments of misinformation expressed with uncertainty. Our\nexperiments study the response of three widely used LLMs (GPT-4o, LlaMA3,\nDeepSeek-v2) to misinformation propositions that have been verified false and\nthen are transformed into uncertain statements according to an uncertainty\ntypology. Our results show that after transformation, LLMs change their\nfactchecking classification from false to not-false in 25% of the cases.\nAnalysis reveals that the change cannot be explained by predictors to which\nhumans are expected to be sensitive, i.e., modality, linguistic cues, or\nargumentation strategy. The exception is doxastic transformations, which use\nlinguistic cue phrases such as \"It is believed ...\".To gain further insight, we\nprompt the LLM to make another judgment about the transformed misinformation\nstatements that is not related to truth value. Specifically, we study LLM\nestimates of the frequency with which people make the uncertain statement. We\nfind a small but significant correlation between judgment of fact and\nestimation of frequency."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16382"
    ],
    "c_title":[
      "GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale\n  Protein-protein Interaction Exploration"
    ],
    "c_abstract":[
      "Drug discovery (DD) has tremendously contributed to maintaining and improving\npublic health. Hypothesizing that inhibiting protein misfolding can slow\ndisease progression, researchers focus on target identification (Target ID) to\nfind protein structures for drug binding. While Large Language Models (LLMs)\nand Retrieval-Augmented Generation (RAG) frameworks have accelerated drug\ndiscovery, integrating models into cohesive workflows remains challenging. We\nconducted a user study with drug discovery researchers to identify the\napplicability of LLMs and RAGs in Target ID. We identified two main findings:\n1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on\nan initial protein and protein candidates that have a therapeutic impact; 2)\nthe model must provide the PPI and relevant explanations for better\nunderstanding. Based on these observations, we identified three limitations in\nprevious approaches for Target ID: 1) semantic ambiguity, 2) lack of\nexplainability, and 3) short retrieval units. To address these issues, we\npropose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve\nagent pipeline RAG framework to support large-scale PPI signaling pathway\nexploration in understanding therapeutic impacts by decomposing the analysis of\nentire PPI pathways into sub-tasks focused on the analysis of PPI edges."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-903",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.09695"
    ],
    "b_title":[
      "Modified large-$N$ approach to gapless spin liquids, magnetic orders,\n  and dynamics: Application to triangular lattice antiferromagnets"
    ],
    "b_abstract":[
      "Recent work has shown that the triangular lattice spin-$1\/2$ $J_1$-$J_2$\nHeisenberg and XXZ antiferromagnets may exhibit coplanar or supersolid orders\nproximate to a gapless Dirac spin liquid phase. We explore a distinct\n$SU(2N)\\!\\!\\times\\!\\!SU(M)$ fermionic parton approach, complemented by\nvariational Monte Carlo calculations for the spin-$1\/2$ model, to study the\nphase diagram of these models. We also calculate their dynamical spin response\nincluding parton interactions within a random phase approximation, and discuss\nimplications for neutron scattering on triangular lattice cobaltates\nBa$_3$CoSb$_2$O$_9$, Na$_2$BaCo(PO$_4$)$_2$, K$_2$Co(SeO$_3$)$_2$,\nRb$_2$Co(SeO$_3$)$_2$, and Yb-based magnet KYbSe$_2$."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.14852"
    ],
    "c_title":[
      "UntrustVul: An Automated Approach for Identifying Untrustworthy Alerts\n  in Vulnerability Detection Models"
    ],
    "c_abstract":[
      "Machine learning (ML) has shown promise in detecting vulnerabilities. To\nreview vulnerabilities detected by ML predictions, developers manually assess\nsuspicious lines in their interpretations. However, studies have revealed that\nthese models often learn and predict based on irrelevant features frequently\nappearing in vulnerable code. This leads to predictions that may correctly flag\nvulnerable functions but for the wrong reasons, which we call untrustworthy.\nThese predictions can mislead developers, hindering them from locating the\nvulnerabilities. This increases the efforts of manual assessment and, worse,\nrisks creating flawed patches that fail to address existing vulnerabilities and\neven introduce new ones. Hence, automated approaches are needed to detect\nuntrustworthy predictions, preventing overlooked vulnerabilities and\nalleviating the burden of manual assessment.\n  We propose UntrustVul, the first automated approach to identify untrustworthy\nvulnerability predictions. Given a vulnerability prediction during inference,\nUntrustVul systematically assesses whether suspicious lines annotated by the\nprediction are vulnerability-unrelated. It simulates developers' rationales,\nconsidering a line unrelated if (1) it is absent from historical\nvulnerabilities and (2) it cannot reach any vulnerabilities in execution flows.\nUntrustVul assesses (1) by analysing its syntactic meaning using deep\nrepresentations to determine whether it is syntax-benign. To assess (2),\nUntrustVul traces dependencies of the syntax-benign lines on other suspicious\nlines using static and rule-based analyses. We evaluate UntrustVul on 155K\nvulnerability predictions by four models across three datasets. UntrustVul\neffectively detects untrustworthy predictions with an F1-score of 82%-94% and\nhelps improve the ability of models to detect vulnerabilities by up to 321% in\nF1-score and 100% in trustworthiness."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-904",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00843"
    ],
    "b_title":[
      "Solving an infinite number of purely exponential Diophantine equations\n  with four terms"
    ],
    "b_abstract":[
      "An important unsolved problem in Diophantine number theory is to establish a\ngeneral method to effectively find all solutions to any given $S$-unit equation\nwith at least four terms. Although there are many works contributing to this\nproblem in literature, most of which handle purely exponential Diophantine\nequations, it can be said that all of them only solve finitely many equations\nin a natural distinction. In this paper, we study infinitely many purely\nexponential Diophantine equations with four terms of consecutive bases. Our\nresult states that all solutions to the equation $n^x+(n+1)^y+(n+2)^z=(n+3)^w$\nin positive integers $n,x,y,z,w$ with $n \\equiv 3 \\pmod{4}$ are given by\n$(n,x,y,z,w)=(3,3,1,1,2), (3,3,3,3,3)$. The proof uses elementary congruence\narguments developed in the study of ternary case, Baker's method in both\nrational and $p$-adic cases, and the algorithm of Bert\\'ok and Hajdu based on a\nvariant of Skolem's conjecture on purely exponential equations."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20067"
    ],
    "c_title":[
      "UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook"
    ],
    "c_abstract":[
      "The emergence of audio language models is empowered by neural audio codecs,\nwhich establish critical mappings between continuous waveforms and discrete\ntokens compatible with language model paradigms. The evolutionary trends from\nmulti-layer residual vector quantizer to single-layer quantizer are beneficial\nfor language-autoregressive decoding. However, the capability to handle\nmulti-domain audio signals through a single codebook remains constrained by\ninter-domain distribution discrepancies. In this work, we introduce UniCodec, a\nunified audio codec with a single codebook to support multi-domain audio data,\nincluding speech, music, and sound. To achieve this, we propose a partitioned\ndomain-adaptive codebook method and domain Mixture-of-Experts strategy to\ncapture the distinct characteristics of each audio domain. Furthermore, to\nenrich the semantic density of the codec without auxiliary modules, we propose\na self-supervised mask prediction modeling approach. Comprehensive objective\nand subjective evaluations demonstrate that UniCodec achieves excellent audio\nreconstruction performance across the three audio domains, outperforming\nexisting unified neural codecs with a single codebook, and even surpasses\nstate-of-the-art domain-specific codecs on both acoustic and semantic\nrepresentation capabilities."
    ],
    "c_categories":[
      [
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-905",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.13507"
    ],
    "b_title":[
      "Iterative Shaping of Multi-Particle Aggregates based on Action Trees and\n  VLM"
    ],
    "b_abstract":[
      "In this paper, we address the problem of manipulating multi-particle\naggregates using a bimanual robotic system. Our approach enables the autonomous\ntransport of dispersed particles through a series of shaping and pushing\nactions using robotically-controlled tools. Achieving this advanced\nmanipulation capability presents two key challenges: high-level task planning\nand trajectory execution. For task planning, we leverage Vision Language Models\n(VLMs) to enable primitive actions such as tool affordance grasping and\nnon-prehensile particle pushing. For trajectory execution, we represent the\nevolving particle aggregate's contour using truncated Fourier series, providing\nefficient parametrization of its closed shape. We adaptively compute trajectory\nwaypoints based on group cohesion and the geometric centroid of the aggregate,\naccounting for its spatial distribution and collective motion. Through\nreal-world experiments, we demonstrate the effectiveness of our methodology in\nactively shaping and manipulating multi-particle aggregates while maintaining\nhigh system cohesion."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04427"
    ],
    "c_title":[
      "Near instance optimality of the Lanczos method for Stieltjes and related\n  matrix functions"
    ],
    "c_abstract":[
      "Polynomial Krylov subspace methods are among the most widely used methods for\napproximating $f(A)b$, the action of a matrix function on a vector, in\nparticular when $A$ is large and sparse. When $A$ is Hermitian positive\ndefinite, the Lanczos method is the standard choice of Krylov method, and\ndespite being very simplistic in nature, it often outperforms other, more\nsophisticated methods. In fact, one often observes that the error of the\nLanczos method behaves almost exactly as the error of the best possible\napproximation from the Krylov space (which is in general not efficiently\ncomputable). However, theoretical guarantees for the deviation of the Lanczos\nerror from the optimal error are mostly lacking so far (except for linear\nsystems and a few other special cases). We prove a rigorous bound for this\ndeviation when $f$ belongs to the important class of Stieltjes functions\n(which, e.g., includes inverse fractional powers as special cases) and a\nrelated class (which contains, e.g., the square root and the shifted\nlogarithm), thus providing a \\emph{near instance optimality} guarantee. While\nthe constants in our bounds are likely not optimal, they greatly improve over\nthe few results that are available in the literature and resemble the actual\nbehavior much better."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-906",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20974"
    ],
    "b_title":[
      "Improving Open-world Continual Learning under the Constraints of Scarce\n  Labeled Data"
    ],
    "b_abstract":[
      "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories\/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https:\/\/github.com\/liyj1201\/OFCL."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.08091"
    ],
    "c_title":[
      "Role of phase distortion in nonlinear saturation of the unstable\n  acoustic modes in hypersonic parallel flow boundary layer"
    ],
    "c_abstract":[
      "We analyze the role of the relative phasing in the nonlinear saturation of\nthe unstable Mack modes in a hypersonic parallel flow boundary layer in two\ndimensions (2D). As the linearly unstable Mack modes extract energy from the\nmean flow, the perturbation energy cascades into higher harmonics as well as\nthe mean flow. The higher harmonics are generated with < 0.5% of total\nperturbation energy at steady state, indicating a very small role of higher\nharmonics in 2D. Additionally, the higher harmonics propagate with the same\nphase speed as the unstable mode, indicating wave steepening and a coherent\nenergy cascade. The mean flow gets decelerated and heated due to the continuous\nextraction of the perturbation energy into traveling modes and the viscous\ndissipation of these modes. Unlike unstable modes in classical hydrodynamics,\nwe show that the distortion in relative phasing between the streamwise velocity\nand wall-normal velocity due to nonlinear distortion of the mean flow is\ndominant. Using asymptotic reconstruction of the unstable eigenmodes, we\ncompute the perturbation energy budgets in the linear and nonlinear regimes.\nThrough energy budgets, we show that the viscous effects in the wall layer and\nthe viscous effects in the critical layer sufficiently capture the distortion\nin phase due to the mean-flow distortion. We then combine this in a numerical\nmodel for calculating the steady-state perturbation energy and mean-flow\ndistortion through the nonlinear saturation of unstable Mack modes in a\nhypersonic parallel flow boundary layer in 2D. Throughout, we compare the\nresults of approximate theoretical analysis with 2D direct numerical\nsimulations (DNS)."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-907",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03424"
    ],
    "b_title":[
      "Rigidity of Furstenberg entropy under ucp maps"
    ],
    "b_abstract":[
      "Given a tracial von Neumann algebra $(M,\\tau)$, we prove that a state\npreserving $M$-bimodular ucp map between two stationary W$^*$-extensions of\n$(M,\\tau)$ preserves the Furstenberg entropy if and only if it induces an\nisomorphism between the Radon-Nikodym factors. With a similar proof, we extend\nthis result to quasi-factor maps between stationary spaces of locally compact\ngroups and prove an entropy separation between unique stationary and amenable\nspaces. As applications, we use these results to establish rigidity phenomena\nfor unique stationary Poisson boundaries."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.GR",
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.19582"
    ],
    "c_title":[
      "Where Are We? Evaluating LLM Performance on African Languages"
    ],
    "c_abstract":[
      "Africa's rich linguistic heritage remains underrepresented in NLP, largely\ndue to historical policies that favor foreign languages and create significant\ndata inequities. In this paper, we integrate theoretical insights on Africa's\nlanguage landscape with an empirical evaluation using Sahara - a comprehensive\nbenchmark curated from large-scale, publicly accessible datasets capturing the\ncontinent's linguistic diversity. By systematically assessing the performance\nof leading large language models (LLMs) on Sahara, we demonstrate how\npolicy-induced data variations directly impact model effectiveness across\nAfrican languages. Our findings reveal that while a few languages perform\nreasonably well, many Indigenous languages remain marginalized due to sparse\ndata. Leveraging these insights, we offer actionable recommendations for policy\nreforms and inclusive data practices. Overall, our work underscores the urgent\nneed for a dual approach - combining theoretical understanding with empirical\nevaluation - to foster linguistic diversity in AI for African communities."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-908",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17337"
    ],
    "b_title":[
      "Global $C^{1,\\alpha}$ regularity for Monge-Amp\\`ere equations on planar\n  convex domains"
    ],
    "b_abstract":[
      "In this paper, we establish the global H\\\"older gradient estimate for\nsolutions to the Dirichlet problem of the Monge-Amp\\`ere equation $\\det D^2u =\nf$ on strictly convex but not uniformly convex domain $\\Omega$."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.11061"
    ],
    "c_title":[
      "Superlubric-Locked Transition of Twist Grain Boundaries in 3D Crystals"
    ],
    "c_abstract":[
      "Properties of twist grain boundaries (TGB), long known structurally but not\ntribologically, are simulated under sliding and load, with Au(111) our test\ncase. The load-free TGB moir\\'e is smooth and superlubric at incommensurate\ntwists. Strikingly, load provokes a first-order structural transformation,\nwhere the highest energy moir\\'e nodes are removed -- an Aubry-type transition\nfor which we provide a Landau theory and a twist-load phase diagram. Upon\nfrictional sliding, the transformation causes a superlubric-locked transition,\nwith a huge friction jump, and irreversible plastic flow. The predicted\nphenomena are robust, also recovered in a Lennard-Jones lattice TGB, and not\nexclusive to gold or to metals."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-909",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10114"
    ],
    "b_title":[
      "Non-Gibbsian Multivariate Ewens Probability Distributions on Regular\n  Trees"
    ],
    "b_abstract":[
      "Ewens' sampling formula (ESF) provides the probability distribution governing\nthe number of distinct genetic types and their respective frequencies at a\nselectively neutral locus under the infinitely-many-alleles model of mutation.\nA natural and significant question arises: ``Is the Ewens probability\ndistribution on regular trees Gibbsian?\"\n  In this paper, we demonstrate that Ewens probability distributions can be\nregarded as non-Gibbsian distributions on regular trees and derive a sufficient\ncondition for the consistency condition. This study lays the groundwork for a\nnew direction in the theory of non-Gibbsian probability distributions on trees."
    ],
    "b_categories":[
      [
        "math.FA",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.16870"
    ],
    "c_title":[
      "Experimenting with Affective Computing Models in Video Interviews with\n  Spanish-speaking Older Adults"
    ],
    "c_abstract":[
      "Understanding emotional signals in older adults is crucial for designing\nvirtual assistants that support their well-being. However, existing affective\ncomputing models often face significant limitations: (1) limited availability\nof datasets representing older adults, especially in non-English-speaking\npopulations, and (2) poor generalization of models trained on younger or\nhomogeneous demographics. To address these gaps, this study evaluates\nstate-of-the-art affective computing models -- including facial expression\nrecognition, text sentiment analysis, and smile detection -- using videos of\nolder adults interacting with either a person or a virtual avatar. As part of\nthis effort, we introduce a novel dataset featuring Spanish-speaking older\nadults engaged in human-to-human video interviews. Through three comprehensive\nanalyses, we investigate (1) the alignment between human-annotated labels and\nautomatic model outputs, (2) the relationships between model outputs across\ndifferent modalities, and (3) individual variations in emotional signals. Using\nboth the Wizard of Oz (WoZ) dataset and our newly collected dataset, we uncover\nlimited agreement between human annotations and model predictions, weak\nconsistency across modalities, and significant variability among individuals.\nThese findings highlight the shortcomings of generalized emotion perception\nmodels and emphasize the need of incorporating personal variability and\ncultural nuances into future systems."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-910",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.10794"
    ],
    "b_title":[
      "Distraction is All You Need for Multimodal Large Language Model\n  Jailbreaking"
    ],
    "b_abstract":[
      "Multimodal Large Language Models (MLLMs) bridge the gap between visual and\ntextual data, enabling a range of advanced applications. However, complex\ninternal interactions among visual elements and their alignment with text can\nintroduce vulnerabilities, which may be exploited to bypass safety mechanisms.\nTo address this, we analyze the relationship between image content and task and\nfind that the complexity of subimages, rather than their content, is key.\nBuilding on this insight, we propose the Distraction Hypothesis, followed by a\nnovel framework called Contrasting Subimage Distraction Jailbreaking (CS-DJ),\nto achieve jailbreaking by disrupting MLLMs alignment through multi-level\ndistraction strategies. CS-DJ consists of two components: structured\ndistraction, achieved through query decomposition that induces a distributional\nshift by fragmenting harmful prompts into sub-queries, and visual-enhanced\ndistraction, realized by constructing contrasting subimages to disrupt the\ninteractions among visual elements within the model. This dual strategy\ndisperses the model's attention, reducing its ability to detect and mitigate\nharmful content. Extensive experiments across five representative scenarios and\nfour popular closed-source MLLMs, including GPT-4o-mini, GPT-4o, GPT-4V, and\nGemini-1.5-Flash, demonstrate that CS-DJ achieves average success rates of\n52.40% for the attack success rate and 74.10% for the ensemble attack success\nrate. These results reveal the potential of distraction-based approaches to\nexploit and bypass MLLMs' defenses, offering new insights for attack\nstrategies."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20781"
    ],
    "c_title":[
      "Overlapped Arithmetic Codes"
    ],
    "c_abstract":[
      "Arithmetic codes are usually deemed as the most important means to implement\nlossless source coding, whose principle is mapping every source symbol to a\nsub-interval in [0, 1). For every source symbol, the length of its mapping\nsub-interval is exactly equal to its probability. With this symbol-interval\nmapping rule, the interval [0,1) will be fully covered and there is neither\noverlapped sub-interval (corresponds to more than one source symbol) nor\nforbidden sub-interval (does not correspond to any source symbol).\n  It is well-known that there is a duality between source coding and channel\ncoding, so every good source code may also be a good channel code meanwhile,\nand vice versa. Inspired by this duality, arithmetic codes can be easily\ngeneralized to address many coding problems beyond source coding by redefining\nthe source-interval mapping rule. If every source symbol is mapped to an\nenlarged sub-interval, the mapping sub-intervals of different source symbols\nwill be partially overlapped and we obtain overlapped arithmetic codes, which\ncan realize distributed source coding. On the contrary, if every source symbol\nis mapped to a narrowed sub-interval, there will be one or more forbidden\nsub-intervals in [0, 1) that do not correspond to any source symbol and we\nobtain forbidden arithmetic codes, which can implement joint source-channel\ncoding. Furthermore, by allowing the coexistence of overlapped sub-intervals\nand forbidden sub-intervals, we will obtain hybrid arithmetic codes, which can\ncope with distributed joint source-channel coding."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-911",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18771"
    ],
    "b_title":[
      "Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data\n  Contamination's Impact on Machine Translation"
    ],
    "b_abstract":[
      "Data contamination -- the accidental consumption of evaluation examples\nwithin the pre-training data -- can undermine the validity of evaluation\nbenchmarks. In this paper, we present a rigorous analysis of the effects of\ncontamination on language models at 1B and 8B scales on the machine translation\ntask. Starting from a carefully decontaminated train-test split, we\nsystematically introduce contamination at various stages, scales, and data\nformats to isolate its effect and measure its impact on performance metrics.\nOur experiments reveal that contamination with both source and target\nsubstantially inflates BLEU scores, and this inflation is 2.5 times larger (up\nto 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and\ntarget-only contamination generally produce smaller, less consistent\nover-estimations. Finally, we study how the temporal distribution and frequency\nof contaminated samples influence performance over-estimation across languages\nwith varying degrees of data resources."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12811"
    ],
    "c_title":[
      "A Multi-Power Law for Loss Curve Prediction Across Learning Rate\n  Schedules"
    ],
    "c_abstract":[
      "Training large models is both resource-intensive and time-consuming, making\nit crucial to understand the quantitative relationship between model\nperformance and hyperparameters. In this paper, we present an empirical law\nthat describes how the pretraining loss of large language models evolves under\ndifferent learning rate schedules, such as constant, cosine, and step decay\nschedules. Our proposed law takes a multi-power form, combining a power law\nbased on the sum of learning rates and additional power laws to account for a\nloss reduction effect induced by learning rate decay. We extensively validate\nthis law on various model sizes and architectures, and demonstrate that after\nfitting on a few learning rate schedules, the law accurately predicts the loss\ncurves for unseen schedules of different shapes and horizons. Moreover, by\nminimizing the predicted final pretraining loss across learning rate schedules,\nwe are able to find a schedule that outperforms the widely used cosine learning\nrate schedule. Interestingly, this automatically discovered schedule bears some\nresemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et\nal, 2024) but achieves a slightly lower final loss. We believe these results\ncould offer valuable insights for understanding the dynamics of pretraining and\ndesigning learning rate schedules to improve efficiency."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-912",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09744"
    ],
    "b_title":[
      "KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity\n  Recognition and Normalization for Dysmorphology Physical Examination Reports"
    ],
    "b_abstract":[
      "The objective of BioCreative8 Track 3 is to extract phenotypic key medical\nfindings embedded within EHR texts and subsequently normalize these findings to\ntheir Human Phenotype Ontology (HPO) terms. However, the presence of diverse\nsurface forms in phenotypic findings makes it challenging to accurately\nnormalize them to the correct HPO terms. To address this challenge, we explored\nvarious models for named entity recognition and implemented data augmentation\ntechniques such as synonym marginalization to enhance the normalization step.\nOur pipeline resulted in an exact extraction and normalization F1 score 2.6\\%\nhigher than the mean score of all submissions received in response to the\nchallenge. Furthermore, in terms of the normalization F1 score, our approach\nsurpassed the average performance by 1.9\\%. These findings contribute to the\nadvancement of automated medical data extraction and normalization techniques,\nshowcasing potential pathways for future research and application in the\nbiomedical domain."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16569"
    ],
    "c_title":[
      "Anomaly of the fractional heat propagator in abstract settings"
    ],
    "c_abstract":[
      "We study the following time-fractional heat equation: \\begin{equation*}\n^{C}\\partial_{t}^{\\alpha}u(t)+\\mathscr{L}u(t)=0,\\quad u(0)=u_0\\in X, \\quad\nt\\in[0,T],\\quad T>0,\\quad 0<\\alpha<1, \\end{equation*} where\n$^{C}\\partial_{t}^{\\alpha}$ is the Djrbashian-Caputo fractional derivative, $X$\nis a complex Banach space and $\\mathscr{L}:\\mathcal{D}(\\mathscr{L})\\subset X\\to\nX$ is a closed linear operator. The solution operator of the equation above is\ngiven by the strongly continuous operator $E_\\alpha(-t^{\\alpha}\\mathscr{L})$\nfor any $t\\geqslant0$, closely related with the Mittag-Leffler function\n$E_\\alpha(-x)$ for $x\\geqslant0.$ There are different ways to present\nexplicitly this operator and one of the most popular is given in terms of the\n$C_0$-semigroup generated by $-\\mathscr{L}$\n$\\big(\\{e^{-t\\mathscr{L}}\\}_{t\\geqslant0}\\big)$ as follows: \\[\nE_\\alpha(-t^{\\alpha}\\mathscr{L})=\\int_0^{+\\infty}M_{\\alpha}(s)e^{-st^{\\alpha}\\mathscr{L}}{\\rm\nd}s,\\quad t\\geqslant0, \\] where $M_{\\alpha}(s)$ is a Wright-type function. We\nwill see that the latter expression is not always optimal (regarding\nrestrictions: endpoint lost) to estimate different norms. An additional\nrestriction appears while bounding the above integral, which can be avoided by\nusing directly the function itself and its well-known uniform bound\n$|E_{\\alpha}(-x)|\\leqslant \\frac{C}{1+x},$ $x\\geqslant0.$"
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-913",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.19250"
    ],
    "b_title":[
      "ObjectVLA: End-to-End Open-World Object Manipulation Without\n  Demonstration"
    ],
    "b_abstract":[
      "Imitation learning has proven to be highly effective in teaching robots\ndexterous manipulation skills. However, it typically relies on large amounts of\nhuman demonstration data, which limits its scalability and applicability in\ndynamic, real-world environments. One key challenge in this context is object\ngeneralization, where a robot trained to perform a task with one object, such\nas \"hand over the apple,\" struggles to transfer its skills to a semantically\nsimilar but visually different object, such as \"hand over the peach.\" This gap\nin generalization to new objects beyond those in the same category has yet to\nbe adequately addressed in previous work on end-to-end visuomotor policy\nlearning. In this paper, we present a simple yet effective approach for\nachieving object generalization through Vision-Language-Action (VLA) models,\nreferred to as \\textbf{ObjectVLA}. Our model enables robots to generalize\nlearned skills to novel objects without requiring explicit human demonstrations\nfor each new target object. By leveraging vision-language pair data, our method\nprovides a lightweight and scalable way to inject knowledge about the target\nobject, establishing an implicit link between the object and the desired\naction. We evaluate ObjectVLA on a real robotic platform, demonstrating its\nability to generalize across 100 novel objects with a 64\\% success rate in\nselecting objects not seen during training. Furthermore, we propose a more\naccessible method for enhancing object generalization in VLA models, using a\nsmartphone to capture a few images and fine-tune the pre-trained model. These\nresults highlight the effectiveness of our approach in enabling object-level\ngeneralization and reducing the need for extensive human demonstrations, paving\nthe way for more flexible and scalable robotic learning systems."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.01641"
    ],
    "c_title":[
      "Contrasting the relative performance of RF photonic transversal signal\n  processors based on microcombs using discrete components versus integrated\n  devices"
    ],
    "c_abstract":[
      "RF photonic transversal signal processors, which combine reconfigurable\nelectrical digital signal processing and high-bandwidth photonic processing,\nprovide a powerful solution for achieving adaptive high-speed information\nprocessing. Recent progress in optical microcomb technology provides compelling\nmulti-wavelength sources with compact footprint, yielding a variety of\nmicrocomb-based RF photonic transversal signal processors implemented by either\ndiscrete or integrated components. Although operating based on the same\nprinciple, processors in these two forms exhibit distinct performance. This\nletter presents a comparative investigation into their performance. First, we\ncompare the performance of state-of-the-art processors, focusing on the\nprocessing accuracy. Next, we analyze various factors that contribute to the\nperformance differences, including tap number and imperfect response of\nexperimental components. Finally, we discuss the potential for future\nimprovement. These results provide a comprehensive comparison of microcomb\nbased RF photonic transversal signal processors implemented using discrete and\nintegrated components and provide insights for their future development."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-914",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14015"
    ],
    "b_title":[
      "Bayesian Optimization with Lower Confidence Bounds for Minimization\n  Problems with Known Outer Structure"
    ],
    "b_abstract":[
      "This paper considers Bayesian optimization (BO) for problems with known outer\nproblem structure. In contrast to the classic BO setting, where the objective\nfunction itself is unknown and needs to be iteratively estimated from noisy\nobservations, we analyze the case where the objective has a known outer\nstructure - given in terms of a loss function - while the inner structure - an\nunknown input-output model - is again iteratively estimated from noisy\nobservations of the model outputs. We introduce a novel lower confidence bound\nalgorithm for this particular problem class which exploits the known outer\nproblem structure. The proposed method is analyzed in terms of regret for the\nspecial case of convex loss functions and probabilistic parametric models which\nare linear in the uncertain parameters. Numerical examples illustrate the\nsuperior performance of structure-exploiting methods compared to\nstructure-agnostic approaches."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.05054"
    ],
    "c_title":[
      "SN 2024iss: Double-Peaked Light Curves and Implications for a Yellow\n  Supergiant Progenitor"
    ],
    "c_abstract":[
      "We report the multi-band photometric observations of the Type IIb supernova\n(SN) 2024iss with ultra-violet (UV), optical, and near-infrared (NIR)\nwavelengths starting one day after the explosion. The UV and optical light\ncurves show the first peak two days after the explosion date. Following a first\npeak, a secondary maximum is observed in the optical and NIR bands, similar to\nSNe IIb with double-peaked light curves. The quasi-bolometric light curve shows\nthe fast decay until a week after the explosion. From the analysis of the\nbolometric light curve, the ejecta mass and kinetic energy are estimated to be\n$M_{ej}=2.8\\pm0.6~M_{\\odot}$ and $E_{kin}=9.4\\pm4.1\\times10^{50}$ erg. The mass\nof the radioactive $^{56}$Ni is estimated to be $M(^{56}Ni)=0.2~M_{\\odot}$.\nFitting a black-body function to the spectral energy distribution reveals that\nthe photospheric temperature exhibits a rapid exponential decline during the\nfirst week after the explosion. An analytic model describing the cooling\nemission after shock breakout provides a reasonable explanation for the\nobserved temperature evolution. From these ejecta parameters, we calculated the\nprogenitor radius to be $R_{pro}=50-340$~$R_{\\odot}$. We conclude that these\nexplosion properties are consistent with a core-collapse explosion from a\nyellow supergiant (YSG) progenitor."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-915",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09839"
    ],
    "b_title":[
      "Coarse tree-width"
    ],
    "b_abstract":[
      "We prove two theorems about tree-decompositions in the setting of coarse\ngraph theory. First, we show that a graph $G$ admits a tree-decomposition in\nwhich each bag is contained in the union of a bounded number of balls of\nbounded radius, if and only if $G$ admits a quasi-isometry to a graph with\nbounded tree-width. (The ``if'' half is easy, but the ``only if'' half is\nchallenging.) This generalizes a recent result of Berger and Seymour,\nconcerning tree-decompositions when each bag has bounded radius.\n  Second, we show that if $G$ admits a quasi-isometry $\\phi$ to a graph $H$ of\nbounded path-width, then $G$ admits a quasi-isometry (with error only an\nadditive constant) to a graph of bounded path-width. Indeed, we will show a\nmuch stronger statement: that we can assign a non-negative integer length to\neach edge of $H$, such that the same function $\\phi$ is a quasi-isometry (with\nerror only an additive constant) to this weighted version of $H$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.11863"
    ],
    "c_title":[
      "FedEAT: A Robustness Optimization Framework for Federated LLMs"
    ],
    "c_abstract":[
      "Significant advancements have been made by Large Language Models (LLMs) in\nthe domains of natural language understanding and automated content creation.\nHowever, they still face persistent problems, including substantial\ncomputational costs and inadequate availability of training data. The\ncombination of Federated Learning (FL) and LLMs (federated LLMs) offers a\nsolution by leveraging distributed data while protecting privacy, which\npositions it as an ideal choice for sensitive domains. However, Federated LLMs\nstill suffer from robustness challenges, including data heterogeneity,\nmalicious clients, and adversarial attacks, which greatly hinder their\napplications. We first introduce the robustness problems in federated LLMs, to\naddress these challenges, we propose FedEAT (Federated Embedding space\nAdversarial Training), a novel framework that applies adversarial training in\nthe embedding space of client LLM and employs a robust aggregation approach,\nspecifically geometric median aggregation, to enhance the robustness of\nFederated LLMs. Our experiments demonstrate that FedEAT effectively improves\nthe robustness of Federated LLMs with minimal performance loss."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-916",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15247"
    ],
    "b_title":[
      "Anisotropic Exchange Spin Model to Investigate the Curie Temperature\n  Dispersion of Finite-Size L10-FePt Magnetic Nanoparticles"
    ],
    "b_abstract":[
      "We developed an anisotropic spin model that accounts for magnetic anisotropy\nand evaluated the Curie temperature (Tc) dispersion due to finite size effects\nin L10-FePt nanoparticles. In heat-assisted magnetic recording (HAMR) media, a\nnext-generation magnetic recording technology, high-density recording is\nachieved by locally heating L10-FePt nanoparticles near their Tc and rapidly\ncooling them. However, variations in Tc caused by differences in particle size\nand shape can compromise recording stability and areal density capacity, making\nthe control of Tc dispersion critical. In this study, we constructed atomistic\nLLG models to explicitly incorporate the spin exchange anisotropy of L10-FePt,\nbased on parameters determined by first-principles calculations. Using this\nmodel, we evaluated the impact of particle size on Tc dispersion. As a result,\n(1) the Tc dispersion critical to the performance of HAMR can be reproduced,\nwhereas it was previously underestimated by isotropic models and (2)\napproximately 70% of the experimentally observed Tc dispersion can be\nattributed to particle size effects. This research highlights the role of\nexchange anisotropy in amplifying finite-size effects and underscores the\nimportance of size control in HAMR media."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.00202"
    ],
    "c_title":[
      "Toward Human-Quantum Computer Interaction: Interface Techniques for\n  Usable Quantum Computing"
    ],
    "c_abstract":[
      "By leveraging quantum-mechanical properties like superposition, entanglement,\nand interference, quantum computing (QC) offers promising solutions for\nproblems that classical computing has not been able to solve efficiently, such\nas drug discovery, cryptography, and physical simulation. Unfortunately,\nadopting QC remains difficult for potential users like QC beginners and\napplication-specific domain experts, due to limited theoretical and practical\nknowledge, the lack of integrated interface-wise support, and poor\ndocumentation. For example, to use quantum computers, one has to convert\nconceptual logic into low-level codes, analyze quantum program results, and\nshare programs and results. To support the wider adoption of QC, we, as\ndesigners and QC experts, propose interaction techniques for QC through design\niterations. These techniques include writing quantum codes conceptually,\ncomparing initial quantum programs with optimized programs, sharing quantum\nprogram results, and exploring quantum machines. We demonstrate the feasibility\nand utility of these techniques via use cases with high-fidelity prototypes."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-917",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.15642"
    ],
    "b_title":[
      "Training Neural ODEs Using Fully Discretized Simultaneous Optimization"
    ],
    "b_abstract":[
      "Neural Ordinary Differential Equations (Neural ODEs) represent\ncontinuous-time dynamics with neural networks, offering advancements for\nmodeling and control tasks. However, training Neural ODEs requires solving\ndifferential equations at each epoch, leading to high computational costs. This\nwork investigates simultaneous optimization methods as a faster training\nalternative. In particular, we employ a collocation-based, fully discretized\nformulation and use IPOPT--a solver for large-scale nonlinear optimization--to\nsimultaneously optimize collocation coefficients and neural network parameters.\nUsing the Van der Pol Oscillator as a case study, we demonstrate faster\nconvergence compared to traditional training methods. Furthermore, we introduce\na decomposition framework utilizing Alternating Direction Method of Multipliers\n(ADMM) to effectively coordinate sub-models among data batches. Our results\nshow significant potential for (collocation-based) simultaneous Neural ODE\ntraining pipelines."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03683"
    ],
    "c_title":[
      "First Limits on Light Dark Matter Interactions in a Low Threshold Two\n  Channel Athermal Phonon Detector from the TESSERACT Collaboration"
    ],
    "c_abstract":[
      "We present results of a search for spin-independent dark matter-nucleon\ninteractions in a 1 cm$^2$ by 1 mm thick (0.233 gram) high-resolution silicon\nathermal phonon detector operated above ground. This sensor achieves an energy\nresolution of $\\sigma_P =$ \\SI{361.5(4)}{\\milli\\electronvolt}, the best for any\nathermal phonon detector to date. With an exposure of \\SI{0.233}{\\gram}\n$\\times$ 12 hours, we place the most stringent constraints on dark matter\nmasses between 44 and \\SI{87}{\\mega\\electronvolt\\per\\square c}, with the lowest\nunexplored cross section of \\SI{4e-32}{\\square\\centi\\meter} at\n\\SI{87}{\\mega\\electronvolt\\per\\square c}. We employ a conservative salting\ntechnique to reach the lowest dark matter mass ever probed via direct detection\nexperiment. This constraint is enabled by two-channel rejection of low-energy\nbackgrounds that are coupled to individual sensors."
    ],
    "c_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-918",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.16708"
    ],
    "b_title":[
      "BASS XLV: Quantifying AGN Selection Effects in the Chandra COSMOS-Legacy\n  Survey with BASS"
    ],
    "b_abstract":[
      "Deep extragalactic X-ray surveys, such as the Chandra COSMOS-Legacy field\n(CCLS), are prone to be biased against active galactic nuclei (AGN) with high\ncolumn densities due to their lower count rates at a given luminosity. To\nquantify this selection effect, we forward model nearby ($z\\sim0.05$) AGN from\nthe BAT AGN Spectroscopic Survey (BASS) with well-characterized ($\\gtrsim$1000\ncts) broadband X-ray spectra (0.5-195 keV) to simulate the CCLS absorption\ndistribution. We utilize the BASS low-redshift analogs with similar\nluminosities to the CCLS ($L_\\mathrm{2-10\\ keV}^\\mathrm{int}\\sim10^{42-45}\\\n\\mathrm{erg}\\ \\mathrm{s}^{-1}$), which are much less affected by obscuration\nand low-count statistics, as the seed for our simulations, and follow the\nspectral fitting of the CCLS. Our simulations reveal that Chandra would fail to\ndetect the majority (53.3%; 563\/1056) of obscured ($N_\\mathrm{H}>10^{22}\\\n\\mathrm{cm}^{-2}$) simulated BASS AGN given the observed redshift and\nluminosity distribution of the CCLS. Even for detected sources with sufficient\ncounts ($\\geq30$) for spectral modeling, the level of obscuration is\nsignificantly overestimated. This bias is most extreme for objects whose best\nfit indicates a high-column density AGN ($N_\\mathrm{H}\\geq10^{24}\\\n\\mathrm{cm}^{-2}$), since the majority (66.7%; 18\/27) of these are actually\nunobscured sources ($N_\\mathrm{H}<10^{22}\\ \\mathrm{cm}^{-2}$). This implies\nthat previous studies may have significantly overestimated the increase in the\nobscured fraction with redshift and the fraction of luminous obscured AGN. Our\nfindings highlight the importance of directly considering obscuration biases\nand forward modeling in X-ray surveys, as well as the need for\nhigher-sensitivity X-ray missions such as the Advanced X-ray Imaging Satellite\n(AXIS), and the importance of multi-wavelength indicators to estimate\nobscuration in distant supermassive black holes."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.10538"
    ],
    "c_title":[
      "Universality of Benign Overfitting in Binary Linear Classification"
    ],
    "c_abstract":[
      "The practical success of deep learning has led to the discovery of several\nsurprising phenomena. One of these phenomena, that has spurred intense\ntheoretical research, is ``benign overfitting'': deep neural networks seem to\ngeneralize well in the over-parametrized regime even though the networks show a\nperfect fit to noisy training data. It is now known that benign overfitting\nalso occurs in various classical statistical models. For linear maximum margin\nclassifiers, benign overfitting has been established theoretically in a class\nof mixture models with very strong assumptions on the covariate distribution.\nHowever, even in this simple setting, many questions remain open. For instance,\nmost of the existing literature focuses on the noiseless case where all true\nclass labels are observed without errors, whereas the more interesting noisy\ncase remains poorly understood. We provide a comprehensive study of benign\noverfitting for linear maximum margin classifiers. We discover a phase\ntransition in test error bounds for the noisy model which was previously\nunknown and provide some geometric intuition behind it. We further considerably\nrelax the required covariate assumptions in both, the noisy and noiseless case.\nOur results demonstrate that benign overfitting of maximum margin classifiers\nholds in a much wider range of scenarios than was previously known and provide\nnew insights into the underlying mechanisms."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-919",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13120"
    ],
    "b_title":[
      "Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language\n  in a Coreference Context"
    ],
    "b_abstract":[
      "Gender-inclusive language is often used with the aim of ensuring that all\nindividuals, regardless of gender, can be associated with certain concepts.\nWhile psycholinguistic studies have examined its effects in relation to human\ncognition, it remains unclear how Large Language Models (LLMs) process\ngender-inclusive language. Given that commercial LLMs are gaining an\nincreasingly strong foothold in everyday applications, it is crucial to examine\nwhether LLMs in fact interpret gender-inclusive language neutrally, because the\nlanguage they generate has the potential to influence the language of their\nusers. This study examines whether LLM-generated coreferent terms align with a\ngiven gender expression or reflect model biases. Adapting psycholinguistic\nmethods from French to English and German, we find that in English, LLMs\ngenerally maintain the antecedent's gender but exhibit underlying masculine\nbias. In German, this bias is much stronger, overriding all tested\ngender-neutralization strategies."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.01693"
    ],
    "c_title":[
      "Correlated study on some $B_{c}\\rightarrow \\text{ }P$ and\n  $B_{c}\\rightarrow\\text{ }S$ wave channels in light of new inputs"
    ],
    "c_abstract":[
      "This study investigates the decay modes of the $B_c$ meson, focusing on\nsemileptonic and nonleptonic decay into S and P wave charmonia. The primary\nobjective is to extract the shape parameter of the $B_{c}$ meson distribution\namplitude through a data-driven approach, utilizing the lattice results on\n$B_{c}\\rightarrow\\eta_{c},J\/\\psi$ semileptonic form factors and yielding an\nestimate of ${\\omega_B}_c = 0.998(34)$ for the same. We use the form factors\nderived from the modified perturbative QCD framework in the analysis. This\nresult and various other inputs on the radiative decays of the P wave charmonia\nenable us to estimate the $q^2$ shapes of the\n$B_{c}\\rightarrow\\chi_{c0},\\chi_{c1}$ and $h_{c}$ form factors using pole\nexpansion parametrization. Using these results, we have obtained predictions of\nLFUV observables $R(\\chi_{c0})=0.169(11)$, $R(\\chi_{c1})=0.126(2)$ and\n$R(h_{c})=0.113(3)$. Finally, we have presented predictions for branching\nratios of some nonleptonic decay modes of the $B_{c}$ meson into S and P wave\ncharmonia in the same modified perturbative QCD framework."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-920",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11330"
    ],
    "b_title":[
      "Learning to reset in target search problems"
    ],
    "b_abstract":[
      "Target search problems are central to a wide range of fields, from biological\nforaging to the optimization algorithms. Recently, the ability to reset the\nsearch has been shown to significantly improve the searcher's efficiency.\nHowever, the optimal resetting strategy depends on the specific properties of\nthe search problem and can often be challenging to determine. In this work, we\npropose a reinforcement learning (RL)-based framework to train agents capable\nof optimizing their search efficiency in environments by learning how to reset.\nFirst, we validate the approach in a well-established benchmark: the Brownian\nsearch with resetting. There, RL agents consistently recover strategies closely\nresembling the sharp resetting distribution, known to be optimal in this\nscenario. We then extend the framework by allowing agents to control not only\nwhen to reset, but also their spatial dynamics through turning actions. In this\nmore complex setting, the agents discover strategies that adapt both resetting\nand turning to the properties of the environment, outperforming the proposed\nbenchmarks. These results demonstrate how reinforcement learning can serve both\nas an optimization tool and a mechanism for uncovering new, interpretable\nstrategies in stochastic search processes with resetting."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11862"
    ],
    "c_title":[
      "A multi-frequency census of 100 pulsars below 100 MHz with LWA: a\n  systematic study of flux density, spectra, timing, dispersion, polarization,\n  and its variation from a decade of observations"
    ],
    "c_abstract":[
      "We present a census of 100 pulsars, the largest below 100 MHz, including 94\nnormal pulsars and six millisecond pulsars, with the Long Wavelength Array\n(LWA). Pulse profiles are detected across a range of frequencies from 26 to 88\nMHz, including new narrow-band profiles facilitating profile evolution studies\nand breaks in pulsar spectra at low frequencies. We report mean flux density,\nspectral index, curvature, and low-frequency turnover frequency measurements\nfor 97 pulsars, including new measurements for 61 sources. Multi-frequency\nprofile widths are presented for all pulsars, including component spacing for\n27 pulsars with two components. Polarized emission is detected from 27 of the\nsources (the largest sample at these frequencies) in multiple frequency bands,\nwith one new detection. We also provide new timing solutions for five\nrecently-discovered pulsars. Low-frequency observations with the LWA are\nespecially sensitive to propagation effects arising in the interstellar medium.\nWe have made the most sensitive measurements of pulsar dispersion measures\n(DMs) and rotation measures (RMs), with median uncertainties of 2.9x10^-4 pc\ncm^-3 and 0.01 rad m^-2, respectively, and can track their variations over\nalmost a decade, along with other frequency-dependent effects. This allows\nstringent limits on average magnetic fields, with no variations detected above\n~20 nG. Finally, the census yields some interesting phenomena in individual\nsources, including the detection of frequency and time-dependent DM variations\nin B2217+47, and the detection of highly circularly polarized emission from\nJ0051+0423."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-921",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.12930"
    ],
    "b_title":[
      "Planarity ranks of modular varieties of semigroups"
    ],
    "b_abstract":[
      "By the planarity rank of a semigroup variety we mean the largest number of\ngenerators of a free semigroup of a variety with respect to which the semigroup\nadmits a planar Cayley graph. Since the time when L.M.Martynov formulated the\nproblem of describing the planarity ranks of semigroup varieties, many specific\nresults have been obtained in this direction. A modular variety of semigroups\nis a variety of semigroups with a modular lattice of subvarieties. In this\npaper, we calculate the exact values of the planarity ranks of an infinite\ncountable set of all possible modular varieties of semigroups. It turns out\nthat these values do not exceed 3. Machine calculations are mostly used in the\nproof. Prover9 and Mace4 are used to check the equalities of elements of free\nsemigroups of varieties defined by a large number of identities. To prove the\nnon-planarity of graphs, the Pontryagin-Kuratovsky criterion is used, and the\nColin de Verdiere invariant is indirectly used to justify planarity."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.05335"
    ],
    "c_title":[
      "Force-Velocity Relationship in Branched Actin Networks: Consequences of\n  Entanglement, Drag and Stall Force"
    ],
    "c_abstract":[
      "We investigate the growth of a branched actin network under load. Using a\ncombination of simulations and theory, we show that the network adapts to the\nload and exhibits two regimes: a finite velocity at low stress, followed by a\npower-law decay of the velocity as a function of stress. This decay is\nexplained by a theoretical model relating branched network elasticity to\nfilament entanglement. The finite maximum velocity is attributed to network\ndrag, which dictates dynamics at low stress. Additionally, analysis of filament\nstall force contribution reveals a transition from a stalled network to a\ngrowing network, when the filament stall force exceeds a critical value\ncontrolled by the applied stress."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-922",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18836"
    ],
    "b_title":[
      "Transfer Learning for Nonparametric Contextual Dynamic Pricing"
    ],
    "b_abstract":[
      "Dynamic pricing strategies are crucial for firms to maximize revenue by\nadjusting prices based on market conditions and customer characteristics.\nHowever, designing optimal pricing strategies becomes challenging when\nhistorical data are limited, as is often the case when launching new products\nor entering new markets. One promising approach to overcome this limitation is\nto leverage information from related products or markets to inform the focal\npricing decisions. In this paper, we explore transfer learning for\nnonparametric contextual dynamic pricing under a covariate shift model, where\nthe marginal distributions of covariates differ between source and target\ndomains while the reward functions remain the same. We propose a novel Transfer\nLearning for Dynamic Pricing (TLDP) algorithm that can effectively leverage\npre-collected data from a source domain to enhance pricing decisions in the\ntarget domain. The regret upper bound of TLDP is established under a simple\nLipschitz condition on the reward function. To establish the optimality of\nTLDP, we further derive a matching minimax lower bound, which includes the\ntarget-only scenario as a special case and is presented for the first time in\nthe literature. Extensive numerical experiments validate our approach,\ndemonstrating its superiority over existing methods and highlighting its\npractical utility in real-world applications."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01374"
    ],
    "c_title":[
      "Data Acquisition Through Participatory Design for Automated\n  Rehabilitation Assessment"
    ],
    "c_abstract":[
      "Through participatory design, we are developing a computational system for\nthe semi-automated assessment of the Action Research Arm Test (ARAT) for stroke\nrehabilitation. During rehabilitation assessment, clinicians rate movement\nsegments and components in the context of overall task performance. Clinicians\nchange viewing angles to assess particular components. Through studies with\nclinicians, we develop a system that includes: a) unobtrusive multi-camera\ncapture, b) a segmentation interface for non-expert segmentors, and c) a rating\ninterface for expert clinicians. Five clinicians independently captured 1800\nstroke survivor videos with <5$\\%$ errors. Three segmentors have segmented 760\nof these videos, averaging 20 seconds per segment. They favor the recommended\ncamera view $>$ 90\\%. Multiple clinicians have rated the segmented videos while\nreporting minimal problems. The complete data will be used for training an\nautomated segmentation and rating system that empowers the clinicians as the\nratings will be compatible with clinical practice and intuition."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-923",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17705"
    ],
    "b_title":[
      "A Bayesian Integrative Mixed Modeling Framework for Analysis of the\n  Adolescent Brain and Cognitive Development Study"
    ],
    "b_abstract":[
      "Integrating high-dimensional, heterogeneous data from multi-site cohort\nstudies with complex hierarchical structures poses significant feature\nselection and prediction challenges. We extend the Bayesian Integrative\nAnalysis and Prediction (BIP) framework to enable simultaneous feature\nselection and outcome modeling in data of nested hierarchical structure. We\napply the proposed Bayesian Integrative Mixed Modeling (BIPmixed) framework to\nthe Adolescent Brain Cognitive Development (ABCD) Study, leveraging multi-view\ndata, including structural and functional MRI and early life adversity (ELA)\nmetrics, to identify relevant features and predict the behavioral outcome.\nBIPmixed incorporates 2-level nested random effects, to enhance\ninterpretability and make predictions in hierarchical data settings. Simulation\nstudies illustrate BIPmixed's robustness in distinct random effect settings,\nhighlighting its use for complex study designs. Our findings suggest that\nBIPmixed effectively integrates multi-view data while accounting for nested\nsampling, making it a valuable tool for analyzing large-scale studies with\nhierarchical data."
    ],
    "b_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.10077"
    ],
    "c_title":[
      "Towards Empowerment Gain through Causal Structure Learning in\n  Model-Based RL"
    ],
    "c_abstract":[
      "In Model-Based Reinforcement Learning (MBRL), incorporating causal structures\ninto dynamics models provides agents with a structured understanding of the\nenvironments, enabling efficient decision. Empowerment as an intrinsic\nmotivation enhances the ability of agents to actively control their\nenvironments by maximizing the mutual information between future states and\nactions. We posit that empowerment coupled with causal understanding can\nimprove controllability, while enhanced empowerment gain can further facilitate\ncausal reasoning in MBRL. To improve learning efficiency and controllability,\nwe propose a novel framework, Empowerment through Causal Learning (ECL), where\nan agent with the awareness of causal dynamics models achieves\nempowerment-driven exploration and optimizes its causal structure for task\nlearning. Specifically, ECL operates by first training a causal dynamics model\nof the environment based on collected data. We then maximize empowerment under\nthe causal structure for exploration, simultaneously using data gathered\nthrough exploration to update causal dynamics model to be more controllable\nthan dense dynamics model without causal structure. In downstream task\nlearning, an intrinsic curiosity reward is included to balance the causality,\nmitigating overfitting. Importantly, ECL is method-agnostic and is capable of\nintegrating various causal discovery methods. We evaluate ECL combined with 3\ncausal discovery methods across 6 environments including pixel-based tasks,\ndemonstrating its superior performance compared to other causal MBRL methods,\nin terms of causal discovery, sample efficiency, and asymptotic performance."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-924",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.17463"
    ],
    "b_title":[
      "Model reduction of convection-dominated viscous conservation laws using\n  implicit feature tracking and landmark image registration"
    ],
    "b_abstract":[
      "Reduced-order models (ROMs) remain generally unreliable for\nconvection-dominated problems, such as those encountered in hypersonic flows,\ndue to the slowly decaying Kolmogorov $n$-width of linear subspace\napproximations, known as the Kolmogorov barrier. This limitation hinders the\naccuracy of traditional ROMs and necessitates impractical amounts of training\ndata during the offline phase. To address this challenge, we introduce a novel\nlandmark-based registration procedure tailored for ROMs of convection-dominated\nproblems. Our approach leverages limited training data and incorporates a\nnonlinear transformation of the data using a landmark-based registration\ntechnique combined with radial basis function (RBF) interpolation. During the\noffline phase, we align dominant convective features in a reference domain,\nresulting in a rapid decay of error relative to the reduced space dimension.\nLandmarks are generated through a three-step process: (1) detecting shocks via\nedge detection techniques, (2) sampling using Monte Carlo methods, and (3)\ndomain partitioning with $k$-means clustering, where cluster centroids serve as\nlandmarks. Accurate landmark correspondence is achieved by minimizing pairing\ndistances for similar features. The online phase integrates standard\nminimum-residual ROM methodologies, extending the optimization space to include\nadmissible domain mappings. We validate our approach on two test cases: a\nspace-time Burgers' equation parameterized by the initial condition, and a\nhypersonic viscous flow over a cylinder parameterized by the Mach number.\nResults demonstrate the efficacy of the proposed method in overcoming the\nKolmogorov barrier and enhancing the reliability of ROMs for\nconvection-dominated problems."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03505"
    ],
    "c_title":[
      "Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems"
    ],
    "c_abstract":[
      "Recent advancements in Large Language Model(LLM)-based Multi-Agent\nSystems(MAS) have demonstrated remarkable potential for tackling complex\ndecision-making tasks. However, existing frameworks inevitably rely on\nserialized execution paradigms, where agents must complete sequential LLM\nplanning before taking action. This fundamental constraint severely limits\nreal-time responsiveness and adaptation, which is crucial in dynamic\nenvironments with ever-changing scenarios. In this paper, we propose a novel\nparallelized planning-acting framework for LLM-based MAS, featuring a\ndual-thread architecture with interruptible execution to enable concurrent\nplanning and acting. Specifically, our framework comprises two core threads:(1)\na planning thread driven by a centralized memory system, maintaining\nsynchronization of environmental states and agent communication to support\ndynamic decision-making; and (2) an acting thread equipped with a comprehensive\nskill library, enabling automated task execution through recursive\ndecomposition. Extensive experiments on challenging Minecraft demonstrate the\neffectiveness of the proposed framework."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-925",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11100"
    ],
    "b_title":[
      "The Role of Hydrogen and Oxygen Interstitial Defects in Crystalline Si\n  cells: Mechanism of Device Degradation in Humid Environment"
    ],
    "b_abstract":[
      "The efficiency of silicon solar cells gradually decreases in various\nenvironments, with humidity being a key factor contributing to this decline.\nThis study investigates the humidity-induced failure mechanisms in crystalline\nsilicon solar cells. Using density functional theory and the non-equilibrium\nGreen's function method, we systematically examine the microscopic diffusion\nmechanisms of hydrogen and oxygen defects and their impact on photovoltaic\nperformance. Hydrogen and oxygen are interstitial defects that can introduce\nboth deep-level and resonant-state recombination centers, thereby reducing\ncarrier lifetime and solar cell efficiency. Furthermore, hydrogen exhibits\nprominent diffusion pathways, particularly in its +1 and 0 charge states at the\nBC site ( \"H\" _\"i(BC)\" ^\"+1\" and \"H\" _\"i(BC)\" ^\"0\" ), while oxygen in its +1\nand 0 charge states shows a higher diffusion barrier at the BC1 site ( \"O\"\n_\"i(BC1)\" ^\"+1\" and \"O\" _\"i(BC1)\" ^\"0\" ). These defects, induced by moisture\nand temperature fluctuations, exacerbate the degradation of solar cell\nperformance. By analyzing these defect behaviors, this research provides\nvaluable insights into the failure mechanisms of Si solar cells, especially\nunder humid conditions."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02345"
    ],
    "c_title":[
      "CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for\n  Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented\n  3D MRI"
    ],
    "c_abstract":[
      "The detection of Alzheimer disease (AD) from clinical MRI data is an active\narea of research in medical imaging. Recent advances in quantum computing,\nparticularly the integration of parameterized quantum circuits (PQCs) with\nclassical machine learning architectures, offer new opportunities to develop\nmodels that may outperform traditional methods. However, quantum machine\nlearning (QML) remains in its early stages and requires further experimental\nanalysis to better understand its behavior and limitations. In this paper, we\npropose an end to end hybrid classical quantum convolutional neural network (CQ\nCNN) for AD detection using clinically formatted 3D MRI data. Our approach\ninvolves developing a framework to make 3D MRI data usable for machine\nlearning, designing and training a brain tissue segmentation model (Skull Net),\nand training a diffusion model to generate synthetic images for the minority\nclass. Our converged models exhibit potential quantum advantages, achieving\nhigher accuracy in fewer epochs than classical models. The proposed beta8 3\nqubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA)\nmodels while requiring significantly fewer computational resources. In\nparticular, the architecture employs only 13K parameters (0.48 MB), reducing\nthe parameter count by more than 99.99% compared to current SOTA models.\nFurthermore, the diffusion-generated data used to train our quantum models, in\nconjunction with real samples, preserve clinical structural standards,\nrepresenting a notable first in the field of QML. We conclude that CQCNN\narchitecture like models, with further improvements in gradient optimization\ntechniques, could become a viable option and even a potential alternative to\nclassical models for AD detection, especially in data limited and resource\nconstrained clinical settings."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-926",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.07414"
    ],
    "b_title":[
      "Cost-Effective Design of Grid-tied Community Microgrid"
    ],
    "b_abstract":[
      "This study aims to develop a cost-effective microgrid design that optimally\nbalances the economic feasibility, reliability, efficiency, and environmental\nimpact in a grid-tied community microgrid. A multi-objective optimization\nframework is employed, integrating HOMER Pro for system sizing with deep\nreinforcement learning (DRL). Sensitivity analyses are conducted to evaluate\nthe system performance under varying load demand and renewable energy\nfluctuations, while an economic sensitivity assessment examines the impact of\nelectricity prices and capital costs on the Levelized Cost of Energy (LCOE).\nThe proposed microgrid configuration achieves high reliability, satisfying 100%\nof the load, even under adverse weather conditions. The proposed framework\nattains an efficiency of 91.99% while maintaining a carbon footprint of 302,747\nkg\/year, which is approximately 95% lower than that of the grid system. The\neconomic analysis indicates a net present cost (NPC) of $4.83M with a\ncompetitive LCOE of $0.208\/kWh. In addition, the operation cost is $201,473 per\nyear with a capital investment of $1.42M, rendering it a financially viable\nalternative to conventional grid-dependent systems.This work can be valuable in\nidentifying effective solutions for supplying reliable and cost-effective power\nto regional and remote areas."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09295"
    ],
    "c_title":[
      "Internal Aerodynamics of Supersonic Crossflows with Transverse Liquid\n  Injection"
    ],
    "c_abstract":[
      "This study experimentally investigates the internal aerodynamics of\ntransverse liquid injection in a supersonic crossflow (Mach (M) = 2.1) using\ntwo configurations: single and tandem (8 mm spacing) at three injection mass\nflow rates. Back-lit imaging revealed classical jet breakup phenomena,\nincluding surface wave instabilities with increasing amplitudes along the jet\nboundary, leading to protrusions, breakup into large liquid clumps, and their\ndisintegration into finer droplets under aerodynamic forces. The single\ninjection exhibited the formation of large liquid clumps further downstream\ncompared to the tandem injection. Schlieren imaging showed that at a low\nmomentum flux ratio (J = 0.94), both configurations produced regular reflection\n(RR) of the bow shock wave from the top wall. Increasing J to 1.90 resulted in\nRR for the single injection, while the tandem injection transitioned to Mach\nreflection (MR). At J = 2.67, both configurations exhibited MR. The earlier\nRR-to MR transition in tandem injection is attributed to its higher jet\npenetration and spanwise spread, which reduce the downstream crossflow passage\narea, acting as a supersonic diffuser and increasing downstream pressure which\nis favorable for MR transition. Separation zones were observed at the bottom\nwall due to bow shock wave-boundary layer interaction, and at the side walls\ndue to the interaction of the Mach stem of the MR structure with the walls.\nThese interactions create complex flow regions dominated by vortex structures,\nsignificantly influencing the overall flow dynamics."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-927",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06765"
    ],
    "b_title":[
      "Comfortability of quantum walks on embedded graphs on surfaces"
    ],
    "b_abstract":[
      "In this paper, a quantum walk model which reflects the underlying embedding\non the surface is proposed. We obtain the scattering matrix of this quantum\nwalk model characterized by the faces on the surface, and find a detection of\nthe orientablility of the underlying embedding by the scattering information.\nThe comfortability is the square norm of the stationary state restricted to the\ninternal and reflected by the underlying embedding. We find that quantum walker\nfeels more comfortable to a surface with small genus in some natural setting."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.10040"
    ],
    "c_title":[
      "LWGANet: A Lightweight Group Attention Backbone for Remote Sensing\n  Visual Tasks"
    ],
    "c_abstract":[
      "Remote sensing (RS) visual tasks have gained significant academic and\npractical importance. However, they encounter numerous challenges that hinder\neffective feature extraction, including the detection and recognition of\nmultiple objects exhibiting substantial variations in scale within a single\nimage. While prior dual-branch or multi-branch architectural strategies have\nbeen effective in managing these object variances, they have concurrently\nresulted in considerable increases in computational demands and parameter\ncounts. Consequently, these architectures are rendered less viable for\ndeployment on resource-constrained devices. Contemporary lightweight backbone\nnetworks, designed primarily for natural images, frequently encounter\ndifficulties in effectively extracting features from multi-scale objects, which\ncompromises their efficacy in RS visual tasks. This article introduces LWGANet,\na specialized lightweight backbone network tailored for RS visual tasks,\nincorporating a novel lightweight group attention (LWGA) module designed to\naddress these specific challenges. LWGA module, tailored for RS imagery,\nadeptly harnesses redundant features to extract a wide range of spatial\ninformation, from local to global scales, without introducing additional\ncomplexity or computational overhead. This facilitates precise feature\nextraction across multiple scales within an efficient framework.LWGANet was\nrigorously evaluated across twelve datasets, which span four crucial RS visual\ntasks: scene classification, oriented object detection, semantic segmentation,\nand change detection. The results confirm LWGANet's widespread applicability\nand its ability to maintain an optimal balance between high performance and low\ncomplexity, achieving SOTA results across diverse datasets. LWGANet emerged as\na novel solution for resource-limited scenarios requiring robust RS image\nprocessing capabilities."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-928",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09015"
    ],
    "b_title":[
      "Generalized Cross-Entropy Benchmarking for Random Circuits with\n  Ergodicity"
    ],
    "b_abstract":[
      "Cross-entropy benchmarking is a central technique used to certify a quantum\nchip in recent experiments. To better understand its mathematical foundation\nand develop new benchmarking schemes, we introduce the concept of ergodicity to\nrandom circuit sampling and find that the Haar random quantum circuit satisfies\nan ergodicity condition -- the average of certain types of post-processing\nfunction over the output bit strings is close to the average over the unitary\nensemble. For noiseless random circuits, we prove that the ergodicity holds for\npolynomials of degree $t$ with positive coefficients and when the random\ncircuits form a unitary $2t$-design. For strong enough noise, the ergodicity\ncondition is violated. This suggests that ergodicity is a property that can be\nexploited to certify a quantum chip. We formulate the deviation of ergodicity\nas a measure for quantum chip benchmarking and show that it can be used to\nestimate the circuit fidelity for global depolarizing noise and weakly\ncorrelated noise. For a quadratic post-processing function, our framework\nrecovers Google's result on estimating the circuit fidelity via linear\ncross-entropy benchmarking (XEB), and we give a sufficient condition on the\nnoise model characterizing when such estimation is valid. Our results establish\nan interesting connection between ergodicity and noise in random circuits and\nprovide new insights into designing quantum benchmarking schemes."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.00568"
    ],
    "c_title":[
      "Logica-TGD: Transforming Graph Databases Logically"
    ],
    "c_abstract":[
      "Graph transformations are a powerful computational model for manipulating\ncomplex networks, but handling temporal aspects and scalability remain\nsignificant challenges. We present a novel approach to implementing these\ntransformations using Logica, an open-source logic programming language and\nsystem that operates on parallel databases like DuckDB and BigQuery. Leveraging\nthe parallelism of these engines, our method enhances performance and\naccessibility, while also offering a practical way to handle time-varying\ngraphs. We illustrate Logica's graph querying and transformation capabilities\nwith several examples, including the computation of the well-founded solution\nto the classic \"Win-Move\" game, a declarative program for pathfinding in a\ndynamic graph, and the application of Logica to the collection of all current\nfacts of Wikidata for taxonomic relations analysis. We argue that clear\ndeclarative syntax, built-in visualization and powerful supported engines make\nLogica a convenient tool for graph transformations."
    ],
    "c_categories":[
      [
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-929",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17760"
    ],
    "b_title":[
      "Probabilistic Dual Frames and Minimization of Dual Frame Potentials"
    ],
    "b_abstract":[
      "This paper studies probabilistic dual frames and associated dual frame\npotentials from the optimal mass transport perspective. The main contribution\nin this work shows that given a probabilistic frame, its dual frame potential\nis minimized if and only if the probabilistic frame is tight and the\nprobabilistic dual frame is the canonical dual. In particular, the tightness\ncondition can be dropped if the probabilistic dual frame potential is minimized\nonly among probabilistic dual frames of pushforward type."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.15035"
    ],
    "c_title":[
      "GraspCorrect: Robotic Grasp Correction via Vision-Language Model-Guided\n  Feedback"
    ],
    "c_abstract":[
      "Despite significant advancements in robotic manipulation, achieving\nconsistent and stable grasping remains a fundamental challenge, often limiting\nthe successful execution of complex tasks. Our analysis reveals that even\nstate-of-the-art policy models frequently exhibit unstable grasping behaviors,\nleading to failure cases that create bottlenecks in real-world robotic\napplications. To address these challenges, we introduce GraspCorrect, a\nplug-and-play module designed to enhance grasp performance through\nvision-language model-guided feedback. GraspCorrect employs an iterative visual\nquestion-answering framework with two key components: grasp-guided prompting,\nwhich incorporates task-specific constraints, and object-aware sampling, which\nensures the selection of physically feasible grasp candidates. By iteratively\ngenerating intermediate visual goals and translating them into joint-level\nactions, GraspCorrect significantly improves grasp stability and consistently\nenhances task success rates across existing policy models in the RLBench and\nCALVIN datasets."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-930",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13340"
    ],
    "b_title":[
      "A Python Toolkit for Plotting Double Star Observations with 1:1 Aspect\n  Ratio"
    ],
    "b_abstract":[
      "Accurate visualization of double star astrometric data is essential for\neffective analysis and interpretation. This article presents a Python toolkit\ndesigned for astronomers who need to plot measurements from diverse sources --\nhistorical, Gaia DR3, and the Las Cumbres Observatory (LCO) network -- while\nmaintaining a 1:1 aspect ratio to avoid visually distorting the data. The\ntoolkit is composed of three scripts: one that handles polar coordinates (P.A.,\nseparation), one for Cartesian (X, Y) coordinates, and another with the option\nto include predicted theoretical points. This paper describes the purpose,\nfunctionality, and usage of these scripts, including example figures,\ninstallation guides, and licensing information.\n  This toolkit has been used by the author and collaborators in published and\nsubmitted research on double star systems, demonstrating its versatility for\nboth professional and student-driven investigations."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.14400"
    ],
    "c_title":[
      "SKIL: Semantic Keypoint Imitation Learning for Generalizable\n  Data-efficient Manipulation"
    ],
    "c_abstract":[
      "Real-world tasks such as garment manipulation and table rearrangement demand\nrobots to perform generalizable, highly precise, and long-horizon actions.\nAlthough imitation learning has proven to be an effective approach for teaching\nrobots new skills, large amounts of expert demonstration data are still\nindispensible for these complex tasks, resulting in high sample complexity and\ncostly data collection. To address this, we propose Semantic Keypoint Imitation\nLearning (SKIL), a framework which automatically obtain semantic keypoints with\nhelp of vision foundation models, and forms the descriptor of semantic\nkeypoints that enables effecient imitation learning of complex robotic tasks\nwith significantly lower sample complexity. In real world experiments, SKIL\ndoubles the performance of baseline methods in tasks such as picking a cup or\nmouse, while demonstrating exceptional robustness to variations in objects,\nenvironmental changes, and distractors. For long-horizon tasks like hanging a\ntowel on a rack where previous methods fail completely, SKIL achieves a mean\nsuccess rate of 70\\% with as few as 30 demonstrations. Furthermore, SKIL\nnaturally supports cross-embodiment learning due to its semantic keypoints\nabstraction, our experiments demonstrate that even human videos bring\nconsiderable improvement to the learning performance. All these results\ndemonstrate the great success of SKIL in achieving data-efficint generalizable\nrobotic learning. Visualizations and code are available at:\nhttps:\/\/skil-robotics.github.io\/SKIL-robotics\/."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-931",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04389"
    ],
    "b_title":[
      "Overcoming Vision Language Model Challenges in Diagram Understanding: A\n  Proof-of-Concept with XML-Driven Large Language Models Solutions"
    ],
    "b_abstract":[
      "Diagrams play a crucial role in visually conveying complex relationships and\nprocesses within business documentation. Despite recent advances in\nVision-Language Models (VLMs) for various image understanding tasks, accurately\nidentifying and extracting the structures and relationships depicted in\ndiagrams continues to pose significant challenges. This study addresses these\nchallenges by proposing a text-driven approach that bypasses reliance on VLMs'\nvisual recognition capabilities. Instead, it utilizes the editable source\nfiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,\nannotations) are preserved as textual metadata. In our proof-of-concept, we\nextracted diagram information from xlsx-based system design documents and\ntransformed the extracted shape data into textual input for Large Language\nModels (LLMs). This approach allowed the LLM to analyze relationships and\ngenerate responses to business-oriented questions without the bottleneck of\nimage-based processing. Experimental comparisons with a VLM-based method\ndemonstrated that the proposed text-driven framework yielded more accurate\nanswers for questions requiring detailed comprehension of diagram\nstructures.The results obtained in this study are not limited to the tested\n.xlsx files but can also be extended to diagrams in other documents with source\nfiles, such as Office pptx and docx formats. These findings highlight the\nfeasibility of circumventing VLM constraints through direct textual extraction\nfrom original source files. By enabling robust diagram understanding through\nLLMs, our method offers a promising path toward enhanced workflow efficiency\nand information analysis in real-world business scenarios."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19168"
    ],
    "c_title":[
      "Chiral Representation of the Nucleon Mass at Leading Two-loop Order"
    ],
    "c_abstract":[
      "We calculate the nucleon mass in a manifestly relativistic baryon chiral\nperturbation theory up to the leading two-loop order. Through dimensional\ncounting analysis, we perform the chiral expansion and verify the validity of\nthe extended-on-mass-shell scheme at the two-loop level. As a result, we obtain\nthe complete chiral representation of the nucleon mass up to\n$\\mathcal{O}(p^5)$, which preserves the original analytic properties and\nsatisfies the correct power counting. The obtained chiral result is well-suited\nfor chiral extrapolation and provides an excellent description of lattice QCD\ndata across a broad range of pion masses. We find that the $\\mathcal{O}(p^5)$\ncontribution is small, approximately $10$ MeV, and varies only mildly with\nincreasing pion mass, demonstrating good convergence of the nucleon mass up to\npion masses of about 350 MeV at two-loop order."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-932",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.20517"
    ],
    "b_title":[
      "Abelian congruences and similarity in varieties with a weak difference\n  term"
    ],
    "b_abstract":[
      "This is the first of three papers motivated by the author's desire to\nunderstand and explain \"algebraically\" one aspect of Dmitriy Zhuk's proof of\nthe CSP Dichotomy Theorem. In this paper we study abelian congruences in\nvarieties having a weak difference term. Each class of the congruence supports\nan abelian group structure; if the congruence is minimal, each class supports\nthe structure of a vector space over a division ring determined by the\ncongruence. A construction due to J. Hagemann, C. Herrmann and R. Freese in the\ncongruence modular setting extends to varieties with a weak difference term,\nand provides a \"universal domain\" for the abelian groups or vector spaces that\narise from the classes of the congruence within a single class of the\nannihilator of the congruence. The construction also supports an extension of\nFreese's similarity relation (between subdirectly irreducible algebras) from\nthe congruence modular setting to varieties with a weak difference term."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.04517"
    ],
    "c_title":[
      "Towards Cost-Effective Reward Guided Text Generation"
    ],
    "c_abstract":[
      "Reward-guided text generation (RGTG) has emerged as a viable alternative to\noffline reinforcement learning from human feedback (RLHF). RGTG methods can\nalign baseline language models to human preferences without further training\nlike in standard RLHF methods. However, they rely on a reward model to score\neach candidate token generated by the language model at inference, incurring\nsignificant test-time overhead. Additionally, the reward model is usually only\ntrained to score full sequences, which can lead to sub-optimal choices for\npartial sequences. In this work, we present a novel reward model architecture\nthat is trained, using a Bradley-Terry loss, to prefer the optimal expansion of\na sequence with just a \\emph{single call} to the reward model at each step of\nthe generation process. That is, a score for all possible candidate tokens is\ngenerated simultaneously, leading to efficient inference. We theoretically\nanalyze various RGTG reward models and demonstrate that prior techniques prefer\nsub-optimal sequences compared to our method during inference. Empirically, our\nreward model leads to significantly faster inference than other RGTG methods.\nIt requires fewer calls to the reward model and performs competitively compared\nto previous RGTG and offline RLHF methods."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-933",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.16128"
    ],
    "b_title":[
      "Coupling deep and handcrafted features to assess smile genuineness"
    ],
    "b_abstract":[
      "Assessing smile genuineness from video sequences is a vital topic concerned\nwith recognizing facial expression and linking them with the underlying\nemotional states. There have been a number of techniques proposed underpinned\nwith handcrafted features, as well as those that rely on deep learning to\nelaborate the useful features. As both of these approaches have certain\nbenefits and limitations, in this work we propose to combine the features\nlearned by a long short-term memory network with the features handcrafted to\ncapture the dynamics of facial action units. The results of our experiments\nindicate that the proposed solution is more effective than the baseline\ntechniques and it allows for assessing the smile genuineness from video\nsequences in real-time."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14921"
    ],
    "c_title":[
      "Unique extremality of affine maps on plane domains"
    ],
    "c_abstract":[
      "We prove that affine maps are uniquely extremal quasiconformal maps on the\ncomplement of a well distribute set in the complex plane answering a conjecture\nfrom \\cite{markovic}. We construct the required Reich sequence using Bergman\nprojections, and meromorphic partitions of unity."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-934",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06891"
    ],
    "b_title":[
      "Oscillations of Solitonic Galactic Cores in Ultralight Dark Matter"
    ],
    "b_abstract":[
      "A remarkable feature of dark matter consisting of ultralight bosonic\nparticles is the emergence of superfluid Bose-Einstein condensate structures on\ngalactic scales. We investigate the oscillations of the solitonic dark matter\nstructure in the central galactic region by numerically solving the\nBogoliubov-de Gennes problem, accounting for perturbations in the gravitational\npotential and local self-interactions. Our findings reveal that the central\nsolitonic core, formed by the balance of gravitational attraction, quantum\npressure, and repulsive interactions, exhibits significant oscillatory\nbehaviour. These oscillations, characterized by distinct eigenmodes, provide\ninsights into the dynamical properties of solitonic dark matter structures and\ntheir observational implications and contributions to galactic structure\nformation and evolution."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA",
        "nlin.PS"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.02353"
    ],
    "c_title":[
      "Controllable Motion Generation via Diffusion Modal Coupling"
    ],
    "c_abstract":[
      "Diffusion models have recently gained significant attention in robotics due\nto their ability to generate multi-modal distributions of system states and\nbehaviors. However, a key challenge remains: ensuring precise control over the\ngenerated outcomes without compromising realism. This is crucial for\napplications such as motion planning or trajectory forecasting, where adherence\nto physical constraints and task-specific objectives is essential. We propose a\nnovel framework that enhances controllability in diffusion models by leveraging\nmulti-modal prior distributions and enforcing strong modal coupling. This\nallows us to initiate the denoising process directly from distinct prior modes\nthat correspond to different possible system behaviors, ensuring sampling to\nalign with the training distribution. We evaluate our approach on motion\nprediction using the Waymo dataset and multi-task control in Maze2D\nenvironments. Experimental results show that our framework outperforms both\nguidance-based techniques and conditioned models with unimodal priors,\nachieving superior fidelity, diversity, and controllability, even in the\nabsence of explicit conditioning. Overall, our approach provides a more\nreliable and scalable solution for controllable motion generation in robotics."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-935",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01752"
    ],
    "b_title":[
      "Re-Embeddings of Special Border Basis Schemes"
    ],
    "b_abstract":[
      "Border basis schemes are open subschemes of the Hilbert scheme of $\\mu$\npoints in an affine space $\\mathbb{A}^n$. They have easily describable systems\nof generators of their vanishing ideals for a natural embedding into a large\naffine space $\\mathbb{A}^{\\mu\\nu}$. Here we bring together several techniques\nfor re-embedding affine schemes into lower dimensional spaces which we\ndeveloped in the last years. We study their efficacy for some special types of\nborder basis schemes such as MaxDeg border basis schemes, L-shape and\nsimplicial border basis schemes, as well as planar border basis schemes. A\nparticular care is taken to make these re-embeddings efficiently computable and\nto check when we actually get an isomorphism with $\\mathbb{A}^{n\\mu}$, i.e.,\nwhen the border basis scheme is an affine cell."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.10796"
    ],
    "c_title":[
      "Dynamic Trend Fusion Module for Traffic Flow Prediction"
    ],
    "c_abstract":[
      "Accurate traffic flow prediction is essential for applications like transport\nlogistics but remains challenging due to complex spatio-temporal correlations\nand non-linear traffic patterns. Existing methods often model spatial and\ntemporal dependencies separately, failing to effectively fuse them. To overcome\nthis limitation, the Dynamic Spatial-Temporal Trend Transformer DST2former is\nproposed to capture spatio-temporal correlations through adaptive embedding and\nto fuse dynamic and static information for learning multi-view dynamic features\nof traffic networks. The approach employs the Dynamic Trend Representation\nTransformer (DTRformer) to generate dynamic trends using encoders for both\ntemporal and spatial dimensions, fused via Cross Spatial-Temporal Attention.\nPredefined graphs are compressed into a representation graph to extract static\nattributes and reduce redundancy. Experiments on four real-world traffic\ndatasets demonstrate that our framework achieves state-of-the-art performance."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-936",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11960"
    ],
    "b_title":[
      "Consider What Humans Consider: Optimizing Commit Message Leveraging\n  Contexts Considered By Human"
    ],
    "b_abstract":[
      "Commit messages are crucial in software development, supporting maintenance\ntasks and communication among developers. While Large Language Models (LLMs)\nhave advanced Commit Message Generation (CMG) using various software contexts,\nsome contexts developers consider to write high-quality commit messages are\noften missed by CMG techniques and can't be easily retrieved or even retrieved\nat all by automated tools. To address this, we propose Commit Message\nOptimization (CMO), which enhances human-written messages by leveraging LLMs\nand search-based optimization. CMO starts with human-written messages and\niteratively improves them by integrating key contexts and feedback from\nexternal evaluators. Our extensive evaluation shows CMO generates commit\nmessages that are significantly more Rational, Comprehensive, and Expressive\nwhile outperforming state-of-the-art CMG methods and human messages 40.3% to\n78.4% of the time. Moreover, CMO can support existing CMG techniques to further\nimprove message quality and generate high-quality messages when the\nhuman-written ones are left blank."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02794"
    ],
    "c_title":[
      "Social hierarchy shapes foraging decisions"
    ],
    "c_abstract":[
      "Social foraging is a widespread form of animal foraging in which groups of\nindividuals coordinate their decisions to exploit resources in the environment.\nAnimals show a variety of social structures from egalitarian to hierarchical.\nIn this study, we examine how different forms of social hierarchy shape\nforaging decisions. We developed a mechanistic analytically tractable model to\nstudy the underlying processes of social foraging, tying the microscopic\nindividual to the macroscopic group levels. Based on a stochastic evidence\naccumulation framework, we developed a model of patch-leaving decisions in a\nlarge hierarchical group with leading and following individuals. Across a\nvariety of information sharing mechanisms, we were able to analytically\nquantify emergent collective dynamics. We found that follower-leader dynamics\nthrough observations of leader movements or through counting the number of\nindividuals in a patch confers, for most conditions, a benefit for the\nfollowing individuals by increasing their accuracy in inferring patch richness.\nOn the other hand, misinformation, through the communication of false beliefs\nabout food rewards or patch quality, shows to be detrimental to following\nindividuals, but paradoxically may lead to increased group cohesion. In an era\nwhere there is a huge amount of animal foraging data collected, our model\nprovides a systematic way to conceptualize and understand those data by\nuncovering hidden mechanisms underlying social foraging decisions."
    ],
    "c_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-937",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.14229"
    ],
    "b_title":[
      "On the multi-$\\mathbf{q}$ characteristics of magnetic ground states of\n  honeycomb cobalt oxides"
    ],
    "b_abstract":[
      "The Kitaev honeycomb model has received significant attention for its exactly\nsolvable quantum spin liquid ground states and fractionalized excitations. For\nrealizing the model, layered cobalt oxides have been considered a promising\nplatform. Yet, in contrast to the conventional wisdom about single-$\\mathbf{q}$\nzigzag magnetic order inferred from previous studies of the Na$_2$IrO$_3$ and\n$\\alpha$-RuCl$_3$ candidate materials, recent experiments on two of the\nrepresentative honeycomb cobalt oxides, hexagonal Na$_2$Co$_2$TeO$_6$ and\nmonoclinic Na$_3$Co$_2$SbO$_6$, have uncovered evidence for more complex\nmulti-$\\mathbf{q}$ variants of the zigzag order. This review surveys on\nexperimental strategies to distinguish between single- and multi-$\\mathbf{q}$\norders, along with the crystallographic symmetries of the cobalt oxides in\ncomparison to the previously studied systems. General formation mechanism of\nmulti-$\\mathbf{q}$ order is also briefly discussed. The goal is to provide some\nrationales for examining the relevance of multi-$\\mathbf{q}$ order in the\nhoneycomb cobalt oxides, along with its implications on the microscopic model\nof these intriguing quantum magnets."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.18698"
    ],
    "c_title":[
      "Human Re-ID Meets LVLMs: What can we expect?"
    ],
    "c_abstract":[
      "Large vision-language models (LVLMs) have been regarded as a breakthrough\nadvance in an astoundingly variety of tasks, from content generation to virtual\nassistants and multimodal search or retrieval. However, for many of these\napplications, the performance of these methods has been widely criticized,\nparticularly when compared with state-of-the-art methods and technologies in\neach specific domain. In this work, we compare the performance of the leading\nlarge vision-language models in the human re-identification task, using as\nbaseline the performance attained by state-of-the-art AI models specifically\ndesigned for this problem. We compare the results due to ChatGPT-4o,\nGemini-2.0-Flash, Claude 3.5 Sonnet, and Qwen-VL-Max to a baseline ReID\nPersonViT model, using the well-known Market1501 dataset. Our evaluation\npipeline includes the dataset curation, prompt engineering, and metric\nselection to assess the models' performance. Results are analyzed from many\ndifferent perspectives: similarity scores, classification accuracy, and\nclassification metrics, including precision, recall, F1 score, and area under\ncurve (AUC). Our results confirm the strengths of LVLMs, but also their severe\nlimitations that often lead to catastrophic answers and should be the scope of\nfurther research. As a concluding remark, we speculate about some further\nresearch that should fuse traditional and LVLMs to combine the strengths from\nboth families of techniques and achieve solid improvements in performance."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-938",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.08224"
    ],
    "b_title":[
      "HRAvatar: High-Quality and Relightable Gaussian Head Avatar"
    ],
    "b_abstract":[
      "Reconstructing animatable and high-quality 3D head avatars from monocular\nvideos, especially with realistic relighting, is a valuable task. However, the\nlimited information from single-view input, combined with the complex head\nposes and facial movements, makes this challenging. Previous methods achieve\nreal-time performance by combining 3D Gaussian Splatting with a parametric head\nmodel, but the resulting head quality suffers from inaccurate face tracking and\nlimited expressiveness of the deformation model. These methods also fail to\nproduce realistic effects under novel lighting conditions. To address these\nissues, we propose HRAvatar, a 3DGS-based method that reconstructs\nhigh-fidelity, relightable 3D head avatars. HRAvatar reduces tracking errors\nthrough end-to-end optimization and better captures individual facial\ndeformations using learnable blendshapes and learnable linear blend skinning.\nAdditionally, it decomposes head appearance into several physical properties\nand incorporates physically-based shading to account for environmental\nlighting. Extensive experiments demonstrate that HRAvatar not only reconstructs\nsuperior-quality heads but also achieves realistic visual effects under varying\nlighting conditions."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.17103"
    ],
    "c_title":[
      "Directional propagation of quantum Hall viscous fluid by nano-structural\n  engineering"
    ],
    "c_abstract":[
      "We present a microscopic theory of the viscous electron fluid in the quantum\nHall state based on the nonequilibrium Green's function method and the von\nNeumann lattice representation. This approach permits the formulation of\nhydrodynamic equations in the strong field regime that accommodates arbitrary\nboundary conditions. We demonstrate nonreciprocal transport resulting from the\ninterplay between magnetic field-induced viscosity and device geometry in a\nnotched system. Our results will offer a powerful tool for studying the\nnonperturbative effects of magnetic fields on electron viscous fluids."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-939",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14943"
    ],
    "b_title":[
      "3D Engine-ready Photorealistic Avatars via Dynamic Textures"
    ],
    "b_abstract":[
      "As the digital and physical worlds become more intertwined, there has been a\nlot of interest in digital avatars that closely resemble their real-world\ncounterparts. Current digitization methods used in 3D production pipelines\nrequire costly capture setups, making them impractical for mass usage among\ncommon consumers. Recent academic literature has found success in\nreconstructing humans from limited data using implicit representations (e.g.,\nvoxels used in NeRFs), which are able to produce impressive videos. However,\nthese methods are incompatible with traditional rendering pipelines, making it\ndifficult to use them in applications such as games. In this work, we propose\nan end-to-end pipeline that builds explicitly-represented photorealistic 3D\navatars using standard 3D assets. Our key idea is the use of\ndynamically-generated textures to enhance the realism and visually mask\ndeficiencies in the underlying mesh geometry. This allows for seamless\nintegration with current graphics pipelines while achieving comparable visual\nquality to state-of-the-art 3D avatar generation methods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.03350"
    ],
    "c_title":[
      "Optimal Task Order for Continual Learning of Multiple Tasks"
    ],
    "c_abstract":[
      "Continual learning of multiple tasks remains a major challenge for neural\nnetworks. Here, we investigate how task order influences continual learning and\npropose a strategy for optimizing it. Leveraging a linear teacher-student model\nwith latent factors, we derive an analytical expression relating task\nsimilarity and ordering to learning performance. Our analysis reveals two\nprinciples that hold under a wide parameter range: (1) tasks should be arranged\nfrom the least representative to the most typical, and (2) adjacent tasks\nshould be dissimilar. We validate these rules on both synthetic data and\nreal-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100),\ndemonstrating consistent performance improvements in both multilayer\nperceptrons and convolutional neural networks. Our work thus presents a\ngeneralizable framework for task-order optimization in task-incremental\ncontinual learning."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-940",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08043"
    ],
    "b_title":[
      "PolyLUT: Ultra-low Latency Polynomial Inference with Hardware-Aware\n  Structured Pruning"
    ],
    "b_abstract":[
      "Standard deep neural network inference involves the computation of\ninterleaved linear maps and nonlinear activation functions. Prior work for\nultra-low latency implementations has hardcoded these operations inside FPGA\nlookup tables (LUTs). However, FPGA LUTs can implement a much greater variety\nof functions. In this paper, we propose a novel approach to training DNNs for\nFPGA deployment using multivariate polynomials as the basic building block. Our\nmethod takes advantage of the flexibility offered by the soft logic, hiding the\npolynomial evaluation inside the LUTs with minimal overhead. By using\npolynomial building blocks, we achieve the same accuracy using considerably\nfewer layers of soft logic than by using linear functions, leading to\nsignificant latency and area improvements. LUT-based implementations also face\na significant challenge: the LUT size grows exponentially with the number of\ninputs. Prior work relies on a priori fixed sparsity, with results heavily\ndependent on seed selection. To address this, we propose a structured pruning\nstrategy using a bespoke hardware-aware group regularizer that encourages a\nparticular sparsity pattern that leads to a small number of inputs per neuron.\nWe demonstrate the effectiveness of PolyLUT on three tasks: network intrusion\ndetection, jet identification at the CERN Large Hadron Collider, and MNIST."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.17052"
    ],
    "c_title":[
      "Low-temperature magnetic behaviour on the triangular lattice in\n  hexagonal Ba$_3$Tb(BO$_3$)$_3$"
    ],
    "c_abstract":[
      "The hexagonal polymorph of Ba$_3$Tb(BO$_3$)$_3$ contains Tb$^{3+}$ ions on a\nquasi-2D triangular lattice, resulting in geometric magnetic frustration.\nPowder samples of Ba$_3$Tb(BO$_3$)$_3$ have been investigated using specific\nheat, powder neutron diffraction (PND), inelastic neutron scattering (INS) and\nmuon-spin relaxation spectroscopy ($\\mu$SR). No long-range magnetic ordering is\nobserved down to the lowest measured temperatures of 75 mK in PND and specific\nheat data and 1.5 K in the $\\mu$SR data. Modelling the INS spectrum using a\npoint charge model suggests that the ground state is a singlet with a low-lying\ndoublet on each of the two crystallographically independent Tb$^{3+}$ sites and\nthat both the Tb ions display weak XY single-ion anisotropy."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-941",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.05312"
    ],
    "b_title":[
      "Unveiling structure-property correlations in ferroelectric\n  $Hf_{0.5}Zr_{0.5}O_2$ films using variational autoencoders"
    ],
    "b_abstract":[
      "While $Hf_{0.5}Zr_{0.5}O_2$ (HZO) thin films hold significant promise for\nmodern nanoelectronic devices, a comprehensive understanding of the interplay\nbetween their polycrystalline structure and electrical properties remains\nelusive. Here, we present a novel framework combining phase-field (PF) modeling\nwith Variational Autoencoders (VAEs) to uncover structure-property correlations\nin polycrystalline HZO. Leveraging PF simulations, we constructed a\nhigh-fidelity dataset of $P-V$ loops by systematically varying critical\nmaterial parameters, including grain size, polar grain fraction, and\ncrystalline orientation. The VAEs effectively encoded hysteresis loops into a\nlow-dimensional latent space, capturing electrical properties while\ndisentangling complex material parameters interdependencies. We further\ndemonstrate a VAE-based inverse design approach to optimize $P-V$ loop\nfeatures, enabling the tailored design of device-specific key performance\nindicators (KPIs), including coercive field, remanent polarization, and loop\narea. The proposed approach offers a pathway to systematically explore and\noptimize the material design space for ferroelectric nanoelectronics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.08985"
    ],
    "c_title":[
      "Channel Estimation for Rydberg Atomic Receivers"
    ],
    "c_abstract":[
      "The rapid development of the quantum technology presents huge opportunities\nfor 6G communications. Leveraging the quantum properties of highly excited\nRydberg atoms, Rydberg atom-based antennas present distinct advantages, such as\nhigh sensitivity, broad frequency range, and compact size, over traditional\nantennas. To realize efficient precoding, accurate channel state information is\nessential. However, due to the distinct characteristics of atomic receivers,\ntraditional channel estimation algorithms developed for conventional receivers\nare no longer applicable. To this end, we propose a novel channel estimation\nalgorithm based on projection gradient descent (PGD), which is applicable to\nboth one-dimensional (1D) and twodimensional (2D) arrays. Simulation results\nare provided to show the effectiveness of our proposed channel estimation\nmethod."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-942",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18852"
    ],
    "b_title":[
      "Data-Driven and Theory-Guided Pseudo-Spectral Seismic Imaging Using Deep\n  Neural Network Architectures"
    ],
    "b_abstract":[
      "Full Waveform Inversion (FWI) reconstructs high-resolution subsurface models\nvia multi-variate optimization but faces challenges with solver selection and\ndata availability. Deep Learning (DL) offers a promising alternative, bridging\ndata-driven and physics-based methods. While FWI in DL has been explored in the\ntime domain, the pseudo-spectral approach remains underutilized, despite its\nsuccess in classical FWI.\n  This thesis integrates pseudo-spectral FWI into DL, formulating both\ndata-driven and theory-guided approaches using Deep Neural Networks (DNNs) and\nRecurrent Neural Networks (RNNs). These methods were theoretically derived,\ntested on synthetic and Marmousi datasets, and compared with deterministic and\ntime-domain approaches.\n  Results show that data-driven pseudo-spectral DNNs outperform classical FWI\nin deeper and over-thrust regions due to their global approximation capability.\nTheory-guided RNNs yield greater accuracy, with lower error and better fault\nidentification. While DNNs excel in velocity contrast recovery, RNNs provide\nsuperior edge definition and stability in shallow and deep sections.\n  Beyond enhancing FWI performance, this research identifies broader\napplications of DL-based inversion and outlines future directions for these\nframeworks."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.00229"
    ],
    "c_title":[
      "Armijo Line-search Makes (Stochastic) Gradient Descent Go Fast"
    ],
    "c_abstract":[
      "Armijo line-search (Armijo-LS) is a standard method to set the step-size for\ngradient descent (GD). For smooth functions, Armijo-LS alleviates the need to\nknow the global smoothness constant $L$ and adapts to the local smoothness,\nenabling GD to converge faster. However, existing theoretical analyses of GD\nwith Armijo-LS (GD-LS) do not characterize this fast convergence. We show that\nif the objective function satisfies a certain non-uniform smoothness condition,\nGD-LS converges provably faster than GD with a constant $1\/L$ step-size\n(denoted as GD(1\/L)). Our results imply that for convex losses corresponding to\nlogistic regression and multi-class classification, GD-LS can converge to the\noptimum at a linear rate and, hence, improve over the sublinear convergence of\nGD(1\/L). Furthermore, for non-convex losses satisfying gradient domination (for\nexample, those corresponding to the softmax policy gradient in RL or\ngeneralized linear models with a logistic link function), GD-LS can match the\nfast convergence of algorithms tailored for these specific settings. Finally,\nwe prove that under the interpolation assumption, for convex losses, stochastic\nGD with a stochastic line-search can match the fast convergence of GD-LS."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-943",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11290"
    ],
    "b_title":[
      "EmoAgent: Multi-Agent Collaboration of Plan, Edit, and Critic, for\n  Affective Image Manipulation"
    ],
    "b_abstract":[
      "Affective Image Manipulation (AIM) aims to alter an image's emotional impact\nby adjusting multiple visual elements to evoke specific feelings.Effective AIM\nis inherently complex, necessitating a collaborative approach that involves\nidentifying semantic cues within source images, manipulating these elements to\nelicit desired emotional responses, and verifying that the combined adjustments\nsuccessfully evoke the target emotion.To address these challenges, we introduce\nEmoAgent, the first multi-agent collaboration framework for AIM. By emulating\nthe cognitive behaviors of a human painter, EmoAgent incorporates three\nspecialized agents responsible for planning, editing, and critical evaluation.\nFurthermore, we develop an emotion-factor knowledge retriever, a\ndecision-making tree space, and a tool library to enhance EmoAgent's\neffectiveness in handling AIM. Experiments demonstrate that the proposed\nmulti-agent framework outperforms existing methods, offering more reasonable\nand effective emotional expression."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.09593"
    ],
    "c_title":[
      "Evolution of exchange rate regime: Impact of macroeconomy of Bangladesh"
    ],
    "c_abstract":[
      "Bangladesh has experienced two distinct exchange rate regimes: a fixed\nexchange rate system from January 1972 to May 2003 and a floating one since\nJune 2003. After adopting the floating exchange rate regime, Bangladesh\npositively impacted macroeconomic development. The key macroeconomic variables\nconsidered include foreign reserves, worker's remittances, and export proceeds.\nHowever, ongoing challenges for the country include the depreciating trend of\nthe local currency within a highly inflationary economy. This paper aims to\nevaluate macroeconomic performance across the two regimes and analyze the\ncurrent currency situation in Bangladesh."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-944",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04003"
    ],
    "b_title":[
      "Understanding and Detecting Compatibility Issues in Android Auto Apps"
    ],
    "b_abstract":[
      "Mobile platforms now power not only smartphones but also in-vehicle systems\nlike Android Auto and CarPlay. Despite an ecosystem of over 3.5 million Android\napps and more than 200 million Android Auto-compatible vehicles, only a few\nhundred apps have been adapted for automotive use. To better understand this\ngap, we studied 147 reported issues related to Android Auto and identified\ntheir root causes. We found that more than 70% of issues result from UI\nincompatibilities, 24% from media playback errors, and around 5% from failures\nin voice command handling, showing a lack of effective tools for developers. We\nintroduce CarCompat, a static analysis framework that detects compatibility\nproblems in Android Auto apps. CarCompat constructs a Car-Control Flow Graph\n(CCFG) to capture interactions among app components, lifecycle methods, and\nplatform-specific callbacks. It applies specialized checkers to detect UI\nviolations, media playback errors, and issues with voice command handling. We\nevaluated CarCompat on a dataset of 54 Android Auto apps and detected 25 new\nissues, 4 of which were confirmed by developers, and 2 developers have already\nreleased their fixes. The results show that CarCompat helps developers identify\nand fix compatibility issues, improving the in-vehicle experience."
    ],
    "b_categories":[
      [
        "cs.PL",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.15341"
    ],
    "c_title":[
      "The Maximum Theoretical Ground Speed of the Wheeled Vehicle"
    ],
    "c_abstract":[
      "In this paper, we propose one possible theoretical limit on the maximum\nground speed of wheeled vehicles."
    ],
    "c_categories":[
      [
        "math.OC",
        "physics.class-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-945",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.04901"
    ],
    "b_title":[
      "On the Difficulty of Constructing a Robust and Publicly-Detectable\n  Watermark"
    ],
    "b_abstract":[
      "This work investigates the theoretical boundaries of creating\npublicly-detectable schemes to enable the provenance of watermarked imagery.\nMetadata-based approaches like C2PA provide unforgeability and\npublic-detectability. ML techniques offer robust retrieval and watermarking.\nHowever, no existing scheme combines robustness, unforgeability, and\npublic-detectability. In this work, we formally define such a scheme and\nestablish its existence. Although theoretically possible, we find that at\npresent, it is intractable to build certain components of our scheme without a\nleap in deep learning capabilities. We analyze these limitations and propose\nresearch directions that need to be addressed before we can practically realize\nrobust and publicly-verifiable provenance."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.09181"
    ],
    "c_title":[
      "Galactic Isolated Stellar-Mass Black Holes with the Magnetospheric Spark\n  Gap as Possible GeV-TeV Gamma-ray Unidentified Sources"
    ],
    "c_abstract":[
      "Billions of isolated stellar-mass black holes (IBHs) are thought to wander\nthrough the interstellar medium (ISM) in the Galaxy, yet only one has been\ndetected. IBHs embedded in ISM would accrete gas via Bondi-Hoyle-Littleton\naccretion, and with efficient magnetic flux accumulation, the magnetosphere\nwould be formed in the vicinity of IBHs. We explore the detectability of such\nIBHs through high-energy gamma rays from spark gaps in their magnetospheres\nbased on our recent numerical simulation. The gap gamma rays can be bright at\nthe GeV-TeV energies when IBHs are in the dense ISM. About $10^3$ and $10$ IBHs\nmight be contained in unidentified objects of the $\\textit{Fermi}$ Large Area\nTelescope and the High Energy Stereoscopic System, respectively. A future\nGalactic plane survey by the Cherenkov Telescope Array Observatory would lead\nto $\\sim10^2$ detections. We also evaluate the combined gamma-ray emission of\nIBHs in the Galaxy and find that the IBHs may contribute to the Galactic\ndiffuse gamma rays. IBHs will emit optical and X-ray photons from their\naccretion disk as counterparts, potentially useful for identifying candidates."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-946",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.07616"
    ],
    "b_title":[
      "The Ingenuity Mars Helicopter Specified and Analyzed with the Real-time\n  Mode-aware Dataflow Model"
    ],
    "b_abstract":[
      "Ingenuity is an autonomous Cyber-Pysical System (CPS) that has successfully\ncompleted more than 70 flights over Mars between 2021 and 2024. Ensuring the\nsafety of its mission is paramount, as any failure could result in catastrophic\neconomic damage and significant financial losses. Dataflow Models of\nComputation and Communication (DF MoCCs) serve as a formal framework for\nspecifying and analyzing the timing behavior of such CPSs. In particular, the\nReal-time Mode-aware Dataflow (RMDF) model is highly suitable to specify and\nanalyze real-time and mode-dependent Cyber-Physical Systems (CPSs) like\nIngenuity. This paper showcases the application of RMDF for the specification\nand analysis of Ingenuity. We propose a dataflow specification of Ingenuity,\nanalyze its timing behavior, and provide a feasibility test. Finally, we\nproposed a plausible explanation of the timing anomaly that occurred during the\nsixth flight of Ingenuity."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.13793"
    ],
    "c_title":[
      "The link between Microstructural Heterogeneity, Diffusivity, and\n  Hydrogen Embrittlement"
    ],
    "c_abstract":[
      "Green hydrogen is likely to play a major role in decarbonising the aviation\nindustry. It is crucial to understand the effects of microstructure on hydrogen\nredistribution, which may be implicated in the embrittlement of candidate fuel\nsystem metals. We have developed a stochastic multiscale finite element\nmodelling framework that integrates micromechanical and hydrogen transport\nmodels, such that the dominant microstructural effects can be efficiently\naccounted for at millimetre length scales. Our results show that microstructure\nhas a significant effect on hydrogen localisation in elastically anisotropic\nmaterials, which exhibit an interesting interplay between microstructure and\nmillimetre-scale hydrogen redistribution at various loading rates. Considering\n316L stainless steel and nickel, a direct comparison of model predictions\nagainst experimental hydrogen embrittlement data reveals that the reported\nsensitivity to loading rate is strongly linked with rate-dependent grain scale\ndiffusion. These findings highlight the need to incorporate microstructural\ncharacteristics in the design of hydrogen resistant materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-947",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05682"
    ],
    "b_title":[
      "Task-oriented Uncertainty Collaborative Learning for Label-Efficient\n  Brain Tumor Segmentation"
    ],
    "b_abstract":[
      "Multi-contrast magnetic resonance imaging (MRI) plays a vital role in brain\ntumor segmentation and diagnosis by leveraging complementary information from\ndifferent contrasts. Each contrast highlights specific tumor characteristics,\nenabling a comprehensive understanding of tumor morphology, edema, and\npathological heterogeneity. However, existing methods still face the challenges\nof multi-level specificity perception across different contrasts, especially\nwith limited annotations. These challenges include data heterogeneity,\ngranularity differences, and interference from redundant information. To\naddress these limitations, we propose a Task-oriented Uncertainty Collaborative\nLearning (TUCL) framework for multi-contrast MRI segmentation. TUCL introduces\na task-oriented prompt attention (TPA) module with intra-prompt and\ncross-prompt attention mechanisms to dynamically model feature interactions\nacross contrasts and tasks. Additionally, a cyclic process is designed to map\nthe predictions back to the prompt to ensure that the prompts are effectively\nutilized. In the decoding stage, the TUCL framework proposes a dual-path\nuncertainty refinement (DUR) strategy which ensures robust segmentation by\nrefining predictions iteratively. Extensive experimental results on limited\nlabeled data demonstrate that TUCL significantly improves segmentation accuracy\n(88.2\\% in Dice and 10.853 mm in HD95). It shows that TUCL has the potential to\nextract multi-contrast information and reduce the reliance on extensive\nannotations. The code is available at:\nhttps:\/\/github.com\/Zhenxuan-Zhang\/TUCL_BrainSeg."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.05958"
    ],
    "c_title":[
      "Simplicial effects and weakly associative partial groups"
    ],
    "c_abstract":[
      "In this paper, we introduce a new category of simplicial effects that extends\nthe categories of effect algebras and their multi-object counterpart, effect\nalgebroids. Our approach is based on relaxing the associativity condition\nsatisfied by effect algebras and, more generally, partial monoids. Within this\nframework, simplicial effects and weakly associative partial groups arise as\ntwo extreme cases in the category of weak partial monoids. Our motivation is to\ncapture simplicial structures from the theory of simplicial distributions and\nmeasurements that behave like effects."
    ],
    "c_categories":[
      [
        "math.CT",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-948",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09434"
    ],
    "b_title":[
      "Redistribute Ensemble Training for Mitigating Memorization in Diffusion\n  Models"
    ],
    "b_abstract":[
      "Diffusion models, known for their tremendous ability to generate high-quality\nsamples, have recently raised concerns due to their data memorization behavior,\nwhich poses privacy risks. Recent methods for memory mitigation have primarily\naddressed the issue within the context of the text modality in cross-modal\ngeneration tasks, restricting their applicability to specific conditions. In\nthis paper, we propose a novel method for diffusion models from the perspective\nof visual modality, which is more generic and fundamental for mitigating\nmemorization. Directly exposing visual data to the model increases memorization\nrisk, so we design a framework where models learn through proxy model\nparameters instead. Specially, the training dataset is divided into multiple\nshards, with each shard training a proxy model, then aggregated to form the\nfinal model. Additionally, practical analysis of training losses illustrates\nthat the losses for easily memorable images tend to be obviously lower. Thus,\nwe skip the samples with abnormally low loss values from the current mini-batch\nto avoid memorizing. However, balancing the need to skip memorization-prone\nsamples while maintaining sufficient training data for high-quality image\ngeneration presents a key challenge. Thus, we propose IET-AGC+, which\nredistributes highly memorizable samples between shards, to mitigate these\nsamples from over-skipping. Furthermore, we dynamically augment samples based\non their loss values to further reduce memorization. Extensive experiments and\nanalysis on four datasets show that our method successfully reduces memory\ncapacity while maintaining performance. Moreover, we fine-tune the pre-trained\ndiffusion models, e.g., Stable Diffusion, and decrease the memorization score\nby 46.7\\%, demonstrating the effectiveness of our method. Code is available in:\nhttps:\/\/github.com\/liuxiao-guan\/IET_AGC."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.12179"
    ],
    "c_title":[
      "Block Adaptive Progressive Type-II Censored Sampling for the Inverted\n  Exponentiated Pareto Distribution: Parameter Inference and Reliability\n  Assessment"
    ],
    "c_abstract":[
      "This article explores the estimation of unknown parameters and reliability\ncharacteristics under the assumption that the lifetimes of the testing units\nfollow an Inverted Exponentiated Pareto (IEP) distribution. Here, both point\nand interval estimates are calculated by employing the classical maximum\nlikelihood and a pivotal estimation methods. Also, existence and uniqueness of\nthe maximum likelihood estimates are verified. Further, asymptotic confidence\nintervals are derived by using the asymptotic normality property of the maximum\nlikelihood estimator. Moreover, generalized confidence intervals are obtained\nby utilizing the pivotal quantities. Additionally, some mathematical\ndevelopments of the IEP distribution are discussed based on the concept of\norder statistics. Furthermore, all the estimations are performed on the basis\nof the block censoring procedure, where an adaptive progressive Type-II\ncensoring is employed to every block. In this regard, the performances of two\nestimation methods, namely maximum likelihood estimation and pivotal\nestimation, is evaluated and compared through a simulation study. Finally, a\nreal data is illustrated to demonstrate the flexibility of the proposed IEP\nmodel."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-949",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.06062"
    ],
    "b_title":[
      "Personalized Language Model Learning on Text Data Without User\n  Identifiers"
    ],
    "b_abstract":[
      "In many practical natural language applications, user data are highly\nsensitive, requiring anonymous uploads of text data from mobile devices to the\ncloud without user identifiers. However, the absence of user identifiers\nrestricts the ability of cloud-based language models to provide personalized\nservices, which are essential for catering to diverse user needs. The trivial\nmethod of replacing an explicit user identifier with a static user embedding as\nmodel input still compromises data anonymization. In this work, we propose to\nlet each mobile device maintain a user-specific distribution to dynamically\ngenerate user embeddings, thereby breaking the one-to-one mapping between an\nembedding and a specific user. We further theoretically demonstrate that to\nprevent the cloud from tracking users via uploaded embeddings, the local\ndistributions of different users should either be derived from a linearly\ndependent space to avoid identifiability or be close to each other to prevent\naccurate attribution. Evaluation on both public and industrial datasets using\ndifferent language models reveals a remarkable improvement in accuracy from\nincorporating anonymous user embeddings, while preserving real-time inference\nrequirement."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08800"
    ],
    "c_title":[
      "Diophantine enumeration of Dynkin friezes"
    ],
    "c_abstract":[
      "We prove the Fontaine-Plamondon conjecture and show that there are precisely\n$4400$ and $26952$ positive integral $E_7$-friezes and $E_8$-friezes\nrespectively, completing the enumerative classification of all positive\nintegral friezes of Dynkin type. We also give new Diophantine proofs of the\nenumeration theorems for friezes of all other Dynkin types, which were\npreviously proved using discrete geometry, algebraic combinatorics, and the\ntheory of cluster algebras. In general, we count Dynkin friezes of rank $n$ by\ndetermining the positive integral points on certain $n$-dimensional affine\nvarieties with infinitely many integral points."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.NT",
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-950",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06496"
    ],
    "b_title":[
      "Modeling Nonlinear Optics with the Transfer Matrix Method"
    ],
    "b_abstract":[
      "The Transfer Matrix Method (TMM) is a widely used technique for modeling\nlinear propagation of electromagnetic waves through stratified layered media.\nHowever, since its extension to inhomogeneous and nonlinear systems is not\nstraightforward, much more computationally demanding methods such as\nFinite-difference time-domain (FDTD) or Method of lines (MoL) are typically\nused. In this work, we extend the TMM framework to incorporate the effects of\nnonlinearity. We consider the case when strong coupling between excitons\n(electron-hole pairs) and photons leads to the formation of exciton-polaritons.\nThis extension is crucial for accurately simulating the behavior of light in\npolariton microcavities, where nonlinearities arising from exciton-exciton\ninteractions play a key role. We perform efficient simulations of light\ntransmission and reflection in a multidimensional system using the plane wave\nbasis. Additionally, we compare our extended TMM approach with the\nstate-of-the-art admittance transfer method, and highlight the computational\nadvantage of extended TMM for large-scale systems. The extended TMM not only\nprovides a robust and computationally efficient numerical framework, but also\npaves the way for the development of future low-power nonlinear optical\ndevices, polariton-based photonic circuits, and quantum photonic technologies."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.11894"
    ],
    "c_title":[
      "Black Older Adults' Perception of Using Voice Assistants to Enact a\n  Medical Recovery Curriculum"
    ],
    "c_abstract":[
      "The use of interactive voice assistants (IVAs) in healthcare provides an\navenue to address diverse health needs, such as gaps in the medical recovery\nperiod for older adult patients who have recently experienced serious illness.\nBy using a voice-assisted medical recovery curriculum, discharged patients can\nreceive ongoing support as they recover. However, there exist significant\nmedical and technology disparities among older adults, particularly among Black\nolder adults. We recruited 26 Black older adults to participate in the design\nprocess of an IVA-enacted medical recovery curriculum by providing feedback\nduring the early stages of design. Lack of cultural relevancy, accountability,\nprivacy concerns, and stigmas associated with aging and disability made\nparticipants reluctant to engage with the technology unless in a position of\nextreme need. This study underscored the need for Black cultural\nrepresentation, whether it regarded the IVA's accent, the types of media\nfeatured, or race-specific medical advice, and the need for strategies to\naddress participants' concerns and stigmas. Participants saw the value in the\ncurriculum for those who did not have caregivers and deliberated about the\ntrade-offs the technology presented. We discuss tensions surrounding inclusion\nand representation and conclude by showing how we enacted the lessons from this\nstudy in future design plans."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-951",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.01940"
    ],
    "b_title":[
      "Toward a Low-Cost Perception System in Autonomous Vehicles: A Spectrum\n  Learning Approach"
    ],
    "b_abstract":[
      "We present a cost-effective new approach for generating denser depth maps for\nAutonomous Driving (AD) and Autonomous Vehicles (AVs) by integrating the images\nobtained from deep neural network (DNN) 4D radar detectors with conventional\ncamera RGB images. Our approach introduces a novel pixel positional encoding\nalgorithm inspired by Bartlett's spatial spectrum estimation technique. This\nalgorithm transforms both radar depth maps and RGB images into a unified pixel\nimage subspace called the Spatial Spectrum, facilitating effective learning\nbased on their similarities and differences. Our method effectively leverages\nhigh-resolution camera images to train radar depth map generative models,\naddressing the limitations of conventional radar detectors in complex vehicular\nenvironments, thus sharpening the radar output. We develop spectrum estimation\nalgorithms tailored for radar depth maps and RGB images, a comprehensive\ntraining framework for data-driven generative models, and a camera-radar\ndeployment scheme for AV operation. Our results demonstrate that our approach\nalso outperforms the state-of-the-art (SOTA) by 27.95% in terms of\nUnidirectional Chamfer Distance (UCD)."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.12249"
    ],
    "c_title":[
      "Particle production from inhomogeneities: general metric perturbations"
    ],
    "c_abstract":[
      "We present universal formulas for particle production from gravitational\ninhomogeneities. In the massless limit the result is strikingly simple and\ncompletely determined by the two-point function of the energy-momentum tensor\nthat is fixed up to a constant - the central charge - for conformally coupled\nscalars, massless fermions and gauge fields. This result can be applied to any\nconformally coupled theory, weakly or strongly interacting, unifying previous\nderivations for fields of different spin and for scalar and tensor\nperturbations. We derive the results using the Schwinger method of 1PI\neffective action and through Bogoliubov transformations that allows to compute\nexclusive information on the distribution of particles. We then apply these\nresults to stochastic backgrounds of scalar and tensor perturbations that can\nbe generated by various phenomena such us inflationary perturbations and first\norder phase transitions. Differently from particle production usually\nconsidered in cosmology this mechanism allows for the production of massless\nfields. In particular the abundance induced by inhomogeneities can easily\nreproduce the dark matter abundance if scalar perturbations produced from\ninflation are enhanced at short scales."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-952",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02494"
    ],
    "b_title":[
      "Analyzing Similarity Metrics for Data Selection for Language Model\n  Pretraining"
    ],
    "b_abstract":[
      "Similarity between training examples is used to curate pretraining datasets\nfor language models by many methods -- for diversification and to select\nexamples similar to high-quality data. However, similarity is typically\nmeasured with off-the-shelf embedding models that are generic or trained for\ntasks such as retrieval. This paper introduces a framework to analyze the\nsuitability of embedding models specifically for data curation in the language\nmodel pretraining setting. We quantify the correlation between similarity in\nthe embedding space to similarity in pretraining loss between different\ntraining examples, and how diversifying in the embedding space affects\npretraining quality. We analyze a variety of embedding models in our framework,\nwith experiments using the Pile dataset for pretraining a 1.7B parameter\ndecoder-only language model. We find that the embedding models we consider are\nall useful for pretraining data curation. Moreover, a simple approach of\naveraging per-token embeddings proves to be surprisingly competitive with more\nsophisticated embedding models -- likely because the latter are not designed\nspecifically for pretraining data curation. Indeed, we believe our analysis and\nevaluation framework can serve as a foundation for the design of embedding\nmodels that specifically reason about similarity in pretraining datasets."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.02638"
    ],
    "c_title":[
      "Models of hypersurfaces and Bruhat-Tits buildings"
    ],
    "c_abstract":[
      "We propose a new approach to constructing semistable integral models of\nhypersurfaces over a discrete non-archimedian field $K$. For each stable\nhypersurface over $K$ we define a stability function on the Bruhat-Tits\nbuilding of ${\\rm PGL}(K)$ and show that its global minima correspond to\nsemistable hypersurface models over some extension of $K$. This extends work of\nKollar and of Elsenhans and Stoll on minimal hypersurface models. In the case\nof plane curves and residue characteristic zero, our results give a practical\nalgorithm for constructing a semistable model over a suitable extension field."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-953",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02717"
    ],
    "b_title":[
      "Astromer 2"
    ],
    "b_abstract":[
      "Foundational models have emerged as a powerful paradigm in deep learning\nfield, leveraging their capacity to learn robust representations from\nlarge-scale datasets and effectively to diverse downstream applications such as\nclassification. In this paper, we present Astromer 2 a foundational model\nspecifically designed for extracting light curve embeddings. We introduce\nAstromer 2 as an enhanced iteration of our self-supervised model for light\ncurve analysis. This paper highlights the advantages of its pre-trained\nembeddings, compares its performance with that of its predecessor, Astromer 1,\nand provides a detailed empirical analysis of its capabilities, offering deeper\ninsights into the model's representations. Astromer 2 is pretrained on 1.5\nmillion single-band light curves from the MACHO survey using a self-supervised\nlearning task that predicts randomly masked observations within sequences.\nFine-tuning on a smaller labeled dataset allows us to assess its performance in\nclassification tasks. The quality of the embeddings is measured by the F1 score\nof an MLP classifier trained on Astromer-generated embeddings. Our results\ndemonstrate that Astromer 2 significantly outperforms Astromer 1 across all\nevaluated scenarios, including limited datasets of 20, 100, and 500 samples per\nclass. The use of weighted per-sample embeddings, which integrate intermediate\nrepresentations from Astromer's attention blocks, is particularly impactful.\nNotably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset\ncompared to prior models, showcasing robust generalization to new datasets.\nThis enhanced performance, especially with minimal labeled data, underscores\nthe potential of Astromer 2 for more efficient and scalable light curve\nanalysis."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18659"
    ],
    "c_title":[
      "SAFL: Structure-Aware Personalized Federated Learning via\n  Client-Specific Clustering and SCSI-Guided Model Pruning"
    ],
    "c_abstract":[
      "Federated Learning (FL) enables clients to collaboratively train machine\nlearning models without sharing local data, preserving privacy in diverse\nenvironments. While traditional FL approaches preserve privacy, they often\nstruggle with high computational and communication overhead. To address these\nissues, model pruning is introduced as a strategy to streamline computations.\nHowever, existing pruning methods, when applied solely based on local data,\noften produce sub-models that inadequately reflect clients' specific tasks due\nto data insufficiency. To overcome these challenges, this paper introduces SAFL\n(Structure-Aware Federated Learning), a novel framework that enhances\npersonalized federated learning through client-specific clustering and Similar\nClient Structure Information (SCSI)-guided model pruning. SAFL employs a\ntwo-stage process: initially, it groups clients based on data similarities and\nuses aggregated pruning criteria to guide the pruning process, facilitating the\nidentification of optimal sub-models. Subsequently, clients train these pruned\nmodels and engage in server-based aggregation, ensuring tailored and efficient\nmodels for each client. This method significantly reduces computational\noverhead while improving inference accuracy. Extensive experiments demonstrate\nthat SAFL markedly diminishes model size and improves performance, making it\nhighly effective in federated environments characterized by heterogeneous data."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-954",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.09528"
    ],
    "b_title":[
      "SteROI-D: System Design and Mapping for Stereo Depth Inference on\n  Regions of Interest"
    ],
    "b_abstract":[
      "Machine learning algorithms have enabled high quality stereo depth estimation\nto run on Augmented and Virtual Reality (AR\/VR) devices. However, high energy\nconsumption across the full image processing stack prevents stereo depth\nalgorithms from running effectively on battery-limited devices. This paper\nintroduces SteROI-D, a full stereo depth system paired with a mapping\nmethodology. SteROI-D exploits Region-of-Interest (ROI) and temporal sparsity\nat the system level to save energy. SteROI-D's flexible and heterogeneous\ncompute fabric supports diverse ROIs. Importantly, we introduce a systematic\nmapping methodology to effectively handle dynamic ROIs, thereby maximizing\nenergy savings. Using these techniques, our 28nm prototype SteROI-D design\nachieves up to 4.35x reduction in total system energy compared to a baseline\nASIC."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.13203"
    ],
    "c_title":[
      "Safe and Efficient Robot Action Planning in the Presence of Unconcerned\n  Humans"
    ],
    "c_abstract":[
      "This paper proposes a robot action planning scheme that provides an efficient\nand probabilistically safe plan for a robot interacting with an unconcerned\nhuman -- someone who is either unaware of the robot's presence or unwilling to\nengage in ensuring safety. The proposed scheme is predictive, meaning that the\nrobot is required to predict human actions over a finite future horizon; such\npredictions are often inaccurate in real-world scenarios. One possible approach\nto reduce the uncertainties is to provide the robot with the capability of\nreasoning about the human's awareness of potential dangers. This paper\ndiscusses that by using a binary variable, so-called danger awareness\ncoefficient, it is possible to differentiate between concerned and unconcerned\nhumans, and provides a learning algorithm to determine this coefficient by\nobserving human actions. Moreover, this paper argues how humans rely on\npredictions of other agents' future actions (including those of robots in\nhuman-robot interaction) in their decision-making. It also shows that ignoring\nthis aspect in predicting human's future actions can significantly degrade the\nefficiency of the interaction, causing agents to deviate from their optimal\npaths. The proposed robot action planning scheme is verified and validated via\nextensive simulation and experimental studies on a LoCoBot WidowX-250."
    ],
    "c_categories":[
      [
        "cs.RO",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-955",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.11655"
    ],
    "b_title":[
      "Explainable Sentiment Analysis with DeepSeek-R1: Performance,\n  Efficiency, and Few-Shot Learning"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have significantly\nenhanced sentiment analysis capabilities. However, the trade-offs between model\nperformance, efficiency, and explainability of some latest models remain\nunderexplored. This study presents the first comprehensive evaluation of the\nDeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment\nanalysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We\nsystematically analyze their performance under few-shot prompting conditions,\nscaling up to 50-shot configurations to assess in-context learning\neffectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive\naccuracy, particularly in multi-class sentiment tasks, while offering enhanced\ninterpretability through its detailed reasoning process. Additionally, we\nhighlight the impact of increasing few-shot examples on model performance and\ndiscuss key trade-offs between explainability and computational efficiency."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.01762"
    ],
    "c_title":[
      "Dynamic wetting of concentrated granular suspensions"
    ],
    "c_abstract":[
      "Many materials, such as paints and inks used in applications like painting\nand 3D printing, are concentrated granular suspensions. In such systems, the\ncontact line dynamics and the internal structure of the suspension interact\nthrough shear-rate dependent viscosity and internal structural rearrangements.\nThe shear rate increases sharply near moving contact lines, profoundly\ninfluencing the non-Newtonian rheology of dense suspensions. Frictional\ncontacts become significant as particles approach each other, forming\nforce-carrying networks of contacts. While hydrodynamic solutions can describe\ndilute suspensions, their applicability near advancing contact lines in dense\nsuspensions remains unclear. This study explores such applicability by\nsystematically varying inter-particle interactions. We use silica suspensions\nin two refractive-index matched media: (i) aqueous 2,$2^{\\prime}$-thiodiethanol\n(weak interactions) and (ii) aqueous sodium thiocyanate solution (strong\ninteractions). The two samples vary substantially in their rheological\nresponse. Using astigmatism particle tracking velocimetry (APTV), we precisely\ntrack the 3D motion of tracer particles within the suspension. To observe the\ndrop over a long travel distance, we use a configuration consisting of a pinned\ndroplet on a moving substrate. We observe distinct behaviours depending on\nparticle interactions and the resulting suspension rheology. The more the\nparticle interactions play a role, i.e., the more pronounced the non-Newtonian\neffects, the stronger the measured flow profiles differ from the Newtonian\nsolution to the hydrodynamic equations. In case of the viscous suspension, a\nnotable deviation from Newtonian behaviour is observed. Conversely, the\nyield-stress suspension exhibits plug flow over the substrate, with\nNewtonian-like behaviour restricted to the yielded region near the substrate."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-956",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17425"
    ],
    "b_title":[
      "Introducing Visual Perception Token into Multimodal Large Language Model"
    ],
    "b_abstract":[
      "To utilize visual information, Multimodal Large Language Model (MLLM) relies\non the perception process of its vision encoder. The completeness and accuracy\nof visual perception significantly influence the precision of spatial\nreasoning, fine-grained understanding, and other tasks. However, MLLM still\nlacks the autonomous capability to control its own visual perception processes,\nfor example, selectively reviewing specific regions of an image or focusing on\ninformation related to specific object categories. In this work, we propose the\nconcept of Visual Perception Token, aiming to empower MLLM with a mechanism to\ncontrol its visual perception processes. We design two types of Visual\nPerception Tokens, termed the Region Selection Token and the Vision Re-Encoding\nToken. MLLMs autonomously generate these tokens, just as they generate text,\nand use them to trigger additional visual perception actions. The Region\nSelection Token explicitly identifies specific regions in an image that require\nfurther perception, while the Vision Re-Encoding Token uses its hidden states\nas control signals to guide additional visual perception processes. Extensive\nexperiments demonstrate the advantages of these tokens in handling spatial\nreasoning, improving fine-grained understanding, and other tasks. On average,\nthe introduction of Visual Perception Tokens improves the performance of a 2B\nmodel by 23.6\\%, increasing its score from 0.572 to 0.708, and even outperforms\na 7B parameter model by 13.4\\% (from 0.624). Please check out our repo\nhttps:\/\/github.com\/yu-rp\/VisualPerceptionToken"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19255"
    ],
    "c_title":[
      "Can RLHF be More Efficient with Imperfect Reward Models? A Policy\n  Coverage Perspective"
    ],
    "c_abstract":[
      "Sample efficiency is critical for online Reinforcement Learning from Human\nFeedback (RLHF). While existing works investigate sample-efficient online\nexploration strategies, the potential of utilizing misspecified yet relevant\nreward models to accelerate learning remains underexplored. This paper studies\nhow to transfer knowledge from those imperfect reward models in online RLHF. We\nstart by identifying a novel property of the KL-regularized RLHF objective:\n\\emph{a policy's ability to cover the optimal policy is captured by its\nsub-optimality}. Building on this insight, we propose a theoretical transfer\nlearning algorithm with provable benefits compared to standard online learning.\nOur approach achieves low regret in the early stage by quickly adapting to the\nbest available source reward models without prior knowledge of their quality,\nand over time, it attains an $\\tilde{O}(\\sqrt{T})$ regret bound\n\\emph{independent} of structural complexity measures. Inspired by our\ntheoretical findings, we develop an empirical algorithm with improved\ncomputational efficiency, and demonstrate its effectiveness empirically in\nsummarization tasks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-957",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03304"
    ],
    "b_title":[
      "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient\n  Zeroth-order LLM Fine-tuning"
    ],
    "b_abstract":[
      "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose \\textbf{Di}vergence-driven\n\\textbf{Z}eroth-\\textbf{O}rder (\\textbf{DiZO}) optimization. DiZO conducts\ndivergence-driven layer adaptation by incorporating projections to ZO updates,\ngenerating diverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48\\% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.18235"
    ],
    "c_title":[
      "Experimental Study of AM and PM Noise in Cascaded Amplifiers"
    ],
    "c_abstract":[
      "An experimental study of amplitude modulation and phase modulation noise\nspectra in cascaded amplifiers was carried out as a function of the number of\namplification stages and the input power. Flicker and white noise contributions\nwere determined, as well as effective noise figure from AM and PM noise spectra\nfrom small signal to large signal regimes. Simultaneous measurements of AM and\nPM noise were performed, and associated correlation was measured as a function\nof the offset frequency from the carrier. Measurements exhibited, in general,\nquite low AM PM correlation levels both in the flicker and white noise parts of\nthe spectrum. In some particular amplifier configurations, however,\nmeasurements showed some peaks in the correlation at some specific input power\nlevels in the transition zone, from a quasi-linear to strong compression. The\nresults show that the effective noise figure decreases with the number of\nstages for a given carrier output power level."
    ],
    "c_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-958",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.04049"
    ],
    "b_title":[
      "Neural Network Surrogate Model for Junction Temperature and Hotspot\n  Position in $3$D Multi-Layer High Bandwidth Memory (HBM) Chiplets under\n  Varying Thermal Conditions"
    ],
    "b_abstract":[
      "As the demand for computational power increases, high-bandwidth memory (HBM)\nhas become a critical technology for next-generation computing systems.\nHowever, the widespread adoption of HBM presents significant thermal management\nchallenges, particularly in multilayer through-silicon-via (TSV) stacked\nstructures under varying thermal conditions, where accurate prediction of\njunction temperature and hotspot position is essential during the early design.\nThis work develops a data-driven neural network model for the fast prediction\nof junction temperature and hotspot position in 3D HBM chiplets. The model,\ntrained with a data set of $13,494$ different combinations of thermal condition\nparameters, sampled from a vast parameter space characterized by\nhigh-dimensional combination (up to $3^{27}$), can accurately and quickly infer\nthe junction temperature and hotspot position for any thermal conditions in the\nparameter space. Moreover, it shows good generalizability for other thermal\nconditions not considered in the parameter space. The data set is constructed\nusing accurate finite element solvers. This method not only minimizes the\nreliance on costly experimental tests and extensive computational resources for\nfinite element analysis but also accelerates the design and optimization of\ncomplex HBM systems, making it a valuable tool for improving thermal management\nand performance in high-performance computing applications."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.18902"
    ],
    "c_title":[
      "Scalable Low-overhead Superconducting Non-local Coupler with\n  Exponentially Enhanced Connectivity"
    ],
    "c_abstract":[
      "Quantum error correction codes with non-local connections such as quantum\nlow-density parity-check (qLDPC) incur lower overhead and outperform surface\ncodes on large-scale devices. These codes are not applicable on current\nsuperconducting devices with nearest-neighbor connections. To rectify the\ndeficiency in connectivity of superconducting circuit system, we experimentally\ndemonstrate a convenient on-chip coupler of centimeters long and propose an\nextra coupler layer to map the qubit array to a binary-tree connecting graph.\nThis mapping layout reduces the average qubit entangling distance from O(N) to\nO(logN), demonstrating an exponentially enhanced connectivity with eliminated\ncrosstalk. The entangling gate with the coupler is performed between two\nfluxonium qubits, reaching a fidelity of 99.37 % while the system static ZZ\nrate remains as low as 144 Hz without active cancellation or circuit parameter\ntargeting. With the scalable binary tree structure and high-fidelity non-local\nentanglement, novel quantum algorithms can be implemented on the\nsuperconducting qubit system, positioning it as a strong competitor to other\nphysics systems regarding circuit connectivity."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-959",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.17524"
    ],
    "b_title":[
      "Multimodal Bearing Fault Classification Under Variable Conditions: A 1D\n  CNN with Transfer Learning"
    ],
    "b_abstract":[
      "Bearings play an integral role in ensuring the reliability and efficiency of\nrotating machinery - reducing friction and handling critical loads. Bearing\nfailures that constitute up to 90% of mechanical faults highlight the\nimperative need for reliable condition monitoring and fault detection. This\nstudy proposes a multimodal bearing fault classification approach that relies\non vibration and motor phase current signals within a one-dimensional\nconvolutional neural network (1D CNN) framework. The method fuses features from\nmultiple signals to enhance the accuracy of fault detection. Under the baseline\ncondition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the model\nreaches an accuracy of 96% with addition of L2 regularization. This represents\na notable improvement of 2% compared to the non-regularized model. In addition,\nthe model demonstrates robust performance across three distinct operating\nconditions by employing transfer learning (TL) strategies. Among the tested TL\nvariants, the approach that preserves parameters up to the first max-pool layer\nand then adjusts subsequent layers achieves the highest performance. While this\napproach attains excellent accuracy across varied conditions, it requires more\ncomputational time due to its greater number of trainable parameters. To\naddress resource constraints, less computationally intensive models offer\nfeasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal\n1D CNN framework with late fusion and TL strategies lays a foundation for more\naccurate, adaptable, and efficient bearing fault classification in industrial\nenvironments with variable operating conditions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.11936"
    ],
    "c_title":[
      "Regimes of spray formation in gas-centered swirl coaxial atomizers"
    ],
    "c_abstract":[
      "Spray formation in ambient atmosphere from gas-centered swirl coaxial\natomizers is described by carrying out experiments in a spray test facility.\nThe atomizer discharges a circular air jet and an axisymmetric swirling water\nsheet from its coaxially arranged inner and outer orifices. A high-speed\ndigital imaging system along with a backlight illumination arrangement is\nemployed to record the details of liquid sheet breakup and spray development.\nSpray regimes exhibiting different sheet breakup mechanisms are identified and\ntheir characteristic features presented. The identified spray regimes are\nwave-assisted sheet breakup, perforated sheet breakup, segmented sheet breakup,\nand pulsation spray regime. In the regime of wave-assisted sheet breakup, the\nsheet breakup shows features similar to the breakup of two-dimensional planar\nair-blasted liquid sheets. At high air-to-liquid momentum ratios, the\ninteraction process between the axisymmetric swirling liquid sheet and the\ncircular air jet develops spray processes which are more specific to the\natomizer studied here. The spray exhibits a periodic ejection of liquid masses\nwhose features are dominantly controlled by the central air jet."
    ],
    "c_categories":[
      [
        "physics.flu-dyn",
        "physics.space-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-960",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08435"
    ],
    "b_title":[
      "Stability and Dynamics of Three-Mode Coupling in $\\delta$ Scuti Stars"
    ],
    "b_abstract":[
      "Recent observations of $\\delta$ Scuti stars find evidence of nonlinear\nthree-mode coupling in their oscillation spectra. There are two types of\nthree-mode coupling likely to be important in $\\delta$ Scuti stars: (i) direct\ncoupling, in which two linearly unstable modes (driven by the kappa-mechanism)\nexcite a linearly stable mode, and (ii) parametric coupling, in which one\nlinearly unstable mode excites two linearly stable modes. Breger & Montgomery\n(2014) find especially strong evidence of direct coupling in the $\\delta$ Scuti\nstar KIC 8054146. However, direct coupling is inherently unstable and cannot be\nthe mechanism by which the modes saturate and achieve nonlinear equilibrium. By\nintegrating the amplitude equations of small mode networks, we show that the\nmodes can achieve equilibrium if parametric coupling operates in tandem with\ndirect coupling. Using mode parameters calculated from a $\\delta$ Scuti model,\nwe also find that parametric and direct coupling are likely to be\nsimultaneously active. Importantly, parametric coupling does not necessarily\ndisrupt the correlations found in KIC 8054146 between the amplitudes and phases\nof the directly coupled modes. We conclude that $\\delta$ Scuti stars are likely\nimpacted by both parametric and direct coupling and that accounting for both in\nfuture large mode network calculations may help explain the complicated mode\ndynamics observed in many $\\delta$ Scuti stars."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.13481"
    ],
    "c_title":[
      "A Polynomial-Time Algorithm for EFX Orientations of Chores"
    ],
    "c_abstract":[
      "This paper addresses the problem of finding EFX orientations of graphs of\nchores, in which each vertex corresponds to an agent, each edge corresponds to\na chore, and a chore has zero marginal utility to an agent if its corresponding\nedge is not incident to the vertex corresponding to the agent. Recently,\nZhou~et~al.~(IJCAI,~2024) analyzed the complexity of deciding whether graphs\ncontaining a mixture of goods and chores admit EFX orientations, and\nconjectured that deciding whether graphs containing only chores admit EFX\norientations is NP-complete. In this paper, we resolve this conjecture by\nexhibiting a polynomial-time algorithm that finds an EFX orientation of a graph\ncontaining only chores if one exists, even if the graph contains self-loops.\nRemarkably, our first result demonstrates a surprising separation between the\ncase of goods and the case of chores, because deciding whether graphs\ncontaining only goods admit EFX orientations of goods was shown to be\nNP-complete by Christodoulou et al.~(EC,~2023). In addition, we show the\nanalogous decision problem for multigraphs to be NP-complete."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.DM",
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-961",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12638"
    ],
    "b_title":[
      "Single-Carrier Waveform Design for Joint Sensing and Communication"
    ],
    "b_abstract":[
      "The emergence of 6G wireless networks demands solutions that seamlessly\nintegrate communication and sensing. This letter proposes a novel waveform\ndesign for joint sensing and communication (JSAC) systems, combining\nsingle-carrier interleaved frequency division multiplexing (SC-IFDM), a 5G\ncommunication candidate signal, with frequency modulated continuous wave\n(FMCW), widely used for sensing. The proposed waveform leverages the sparse\nnature of FMCW within SC-IFDM to achieve orthogonal integration in three steps:\nSC-IFDM symbols are allocated alongside the sparse FMCW, followed by the\nSC-IFDM transform into the time domain, and a cyclic prefix (CP) is applied in\nwhich phase shifts are introduced to the FMCW. Additionally, an enhanced\nchannel estimation method is incorporated to boost system performance.\nSimulation results demonstrate the proposed waveform's ability to deliver\nhigh-resolution sensing and superior communication performance, surpassing\ntraditional multicarrier designs."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.07254"
    ],
    "c_title":[
      "A right-truncated Poisson mixture model for analyzing count data"
    ],
    "c_abstract":[
      "In this paper, we investigate right-truncated count data models incorporating\ncavariates into the parameters. A regression method is proposed to model\n  right-truncated count data exibiting high heterogeneity. The study\nencompasses the formulation of the proposed model, parameter estimation using\nan Expectation-Maximisation (EM) algorithm, and the properties of these\nestimators. We also discuss model selection procedures for the proposed method.\nFurthermore, a Monte Carlo simulation study is presented to assess the\nperformance of the proposed method and the model selection process. Results\nexpress accuracy under regularity conditions of the model. The method is used\nto analyze the determinants of the degree of adherence to preventive\n  measures during teh COVID-19 pandemic. in northern Benin. The results show\nthat a right-truncated Poisson mixture model is adequate to analyze these\n  data. Using this model, we conclude that age, education level, and household\nsize determine an individual's degree of adherence to preventive measures\nduring COVID-19 in this region."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-962",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.02846"
    ],
    "b_title":[
      "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs"
    ],
    "b_abstract":[
      "Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or\nnonsensical information) when serving as AI assistants in various domains.\nSince hallucinations always come with truthful content in the LLM responses,\nprevious factuality alignment methods that conduct response-level preference\nlearning inevitably introduced noises during training. Therefore, this paper\nproposes a fine-grained factuality alignment method based on Direct Preference\nOptimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as\nmask signals, Mask-DPO only learns from factually correct sentences in the\npreferred samples and prevents the penalty on factual contents in the not\npreferred samples, which resolves the ambiguity in the preference learning.\nExtensive experimental results demonstrate that Mask-DPO can significantly\nimprove the factuality of LLMs responses to questions from both in-domain and\nout-of-domain datasets, although these questions and their corresponding topics\nare unseen during training. Only trained on the ANAH train set, the score of\nLlama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%,\neven surpassing the score of Llama3.1-70B-Instruct (53.44%), while its\nFactScore on the out-of-domain Biography dataset is also improved from 30.29%\nto 39.39%. We further study the generalization property of Mask-DPO using\ndifferent training sample scaling strategies and find that scaling the number\nof topics in the dataset is more effective than the number of questions. We\nprovide a hypothesis of what factual alignment is doing with LLMs, on the\nimplication of this phenomenon, and conduct proof-of-concept experiments to\nverify it. We hope the method and the findings pave the way for future research\non scaling factuality alignment."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15494"
    ],
    "c_title":[
      "Three flavor QCD phase transition with M\\\"obius domain wall fermions"
    ],
    "c_abstract":[
      "We present an updated study of the $N_f=3$ QCD phase transition using\nM\\\"{o}bius domain wall fermions. Simulations were performed on $N_t=12$\nlattices with aspect ratios ranging from 2 to 4 for various quark masses, at a\nlattice spacing of $a=0.1361(20)$ fm, corresponding to a temperature of 121(2)\nMeV. To clarify the nature of the phase transition, a large-volume lattice,\n$48^3 \\times 12\\times 16$, was added to analyze the volume dependence of\ndisconnected chiral susceptibility. By examining the chiral condensate,\ndisconnected chiral susceptibility, and Binder cumulant, and incorporating\nresults from $24^3 \\times 12 \\times 16$ and $36^3 \\times 12 \\times 16$ lattices\nreported in earlier studies, we observe that the transition is consistent with\na crossover at a quark mass of approximately $m_f^{\\mathrm{\\overline {MS}}}(2\\,\n\\mathrm{GeV}) \\sim 4$ MeV at this temperature. Furthermore, we discuss the\neffects of residual chiral symmetry breaking on the chiral condensate and\ndisconnected chiral susceptibility for different sizes in the 5th direction."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-th",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-963",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12059"
    ],
    "b_title":[
      "On Product Lie Algebroids, and Collective Motion"
    ],
    "b_abstract":[
      "This work explores the geometrical\/algebraic framework of Lie algebroids,\nwith a specific focus on the decoupling and coupling phenomena within the\nbicocycle double cross product realization. The bicocycle double cross product\ntheory serves as the most general method for (de)coupling an algebroid into the\ndirect sum of two vector bundles in the presence of mutual\n\\textit{representations}, along with two twisted cocycle terms. Consequently,\nit encompasses unified product, double cross product (matched pairs),\nsemi-direct product, and cocycle extension frameworks as particular instances.\nIn addition to algebraic constructions, the research extends to both reversible\nand irreversible Lagrangian and Hamiltonian dynamics on (de)coupled Lie\nalgebroids, as well as Euler-Poincar\\'{e}-(Herglotz) and Lie-Poisson-(Herglotz)\ndynamics on (de)coupled Lie algebras, providing insights into potential\nphysical applications."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.DG",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.18192"
    ],
    "c_title":[
      "Machine Learning Fairness for Depression Detection using EEG Data"
    ],
    "c_abstract":[
      "This paper presents the very first attempt to evaluate machine learning\nfairness for depression detection using electroencephalogram (EEG) data. We\nconduct experiments using different deep learning architectures such as\nConvolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) networks,\nand Gated Recurrent Unit (GRU) networks across three EEG datasets: Mumtaz,\nMODMA and Rest. We employ five different bias mitigation strategies at the\npre-, in- and post-processing stages and evaluate their effectiveness. Our\nexperimental results show that bias exists in existing EEG datasets and\nalgorithms for depression detection, and different bias mitigation methods\naddress bias at different levels across different fairness measures."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-964",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.15370"
    ],
    "b_title":[
      "Tangles: Unpacking Extended Collision Experiences with Soma Trajectories"
    ],
    "b_abstract":[
      "We reappraise the idea of colliding with robots, moving from a position that\ntries to avoid or mitigate collisions to one that considers them an important\nfacet of human interaction. We report on a soma design workshop that explored\nhow our bodies could collide with telepresence robots, mobility aids, and a\nquadruped robot. Based on our findings, we employed soma trajectories to\nanalyse collisions as extended experiences that negotiate key transitions of\nconsent, preparation, launch, contact, ripple, sting, untangle, debris and\nreflect. We then employed these ideas to analyse two collision experiences, an\naccidental collision between a person and a drone, and the deliberate design of\na robot to play with cats, revealing how real-world collisions involve the\ncomplex and ongoing entanglement of soma trajectories. We discuss how viewing\ncollisions as entangled trajectories, or tangles, can be used analytically, as\na design approach, and as a lens to broach ethical complexity."
    ],
    "b_categories":[
      [
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.09611"
    ],
    "c_title":[
      "Extension of Sequence of Physical Processes framework relating the\n  second Piola-Kirchhoff stress tensor to the Green-Lagrange strain tensor"
    ],
    "c_abstract":[
      "An extension of the Sequence of Physical Processes using geometrical\ncorrections of the Piola-Kirchhoff stress tensor and the Green-Lagrange strain\ntensor is addressed. More precisely, the usual Sequence of Physical Processes\nomits some geometrical non linearities that appear when the deformation becomes\nlarge. With this extension, geometrical corrections are added and let the\nopportunity to study rheological non linearities. Application on two famous\nclassical viscoelastic models, namely the linear Maxwell model and the linear\nKelvin-Voigt model, helps to understand how some complex behaviours may be\nrationalised to better understand the behaviours after some corrections."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-965",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01053"
    ],
    "b_title":[
      "Commitment, Conflict, and Status Quo in Bargaining"
    ],
    "b_abstract":[
      "Each period, two players bargain over a unit of surplus. Each player chooses\nbetween remaining flexible and committing to a take-it-or-leave-it offer at a\ncost. If players' committed demands are incompatible, then the current-period\nsurplus is destroyed in the conflict. When both players are flexible, the\nsurplus is split according to the status quo, which is the division in the last\nperiod where there was no conflict. We show that when players are patient and\nthe cost of commitment is small, there exist a class of symmetric Markov\nPerfect equilibria that are asymptotically efficient and renegotiation proof,\nin which players commit to fair demands in almost all periods."
    ],
    "b_categories":[
      [
        "cs.GT",
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.04688"
    ],
    "c_title":[
      "Teach YOLO to Remember: A Self-Distillation Approach for Continual\n  Object Detection"
    ],
    "c_abstract":[
      "Real-time object detectors like YOLO achieve exceptional performance when\ntrained on large datasets for multiple epochs. However, in real-world scenarios\nwhere data arrives incrementally, neural networks suffer from catastrophic\nforgetting, leading to a loss of previously learned knowledge. To address this,\nprior research has explored strategies for Class Incremental Learning (CIL) in\nContinual Learning for Object Detection (CLOD), with most approaches focusing\non two-stage object detectors. However, existing work suggests that Learning\nwithout Forgetting (LwF) may be ineffective for one-stage anchor-free detectors\nlike YOLO due to noisy regression outputs, which risk transferring corrupted\nknowledge. In this work, we introduce YOLO LwF, a self-distillation approach\ntailored for YOLO-based continual object detection. We demonstrate that when\ncoupled with a replay memory, YOLO LwF significantly mitigates forgetting.\nCompared to previous approaches, it achieves state-of-the-art performance,\nimproving mAP by +2.1% and +2.9% on the VOC and COCO benchmarks, respectively."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-966",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03326"
    ],
    "b_title":[
      "Arc Blanc: a real time ocean simulation framework"
    ],
    "b_abstract":[
      "The oceans cover the vast majority of the Earth. Therefore, their simulation\nhas many scientific, industrial and military interests, including computer\ngraphics domain. By fully exploiting the multi-threading power of GPU and CPU,\ncurrent state-of-the-art tools can achieve real-time ocean simulation, even if\nit is sometimes needed to reduce the physical realism for large scenes.\nAlthough most of the building blocks for implementing an ocean simulator are\ndescribed in the literature, a clear explanation of how they interconnect is\nlacking. Hence, this paper proposes to bring all these components together,\ndetailing all their interactions, in a comprehensive and fully described\nreal-time framework that simulates the free ocean surface and the coupling\nbetween solids and fluid. This article also presents several improvements to\nenhance the physical realism of our model. The two main ones are: calculating\nthe real-time velocity of ocean fluids at any depth; computing the input of the\nfluid to solid coupling algorithm."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08794"
    ],
    "c_title":[
      "Securities Transaction Settlement Optimization on superconducting\n  quantum devices"
    ],
    "c_abstract":[
      "We describe a quantum variational algorithm for securities transactions\nsettlement optimization, based on a novel mathematical formalization of the\nproblem that includes the most relevant constraints considered in the\npan-European securities settlement platform TARGET2-Securities. The proposed\nalgorithm is designed for Noisy Intermediate-Scale Quantum devices,\nspecifically targeting IBM's superconducting qubit machines. We adopt\nnon-linear activation functions to encode inequality constraints in the\nobjective function of the problem, and design customized noise mitigation\ntechniques to alleviate the effect of readout errors. We consider batches of up\nto 40 trades obtained from real transactional data to benchmark our algorithm\non quantum hardware against classical and quantum-inspired solvers."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-967",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.11710"
    ],
    "b_title":[
      "The Worse The Better: Content-Aware Viewpoint Generation Network for\n  Projection-related Point Cloud Quality Assessment"
    ],
    "b_abstract":[
      "Through experimental studies, however, we observed the instability of final\npredicted quality scores, which change significantly over different viewpoint\nsettings. Inspired by the \"wooden barrel theory\", given the default\ncontent-independent viewpoints of existing projection-related PCQA approaches,\nthis paper presents a novel content-aware viewpoint generation network (CAVGN)\nto learn better viewpoints by taking the distribution of geometric and\nattribute features of degraded point clouds into consideration. Firstly, the\nproposed CAVGN extracts multi-scale geometric and texture features of the\nentire input point cloud, respectively. Then, for each default\ncontent-independent viewpoint, the extracted geometric and texture features are\nrefined to focus on its corresponding visible part of the input point cloud.\nFinally, the refined geometric and texture features are concatenated to\ngenerate an optimized viewpoint. To train the proposed CAVGN, we present a\nself-supervised viewpoint ranking network (SSVRN) to select the viewpoint with\nthe worst quality projected image to construct a default-optimized viewpoint\ndataset, which consists of thousands of paired default viewpoints and\ncorresponding optimized viewpoints. Experimental results show that the\nprojection-related PCQA methods can achieve higher performance using the\nviewpoints generated by the proposed CAVGN."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14464"
    ],
    "c_title":[
      "Two-photon scattering in a waveguide by a giant atom"
    ],
    "c_abstract":[
      "We study two-photon scattering by a two-level giant atom in a waveguide. We\nfirst study the case that the giant atom is coupled to the waveguide via two\ncoupling points, and obtain Bethe ansatz eigenstates and eigenvalues in the\nHilbert space of two-excitation. Then we derive bound states by subtracting the\nstates corresponding to Bethe ansatz solutions from the entire two-excitation\nHilbert space, and construct the two-photon scattering matrix (S-matrix) by\nusing Bethe ansatz eigenstates and bound states. We further study the\nproperties of output states, which include both the scattering and bound\nstates, for arbitrarily incident two-photon states by using a concrete example.\nWe find that the oscillation period of the scattering states and decay rates of\nthe bound states strongly depend on the distance between two coupling points.\nMoreover, we find that the two-photon correlation in the bound states can be\nenhanced by changing such distance when the total energy of two incident\nphotons equals to two times of single photon resonance energy. We also\ngeneralize our study to the case that the giant atom is coupled to the\nwaveguide via $N$ coupling points. We obtain all the eigenstates and\neigenvalues of the scattering matrix and construct the S-matrix. Comparing with\nthe case of the two coupling points, we find the photon correlation can be\nfurther enhanced by increasing the number of the coupling points for the same\nincident states when the distance of any two nearest neighbor coupling points\nis half of the wavelength."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-968",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.00416"
    ],
    "b_title":[
      "GO-GAN: Geometry Optimization Generative Adversarial Network for\n  Achieving Optimized Structures with Targeted Physical Properties"
    ],
    "b_abstract":[
      "This paper presents GO-GAN, a novel Generative Adversarial Network (GAN)\narchitecture for geometry optimization (GO), specifically to generate\nstructures based on user-specified input parameters. The architecture for\nGO-GAN proposed here combines a \\texttt{Pix2Pix} GAN with a new input\nmechanism, involving a dynamic batch gradient descent-based training loop that\nleverages dataset symmetries. The model, implemented here using\n\\texttt{TensorFlow} and \\texttt{Keras}, is trained using input images\nrepresenting scalar physical properties generated by a custom MatLab code.\nAfter training, GO-GAN rapidly generates optimized geometries from input images\nrepresenting scalar inputs of the physical properties. Results demonstrate\nGO-GAN's ability to produce acceptable designs with desirable variations. These\nvariations are followed by the influence of discriminators during training and\nare of practical significance in ensuring adherence to specifications while\nenabling creative exploration of the design space."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.14634"
    ],
    "c_title":[
      "Protected phase gate for the $0$-$\\pi$ qubit using its internal modes"
    ],
    "c_abstract":[
      "Protected superconducting qubits such as the $0$-$\\pi$ qubit promise to\nsubstantially reduce physical error rates through a multi-mode encoding. This\nprotection comes at the cost of controllability, as standard techniques for\nquantum gates are ineffective. We propose a protected phase gate for the\n$0$-$\\pi$ qubit that utilises an internal mode of the circuit as an ancilla.\nThe gate is achieved by varying the qubit-ancilla coupling via a tunable\nJosephson element. Our scheme is a modified version of a protected gate\nproposed by Brooks, Kitaev and Preskill that uses an external oscillator as an\nancilla. We find that our scheme is compatible with the protected regime of the\n$0$-$\\pi$ qubit, and does not suffer from spurious coupling to additional modes\nof the $0$-$\\pi$ circuit. Through numerical simulations, we study how the gate\nerror scales with the circuit parameters of the $0$-$\\pi$ qubit and the tunable\nJosephson element that enacts the gate."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-969",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05848"
    ],
    "b_title":[
      "A simple derived categorical generalization of Ulrich bundles"
    ],
    "b_abstract":[
      "We define special objects, Ulrich objects, on a derived category of polarized\nsmooth projective variety as a generalization of Ulrich bundles to the derived\ncategory. These are defined by the cohomological conditions that are the same\nform as a cohomological criterion determining Ulrichness for sheaves. This\npaper gives a characterization of the Ulrich object similar to the one in\n[ES03]. As an application, we have provided a new approach to the\nEisenbud-Schreyer question by using the notions of the generator of the derived\ncategory. We also have given an example of Ulrich objects that are not sheaf by\nthe Yoneda extension."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.15991"
    ],
    "c_title":[
      "Modeling and stability analysis of live systems with time-varying\n  dimension"
    ],
    "c_abstract":[
      "A major limitation of the classical control theory is the assumption that the\nstate space and its dimension do not change with time. This prevents analyzing\nand even formalizing the stability and control problems for open multi-agent\nsystems whose agents may enter or leave the network, industrial processes where\nthe sensors or actuators may be exchanged frequently, smart grids, etc. In this\nwork, we propose a framework of live systems that covers a rather general class\nof systems with a time-varying state space. We argue that input-to-state\nstability is a proper stability notion for this class of systems, and many of\nthe classic tools and results, such as Lyapunov methods and superposition\ntheorems, can be extended to this setting."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.DS",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-970",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08530"
    ],
    "b_title":[
      "Residually Dominated Groups in Henselian Valued Fields of\n  Equicharacteristic Zero"
    ],
    "b_abstract":[
      "We introduce \\emph{residually dominated groups} in pure henselian valued\nfields of equicharacteristic zero as an analogue of stably dominated groups\nintroduced by Hrushovski and Rideau-Kikuchi. We show that when $G$ is a\nresidually dominated group, there is a finite-to-one group homomorphism from\nits connected component into a connected stably dominated group, and we study\nthe functoriality and universality properties of this map. Moreover, we prove\nthat there is a group homomorphism into a definable group in the residue field\nthat witnesses the residual domination. In our proofs, we use the results of\nMontenegro, Onshuus, and Simon on groups definable in $\\mathrm{NTP}_2$-theories\nthat extend the theory of fields. Along the way, we also provide an algebraic\ncharacterization of residually dominated types, generalizing the work by Ealy,\nHaskell and Simon for stably dominated types in algebraically closed valued\nfields and study the properties of residually dominated types."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.13296"
    ],
    "c_title":[
      "Measurement-Device-Independent Certification of Schmidt Number"
    ],
    "c_abstract":[
      "Bipartite quantum states with higher Schmidt numbers have been shown to\noutperform those with lower Schmidt numbers in various information processing\ntasks. Therefore, to ensure the efficient use of resources in these tasks, it\nis essential to certify the Schmidt number of the resource states. Ideally,\nthis certification should rely as little as possible on the certifying devices,\nensuring robustness against potential imperfections. In this work, we explore\nthe scope of fully and partially device-independent Schmidt number\ncertification methods. We demonstrate the general impossibility of fully\ndevice-independent certification for all states. Specifically, in a restricted\nsetting, we present a class of states with Schmidt number 3, for which it is\nimpossible to certify that their Schmidt number is greater than 2. However, we\nshow that the Schmidt number of all states can be certified in a\nmeasurement-device-independent manner via semi-quantum nonlocal games, which\nassume trust in the preparation devices. Finally, we present an explicit\nconstruction of a semi-quantum game for the measurement-device-independent\ncertification of a class of states."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-971",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.01390"
    ],
    "b_title":[
      "Scalable and Accurate Application-Level Crash-Consistency Testing via\n  Representative Testing"
    ],
    "b_abstract":[
      "Crash consistency is essential for applications that must persist data.\nCrash-consistency testing has been commonly applied to find crash-consistency\nbugs in applications. The crash-state space grows exponentially as the number\nof operations in the program increases, necessitating techniques for pruning\nthe search space. However, state-of-the-art crash-state space pruning is far\nfrom ideal. Some techniques look for known buggy patterns or bound the\nexploration for efficiency, but they sacrifice coverage and may miss bugs\nlodged deep within applications. Other techniques eliminate redundancy in the\nsearch space by skipping identical crash states, but they still fail to scale\nto larger applications.\n  In this work, we propose representative testing: a new crash-state space\nreduction strategy that achieves high scalability and high coverage. Our key\nobservation is that the consistency of crash states is often correlated, even\nif those crash states are not identical. We build Pathfinder, a\ncrash-consistency testing tool that implements an update behaviors-based\nheuristic to approximate a small set of representative crash states.\n  We evaluate Pathfinder on POSIX-based and MMIO-based applications, where it\nfinds 18 (7 new) bugs across 8 production-ready systems. Pathfinder scales more\neffectively to large applications than prior works and finds 4x more bugs in\nPOSIX-based applications and 8x more bugs in MMIO-based applications compared\nto state-of-the-art systems."
    ],
    "b_categories":[
      [
        "cs.OS",
        "cs.PL",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.08265"
    ],
    "c_title":[
      "Extension of continuous functions on product spaces, Bohr\n  Compactification and Almost Periodic Functions"
    ],
    "c_abstract":[
      "The Bohr compactification is a well known construction for (topological)\ngroups and semigroups. Recently, this notion has been investigated for\narbitrary structures in \\cite{har_kun:bohr_discrete} where the Bohr\ncompactification is defined, using a set-theoretical approach, as the maximal\ncompactification which is compatible with the structure involved. Here, we give\na characterization of the continuous functions defined on a product space that\ncan be extended continuously to certain compactifications of the product space.\nAs a consequence, the Bohr compactification of an arbitrary topological\nstructure is obtained as the Gelfand space of the commutative Banach algebra of\nall almost periodic functions. Previously, almost periodic functions $f$ are\ndefined in terms of translates of $f$ with no reference to any compactification\nof the underlying structure. An application is given to the representation of\nisometries defined between spaces of almost periodic functions."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.GN"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-972",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.21199"
    ],
    "b_title":[
      "Negative correlations in Ising models of credit risk"
    ],
    "b_abstract":[
      "We analyze a subclass of Ising models in the context of credit risk, focusing\non Dandelion models when the correlations $\\rho$ between the central node and\neach non-central node are negative. We establish the possible range of values\nfor $\\rho$ and derive an explicit formula linking the correlation between any\npair of non-central nodes to $\\rho$. The paper concludes with a simulation\nstudy."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.10866"
    ],
    "c_title":[
      "QGAPHEnsemble : Combining Hybrid QLSTM Network Ensemble via Adaptive\n  Weighting for Short Term Weather Forecasting"
    ],
    "c_abstract":[
      "Accurate weather forecasting holds significant importance, serving as a\ncrucial tool for decision-making in various industrial sectors. The limitations\nof statistical models, assuming independence among data points, highlight the\nneed for advanced methodologies. The correlation between meteorological\nvariables necessitate models capable of capturing complex dependencies. This\nresearch highlights the practical efficacy of employing advanced machine\nlearning techniques proposing GenHybQLSTM and BO-QEnsemble architecture based\non adaptive weight adjustment strategy. Through comprehensive hyper-parameter\noptimization using hybrid quantum genetic particle swarm optimisation algorithm\nand Bayesian Optimization, our model demonstrates a substantial improvement in\nthe accuracy and reliability of meteorological predictions through the\nassessment of performance metrics such as MSE (Mean Squared Error) and MAPE\n(Mean Absolute Percentage Prediction Error). The paper highlights the\nimportance of optimized ensemble techniques to improve the performance the\ngiven weather forecasting task."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-973",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.03905"
    ],
    "b_title":[
      "Partially hyperbolic symplectomorphism with C^1 bundles"
    ],
    "b_abstract":[
      "We prove dynamical coherence for partial hyperbolic symplectomorphism in\ndimension 4 whose stable and unstable bundles are C^1."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2501.08244"
    ],
    "c_title":[
      "What is the general Welfare? Welfare Economic Perspectives"
    ],
    "c_abstract":[
      "Researchers cannot definitively interpret what the framers of the United\nStates Constitution had in mind when they wrote of the general Welfare.\nNevertheless, welfare economics can contribute to policy choice in democracies.\nSpecifying social welfare functions enables coherent analysis, by formalizing\nmechanisms for preference aggregation and studying the policies they yield.\nThis paper argues that it is essential for welfare economics to adequately\nexpress the richness and variety of actual human preferences over social\nstates. I first discuss devices that economists have used in attempts to\ncircumvent or grossly simplify specification of social welfare functions. I\nnext discuss the common welfare economic practice of assuming that personal\npreferences are homogeneous, consequentialist, and self-centered. I then call\nfor incorporation of broader forms of personal preferences into social welfare\nfunctions. Individuals may hold heterogeneous social preferences, being\nconcerned in various ways with the distribution of outcomes in the population.\nThey may hold heterogeneous deontological preferences, placing value on their\nown actions and the actions of others. They may have preferences for the\nmechanism used to aggregate preferences in a social welfare function. These\npotential aspects of personal preference should be recognized in welfare\neconomics."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-974",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12119"
    ],
    "b_title":[
      "Photostriction Facilitates Relaxation of Lattice Distortion in\n  Two-Dimensional Perovskites"
    ],
    "b_abstract":[
      "The photostriction effect, a light-induced mechanical deformation in\nmaterials, originates from the intricate interplay between lattice structure\nand electronic excitation. In photovoltaic semiconductors, this effect plays a\ncrucial role in shaping non-equilibrium structural responses, yet its\nfundamental mechanism remains elusive. Here, we uncover lattice expansion and\nstructural reconfiguration in two-dimensional (2D) perovskites driven by\nphotoinduced excitation using first-principles calculations. Our findings\nreveal that the photoinduced carriers lead to a substantial lattice expansion\nby about 2%. The expanded lattice facilitates strain relaxation with the\namplitude of 20% by increasing interatomic distances and reducing internal\nstresses, thereby enhancing structural stability. The lattice dynamics can be\nsystematically engineered through photodoping density, unveiling a new pathway\nto modulate light-matter interactions in 2D perovskites. These insights not\nonly advance the understanding of optically driven structural dynamics but also\noffer a guiding principle for optimizing next-generation high-efficiency\nphotovoltaic devices and optoelectronics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.05096"
    ],
    "c_title":[
      "Presentation of finite Reedy categories as localizations of finite\n  direct categories"
    ],
    "c_abstract":[
      "In this paper, we present a construction from a Reedy category $C$ of a\ndirect category $\\operatorname{Down}(C)$ and a functor $\\operatorname{Down}(C)\n\\to C$, which exhibits $C$ as an $(\\infty,1)$-categorical localization of\n$\\operatorname{Down}(C)$. This result refines previous constructions in the\nliterature by ensuring finiteness of the direct category\n$\\operatorname{Down}(C)$ whenever $C$ is finite, which is not guaranteed by\nexisting approaches. The finiteness property is useful when we want to embed\nthe construction into the syntax of a (non-infinitary) logic: the author\nexpects the construction may be used to develop a meta-theory of finitely\ntruncated simplicial types for homotopy type theory."
    ],
    "c_categories":[
      [
        "math.AT",
        "math.CT",
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-975",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.08622"
    ],
    "b_title":[
      "Forecasting Drought Using Machine Learning in California"
    ],
    "b_abstract":[
      "Drought is a frequent and costly natural disaster in California, with major\nnegative impacts on agricultural production and water resource availability,\nparticularly groundwater. This study investigated the performance of applying\ndifferent machine learning approaches to predicting the U.S. Drought Monitor\nclassification in California. Four approaches were used: a convolutional neural\nnetwork (CNN), random forest, XGBoost, and long short term memory (LSTM)\nrecurrent neural network, and compared to a baseline persistence model. We\nevaluated the models' performance in predicting severe drought (USDM drought\ncategory D2 or higher) using a macro F1 binary classification metric. The LSTM\nmodel emerged as the top performer, followed by XGBoost, CNN, and random\nforest. Further evaluation of our results at the county level suggested that\nthe LSTM model would perform best in counties with more consistent drought\npatterns and where severe drought was more common, and the LSTM model would\nperform worse where drought scores increased rapidly. Utilizing 30 weeks of\nhistorical data, the LSTM model successfully forecasted drought scores for a\n12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to less\nthan half a drought category on a scale of 0 to 5. Additionally, the LSTM\nachieved a macro F1 score of 0.9, indicating high accuracy in binary\nclassification for severe drought conditions. Evaluation of different window\nand future horizon sizes in weeks suggested that at least 24 weeks of data\nwould result in the best performance, with best performance for shorter horizon\nsizes, particularly less than eight weeks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.16226"
    ],
    "c_title":[
      "The Effect of Optimal Self-Distillation in Noisy Gaussian Mixture Model"
    ],
    "c_abstract":[
      "Self-distillation (SD), a technique where a model refines itself from its own\npredictions, has garnered attention as a simple yet powerful approach in\nmachine learning. Despite its widespread use, the mechanisms underlying its\neffectiveness remain unclear. In this study, we investigate the efficacy of\nhyperparameter-tuned multi-stage SD in binary classification tasks with noisy\nlabeled Gaussian mixture data, utilizing a replica theory. Our findings reveals\nthat the primary driver of SD's performance improvement is denoising through\nhard pseudo-labels, with the most notable gains observed in moderately sized\ndatasets. We also demonstrate the efficacy of practical heuristics, such as\nearly stopping for extracting meaningful signal and bias fixation for\nimbalanced data. These results provide both theoretical guarantees and\npractical insights, advancing our understanding and application of SD in noisy\nsettings."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-976",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.03582"
    ],
    "b_title":[
      "Scaling Crowdsourced Election Monitoring: Construction and Evaluation of\n  Classification Models for Multilingual and Cross-Domain Classification\n  Settings"
    ],
    "b_abstract":[
      "The adoption of crowdsourced election monitoring as a complementary\nalternative to traditional election monitoring is on the rise. Yet, its\nreliance on digital response volunteers to manually process incoming election\nreports poses a significant scaling bottleneck. In this paper, we address the\nchallenge of scaling crowdsourced election monitoring by advancing the task of\nautomated classification of crowdsourced election reports to multilingual and\ncross-domain classification settings. We propose a two-step classification\napproach of first identifying informative reports and then categorising them\ninto distinct information types. We conduct classification experiments using\nmultilingual transformer models such as XLM-RoBERTa and multilingual embeddings\nsuch as SBERT, augmented with linguistically motivated features. Our approach\nachieves F1-Scores of 77\\% for informativeness detection and 75\\% for\ninformation type classification. We conduct cross-domain experiments, applying\nmodels trained in a source electoral domain to a new target electoral domain in\nzero-shot and few-shot classification settings. Our results show promising\npotential for model transfer across electoral domains, with F1-Scores of 59\\%\nin zero-shot and 63\\% in few-shot settings. However, our analysis also reveals\na performance bias in detecting informative English reports over Swahili,\nlikely due to imbalances in the training data, indicating a need for caution\nwhen deploying classification models in real-world election scenarios."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.05838"
    ],
    "c_title":[
      "Shrinking gradient K\\\"ahler-Ricci solitons are simply-connected"
    ],
    "c_abstract":[
      "We show that smooth polarized Fano fibrations have no nontrivial finite\ncovers. Using results by Sun-Zhang and Wylie, it follows that shrinking\nK\\\"ahler-Ricci solitons are simply-connected."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-977",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06420"
    ],
    "b_title":[
      "Explaining Control Policies through Predicate Decision Diagrams"
    ],
    "b_abstract":[
      "Safety-critical controllers of complex systems are hard to construct\nmanually. Automated approaches such as controller synthesis or learning provide\na tempting alternative but usually lack explainability. To this end, learning\ndecision trees (DTs) have been prevalently used towards an interpretable model\nof the generated controllers. However, DTs do not exploit shared\ndecision-making, a key concept exploited in binary decision diagrams (BDDs) to\nreduce their size and thus improve explainability. In this work, we introduce\npredicate decision diagrams (PDDs) that extend BDDs with predicates and thus\nunite the advantages of DTs and BDDs for controller representation. We\nestablish a synthesis pipeline for efficient construction of PDDs from DTs\nrepresenting controllers, exploiting reduction techniques for BDDs also for\nPDDs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.11164"
    ],
    "c_title":[
      "A statistical technique for cleaning option price data"
    ],
    "c_abstract":[
      "Recorded option pricing datasets are not always freely available.\nAdditionally, these datasets often contain numerous prices which are either\nhigher or lower than can reasonably be expected. Various reasons for these\nunexpected observations are possible, including human error in the recording of\nthe details associated with the option in question. In order for the analyses\nperformed on these datasets to be reliable, it is necessary to identify and\nremove these options from the dataset. In this paper, we list three distinct\nproblems often found in recorded option price datasets alongside means of\naddressing these. The methods used are justified using sound statistical\nreasoning and remove option prices violating the standard assumption of no\narbitrage. An attractive aspect of the proposed technique is that no option\npricing model-based assumptions are used. Although the discussion is restricted\nto European options, the procedure is easily modified for use with exotic\noptions as well. As a final contribution, the paper contains a link to six\noption pricing datasets which have already been cleaned using the proposed\nmethods and can be freely used by researchers."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-978",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17687"
    ],
    "b_title":[
      "Topological insulator constrictions -- Dirac particles in a\n  magneto-chiral box"
    ],
    "b_abstract":[
      "We study magneto-transport through topological insulator nanowires shaped in\nthe form of a constriction, as can be obtained by etching techniques. The\nmagnetic field is coaxial, potentially turning the nanowire into a\nmagneto-chiral junction. We show in a detailed analytical and numerical study\nthat two main transport regimes emerge, depending on the central narrow region\nbeing short or long as compared to the magnetic length at the junction entrance\nand exit. In both cases the central region hosts Dirac-particle-in-a-box states\ndue to magnetic confinement, whose conductance properties are strongly\ninfluenced by Landau levels at the ends of the constriction. Notably, in the\nlow-energy regime only chiral states with a specific handedness can transport\ncharge across the junction. Based on these properties and general symmetry\nconsiderations we argue that the shaped nanowire should exhibit strong\nmagneto-chiral non-reciprocal transport beyond linear response. We employ a\nnumerical tight-binding implementation of an effective 2D model on a\nnon-homogeneous grid, capable of simulating samples of realistic sizes, and\ntest its soundness against full simulations for scaled-down 3D topological\ninsulator wires."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2503.18087"
    ],
    "c_title":[
      "HyperNOs: Automated and Parallel Library for Neural Operators Research"
    ],
    "c_abstract":[
      "This paper introduces HyperNOs, a PyTorch library designed to streamline and\nautomate the process of exploring neural operators, with a special focus on\nhyperparameter optimization for comprehensive and exhaustive exploration.\nIndeed, HyperNOs takes advantage of state-of-the-art optimization algorithms\nand parallel computing implemented in the Ray-tune library to efficiently\nexplore the hyperparameter space of neural operators. We also implement many\nuseful functionalities for studying neural operators with a user-friendly\ninterface, such as the possibility to train the model with a fixed number of\nparameters or to train the model with multiple datasets and different\nresolutions. We integrate Fourier neural operators and convolutional neural\noperators in our library, achieving state of the art results on many\nrepresentative benchmarks, demonstrating the capabilities of HyperNOs to handle\nreal datasets and modern architectures. The library is designed to be easy to\nuse with the provided model and datasets, but also to be easily extended to use\nnew datasets and custom neural operator architectures."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-979",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.12645"
    ],
    "b_title":[
      "Understanding Gradient Orthogonalization for Deep Learning via\n  Non-Euclidean Trust-Region Optimization"
    ],
    "b_abstract":[
      "Optimization with matrix gradient orthogonalization has recently demonstrated\nimpressive results in the training of deep neural networks (Jordan et al.,\n2024; Liu et al., 2025). In this paper, we provide a theoretical analysis of\nthis approach. In particular, we show that the orthogonalized gradient method\ncan be seen as a first-order trust-region optimization method, where the\ntrust-region is defined in terms of the matrix spectral norm. Motivated by this\nobservation, we provide the first theoretical analysis of the stochastic\nnon-Euclidean trust-region gradient method with momentum, which recovers the\nMuon optimizer (Jordan et al., 2024) as a special case. In addition, we\nestablish the convergence of the normalized SGD with momentum (Cutkosky and\nMehta, 2020) in the constrained and composite setting, show that its iteration\ncomplexity of finding an $\\varepsilon$-accurate solution can be improved from\n$\\mathcal{O}(\\varepsilon^{-3.5})$ to $\\mathcal{O}(\\varepsilon^{-3})$ under the\nstar-convexity assumption, and obtain similar results for the Muon algorithm.\nFinally, our theoretical findings provide an explanation for the practical\nsuperiority of Muon compared to the Orthogonal-SGDM algorithm of Tuddenham et\nal. (2022)."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.15525"
    ],
    "c_title":[
      "Determination of $\\alpha_s(M_Z)$ via a high-precision effective coupling\n  $\\alpha^{g_1}_s(Q)$"
    ],
    "c_abstract":[
      "We propose a novel method to determine the strong coupling of quantum\nchromodynamics (QCD) and fix its running behavior at all scales by using the\nBjorken sum rules (BSR). The BSR defines an effective coupling\n$\\alpha^{g_1}_s(Q)$ which includes the nonperturbative high-twist corrections\nand perturbative QCD (pQCD) corrections to the leading-twist part. For the\nleading-twist part of $\\alpha^{g_1}_s(Q)$, we adopt the infinite-order\nscale-setting procedure of the principle of maximum conformality\n($\\rm{PMC}_\\infty$) to deal with its pQCD corrections, which reveals the\nintrinsic conformality of series and eliminates conventional renormalization\nscheme-and-scale ambiguities. Using the $\\rm{PMC}_\\infty$ approach, we not only\neliminate \\textit{the first kind of residual scale dependence} due to\nuncalculated higher-order terms, but also resolve the previous\n``self-consistence problem\". The holographic light-front QCD model is used for\n$\\alpha^{g_1}_s(Q)$ in the infrared region, which also reveals a conformal\nbehavior at $Q\\to 0$. As a combination, we obtain a precise $\\alpha^{g_1}_s(Q)$\nat all scales, which matches well with the known experimental data with\n$p$-value $\\sim99\\%$, we determine the strong coupling constant at the critical\nscale $M_Z$, $\\alpha_s(M_Z)=0.1191\\pm{0.0012}\\mp0.0006$, where the first error\ncomes from $\\Delta\\kappa$ of LFHQCD model and the second error is from\n\\textit{the second kind of residual scale dependence} that is negligible."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-980",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.18716"
    ],
    "b_title":[
      "A Mega-FPS low light camera"
    ],
    "b_abstract":[
      "From biology and astronomy to quantum optics, there is a critical need for\nhigh frame rate, high quantum efficiency imaging. In practice, most cameras\nonly satisfy one of these requirements. Here we introduce interlaced fast\nkinetics imaging, a technique that allows burst video acquisition at frame\nrates up to 3.33 Mfps using a commercial EMCCD camera with single-photon\nsensitivity. This approach leverages EMCCD's intrinsic fast row transfer\ndynamics by introducing a tilted lens array into the imaging path, creating a\nspatially distributed grid of exposed pixels, each aligned to its own column of\nthe sensor. The remaining unexposed pixels serve as in-situ storage registers,\nallowing subsequent frames to be captured after just one row shift operation.\nOur interlaced fast kinetics camera maintains 50% contrast for square wave\nintensity modulation frequencies up to 1.61 MHz. We provide benchmarks of the\nvideo performance by capturing two dimensional videos of spatially evolving\npatterns that repeat every 2$\\mu$s, with spatial resolution of 11$\\times$15\npixels. Our approach is compatible with commercial EMCCDs and opens a new route\nto ultra-fast imaging at single-photon sensitivity with applications from fast\nfluorescence imaging to photon correlation measurement."
    ],
    "b_categories":[
      [
        "physics.atom-ph",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.01236"
    ],
    "c_title":[
      "Enhanced Differential Testing in Emerging Database Systems"
    ],
    "c_abstract":[
      "In recent years, a plethora of database management systems have surfaced to\nmeet the demands of various scenarios. Emerging database systems, such as\ntime-series and streaming database systems, are tailored to specific use cases\nrequiring enhanced functionality and performance. However, as they are\ntypically less mature, there can be bugs that either cause incorrect results or\nerrors impacting reliability. To tackle this, we propose enhanced differential\ntesting to uncover various bugs in emerging SQL-like database systems. The\nchallenge is how to deal with differences of these emerging databases. Our\ninsight is that many emerging database systems are conceptually extensions of\nrelational database systems, making it possible to reveal logic bugs leveraging\nexisting relational, known-reliable database systems. However, due to\ninevitable syntax or semantics gaps, it remains challenging to scale\ndifferential testing to various emerging database systems. We enhance\ndifferential testing for emerging database systems with three steps: (i)\nidentifying shared clauses; (ii) extending shared clauses via mapping new\nfeatures back to existing clauses of relational database systems; and (iii)\ngenerating differential inputs using extended shared clauses. We implemented\nour approach in a tool called SQLxDiff and applied it to four popular emerging\ndatabase systems. In total, we found 57 unknown bugs, of which 17 were logic\nbugs and 40 were internal errors. Overall, vendors fixed 50 bugs and confirmed\n5. Our results demonstrate the practicality and effectiveness of SQLxDiff in\ndetecting bugs in emerging database systems, which has the potential to improve\nthe reliability of their applications."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-981",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.17470"
    ],
    "b_title":[
      "Quantum Cross-section of Near-extremal Black Holes"
    ],
    "b_abstract":[
      "We explore how to detect the large quantum fluctuations in the throat of a\nnear-extremal black hole, where the dynamics are governed by the Schwarzian\ntheory. To this end, we scatter a low-frequency wave of a massless, minimal\nscalar off the black hole and calculate the absorption cross-section. In the\nsemiclassical regime, where the Schwarzian is weakly coupled, we recover the\nuniversal result that the cross-section equals the horizon area. However, in\nthe strongly coupled regime, where quantum fluctuations dominate, we find that\nthe absorption cross-section exceeds the semiclassical prediction. This result\nmay seem counterintuitive, given that the density of black hole states is\nsuppressed in this regime. Nevertheless, two effects outweigh this suppression.\nFirst, quantum fluctuations enhance absorption transitions between individual\nstates, with the effect becoming stronger closer to the ground state. Second,\nthese fluctuations significantly reduce stimulated emission. We conclude that a\nmeasurement showing an enhanced absorption cross-section serves as a clear\nsignature of the large quantum fluctuations in the geometry."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.07151"
    ],
    "c_title":[
      "Conditional Distribution Quantization in Machine Learning"
    ],
    "c_abstract":[
      "Conditional expectation \\mathbb{E}(Y \\mid X) often fails to capture the\ncomplexity of multimodal conditional distributions \\mathcal{L}(Y \\mid X). To\naddress this, we propose using n-point conditional quantizations--functional\nmappings of X that are learnable via gradient descent--to approximate\n\\mathcal{L}(Y \\mid X). This approach adapts Competitive Learning Vector\nQuantization (CLVQ), tailored for conditional distributions. It goes beyond\nsingle-valued predictions by providing multiple representative points that\nbetter reflect multimodal structures. It enables the approximation of the true\nconditional law in the Wasserstein distance. The resulting framework is\ntheoretically grounded and useful for uncertainty quantification and multimodal\ndata generation tasks. For example, in computer vision inpainting tasks,\nmultiple plausible reconstructions may exist for the same partially observed\ninput image X. We demonstrate the effectiveness of our approach through\nexperiments on synthetic and real-world datasets."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-982",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.04782"
    ],
    "b_title":[
      "GaussianVideo: Efficient Video Representation via Hierarchical Gaussian\n  Splatting"
    ],
    "b_abstract":[
      "Efficient neural representations for dynamic video scenes are critical for\napplications ranging from video compression to interactive simulations. Yet,\nexisting methods often face challenges related to high memory usage, lengthy\ntraining times, and temporal consistency. To address these issues, we introduce\na novel neural video representation that combines 3D Gaussian splatting with\ncontinuous camera motion modeling. By leveraging Neural ODEs, our approach\nlearns smooth camera trajectories while maintaining an explicit 3D scene\nrepresentation through Gaussians. Additionally, we introduce a spatiotemporal\nhierarchical learning strategy, progressively refining spatial and temporal\nfeatures to enhance reconstruction quality and accelerate convergence. This\nmemory-efficient approach achieves high-quality rendering at impressive speeds.\nExperimental results show that our hierarchical learning, combined with robust\ncamera motion modeling, captures complex dynamic scenes with strong temporal\nconsistency, achieving state-of-the-art performance across diverse video\ndatasets in both high- and low-motion scenarios."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08272"
    ],
    "c_title":[
      "Quantum wormholes at the end of the world"
    ],
    "c_abstract":[
      "We derive the interesting result that the two asymptotically flat Universes\nclassically linked by the Einstein-Rosen bridge may also be quantum\nmechanically connected in their far out regions. This would be felt by the\nNewtonian potential far away from a black\/white hole system, and raises the\npossibility of establishing communication via perturbations. We obtain our\nresults by means of wavepackets with a small variance in the mass, solving the\nequations derived from a maximally symmetry-reduced canonical quantisation\nmethod. Mass and a proxy of the Newtonian potential appear as canonical duals,\nleading to a Heisenberg uncertainty relation between the two. Coherent states\nare then built, which become non-semiclassical only in two regions: asymptotic\nspatial infinity (where unitarity forces the packets to ''feel'' the other\nasymptotic spatial infinity), and inside the horizon at $r=Gm$ where there is\nringing. Whilst the latter has been noted in the literature, the former -- the\nquantum wormhole -- seems to have eluded past scrutiny. Further studies are\nrequired to examine the stability of these conclusions beyond their\nsymmetry-reduced test tube."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-983",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13819"
    ],
    "b_title":[
      "Simplicity of singular value spectrum of random matrices and two-point\n  quantitative invertibility"
    ],
    "b_abstract":[
      "Let $A$ be an $n\\times n$ random matrix with independent, identically\ndistributed mean 0, variance 1 subgaussian entries. We prove that $$\n\\mathbb{P}(A\\text{ has distinct singular values})\\geq 1-e^{-cn} $$ for some\n$c>0$, confirming a conjecture of Vu. This result is then generalized to\nsingular values of rectangular random matrices with i.i.d. entries.\n  We also prove that for two fixed real numbers $\\lambda_1,\\lambda_2$ with a\nsufficient lower bound on $|\\lambda_1-\\lambda_2|$, we have a joint singular\nvalue small ball estimate for any $\\epsilon>0$ $$\n\\mathbb{P}(\\sigma_{min}(A-\\lambda_1I_n)\\leq\\epsilon\nn^{-1\/2},\\sigma_{min}(A-\\lambda_2I_n)\\leq\\epsilon n^{-1\/2})\\leq\nC\\epsilon^2+e^{-cn}, $$ where $\\sigma_{min}(A)$ is the minimal singular value\nof a square matrix $A$ and $I_n$ is the identity matrix. For much smaller\n$|\\lambda_1-\\lambda_2|$ we derive a similar estimate with $C$ replaced by\n$C\\sqrt{n}\/|\\lambda_1-\\lambda_2|$. This generalizes the one-point estimate of\nRudelson and Vershynin, which proves $\\mathbb{P}(\\sigma_{min}(A)\\leq \\epsilon\nn^{-1\/2})\\leq C\\epsilon+e^{-cn}$. Analogous two-point bounds are proven when\n$A$ has i.i.d. real and complex parts, with $\\epsilon^4$ in place of\n$\\epsilon^2$ on the right hand side of the estimate and for any complex numbers\n$\\lambda_1,\\lambda_2$. These two point estimates can be used to derive strong\nanticoncentration bounds for an arbitrary linear combination of two eigenvalues\nof $A$."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.00584"
    ],
    "c_title":[
      "Formally exact fluorescence spectroscopy simulations for mesoscale\n  molecular aggregates with $N^0$ scaling"
    ],
    "c_abstract":[
      "We present a size-invariant (i.e., $N^0$) scaling algorithm for simulating\nfluorescence spectroscopy in large molecular aggregates. We combine the dyadic\nadaptive hierarchy of pure states (DadHOPS) equation-of-motion with an operator\ndecomposition scheme and an efficient Monte Carlo sampling algorithm to enable\na formally exact, local description of the fluorescence spectrum in large\nmolecular aggregates. Furthermore, we demonstrate that the ensemble average\ninverse participation ratio (IPR) of DadHOPS wave functions reproduces the\ndelocalization extent extracted from fluorescence spectroscopy of J-aggregates\nwith strong vibronic transitions. This work provides a computationally\nefficient framework for fluorescence simulations, offering a new tool for\nunderstanding the optical properties of mesoscale molecular systems."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-984",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05928"
    ],
    "b_title":[
      "Triangle-free cyclic conjugacy class graph of a finite group"
    ],
    "b_abstract":[
      "We generalize the enhanced power graph by replacing elements with conjugacy\nclasses. The main result of this paper is to determine when this graph is\ntriangle-free."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.10714"
    ],
    "c_title":[
      "Disentangle Nighttime Lens Flares: Self-supervised Generation-based Lens\n  Flare Removal"
    ],
    "c_abstract":[
      "Lens flares arise from light reflection and refraction within sensor arrays,\nwhose diverse types include glow, veiling glare, reflective flare and so on.\nExisting methods are specialized for one specific type only, and overlook the\nsimultaneous occurrence of multiple typed lens flares, which is common in the\nreal-world, e.g. coexistence of glow and displacement reflections from the same\nlight source. These co-occurring lens flares cannot be effectively resolved by\nthe simple combination of individual flare removal methods, since these\ncoexisting flares originates from the same light source and are generated\nsimultaneously within the same sensor array, exhibit a complex interdependence\nrather than simple additive relation. To model this interdependent flare\nrelationship, our Nighttime Lens Flare Formation model is the first attempt to\nlearn the intrinsic physical relationship between flares on the imaging plane.\nBuilding on this physical model, we introduce a solution to this joint flare\nremoval task named Self-supervised Generation-based Lens Flare Removal Network\n(SGLFR-Net), which is self-supervised without pre-training. Specifically, the\nnighttime glow is detangled in PSF Rendering Network(PSFR-Net) based on PSF\nRendering Prior, while the reflective flare is modelled in Texture Prior Based\nReflection Flare Removal Network (TPRR-Net). Empirical evaluations demonstrate\nthe effectiveness of the proposed method in both joint and individual glare\nremoval tasks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-985",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.10547"
    ],
    "b_title":[
      "HyperCam: Low-Power Onboard Computer Vision for IoT Cameras"
    ],
    "b_abstract":[
      "We present HyperCam, an energy-efficient image classification pipeline that\nenables computer vision tasks onboard low-power IoT camera systems. HyperCam\nleverages hyperdimensional computing to perform training and inference\nefficiently on low-power microcontrollers. We implement a low-power wireless\ncamera platform using off-the-shelf hardware and demonstrate that HyperCam can\nachieve an accuracy of 93.60%, 84.06%, 92.98%, and 72.79% for MNIST,\nFashion-MNIST, Face Detection, and Face Identification tasks, respectively,\nwhile significantly outperforming other classifiers in resource efficiency.\nSpecifically, it delivers inference latency of 0.08-0.27s while using\n42.91-63.00KB flash memory and 22.25KB RAM at peak. Among other machine\nlearning classifiers such as SVM, xgBoost, MicroNets, MobileNetV3, and\nMCUNetV3, HyperCam is the only classifier that achieves competitive accuracy\nwhile maintaining competitive memory footprint and inference latency that meets\nthe resource requirements of low-power camera systems."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.08790"
    ],
    "c_title":[
      "Entering the overcritical regime of nonlinear Breit-Wheeler pair\n  production in collisions of bremsstrahlung $\\gamma$-rays and superintense,\n  tightly focused laser pulses"
    ],
    "c_abstract":[
      "Near-future high-intensity lasers offer prospects for the observation of\nnonlinear Breit-Wheeler pair production in an overcritical field regime, where\nthe quantum nonlinearity parameter substantially exceeds unity. This\nexperimentally yet unexplored scenario is envisaged here to be reached via the\ncollision of a tightly focused laser pulse with high-energy bremsstrahlung\nphotons. We calculate the achievable number of positrons in a range of laser\nintensities around 10$^{23}$ W\/cm$^2$ and GeV-energies of the incident\nbremsstrahlung-generating electron beam. We investigate under which conditions\nthe attenuation of the $\\gamma$-beam due to the production process must be\ntaken into account. In the considered interaction regime, where the local\nproduction rate grows rather moderately with higher field intensities, it is\nshown that the range of mostly contributing bremsstrahlung frequencies is\ngenerally very broad. For sufficiently large values of the quantum nonlinearity\nparameter, an optimum domain of frequencies emerges which is located far below\nthe spectral endpoint. Furthermore, we show that it is beneficial for achieving\nthe optimum pair yield to increase the interaction volume by a wider laser\nfocus at the expense of decreased field intensity."
    ],
    "c_categories":[
      [
        "hep-ph",
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-986",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.05409"
    ],
    "b_title":[
      "Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV\n  in Ocean Environment"
    ],
    "b_abstract":[
      "This paper proposes a vision-in-the-loop simulation environment for deep\nmonocular pose estimation of a UAV operating in an ocean environment. Recently,\na deep neural network with a transformer architecture has been successfully\ntrained to estimate the pose of a UAV relative to the flight deck of a research\nvessel, overcoming several limitations of GPS-based approaches. However,\nvalidating the deep pose estimation scheme in an actual ocean environment poses\nsignificant challenges due to the limited availability of research vessels and\nthe associated operational costs. To address these issues, we present a\nphoto-realistic 3D virtual environment leveraging recent advancements in\nGaussian splatting, a novel technique that represents 3D scenes by modeling\nimage pixels as Gaussian distributions in 3D space, creating a lightweight and\nhigh-quality visual model from multiple viewpoints. This approach enables the\ncreation of a virtual environment integrating multiple real-world images\ncollected in situ. The resulting simulation enables the indoor testing of\nflight maneuvers while verifying all aspects of flight software, hardware, and\nthe deep monocular pose estimation scheme. This approach provides a\ncost-effective solution for testing and validating the autonomous flight of\nshipboard UAVs, specifically focusing on vision-based control and estimation\nalgorithms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.02291"
    ],
    "c_title":[
      "SpecDis: Value added distance catalogue for 4 million stars from DESI\n  Year-1 data"
    ],
    "c_abstract":[
      "We present the SpecDis value added stellar distance catalogue accompanying\nDESI DR1. SpecDis trains a feed-forward Neural Network (NN) on a large sample\nof stars with Gaia parallaxes, but without applying selections on parallax\nerror or signal-to-noise (S\/N) of the stellar spectra. We incorporate parallax\nerror into the loss function for training. This approach ensures the training\nsample not suffering from biases. Moreover, SpecDis predicts the reciprocal of\nthe square root of luminosity, which is linearly proportional to parallax and\nhelps to avoid excluding negative parallaxes. To enhance the precision of\ndistance predictions, we employ Principal Component Analysis (PCA) to reduce\nthe noise and dimensionality of stellar spectra. Validated by independent\nexternal samples of member stars with precise distances from globular clusters,\ndwarf galaxies, and stellar streams, combined with BHB stars, we demonstrate\nthat our distance measurements show no significant bias up to 100 kpc, and are\nmuch more precise than Gaia parallax beyond 7 kpc. The median distance\nuncertainties are 23 %, 19 %, 11 % and 7 % for S\/N$<$20, 20$\\leq$S\/N$<$ 60,\n60$\\leq$ S\/N $<$ 100 and S\/N$\\geq$100. Selecting stars with $\\log g<3.8$ and\ndistance uncertainties smaller than 25 %, we have more than 74,000 giant\ncandidates within 50 kpc to the Galactic center and 1,500 candidates beyond\nthis distance. Additionally, we develop a Gaussian mixture model to identify\nbinaries and identify 120,000 possible binaries, and discover that the binary\nfraction increases with [Fe\/H] and $\\log g$ and declines with [$\\alpha$\/Fe] and\n$T_\\mathrm{eff}$, indicating stars with low Fe and high $\\alpha$, which form\nearly, may have experienced more encounters and tidal effects to disrupt\nbinaries. Our final catalogue provides distances and distance uncertainties for\n$>$4 million stars, offering a valuable resource for Galactic astronomy."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-987",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01753"
    ],
    "b_title":[
      "Detecting Turbulent Patterns in Particulate Pipe Flow by Streak Angle\n  Visualization"
    ],
    "b_abstract":[
      "Detecting the transition from laminar to turbulent flow in particulate pipe\nsystems remains a complex issue in fluid dynamics, often requiring\nsophisticated and costly experimental apparatus. This research presents an\ninnovative streak visualization method designed to offer a simple and robust\napproach to identify transitional turbulent patterns in particulate pipe flows\nwith neutrally buoyant particles. The technique employs a laser arrangement and\na low-cost camera setup to capture particle-generated streaks within the fluid,\nenabling real-time observation of flow patterns. Validation of the proposed\nmethod was conducted through comparison with established techniques like\nParticle Image Velocimetry (PIV) and pressure drop measurements, confirming its\naccuracy and reliability. Experiments demonstrate the streak visualization\nmethod's capacity to differentiate between laminar, transitional, and turbulent\nflow regimes by analyzing the standard deviation of streak angles. The method\nis especially efficient at low particle concentration, ie precisely where other\nmore established methods become less effective. Furthermore, this technique\nenables us to identify a critical Reynolds number using Kullback-Leibler\ndivergence built on the statistical distribution of streak angles, which is\nconsistent with previous studies.\n  Because it is effective at low concentrations and robust, this streak\nvisualization technique opens new perspectives for the characterization of\nparticulate pipe flows not only in the confines of the laboratory but also in\nless controlled industrial multi-phase flows where determining the laminar or\nturbulent nature of the flow is a prerequisite for flowmeter calibration."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2501.07335"
    ],
    "c_title":[
      "TempoGPT: Enhancing Time Series Reasoning via Quantizing Embedding"
    ],
    "c_abstract":[
      "Multi-modal language model has made advanced progress in vision and audio,\nbut still faces significant challenges in dealing with complex reasoning tasks\nin the time series domain. The reasons are twofold. First, labels for\nmulti-modal time series data are coarse and devoid of analysis or reasoning\nprocesses. Training with these data cannot improve the model's reasoning\ncapabilities. Second, due to the lack of precise tokenization in processing\ntime series, the representation patterns for temporal and textual information\nare inconsistent, which hampers the effectiveness of multi-modal alignment. To\naddress these challenges, we propose a multi-modal time series data\nconstruction approach and a multi-modal time series language model (TLM),\nTempoGPT. Specially, we construct multi-modal data for complex reasoning tasks\nby analyzing the variable-system relationships within a white-box system.\nAdditionally, proposed TempoGPT achieves consistent representation between\ntemporal and textual information by quantizing temporal embeddings, where\ntemporal embeddings are quantized into a series of discrete tokens using a\npredefined codebook; subsequently, a shared embedding layer processes both\ntemporal and textual tokens. Extensive experiments demonstrate that TempoGPT\naccurately perceives temporal information, logically infers conclusions, and\nachieves state-of-the-art in the constructed complex time series reasoning\ntasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing\ntemporal embeddings in enhancing multi-modal alignment and the reasoning\ncapabilities of TLMs. Code and data are available at\nhttps:\/\/github.com\/zhanghaochuan20\/TempoGPT."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-988",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.05656"
    ],
    "b_title":[
      "Small-Scale Testbeds for Connected and Automated Vehicles and Robot\n  Swarms: Challenges and a Roadmap"
    ],
    "b_abstract":[
      "This article proposes a roadmap to address the current challenges in\nsmall-scale testbeds for Connected and Automated Vehicles (CAVs) and robot\nswarms. The roadmap is a joint effort of participants in the workshop \"1st\nWorkshop on Small-Scale Testbeds for Connected and Automated Vehicles and Robot\nSwarms,\" held on June 2 at the IEEE Intelligent Vehicles Symposium (IV) 2024 in\nJeju, South Korea. The roadmap contains three parts: 1) enhancing accessibility\nand diversity, especially for underrepresented communities, 2) sharing best\npractices for the development and maintenance of testbeds, and 3) connecting\ntestbeds through an abstraction layer to support collaboration. The workshop\nfeatures eight invited speakers, four contributed papers [1]-[4], and a\npresentation of a survey paper on testbeds [5]. The survey paper provides an\nonline comparative table of more than 25 testbeds, available at\nhttps:\/\/bassamlab.github.io\/testbeds-survey. The workshop's own website is\navailable at https:\/\/cpm-remote.lrt.unibw-muenchen.de\/iv24-workshop."
    ],
    "b_categories":[
      [
        "cs.MA",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.10703"
    ],
    "c_title":[
      "Simulation of Binary-Single Interactions in AGN Disk I: Gas-Enhanced\n  Binary Orbital Hardening"
    ],
    "c_abstract":[
      "Stellar-mass binary black hole\\,(BBH) mergers within the accretion disks of\nactive galactic nuclei may contribute to gravitational wave\\,(GW) events\ndetected by grounded-based GW detectors. In particular, the interaction between\na BBH and a single stellar-mass black hole\\,(sBH), known as the binary-single\ninteraction\\,(BSI) process, can potentially lead to GW events with detectable\nnon-zero eccentricity. Previous studies of the BSI process, which neglected the\neffects of gas, showed that BSIs contribute non-negligibly to GW events in a\ncoplanar disk environment. In this work, we conduct a series of 2-dimensional\nhydrodynamical and N-body simulations to explore the BSI in a gas environment\nby coupling REBOUND with Athena++. We perform 360 simulation runs, spanning\nparameters in disk surface density \\(\\Sigma_0\\) and impact parameter \\(b\\). We\nfind that the gas-induced energy dissipation within the three-body system\nbecomes significant if the encounter velocity between the sBHs is sufficiently\nlarge\\,($\\gg c_s$). Our simulation results indicate that approximately half of\nthe end states of the BSI are changed by gas. Furthermore, at higher gas\ndensity, the number of close encounters during the BSI process will increase\nand the end-state BBHs tend to be more compact. Consequently, the presence of\ngas may shorten the GW merger timescale for end-state BBHs and increase the\nthree-body merger rate."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-989",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.01654"
    ],
    "b_title":[
      "Fundamental polytope for the isometry group of an alcove"
    ],
    "b_abstract":[
      "A fundamental alcove $\\mathcal{A}$ is a tile in a paving of a vector space\n$V$ by an affine reflection group $W_{\\mathrm{aff}}$. Its geometry encodes\nessential features of $W_{\\mathrm{aff}}$, such as its affine Dynkin diagram\n$\\widetilde{D}$ and fundamental group $\\Omega$. In this article we investigate\nits full isometry group $\\mathrm{Aut}(\\mathcal{A})$. It is well known that the\nisometry group of a regular polyhedron is generated by hyperplane reflections\non its faces. Being a simplex, an alcove $\\mathcal{A}$ is the simplest of\npolyhedra, nevertheless it is seldom a regular one. In our first main result we\nshow that $\\mathrm{Aut}(\\mathcal{A})$ is isomorphic to\n$\\mathrm{Aut}(\\widetilde{D})$. Building on this connection, we establish that\n$\\mathrm{Aut}(\\mathcal{A})$ is an abstract Coxeter group, with generators given\nby affine isometric involutions of the ambient space. Although these\ninvolutions are seldom reflections, our second main result leverages them to\nconstruct, by slicing the Komrakov--Premet fundamental polytope $\\mathcal{K}$\nfor the action of $\\Omega$, a family of fundamental polytopes for the action of\n$\\mathrm{Aut}(\\mathcal{A})$ on $\\mathcal{A}$, whose vertices are contained in\nthe vertices of $\\mathcal{K}$ and whose faces are parametrized by the so-called\nbalanced minuscule roots, which we introduce here. In an appendix, we discuss\nsome related negative results on stratified centralizers and equivariant\ntriangulations."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.04370"
    ],
    "c_title":[
      "DreamDPO: Aligning Text-to-3D Generation with Human Preferences via\n  Direct Preference Optimization"
    ],
    "c_abstract":[
      "Text-to-3D generation automates 3D content creation from textual\ndescriptions, which offers transformative potential across various fields.\nHowever, existing methods often struggle to align generated content with human\npreferences, limiting their applicability and flexibility. To address these\nlimitations, in this paper, we propose DreamDPO, an optimization-based\nframework that integrates human preferences into the 3D generation process,\nthrough direct preference optimization. Practically, DreamDPO first constructs\npairwise examples, then compare their alignment with human preferences using\nreward or large multimodal models, and lastly optimizes the 3D representation\nwith a preference-driven loss function. By leveraging pairwise comparison to\nreflect preferences, DreamDPO reduces reliance on precise pointwise quality\nevaluations while enabling fine-grained controllability through\npreference-guided optimization. Experiments demonstrate that DreamDPO achieves\ncompetitive results, and provides higher-quality and more controllable 3D\ncontent compared to existing methods. The code and models will be open-sourced."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-990",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.14900"
    ],
    "b_title":[
      "Deep Contrastive Unlearning for Language Models"
    ],
    "b_abstract":[
      "The past a few years have witnessed the great success of large language\nmodels, demonstrating powerful capabilities in comprehending textual data and\ngenerating human-like languages. Large language models achieve success by being\ntrained on vast amounts of textual data, including online sources with\ncopyrighted content and user-generated knowledge. However, this comes at a\ncost: the potential risk of exposing users' privacy and violating copyright\nprotections. Thus, to safeguard individuals' \"right to be forgotten\", there has\nbeen increasing interests in machine unlearning -- the process of removing\ninformation carried by particular training samples from a model while not\ndeteriorating its predictive quality. This is a challenging task due to the\nblack-box nature of language models. Most existing studies focus on mitigating\nthe impact of those forgot samples upon a model's outputs, and do not\nexplicitly consider the geometric distributions of samples in the latent space\nof a model. To address this issue, we propose a machine unlearning framework,\nnamed Deep Contrastive Unlearning for fine-Tuning (DeepCUT) language models.\nOur proposed model achieves machine unlearning by directly optimizing the\nlatent space of a model. Comprehensive experiments on real-world datasets\ndemonstrate the effectiveness and efficiency of DeepCUT with consistent and\nsignificant improvement over baseline methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.19565"
    ],
    "c_title":[
      "Noise-induced Extreme Events in Hodgkin-Huxley Neural Networks"
    ],
    "c_abstract":[
      "Extreme events are rare, large-scale deviations from typical system behavior\nthat can occur in nonlinear dynamical systems. In this study, we explore the\nemergence of extreme events within a network of identical stochastic\nHodgkin-Huxley neurons with mean-field coupling. The neurons are exposed to\nuncorrelated noise, which introduces stochastic electrical fluctuations that\ninfluence their spiking activity. Analyzing the variations in the amplitude of\nthe mean field, we observe a smooth transition from small-amplitude,\nout-of-sync activity to synchronized spiking activity as the coupling parameter\nincreases, while an abrupt transition occurs with increasing noise intensity.\nHowever, beyond a certain threshold, the coupling abruptly suppresses the\nspiking activity of the network. Our analysis reveals that the influence of\nnoise combined with neuronal coupling near the abrupt transitions can trigger\ncascades of synchronized spiking activity, identified as extreme events. The\nanalysis of the entropy of the mean field allows us to detect the parameter\nregion where these events occur. We characterize the statistics of these events\nand find that, as the network size increases, the parameter range where they\noccur decreases significantly. Our findings shed light on the mechanisms\ndriving extreme events in neural networks and how noise and neural coupling\nshape collective behavior."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.bio-ph",
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-991",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.02928"
    ],
    "b_title":[
      "Large Language Model Guided Self-Debugging Code Generation"
    ],
    "b_abstract":[
      "Automated code generation is gaining significant importance in intelligent\ncomputer programming and system deployment. However, current approaches often\nface challenges in computational efficiency and lack robust mechanisms for code\nparsing and error correction. In this work, we propose a novel framework,\nPyCapsule, with a simple yet effective two-agent pipeline and efficient\nself-debugging modules for Python code generation. PyCapsule features\nsophisticated prompt inference, iterative error handling, and case testing,\nensuring high generation stability, safety, and correctness. Empirically,\nPyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3%\non HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art\nmethods. We also observe a decrease in normalized success rate given more\nself-debugging attempts, potentially affected by limited and noisy error\nfeedback in retention. PyCapsule demonstrates broader impacts on advancing\nlightweight and efficient code generation for artificial intelligence systems."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2501.14806"
    ],
    "c_title":[
      "T-odd observables from anomalous $tbW$ couplings in single-top W\n  associated production at the LHC"
    ],
    "c_abstract":[
      "We investigate the possibility that an imaginary anomalous $tbW$ coupling can\nbe measured in the process $pp \\to tW^-X$ by means of T-odd observables. One\nsuch observable is the polarization of the top quark transverse to the\nproduction plane. Another is the asymmetry between the cross sections with a\npositive and with a negative value of a certain T-odd correlation constructed\nout of observable momenta when the top quark decays leptonically. The mean\nvalue of this correlation, which is also T-odd, is the third observable. These\nthree T-odd observables are shown to be proportional to the imaginary part of\nonly one of the $tbW$ anomalous couplings, the other couplings giving vanishing\ncontributions. This imaginary part could signal either a CP-odd coupling, or an\nabsorptive part in the effective coupling. We estimate the 1-$\\sigma$ limits\nthat might be derived in the case of each of these observables for\ncentre-of-mass energies 7, 8, 13 and 14 TeV at the LHC."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-992",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.18876"
    ],
    "b_title":[
      "QMe14S, A Comprehensive and Efficient Spectral Dataset for Small Organic\n  Molecules"
    ],
    "b_abstract":[
      "Developing machine learning protocols for molecular simulations requires\ncomprehensive and efficient datasets. Here we introduce the QMe14S dataset,\ncomprising 186,102 small organic molecules featuring 14 elements (H, B, C, N,\nO, F, Al, Si, P, S, Cl, As, Se, Br) and 47 functional groups. Using density\nfunctional theory at the B3LYP\/TZVP level, we optimized the geometries and\ncalculated properties including energy, atomic charge, atomic force, dipole\nmoment, quadrupole moment, polarizability, octupole moment, first\nhyperpolarizability, and Hessian. At the same level, we obtained the harmonic\nIR, Raman and NMR spectra. Furthermore, we conducted ab initio molecular\ndynamics simulations to generate dynamic configurations and extract\nnonequilibrium properties, including energy, forces, and Hessians. By\nleveraging our E(3)-equivariant message-passing neural network (DetaNet), we\ndemonstrated that models trained on QMe14S outperform those trained on the\npreviously developed QM9S dataset in simulating molecular spectra. The QMe14S\ndataset thus serves as a comprehensive benchmark for molecular simulations,\noffering valuable insights into structure-property relationships."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.03526"
    ],
    "c_title":[
      "A Novel First-order Method with Event-driven Objective Evaluations"
    ],
    "c_abstract":[
      "Arising in semi-parametric statistics, control applications, and as\nsub-problems in global optimization methods, certain optimization problems can\nhave objective functions requiring numerical integration to evaluate, yet\ngradient function evaluations that are relatively cheap. For such problems,\ntypical optimization methods that require multiple evaluations of the objective\nfor each new iterate become computationally expensive. In light of this,\noptimization methods that avoid objective function evaluations are attractive,\nyet we show anti-convergence behavior for these methods on the problem class of\ninterest. To address this gap, we develop a novel gradient algorithm that only\nevaluates the objective function when specific events are triggered and propose\na step size scheme that greedily takes advantage of the properties induced by\nthese triggering events. We prove that our methodology has global convergence\nguarantees under the most general smoothness conditions, and show through\nextensive numerical results that our method performs favorably on optimization\nproblems arising in semi-parametric statistics."
    ],
    "c_categories":[
      [
        "math.OC",
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-993",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.13026"
    ],
    "b_title":[
      "Deriving the paradox: original derivation of Hawking radiation"
    ],
    "b_abstract":[
      "We revisit Hawking's original derivation of the evaporation process in a\nnon-stationary spacetime, presenting it in a clear and pedagogical manner, with\na focus on the spherical collapse of a star into a black hole. Our analysis\nhighlights the underlying assumptions in the calculations, clarifying their\nphysical significance, potential implications, and the limitations of this\napproach."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.09326"
    ],
    "c_title":[
      "Uplink OFDM Channel Prediction with Hybrid CNN-LSTM for 6G\n  Non-Terrestrial Networks"
    ],
    "c_abstract":[
      "Wireless communications are typically subject to complex channel dynamics,\nrequiring the transmission of pilot sequences to estimate and equalize such\neffects and correctly receive information bits. This is especially true in 6G\nnon-terrestrial networks (NTNs) in low Earth orbit, where one end of the\ncommunication link orbits around the Earth at several kilometers per second,\nand a multi-carrier waveform, such as orthogonal frequency division\nmultiplexing (OFDM), is employed. To minimize the pilot overhead, we remove\npilot symbols every other OFDM slot and propose a channel predictor to obtain\nthe channel frequency response (CFR) matrix in absence of pilots. The algorithm\nemploys an encoder-decoder convolutional neural network and a long short-term\nmemory layer, along with skip connections, to predict the CFR matrix on the\nupcoming slot based on the current one. We demonstrate the effectiveness of the\nproposed predictor through numerical simulations in tapped delay line channel\nmodels, highlighting the effective throughput improvement. We further assess\nthe generalization capabilities of the model, showing minimal throughput\ndegradation when testing under different Doppler spreads and in both line of\nsight (LoS) and non-LoS propagation conditions. Finally, we discuss\ncomputational-complexity-related aspects of the lightweight hybrid CNN-LSTM\narchitecture."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-994",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.00383"
    ],
    "b_title":[
      "Theoretical Insights in Model Inversion Robustness and Conditional\n  Entropy Maximization for Collaborative Inference Systems"
    ],
    "b_abstract":[
      "By locally encoding raw data into intermediate features, collaborative\ninference enables end users to leverage powerful deep learning models without\nexposure of sensitive raw data to cloud servers. However, recent studies have\nrevealed that these intermediate features may not sufficiently preserve\nprivacy, as information can be leaked and raw data can be reconstructed via\nmodel inversion attacks (MIAs). Obfuscation-based methods, such as noise\ncorruption, adversarial representation learning, and information filters,\nenhance the inversion robustness by obfuscating the task-irrelevant redundancy\nempirically. However, methods for quantifying such redundancy remain elusive,\nand the explicit mathematical relation between this redundancy minimization and\ninversion robustness enhancement has not yet been established. To address that,\nthis work first theoretically proves that the conditional entropy of inputs\ngiven intermediate features provides a guaranteed lower bound on the\nreconstruction mean square error (MSE) under any MIA. Then, we derive a\ndifferentiable and solvable measure for bounding this conditional entropy based\non the Gaussian mixture estimation and propose a conditional entropy\nmaximization (CEM) algorithm to enhance the inversion robustness. Experimental\nresults on four datasets demonstrate the effectiveness and adaptability of our\nproposed CEM; without compromising feature utility and computing efficiency,\nplugging the proposed CEM into obfuscation-based defense mechanisms\nconsistently boosts their inversion robustness, achieving average gains ranging\nfrom 12.9\\% to 48.2\\%. Code is available at\n\\href{https:\/\/github.com\/xiasong0501\/CEM}{https:\/\/github.com\/xiasong0501\/CEM}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2502.20403"
    ],
    "c_title":[
      "Adversarial Robustness of Partitioned Quantum Classifiers"
    ],
    "c_abstract":[
      "Adversarial robustness in quantum classifiers is a critical area of study,\nproviding insights into their performance compared to classical models and\nuncovering potential advantages inherent to quantum machine learning. In the\nNISQ era of quantum computing, circuit cutting is a notable technique for\nsimulating circuits that exceed the qubit limitations of current devices,\nenabling the distribution of a quantum circuit's execution across multiple\nquantum processing units through classical communication. We examine how\npartitioning quantum classifiers through circuit cutting increase their\nsusceptibility to adversarial attacks, establishing a link between attacking\nthe state preparation channels in wire cutting and implementing adversarial\ngates within intermediate layers of a quantum classifier. We then proceed to\nstudy the latter problem from both a theoretical and experimental perspective."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-995",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.08056"
    ],
    "b_title":[
      "Magnetic Dichroism in Rutile NiF$_2$: Separating Altermagnetic and\n  Ferromagnetic Effects"
    ],
    "b_abstract":[
      "We present numerical simulations of x-ray magnetic circular dichroism (XMCD)\nat the L$_{2,3}$ edge of Ni in the weakly ferromagnetic altermagnet NiF$_2$.\nOur results predict a significant XMCD signal for light propagating\nperpendicular to the magnetic moments, which are approximately aligned along\nthe [100] easy-axis direction. The analysis shows that the altermagnetic and\nferromagnetic contributions to the XMCD signal can be uniquely distinguished by\ntheir dependence on an applied magnetic field. By varying the angle of the\nfield relative to the easy axis, the in-plane orientation of both the N\\'eel\nvector and the net magnetization can be systematically controlled. We further\ndemonstrate that the XMCD signal, even under fields as strong as 40 T and for\nany in-plane orientation, can be accurately described as a linear combination\nof two spectral components, with geometrical prefactors determined by the field\nmagnitude and direction. This insight enables experimental validation of the\ndistinctive relationship between the N\\'eel vector orientation and the x-ray\nHall vector in the rutile structure. Quantitative simulations supporting these\nfindings are provided."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "2502.16610"
    ],
    "c_title":[
      "AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive\n  Adversarial VAEs"
    ],
    "c_abstract":[
      "Ensuring the quality and integrity of medical images is crucial for\nmaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosis\nand Computer-Aided Detection (CAD) systems. Covariate shifts are subtle\nvariations in the data distribution caused by different imaging devices or\nsettings and can severely degrade model performance, similar to the effects of\nadversarial attacks. Therefore, it is vital to have a lightweight and fast\nmethod to assess the quality of these images prior to using CAD models.\nAdverX-Ray addresses this need by serving as an image-quality assessment layer,\ndesigned to detect covariate shifts effectively. This Adversarial Variational\nAutoencoder prioritizes the discriminator's role, using the suboptimal outputs\nof the generator as negative samples to fine-tune the discriminator's ability\nto identify high-frequency artifacts. Images generated by adversarial networks\noften exhibit severe high-frequency artifacts, guiding the discriminator to\nfocus excessively on these components. This makes the discriminator ideal for\nthis approach. Trained on patches from X-ray images of specific machine models,\nAdverX-Ray can evaluate whether a scan matches the training distribution, or if\na scan from the same machine is captured under different settings. Extensive\ncomparisons with various OOD detection methods show that AdverX-Ray\nsignificantly outperforms existing techniques, achieving a 96.2% average AUROC\nusing only 64 random patches from an X-ray. Its lightweight and fast\narchitecture makes it suitable for real-time applications, enhancing the\nreliability of medical imaging systems. The code and pretrained models are\npublicly available."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-996",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.06304"
    ],
    "b_title":[
      "Optimization and Benchmarking of Monolithically Stackable Gain Cell\n  Memory for Last-Level Cache"
    ],
    "b_abstract":[
      "The Last Level Cache (LLC) is the processor's critical bridge between on-chip\nand off-chip memory levels - optimized for high density, high bandwidth, and\nlow operation energy. To date, high-density (HD) SRAM has been the conventional\ndevice of choice; however, with the slowing of transistor scaling, as reflected\nin the industry's almost identical HD SRAM cell size from 5 nm to 3 nm,\nalternative solutions such as 3D stacking with advanced packaging like hybrid\nbonding are pursued (as demonstrated in AMD's V-cache). Escalating data demands\nnecessitate ultra-large on-chip caches to decrease costly off-chip memory\nmovement, pushing the exploration of device technology toward monolithic 3D\n(M3D) integration where transistors can be stacked in the back-end-of-line\n(BEOL) at the interconnect level. M3D integration requires fabrication\ntechniques compatible with a low thermal budget (<400 degC). Among promising\nBEOL device candidates are amorphous oxide semiconductor (AOS) transistors,\nparticularly desirable for their ultra-low leakage (<fA\/um), enabling\npersistent data retention (>seconds) when used in a gain-cell configuration.\nThis paper examines device, circuit, and system-level tradeoffs when optimizing\nBEOL-compatible AOS-based 2-transistor gain cell (2T-GC) for LLC. A cache\nearly-exploration tool, NS-Cache, is developed to model caches in advanced 7\nand 3 nm nodes and is integrated with the Gem5 simulator to systematically\nbenchmark the impact of the newfound density\/performance when compared to\nHD-SRAM, MRAM, and 1T1C eDRAM alternatives for LLC."
    ],
    "b_categories":[
      [
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "2503.12488"
    ],
    "c_title":[
      "Translation of Valentine Bargmann, \"Remarks on the general relativistic\n  formulation of quantum theory\" (1932)"
    ],
    "c_abstract":[
      "English translation of \"Bemerkungen zur allgemein-relativistischen Fassung\nder Quantentheorie\", originally published in {\\em Sitzber. kgl.-preu{\\ss}.\nAkad. Wiss. Berlin, Sitzung der phys.-math. Klasse} {\\bf XXIV} (1932) 346--354."
    ],
    "c_categories":[
      [
        "gr-qc",
        "physics.hist-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-997",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2503.13993"
    ],
    "b_title":[
      "On a Diophantine Inequality with Primes Yielding Square-Free Sums with\n  Given Numbers"
    ],
    "b_abstract":[
      "Let $\\alpha\\in \\mathbb{R}\\setminus\\mathbb{Q}$ and $\\beta\\in \\mathbb{R}$ be\ngiven. Suppose that $a_1,\\ldots,a_s$ are distinct positive integers that do not\ncontain a reduced residue system modulo $p^2$ for any prime $p$. We prove that\nthere exist infinitely many primes $p$ such that the inequality $||\\alpha\np+\\beta||<p^{-1\/10}$ holds and all the numbers $p+a_1,\\ldots,p+a_s$ are\nsquare-free."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.20347"
    ],
    "c_title":[
      "Modeling Driver Behavior in Speed Advisory Systems: Koopman-based\n  Approach with Online Update"
    ],
    "c_abstract":[
      "Accurate driver behavior modeling is essential for improving the interaction\nand cooperation of the human driver with the driver assistance system. This\npaper presents a novel approach for modeling the response of human drivers to\nvisual cues provided by a speed advisory system using a Koopman-based method\nwith online updates. The proposed method utilizes the Koopman operator to\ntransform the nonlinear dynamics of driver-speed advisory system interactions\ninto a linear framework, allowing for efficient real-time prediction. An online\nupdate mechanism based on Recursive Least Squares (RLS) is integrated into the\nKoopman-based model to ensure continuous adaptation to changes in driver\nbehavior over time. The model is validated using data collected from a\nhuman-in-the-loop driving simulator, capturing diverse driver-specific\ntrajectories. The results demonstrate that the offline learned Koopman-based\nmodel can closely predict driver behavior and its accuracy is further enhanced\nthrough an online update mechanism with the RLS method."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-998",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2501.09741"
    ],
    "b_title":[
      "Asymptotic behavior of clusters in hierarchical species sampling models"
    ],
    "b_abstract":[
      "Consider a sample of size $N$ from a population governed by a hierarchical\nspecies sampling model. We study the large $N$ asymptotic behavior of the\nnumber ${\\bf K}_N$ of clusters and the number ${\\bf M}_{r,N}$ of clusters with\nfrequency $r$ in the sample. In particular, we show almost sure and $L^p$\nconvergence for ${\\bf M}_{r,N}$, obtain Gaussian fluctuation theorems for ${\\bf\nK}_N$, and establish large deviation principles for both ${\\bf K}_N$ and ${\\bf\nM}_{r,N}$. Our approach relies on a random sample size representation of the\nnumber of clusters through the corresponding non-hierarchical species sampling\nmodel."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2502.12074"
    ],
    "c_title":[
      "Lattice QCD Study of Pion Electroproduction and Weak Production from a\n  Nucleon"
    ],
    "c_abstract":[
      "Quantum fluctuations in QCD influence nucleon structure and interactions,\nwith pion production serving as a key probe of chiral dynamics. In this study,\nwe present a lattice QCD calculation of multipole amplitudes at threshold,\nrelated to both pion electroproduction and weak production from a nucleon,\nusing two gauge ensembles near the physical pion mass. We develop a technique\nfor spin projection and construct multiple operators for analyzing the\ngeneralized eigenvalue problem in both the nucleon-pion system in the\ncenter-of-mass frame and the nucleon system with nonzero momentum. The\nnumerical lattice results are then compared with those extracted from\nexperimental data and predicted by low-energy theorems incorporating one-loop\ncorrections."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-999",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":[
      "2502.06447"
    ],
    "b_title":[
      "Biquadratic Tensors: Eigenvalues and Structured Tensors"
    ],
    "b_abstract":[
      "The covariance tensors in statistics{, elasticity tensor in solid mechanics,\nRiemann curvature tensor in relativity theory are all biquadratic tensors that\nare weakly symmetric, but not symmetric in general. Motivated by this, in this\npaper, we consider nonsymmetric biquadratic tensors, and study possible\nconditions and algorithms for identifying positive semi-definiteness and\ndefiniteness of such biquadratic tensors. We extend M-eigenvalues to\nnonsymmetric biquadratic tensors, prove that a general biquadratic tensor has\nat least one M-eigenvalue, and show that a general biquadratic tensor is\npositive semi-definite if and only if all of its M-eigenvalues are nonnegative,\nand a general biquadratic tensor is positive definite if and only if all of its\nM-eigenvalues are positive. We present a Gershgorin-type theorem for\nbiquadratic tensors, and show that (strictly) diagonally dominated biquadratic\ntensors are positive semi-definite (definite). We introduce Z-biquadratic\ntensors, M-biquadratic tensors, strong M-biquadratic tensors, B$_0$-biquadratic\ntensors and B-biquadratic tensors. We show that M-biquadratic tensors and\nsymmetric B$_0$-biquadratic tensors are positive semi-definite, and that strong\nM-biquadratic tensors and symmetric B-biquadratic tensors are positive\ndefinite. A Riemannian LBFGS method for computing the smallest M-eigenvalue of\na general biquadratic tensor is presented. Numerical results are reported."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "2503.06862"
    ],
    "c_title":[
      "FIGLUT: An Energy-Efficient Accelerator Design for FP-INT GEMM Using\n  Look-Up Tables"
    ],
    "c_abstract":[
      "Weight-only quantization has emerged as a promising solution to the\ndeployment challenges of large language models (LLMs). However, it necessitates\nFP-INT operations, which make implementation on general-purpose hardware like\nGPUs difficult. In this paper, we propose FIGLUT, an efficient look-up table\n(LUT)-based GEMM accelerator architecture. Instead of performing traditional\narithmetic operations, FIGLUT retrieves precomputed values from an LUT based on\nweight patterns, significantly reducing the computational complexity. We also\nintroduce a novel LUT design that addresses the limitations of conventional\nmemory architectures. To further improve LUT-based operations, we propose a\nhalf-size LUT combined with a dedicated decoding and multiplexing unit. FIGLUT\nefficiently supports different bit precisions and quantization methods using a\nsingle fixed hardware configuration. For the same 3-bit weight precision,\nFIGLUT demonstrates 59% higher TOPS\/W and 20% lower perplexity than\nstate-of-the-art accelerator designs. When targeting the same perplexity,\nFIGLUT achieves 98% higher TOPS\/W by performing 2.4-bit operations."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"2411.01019",
    "date":null,
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b6",
      "b1"
    ],
    "c_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "c_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "c_categories":[
      [
        "q-bio.CB",
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "date":null,
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "c_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "date":null,
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "c_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "date":null,
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "date":null,
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b2",
      "b0"
    ],
    "c_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "c_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "c_categories":[
      [
        "eess.SP",
        "cs.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "date":null,
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "c_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "date":null,
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "c_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01144",
    "date":null,
    "a_title":"LEARNER: Learning Granular Labels from Coarse Labels using Contrastive\n  Learning",
    "a_abstract":"A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "explanation":"Recent years have seen increasing use of deep learning\n(DL) in predicting diseases using biomedical imaging, such as\npredicting COVID-19 severity using lung ultrasound (LUS)\ndata.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Investigating training-test data splitting strategies for automated segmentation and scoring of COVID-19 lung ultrasound images."
    ],
    "b_abstract":[
      "Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods."
    ],
    "b_categories":[
      [
        "Lung Ultrasound"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A Simple Framework for Contrastive Learning of Visual Representations"
    ],
    "c_abstract":[
      "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "date":null,
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.02695",
    "date":null,
    "a_title":"An ADHD Diagnostic Interface Based on EEG Spectrograms and Deep Learning\n  Techniques",
    "a_abstract":"This paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by employing deep\nlearning (DL) techniques on electroencephalography (EEG) signals. This method\naddresses the limitations of current behavior-based diagnostic methods, which\noften lead to misdiagnosis and gender bias. By utilizing a publicly available\nEEG dataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to extract features\nfor ADHD classification. The model achieved a high precision, recall, and an\noverall F1 score of 0.9. Feature extraction highlighted significant brain\nregions (frontopolar, parietal, and occipital lobes) associated with ADHD.\nThese insights guided the creation of a three-part digital diagnostic system,\nfacilitating cost-effective and accessible ADHD screening, especially in school\nenvironments. This system enables earlier and more accurate identification of\nstudents at risk for ADHD, providing timely support to enhance their\ndevelopmental outcomes. This study showcases the potential of integrating EEG\nanalysis with DL to enhance ADHD diagnostics, presenting a viable alternative\nto traditional methods.",
    "explanation":"his paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by em-\nploying deep learning (DL) techniques on electroencephalography\n(EEG) signals.  By utilizing a publicly available EEG\ndataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to ex-\ntract features for ADHD classification. ",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "EEG data for ADHD \/ Control children"
    ],
    "b_abstract":[
      "Participants were 61 children with ADHD and 60 healthy controls (boys and girls, ages 7-12). The ADHD children were diagnosed by an experienced psychiatrist to DSM-IV criteria, and have taken Ritalin for up to 6 months. None of the children in the control group had a history of psychiatric disorders, epilepsy, or any report of high-risk behaviors. EEG recording was performed based on 10-20 standard by 19 channels (Fz, Cz, Pz, C3, T3, C4, T4, Fp1, Fp2, F3, F4, F7, F8, P3, P4, T5, T6, O1, O2) at 128 Hz sampling frequency. The A1 and A2 electrodes were the references located on earlobes. Since one of the deficits in ADHD children is visual attention, the EEG recording protocol was based on visual attention tasks. In the task, a set of pictures of cartoon characters was shown to the children and they were asked to count the characters. The number of characters in each image was randomly selected between 5 and 16, and the size of the pictures was large enough to be easily visible and countable by children. To have a continuous stimulus during the signal recording, each image was displayed immediately and uninterrupted after the child\u2019s response. Thus, the duration of EEG recording throughout this cognitive visual task was dependent on the child\u2019s performance (i.e. response speed)."
    ],
    "b_categories":[
      [
        "Neurotherapeutics"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Deep Residual Learning for Image Recognition"
    ],
    "c_abstract":[
      "Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8\u00d7 VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "date":null,
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "c_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17702",
    "date":null,
    "a_title":"Finding \"Good Views\" of Electrocardiogram Signals for Inferring\n  Abnormalities in Cardiac Condition",
    "a_abstract":"Electrocardiograms (ECGs) are an established technique to screen for abnormal\ncardiac signals. Recent work has established that it is possible to detect\narrhythmia directly from the ECG signal using deep learning algorithms. While a\nfew prior approaches with contrastive learning have been successful, the best\nway to define a positive sample remains an open question. In this project, we\ninvestigate several ways to define positive samples, and assess which approach\nyields the best performance in a downstream task of classifying arrhythmia. We\nexplore spatiotemporal invariances, generic augmentations, demographic\nsimilarities, cardiac rhythms, and wave attributes of ECG as potential ways to\nmatch positive samples. We then evaluate each strategy with downstream task\nperformance, and find that learned representations invariant to patient\nidentity are powerful in arrhythmia detection. We made our code available in:\nhttps:\/\/github.com\/mandiehyewon\/goodviews_ecg.git",
    "explanation":"Recent work has established that it is possible to de-\ntect arrhythmia directly from the ECG signal using deep learning algorithms. While a few prior approaches with contrastive learning have been successful,\nthe best way to define a positive sample remains an open question.",
    "b_id":[
      "b5",
      "b11"
    ],
    "b_title":[
      "Patient Contrastive Learning: a Performant, Expressive, and Practical Approach to ECG Modeling.",
      "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients"
    ],
    "b_abstract":[
      "Supervised machine learning applications in health care are often limited due to a scarcity of labeled training data. To mitigate this effect small sample size, we introduce pre-training approach, Patient Contrastive Learning Representations (PCLR), which creates latent representations ECGs from large number unlabeled examples. The resulting expressive, performant, and practical across wide spectrum clinical tasks. We develop PCLR using system with over 3.2 million 12-lead ECGs, demonstrate substantial improvements multiple new tasks when there fewer than 5,000 labels.",
      "The healthcare industry generates troves of unlabelled physiological data. This data can be exploited via contrastive learning, a self-supervised pre-training method that encourages representations instances to similar one another. We propose family learning methods, CLOCS, across space, time, \\textit{and} patients show CLOCS consistently outperforms the state-of-the-art BYOL and SimCLR, when performing linear evaluation of, fine-tuning on, downstream tasks. also achieves strong generalization performance with only 25\\% labelled training Furthermore, our procedure naturally patient-specific used quantify patient-similarity."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram"
    ],
    "c_abstract":[
      "Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found1-4. An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction \u226435%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD."
    ],
    "c_categories":[
      [
        "Cardio"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.20007",
    "date":null,
    "a_title":"Uncertainty Quantified Deep Learning and Regression Analysis Framework\n  for Image Segmentation of Skin Cancer Lesions",
    "a_abstract":"Deep learning models (DLMs) frequently achieve accurate segmentation and\nclassification of tumors from medical images. However, DLMs lacking feedback on\ntheir image segmentation mechanisms, such as Dice coefficients and confidence\nin their performance, face challenges when processing previously unseen images\nin real-world clinical settings. Uncertainty estimates to identify DLM\npredictions at the cellular or single-pixel level that require clinician review\ncan enhance trust. However, their deployment requires significant computational\nresources. This study reports two DLMs, one trained from scratch and another\nbased on transfer learning, with Monte Carlo dropout or Bayes-by-backprop\nuncertainty estimations to segment lesions from the publicly available The\nInternational Skin Imaging Collaboration-19 dermoscopy image database with\ncancerous lesions. A novel approach to compute pixel-by-pixel uncertainty\nestimations of DLM segmentation performance in multiple clinical regions from a\nsingle dermoscopy image with corresponding Dice scores is reported for the\nfirst time. Image-level uncertainty maps demonstrated correspondence between\nimperfect DLM segmentation and high uncertainty levels in specific skin tissue\nregions, with or without lesions. Four new linear regression models that can\npredict the Dice performance of DLM segmentation using constants and\nuncertainty measures, either individually or in combination from lesions,\ntissue structures, and non-tissue pixel regions critical for clinical diagnosis\nand prognostication in skin images (Spearman's correlation, p < 0.05), are\nreported for the first time for low-compute uncertainty estimation workflows.",
    "explanation":"Deep learning models (DLMs) frequently achieve\naccurate segmentation and classification of tumors from medical\nimages.  DLMs lacking feedback on their image seg-\nmentation mechanisms such as Dice coefficients and confidence in\ntheir performance face challenges processing previously unseen\nimages in real-world clinical settings. A novel\napproach to compute pixel-by-pixel uncertainty estimations of\nDLM segmentation performance in multiple clinical regions from\na single dermatoscopy image with corresponding Dice scores\nis reported for the first time. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning tools have gained tremendous attention in applied machine learning. However such for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about uncertainty, but usually come with prohibitive computational cost. this paper we develop new theoretical casting dropout training deep neural networks (NNs) as approximate inference Gaussian processes. A direct result of theory gives us uncertainty NNs -- extracting information from existing that has been thrown away so far. This mitigates the problem representing without sacrificing either complexity or test accuracy. We perform an extensive study properties dropout's Various network architectures non-linearities are assessed on tasks classification, using MNIST example. show considerable improvement predictive log-likelihood RMSE compared state-of-the-art methods, finish by reinforcement"
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions"
    ],
    "c_abstract":[
      "Training of neural networks for automated diagnosis pigmented skin lesions is hampered by the small size and lack diversity available datasets dermatoscopic images. We tackle this problem releasing HAM10000 (\"Human Against Machine with 10000 training images\") dataset. collected images from different populations acquired stored modalities. Given we had to apply acquisition cleaning methods developed semi-automatic workflows utilizing specifically trained networks. The final dataset consists 10015 which are released as a set academic machine learning purposes publicly through ISIC archive. This benchmark can be used comparisons human experts. Cases include representative collection all important diagnostic categories in realm lesions. More than 50% have been confirmed pathology, while ground truth rest cases was either follow-up, expert consensus, or confirmation in-vivo confocal microscopy."
    ],
    "c_categories":[
      [
        "Data"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05188",
    "date":null,
    "a_title":"AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive\n  Outcome for Infant Brain Injury",
    "a_abstract":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000\nnewborns, with 30% to 50% of cases resulting in adverse neurocognitive\noutcomes. However, these outcomes can only be reliably assessed as early as age\n2. Therefore, early and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improving clinical\ndecision-making, guiding treatment decisions and assessing novel therapies.\nHowever, a major challenge in developing deep learning models for this purpose\nis the scarcity of large, annotated HIE datasets. We have assembled the first\nand largest public dataset, however it contains only 156 cases with 2-year\nneurocognitive outcome labels. In contrast, we have collected 8,859 normal\nbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are\navailable for brain age estimation using deep learning models. In this paper,\nwe introduce AGE2HIE to transfer knowledge learned by deep learning models from\nhealthy controls brain MRIs to a diseased cohort, from structural to diffusion\nMRIs, from regression of continuous age estimation to prediction of the binary\nneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2\nweeks). Compared to training from scratch, transfer learning from brain age\nestimation significantly improves not only the prediction accuracy (3% or 2%\nimprovement in same or multi-site), but also the model generalization across\ndifferent sites (5% improvement in cross-site validation).",
    "explanation":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of\nevery 1,000 newborns, with 30% to 50% of cases resulting in\nadverse neurocognitive outcomes. However, these outcomes\ncan only be reliably assessed as early as age 2. Therefore,\nearly and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improv-\ning clinical decision-making, guiding treatment decisions and\nassessing novel therapies",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Limitations of conventional magnetic resonance imaging as a predictor of death or disability following neonatal hypoxic-ischemic encephalopathy in the late hypothermia trial"
    ],
    "b_abstract":[
      "Objective: To investigate if magnetic resonance imaging (MRI) is an accurate predictor for death or moderate-severe disability at 18-22 months of age among infants with neonatal encephalopathy in a trial of cooling initiated at 6-24 hours. Study design: Subgroup analysis of infants \u226536 weeks of gestation with moderate-severe neonatal encephalopathy randomized at 6-24 postnatal hours to hypothermia or usual care in a multicenter trial of late hypothermia. MRI scans were performed per each center's practice and interpreted by 2 central readers using the Eunice Kennedy Shriver National Institute of Child Health and Human Development injury score (6 levels, normal to hemispheric devastation). Neurodevelopmental outcomes were assessed at 18-22 months of age. Results: Of 168 enrollees, 128 had an interpretable MRI and were seen in follow-up (n = 119) or died (n = 9). MRI findings were predominantly acute injury and did not differ by cooling treatment. At 18-22 months, death or severe disability occurred in 20.3%. No infant had moderate disability. Agreement between central readers was moderate (weighted kappa 0.56, 95% CI 0.45-0.67). The adjusted odds of death or severe disability increased 3.7-fold (95% CI 1.8-7.9) for each increment of injury score. The area under the curve for severe MRI patterns to predict death or severe disability was 0.77 and the positive and negative predictive values were 36% and 100%, respectively. Conclusions: MRI injury scores were associated with neurodevelopmental outcome at 18-22 months among infants in the Late Hypothermia Trial. However, the results suggest caution when using qualitative interpretations of MRI images to provide prognostic information to families following perinatal hypoxia-ischemia."
    ],
    "b_categories":[
      [
        "Pediatrics"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "What is being transferred in transfer learning?"
    ],
    "c_abstract":[
      "One desired capability for machines is the ability to transfer their knowledge of one domain another where data (usually) scarce. Despite ample adaptation learning in various deep applications, we yet do not understand what enables a successful and which part network responsible that. In this paper, provide new tools analyses address these fundamental questions. Through series on transferring block-shuffled images, separate effect feature reuse from low-level statistics show that some benefit comes latter. We present when training pre-trained weights, model stays same basin loss landscape different instances such are similar space close parameter space."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19345",
    "date":null,
    "a_title":"3D Wasserstein generative adversarial network with dense U-Net based\n  discriminator for preclinical fMRI denoising",
    "a_abstract":"Functional magnetic resonance imaging (fMRI) is extensively used in clinical\nand preclinical settings to study brain function, however, fMRI data is\ninherently noisy due to physiological processes, hardware, and external noise.\nDenoising is one of the main preprocessing steps in any fMRI analysis pipeline.\nThis process is challenging in preclinical data in comparison to clinical data\ndue to variations in brain geometry, image resolution, and low signal-to-noise\nratios. In this paper, we propose a structure-preserved algorithm based on a 3D\nWasserstein generative adversarial network with a 3D dense U-net based\ndiscriminator called, 3D U-WGAN. We apply a 4D data configuration to\neffectively denoise temporal and spatial information in analyzing preclinical\nfMRI data. GAN-based denoising methods often utilize a discriminator to\nidentify significant differences between denoised and noise-free images,\nfocusing on global or local features. To refine the fMRI denoising model, our\nmethod employs a 3D dense U-Net discriminator to learn both global and local\ndistinctions. To tackle potential over-smoothing, we introduce an adversarial\nloss and enhance perceptual similarity by measuring feature space distances.\nExperiments illustrate that 3D U-WGAN significantly improves image quality in\nresting-state and task preclinical fMRI data, enhancing signal-to-noise ratio\nwithout introducing excessive structural changes in existing methods. The\nproposed method outperforms state-of-the-art methods when applied to simulated\nand real data in a fMRI analysis pipeline.",
    "explanation":"Denoising is one of the main preprocessing steps in any fMRI analysis pipeline. In this\npaper, we propose a structure-preserved algorithm based on a 3D Wasserstein\ngenerative adversarial network with a 3D dense U-net based discriminator called,\n3D U-WGAN. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "On the use of preclinical imaging to explore the principles of brain function in rodent models and their relevance for illnesses of the human mind"
    ],
    "b_abstract":[
      "Dear Editor, We recently published in Translational Psychiatry an article that examine the strategies for evaluating brain function at the wholebrain level [1]. In this review, we covered several methods, from functional MRI to functional ultrasound to calcium imaging. For each technique, we wrote a brief history of its development, the physical notion, some key applications, its potentials, and its limitations. We concluded that methods for imaging the rodent brain at the network level are growing and will advance our understanding of brain function. A commentary by Zhuo and colleagues further enhances the complexity of addressing the issue of \u201ctranslation\u201d from animal models to patients for the discipline of psychiatry [2]. They propose that the approaches employed to develop an animal model for a psychiatric disease need to be thoroughly scrutinized and, perhaps, revised. For example, most rodent models of mental diseases are to-date established using a simple pharmacological infusion [3] and\/or psychosocial stimulation [4]. The key concern posed, however, is how these manipulations change the brain\u2019s structure and function, and whether these models genuinely reflect the pathophysiology of human mental illnesses. Especially since it is difficult to evaluate whether one can speak of inverse inference from rodents to humans. This is a true and acceptable statement. However, this is exactly what preclinical imaging aims to deliver. By mapping the dynamic responses of brain networks in animal models and compare them, if possible, with those reported in clinical studies, we can obtain quantitative data and parameters to establish whether our models are effectively translational [5]. If these metrics demonstrate temporal and spatial similarity in network-level modifications as those observed in humans, we can pursue further inquiry utilizing more intrusive and more specific methods for brain recordings in animal models. Otherwise, we must have the confidence and the correctness to move forward and attempt other solutions. Two recent examples. In 2019 we established a causal association between activity of the noradrenergic nucleus locus coeruleus (LC) and the engagement of numerous large-scale brain networks in mice, in particular of the salience and amygdala networks [6]. In addition, we could link network-changes with direct markers of norepinephrine (NE) turnover and with the distribution of NE receptors over the entire brain. The hypothesis that specific brain networks dynamics are related to LC activity and to NE receptor density derives from stress-research and pharmacological studies in humans [7, 8]. However, since it is impossible to selectively stimulate LC in people, it has remained a hypothesis for more than a decade. Our preclinical work helped confirm this causal relationship and this has direct implications for interpreting the results of clinical imaging studies on stress and anxiety behavior. More recently, the Gozzi lab described how chronic local neuronal suppression via overexpression of a potassium channel or acute silencing via chemogenetics result in a paradoxical hyperconnectivity [9]; an intriguing finding often reported in humans after stroke [10] and in early stages of Alzheimer\u2019s disease [11], but never truly understood. Using in vivo electrophysiology, they showed local inhibition improves low frequency (0.1\u20134 Hz) oscillatory power via suppression of neuronal activity not phaselocked to slow rhythms, resulting in increased slow and \u03b4 band coherence between areas that display fMRI overconnectivity. These data present causal evidence that cortical inactivation can counterintuitively augment fMRI connectivity via greater, lesslocalized slow oscillatory processes. Once again, this could be only achieved by combining functional MRI and electrophysiology with neuromodulation in animal models. These and other examples give a peek of what the future of preclinical imaging might look like: a field of research capable of delivering causal explanations to the hypotheses presented by human neuroscience, neurology and psychiatry. Lastly, I would argue against statements like \u201cthe computational complexity of human brains is billions of times that of mouse brain\u201d. While this may be true from a numerical standpoint of mere neuronal counts, preclinical neuroimaging\u2019s objective should not be per se to map every single neuron in real time but of identifying the general neural and cellular principles governing the assembly of brain networks and its breakdown in brain disorders. The field is relatively new but is moving fast and has already produced some important insights. The future is challenging and will require time, devotion and an optimal synergy between engineering, chemistry, biology, and computer science. If the community will be patient and supportive enough, there will be further important discoveries in the future."
    ],
    "b_categories":[
      [
        "Psychiatry"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "GAN\uff08Generative Adversarial Nets\uff09"
    ],
    "c_abstract":[
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal \u00bd everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated"
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "date":null,
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "c_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "date":null,
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      [
        "q-fin.GN"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "b24"
    ],
    "c_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "c_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "date":null,
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The Llama 3 Herd of Models"
    ],
    "c_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18784",
    "date":null,
    "a_title":"MRI Breast tissue segmentation using nnU-Net for biomechanical modeling",
    "a_abstract":"Integrating 2D mammography with 3D magnetic resonance imaging (MRI) is\ncrucial for improving breast cancer diagnosis and treatment planning. However,\nthis integration is challenging due to differences in imaging modalities and\nthe need for precise tissue segmentation and alignment. This paper addresses\nthese challenges by enhancing biomechanical breast models in two main aspects:\nimproving tissue identification using nnU-Net segmentation models and\nevaluating finite element (FE) biomechanical solvers, specifically comparing\nNiftySim and FEBio. We performed a detailed six-class segmentation of breast\nMRI data using the nnU-Net architecture, achieving Dice Coefficients of 0.94\nfor fat, 0.88 for glandular tissue, and 0.87 for pectoral muscle. The overall\nforeground segmentation reached a mean Dice Coefficient of 0.83 through an\nensemble of 2D and 3D U-Net configurations, providing a solid foundation for 3D\nreconstruction and biomechanical modeling. The segmented data was then used to\ngenerate detailed 3D meshes and develop biomechanical models using NiftySim and\nFEBio, which simulate breast tissue's physical behaviors under compression. Our\nresults include a comparison between NiftySim and FEBio, providing insights\ninto the accuracy and reliability of these simulations in studying breast\ntissue responses under compression. The findings of this study have the\npotential to improve the integration of 2D and 3D imaging modalities, thereby\nenhancing diagnostic accuracy and treatment planning for breast cancer.",
    "explanation":"Integrating 2D mammography with 3D magnetic resonance\nimaging (MRI) is crucial for improving breast cancer diagnosis and treat-\nment planning. However, this integration is challenging due to differences\nin imaging modalities and the need for precise tissue segmentation and\nalignment. This paper addresses these challenges by enhancing biome-\nchanical breast models in two main aspects: improving tissue identifica-\ntion using nnU-Net segmentation models and evaluating finite element\n(FE) biomechanical solvers, specifically comparing NiftySim and FEBio.\u00a0",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Multimodal Breast Parenchymal Patterns Correlation Using a Patient-Specific Biomechanical Model"
    ],
    "c_abstract":[
      "In this paper, we aim to produce a realistic 2-D projection of the breast parenchymal distribution from a 3-D breast magnetic resonance image (MRI). To evaluate the accuracy of our simulation, we compare our results with the local breast density (i.e., density map) obtained from the complementary full-field digital mammogram. To achieve this goal, we have developed a fully automatic framework, which registers MRI volumes to X-ray mammograms using a subject-specific biomechanical model of the breast. The optimization step modifies the position, orientation, and elastic parameters of the breast model to perform the alignment between the images. When the model reaches an optimal solution, the MRI glandular tissue is projected and compared with the one obtained from the corresponding mammograms. To reduce the loss of information during the ray-casting, we introduce a new approach that avoids resampling the MRI volume. In the results, we focus our efforts on evaluating the agreement of the distributions of glandular tissue, the degree of structural similarity, and the correlation between the real and synthetic density maps. Our approach obtained a high-structural agreement regardless the glandularity of the breast, whilst the similarity of the glandular tissue distributions and correlation between both images increase in denser breasts. Furthermore, the synthetic images show continuity with respect to large structures in the density maps."
    ],
    "c_categories":[
      [
        "Imaging"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00663",
    "date":null,
    "a_title":"Deep Learning for Longitudinal Gross Tumor Volume Segmentation in\n  MRI-Guided Adaptive Radiotherapy for Head and Neck Cancer",
    "a_abstract":"Accurate segmentation of gross tumor volume (GTV) is essential for effective\nMRI-guided adaptive radiotherapy (MRgART) in head and neck cancer. However,\nmanual segmentation of the GTV over the course of therapy is time-consuming and\nprone to interobserver variability. Deep learning (DL) has the potential to\novercome these challenges by automatically delineating GTVs. In this study, our\nteam, $\\textit{UW LAIR}$, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume\nsegmentation. To this end, we developed a series of DL models for longitudinal\nGTV segmentation. The backbone of our models for both tasks was SegResNet with\ndeep supervision. For Task 1, we trained the model using a combined dataset of\npre-RT and mid-RT MRI data, which resulted in the improved aggregated Dice\nsimilarity coefficient (DSCagg) on an internal testing set compared to models\ntrained solely on pre-RT MRI data. In Task 2, we introduced mask-aware\nattention modules, enabling pre-RT GTV masks to influence intermediate features\nlearned from mid-RT data. This attention-based approach yielded slight\nimprovements over the baseline method, which concatenated mid-RT MRI with\npre-RT GTV masks as input. In the final testing phase, the ensemble of 10\npre-RT segmentation models achieved an average DSCagg of 0.794, with 0.745 for\nprimary GTV (GTVp) and 0.844 for metastatic lymph nodes (GTVn) in Task 1. For\nTask 2, the ensemble of 10 mid-RT segmentation models attained an average\nDSCagg of 0.733, with 0.607 for GTVp and 0.859 for GTVn, leading us to\n$\\textbf{achieve 1st place}$. In summary, we presented a collection of DL\nmodels that could facilitate GTV segmentation in MRgART, offering the potential\nto streamline radiation oncology workflows. Our code and model weights are\navailable at https:\/\/github.com\/xtie97\/HNTS-MRG24-UWLAIR.",
    "explanation":"In this study, our team, UW LAIR, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume seg-\nmentation. To this end, we developed a series of DL models for longitudinal GTV\nsegmentation",
    "b_id":[
      "b4",
      "b2"
    ],
    "b_title":[
      "Deep Learning for Automatic Gross Tumor Volumes Contouring in Esophageal Cancer Based on Contrast-Enhanced Computed Tomography Images: A Multi-Institutional Study",
      "ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of Pneumothorax"
    ],
    "b_abstract":[
      "Purpose To develop and externally validate an automatic artificial intelligence (AI) tool for delineating gross tumor volume (GTV) in patients with esophageal squamous cell carcinoma (ESCC), which can assist in neo-adjuvant or radical radiation therapy treatment planning. Methods and Materials In this multi-institutional study, contrast-enhanced CT images from 580 eligible ESCC patients were retrospectively collected. The GTV contours delineated by 2 experts via consensus were used as ground truth. A 3-dimensional deep learning model was developed for GTV contouring in the training cohort and internally and externally validated in 3 validation cohorts. The AI tool was compared against 12 board-certified experts in 25 patients randomly selected from the external validation cohort to evaluate its assistance in improving contouring performance and reducing variation. Contouring performance was measured using dice similarity coefficient (DSC) and average surface distance. Additionally, our previously established radiomics model for predicting pathologic complete response was used to compare AI-generated and ground truth contours, to assess the potential of the AI contouring tool in radiomics analysis. Results The AI tool demonstrated good GTV contouring performance in multicenter validation cohorts, with median DSC values of 0.865, 0.876, and 0.866 and median average surface distance values of 0.939, 0.789, and 0.875 mm, respectively. Furthermore, the AI tool significantly improved contouring performance for half of 12 board-certified experts (DSC values, 0.794-0.835 vs 0.856-0.881, P = .003-0.048), reduced the intra- and interobserver variations by 37.4% and 55.2%, respectively, and saved contouring time by 77.6%. In the radiomics analysis, 88.7% of radiomic features from ground truth and AI-generated contours demonstrated stable reproducibility, and similar pathologic complete response prediction performance for these contours (P = .430) was observed. Conclusions Our AI contouring tool can improve GTV contouring performance and facilitate radiomics analysis in ESCC patients, which indicates its potential for GTV contouring during radiation therapy treatment planning and radiomics studies.",
      "Radiology narrative reports often describe characteristics of a patient's disease, including its location, size, and shape. Motivated by the recent success multimodal learning, we hypothesized that this descriptive text could guide medical image analysis algorithms. We proposed novel vision-language model, ConTEXTual Net, for task pneumothorax segmentation on chest radiographs. Net extracts language features from physician-generated free-form radiology using pre-trained model. then introduced cross-attention between intermediate embeddings an encoder-decoder convolutional neural network to enable guidance analysis. was trained CANDID-PTX dataset consisting 3196 positive cases with annotations 6 different physicians as well clinical reports. Using cross-validation, achieved Dice score 0.716\u00b10.016, which similar degree inter-reader variability (0.712\u00b10.044) computed subset data. It outperformed vision-only models (Swin UNETR: 0.670\u00b10.015, ResNet50 U-Net: 0.677\u00b10.015, GLoRIA: 0.686\u00b10.014, nnUNet 0.694\u00b10.016) competing model (LAVT: 0.706\u00b10.009). Ablation studies confirmed it information led performance gains. Additionally, show certain augmentation methods degraded Net's breaking image-text concordance. also evaluated effects activation functions in module, highlighting efficacy our chosen architectural design."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "MRI-Guided Adaptive Radiation Therapy"
    ],
    "c_abstract":[
      "Magnetic resonance imaging-guided radiation therapy (MRIgRT) has improved soft tissue contrast over computed tomography (CT) based image-guided RT. Superior visualization of the target and surrounding radiosensitive structures has the potential to improve oncological outcomes partly due to safer dose-escalation and adaptive planning. In this review, we highlight the workflow of adaptive MRIgRT planning, which includes simulation imaging, daily MRI, identifying isocenter shifts, contouring, plan optimization, quality control, and delivery. Increased utilization of MRIgRT will depend on addressing technical limitations of this technology, while addressing treatment efficacy, cost-effectiveness, and workflow training."
    ],
    "c_categories":[
      [
        "Oncology"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18602",
    "date":null,
    "a_title":"Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for\n  Medical Image Analysis",
    "a_abstract":"Purpose: To explore best-practice approaches for generating synthetic chest\nX-ray images and augmenting medical imaging datasets to optimize the\nperformance of deep learning models in downstream tasks like classification and\nsegmentation. Materials and Methods: We utilized a latent diffusion model to\ncondition the generation of synthetic chest X-rays on text prompts and\/or\nsegmentation masks. We explored methods like using a proxy model and using\nradiologist feedback to improve the quality of synthetic data. These synthetic\nimages were then generated from relevant disease information or geometrically\ntransformed segmentation masks and added to ground truth training set images\nfrom the CheXpert, CANDID-PTX, SIIM, and RSNA Pneumonia datasets to measure\nimprovements in classification and segmentation model performance on the test\nsets. F1 and Dice scores were used to evaluate classification and segmentation\nrespectively. One-tailed t-tests with Bonferroni correction assessed the\nstatistical significance of performance improvements with synthetic data.\nResults: Across all experiments, the synthetic data we generated resulted in a\nmaximum mean classification F1 score improvement of 0.150453 (CI:\n0.099108-0.201798; P=0.0031) compared to using only real data. For\nsegmentation, the maximum Dice score improvement was 0.14575 (CI:\n0.108267-0.183233; P=0.0064). Conclusion: Best practices for generating\nsynthetic chest X-ray images for downstream tasks include conditioning on\nsingle-disease labels or geometrically transformed segmentation masks, as well\nas potentially using proxy modeling for fine-tuning such generations.",
    "explanation":"We utilized a latent diffusion model to condition the generation of synthetic chest X-rays on text prompts and\/or segmentation masks",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Rsna pneumonia detection challenge"
    ],
    "b_abstract":[
      "In this competition, you\u2019re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs. Here\u2019s the backstory and why solving this problem matters. Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country. While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis. CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift. To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA\u00ae) has reached out to Kaggle\u2019s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review. Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018."
    ],
    "b_categories":[
      [
        "Imaging"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b14",
      "b9"
    ],
    "c_title":[
      "Adding Conditional Control to Text-to-Image Diffusion Models",
      "Highresolution image synthesis with latent diffusion models"
    ],
    "c_abstract":[
      "We present ControlNet, a neural network architecture to add spatial conditioning controls large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large models, and reuses their deep robust encoding layers with billions of images as strong backbone learn diverse set conditional controls. The is connected \"zero convolutions\" (zero-initialized convolution layers) that progressively grow parameters from zero ensure no harmful noise could affect finetuning. test various controls, e.g., edges, depth, segmentation, human pose, etc., Stable Diffusion, using single or multiple conditions, without prompts. show training ControlNets small (<50k) (>1m) datasets. Extensive results may facilitate wider applications control image",
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18902",
    "date":null,
    "a_title":"MSEMG: Surface Electromyography Denoising with a Mamba-based Efficient\n  Network",
    "a_abstract":"Surface electromyography (sEMG) recordings can be contaminated by\nelectrocardiogram (ECG) signals when the monitored muscle is closed to the\nheart. Traditional signal-processing-based approaches, such as high-pass\nfiltering and template subtraction, have been used to remove ECG interference\nbut are often limited in their effectiveness. Recently, neural-network-based\nmethods have shown greater promise for sEMG denoising, but they still struggle\nto balance both efficiency and effectiveness. In this study, we introduce\nMSEMG, a novel system that integrates the Mamba State Space Model with a\nconvolutional neural network to serve as a lightweight sEMG denoising model. We\nevaluated MSEMG using sEMG data from the Non-Invasive Adaptive Prosthetics\ndatabase and ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The\nresults show that MSEMG outperforms existing methods, generating higher-quality\nsEMG signals with fewer parameters. The source code for MSEMG is available at\nhttps:\/\/github.com\/tonyliu0910\/MSEMG.",
    "explanation":"Surface electromyography (sEMG) recordings can\nbe contaminated by electrocardiogram (ECG) signals when the\nmonitored muscle is closed to the heart. In this study, we introduce MSEMG, a novel\nsystem that integrates the Mamba state space model with a\nconvolutional neural network to serve as a lightweight sEMG\ndenoising mode",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Biomechanics and motor control of human movement"
    ],
    "b_abstract":[
      "Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 its Relationship with Physiology Anatomy. 1.3 Scope of Textbook. 1.4 References. 2 Signal Processing. 2.0 2.1 Auto- Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging Repetitive Waveforms. 2.4 3 Kinematics. 3.0 Historical Development Complexity Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging 3.4 Processing Raw Data. 3.5 Calculation Other Variables. 3.6 Problems Based on 3.7 4 Anthropometry. 4.0 Anthropometry in Movement Biomechanics. 4.1 Density, Mass, Inertial Properties. 4.2 Experimental Measures. 4.3 Muscle 4.4 Anthropometric 4.5 5 Kinetics: Forces Moments Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers Plates. 5.3 Bone-on-Bone During Dynamic Conditions. 5.4 Kinetic 5.5 6 Mechanical Work, Energy, Power. 6.0 6.1 Efficiency. 6.2 Forms Energy Storage. 6.3 Internal External Work. 6.4 Power Balances at Joints Within Segments. 6.5 6.6 7 Three-Dimensional Kinematics Kinetics. 7.0 7.1 Axes Systems. 7.2 Marker Anatomical 7.3 Determination Segment Angular Velocities Accelerations. 7.4 Analysis Reaction Moments. 7.5 Suggested Further Reading. 7.6 8 Synthesis Human Movement-Forward Solutions. 8.0 8.1 Review Forward Solution 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 Torques. 8.5 Designation Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 9 Mechanics. 9.0 9.1 Force-Length Characteristics Muscles. 9.2 Force-Velocity Characteristics. 9.3 Modeling. 9.4 10 Kinesiological Electromyography. 10.0 10.1 Electrophysiology Contraction. 10.2 Recording Electromyogram. 10.3 Electromyogram,. 10.4 between Electromyogram 10.5 11 Synergies. 11.0 11.1 The Support Moment Synergy. 11.2 Medial\/Lateral Anterior\/Posterior Balance Standing. 11.3 during Walking. 11.4 APPENDICES. A. Kinematic, Kinetic, Figure A.1 Walking Trial-Marker Locations Mass Frame Rate Information. Table Coordinate Data (cm). A.2( a ) Filtered Kinematics-Rib Cage Greater Trochanter (Hip). b Kinematics-Femoral Lateral Epicondyle (Knee) Head Fibula. c Kinematics-Lateral Malleolus (Ankle) Heel. d Kinematics-Fifth Metatarsal Toe. A.3( Linear Kinematics-Foot. Kinematics-Leg. Kinematics-Thigh. Kinematics-1\/2 HAT. A.4 Relative Joint Kinematics-Ankle, Knee, Hip. A.5( Force-Ankle Knee. Force-Hip. A.6 Potential, Total Energies-Foot, Leg, Thigh, and1\/2 A.7 Generation\/Absorption Transfer-Ankle, B. Units Definitions Related Electromyographical Measurements. B.1 Base SI Units. B.2 Derived Index."
    ],
    "b_categories":[
      [
        "Biomechanics"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    ],
    "c_abstract":[
      "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution recurrent structured state space models (SSMs) have been developed to address Transformers' computational inefficiency long sequences, but they not performed well important modalities language. We identify that a key weakness is their inability perform content-based reasoning, make several improvements. First, simply letting SSM parameters be functions input addresses with discrete modalities, allowing model selectively propagate or forget information along sequence length dimension depending current token. Second, even though this change prevents use efficient convolutions, we design hardware-aware parallel algorithm mode. integrate these selective SSMs into simplified end-to-end neural network without MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) scaling length, performance improves real data up million-length sequences. As general backbone, achieves state-of-the-art across language, audio, genomics. On language modeling, our Mamba-3B outperforms Transformers same size matches twice size, both pretraining downstream evaluation."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03551",
    "date":null,
    "a_title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation",
    "a_abstract":"Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "explanation":"However, fibrosis appears\nas irregular, diffuse patterns with unclear boundaries, lead-\ning to high inter-observer variability and time-intensive man-\nual annotation. To tackle this challenge, we propose DiffSeg,\na novel weakly supervised semantic segmentation (WSSS)\nmethod that uses image-level annotations to generate pixel-\nlevel fibrosis segmentation, reducing the need for fine-grained\nmanual labeling. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Interobserver Variability in the CT Assessment of Honeycombing in the Lungs"
    ],
    "b_abstract":[
      "To quantify observer agreement and analyze causes of disagreement in identifying honeycombing at chest computed tomography (CT).The institutional review board approved this multiinstitutional HIPAA-compliant retrospective study, informed patient consent was not required. Five core study members scored 80 CT images with a five-point scale (5 = definitely yes to 1 no) establish reference standard for the identification honeycombing. Forty-three observers from various subspecialties geographic regions by using same scoring system. Weighted \u03ba values scores compared were analyzed investigate intergroup differences. Images divided into four groups allow analysis imaging features cases which there disagreement: on presence honeycombing, absence other (none preceding three applied).Agreement 43 moderate (Cohen weighted values: 0.40-0.58). There no significant differences among defined either subspecialty or region (Tukey-Kramer test, P .38 >.99). In 29% cases, These included mixed traction bronchiectasis, large cysts, superimposed pulmonary emphysema.Identification is subjective, largely caused conditions that mimic"
    ],
    "b_categories":[
      [
        "Radiology"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation"
    ],
    "c_abstract":[
      "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09469",
    "date":null,
    "a_title":"An Explainable Attention Model for Cervical Precancer Risk\n  Classification using Colposcopic Images",
    "a_abstract":"Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease.",
    "explanation":"This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-\nAID-Net model based on patients colposcopy images. The model comprises a Convolutional Block\nAttention Module (CBAM) and convolutional layers that extract interpretable and representative\nfeatures of colposcopic images to distinguish high-risk and low-risk cervical precancer. ",
    "b_id":[
      "b36"
    ],
    "b_title":[
      "CBAM: Convolutional block attention module"
    ],
    "b_abstract":[
      "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "The accuracy of colposcopic biopsy: Analyses from the placebo arm of the Gardasil clinical trials"
    ],
    "c_abstract":[
      "We evaluated the overall agreement between colposcopically directed biopsies and definitive excisional specimens within context of three clinical trials. A total 737 women aged 16-45 who had a cervical biopsy taken 6 months before their therapy were included. Per-protocol, colposcopists to also obtain representative immediately therapy. Using adjudicated histological diagnoses, initial same day correlated with surgically excised specimens. The therapy, diagnoses was 42% (weighted kappa = 0.34) (95% CI: 0.29-0.39). underestimation intraepithelial neoplasia grade 2\/3 or adenocarcinoma in situ (CIN2-3\/AIS) CIN3\/AIS 26 42%, respectively. When allowing for one degree variance correlation, 92% CIN2-3\/AIS. specimen 56% 0.41) 0.36-0.47), CIN2-3\/AIS 57%. There significant associations when patients stratified by age, number biopsies, lesion size, presence human papillomavirus (HPV)16\/18 region. Of 178 diagnostic endocervical curettages performed, 14 (7.9%) found any HPV disease. Colposcopic accuracy improved CIN2 grouped as single predictive measure high-grade Colposcopy functioned well allowed one-degree difference surgical histologic interpretations, done practice. Taking more than colposcopic could improve patient management."
    ],
    "c_categories":[
      [
        "Clinical Trial"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14752",
    "date":null,
    "a_title":"Comparative Analysis of nnUNet and MedNeXt for Head and Neck Tumor\n  Segmentation in MRI-guided Radiotherapy",
    "a_abstract":"Radiation therapy (RT) is essential in treating head and neck cancer (HNC),\nwith magnetic resonance imaging(MRI)-guided RT offering superior soft tissue\ncontrast and functional imaging. However, manual tumor segmentation is\ntime-consuming and complex, and therfore remains a challenge. In this study, we\npresent our solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI\nimages. We utilized the HNTS-MRG2024 dataset, which consists of 150 MRI scans\nfrom patients diagnosed with HNC, including original and registered pre-RT and\nmid-RT T2-weighted images with corresponding segmentation masks for GTVp and\nGTVn. We employed two state-of-the-art models in deep learning, nnUNet and\nMedNeXt. For Task 1, we pretrained models on pre-RT registered and mid-RT\nimages, followed by fine-tuning on original pre-RT images. For Task 2, we\ncombined registered pre-RT images, registered pre-RT segmentation masks, and\nmid-RT data as a multi-channel input for training. Our solution for Task 1\nachieved 1st place in the final test phase with an aggregated Dice Similarity\nCoefficient of 0.8254, and our solution for Task 2 ranked 8th with a score of\n0.7005. The proposed solution is publicly available at Github Repository.",
    "explanation":"Radiation therapy (RT) is essential in treating head and neck cancer\n(HNC), with magnetic resonance imaging(MRI)-guided RT offering superior soft tis-\nsue contrast and functional imaging. However, manual tumor segmentation is time-\nconsuming and complex, and therfore remains a challenge. In this study, we present\nour solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI im-\nages. We employed two state-of-the-art models in deep learning, nnUNet and MedNeXt.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "\u201cApr\u00e8s Mois, Le D\u00e9luge\u201d: Preparing for the Coming Data Flood in the MRI-Guided Radiotherapy Era"
    ],
    "b_abstract":[
      "Magnetic resonance imaging provides a sea of quantitative and semi-quantitative data. While radiation oncologists already navigate pool clinical (semantic) data, the tide will swell with advent hybrid MRI\/linear accelerator devices increasing interest in MRI-guided radiotherapy (MRIgRT), including adaptive MRIgRT. The variety MR sequences (of greater complexity than single parameter Hounsfield unit CT scanning routinely used radiotherapy), workflow fractionation, sheer quantity daily images acquired are challenges for scaling this technology. Biomedical informatics, which is science information biomedicine, can provide helpful insights looming transition. Funneling MRIgRT data into clinically meaningful streams requires committing to flow inter-institutional accessibility interoperability initiatives, standardizing dosimetry methods, streamlining linear workflow, MRI acquisition post-processing, current topic review attempt conceptually ford using informatics approaches as theoretical bridge."
    ],
    "b_categories":[
      [
        "Oncology"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https:\/\/github.com\/MIC-DKFZ\/MedNeXt.",
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "date":null,
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "c_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "date":null,
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "How resilient are language models to text perturbations"
    ],
    "c_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01668",
    "date":null,
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Linear-quadratic mean field games"
    ],
    "c_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "date":null,
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "c_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "c_categories":[
      [
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00578",
    "date":null,
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "c_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "date":null,
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "c_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00714",
    "date":null,
    "a_title":"Self-reinforcing cascades: A spreading model for beliefs or products of\n  varying intensity or quality",
    "a_abstract":"Models of how things spread often assume that transmission mechanisms are\nfixed over time. However, social contagions--the spread of ideas, beliefs,\ninnovations--can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. We study the impacts of\nsuch self-reinforcement mechanisms in cascade dynamics. We use different\nmathematical modeling techniques to capture the recursive, yet changing nature\nof the process. We find a critical regime with a range of power-law cascade\nsize distributions with varying scaling exponents. This regime clashes with\nclassic models, where criticality requires fine tuning at a precise critical\npoint. Self-reinforced cascades produce critical-like behavior over a wide\nrange of parameters, which may help explain the ubiquity of power-law\ndistributions in empirical social data.",
    "explanation":"Models of how things spread often assume that transmission mechanisms are fixed over time. However, social\ncontagions\u2013the spread of ideas, beliefs, innovations\u2013can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. e use different mathematical modeling techniques to capture the recursive, yet changing\nnature of the process.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Universality, criticality and complexity of information propagation in social media"
    ],
    "b_abstract":[
      "Abstract Statistical laws of information avalanches in social media appear, at least according to existing empirical studies, not robust across systems. As a consequence, radically different processes may represent plausible driving mechanisms for propagation. Here, we analyze almost one billion time-stamped events collected from several online platforms \u2013 including Telegram, Twitter and Weibo over observation windows longer than ten years, show that the propagation is universal critical process. Universality arises identical macroscopic patterns platforms, irrespective details specific system hand. Critical behavior deduced power-law distributions, corresponding hyperscaling relations, characterizing size duration information. testing on our data indicates mixture simple complex contagion characterizes media. Data suggest complexity process correlated with semantic content propagated."
    ],
    "b_categories":[
      [
        "Human Behaviors"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Random graphs with arbitrary degree distributions and their applications"
    ],
    "c_abstract":[
      "Recent work on the structure of social networks and internet has focused attention graphs with distributions vertex degree that are significantly different from Poisson have been widely studied in past. In this paper we develop detail theory random arbitrary distributions. addition to simple undirected, unipartite graphs, examine properties directed bipartite graphs. Among other results, derive exact expressions for position phase transition at which a giant component first forms, mean size, size if there is one, number vertices certain distance away randomly chosen vertex, average vertex-vertex within graph. We apply our some real-world including world-wide web collaboration scientists Fortune 1000 company directors. demonstrate cases appropriate predict surprising accuracy behavior real world, while others measurable discrepancy between reality, perhaps indicating presence additional network not captured by"
    ],
    "c_categories":[
      [
        "Modeling"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00749",
    "date":null,
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "c_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00758",
    "date":null,
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Inverse methods for illumination optics"
    ],
    "c_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "c_categories":[
      [
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.01291",
    "date":null,
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "c_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "date":null,
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "c_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "date":null,
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "c_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "date":null,
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "c_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "date":null,
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "c_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.17907",
    "date":null,
    "a_title":"A Multimodal Emotion Recognition System: Integrating Facial Expressions,\n  Body Movement, Speech, and Spoken Language",
    "a_abstract":"Traditional psychological evaluations rely heavily on human observation and\ninterpretation, which are prone to subjectivity, bias, fatigue, and\ninconsistency. To address these limitations, this work presents a multimodal\nemotion recognition system that provides a standardised, objective, and\ndata-driven tool to support evaluators, such as psychologists, psychiatrists,\nand clinicians. The system integrates recognition of facial expressions,\nspeech, spoken language, and body movement analysis to capture subtle emotional\ncues that are often overlooked in human evaluations. By combining these\nmodalities, the system provides more robust and comprehensive emotional state\nassessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in\na simulated real-world condition demonstrates the system's potential to provide\nreliable emotional insights to improve the diagnostic accuracy. This work\nhighlights the promise of automated multimodal analysis as a valuable\ncomplement to traditional psychological evaluation practices, with applications\nin clinical and therapeutic settings.",
    "explanation":"Traditional psychological evaluations rely heavily\non human observation and interpretation, which are prone to\nsubjectivity, bias, fatigue, and inconsistency. To address these\nlimitations, this work presents a multimodal emotion recognition\nsystem that provides a standardised, objective, and data-driven\ntool to support evaluators, such as psychologists, psychiatrists,\nand clinicians.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Deep Facial Expression Recognition: A Survey"
    ],
    "b_abstract":[
      "With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and recent success deep learning techniques in various fields, neural networks have increasingly been leveraged learn discriminative representations for automatic FER. Recent FER systems generally focus on two important issues: overfitting caused by a lack sufficient training data expression-unrelated variations, such as illumination, head pose identity bias. In this paper, we provide comprehensive survey FER, including datasets algorithms that insights into these intrinsic problems. First, describe standard pipeline system with related background knowledge suggestions applicable implementations each stage. We then introduce available are widely used literature accepted selection evaluation principles datasets. For state art review existing novel strategies designed based both static images dynamic image sequences, discuss their advantages limitations. Competitive performances benchmarks also summarized section. extend our additional issues application scenarios. Finally, remaining challenges corresponding opportunities field well future directions design robust systems."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Recognizing and reducing cognitive bias in clinical and forensic neurology"
    ],
    "c_abstract":[
      "In medicine, cognitive errors form the basis of bias in clinical practice. Several types are common and pervasive, may lead to inaccurate diagnosis or treatment. Forensic neurology, even when aided by current technologies, still dependent on interpretations, therefore prone bias. This article discusses 4 biases that can clinician astray. They confirmation (selective gathering neglect contradictory evidence); base rate (ignoring misusing prevailing data); hindsight (oversimplification past causation); good old days (the tendency for patients misremember exaggerate their preinjury functioning). We briefly describe strategies adopted from field psychology could minimize While debiasing is not easy, reducing such requires awareness acknowledgment our susceptibility these distortions."
    ],
    "c_categories":[
      [
        "Clinical Neurology"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "date":null,
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "c_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "date":null,
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "c_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "date":null,
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "c_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "date":null,
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "A primer on deep learning in genomics"
    ],
    "c_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08664",
    "date":null,
    "a_title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning",
    "a_abstract":"Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.",
    "explanation":"n this work, we evaluate common techniques in multi-modal learning\n(alignment and fusion) in unifying some of the most important modalities in materials\nscience: atomic structure, X-ray diffraction patterns (XRD), and composition.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Comprehensive Inorganic Chemistry III (Third Edition)"
    ],
    "b_abstract":[
      "Comprehensive Inorganic Chemistry III, a ten-volume reference work, is intended to cover fundamental principles, recent discoveries, and significant applications of elements and their compounds. Authored by renowned experts in the field and edited by a world-class editorial board, each chapter provides a thorough and in-depth overview of the topic covered, featuring resources which will be useful to students, researchers, faculty as well as those in the industry. Comprehensive Inorganic Chemistry III focuses on main group chemistry, biological inorganic chemistry, solid state and materials chemistry, catalysis, and new developments in electrochemistry and photochemistry, as well as NMR and diffraction methods for studying inorganic compounds. The work expands on our 2013 work Comprehensive Inorganic Chemistry II while also adding new volumes on cutting-edge research areas and techniques for studying inorganic compounds. Researchers seeking background information on a specific problem involving the synthesis of inorganic compounds, as well as applications for numerous elements from the periodic table, and their compounds, will be able to rely on and refer to this authoritative scientific resource time and again."
    ],
    "b_categories":[
      [
        "Material"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Multimodal Foundation Models for Material Property Prediction and Discovery"
    ],
    "c_abstract":[
      "Artificial intelligence is transforming computational materials science, improving the prediction of material properties, and accelerating the discovery of novel materials. Recently, publicly available material data repositories have grown rapidly. This growth encompasses not only more materials but also a greater variety and quantity of their associated properties. Existing machine learning efforts in materials science focus primarily on single-modality tasks, i.e. relationships between materials and a single physical property, thus not taking advantage of the rich and multimodal set of material properties. Here, we introduce Multimodal Learning for Materials (MultiMat), which enables self-supervised multi-modality training of foundation models for materials. We demonstrate our framework's potential using data from the Materials Project database on multiple axes: (i) MultiMat achieves state-of-the-art performance for challenging material property prediction tasks; (ii) MultiMat enables novel and accurate material discovery via latent space similarity, enabling screening for stable materials with desired properties; and (iii) MultiMat encodes interpretable emergent features that may provide novel scientific insights."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09080",
    "date":null,
    "a_title":"Language Models for Music Medicine Generation",
    "a_abstract":"Music therapy has been shown in recent years to provide multiple health\nbenefits related to emotional wellness. In turn, maintaining a healthy\nemotional state has proven to be effective for patients undergoing treatment,\nsuch as Parkinson's patients or patients suffering from stress and anxiety. We\npropose fine-tuning MusicGen, a music-generating transformer model, to create\nshort musical clips that assist patients in transitioning from negative to\ndesired emotional states. Using low-rank decomposition fine-tuning on the\nMTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere\nto the iso principle, guiding patients through intermediate states in the\nvalence-arousal circumplex. The generated music is evaluated using a music\nemotion recognition model to ensure alignment with intended emotions. By\nconcatenating these clips, we produce a 15-minute \"music medicine\" resembling a\nmusic therapy session. Our approach is the first model to leverage Language\nModels to generate music medicine. Ultimately, the output is intended to be\nused as a temporary relief between music therapy sessions with a\nboard-certified therapist.",
    "explanation":"We propose fine-tuning MusicGen, a music-generating\ntransformer model, to create short musical clips that assist\npatients in transitioning from negative to desired emotional\nstates",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Music Transformer: Generating Music with Long-Term Structure"
    ],
    "b_abstract":[
      "Music relies heavily on repetition to build structure and meaning. Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure. The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important. Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018). This is impractical for long sequences such as musical compositions since their memory complexity for intermediate relative information is quadratic in the sequence length. We propose an algorithm that reduces their intermediate memory requirement to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long compositions (thousands of steps, four times the length modeled in Oore et al., 2018) with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies. We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-Competition, and obtain state-of-the-art results on the latter."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "On the use of AI for Generation of Functional Music to Improve Mental Health"
    ],
    "c_abstract":[
      "Increasingly music has been shown to have both physical and mental health benefits including improvements in cardiovascular health, a link reduction of cases dementia elderly populations, markers general well-being such as stress reduction. Here, we describe short case studies addressing (anxiety, stress-reduction) through AI-driven generation. Engaging active listening music-making activities (especially for at risk age groups) can be particularly beneficial, the practice therapy helpful range use across wide range. However, access prohibitive terms expertize, materials, cost. Furthermore existing functional outcomes (such targeted improvement suggested above) hindered by issues repetition subsequent over-familiarity with material. In this paper, machine learning approaches which create informed biophysiological measurement two studies, target emotional states opposing ends Cartesian affective space (a dimensional emotion points ranging from descriptors relaxation, fear). Galvanic skin response is used marker psychological arousal an estimate state control signal training algorithm. This algorithm creates non-linear time series musical features sound synthesis \u201con-the-fly\u201d, using perceptually feature similarity model. We find interaction between familiarity perceived response. also report on psychometric evaluation generated material, consider how these - similar techniques might useful generation tasks, example, nonlinear sound-tracking that found interactive media or video games."
    ],
    "c_categories":[
      [
        "Mental Health"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "date":null,
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "c_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "date":null,
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b29"
    ],
    "c_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "c_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "date":null,
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "c_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17595",
    "date":null,
    "a_title":"Can artificial intelligence predict clinical trial outcomes?",
    "a_abstract":"The increasing complexity and cost of clinical trials, particularly in the\ncontext of oncology and advanced therapies, pose significant challenges for\ndrug development. This study evaluates the predictive capabilities of large\nlanguage models (LLMs) such as GPT-3.5, GPT-4, and HINT in determining clinical\ntrial outcomes. By leveraging a curated dataset of trials from\nClinicalTrials.gov, we compare the models' performance using metrics including\nbalanced accuracy, specificity, recall, and Matthews Correlation Coefficient\n(MCC). Results indicate that GPT-4o demonstrates robust performance in early\ntrial phases, achieving high recall but facing limitations in specificity.\nConversely, the HINT model excels in recognizing negative outcomes,\nparticularly in later trial phases, offering a balanced approach across diverse\nendpoints. Oncology trials, characterized by high complexity, remain\nchallenging for all models. Additionally, trial duration and disease categories\ninfluence predictive performance, with longer durations and complex diseases\nsuch as neoplasms reducing accuracy. This study highlights the complementary\nstrengths of LLMs and HINT, providing insights into optimizing predictive tools\nfor clinical trial design and risk management. Future advancements in LLMs are\nessential to address current gaps in handling negative outcomes and complex\ndomains.",
    "explanation":"This study evaluates the performance of large language models (LLMs) and the\nHINT model in predicting clinical trial outcomes, focusing on metrics includ-\ning Balanced Accuracy, Matthews Correlation Coefficient (MCC), Recall, and\nSpecificity",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Machine learning model to predict oncologic outcomes for drugs in randomized clinical trials"
    ],
    "b_abstract":[
      "Abstract Predicting oncologic outcome is challenging due to the diversity of cancer histologies and complex network underlying biological factors. In this study, we determine whether machine learning (ML) can extract meaningful associations between clinical trial, drug\u2010related biomarker molecular profile information. We analyzed therapeutic trials corresponding 1102 outcomes from 104 758 patients with advanced colorectal adenocarcinoma, pancreatic melanoma nonsmall\u2010cell lung cancer. For each intervention arm, a dataset following attributes was curated: line treatment, number cytotoxic chemotherapies, small\u2010molecule inhibitors, or monoclonal antibody agents, drug class, alteration status arm's population, type, probability sensitivity (PDS) (integrating genomic, transcriptomic proteomic biomarkers in population interest) outcome. A total 467 progression\u2010free survival (PFS) 369 overall (OS) data points were used as training sets build our ML (random forest) model. Cross\u2010validation for PFS OS, obtaining correlation coefficients ( r ) 0.82 0.70, respectively (outcome vs model's parameters). 156 110 OS test sets. The Spearman s predicted actual statistically significant (PFS: = 0.879, OS: 0.878, P &lt; .0001). better arm 81% N 59\/73, z 5.24, .0001) 71% (OS: 37\/52, 2.91, .004) randomized trials. success algorithm predict may be exploitable model optimize trial design pharmaceutical agents."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Lint: Llm interaction network for clinical trial outcome prediction"
    ],
    "c_abstract":[
      "Clinical trial outcome prediction aims to predict the success probability of a clinical trial that reaches its desirable endpoint. Most of the effort focuses on developing machine learning models for making accurate predictions with diverse data sources, including clinical trial descriptions, drug molecules, and target disease conditions. Accurate trial outcome prediction helps trial planning and asset portfolio prioritization. Previous works have focused on small-molecule drugs; however, biologics are a quickly growing intervention type that lacks information that is traditionally known for drugs, like molecular properties. Additionally, traditional methods like graph neural networks are much more difficult to apply to biologics data which are a fast-growing type of drug. To address these points, we propose a Language Interaction Network (LINT), a novel method for trial outcome prediction using only free-text descriptions. We validate the effectiveness of LINT with thorough experiments across three trial phases. Specifically, LINT obtains 0.770, 0.740, and 0.748 ROC-AUC scores on phase I, II, and III, respectively, for clinical trials with biologic interventions."
    ],
    "c_categories":[
      [
        "Clinical trials"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "date":null,
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "c_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "date":null,
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "c_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "date":null,
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "c_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "date":null,
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "c_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "date":null,
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "c_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "c_categories":[
      [
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "date":null,
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "c_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "date":null,
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      [
        "q-bio.OT"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "c_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "date":null,
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "c_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "date":null,
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "c_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01375",
    "date":null,
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "c_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "c_categories":[
      [
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.00544",
    "date":null,
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "c_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04840",
    "date":null,
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "c_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "c_categories":[
      [
        "cs.DS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.17342",
    "date":null,
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b35"
    ],
    "c_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "c_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "date":null,
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "c_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.11513",
    "date":null,
    "a_title":"A Modular Open Source Framework for Genomic Variant Calling",
    "a_abstract":"Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.",
    "explanation":"Some sentences that point to the key references selected in Task 3 are specified below:\n\n\"Variant calling is a fundamental task in genomic research, essential for detecting genetic variations such as single nucleotide polymorphisms (SNPs) and insertions or deletions (indels).\"\n\n\"Our work adds a modular and extensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem\u2019s drug discovery infrastructure more tightly with bioinformatics pipelines.\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data"
    ],
    "b_abstract":[
      "Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, massive data sets generated by NGS\u2014the Genome pilot alone includes nearly five terabases\u2014make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated Indeed, many professionals limited in scope ease with which they can answer scientific questions complexity accessing manipulating produced these machines. Here, we discuss Analysis Toolkit (GATK), a structured programming framework designed to development efficient next-generation sequencers using functional philosophy MapReduce. The GATK provides small but rich set access patterns that encompass majority tool needs. Separating specific calculations from common management infrastructure enables us optimize correctness, stability, CPU memory efficiency enable distributed shared parallelization. We highlight capabilities describing implementation application robust, scale-tolerant like coverage calculators single nucleotide polymorphism (SNP) calling. conclude developers analysts quickly easily write NGS tools, have been incorporated into large-scale projects Project Cancer Atlas."
    ],
    "b_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "Rethinking the Inception Architecture for Computer Vision"
    ],
    "c_abstract":[
      "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set."
    ],
    "c_categories":[
      [
        "BioInformatics"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "date":null,
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "Speaker Diarization with LSTM"
    ],
    "c_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "date":null,
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "c_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "date":null,
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "c_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05237",
    "date":null,
    "a_title":"Pruning the Path to Optimal Care: Identifying Systematically Suboptimal\n  Medical Decision-Making with Inverse Reinforcement Learning",
    "a_abstract":"In aims to uncover insights into medical decision-making embedded within\nobservational data from clinical settings, we present a novel application of\nInverse Reinforcement Learning (IRL) that identifies suboptimal clinician\nactions based on the actions of their peers. This approach centers two stages\nof IRL with an intermediate step to prune trajectories displaying behavior that\ndeviates significantly from the consensus. This enables us to effectively\nidentify clinical priorities and values from ICU data containing both optimal\nand suboptimal clinician decisions. We observe that the benefits of removing\nsuboptimal actions vary by disease and differentially impact certain\ndemographic groups.",
    "explanation":"In aims to uncover insights into medical decision-making embedded within observational data from clinical settings,\nwe present a novel application of Inverse Reinforcement Learning (IRL) that identifies suboptimal clinician actions\nbased on the actions of their peers. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Factors Influencing Physicians' Clinical Decision-making at Upazila Health Complexes in Bangladesh"
    ],
    "b_abstract":[
      "Selecting the most appropriate treatment for each patient is key activity in patient-physician encounters and providing healthcare services. Achieving desirable clinical goals mostly depends on making right decision at time any setting. But little known about physicians' decision-making primary care setting Bangladesh. Therefore, this study explored factors that influence decisions prescribing medications, ordering pathologic tests, counseling patients, average length of visits a consultation session, referral patients to other physicians or hospitals by Upazila Health Complexes (UHCs) country. It also structure social networks their association with process.This was cross-sectional descriptive used data collected from 85 physicians. The respondents, who work UHCs Rajshahi Division, were selected purposively. analyzed statistics including frequency, percentage, one-way analysis variance, linear regression understand relationships among variables.The results reveal multiple visits, referring UHCs. Most prescribe drugs keeping mind purchasing capacity. Risk violence patients' relatives better management are two decisions. professional personal play an influential role process. found dedicate 16.17 minutes session. influenced various distance between residence workplace, level education, number colleagues whom they have regular contact can seek help.The yielded some novel insights complexity everyday tasks would be interest public health researchers policy makers."
    ],
    "b_categories":[
      [
        "Healthcare"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Interactive Teaching Algorithms for Inverse Reinforcement Learning"
    ],
    "c_abstract":[
      "We study the problem of inverse reinforcement learning (IRL) with added twist that learner is assisted by a helpful teacher. More formally, we tackle following algorithmic question: How could teacher provide an informative sequence demonstrations to IRL speed up process? present interactive teaching framework where adaptively chooses next demonstration based on learner's current policy. In particular, design algorithms for two concrete settings: omniscient setting has full knowledge about dynamics and blackbox minimal knowledge. Then, sequential variant popular MCE-IRL prove convergence guarantees our algorithm in setting. Extensive experiments car driving simulator environment show progress can be speeded drastically as compared uninformative"
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.09927",
    "date":null,
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "c_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "date":null,
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b40"
    ],
    "c_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "c_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "date":null,
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "c_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "date":null,
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "c_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "date":null,
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "c_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05213",
    "date":null,
    "a_title":"A chemostat model with variable dilution rate due to biofilm growth",
    "a_abstract":"In many real life applications, a continuous culture bioreactor may cease to\nfunction properly due to bioclogging which is typically caused by the microbial\novergrowth. This is a problem that has been largely overlooked in the chemostat\nmodeling literature, despite the fact that a number of models explicitly\naccounted for biofilm development inside the bioreactor. In a typical chemostat\nmodel, the physical volume of the biofilm is considered negligible when\ncompared to the volume of the fluid. In this paper, we investigate the\ntheoretical consequences of removing such assumption. Specifically, we\nformulate a novel mathematical model of a chemostat where the increase of the\nbiofilm volume occurs at the expense of the fluid volume of the bioreactor, and\nas a result the corresponding dilution rate increases reciprocally. We show\nthat our model is well-posed and describes the bioreactor that can operate in\nthree distinct types of dynamic regimes: the washout equilibrium, the\ncoexistence equilibrium, or a transient towards the clogged state which is\nreached in finite time. We analyze the multiplicity and the stability of the\ncorresponding equilibria. In particular, we delineate the parameter\ncombinations for which the chemostat never clogs up and those for which it\nclogs up in finite time. We also derive criteria for microbial persistence and\nextinction. Finally, we present a numerical evidence that a multistable\ncoexistence in the chemostat with variable dilution rate is feasible.",
    "explanation":"Specifically, we formulate a novel mathematical model of a chemostat where the increase of the biofilm volume occurs at the expense of the fluid volume of the bioreactor, and as a result the corresponding dilution rate increases reciprocally.",
    "b_id":[
      "b1",
      "b8"
    ],
    "b_title":[
      "Microreactors gain wider use as alternative to batch production",
      "How flocculation can explain coexistence in the chemostat"
    ],
    "b_abstract":[
      "The microreactors are gaining wide use among the pharmaceuticals and chemical companies as an alternative to batch production. They not only offers a flexible approach to continuous processing, but promises to save much of the time and effort consumed while expanding the chemistries at commercial scale. Most of the ten global pharma and chemical companies have acquired the Cytos Lab System,, a microreactor product developed by Cellular Process Chemistry Systems GmbH (CPC). Microreactors are comprised of plates with distinct channels in the submillimeter range, providing high surface-to-volume ratio, ultra fast mixing and high degree of control at all levels of production.",
      "We study a chemostat model in which two microbial species grow on single resource. show that coexistence is possible when the would normally win exclusive competition aggregates flocs. Our mathematical analysis exploits fact flocculation fast compared to biological growth, common hypothesis floc models. A numerical shows validity of this approach large parameter range. indicate how our yields mechanistic justification for so-called density-dependent growth."
    ],
    "b_categories":[
      [
        "q-bio.OT"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Effect of bioclogging in porous media on complex conductivity signatures"
    ],
    "c_abstract":[
      "Flow through sand columns inoculated with Pseudomonas aeruginosa were used to investigate the effect of bioclogging on complex conductivity and flow transport properties. Complex (0.1\u20131000 Hz), bulk hydraulic (K), volumetric rate (Q), dispersivity (D), microbial cell concentrations monitored over time. Environmental scanning electron microscope images sands obtained at end experiment. Bioclogging resulting from increases in concentration production exopolymeric substances (EPS) had a large impact imaginary ( \u03c3 \u2033), K, Q, D, porosity (\u03a6). Changes electrical properties developed three stages: an initial stage 1 no significant changes all measured parameters (Days 1\u20138), which we attribute reversible irreversible attachment cells sand. In 2a 9\u201316), caused by growth biomass either as microcolonies filling pore throats and\/or uniform covering surfaces resulted maximum decrease Q but only moderate \u2033. 2b 17\u201324), EPS increase biofilm thickness higher \u2033 compared 2a. 3 25\u201332), reached quasi steady state insignificant are observed parameters. The results this study suggest that can provide complimentary information assessment porous media."
    ],
    "c_categories":[
      [
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.07031",
    "date":null,
    "a_title":"Evaluating the Accuracy of Chatbots in Financial Literature",
    "a_abstract":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "explanation":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview versions), and Gemini Advanced, in providing references on financial literature and employing novel methodologies.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "ChatGPT Hallucinates Non-existent Citations: Evidence from Economics"
    ],
    "b_abstract":[
      "In this study, we generate prompts derived from every topic within the Journal of Economic Literature to assess abilities both GPT-3.5 and GPT-4 versions ChatGPT large language model (LLM) write about economic concepts. demonstrates considerable competency in offering general summaries but also cites non-existent references. More than 30% citations provided by version do not exist rate is only slightly reduced for version. Additionally, our findings suggest that reliability decreases as become more specific. We provide quantitative evidence errors output demonstrate importance LLM verification. JEL Codes: B4; O33; I2"
    ],
    "b_categories":[
      [
        "q-fin.ST"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Accuracy of Chatbots in Citing Journal Articles"
    ],
    "c_abstract":[
      "This cross-sectional study quantifies the journal article citation error rate of an artificial intelligence chatbot."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06184",
    "date":null,
    "a_title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
    "a_abstract":"In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.",
    "explanation":"This study examines the feasibility of employing multi-task Bayesian optimization to accelerate the hyperparameters search for classifying benign and malignant pulmonary nodules using RBF SVM.",
    "b_id":[
      "b6",
      "b7"
    ],
    "b_title":[
      "Multi-Task Bayesian Optimization",
      "Taking the Human Out of the Loop: A Review of Bayesian Optimization"
    ],
    "b_abstract":[
      "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and shown to yield state-of-the-art performance with impressive ease efficiency. In this paper, we explore whether it is possible transfer knowledge gained from previous optimizations new tasks in order find optimal hyperparameter settings more efficiently. Our approach based on extending multi-task Gaussian processes optimization. We show that method significantly speeds up process when compared standard single-task approach. further propose straightforward extension our algorithm jointly minimize average error across multiple demonstrate how can be used greatly speed k-fold cross-validation. Lastly, an adaptation developed acquisition function, entropy search, cost-sensitive, setting. utility function by leveraging small dataset hyper-parameter large dataset. dynamically chooses which query most information per unit cost.",
      "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing storage architectures. The construction such involves many distributed design choices. end products (e.g., recommendation medical analysis tools, real-time game engines, speech recognizers) thus involve tunable configuration parameters. These parameters often specified hard-coded into the by various developers or teams. If optimized jointly, these can result in significant improvements. Bayesian optimization is a powerful tool for joint choices that gaining great popularity recent years. It promises greater automation so as to increase both product quality human productivity. This review paper introduces optimization, highlights some its methodological aspects, showcases wide range applications."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "New Pathologic Classification of Lung Cancer: Relevance for Clinical Practice and Clinical Trials"
    ],
    "c_abstract":[
      "We summarize significant changes in pathologic classification of lung cancer resulting from the 2011 International Association for Study Lung Cancer\/American Thoracic Society\/European Respiratory Society (IASLC\/ATS\/ERS) adenocarcinoma classification. The was developed by an international core panel experts representing IASLC, ATS, and ERS with oncologists\/pulmonologists, pathologists, radiologists, molecular biologists, thoracic surgeons. Because 70% patients present advanced stages, a new approach to small biopsies cytology specific terminology criteria focused on need distinguishing squamous cell carcinoma testing EGFR mutations ALK rearrangement. Tumors previously classified as non-small-cell carcinoma, not otherwise specified, because lack clear or morphology should be further using limited immunohistochemical workup preserve tissue testing. terms \"bronchioloalveolar carcinoma\" \"mixed subtype adenocarcinoma\" have been discontinued. For resected adenocarcinomas, concepts situ minimally invasive define who, if they undergo complete resection, will 100% disease-free survival. Invasive adenocarcinomas are now predominant pattern after comprehensive histologic subtyping lepidic, acinar, papillary, solid patterns; micropapillary is added poor prognosis. Former mucinous bronchioloalveolar carcinomas called \"invasive adenocarcinoma.\" field rapidly evolving advances occurring frequent basis, particularly arena, this provides much needed standard diagnosis only patient care but also clinical trials TNM"
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.20675",
    "date":null,
    "a_title":"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data\n  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots",
    "a_abstract":"Magnetic adhesion tracked climbing robots are widely utilized in\nhigh-altitude inspection, welding, and cleaning tasks due to their ability to\nperform various operations against gravity on vertical or inclined walls.\nHowever, during operation, the robot may experience overturning torque caused\nby its own weight and load, which can lead to the detachment of magnetic plates\nand subsequently pose safety risks. This paper proposes an improved ICNN-LSTM\nnetwork classification method based on Micro-Electro-Mechanical Systems (MEMS)\nattitude sensor data for real-time monitoring and assessment of hazardous\nstates in magnetic adhesion tracked climbing robots. Firstly, a data\nacquisition strategy for attitude sensors capable of capturing minute\nvibrations is designed. Secondly, a feature extraction and classification model\ncombining an Improved Convolutional Neural Network (ICNN) with a Long\nShort-Term Memory (LSTM) network is proposed. Experimental validation\ndemonstrates that the proposed minute vibration sensing method achieves\nsignificant results, and the proposed classification model consistently\nexhibits high accuracy compared to other models. The research findings provide\neffective technical support for the safe operation of climbing robots",
    "explanation":"This paper proposes an improved ICNN-LSTM network classification method based on Micro-Electro-Mechanical Systems (MEMS) attitude sensor data for real-time monitoring and assessment of hazardous states in magnetic adhesion tracked climbing robots.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Discriminative feature learning using a multiscale convolutional capsule network from attitude data for fault diagnosis of industrial robots"
    ],
    "b_abstract":[
      "Effective fault diagnosis is important to ensure the reliability, safety, and efficiency of industrial robots. This article proposes a simple yet effective data acquisition strategy based on transmission mechanism analysis, using only one attitude sensor mounted on an end effector or an output component to monitor the attitude of all transmission components. Unlike widely used vibration-monitoring signals, attitude signals can provide fault features reflecting spatial relationships. Using one attitude sensor facilitates the data collection, but weakens fault features and introduces strong background noise in attitude signals. To learn discriminative features from the attitude data collected by the attitude sensor, a multiscale convolutional capsule network (MCCN) is proposed. In MCCN, integrating low-level and high-level features in a convolutional neural network (CNN) as multiscale features is conductive to noise reduction and robust feature extraction, and a capsule network (CapsNet) is used to recognize the spatial relationships in attitude data. The extracted multiscale features in CNN and the spatial-relational features in CapsNet are fused for effective fault diagnosis of industrial robots. The performance of MCCN is evaluated by attaching a softmax-based classifier and integrating it into different transfer learning frameworks to diagnose faults in industrial robots under single and variable working conditions, respectively. Fault diagnosis experiments were conducted on a 6-axis series industrial robot and a parallel robot-driven 3D printer. The superiority of the proposed MCCN was demonstrated by comparing its performance with the other feature learning methods."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "LSTM Based Bearing Fault Diagnosis of Electrical Machines using Motor Current Signal"
    ],
    "c_abstract":[
      "Rolling element bearings are one of the most critical components rotating machinery, with bearing faults amounting up to 50% in electrical machines. Therefore, fault diagnosis has attracted attention many researchers. Typically, is performed using vibration signals from machine. In addition, by deep learning algorithms on signals, detection accuracy close 100% can be achieved. However, measurement requires an additional sensor, which not present majority Nevertheless, alternative approach, stator current used for diagnosis. paper emphasizes current. The signal processing signature extraction that buried underneath noise signal. uses Paderborn University damaged dataset, contains data healthy, real inner raceway and outer different severity. For redundant frequencies filtered, then filtered eight features extracted time time-frequency domain wavelet packet decomposition (WPD). Then, these well known algorithm Long Short-Term Memory (LSTM), classification made. LSTM mostly speech recognition due its coherence, but this paper, ability also demonstrated 96%, outperforms perform method developed independent speed loading conditions."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10403",
    "date":null,
    "a_title":"On the Foundation Model for Cardiac MRI Reconstruction",
    "a_abstract":"In recent years, machine learning (ML) based reconstruction has been widely\ninvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-based\nreconstructions can deliver clinically acceptable image quality under\nsubstantially accelerated scans. ML-based reconstruction, however, also\nrequires substantial data and computational time to train the neural network,\nwhich is often optimized for a fixed acceleration rate or image contrast. In\npractice, imaging parameters are often tuned to best suit the diagnosis, which\nmay differ from the training data. This can result in degraded image quality,\nand multiple trained networks are needed to fulfill the clinical demands. In\nthis study, we propose a foundation model that uses adaptive unrolling,\nchannel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the\nproblem. In particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality. The PCP-UNet is equipped with an image\ncontrast and sampling pattern prompt. In vivo CMR experiments were performed\nusing mixed combinations of image contrasts, acceleration rates, and\n(under)sampling patterns. The proposed foundation model has significantly\nimproved image quality for a wide range of CMR protocols and outperforms the\nconventional ML-based method.",
    "explanation":"n this study, we propose\na foundation model that uses adaptive unrolling, channel-shifting, and\nPattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the problem.\nIn particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality.",
    "b_id":[
      "b14",
      "b1"
    ],
    "b_title":[
      "Sparse MRI: The application of compressed sensing for rapid MR imaging",
      "MoDL: Model-Based Deep Learning Architecture for Inverse Problems"
    ],
    "b_abstract":[
      "Abstract The sparsity which is implicit in MR images exploited to significantly undersample k \u2010space. Some such as angiograms are already sparse the pixel representation; other, more complicated have a representation some transform domain\u2013for example, terms of spatial finite\u2010differences or their wavelet coefficients. According recently developed mathematical theory compressed\u2010sensing, with can be recovered from randomly undersampled \u2010space data, provided an appropriate nonlinear recovery scheme used. Intuitively, artifacts due random undersampling add noise\u2010like interference. In domain significant coefficients stand out above A thresholding recover coefficients, effectively recovering image itself. this article, practical incoherent schemes and analyzed by means aliasing Incoherence introduced pseudo\u2010random variable\u2010density phase\u2010encodes. reconstruction performed minimizing \u2113 1 norm transformed image, subject data fidelity constraints. Examples demonstrate improved resolution accelerated acquisition for multislice fast spin\u2010echo brain imaging 3D contrast enhanced angiography. Magn Reson Med, 2007. \u00a9 2007 Wiley\u2010Liss, Inc.",
      "We introduce a model-based image reconstruction framework with convolution neural network (CNN)-based regularization prior. The proposed formulation provides systematic approach for deriving deep architectures inverse problems the arbitrary structure. Since forward model is explicitly accounted for, smaller fewer parameters sufficient to capture information compared direct inversion approaches. Thus, reducing demand training data and time. we rely on end-to-end weight sharing across iterations, CNN weights are customized model, thus offering improved performance over approaches that pre-trained denoisers. Our experiments show decoupling of number iterations from complexity offered by this benefits, including lower data, reduced risk overfitting, implementations significantly memory footprint. propose enforce data-consistency using numerical optimization blocks, such as conjugate gradients algorithm within network. This offers faster convergence per iteration, methods proximal steps consistency. translates performance, primarily when available GPU restricts iterations."
    ],
    "b_categories":[
      [
        "stat.CO",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Cardiovascular Flow Measurement with Phase-Contrast MR Imaging: Basic Facts and Implementation"
    ],
    "c_abstract":[
      "Phase-contrast magnetic resonance (MR) imaging is a well-known but undervalued method of obtaining quantitative information on blood flow. Applications this technique in cardiovascular MR are expanding. According to the sequences available, phase-contrast measurement can be performed breath hold or during normal respiration. Prospective as well retrospective gating techniques used. Common errors include mismatched encoding velocity, deviation plane, inadequate temporal resolution, spatial accelerated flow and misregistration, phase offset errors. Flow measurements most precise if plane perpendicular vessel interest set through-plane The sequence should repeated at least once, with high velocity used initially. If peak has estimated, an adapted velocity. overall error comprises prescription that occur image analysis data. With imaging, reduced less than 10%, acceptable level for routine clinical use."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15202",
    "date":null,
    "a_title":"A Comparison of Machine Learning Algorithms for Predicting Sea Surface\n  Temperature in the Great Barrier Reef Region",
    "a_abstract":"Predicting Sea Surface Temperature (SST) in the Great Barrier Reef (GBR)\nregion is crucial for the effective management of its fragile ecosystems. This\nstudy provides a rigorous comparative analysis of several machine learning\ntechniques to identify the most effective method for SST prediction in this\narea. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting\n(XGBoost) algorithms. Our results reveal that while LASSO and ridge regression\nperform well, Random Forest and XGBoost significantly outperform them in terms\nof predictive accuracy, as evidenced by lower Mean Squared Error (MSE), Mean\nAbsolute Error (MAE), and Root Mean Squared Prediction Error (RMSPE).\nAdditionally, XGBoost demonstrated superior performance in minimizing Kullback-\nLeibler Divergence (KLD), indicating a closer alignment of predicted\nprobability distributions with actual observations. These findings highlight\nthe efficacy of using ensemble methods, particularly XGBoost, for predicting\nsea surface temperatures, making them valuable tools for climatological and\nenvironmental modeling.",
    "explanation":"This study provides a rigorous comparative\nanalysis of several machine learning techniques to identify the most effective method for SST\nprediction in this area. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting (XGBoost)\nalgorithms. Our results reveal that while LASSO and ridge regression perform well, Random Forest\nand XGBoost significantly outperform them in terms of predictive accuracy, as evidenced by lower\nMean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Prediction\nError (RMSPE).",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "The Great Barrier Reef: an environmental history"
    ],
    "b_abstract":[
      "Reconstructing changes in the Great Barrier Reef 15 3 The natural context of 33 4 spread European settlement coastal Queensland 43 5 beche--de ... mer, pearl shell and trochus fisheries 55 6 Impacts on marine turtles 72 7 dugongs 95 8 whales, sharks fish 9 impacts coral collecting 10 guano rock phosphate mining 11 vi Contents 12 Other reefs 13 Changes island biota 14 Conclusion"
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Ilf-lstm: Enhanced loss function in lstm to predict the sea surface temperature"
    ],
    "c_abstract":[
      "Globe's primary issue is global warming, water temperatures have accompanied it as the sea surface temperature, and it is the primary attribute to balance the energy on the earth's surface. Sea surface temperature prediction is vital to climate forecast. Downwelling currents carry some of this heat to the ocean's bottom layers, which are also heating, covering far behind the increase in sea surface temperature. In deep learning models, the correct loss function will try to reduce the error and converge fast. The proposed improved loss function correctly estimates how close the predictions made by the long short-term memory match the observed values in the training data. This research considers location-specific sea surface temperature predictions using the improved loss function in the long short-term memory neural network at six different locations around India for daily, weekly, and monthly time horizons. Most existing research concentrated on periodic forecasts, but this paper focused on daily, weekly, and monthly predictions. The improved loss function\u2014long short-term memory, achieved 98.7% accuracy, and this improved loss function overcomes the limitations of the existing techniques and reduces the processing time to\u2009~\u20090.35 s. In this research, the sea surface temperature prediction using the improved loss function in the long short-term memory neural network gives better results than the standard prediction models and other existing techniques by considering the long-time dependencies and obtaining features from the spatial data."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06741",
    "date":null,
    "a_title":"Methane projections from Canada's oil sands tailings using scientific\n  deep learning reveal significant underestimation",
    "a_abstract":"Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels.",
    "explanation":"In order\nto determine the methane emitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory controlled experiments,\nand industrial reports to train a physics constrained machine learning model.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Learning Polynomials with Neural Networks"
    ],
    "b_abstract":[
      "We study the effectiveness of learning low degree polynomials using neural networks by gradient descent method. While have been shown to great expressive power, and has widely used in practice for networks, few theoretical guarantees are known such methods. In particular, it is well that can get stuck at local minima, even simple classes target functions. this paper, we present several positive results support networks. focus on twolayer where bottom layer a set non-linear hidden nodes, top node linear function, similar Barron (1993). First show randomly initialized network with sufficiently many units, generic algorithm learns any polynomial, assuming initialize weights randomly. Secondly, if use complex-valued (the function still be real), then under suitable conditions, there no robust minima: always escape minimum performing random perturbation. This property does not hold real-valued weights. Thirdly, discuss whether sparse learned small size dependent sparsity function."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Physics-informed machine learning"
    ],
    "c_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18259",
    "date":null,
    "a_title":"Transfer Learning for Deep Learning-based Prediction of Lattice Thermal\n  Conductivity",
    "a_abstract":"Machine learning promises to accelerate the material discovery by enabling\nhigh-throughput prediction of desirable macro-properties from atomic-level\ndescriptors or structures. However, the limited data available about precise\nvalues of these properties have been a barrier, leading to predictive models\nwith limited precision or the ability to generalize. This is particularly true\nof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,\nDFT-based) computed values are limited to a few dozen materials with little\nvariability. Based on such datasets, we study the impact of transfer learning\non both the precision and generalizability of a deep learning model\n(ParAIsite). We start from an existing model (MEGNet~\\cite{Chen2019}) and show\nthat improvements are obtained by fine-tuning a pre-trained version on\ndifferent tasks. Interestingly, we also show that a much greater improvement is\nobtained when first fine-tuning it on a large datasets of low-quality\napproximations of LTC (based on the AGL model) and then applying a second phase\nof fine-tuning with our high-quality, smaller-scale datasets. The promising\nresults obtained pave the way not only towards a greater ability to explore\nlarge databases in search of low thermal conductivity materials but also to\nmethods enabling increasingly precise predictions in areas where quality data\nare rare.",
    "explanation":"Machine learning promises to accelerate the material discovery by enabling high-throughput pre-\ndiction of desirable macro-properties from atomic-level descriptors or structures.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Physics-informed machine learning"
    ],
    "b_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Quantifying the performance of machine learning models in materials discovery"
    ],
    "c_abstract":[
      "The predictive capabilities of machine learning (ML) models used in materials discovery are typically measured using simple statistics such as the root-mean-square error (RMSE) or coefficient determination ($r^2$) between ML-predicted property values and their known values. A tempting assumption is that with low should be effective at guiding discovery, conversely, high give poor performance. However, we observe no clear connection exists a \"static\" quantity averaged across an entire training set, RMSE, ML model's ability to dynamically guide iterative (and often extrapolative) novel targeted properties. In this work, simulate sequential (SL)-guided process demonstrate decoupling traditional model metrics performance discoveries. We show depends strongly on (1) target range within distribution (e.g., whether 1st 10th decile material desired); (2) incorporation uncertainty estimates SL acquisition function; (3) scientist interested one many targets; (4) how iterations allowed. To overcome limitations static robustly capture performance, recommend Discovery Yield ($DY$), measure high-performing were discovered during SL, Probability ($DP$), likelihood discovering any point process."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18253",
    "date":null,
    "a_title":"Multimodal Integration of Longitudinal Noninvasive Diagnostics for\n  Survival Prediction in Immunotherapy Using Deep Learning",
    "a_abstract":"Purpose: Analyzing noninvasive longitudinal and multimodal data using\nartificial intelligence could potentially transform immunotherapy for cancer\npatients, paving the way towards precision medicine. Methods: In this study, we\nintegrated pre- and on-treatment blood measurements, prescribed medications and\nCT-based volumes of organs from a large pan-cancer cohort of 694 patients\ntreated with immunotherapy to predict short and long-term overall survival. By\nleveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA)\nnetwork were trained end-to-end to predict mortality at three, six, nine and\ntwelve months. These models were also compared to baseline methods\nincorporating intermediate and late fusion based integration methods. Results:\nThe strongest prognostic performance was demonstrated using the extended\ntransformer-based multimodal model with area under the curves (AUCs) of $0.84\n\\pm $0.04, $0.83 \\pm $0.02, $0.82 \\pm $0.02, $0.81 \\pm $0.03 for 3-, 6-, 9-,\nand 12-month survival prediction, respectively. Conclusion: Our findings\nsuggest that analyzing integrated early treatment data has potential for\npredicting survival of immunotherapy patients. Integrating complementary\nnoninvasive modalities into a jointly trained model, using our extended\ntransformer-based architecture, demonstrated an improved multimodal prognostic\nperformance, especially in short term survival prediction.",
    "explanation":"In this study, we integrated pre- and on-treatment blood\nmeasurements, prescribed medications and CT-based volumes of organs from a large\npan-cancer cohort of 694 patients treated with immunotherapy to predict short and long-term\noverall survival. By leveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA) network were\ntrained end-to-end to predict mortality at three, six, nine and twelve months.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Multimodal data fusion for cancer biomarker discovery with deep learning"
    ],
    "b_abstract":[
      "Technological advances have made it possible to study a patient from multiple angles with high-dimensional, high-throughput multiscale biomedical data. In oncology, massive amounts of data are being generated, ranging from molecular, histopathology, radiology to clinical records. The introduction of deep learning has greatly advanced the analysis of biomedical data. However, most approaches focus on single data modalities, leading to slow progress in methods to integrate complementary data types. Development of effective multimodal fusion approaches is becoming increasingly important as a single modality might not be consistent and sufficient to capture the heterogeneity of complex diseases to tailor medical care and improve personalized medicine. Many initiatives now focus on integrating these disparate modalities to unravel the biological processes involved in multifactorial diseases such as cancer. However, many obstacles remain, including lack of usable data as well as methods for clinical validation and interpretation. Here, we cover these current challenges and reflect on opportunities through deep learning to tackle data sparsity and scarcity, multimodal interpretability and standardization of datasets."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Artificial intelligence for predictive biomarker discovery in immuno-oncology: a systematic review"
    ],
    "c_abstract":[
      "Background: The widespread use of immune checkpoint inhibitors (ICIs) has revolutionised treatment of multiple cancer types. However, selecting patients who may benefit from ICI remains challenging. Artificial intelligence (AI) approaches allow exploitation of high-dimension oncological data in research and development of precision immuno-oncology. Materials and methods: We conducted a systematic literature review of peer-reviewed original articles studying the ICI efficacy prediction in cancer patients across five data modalities: genomics (including genomics, transcriptomics, and epigenomics), radiomics, digital pathology (pathomics), and real-world and multimodality data. Results: A total of 90 studies were included in this systematic review, with 80% published in 2021-2022. Among them, 37 studies included genomic, 20 radiomic, 8 pathomic, 20 real-world, and 5 multimodal data. Standard machine learning (ML) methods were used in 72% of studies, deep learning (DL) methods in 22%, and both in 6%. The most frequently studied cancer type was non-small-cell lung cancer (36%), followed by melanoma (16%), while 25% included pan-cancer studies. No prospective study design incorporated AI-based methodologies from the outset; rather, all implemented AI as a post hoc analysis. Novel biomarkers for ICI in radiomics and pathomics were identified using AI approaches, and molecular biomarkers have expanded past genomics into transcriptomics and epigenomics. Finally, complex algorithms and new types of AI-based markers, such as meta-biomarkers, are emerging by integrating multimodal\/multi-omics data. Conclusion: AI-based methods have expanded the horizon for biomarker discovery, demonstrating the power of integrating multimodal data from existing datasets to discover new meta-biomarkers. While most of the included studies showed promise for AI-based prediction of benefit from immunotherapy, none provided high-level evidence for immediate practice change. A priori planned prospective trial designs are needed to cover all lifecycle steps of these software biomarkers, from development and validation to integration into clinical practice."
    ],
    "c_categories":[
      [
        "Immunotherapy"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17617",
    "date":null,
    "a_title":"An Ensemble Approach for Brain Tumor Segmentation and Synthesis",
    "a_abstract":"The integration of machine learning in magnetic resonance imaging (MRI),\nspecifically in neuroimaging, is proving to be incredibly effective, leading to\nbetter diagnostic accuracy, accelerated image analysis, and data-driven\ninsights, which can potentially transform patient care. Deep learning models\nutilize multiple layers of processing to capture intricate details of complex\ndata, which can then be used on a variety of tasks, including brain tumor\nclassification, segmentation, image synthesis, and registration. Previous\nresearch demonstrates high accuracy in tumor segmentation using various model\narchitectures, including nn-UNet and Swin-UNet. U-Mamba, which uses state space\nmodeling, also achieves high accuracy in medical image segmentation. To\nleverage these models, we propose a deep learning framework that ensembles\nthese state-of-the-art architectures to achieve accurate segmentation and\nproduce finely synthesized images.",
    "explanation":"The integration of machine learning in magnetic resonance\nimaging (MRI), specifically in neuroimaging, is proving to be incred-\nibly effective, leading to better diagnostic accuracy, accelerated image\nanalysis, and data-driven insights, which can potentially transform pa-\ntient care.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "ALL-Net: Anatomical information lesion-wise loss function integrated into neural network for multiple sclerosis lesion segmentation"
    ],
    "b_abstract":[
      "Accurate detection and segmentation of multiple sclerosis (MS) brain lesions on magnetic resonance images are important for disease diagnosis treatment. This is a challenging task as vary greatly in size, shape, location, image contrast. The objective our study was to develop an algorithm based deep convolutional neural network integrated with anatomic information lesion-wise loss function (ALL-Net) fast accurate automated MS lesions. Distance transformation mapping used construct module that encoded lesion-specific anatomical information. To overcome the lesion size imbalance during training improve small lesions, developed which individual were modeled spheres equal size. On ISBI-2015 longitudinal challenge dataset (19 subjects total), ALL-Net achieved overall score 93.32 amongst top performing methods. larger Cornell (176 significantly improved both voxel-wise metrics (Dice improvement 3.9% 35.3% p-values ranging from p < 0.01 0.0001, AUC precision-recall curve 2.1% 29.8%) (lesion-wise F1 12.6% 29.8% all ROC 1.4% 20.0%) compared leading publicly available tools."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Deep learning-Based 3D inpainting of brain MR images"
    ],
    "c_abstract":[
      "Abstract The detailed anatomical information of the brain provided by 3D magnetic resonance imaging (MRI) enables various neuroscience research. However, due to long scan time for MR images, 2D images are mainly obtained in clinical environments. purpose this study is generate from a sparsely sampled using an inpainting deep neural network that has U-net-like structure and DenseNet sub-blocks. To train network, not only fidelity loss but also perceptual based on VGG were considered. Various methods used assess overall similarity between inpainted original data. In addition, morphological analyzes performed investigate whether data produced local features similar diagnostic ability was evaluated investigating pattern changes disease groups. Brain anatomy details efficiently recovered proposed network. voxel-based analysis gray matter volume cortical thickness, differences observed small clusters. method will be useful utilizing advanced neuroimaging techniques with MRI"
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00252",
    "date":null,
    "a_title":"Localization Phenomena in Large-Scale Networked Systems: Implications\n  for Fragility",
    "a_abstract":"We study phenomena where some eigenvectors of a graph Laplacian are largely\nconfined in small subsets of the graph. These localization phenomena are\nsimilar to those generally termed Anderson Localization in the Physics\nliterature, and are related to the complexity of the structure of large graphs\nin still unexplored ways. Using spectral perturbation theory and\npseudo-spectrum analysis, we explain how the presence of localized eigenvectors\ngives rise to fragilities (low robustness margins) to unmodeled node or link\ndynamics. Our analysis is demonstrated by examples of networks with relatively\nlow complexity, but with features that appear to induce eigenvector\nlocalization. The implications of this newly-discovered fragility phenomenon\nare briefly discussed.",
    "explanation":"The choices in Task 3 where represent the interdisciplinary topics utilized in this research paper summarized in the Abstract. Below are a few sentences from the Abstract that reflect that:\n\n\"Localization in the Physics literature, and are related to the complexity of the structure of large graphs in still unexplored ways.\"\n\"Using spectral perturbation theory and pseudospectrum analysis, we explain how the presence of localized eigenvectors gives rise to fragilities (low robustness margins) to unmodeled node or link dynamics.\"",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Analytic perturbation theory for matrices and operators"
    ],
    "b_abstract":[
      "Perturbation theory is the study of the behavior of mathematical objects under the influence of perturbations. It is not a well-defined mathematical topic with specific objects and methods, but rather a method of investigation. In this book, perturbation theory will be developed for linear operators. First, inter-est focuses on the properties of spectral objects, such as eigenvalues, eigenprojections, eigenvectors and Jordan vectors, under perturbation of the underlying operator. This study encompasses some difficult problems. On the one hand, variations of the spectral objects need to be calculated quantitatively. The spectral objects are assumed known for the unperturbed operator, the determination (or at least the approximation) of the spectral objects for the perturbed operator is at issue. This is the starting point for the perturbation theory of L. RAYLEIGH [1] (see also R. COURANT and D. HTT.BEBT [1, p. 296 sqq]). On the other hand, the spectral objects often undergo abrupt qualitative changes, even in the case of small perturbations. These changes cause significant complications. Usually, the behavior of the spectral objects depends strongly on the assumptions about the nature of the perturbation. For example, one can assume continuity, differ-entiability, smoothness (i.e. arbitrary differentiability) or analyticity. In the following discussion, only the case of analytic (holomorphic) perturbations will be investigated, even if this strong restriction is applied, the problems remain difficult enough. On the one hand, solving problems of perturbation theory is of conceptual interest. The study of intrinsic spectral properties of a linear operator undergoing perturbation leads to deeper insights and understanding of the structure of the operator. It also leads to the development of new tools for further investigations. On the other hand, applications (inside and outside of mathematics) lead to new questions in perturbation theory. One of the first calculations of perturbation theory was given by L. Rayleigh, who determined the eigenfrequencies and eigenmodes of an oscillating string, fixed at x = 0 and x = n, whose elasticity modulus is constant and whose mass density Q(X) has only a small deviation from a constant value for all x, 0 ^ x 5S n. (That is, the density o(x) is of the form Q(X) = p0 + ea(x), where a(x) is a given function and where e is a small perturbation parameter.) Actually, as this example indicates, the starting point for the development of per-turbation theory was the study of perturbations of spectral objects (eigenvalues and eigenvectors) for concrete classes of operators, for example, Fredholm integral operators or Sturm-Liouville differential operators (for example, see L. LIECHTENSTEIN [1])."
    ],
    "b_categories":[
      [
        "Analytic Perturbation Theory "
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Localization and landscape functions for graph laplacians"
    ],
    "c_abstract":[
      "We discuss explicit landscape functions for quantum graphs. By a 'landscape function' Upsilon(x) we mean a function that controls the localization properties of normalized eigenfunctions psi(x) through a pointwise inequality of the form |psi(x)| le Upsilon(x). The ideal Upsilon is a function that a) responds to the potential energy V(x) and to the structure of the graph in some formulaic way; b) is small in examples where eigenfunctions are suppressed by the tunneling effect, and c) relatively large in regions where eigenfunctions may - or may not - be concentrated, as observed in specific examples. It turns out that the connectedness of a graph can present a barrier to the existence of universal landscape functions in the high-energy r\u00e9gime, as we show with simple examples. We therefore apply different methods in different r\u00e9gimes determined by the values of the potential energy V(x) and the eigenvalue parameter E."
    ],
    "c_categories":[
      [
        "Anderson Localization"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.06513",
    "date":null,
    "a_title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning",
    "a_abstract":"Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI\/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI\/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https:\/\/github.com\/saranggalada\/PRISM",
    "explanation":"From the selected references in Task 3, the following sentences from the abstract reflect the interdisciplinary topics of this research paper, combining the field of medicine  (MRI Scans) with machine learning (AI\/ML tasks):\n\n\"Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware,\nand acquisition protocols, thereby compromising accuracy\nand reliability in clinical AI\/ML tasks. \"\n\n\"We present PRISM (Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning framework for harmonizing structural brain MRI across multiple sites while preserving data privacy.\"",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Advances and Open Problems in Federated Learning"
    ],
    "b_abstract":[
      "The term Federated Learning was coined as recently 2016 to describe a machine learning setting where multiple entities collaborate in solving problem, under the coordination of central server or service provider. Each client\u2019s raw data is stored locally and not exchanged transferred; instead, focused updates intended for immediate aggregation are used achieve objective. Since then, topic has gathered much interest across many different disciplines realization that these interdisciplinary problems likely requires just but techniques from distributed optimization, cryptography, security, differential privacy, fairness, compressed sensing, systems, information theory, statistics, more. This monograph contributions leading experts disciplines, who latest state-of-the art their perspective. These have been carefully curated into comprehensive treatment enables reader understand work done get pointers effort required solve before can become reality practical systems. Researchers working area systems will find this an enlightening read may inspire them on challenging issues outlined. up speed quickly easily what increasingly important topic: Learning."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "The future of digital health with federated learning"
    ],
    "c_abstract":[
      "Abstract Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing data not fully exploited ML primarily because it sits silos privacy concerns restrict access to this data. However, without sufficient will be prevented reaching its full potential and, ultimately, making the transition research clinical practice. This paper considers key factors contributing issue, explores how federated (FL) may provide solution future of digital health highlights challenges considerations that need addressed."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16464",
    "date":null,
    "a_title":"Generating social networks with static and dynamic utility-maximization\n  approaches",
    "a_abstract":"In this paper, we introduce a conceptual framework that model human social\nnetworks as an undirected dot-product graph of independent individuals. Their\nrelationships are only determined by a cost-benefit analysis, i.e. by\nmaximizing an objective function at the scale of the individual or of the whole\nnetwork. On this framework, we build a new artificial network generator in two\nversions. The first fits within the tradition of artificial network generators\nby being able to generate similar networks from empirical data. The second\nrelaxes the computational efficiency constraint and implements the same\nmicro-based decision algorithm, but in agent-based simulations with time and\nfully independent agents. This latter version enables social scientists to\nperform an in-depth analysis of the consequences of behavioral constraints\naffecting individuals on the network they form. This point is illustrated by a\ncase study of imperfect information.",
    "explanation":"The two key references selected in Task 3 reflect what makes this paper an IDR. The sentences copied from the abstract that relate to the references are shown below, combining economics and computational engineering.\n\n\"Their relationships are only determined by a cost-benefit analysis...\"\n\n\"The second relaxes the computational efficiency constraint\nand implements the same micro-based decision algorithm, but in agent-based simulations with time and fully independent agents.\"",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Meeting Strangers and Friends of Friends: How Random Are Social Networks?"
    ],
    "b_abstract":[
      "We present a dynamic model of network formation where nodes find other with whom to form links in two ways: some are found uniformly at random, while others by searching locally through the current structure (e.g., meeting friends friends). This combination processes results spectrum features exhibited large social networks, including presence more high- and low-degree than when formed independently having low distances between network, high clustering on local level. fit data from six networks impute relative ratio random network-based meetings link formation, which turns out vary dramatically across applications. show that as random\/network-based varies, resulting degree distributions can be ordered sense stochastic dominance, allows us infer how process affects average utility network. (JEL D85, Z13)"
    ],
    "b_categories":[
      [
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "An agent-based spatial urban social network generator: A case study of beijing, china"
    ],
    "c_abstract":[
      "This paper proposes an agent-based spatial social network model, which combines a utility function and heuristic algorithms, to formulate friendships of agents in a given synthetic population comprising individuals and households, as well as their attributes and locations. In order to better and explicitly represent the real social networks, the model attempts to generate both close and somewhat close social networks by linking agents with either close or somewhat close friendships, fitting both distributions of network degree and transitivity, which are two basic characteristics of a network. Here, a utility function, which incorporates the similarity between agents in individual attributes (e.g., sex), as well as the spatial closeness of their residential locations and workplaces, is developed to judge whether a friendship between a pair of agents can be built. Furthermore, the social network model is developed as a key component of an agent-and Geographic Information System (GIS)-based virtual city creator that is a set of synthesis methods used to generate spatially disaggregate urban data. Finally, Beijing, China is used as a case study. Both close and somewhat close social networks are generated with the target and generated distributions well matched, and the generated networks are further analysed from a geographical perspective."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.17260",
    "date":null,
    "a_title":"MiceBoneChallenge: Micro-CT public dataset and six solutions for\n  automatic growth plate detection in micro-CT mice bone scans",
    "a_abstract":"Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
    "explanation":"This IDR combines various fields like computer science (Computer Vision and AI) and physical medicine (CT Scans) introduced in the abstract. The selected key references from Task 3 are described with a few sentences from the abstract shown below:\n\n\"We prepared and annotated a high-quality dataset of 3D \u03bcCT bone scans from 83 mice. \"\n\n\"As a result, six computer vision solutions were developed that can accurately identify the location of the growth plate plane. \"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Differentiation of distal ureteral stones and pelvic phleboliths using a convolutional neural network"
    ],
    "b_abstract":[
      "Abstract The objectives were to develop and validate a Convolutional Neural Network (CNN) using local features for differentiating distal ureteral stones from pelvic phleboliths, compare the CNN method with semi-quantitative radiologists\u2019 assessments evaluate whether assessment of calcification its surroundings is sufficient discriminating phleboliths in non-contrast-enhanced CT (NECT). We retrospectively included 341 consecutive patients acute renal colic stone on NECT showing either stone, phlebolith or both. A 2.5-dimensional (2.5D-CNN) model was used, where perpendicular axial, coronal sagittal images through each used as input data CNN. trained 384 calcifications, evaluated an unseen dataset 50 phleboliths. compared by seven radiologists who reviewed 5 \u00d7 cm image stack surrounding calcification, cut-off values based attenuation volume calcifications. differentiated sensitivity, specificity accuracy 94%, 90% 92% AUC 0.95. This similar majority vote 93% significantly higher ( p = 0.03) than mean radiologist 86%. 49%. In conclusion, features. However, more are needed reach optimal discrimination."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Micro-CT data of early physiological cancellous bone formation in the lumbar spine of female C57BL\/6 mice"
    ],
    "c_abstract":[
      "Micro-CT provides critical data for musculoskeletal research, yielding three-dimensional datasets containing distributions of mineral density. Using high-resolution scans, we quantified changes in the fine architecture of bone in the spine of young mice. This data is made available as a reference to physiological cancellous bone growth. The scans (n\u2009=\u200919) depict the extensive structural changes typical for female C57BL\/6 mice pups, aged 1-, 3-, 7-, 10- and 14-days post-partum, as they attain the\u00a0mature geometry. We reveal the micro-morphology down to individual\u00a0trabeculae in the spine that follow phases of mineral-tissue rearrangement in the growing lumbar vertebra on a micrometer length scale. Phantom data is provided to facilitate mineral density calibration. Conventional histomorphometry matched with our micro-CT data on selected samples confirms the validity and accuracy of our 3D scans. The data may thus serve as a reference for modeling normal bone growth and can be used to benchmark other experiments assessing the effects of biomaterials, tissue growth, healing, and regeneration. Measurement(s) bone growth \u2022 bone mineralization involved in bone maturation Technology Type(s) micro-computed tomography Factor Type(s) age Sample Characteristic - Organism Mus musculus Sample Characteristic - Environment biological_process Machine-accessible metadata file describing the reported data: https:\/\/doi.org\/10.6084\/m9.figshare.14062073"
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.14846",
    "date":null,
    "a_title":"Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy\n  with Pre-training, Data Augmentation and Dual Flow UNet",
    "a_abstract":"Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps:\/\/github.com\/WltyBY\/HNTS-MRG2024_train_code.",
    "explanation":"In this IDR, mainly two topics from the two the two different fields of medical physics and artificial intelligence are being described. The use of MRI scans falls under the Medical Physics category and utilizing computer vision falls under AI. \n\nHere are a few sentences from the abstract that reflect the integration of this interdisciplinary ideas:\n\n\" In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images.\"\n\"For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels.\"",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Evaluation of the Impact of Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) Definition for Radiation Treatment Planning (RTP) of Inoperable High Grade Gliomas (HGGs)"
    ],
    "b_abstract":[
      "Aim and Background . Inoperable high-grade gliomas (HGGs) comprise a specific group of brain tumors portending very poor prognosis. In the absence surgical management, radiation therapy (RT) offers primary local treatment modality for inoperable HGGs. Optimal target definition planning (RTP) HGGs is difficult task given diffusely infiltrative nature disease. this context, detailed multimodality imaging information may add to accuracy in We evaluated impact Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) RTP study. Materials Methods Twenty-five patients with clinical diagnosis HGG were included GTV was based Computed Tomography- (CT-) simulation images only or both CT-simulation MR images, comparative assessment performed investigate incorporation MRI into Results Median volume acquired by using use CT 65.3 (39.6 - 94.3) cc 76.1 (46.8-108.9) cc, respectively. Incorporation has resulted median increase 12.61% (6%-19%) defined only, which statistically significant (p &lt; 0.05). Conclusion improve have implications dose escalation\/intensification strategies despite need further supporting evidence."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.16995",
    "date":null,
    "a_title":"Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies\n  in Concentrating Solar Power Tower Plants",
    "a_abstract":"Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to\nfocus sunlight onto a central receiver. Although simple aiming strategies, such\nas directing all heliostats to the receivers equator, can maximize energy\ncollection, they often result in uneven flux distributions that lead to\nhotspots, thermal stresses, and reduced receiver lifetimes. This paper presents\na novel, data-driven approach that integrates constraint learning, neural\nnetwork-based surrogates, and mathematical optimization to overcome these\nchallenges. The methodology learns complex heliostat-to-receiver flux\ninteractions from simulation data, constructing a surrogate model that is\nembedded into a tractable optimization framework. By maximizing a tailored\nquality score that balances energy collection and flux uniformity, the approach\nyields smoothly distributed flux profiles and mitigates excessive thermal\npeaks. An iterative refinement process, guided by the trust region and\nprogressive data sampling, ensures the surrogate model improves the obtained\nsolution by exploring new spaces during the iterations. Results from a real\nCSPT case study demonstrate that the proposed approach surpasses conventional\nheuristic methods, offering flatter flux distributions and safer thermal\nconditions without a substantial loss in overall energy capture.",
    "explanation":"The two fields described in the references chosen in Task 3 were AI and Mathematics. This IDR talks a lot about mathematical optimization and control to overcome certain challenges as well as leverages AI and machine learning (neural networks).\n\nSentences from the abstract:\n\"This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges.\"\n",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Multi-objective performance optimization & thermodynamic analysis of solar powered supercritical co2 power cycles using machine learning methods & genetic algorithm"
    ],
    "b_abstract":[
      "The present study is focused on multi-objective performance optimization & thermodynamic analysis from the perspectives of energy and exergy for Recompression, Partial Cooling & Main Compression Intercooling supercritical CO2 (sCO2) Brayton cycles for concentrated solar power (CSP) applications using machine learning algorithms. The novelty of this work lies in the integration of artificial neural networks (ANN) and genetic algorithms (GA) for optimizing the performance of advanced sCO2 power cycles considering climatic variation, which has significant implications for both the scientific community and engineering applications in the renewable energy sector. The methodology employed includes thermodynamic analysis based on energy, exergy & environmental factors including system performance optimization. The system is modelled for net power production of 15 MW thermal output utilizing equations for the energy and exergy balance for each component. Subsequently, thermodynamic model extracted dataset used for prediction & evaluation of Random Forest, XGBoost, KNN, AdaBoost, ANN and LightGBM algorithm. Finally, considering climate conditions, multi-objective optimization is carried out for the CSP integrated sCO2 Power cycle for optimal power output, exergy destruction, thermal and exergetic efficiency. Genetic algorithm and TOPSIS (technique for order of preference by similarity to ideal solution), multi-objective decision-making tool, were used to determine the optimum operating conditions. The major findings of this work reveal significant improvements in the performance of the advanced sCO2 cycle by 1.68 % and 7.87 % compared to conventional recompression and partial cooling cycle, respectively. This research could advance renewable energy technologies, particularly concentrated solar power, by improving power cycle designs to increase system efficiency and economic feasibility. Optimized advanced supercritical CO2 power cycles in concentrated solar power plants might increase renewable energy use and energy generation infrastructure, potentially opening new research avenues."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A method for real-time optimal heliostat aiming strategy generation via deep learning"
    ],
    "c_abstract":[
      "Optimal aiming strategies are essential for efficient solar power tower technology operation. However, the high calculation complexity makes it difficult for existing optimization methods to solve the optimization problem in real-time directly. This work proposes a real-time optimal heliostat aiming strategy generation method via deep learning. First, a two-stage learning scheme where the neural network models are trained by genetic algorithm (GA) benchmark solutions to produce an optimal aiming strategy is presented. Then, an end-to-end model without needing GA solutions for training is developed and discussed. Furthermore, a robust end-to-end training method using randomly sampled flux maps is also proposed. The proposed models demonstrated comparable performance as GA with two orders of magnitude less computation time through case studies. Among the proposed models, the end-to-end model shows significantly better generalization ability than the pure data-driven two-stage model on the test set. A robust end-to-end model with data enhancement has better robustness on unseen flux maps."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.12897",
    "date":null,
    "a_title":"Tree Species Classification using Machine Learning and 3D Tomographic\n  SAR -- a case study in Northern Europe",
    "a_abstract":"Tree species classification plays an important role in nature conservation,\nforest inventories, forest management, and the protection of endangered\nspecies. Over the past four decades, remote sensing technologies have been\nextensively utilized for tree species classification, with Synthetic Aperture\nRadar (SAR) emerging as a key technique. In this study, we employed TomoSense,\na 3D tomographic dataset, which utilizes a stack of single-look complex (SLC)\nimages, a byproduct of SAR, captured at different incidence angles to generate\na three-dimensional representation of the terrain. Our research focuses on\nevaluating multiple tabular machine-learning models using the height\ninformation derived from the tomographic image intensities to classify eight\ndistinct tree species. The SLC data and tomographic imagery were analyzed\nacross different polarimetric configurations and geosplit configurations. We\ninvestigated the impact of these variations on classification accuracy,\ncomparing the performance of various tabular machine-learning models and\noptimizing them using Bayesian optimization. Additionally, we incorporated a\nproxy for actual tree height using point cloud data from Light Detection and\nRanging (LiDAR) to provide height statistics associated with the model's\npredictions. This comparison offers insights into the reliability of\ntomographic data in predicting tree species classification based on height.",
    "explanation":"Some sentences that describe the integration of interdisciplinary fields based on the selected references in Task 3:\n\n\"Over the past four decades, remote sensing technologies have been extensively utilized for tree species classification, with Synthetic Aperture Radar (SAR) emerging as a key technique. \"\n\"Tree species classification plays an important role in nature conservation, forest inventories, forest management, and the protection of endangered species.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Mapping Tree Species Using Advanced Remote Sensing Technologies: A State-of-the-Art Review and Perspective"
    ],
    "b_abstract":[
      "Timely and accurate information on tree species (TS) is crucial for developing strategies sustainable management conservation of artificial natural forests. Over the last four decades, advances in remote sensing technologies have made TS classification possible. Since many studies topic been conducted their comprehensive results novel findings published literature, it necessary to conduct an updated review status, trends, potentials, challenges recommend future directions. The will provide overview various optical light detection ranging (LiDAR) sensors; present assess current techniques\/methods for, a general trend method development in, classification; identify limitations In this review, several concluding remarks were made. They include following: (1) A large group using high-resolution satellite, airborne multi-\/hyperspectral imagery, LiDAR data. (2) \u201cmultiple\u201d was observed. (3) Machine learning methods including deep models demonstrated be significant improving accuracy. (4) Recently, unmanned aerial vehicle- (UAV-) based sensors caught interest researchers practitioners topic-related research applications. addition, three directions recommended, refining categories methods, data fusion algorithms or processing chains, exploring new spectral unmixing automatically extract map from satellite hyperspectral"
    ],
    "b_categories":[
      [
        "Remote Sensing Technologies"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Morphological transformation and spatial-logical aggregation for tree species classification using hyperspectral imagery"
    ],
    "c_abstract":[
      "Hyperspectral image (HSI) consists of abundant spectral and spatial characteristics, which contribute to a more accurate identification of materials and land covers. However, most existing methods of hyperspectral image analysis primarily focus on spectral knowledge or coarse-grained spatial information while neglecting the fine-grained morphological structures. In the classification task of complex objects, spatial morphological differences can help to search for the boundary of fine-grained classes, e.g., forestry tree species. Focusing on subtle traits extraction, a spatial-logical aggregation network (SLA-NET) is proposed with morphological transformation for tree species classification. The morphological operators are effectively embedded with the trainable structuring elements, which contributes to distinctive morphological representations. We evaluate the classification performance of the proposed method on two tree species datasets, and the results demonstrate that the proposed SLA-NET significantly outperforms the other state-of-the-art classifiers."
    ],
    "c_categories":[
      [
        "Evolutionary Biology"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07018",
    "date":null,
    "a_title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac",
    "a_abstract":"Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.",
    "explanation":"The field emission is one of the most detrimental problems in superconducting radio-frequency linear accelerators (linacs). The research aims to utilize machine learning with uncertainty quantification to predict radiation levels at multiple locations throughout the linacs.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Field Emission in Superconducting Accelerators: Instrumented Measurements for Its Understanding and Mitigation"
    ],
    "b_abstract":[
      "Several new accelerator projects are adopting superconducting RF (SRF) technology. When accelerating SRF cavities maintain high RF gradients, field emission, the emission of electrons from cavity walls, can occur and may impact operational cavity gradient, radiological environment via activated components, and reliability. In this talk, we will discuss instrumented measurements of field emission from the two 1.1 GeV superconducting continuous wave (CW) linacs in CEBAF. The goal is to improve the understanding of field emission sources originating from cryomodule production, installation and operation. Such basic knowledge is needed in guiding field emission control, mitigation, and reduction toward high gradient and reliable operation of superconducting accelerators."
    ],
    "b_categories":[
      [
        "physics.acc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Accelerating cavity fault prediction using deep learning at Jefferson laboratory"
    ],
    "c_abstract":[
      "Abstract Accelerating cavities are an integral part of the continuous electron beam accelerator facility (CEBAF) at Jefferson Laboratory. When any over 400 in CEBAF experiences a fault, it disrupts delivery to experimental user halls. In this study, we propose use deep learning model predict slowly developing cavity faults. By utilizing pre-fault signals, train long short-term memory-convolutional neural network binary classifier distinguish between radio-frequency (RF) signals during normal operation and RF indicative impending We optimize by adjusting fault confidence threshold implementing multiple consecutive window criterion identify events, ensuring low false positive rate. Results obtained from analysis real dataset collected accelerating simulating deployed scenario demonstrate model\u2019s ability with 99.99% accuracy correctly 80% Notably, these achievements were achieved context highly imbalanced dataset, predictions made several hundred milliseconds before onset fault. Anticipating faults enables preemptive measures improve operational efficiency preventing or mitigating their occurrence."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19844",
    "date":null,
    "a_title":"Musical composition and 2D cellular automata based on music intervals",
    "a_abstract":"This study is a theoretical approach for exploring the applicability of a 2D\ncellular automaton based on melodic and harmonic intervals in random arrays of\nmusical notes. The aim of this study was to explore alternatives uses for a\ncellular automaton in the musical context for better understanding the musical\ncreativity. We used the complex systems and humanities approaches as a\nframework for capturing the essence of creating music based on rules of music\ntheory. Findings suggested that such rules matter for generating large-scale\npatterns of organized notes. Therefore, our formulation provides a novel\napproach for understanding and replicating aspects of the musical creativity.",
    "explanation":"The study is a theorical approach for exploring thge applicability of a D cellular automaton based on moelodic and harmonic intervals in random arrays of musical notes.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A New Kind of Science"
    ],
    "b_abstract":[
      "3R3. A New Kind of Science. - S Wolfram (Wolfram Res Inc, 100 Trade Center Dr, Champaign IL 61820-7237). Media, Champaign, IL. 2002. 1197 pp. ISBN 1-57955-008-8. $44.95. Reviewed by M Gad-el-Hak (Eng Build, Rm 303, Virginia Commonwealth Univ, 601 W Main St, PO Box 843015, Richmond, VA 23284-3015). Reviewing Science is like stepping in a minefield. The danger lies going against the deluge praise, proving relevance to this audience, and arguing proposed new science that allegedly set replace science, as we know it. Those issues will be addressed turn, but first brief background. Stephen considered many have been child prodigy: journal paper particle physics at age 15; stint Oxford; PhD from Caltech 20; youngest recipient MacArthur Prize; faculty positions Caltech, Princeton, Illinois; significant contributions cellular automata complexity theory; developer popular software Mathematica; successful entrepreneur, becoming multi-millionaire 30. Running his company via e-mail videoconference, spent last 10 years virtual seclusion, relentlessly, tirelessly, secretly, nocturnally working on an idea possessed him: generating simple computations, algorithms only few lines. book, targeting both scientists non-scientists, partially about using rules generate complex patterns. In task, author has succeeded beyond reproach not showing can done brilliantly beautifully, also explaining it lucidly enough for all understand, appreciate, savor. opinion several reviewers, including one, aspect book tour de force clarity, elegance, simplicity. problem huge leap takes since nature computer-generated patterns look or behave similarly natural man-made things around us\u2014a snow flake, turbulent flow, lung, mollusk shell, traffic jam, outbreak starfish coral reef, entire universe\u2014therefore must way works. Nature runs its course same computer program. That essence science: yield secrets universe, solve our long-standing problems, provide theory everything. More flight fancy later. Deluge: was widely anticipated before actual publication. Published May 14, 2002, quickly became Amazon.com bestseller promptly reviewed scientific press. Heavyweights former included York Times, Chicago Tribune, Newsweek, Time, Daily Telegraph, Le Monde, Frankfurter Allgemeine Zeitung, Economist. Except last, press went gaga over touting author's claim stand existing head. Economist (p 79, June 1, 2002) more subdued even provocatively titling review \"The Emperor's Theory.\" press, reviews were somewhat less glorious skeptical. Physics Today 55, July 2002), Leo Kadanoff's once pointed, subtle polite, concluding he cannot support view any \"new kind science\" displayed Wolfram's book. Newsweek 59, 27, quoted famed physicist Freeman Dyson: \"There's tradition approaching senility come up with grand, improbable theories. unusual he's doing 40s.\" Kadanoff Dyson express minority opinion, however, majority reviewers being excited reason every human mystery currently depressed stock market, free will, quantum field theory, entropy. For present reviewer, lurks high particularly so months behind who already anointed Isaac Newton 21st century. Relevance: As aims replacing readers Applied Mechanics Reviews stake matter. Mechanics\u2014classical most part occasionally quantum\u2014is underlying branch upon which almost applied mechanics based. mathematics here often form partial differential equations, where space time are indefinitely divisible continuum. example, most, all, fluid flows described well-known, well-posed Navier\u2013Stokes equations. those first-principles equations solved agreement experiment reproach. It problem, such frustrated scores him. search simpler alternative is, therefore, quite alluring. mechanics, when they solved, powerful predictive tool explain mechanical world us well help design machines. When analytical solutions unattainable, discretized brute numerical integration used. But possible some situations, example realistic high-Reynolds-number other multi-scale problems required computational memory speed overwhelm today's supercomputers. impenetrable certain degree empiricism introduced relatively faster computations then proceed. Heuristic turbulence modeling compromise. Despite limitations, traditional works exceedingly well, mechanicians happily practice their craft. Readers should, care passionately if laws supplanted science. Argument: Cellular late 1940s John von Neumann Stanislaw Ulam, although claims independently discovered three decades discrete dynamical systems whose behavior completely specified terms repetitive local relation. continuum represented uniform one-, two-, three-dimensional grid, each cell containing single bit data, 0 red, white, blue, etc, bits states. advances steps. state cell, location, computed step algorithm priori defined close neighbors. Simple programs could, fact, result researched one-dimensional arranged line. data updated based value two nearest cells. methodically studied identified total 256 different rules. Space\u2013time diagrams generated show four distinct patterns: dull uniformity; periodic time-dependence; fractal behavior; truly non-repetitive says broken than 300 fix \"errors\" Darwin, Newton, great ones corrected all. proposes radical notion development world, uncover fundamental universe. pattern-generating capabilities supplant difficult-to-solve yet-to-be-found just because resemble does mean work way. Furthermore, believed represent reality used make predictions agree observations. This Galileo's paradigm underpinning modern explanatory power authority stem ability verifiable predictions; otherwise mere post-hoc speculation. exactly what is. games speculation possibly compete horsepower F=ma E=mc2.Wolfram's boasting, throughout 1200 pages, minimum excessive. He writes, \"I vastly I ever thought possible, fact now touches area besides.\" writes ideas originating him, credits belong elsewhere. Alan Turing conceptualized simplest universal computer, machine. Thinking universe vast digital brainchild Edward Fredkin. use machine environment physical detailed Tommaso Toffoli Norman Margolus. Other Per Bak, Charles Bennett, Hans Meinhardt percolate properly credited. Writing person, relegating notes 350 pages grudgingly dismissively mentioning names, restricting list references own publications, dispel important shortcoming. took approach bypassing peer process. self-published acting author, editor, publisher. opening paragraph mostly favorable Time's (May 20, worth reflecting on: \"Cranks occupational hazard scientist eventually faces. Fortunately, these characters usually easy spot. If someone grand overturns centuries knowledge\u2014especially spans unrelated fields biology economics\u2014the odds good she crank. publishes standard journals general readers, watch out. And issued rather conventional publisher, case pretty much airtight.\" extravagant cold fusion\u2014a` la Stanley Pons Martin Fleischman\u2014and deserve proportionally vigilant scrutiny. validated nor subjected process rest mortals expected do. contrast old anti-Newtonian model predict anything. emperor no clothes. offense play brick build edifice call Bottom Line: fun reading pictures, bad recommendation. inspiration, read Newton's Principia Mathematica, Latin. solving Newtonian framework still best bet, one's better books mechanics."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "The structure of musical harmony as an ordered phase of sound: A statistical mechanics approach to music theory"
    ],
    "c_abstract":[
      "Music, while allowing nearly unlimited creative expression, almost always conforms to a set of rigid rules at fundamental level. The description and study these rules, the ordered structures that arise from them, is basis field music theory. Here, I present theoretical formalism aims explain why basic patterns emerge in music, using same statistical mechanics framework describes emergent order across phase transitions physical systems. first apply mean approximation demonstrate occur this model disordered sound discrete sets pitches, including 12-fold octave division used Western music. Beyond model, use numerical simulation uncover musical harmony. These results provide new lens through which view discover ideas explore."
    ],
    "c_categories":[
      [
        "cs.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06414",
    "date":null,
    "a_title":"Psycho Gundam: Electroencephalography based real-time robotic control\n  system with deep learning",
    "a_abstract":"The Psycho Frame, a sophisticated system primarily used in Universal Century\n(U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral\ncomponent in harnessing the latent potential of mental energy. Its ability to\namplify and resonate with the pilot's psyche enables real-time mental control,\ncreating unique applications such as psychomagnetic fields and sensory-based\nweaponry. This paper presents the development of a novel robotic control system\ninspired by the Psycho Frame, combining electroencephalography (EEG) and deep\nlearning for real-time control of robotic systems. By capturing and\ninterpreting brainwave data through EEG, the system extends human cognitive\ncommands to robotic actions, reflecting the seamless synchronization of thought\nand machine, much like the Psyco Frame's integration with a Newtype pilot's\nmental faculties. This research demonstrates how modern AI techniques can\nexpand the limits of human-machine interaction, potentially transcending\ntraditional input methods and enabling a deeper, more intuitive control of\ncomplex robotic systems.",
    "explanation":"This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalograhy and deep learning for real-time control of robotic systems.",
    "b_id":[
      "b1",
      "b9"
    ],
    "b_title":[
      "An EEG-based brain-computer interface for real-time multi-task robotic control",
      "QEEGNet: Quantum Machine Learning for Enhanced Electroencephalography\n  Encoding"
    ],
    "b_abstract":[
      "The Brain Computer Interface (BCI) is the communication between human brain and computer. Electroencephalogram (EEG) one of biomedical signals which can be obtained by attaching electrodes to scalp. Some EEG related applications developed help disabled people, such as based wheelchair or robotic arm. A hybrid BCI real-time control system proposed a multi-tasks robot. In this system, sliding window online data segmentation strategy segment training data, enable learn dynamic features when subject's state transfer from rest task execution state. achieve ensure continuity executing actions. addition, Common Spatial Pattern (CSP) better extract spatial these continuous actions that multiple commands are accurately classified. experiment, three subjects' collected, trained tested performance reliability system. records robot's spending time, moving distance, number objects pushing down. Experimental results given show feasibility Compared remote controller, similar performance. Thus, able robot in environment used develop robot-aided arm methods on neurological rehabilitation principles for stroke injury patients.",
      "Electroencephalography (EEG) is a critical tool in neuroscience and clinical practice for monitoring analyzing brain activity. Traditional neural network models, such as EEGNet, have achieved considerable success decoding EEG signals but often struggle with the complexity high dimensionality of data. Recent advances quantum computing present new opportunities to enhance machine learning models through (QML) techniques. In this paper, we introduce Quantum-EEGNet (QEEGNet), novel hybrid that integrates classical EEGNet architecture improve encoding analysis, forward-looking approach, acknowledging results might not always surpass traditional methods it shows its potential. QEEGNet incorporates layers within network, allowing capture more intricate patterns data potentially offering computational advantages. We evaluate on benchmark dataset, BCI Competition IV 2a, demonstrating consistently outperforms most subjects other robustness noise. Our highlight significant potential quantum-enhanced networks suggesting directions both research practical applications field."
    ],
    "b_categories":[
      [
        "cs.RO",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Braincomputer interfaces for communication and control"
    ],
    "c_abstract":[
      "For many years people have speculated that electroencephalographic activity or other electrophysiological measures of brain function might provide a new non-muscular channel for sending messages and commands to the external world \u2013 a brain\u2013computer interface (BCI). Over the past 15 years, productive BCI research programs have arisen. Encouraged by new understanding of brain function, by the advent of powerful low-cost computer equipment, and by growing recognition of the needs and potentials of people with disabilities, these programs concentrate on developing new augmentative communication and control technology for those with severe neuromuscular disorders, such as amyotrophic lateral sclerosis, brainstem stroke, and spinal cord injury. The immediate goal is to provide these users, who may be completely paralyzed, or \u2018locked in\u2019, with basic communication capabilities so that they can express their wishes to caregivers or even operate word processing programs or neuroprostheses. Present-day BCIs determine the intent of the user from a variety of different electrophysiological signals. These signals include slow cortical potentials, P300 potentials, and mu or beta rhythms recorded from the scalp, and cortical neuronal activity recorded by implanted electrodes. They are translated in real-time into commands that operate a computer display or other device. Successful operation requires that the user encode commands in these signals and that the BCI derive the commands from the signals. Thus, the user and the BCI system need to adapt to each other both initially and continually so as to ensure stable performance. Current BCIs have maximum information transfer rates up to 10\u201325 bits\/min. This limited capacity can be valuable for people whose severe disabilities prevent them from using conventional augmentative communication methods. At the same time, many possible applications of BCI technology, such as neuroprosthesis control, may require higher information transfer rates. Future progress will depend on: recognition that BCI research and development is an interdisciplinary problem, involving neurobiology, psychology, engineering, mathematics, and computer science; identification of those signals, whether evoked potentials, spontaneous rhythms, or neuronal firing rates, that users are best able to control independent of activity in conventional motor output pathways; development of training methods for helping users to gain and maintain that control; delineation of the best algorithms for translating these signals into device commands; attention to the identification and elimination of artifacts such as electromyographic and electro-oculographic activity; adoption of precise and objective procedures for evaluating BCI performance; recognition of the need for long-term as well as short-term assessment of BCI performance; identification of appropriate BCI applications and appropriate matching of applications and users; and attention to factors that affect user acceptance of augmentative technology, including ease of use, cosmesis, and provision of those communication and control capacities that are most important to the user. Development of BCI technology will also benefit from greater emphasis on peer-reviewed research publications and avoidance of the hyperbolic and often misleading media attention that tends to generate unrealistic expectations in the public and skepticism in other researchers. With adequate recognition and effective engagement of all these issues, BCI systems could eventually provide an important new communication and control option for those with motor disabilities and might also give those without disabilities a supplementary control channel or a control channel useful in special circumstances."
    ],
    "c_categories":[
      [
        "Neurophysiology"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07453",
    "date":null,
    "a_title":"Research on fault diagnosis of nuclear power first-second circuit based\n  on hierarchical multi-granularity classification network",
    "a_abstract":"The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "explanation":"The existing fault diagnosis methods of power plants mainly target a single device or subsystem, making it difficult to analyze the inherent connections and mutual effects between different types of faults at the entire unit level. The use of EfficientNet for classify faults in different circuits through a simulator.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Review of Research on Condition Assessment of Nuclear Power Plant Equipment Based on Data-Driven"
    ],
    "b_abstract":[
      "The condition assessment of the entire life cycle of nuclear power equipment has a significant impact on improving the safety and economy of nuclear power plants. In the past, operation and maintenance of systems, equipment, and structures of domestic nuclear power plants, mostly relied on the alarm mechanism of equipments, the simple threshold judgments of parameters, or the empirical judgments of engineers. With the implementation of online monitoring system in nuclear power plants, a large number of equipment operation data have been accumulated, and the use of data-driven technology to assess the health of equipment has become the focus of attention in the industry. In this paper, the current situation of the online monitoring system of nuclear power equipment was introduced and the common malfunction of nuclear power equipment was analyzed. The condition assessment of nuclear power equipment were categorized into three major problems (i.e., anomaly detection, life prediction, and fault diagnosis), the situation of research and application were summarized respectively, and the application potential of deep learning technology in this field was emphasized. Based on this, the challenges and possible solutions to the condition assessment of nuclear power plant equipment were further analyzed."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth\/width\/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. \nTo go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 \/ 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04775",
    "date":null,
    "a_title":"Learning dynamical systems from data: Gradient-based dictionary\n  optimization",
    "a_abstract":"The Koopman operator plays a crucial role in analyzing the global behavior of\ndynamical systems. Existing data-driven methods for approximating the Koopman\noperator or discovering the governing equations of the underlying system\ntypically require a fixed set of basis functions, also called dictionary. The\noptimal choice of basis functions is highly problem-dependent and often\nrequires domain knowledge. We present a novel gradient descent-based\noptimization framework for learning suitable and interpretable basis functions\nfrom data and show how it can be used in combination with EDMD, SINDy, and\nPDE-FIND. We illustrate the efficacy of the proposed approach with the aid of\nvarious benchmark problems such as the Ornstein-Uhlenbeck process, Chua's\ncircuit, a nonlinear heat equation, as well as protein-folding data.",
    "explanation":"The optimal choice of basis functions for approximation the Koopman operator is highly problem-dependent and often requires domain knowledge. The paper presents a gradient descent-based optimization framework for learning suitable and interpretable basis function from data.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "A Data\u2013Driven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition"
    ],
    "b_abstract":[
      "The Koopman operator is a linear but infinite dimensional operator that\ngoverns the evolution of scalar observables defined on the state space of an\nautonomous dynamical system, and is a powerful tool for the analysis and\ndecomposition of nonlinear dynamical systems. In this manuscript, we present a\ndata driven method for approximating the leading eigenvalues, eigenfunctions,\nand modes of the Koopman operator. The method requires a data set of snapshot\npairs and a dictionary of scalar observables, but does not require explicit\ngoverning equations or interaction with a \"black box\" integrator. We will show\nthat this approach is, in effect, an extension of Dynamic Mode Decomposition\n(DMD), which has been used to approximate the Koopman eigenvalues and modes.\nFurthermore, if the data provided to the method are generated by a Markov\nprocess instead of a deterministic dynamical system, the algorithm approximates\nthe eigenfunctions of the Kolmogorov backward equation, which could be\nconsidered as the \"stochastic Koopman operator\" [1]. Finally, four illustrative\nexamples are presented: two that highlight the quantitative performance of the\nmethod when presented with either deterministic or stochastic data, and two\nthat show potential applications of the Koopman eigenfunctions."
    ],
    "b_categories":[
      [
        "Mathematical Analysis"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b21",
      "b14"
    ],
    "c_title":[
      "Towards Scalable Koopman Operator Learning: Convergence Rates and A Distributed Learning Algorithm",
      "VAMPnets for deep learning of molecular kinetics"
    ],
    "c_abstract":[
      "We propose an alternating optimization algorithm to the nonconvex Koopman operator learning problem for nonlinear dynamic systems. show that proposed will converge a critical point with rate O(1\/T) and $O\\left( {\\frac{1}{{\\log T}}} \\right)$ constant diminishing rates, respectively, under some mild conditions. To cope high dimensional dynamical systems, we present first-ever distributed algorithm. has same convergence properties as centralized learning, in absence of optimal tracker, so long basis functions satisfy set state-based decomposition Numerical experiments are provided complement our theoretical results.",
      "Abstract There is an increasing demand for computing the relevant structures, equilibria, and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation simulated coordinates into structural features, dimension reduction, clustering dimension-reduced data, estimation a Markov state model or related interconversion rates between structures. This handcrafted approach demands substantial amount modeling expertise, poor decisions at any step will lead to large errors. Here we variational processes (VAMP) develop deep learning framework using neural networks, dubbed VAMPnets. A VAMPnet encodes entire mapping states, thus combining whole data processing pipeline in single end-to-end framework. Our method performs equally better than state-of-the-art provides easily interpretable few-state kinetic models."
    ],
    "c_categories":[
      [
        "eess.SP",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17971",
    "date":null,
    "a_title":"Graph Neural Network for Cerebral Blood Flow Prediction With Clinical\n  Datasets",
    "a_abstract":"Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
    "explanation":"This paper proposes a graph neural network (GNN) to predict blood flow and pressure in previously unseen cerebral vascular network structures that were not included in training data.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Multiscale modeling and simulation of brain blood flow"
    ],
    "b_abstract":[
      "The aim of this work is to present an overview recent advances in multi-scale modeling brain blood flow. In particular, we some approaches that enable the silico study and multi-physics phenomena cerebral vasculature. We discuss formulation continuum atomistic approaches, a consistent framework for their concurrent coupling, list challenges one needs overcome achieving seamless scalable integration heterogeneous numerical solvers. effectiveness proposed demonstrated realistic case involving thrombus formation process taking place on wall patient-specific aneurysm. This highlights ability algorithms resolve important biophysical processes span several spatial temporal scales, potentially yielding new insight into key aspects flow health disease. Finally, open questions emerging topics future research."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Learning Reduced-Order Models for Cardiovascular Simulations with Graph Neural Networks"
    ],
    "c_abstract":[
      "Reduced-order models based on physics are a popular choice in cardiovascular modeling due to their efficiency, but they may experience loss in accuracy when working with anatomies that contain numerous junctions or pathological conditions. We develop one-dimensional reduced-order models that simulate blood flow dynamics using a graph neural network trained on three-dimensional hemodynamic simulation data. Given the initial condition of the system, the network iteratively predicts the pressure and flow rate at the vessel centerline nodes. Our numerical results demonstrate the accuracy and generalizability of our method in physiological geometries comprising a variety of anatomies and boundary conditions. Our findings demonstrate that our approach can achieve errors below 3% for pressure and flow rate, provided there is adequate training data. As a result, our method exhibits superior performance compared to physics-based one-dimensional models while maintaining high efficiency at inference time."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18141",
    "date":null,
    "a_title":"Predicting Water Quality using Quantum Machine Learning: The Case of the\n  Umgeni Catchment (U20A) Study Region",
    "a_abstract":"In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
    "explanation":"In this study, we consider a real-world application of QML techniques to study water quality in the U20A region in Durban, South Africa.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Quantum machine learning in chemistry and materials"
    ],
    "b_abstract":[
      "Within the past few years, we have witnessed the rising of quantum machine learning (QML) models which infer electronic properties of molecules and materials, rather than solving approximations to the electronic Schr\u00f6dinger equation. The increasing availability of large quantum mechanics reference datasets has enabled these developments. We review the basic theories and key ingredients of popular QML models such as choice of regressor, data of varying trustworthiness, the role of the representation, and the effect of training set selection. Throughout we emphasize the indispensable role of learning curves when it comes to the comparative assessment of different QML models."
    ],
    "b_categories":[
      [
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b26"
    ],
    "c_title":[
      "Durban's water wars, sewage spills, fish kills and blue flag beaches. Durban's Climate Gamble"
    ],
    "c_abstract":[
      "Water is one of the primary barometers of climate change: A rise in sea-levels, flooding, and extreme storms combined with general water stress and more severe and frequent droughts will escalate crises in municipal infrastructure, requiring continual upgrades for water purification, stormwater drainage, and sewage treatment, all of which will dramatically raise the price of water at the retail level. In South Africa, the dry western side will be most adversely affected by droughts (threatening the production of rooibos tea and Cape wines). According to the Academy of Science in South Africa (ASSAf), Durban is also at great risk and will experience higher temperatures and heat stress, volatile rainfall, up to 160 million cubic metres less water each year by 2100, a sea-level rise of up to a metre by 2100 across Durban\u2019s 100 km of developed coastline, lower biodiversity, higher disease levels (especially malaria and cholera), declining agricultural output (a one degree Celsius rise leaves the surrounding region unreliable for the staple maize production), and other economic stresses (ASSAf 2011: 27). Tourism, one of Durban\u2019s main economic engines, will be irreparably harmed. Swimmers and surfers think of Durban\u2019s beachfront as one of the world\u2019s finest in any urban context. After apartheid-era rules that prohibited black people from using the best beaches were lifted at the end of the 1980s, the area stretching from the Blue Lagoon\u2019s Umgeni River to South Beach\u2019s uShaka Marine World\u2013including the immensely popular North Beach area near the main restaurant strip\u2013represented one of South Africa\u2019s most impressive, open and democratic public spaces."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16349",
    "date":null,
    "a_title":"Machine learning for cerebral blood vessels' malformations",
    "a_abstract":"Cerebral aneurysms and arteriovenous malformations are life-threatening\nhemodynamic pathologies of the brain. While surgical intervention is often\nessential to prevent fatal outcomes, it carries significant risks both during\nthe procedure and in the postoperative period, making the management of these\nconditions highly challenging. Parameters of cerebral blood flow, routinely\nmonitored during medical interventions, could potentially be utilized in\nmachine learning-assisted protocols for risk assessment and therapeutic\nprognosis. To this end, we developed a linear oscillatory model of blood\nvelocity and pressure for clinical data acquired from neurosurgical operations.\nUsing the method of Sparse Identification of Nonlinear Dynamics (SINDy), the\nparameters of our model can be reconstructed online within milliseconds from a\nshort time series of the hemodynamic variables. The identified parameter values\nenable automated classification of the blood-flow pathologies by means of\nlogistic regression, achieving an accuracy of 73 %. Our results demonstrate the\npotential of this model for both diagnostic and prognostic applications,\nproviding a robust and interpretable framework for assessing cerebral blood\nvessel conditions.",
    "explanation":"Parameters of cerebral blood flow, routinely monitored during medical interventions or with modern noninvasive high-resolution imaging methods, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Cerebral aneurysms. New Engl. J. Medicine"
    ],
    "b_abstract":[
      "Saccular intracranial aneurysms cause substantial morbidity and mortality. Recently, major changes have occurred in the way we think about and treat this disease. This review discusses the percutaneous endovascular treatment of intracranial aneurysms as compared with surgical intervention. The technological advances and supporting research contributing to this important change in practice patterns are reviewed."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Data-driven science and engineering: machine learning, dynamical systems, and control"
    ],
    "c_abstract":[
      "\"Data-driven science and engineering: machine learning, dynamical systems, control.\" Contemporary Physics, 60(4), p. 320"
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19000",
    "date":null,
    "a_title":"A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by\n  Wearable Technologies and Artificial Intelligence",
    "a_abstract":"At-home rehabilitation for post-stroke patients presents significant\nchallenges, as continuous, personalized care is often limited outside clinical\nsettings. Additionally, the absence of comprehensive solutions addressing\ndiverse rehabilitation needs in home environments complicates recovery efforts.\nHere, we introduce a smart home platform that integrates wearable sensors,\nambient monitoring, and large language model (LLM)-powered assistance to\nprovide seamless health monitoring and intelligent support. The system\nleverages machine learning enabled plantar pressure arrays for motor recovery\nassessment (94% classification accuracy), a wearable eye-tracking module for\ncognitive evaluation, and ambient sensors for precise smart home control (100%\noperational success, <1 s latency). Additionally, the LLM-powered agent,\nAuto-Care, offers real-time interventions, such as health reminders and\nenvironmental adjustments, enhancing user satisfaction by 29%. This work\nestablishes a fully integrated platform for long-term, personalized\nrehabilitation, offering new possibilities for managing chronic conditions and\nsupporting aging populations.",
    "explanation":"Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Addressing disparities in the global epidemiology of stroke"
    ],
    "b_abstract":[
      "Stroke is the second leading cause of death and the third leading cause of disability worldwide. Though the burden of stroke worldwide seems to have declined in the past three decades, much of this effect reflects decreases in high-income countries (HICs). By contrast, the burden of stroke has grown rapidly in low-income and middle-income countries (LMICs), where epidemiological, socioeconomic and demographic shifts have increased the incidence of stroke and other non-communicable diseases. Furthermore, even in HICs, disparities in stroke epidemiology exist along racial, ethnic, socioeconomic and geographical lines. In this Review, we highlight the under-acknowledged disparities in the burden of stroke. We emphasize the shifting global landscape of stroke risk factors, critical gaps in stroke service delivery, and the need for a more granular analysis of the burden of stroke within and between LMICs and HICs to guide context-appropriate capacity-building. Finally, we review strategies for addressing key inequalities in stroke epidemiology, including improvements in epidemiological surveillance and context-specific research efforts in under-resourced regions, development of the global workforce of stroke care providers, expansion of access to preventive and treatment services through mobile and telehealth platforms, and scaling up of evidence-based strategies and policies that target local, national, regional and global stroke disparities."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Artificial intelligence applications in stroke"
    ],
    "c_abstract":[
      "Management of stroke highly depends on information from imaging studies. Noncontrast computed tomography (CT) and magnetic resonance imaging (MRI) can both be used to distinguish between ischemic and hemorrhagic stroke, which is difficult based on clinical features. Hypodensity on CT and DWI hyperintensity on MRI identifies irreversibly damaged tissue, although the sensitivity of MRI is higher in the acute setting. Angiographic and perfusion imaging sequences can identify a large vessel occlusion and, along with perfusion imaging, can select patients for endovascular therapy. The FLAIR-DWI mismatch yields information about patients with unknown time of onset (including wake-up strokes). Stroke imaging also gives insight into prognosis, with current methods aiming to give a picture of the short-term consequences of successful reperfusion or continued large vessel occlusion. One important caveat about stroke imaging is that it must be done quickly, as faster treatment leads to better outcomes.1 However, most steps in the stroke imaging triage pathway require the presence of human radiologists and neurologists, and this is often the time-limiting step. The expertise required for these tasks may not be available at all sites or at all times. Therefore, there is interest in automated methods for stroke imaging evaluation. Artificial intelligence (AI) is a broad term reflecting the use of computers to perform tasks that humans may find difficult, often in ways that are hard to pinpoint. For example, although humans find high-level computation difficult, calculator technology is not considered AI because we know how to break this down into discrete steps and feel we understand it. However, facial recognition is a task that humans perform well, but an algorithm to identify faces is usually considered AI since we cannot articulate precisely how this is done. Machine learning (ML) is a subset of AI in which algorithms learn from the data itself without explicit programming. ML methods reflect a broad range of statistical techniques ranging from linear regression to more complex methods such as support vector machines and decision trees. ML methods can be further broken into supervised and unsupervised learning, which differ from one another in that the former requires access to gold standard labels although the latter attempts to find the answers implicitly in the data itself. While ML methods have grown more popular over recent years, the advent of a specific supervised ML method based on architectures resembling human neural networks over the past decade has led to a quantum leap in performance.2 This method, called deep learning (DL) because of many multiple internal layers, can be considered a transformative technology. Compared with previous methods that required humans to identify image features, a deep neural network trained on a dataset with known outputs can learn the best features for organizing the data. In this review, we will discuss ML methods applied to stroke imaging with an emphasis on DL applications. We refer to Figure for a graphical overview of the applications discussed in this review."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10570",
    "date":null,
    "a_title":"Normative Modeling for AD Diagnosis and Biomarker Identification",
    "a_abstract":"In this paper, we introduce a novel normative modeling approach that\nincorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer's\nDisease (AD) diagnosis and biomarker identification. Our method is an\nend-to-end approach that embeds an adversarial focal loss discriminator within\nthe autoencoder structure, specifically designed to effectively target and\ncapture more complex and challenging cases. We first use the enhanced\nautoencoder to create a normative model based on data from healthy control (HC)\nindividuals. We then apply this model to estimate total and regional\nneuroanatomical deviation in AD patients. Through extensive experiments on the\nOASIS-3 and ADNI datasets, our approach significantly outperforms previous\nstate-of-the-art methods. This advancement not only streamlines the detection\nprocess but also provides a greater insight into the biomarker potential for\nAD. Our code can be found at \\url{https:\/\/github.com\/soz223\/FAAE}.",
    "explanation":"In this paper, we introduce a novel normative modeling ap proach that incorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer\u2019s Disease (AD) diagnosis and biomarker identification",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: A large\u2010scale multi\u2010sample study"
    ],
    "b_abstract":[
      "Machine learning is becoming an increasingly popular approach for investigating spatially distributed and subtle neuroanatomical alterations in brain\u2010based disorders. However, some machine learning models have been criticized for requiring a large number of cases in each experimental group, and for resembling a \u201cblack box\u201d that provides little or no insight into the nature of the data. In this article, we propose an alternative conceptual and practical approach for investigating brain\u2010based disorders which aim to overcome these limitations. We used an artificial neural network known as \u201cdeep autoencoder\u201d to create a normative model using structural magnetic resonance imaging data from 1,113 healthy people. We then used this model to estimate total and regional neuroanatomical deviation in individual patients with schizophrenia and autism spectrum disorder using two independent data sets (n =\u2009263). We report that the model was able to generate different values of total neuroanatomical deviation for each disease under investigation relative to their control group (p <\u2009.005). Furthermore, the model revealed distinct patterns of neuroanatomical deviations for the two diseases, consistent with the existing neuroimaging literature. We conclude that the deep autoencoder provides a flexible and promising framework for assessing total and regional neuroanatomical deviations in neuropsychiatric populations."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer\u2019s disease in a cross-sectional multi-cohort study"
    ],
    "c_abstract":[
      "Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer\u2019s disease (n\u2009=\u2009206) and mild cognitive impairment (n\u2009=\u2009354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14474",
    "date":null,
    "a_title":"Attention-guided Spectrogram Sequence Modeling with CNNs for Music Genre\n  Classification",
    "a_abstract":"Music genre classification is a critical component of music recommendation\nsystems, generation algorithms, and cultural analytics. In this work, we\npresent an innovative model for classifying music genres using attention-based\ntemporal signature modeling. By processing spectrogram sequences through\nConvolutional Neural Networks (CNNs) and multi-head attention layers, our\napproach captures the most temporally significant moments within each piece,\ncrafting a unique \"signature\" for genre identification. This temporal focus not\nonly enhances classification accuracy but also reveals insights into\ngenre-specific characteristics that can be intuitively mapped to listener\nperceptions. Our findings offer potential applications in personalized music\nrecommendation systems by highlighting cross-genre similarities and\ndistinctiveness, aligning closely with human musical intuition. This work\nbridges the gap between technical classification tasks and the nuanced, human\nexperience of genre.",
    "explanation":"In this work, we present an innovative model for classifying music genres using attention based temporal signature modeling. By processing spectrogram sequences through Convolutional Neural Networks (CNNs) and multi-head attention layers, our approach captures the most temporally significant moments within each piece, crafting a unique \u201dsignature\u201d for genre identification",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Convolutional recurrent neural networks for music classification"
    ],
    "b_abstract":[
      "We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of networks (CNNs) local feature extraction and temporal summarisation the extracted features. compare CRNN with three CNN structures that have been used tagging while controlling number parameters respect to their performance training time per sample. Overall, we found show strong parameter time, indicating effectiveness its hybrid structure in summarisation."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A deep representation for invariance and music classification"
    ],
    "c_abstract":[
      "Representations in the auditory cortex might be based on mechanisms similar to visual ventral stream; modules for building invariance transformations and multiple layers compositionality selectivity. In this paper we propose use of such computational extracting invariant discriminative audio representations. Building a theory hierarchical architectures, novel, mid-level representation acoustical signals, using empirical distributions projections set templates their transformations. Under assumption that, by construction, dictionary is composed from classes, samples orbit variance-inducing signal (such as shift scale), resulting signature theoretically guaranteed unique, stable deformations. Modules projection pooling can then constitute deep networks, learning composite We present main theoretical aspects framework unsupervised representations, empirically evaluated music genre classification."
    ],
    "c_categories":[
      [
        "physics.class-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14975",
    "date":null,
    "a_title":"Exploring Foundation Models Fine-Tuning for Cytology Classification",
    "a_abstract":"Cytology slides are essential tools in diagnosing and staging cancer, but\ntheir analysis is time-consuming and costly. Foundation models have shown great\npotential to assist in these tasks. In this paper, we explore how existing\nfoundation models can be applied to cytological classification. More\nparticularly, we focus on low-rank adaptation, a parameter-efficient\nfine-tuning method suited to few-shot learning. We evaluated five foundation\nmodels across four cytological classification datasets. Our results demonstrate\nthat fine-tuning the pre-trained backbones with LoRA significantly improves\nmodel performance compared to fine-tuning only the classifier head, achieving\nstate-of-the-art results on both simple and complex classification tasks while\nrequiring fewer data samples.",
    "explanation":"In this paper, we explore how existing foundation models can be applied to cytological classification",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "HiCervix: An Extensive Hierarchical Dataset and Benchmark for Cervical Cytology Classification"
    ],
    "b_abstract":[
      "Cervical cytology is a critical screening strategy for early detection of pre-cancerous and cancerous cervical lesions. The challenge lies in accurately classifying various cell types. Existing automated methods are primarily trained on databases covering narrow range coarse-grained types, which fail to provide comprehensive detailed performance analysis that represents real-world cytopathology conditions. To overcome these limitations, we introduce HiCervix, the most extensive, multi-center dataset currently available public. HiCervix includes 40,229 cells from 4,496 whole slide images, categorized into 29 annotated classes. These classes organized within three-level hierarchical tree capture fine-grained subtype information. exploit semantic correlation inherent this tree, propose HierSwin, vision transformer-based classification network. HierSwin serves as benchmark feature learning both coarse-level fine-level cancer tasks. In our experiments, demonstrated remarkable performance, achieving 92.08% accuracy 82.93% averaged across all three levels. When compared board-certified cytopathologists, achieved high (0.8293 versus 0.7359 accuracy), highlighting its potential clinical applications. This newly released dataset, along with method, poised make substantial impact advancement deep algorithms rapid greatly improve prevention patient outcomes settings."
    ],
    "b_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "LoRA: Low-Rank Adaptation of Large Language Models"
    ],
    "c_abstract":[
      "An important paradigm of natural language processing consists large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances fine-tuned each with is prohibitively expensive. We propose Low-Rank Adaptation, LoRA, freezes the pre-trained weights injects trainable rank decomposition matrices into layer Transformer architecture, greatly reducing number parameters for downstream tasks. Compared Adam, LoRA can reduce by 10,000 times GPU memory requirement 3 times. performs on-par better than fine-tuning in quality RoBERTa, DeBERTa, GPT-2, GPT-3, despite having fewer a higher training throughput, and, unlike adapters, no additional inference latency. also provide empirical investigation rank-deficiency adaptation, sheds light efficacy LoRA. release package that facilitates integration PyTorch models our implementations checkpoints GPT-2 at https:\/\/github.com\/microsoft\/LoRA."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15331",
    "date":null,
    "a_title":"GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural\n  Network Model for Ames Mutagenicity Prediction",
    "a_abstract":"This paper tackles the pressing challenge of mutagenicity prediction by\nintroducing three ground-breaking approaches. First, it showcases the superior\nperformance of 2D scattering coefficients extracted from molecular images,\ncompared to traditional molecular descriptors. Second, it presents a hybrid\napproach that combines geometric graph scattering (GGS), Graph Isomorphism\nNetworks (GIN), and machine learning models, achieving strong results in\nmutagenicity prediction. Third, it introduces a novel graph neural network\narchitecture, MOLG3-SAGE, which integrates GGS node features into a fully\nconnected graph structure, delivering outstanding predictive accuracy.\nExperimental results on the ZINC dataset demonstrate significant improvements,\nemphasizing the effectiveness of blending 2D and geometric scattering\ntechniques with graph neural networks. This study illustrates the potential of\nGNNs and GGS for mutagenicity prediction, with broad implications for drug\ndiscovery and chemical safety assessment.",
    "explanation":"This study illustrates the potential of GNNs and GGS for mutagenicity prediction, with broad implications for drug discovery and chemical safety assessment",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Improvement of quantitative structure\u2013activity relationship (QSAR) tools for predicting Ames mutagenicity: outcomes of the Ames\/QSAR International Challenge Project"
    ],
    "b_abstract":[
      "The International Conference on Harmonization (ICH) M7 guideline allows the use of in silico approaches for predicting Ames mutagenicity initial assessment impurities pharmaceuticals. This is first international that addresses quantitative structure\u2013activity relationship (QSAR) models lieu actual toxicological studies human health assessment. Therefore, QSAR now require higher predictive power identifying mutagenic chemicals. To increase models, larger experimental datasets from reliable sources are required. Division Genetics and Mutagenesis, National Institute Health Sciences (DGM\/NIHS) Japan recently established a unique proprietary database containing 12140 new chemicals have not been previously used developing models. DGM\/NIHS provided this to vendors validate improve their tools. Ames\/QSAR Challenge Project was initiated 2014 with 12 testing 17 tools against these compounds three phases. We present final results. All were considerably improved by participation project. Most achieved >50% sensitivity (positive prediction among all positives) (accuracy) as high 80%, almost equivalent inter-laboratory reproducibility tests. further tools, accumulation additional test data required well re-evaluation some previous Indeed, Ames-positive or Ames-negative may incorrectly classified because methodological weakness, resulting false-positive false-negative predictions These incorrect hamper source noise development It thus essential establish large benchmark consisting only well-validated results build more accurate"
    ],
    "b_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Mutagenpred-gcnns: a graph convolutional neural network-based classification model for mutagenicity prediction with data-driven molecular fingerprints"
    ],
    "c_abstract":[
      "An important task in the early stage of drug discovery is the identification of mutagenic compounds. Mutagenicity prediction models that can interpret relationships between toxicological endpoints and compound structures are especially favorable. In this research, we used an advanced graph convolutional neural network (GCNN) architecture to identify the molecular representation and develop predictive models based on these representations. The predictive model based on features extracted by GCNNs can not only predict the mutagenicity of compounds but also identify the structure alerts in compounds. In fivefold cross-validation and external validation, the highest area under the curve was 0.8782 and 0.8382, respectively; the highest accuracy (Q) was 80.98% and 76.63%, respectively; the highest sensitivity was 83.27% and 78.92%, respectively; and the highest specificity was 78.83% and 76.32%, respectively. Additionally, our model also identified some toxicophores, such as aromatic nitro, three-membered heterocycles, quinones, and nitrogen and sulfur mustard. These results indicate that GCNNs could learn the features of mutagens effectively. In summary, we developed a mutagenicity classification model with high predictive performance and interpretability based on a data-driven molecular representation trained through GCNNs."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03341",
    "date":null,
    "a_title":"Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in\n  Multiplex Imaging",
    "a_abstract":"Multiplex Imaging (MI) enables the simultaneous visualization of multiple\nbiological markers in separate imaging channels at subcellular resolution,\nproviding valuable insights into cell-type heterogeneity and spatial\norganization. However, current computational pipelines rely on cell\nsegmentation algorithms, which require laborious fine-tuning and can introduce\ndownstream errors due to inaccurate single-cell representations. We propose a\nsegmentation-free deep learning approach that leverages grouped convolutions to\nlearn interpretable embedded features from each imaging channel, enabling\nrobust cell-type identification without manual feature selection. Validated on\nan Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma\npatients, our method enables the accurate identification of known cell types,\nshowcasing its scalability and suitability for high-dimensional MI data.",
    "explanation":"Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Highly multiplexed imaging of tumor tissues with subcellular resolution by mass cytometry"
    ],
    "b_abstract":[
      "Mass cytometry enables high-dimensional, single-cell analysis of cell type and state. In mass cytometry, rare earth metals are used as reporters on antibodies. Analysis of metal abundances using the mass cytometer allows determination of marker expression in individual cells. Mass cytometry has previously been applied only to cell suspensions. To gain spatial information, we have coupled immunohistochemical and immunocytochemical methods with high-resolution laser ablation to CyTOF mass cytometry. This approach enables the simultaneous imaging of 32 proteins and protein modifications at subcellular resolution; with the availability of additional isotopes, measurement of over 100 markers will be possible. We applied imaging mass cytometry to human breast cancer samples, allowing delineation of cell subpopulations and cell-cell interactions and highlighting tumor heterogeneity. Imaging mass cytometry complements existing imaging approaches. It will enable basic studies of tissue heterogeneity and function and support the transition of medicine toward individualized molecularly targeted diagnosis and therapies."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "A ConvNet for the 2020s"
    ],
    "c_abstract":[
      "The \"Roaring 20s\" of visual recognition began with the introduction Vision Transformers (ViTs), which quickly superseded ConvNets as state-of-the-art image classification model. A vanilla ViT, on other hand, faces difficulties when applied to general computer vision tasks such object detection and semantic segmentation. It is hierarchical (e.g., Swin Transformers) that reintroduced several ConvNet priors, making practically viable a generic backbone demonstrating remarkable performance wide variety tasks. However, effectiveness hybrid approaches still largely credited intrinsic superiority Transformers, rather than inherent inductive biases convolutions. In this work, we reexamine design spaces test limits what pure can achieve. We gradually \"modernize\" standard ResNet toward Transformer, discover key components contribute difference along way. outcome exploration family models dubbed ConvNeXt. Constructed entirely from modules, ConvNeXts compete favorably in terms accuracy scalability, achieving 87.8% ImageNet top-1 outperforming COCO ADE20K segmentation, while maintaining simplicity efficiency ConvNets."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.11399",
    "date":null,
    "a_title":"Quantization of Climate Change Impacts on Renewable Energy Generation\n  Capacity: A Super-Resolution Recurrent Diffusion Model",
    "a_abstract":"Driven by global climate change and the ongoing energy transition, the\ncoupling between power supply capabilities and meteorological factors has\nbecome increasingly significant. Over the long term, accurately quantifying the\npower generation capacity of renewable energy under the influence of climate\nchange is essential for the development of sustainable power systems. However,\ndue to interdisciplinary differences in data requirements, climate data often\nlacks the necessary hourly resolution to capture the short-term variability and\nuncertainties of renewable energy resources. To address this limitation, a\nsuper-resolution recurrent diffusion model (SRDM) has been developed to enhance\nthe temporal resolution of climate data and model the short-term uncertainty.\nThe SRDM incorporates a pre-trained decoder and a denoising network, that\ngenerates long-term, high-resolution climate data through a recurrent coupling\nmechanism. The high-resolution climate data is then converted into power value\nusing the mechanism model, enabling the simulation of wind and photovoltaic\n(PV) power generation capacity on future long-term scales. Case studies were\nconducted in the Ejina region of Inner Mongolia, China, using fifth-generation\nreanalysis (ERA5) and coupled model intercomparison project (CMIP6) data under\ntwo climate pathways: SSP126 and SSP585. The results demonstrate that the SRDM\noutperforms existing generative models in generating super-resolution climate\ndata. For the Ejina region, under a high-emission pathway, the annual\nutilization hours of wind power are projected to decrease by 2.82 hours\/year,\nwhile those for PV power are projected to decrease by 0.26 hours\/year.\nFurthermore, the research highlights the estimation biases introduced when\nlow-resolution climate data is used for power conversion.",
    "explanation":"CLimate data often lacks the necessary hourly resolution to capture the shot-term variability and uncertainties of renewable energy resources. TO address this limitation, a super-resolution recurrent diffusiion model (SRDM) has been developed toenhance the temporal resolution of climate data and model the short-term uncertainty.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Forecasting the inevitable: A review on the impacts of climate change on renewable energy resources"
    ],
    "b_abstract":[
      "Understanding the relationship and quantifying impacts of climate change on energy production is key to meeting our objectives achieving a sustainable future. Here we review current state art methodologies forecast future climate, potential changes in renewable main findings regarding role renewables decarbonisation supply. Most studies used model power equations estimate output. The largest variation estimated was for long-term scenarios, with non-significant variations reported short-term. highest variability found wind followed by hydro, both long-term, overall low solar any period. Additionally, efforts point investments as one pillars reducing fossil fuel dependency. Current knowledge gaps about uncertainty modelling results combined effects resources. Future should focus increasing resolution models improving input data, well assess entire electricity system not concentrate single source, which will aid defining strategies."
    ],
    "b_categories":[
      [
        "Physical Geography"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "High-Resolution Image Synthesis with Latent Diffusion Models"
    ],
    "c_abstract":[
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on data and beyond. Additionally, their formulation allows for guiding mechanism to control generation without retraining. However, since these typically operate directly in pixel space, optimization powerful DMs often consumes hundreds GPU days inference is expensive due evaluations. To enable DM training limited computational resources while retaining quality flexibility, we apply them latent space pretrained autoencoders. In contrast previous work, such representation first time reach near-optimal point between complexity reduction detail preservation, greatly boosting visual fidelity. introducing cross-attention layers model architecture, turn flexible generators general conditioning inputs as text or bounding boxes high-resolution becomes possible convolutional manner. Our (LDMs) new state art scores inpainting class-conditional highly competitive performance various tasks, including unconditional generation, text-to-image synthesis, super-resolution, significantly reducing requirements compared pixel-based DMs."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.18649",
    "date":null,
    "a_title":"FITS: Ensuring Safe and Effective Touchscreen Use in Moving Vehicles",
    "a_abstract":"Touch interfaces are replacing physical buttons, dials, and switches in the\nnew generation of cars, aircraft, and vessels. However, vehicle vibrations and\naccelerations perturb finger movements and cause erroneous touchscreen inputs\nby users. Furthermore, unlike physical buttons, touchscreens cannot be operated\nby touch alone and always require users' visual focus. Hence, despite their\nnumerous benefits, touchscreens are not inherently suited for use in vehicles,\nwhich results in an increased risk of accidents. In a recently awarded research\nproject titled \"Right Touch Right Time: Future In-vehicle Touchscreens (FITS)\",\nwe aim to address these problems by developing novel in-vehicle touchscreens\nthat actively predict and correct perturbed finger movements and simulate\nphysical touch interactions with artificial tactile feedback.",
    "explanation":"The paper address the tactile feedback problems by developing novel in-vehicle touchscreens that actively predict and correct perturbed finger movements and simulate physical touch interactions with artificial tactile feedback.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A Review of Surface Haptics: Enabling Tactile Effects on Touch Surfaces"
    ],
    "b_abstract":[
      "In this article, we review the current technology underlying surface haptics that converts passive touch surfaces to active ones (machine haptics), our perception of tactile stimuli displayed through (human their potential applications (human-machine interaction), and finally, challenges ahead us in making them available commercial systems. This article primarily covers interactions human fingers or hands with surface-haptics displays by focusing on three most popular actuation methods: vibrotactile, electrostatic, ultrasonic."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Biophysical properties of the human finger for touch comprehension: influences of ageing and gender"
    ],
    "c_abstract":[
      "The human finger plays an extremely important role in tactile perception, but little is known about how age and gender affect its biophysical properties their perception. We combined studies on contact characteristics, mechanical surface topography to understand effects the finger. values obtained regarding characteristics (i.e. adhesive force) were significantly higher for women than men. As Young's modulus E), a significant positive correlation with was observed found be women. A between arithmetic mean of roughness However, inverse effect highlighted have never been reported previously literature. These results open new perspectives understanding weakening perception across ages it differs men"
    ],
    "c_categories":[
      [
        "Biodynamic"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06560",
    "date":null,
    "a_title":"ElectricityEmissions.jl: A Framework for the Comparison of Carbon\n  Intensity Signals",
    "a_abstract":"An increasing number of individuals, companies and organizations are\ninterested in computing and minimizing the carbon emissions associated with\ntheir real-time electricity consumption. To achieve this, they require a carbon\nsignal, i.e. a metric that defines the real-time carbon intensity of their\nelectricity supply. Unfortunately, in a grid with multiple generation sources\nand multiple consumers, there is no unambiguous way to trace electricity from\nsource to sink. This makes it hard to define an appropriate signal, leading to\na raging discussion about how to best quantify the carbon footprint of\nelectricity.\n  This paper seeks to inform the discussion about which carbon signal is better\nor more suitable for two important use cases, namely carbon-informed load\nshifting and carbon accounting. We do this by developing a new software package\nElectricityEmissions$.$jl, that computes several established and newly proposed\ncarbon emission metrics for standard electric grid test cases. We also\ndemonstrate how the package can be used to investigate the effects of using\nthese metrics to guide load shifting. Our results affirm previous research,\nwhich showed that the choice of carbon emission metric has significant impact\non shifting results and associated carbon emission reductions. In addition, we\ndemonstrate the impact of load shifting on both the consumers that perform the\nshifting and consumers that do not. Disconcertingly, we observe that shifting\naccording to common metrics such as average carbon emissions can reduce the\namount of emissions allocated to data center, but cause an increase in the\ntotal emissions of the system.",
    "explanation":"The paper proposes a software package that computes several established and newly proposed carbon emission metrics for standard electric grid test cases.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Tracing Power With Circuit Theory"
    ],
    "b_abstract":[
      "Power tracing is the task of disaggregating power injection a generator (or load) into sum constituent components that can unambiguously be attributed to loads (generators) and losses. Applications range broad spectrum of: transmission services pricing, loss allocation in distribution networks, fixed-cost allocation, modelling bilateral transactions, financial storage rights. This paper develops an analytical approach leveraging elementary circuit laws. The method rigorous from system-theoretic vantage point, it yields unambiguous results are consistent with constitutive principles describe steady-state behaviour networks. Moreover, implemented limited computational burden, applies networks arbitrary topologies, preserves coupling between activeand reactive-power injections. Numerical experiments indicate given solved power-flow solution, disaggregations computed for test system 2383 buses, 327 generators, 2056 4.34 s on personal computer, hence establishing scalability. Furthermore, applications demonstrated case studies focused quantifying impact distributed generation extracting nodal contributions respectively."
    ],
    "b_categories":[
      [
        "Digital Circuits"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Carbon-Aware Optimal Power Flow"
    ],
    "c_abstract":[
      "To facilitate effective decarbonization of the electric power sector, this paper introduces generic Carbon-aware Optimal Power Flow (C-OPF) method for system decision-making that considers demand-side carbon accounting and emission management. Built upon classic optimal flow (OPF) model, C-OPF incorporates equations constraints, as well carbon-related objectives, to jointly optimize flow. In particular, establishes invertibility matrix proposes modeling linearization techniques address issues undetermined directions bilinear terms in model. Additionally, two novel models, together with schemes, energy storage systems are developed integrated into Numerical simulations demonstrate characteristics effectiveness method, comparison OPF solutions."
    ],
    "c_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05443",
    "date":null,
    "a_title":"ClusterGraph: a new tool for visualization and compression of\n  multidimensional data",
    "a_abstract":"Understanding the global organization of complicated and high dimensional\ndata is of primary interest for many branches of applied sciences. It is\ntypically achieved by applying dimensionality reduction techniques mapping the\nconsidered data into lower dimensional space. This family of methods, while\npreserving local structures and features, often misses the global structure of\nthe dataset. Clustering techniques are another class of methods operating on\nthe data in the ambient space. They group together points that are similar\naccording to a fixed similarity criteria, however unlike dimensionality\nreduction techniques, they do not provide information about the global\norganization of the data. Leveraging ideas from Topological Data Analysis, in\nthis paper we provide an additional layer on the output of any clustering\nalgorithm. Such data structure, ClusterGraph, provides information about the\nglobal layout of clusters, obtained from the considered clustering algorithm.\nAppropriate measures are provided to assess the quality and usefulness of the\nobtained representation. Subsequently the ClusterGraph, possibly with an\nappropriate structure--preserving simplification, can be visualized and used in\nsynergy with state of the art exploratory data analysis techniques.",
    "explanation":"Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically\nachieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space.\nThe paper proposes ClusterGraph, obtained through clustering algorithm, to be use in synergy with state of the art exploratory data analysis techniques.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. The Eurographics Association"
    ],
    "b_abstract":[
      "We present a computational method for extracting simple descriptions of high dimensional data sets in the form of simplicial complexes. Our method, called Mapper, is based on the idea of partial clustering of the data guided by a set of functions defined on the data. The proposed method is not dependent on any particular clustering algorithm, i.e. any clustering algorithm may be used with Mapper. We implement this method and present a few sample applications in which simple descriptions of the data present important information about its structure."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "A Global Geometric Framework for Nonlinear Dimensionality Reduction"
    ],
    "c_abstract":[
      "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem dimensionality reduction: finding meaningful low-dimensional structures hidden in their observations. The brain confronts same everyday perception, extracting from its sensory inputs\u201430,000 auditory nerve fibers 106 optic fibers\u2014a manageably small number perceptually relevant features. Here we describe an approach to solving reduction problems that uses easily measured local metric information learn underlying geometry a data set. Unlike classical techniques principal component analysis (PCA) and multidimensional scaling (MDS), our is capable discovering nonlinear degrees freedom underlie complex natural observations, handwriting images face under different viewing conditions. In contrast previous algorithms for reduction, ours efficiently computes globally optimal solution, and, important class manifolds, guaranteed converge asymptotically true structure."
    ],
    "c_categories":[
      [
        "math.ST"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04992",
    "date":null,
    "a_title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck",
    "a_abstract":"Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.",
    "explanation":"Much like mutual information, transfer entropy is generally reported as a single\nvalue summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. The paper propose to decompose transfer entropy and localize the bits of variation on both sides of information flow.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information Transfer"
    ],
    "b_abstract":[
      "When presented with a data stream of two statistically dependent variables, predicting the future one variables (the target stream) can benefit from information about both its history and other variable source stream). For example, fluctuations in temperature at weather station be predicted using temperatures barometric readings. However, challenge when modelling such is that it easy for neural network to rely on greatest joint correlations within stream, which may ignore crucial but small transfer stream. As well, there are often situations where have previously been modelled independently would useful use model inform new model. Here, we develop an bottleneck approach conditional learning streams data. Our method, call Transfer Entropy Bottleneck (TEB), allows learn bottlenecks directed transferred variable, while quantifying this such, TEB provides order make predictions them."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Symbolic Transfer Entropy"
    ],
    "c_abstract":[
      "We propose to estimate transfer entropy using a technique of symbolization. demonstrate numerically that symbolic is robust and computationally fast method quantify the dominating direction information flow between time series from structurally identical nonidentical coupled systems. Analyzing multiday, multichannel electroencephalographic recordings 15 epilepsy patients our approach allowed us reliably identify hemisphere containing epileptic focus without observing actual seizure activity."
    ],
    "c_categories":[
      [
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06447",
    "date":null,
    "a_title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed\n  Self-Supervised Learning",
    "a_abstract":"Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001).",
    "explanation":"The model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "A deep learning approach for magnetization transfer contrast MR fingerprinting and chemical exchange saturation transfer imaging"
    ],
    "b_abstract":[
      "Semisolid magnetization transfer contrast (MTC) and chemical exchange saturation (CEST) MRI based on MT phenomenon have shown potential to evaluate brain development, neurological, psychiatric, neurodegenerative diseases. However, a qualitative ratio (MTR) metric commonly used in conventional MTC imaging is limited the assessment of quantitative semisolid macromolecular proton rates concentrations. In addition, CEST signals measured by MTR asymmetry analysis are unavoidably contaminated upfield nuclear Overhauser enhancement (NOE) mobile macromolecules. To address these issues, we developed an MTC-MR fingerprinting (MTC-MRF) technique quantify tissue parameters, which further allows estimation accurate at certain frequency offset. A pseudorandomized RF scheme was generate unique signal evolutions for different tissues supervised deep neural network designed extract properties from MTC-MRF signals. Through detailed Bloch equation-based digital phantom vivo studies, demonstrated that can characteristics with high accuracy computational efficiency, compared equation fitting approach, provide baseline reference NOE imaging. For validation, images were synthesized using parameters estimated deep-learning method experimentally acquired as standard. The proposed framework 3D MTC, CEST, human within clinically acceptable scan time."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Magnetic resonance fingerprinting"
    ],
    "c_abstract":[
      "Magnetic Resonance Fingerprinting (MRF) is a new approach to quantitative magnetic resonance imaging that allows simultaneous measurement of multiple tissue properties in a single, time-efficient acquisition. The ability to reproducibly and quantitatively measure tissue properties could enable more objective tissue diagnosis, comparisons of scans acquired at different locations and time points, longitudinal follow-up of individual patients and development of imaging biomarkers. This review provides a general overview of MRF technology, current preclinical and clinical applications and potential future directions. MRF has been initially evaluated in brain, prostate, liver, cardiac, musculoskeletal imaging, and measurement of perfusion and microvascular properties through MR vascular fingerprinting."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10822",
    "date":null,
    "a_title":"A Data-Efficient Sequential Learning Framework for Melt Pool Defect\n  Classification in Laser Powder Bed Fusion",
    "a_abstract":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM)\ncomponents is crucial, especially in the Laser Powder Bed Fusion (L-PBF)\nprocess, where melt pool defects such as keyhole, balling, and lack of fusion\ncan significantly compromise structural integrity. This study presents SL-RF+\n(Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential\nLearning (SL) framework for melt pool defect classification designed to\nmaximize data efficiency and model accuracy in data-scarce environments. SL-RF+\nutilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol\nsequence-based synthetic sampling to iteratively select the most informative\nsamples to learn from, thereby refining the model's decision boundaries with\nminimal labeled data. Results show that SL-RF+ outperformed traditional machine\nlearning models across key performance metrics, including accuracy, precision,\nrecall, and F1 score, demonstrating significant robustness in identifying melt\npool defects with limited data. This framework efficiently captures complex\ndefect patterns by focusing on high-uncertainty regions in the process\nparameter space, ultimately achieving superior classification performance\nwithout the need for extensive labeled datasets. While this study utilizes\npre-existing experimental data, SL-RF+ shows strong potential for real-world\napplications in pure sequential learning settings, where data is acquired and\nlabeled incrementally, mitigating the high costs and time constraints of sample\nacquisition.",
    "explanation":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Additive manufacturing and sustainability: an exploratory study of the advantages and challenges"
    ],
    "b_abstract":[
      "The emergence of advanced manufacturing technologies, coupled with consumer demands for more customised products and services, are causing shifts in the scale distribution manufacturing. In this paper, consideration is given to role one such process technology: additive consequences adopting novel production technology on industrial sustainability not well understood exploratory study draws publically available data provide insights into impacts sustainability. Benefits found exist across product material life cycles through redesign, improvements input processing, make-to-order component manufacturing, closing loop. As an immature technology, there substantial challenges these benefits being realised at each stage cycle. This paper summarises advantages challenges, discusses implications terms sources innovation, business models, configuration value chains."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Machine learning in additive manufacturing: State-of-the-art and perspectives"
    ],
    "c_abstract":[
      "Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04323",
    "date":null,
    "a_title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks",
    "a_abstract":"Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.",
    "explanation":"Materials discovery necessitates both optimized solution structures and diversity in the generated material structures. We propose the Symmetry-aware\nHierarchical Architecture for Flow-based Traversal (SHAFT),a novel generative model employing a hierarchical exploration strategy to efficiently exploit the symmetry of the materials space to generate crystal structures given desired properties.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation"
    ],
    "b_abstract":[
      "This paper is about the problem of learning a stochastic policy for generating an object (like molecular graph) from sequence actions, such that probability proportional to given positive reward object. Whereas standard return maximization tends converge single return-maximizing sequence, there are cases where we would like sample diverse set high-return solutions. These arise, example, in black-box function optimization when few rounds possible, each with large batches queries, should be diverse, e.g., design new molecules. One can also see this as approximately converting energy generative distribution. While MCMC methods achieve that, they expensive and generally only perform local exploration. Instead, training amortizes cost search during yields fast generation. Using insights Temporal Difference learning, propose GFlowNet, based on view process flow network, making it possible handle tricky case different trajectories yield same final state, many ways sequentially add atoms generate some graph. We cast convert consistency equations into objective, akin casting Bellman methods. prove any global minimum proposed objectives which samples desired distribution, demonstrate improved performance diversity GFlowNet simple domain modes function, molecule synthesis task."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals"
    ],
    "c_abstract":[
      "Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Network (MEGNet) models for accurate property prediction in molecules crystals. We demonstrate the MEGNet outperform prior ML such as SchNet 11 out of 13 properties QM9 molecule data set. Similarly, show trained on \u223c60 000 crystals Materials Project substantially formation energies, band gaps, elastic moduli crystals, achieving better than density functional theory accuracy over much larger present two strategies to address limitations common materials science chemistry. First, physically intuitive approach unify four separate molecular internal energy at 0 K room temperature, enthalpy, Gibbs free into single model by incorporating pressure, entropy global state inputs. Second, learned element embeddings encode periodic chemical trends can be transfer-learned from set (formation energies) improve with smaller amounts (band gaps moduli)."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.2062",
    "date":null,
    "a_title":"Construction and optimization of health behavior prediction model for   the elderly in smart elderly care",
    "a_abstract":"With the intensification of global aging, health management of the elderly has become a focus of social attention. This study designs and implements a smart elderly care service model to address issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection. In the experimental design, based on multi-source data sets and market research results, the model demonstrates excellent performance in health behavior prediction, emergency detection, and personalized services. The experimental results show that the model can effectively improve the accuracy and robustness of health behavior prediction and meet the actual application needs in the field of smart elderly care. In the future, with the integration of more data and further optimization of technology, the model will provide more powerful technical support for smart elderly care services.",
    "explanation":"This study designs and implements a smart elderly care service model to\naddress issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Artificial intelligence in elderly healthcare: A scoping review"
    ],
    "b_abstract":[
      "The ageing population has led to a surge in the adoption of artificial intelligence (AI) technologies in elderly healthcare worldwide. However, in the advancement of AI technologies, there is currently a lack of clarity about the types and roles of AI technologies in elderly healthcare. This scoping review aimed to provide a comprehensive overview of AI technologies in elderly healthcare by exploring the types of AI technologies employed, and identifying their roles in elderly healthcare based on existing studies. A total of 10 databases were searched for this review, from January 1 2000 to July 31 2022. Based on the inclusion criteria, 105 studies were included. The AI devices utilized in elderly healthcare were summarised as robots, exoskeleton devices, intelligent homes, AI-enabled health smart applications and wearables, voice-activated devices, and virtual reality. Five roles of AI technologies were identified: rehabilitation therapists, emotional supporters, social facilitators, supervisors, and cognitive promoters. Results showed that the impact of AI technologies on elderly healthcare is promising and that AI technologies are capable of satisfying the unmet care needs of older adults and demonstrating great potential in its further development in this area. More well-designed randomised controlled trials are needed in the future to validate the roles of AI technologies in elderly healthcare."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Digital health platforms for the elderly? Key adoption and usage barriers and ways to address them"
    ],
    "c_abstract":[
      "Digital healthcare platforms (DHPs) represent a relatively new phenomenon that could provide valuable complement to physical primary care \u2013 for example, by reducing costs, improving access healthcare, and allowing patient monitoring. However, such are mainly used today the younger generations, which creates \"digital divide\" between elderly. This article aims identify: i) perceived key barriers inhibit adoption usage of DHPs elderly, ii) what DHP providers can do facilitate increased The draws on qualitative interviews with elderly complementary process data from major Swedish DHP. We find perceives two initial DHPs: negative attitudes technology anxiety one barrier affecting both lack trust. analysis also identifies multiple development suggestions improvement better accommodate needs including application tailored education activities. an integrated framework outlining ways address them. In so doing, we contribute literature mHealth in healthcare."
    ],
    "c_categories":[
      [
        "Healthcare"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16896",
    "date":null,
    "a_title":"Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with\n  Differential Transformer Based Deep Learning Model Incorporating Pixelwise\n  Instrument Response Function",
    "a_abstract":"Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "explanation":"Recent advancements in Deep Learning (DL) have enabled improved fluorescence lifetime parameter estimation",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Characterization of fluorescence lifetime of organic fluorophores for molecular imaging in the shortwave infrared window"
    ],
    "b_abstract":[
      "SignificanceFluorescence lifetime imaging in the shortwave infrared (SWIR) is expected to enable high-resolution multiplexed molecular highly scattering tissue.AimTo characterize brightness and fluorescence of commercially available organic SWIR fluorophores benchmark them against tail emission conventional NIR-excited probes.ApproachCharacterization was performed through our established time-domain mesoscopic tomography system integrated around a time-correlated single-photon counting-single-photon avalanche diode array. Brightness were measured for NIR probes >1000 nm. Simultaneous probe then assess their potential studies.ResultsThe outperformed while mean lifetimes extremely short. The phantom study demonstrated feasibility multiplexing window with both probes.ConclusionsLong-tail Fluorescence readily detectable window, where showed shorter compared probes. We demonstrate which paves way vivo studies intact tissues at improved resolution."
    ],
    "b_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Fast fit-free analysis of fluorescence lifetime imaging via deep learning"
    ],
    "c_abstract":[
      "Fluorescence lifetime imaging (FLI) provides unique quantitative information in biomedical and molecular biology studies but relies on complex data-fitting techniques to derive the quantities of interest. Herein, we propose a fit-free approach FLI image formation that is based deep learning (DL) quantify fluorescence decays simultaneously over whole at fast speeds. We report neural network (DNN) architecture, named (FLI-Net) designed trained for different classes experiments, including visible near-infrared (NIR) microscopy (FLIM) NIR gated macroscopy (MFLI). FLI-Net outputs quantitatively spatially resolved lifetime-based parameters are typically employed field. validate utility framework by performing microscopic preclinical across spectra, as well 2 main data acquisition technologies. These results demonstrate suited accurately lifetimes cells and, real time, intact animals without any parameter settings. Hence, paves way reproducible unprecedented speeds, improved dissemination impact many important applications ranging from fundamental discoveries cellular clinical translation."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16961",
    "date":null,
    "a_title":"Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and\n  Lesions in Human and Mouse Histopathology",
    "a_abstract":"Segmenting glomerular intraglomerular tissue and lesions traditionally\ndepends on detailed morphological evaluations by expert nephropathologists, a\nlabor-intensive process susceptible to interobserver variability. Our group\npreviously developed the Glo-In-One toolkit for integrated detection and\nsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit to\nversion 2 with fine-grained segmentation capabilities, curating 14 distinct\nlabels for tissue regions, cells, and lesions across a dataset of 23,529\nannotated glomeruli across human and mouse histopathology data. To our\nknowledge, this dataset is among the largest of its kind to date.In this study,\nwe present a single dynamic head deep learning architecture designed to segment\n14 classes within partially labeled images of human and mouse pathology data.\nOur model was trained using a training set derived from 368 annotated kidney\nwhole-slide images (WSIs) to identify 5 key intraglomerular tissues covering\nBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.\nAdditionally, the network segments 9 glomerular lesion classes including\nadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,\nmicroaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.\nThe glomerulus segmentation model achieved a decent performance compared with\nbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).\nAdditional, transfer learning from rodent to human for glomerular lesion\nsegmentation model has enhanced the average segmentation accuracy across\ndifferent types of lesions by more than 3 %, as measured by Dice scores. The\nGlo-In-One-v2 model and trained weight have been made publicly available at\nhttps: \/\/github.com\/hrlblab\/Glo-In-One_v2.",
    "explanation":"In this study, we present a single dynamic head deep learning architecture designed to segment 14 classes within partially labeled images of human and mouse pathology data",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Pathology image analysis using segmentation deep learning algorithms"
    ],
    "b_abstract":[
      "With the rapid development of image scanning techniques and visualization software, whole slide imaging (WSI) is becoming a routine diagnostic method. Accelerating clinical diagnosis from pathology images and automating image analysis efficiently and accurately remain significant challenges. Recently, deep learning algorithms have shown great promise in pathology image analysis, such as in tumor region identification, metastasis detection, and patient prognosis. Many machine learning algorithms, including convolutional neural networks, have been proposed to automatically segment pathology images. Among these algorithms, segmentation deep learning algorithms such as fully convolutional networks stand out for their accuracy, computational efficiency, and generalizability. Thus, deep learning\u2013based pathology image segmentation has become an important tool in WSI analysis. In this review, the pathology image segmentation process using deep learning algorithms is described in detail. The goals are to provide quick guidance for implementing deep learning into pathology image analysis and to provide some potential ways of further improving segmentation performance. Although there have been previous reviews on using machine learning methods in digital pathology image analysis, this is the first in-depth review of the applications of deep learning algorithms for segmentation in WSI analysis."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Comparative gene expression profiles of intestinal transporters in mice, rats and humans"
    ],
    "c_abstract":[
      "We have studied gene expression profiles of intestinal transporters in model animals and humans. Total RNA was isolated from duodenum and the mRNA expression was measured using Affymetrix GeneChip oligonucleotide arrays. Detected genes from the intestine of mice, rats, and humans were about 60% of 22,690 sequences, 40% of 8739, and 47% of 12,559, respectively. A total of 86 genes involving transporters expressed in mice, 50 genes in rats, and 61 genes in humans were detected. Mice exhibited abundant mRNA expressions for peptide transporter HPT1, amino acid transporters CSNU3, CT1 and ASC1, nucleoside transporter CNT2, organic cation transporter SFXN1, organic anion transporter NBC3, glucose transporter SGLT1, and fatty acid transporters FABP1 and FABP2. Rats showed high expression profiles of peptide transporter PEPT1, amino acid transporters CSNU1 and 4F2HC, nucleoside transporter CNT2, organic cation transporter OCT5, organic anion transporter SDCT1, glucose transporter GLUT2 and GLUT5, and folate carrier FOLT. In humans, the highly expressed genes were peptide transporter HPT1, amino acid transporters LAT3, 4F2HC and PROT, nucleoside transporter CNT2, organic cation transporter OCTN2, organic anion transporters NADC1, NBC1 and SBC2, glucose transporters SGLT1 and GLUT5, multidrug resistance-associated protein RHO12, fatty acid transporters FABP1 and FABP2, and phosphate carrier PHC. Overall these data reveal diverse transcriptomic profiles for intestinal transporters among these species. Therefore, this transcriptional data may lead to more effective use of the laboratory animals as a model for oral drug development."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.02083",
    "date":null,
    "a_title":"Implementing An Artificial Quantum Perceptron",
    "a_abstract":"A Perceptron is a fundamental building block of a neural network. The\nflexibility and scalability of perceptron make it ubiquitous in building\nintelligent systems. Studies have shown the efficacy of a single neuron in\nmaking intelligent decisions. Here, we examined and compared two perceptrons\nwith distinct mechanisms, and developed a quantum version of one of those\nperceptrons. As a part of this modeling, we implemented the quantum circuit for\nan artificial perception, generated a dataset, and simulated the training.\nThrough these experiments, we show that there is an exponential growth\nadvantage and test different qubit versions. Our findings show that this\nquantum model of an individual perceptron can be used as a pattern classifier.\nFor the second type of model, we provide an understanding to design and\nsimulate a spike-dependent quantum perceptron. Our code is available at\n\\url{https:\/\/github.com\/ashutosh1919\/quantum-perceptron}",
    "explanation":"Studies have shown the efficacy of a single neuron in making intelligent decisions. Here, we examined and compared two perceptrons with distinct mechanisms, and developed a quantum version of one of those perceptrons",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Learning internal representations by back-propagating errors"
    ],
    "b_abstract":[
      "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Quantum algorithms for supervised and unsupervised machine learning"
    ],
    "c_abstract":[
      "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers vectors in high-dimensional spaces. Classical algorithms for solving such typically take time polynomial the number dimension space. Quantum computers are good at tensor product This paper provides supervised unsupervised quantum machine learning cluster assignment finding. can logarithmic both their dimension, an exponential speed-up over classical algorithms."
    ],
    "c_categories":[
      [
        "Quantum Physics"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.06750",
    "date":null,
    "a_title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision",
    "a_abstract":"Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.",
    "explanation":"Ultrasound (US) image stitching can expand the field-of view (FOV) by combining multiple US images from varied probe positions [...] In this work, we introduce SynStitch, a self-supervised framework designed for 2DUS stitching",
    "b_id":[
      "b3",
      "b21"
    ],
    "b_title":[
      "3-D ultrasound imaging: a review",
      "Generative AI for Medical Imaging: extending the MONAI Framework"
    ],
    "b_abstract":[
      "The development of 3-D ultrasound imaging is a way to address the disadvantages conventional imaging. In this article authors review approaches that have been attempted in such as B-mode, color Doppler, and power Doppler systems. Acquisition, reconstruction, rendering techniques for are discussed, well applications limitations.",
      "Recent advances in generative AI have brought incredible breakthroughs several areas, including medical imaging. These models tremendous potential not only to help safely share data via synthetic datasets but also perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due the complexity these models, their implementation reproducibility can be difficult. This hinder progress, act a use barrier, dissuade comparison new methods with existing works. In this study, we present MONAI Generative Models, freely available open-source platform that allows researchers developers easily train, evaluate, deploy related applications. Our reproduces state-of-art studies standardised way involving different architectures (such diffusion autoregressive transformers, GANs), provides pre-trained for community. We implemented generalisable fashion, illustrating results extended 2D or 3D scenarios, images modalities (like CT, MRI, X-Ray data) from anatomical areas. Finally, adopt modular extensible approach, ensuring long-term maintainability extension current applications future features."
    ],
    "b_categories":[
      [
        "eess.IV",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Symmetric diffeomorphic image registration with crosscorrelation: evaluating automated labeling of elderly and neurodegenerative brain"
    ],
    "c_abstract":[
      "One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17420",
    "date":null,
    "a_title":"Cross-modal Medical Image Generation Based on Pyramid Convolutional\n  Attention Network",
    "a_abstract":"The integration of multimodal medical imaging can provide complementary and\ncomprehensive information for the diagnosis of Alzheimer's disease (AD).\nHowever, in clinical practice, since positron emission tomography (PET) is\noften missing, multimodal images might be incomplete. To address this problem,\nwe propose a method that can efficiently utilize structural magnetic resonance\nimaging (sMRI) image information to generate high-quality PET images. Our\ngeneration model efficiently utilizes pyramid convolution combined with channel\nattention mechanism to extract multi-scale local features in sMRI, and injects\nglobal correlation information into these features using self-attention\nmechanism to ensure the restoration of the generated PET image on local texture\nand global structure. Additionally, we introduce additional loss functions to\nguide the generation model in producing higher-quality PET images. Through\nexperiments conducted on publicly available ADNI databases, the generated\nimages outperform previous research methods in various performance indicators\n(average absolute error: 0.0194, peak signal-to-noise ratio: 29.65, structural\nsimilarity: 0.9486) and are close to real images. In promoting AD diagnosis,\nthe generated images combined with their corresponding sMRI also showed\nexcellent performance in AD diagnosis tasks (classification accuracy: 94.21 %),\nand outperformed previous research methods of the same type. The experimental\nresults demonstrate that our method outperforms other competing methods in\nquantitative metrics, qualitative visualization, and evaluation criteria.",
    "explanation":"Our generation model efficiently utilizes pyramid convolution combined with channel attention mechanism to extract multi-scale local features in sMRI, and injects global correlation information into these features using self-attention mechanism to ensure the restoration of the generated PET image on local texture and global structure",
    "b_id":[
      "b3",
      "b17"
    ],
    "b_title":[
      "Deep learning-based classification of healthy aging controls, mild cognitive impairment and alzheimer's disease using fusion of mri-pet imaging",
      "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"
    ],
    "b_abstract":[
      "Automated detection of dementia stage using multimodal imaging modalities will be helpful for improving the clinical diagnosis. In this study, we develop the Inception-ResNet wrapper model in differentiating the healthy controls (HC), mild cognitive impairment (MCI), and Alzheimer\u2019s disease (AD) using conjoint magnetic resonance imaging (MRI) and positron emission tomography (PET) scans. We use T1-weighted MR and PET images of individuals aged between 42 and 95 years, including HC, MCI and AD patients. We first perform 3D tissue segmentation of MR images after skull striping. The atlas-based segmented MR image tissue is fused with PET image. Then we transform PET images from RGB to HSI color space and apply fusion of MRI with PET images using two-dimensional Fourier and discrete wavelet transform (DWT) and then reconstruct the MR-PET fused image using inverse Fourier and DWT methods. After the fusion of MRI and PET imaging modalities, we used 60 % training, 20 % for validation and the remaining 20 % as a test set using various convolutional neural networks. We found the proposed model as the best classifier with an accuracy of 95.5 %, 94.1 % and 95.9 % in classifying HC vs MCI, MCI vs AD and AD vs HC respectively when compared to the existing methods. We conclude that the proposed deep learning model has potential in automated classification of healthy and dementia stages using combined MRI and PET modalities with good performance.",
      "Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : \u2192 such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) \u2248 (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach."
    ],
    "b_categories":[
      [
        "cs.NE",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "Bidirectional Mapping of Brain MRI and PET With 3D Reversible GAN for the Diagnosis of Alzheimer\u2019s Disease"
    ],
    "c_abstract":[
      "<jats:p>Combining multi-modality data for brain disease diagnosis such as Alzheimer\u2019s disease (AD) commonly leads to improved performance than those using a single modality. However, it is still challenging to train a multi-modality model since it is difficult in clinical practice to obtain complete data that includes all modality data. Generally speaking, it is difficult to obtain both magnetic resonance images (MRI) and positron emission tomography (PET) images of a single patient. PET is expensive and requires the injection of radioactive substances into the patient\u2019s body, while MR images are cheaper, safer, and more widely used in practice. Discarding samples without PET data is a common method in previous studies, but the reduction in the number of samples will result in a decrease in model performance. To take advantage of multi-modal complementary information, we first adopt the Reversible Generative Adversarial Network (RevGAN) model to reconstruct the missing data. After that, a 3D convolutional neural network (CNN) classification model with multi-modality input was proposed to perform AD diagnosis. We have evaluated our method on the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, and compared the performance of the proposed method with those using state-of-the-art methods. The experimental results show that the structural and functional information of brain tissue can be mapped well and that the image synthesized by our method is close to the real image. In addition, the use of synthetic data is beneficial for the diagnosis and prediction of Alzheimer\u2019s disease, demonstrating the effectiveness of the proposed framework.<\/jats:p>"
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.16425",
    "date":null,
    "a_title":"Patherea: Cell Detection and Classification for the 2020s",
    "a_abstract":"This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "explanation":"This paper presents a Patherea, a framework for point-based cell detection and classification that provides a complete solution for developing and evaluating state-of-the-art approaches.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Whole Slide Imaging Versus Microscopy for Primary Diagnosis in Surgical Pathology: A Multicenter Blinded Randomized Noninferiority Study of 1992 Cases (Pivotal Study)"
    ],
    "b_abstract":[
      "Most prior studies of primary diagnosis in surgical pathology using whole slide imaging (WSI) versus microscopy have focused on specific organ systems or included relatively few cases. The objective this study was to demonstrate that WSI is noninferior for pathology. A blinded randomized noninferiority conducted across the entire range cases (biopsies and resections, including hematoxylin eosin, immunohistochemistry, special stains) from 4 institutions original sign-out (baseline diagnosis) as reference standard. Cases were scanned, converted randomized. Sixteen pathologists interpreted by WSI, followed a wash-out period \u22654 weeks, after which read same observers other modality. Major discordances identified an adjudication panel, differences between major discordance rates both (against standard) calculated. total 1992 included, resulting 15,925 reads. rate with standard 4.9% 4.6% microscopy. difference 0.4% (95% confidence interval, -0.30% 1.01%). highest endocrine (1.8%), neoplastic kidney (1.5%), urinary bladder (1.3%), gynecologic (1.2%). Detailed analysis these revealed no instances where interpretation consistently inaccurate compared multiple observers. We conclude pathology, biopsies resections stained immunohistochemistry stains. This conclusion valid wide variety specimen types."
    ],
    "b_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":true,
    "research_type":"applied"
  }
]