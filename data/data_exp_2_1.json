[
  {
    "id":"neg-d21-0",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18058",
    "b_title":[
      "On the Classification of Isoparametric Hypersurfaces with Constant\n  Principal Curvatures in Compact 3-Manifolds"
    ],
    "b_abstract":[
      "Establishing detailed relationships between transnormal systems of different\ntypes and their behaviors under covering maps, this paper presents a\nclassification of transnormal systems on compact 3-manifolds in the sense of\nequivalence. For CPC transnormal systems, we show that the ambient manifolds\nmust be locally isometric to one of six standard geometries up to equivalence.\nWe also find some equivalence classes containing no CPC transnormal system,\nhighlighting a critical distinction between isoparametric foliations and CPC\ntransnormal systems, which has not been previously addressed in the literature."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19457",
    "c_title":[
      "Compression in 3D Gaussian Splatting: A Survey of Methods, Trends, and\n  Future Directions"
    ],
    "c_abstract":[
      "3D Gaussian Splatting (3DGS) has recently emerged as a pioneering approach in\nexplicit scene rendering and computer graphics. Unlike traditional neural\nradiance field (NeRF) methods, which typically rely on implicit,\ncoordinate-based models to map spatial coordinates to pixel values, 3DGS\nutilizes millions of learnable 3D Gaussians. Its differentiable rendering\ntechnique and inherent capability for explicit scene representation and\nmanipulation positions 3DGS as a potential game-changer for the next generation\nof 3D reconstruction and representation technologies. This enables 3DGS to\ndeliver real-time rendering speeds while offering unparalleled editability\nlevels. However, despite its advantages, 3DGS suffers from substantial memory\nand storage requirements, posing challenges for deployment on\nresource-constrained devices. In this survey, we provide a comprehensive\noverview focusing on the scalability and compression of 3DGS. We begin with a\ndetailed background overview of 3DGS, followed by a structured taxonomy of\nexisting compression methods. Additionally, we analyze and compare current\nmethods from the topological perspective, evaluating their strengths and\nlimitations in terms of fidelity, compression ratios, and computational\nefficiency. Furthermore, we explore how advancements in efficient NeRF\nrepresentations can inspire future developments in 3DGS optimization. Finally,\nwe conclude with current research challenges and highlight key directions for\nfuture exploration."
    ],
    "c_categories":[
      [
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-1",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08479",
    "b_title":[
      "Skyrise: Exploiting Serverless Cloud Infrastructure for Elastic Data\n  Processing"
    ],
    "b_abstract":[
      "Serverless computing offers elasticity unmatched by conventional server-based\ncloud infrastructure. Although modern data processing systems embrace\nserverless storage, such as Amazon S3, they continue to manage their compute\nresources as servers. This is challenging for unpredictable workloads, leaving\nclusters often underutilized. Recent research shows the potential of serverless\ncompute resources, such as cloud functions, for elastic data processing, but\nalso sees limitations in performance robustness and cost efficiency for long\nrunning workloads. These challenges require holistic approaches across the\nsystem stack. However, to the best of our knowledge, there is no end-to-end\ndata processing system built entirely on serverless infrastructure. In this\npaper, we present Skyrise, our effort towards building the first fully\nserverless SQL query processor. Skyrise exploits the elasticity of its\nunderlying infrastructure, while alleviating the inherent limitations with a\nnumber of adaptive and cost-aware techniques. We show that both Skyrise's\nperformance and cost are competitive to other cloud data systems for\nterabyte-scale queries of the analytical TPC-H benchmark."
    ],
    "b_categories":[
      [
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05127",
    "c_title":[
      "Self-supervised Conformal Prediction for Uncertainty Quantification in\n  Imaging Problems"
    ],
    "c_abstract":[
      "Most image restoration problems are ill-conditioned or ill-posed and hence\ninvolve significant uncertainty. Quantifying this uncertainty is crucial for\nreliably interpreting experimental results, particularly when reconstructed\nimages inform critical decisions and science. However, most existing image\nrestoration methods either fail to quantify uncertainty or provide estimates\nthat are highly inaccurate. Conformal prediction has recently emerged as a\nflexible framework to equip any estimator with uncertainty quantification\ncapabilities that, by construction, have nearly exact marginal coverage. To\nachieve this, conformal prediction relies on abundant ground truth data for\ncalibration. However, in image restoration problems, reliable ground truth data\nis often expensive or not possible to acquire. Also, reliance on ground truth\ndata can introduce large biases in situations of distribution shift between\ncalibration and deployment. This paper seeks to develop a more robust approach\nto conformal prediction for image restoration problems by proposing a\nself-supervised conformal prediction method that leverages Stein's Unbiased\nRisk Estimator (SURE) to self-calibrate itself directly from the observed noisy\nmeasurements, bypassing the need for ground truth. The method is suitable for\nany linear imaging inverse problem that is ill-conditioned, and it is\nespecially powerful when used with modern self-supervised image restoration\ntechniques that can also be trained directly from measurement data. The\nproposed approach is demonstrated through numerical experiments on image\ndenoising and deblurring, where it delivers results that are remarkably\naccurate and comparable to those obtained by supervised conformal prediction\nwith ground truth data."
    ],
    "c_categories":[
      [
        "cs.CV",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-2",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17489",
    "b_title":[
      "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding"
    ],
    "b_abstract":[
      "Brain-computer interfaces (BCIs) present a promising avenue by translating\nneural activity directly into text, eliminating the need for physical actions.\nHowever, existing non-invasive BCI systems have not successfully covered the\nentire alphabet, limiting their practicality. In this paper, we propose a novel\nnon-invasive EEG-based BCI system with Curriculum-based Neural Spelling\nFramework, which recognizes all 26 alphabet letters by decoding neural signals\nassociated with handwriting first, and then apply a Generative AI (GenAI) to\nenhance spell-based neural language decoding tasks. Our approach combines the\nease of handwriting with the accessibility of EEG technology, utilizing\nadvanced neural decoding algorithms and pre-trained large language models\n(LLMs) to translate EEG patterns into text with high accuracy. This system show\nhow GenAI can improve the performance of typical spelling-based neural language\ndecoding task, and addresses the limitations of previous methods, offering a\nscalable and user-friendly solution for individuals with communication\nimpairments, thereby enhancing inclusive communication options."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00614",
    "c_title":[
      "A coupled finite and boundary spectral element method for linear\n  water-wave propagation problems"
    ],
    "c_abstract":[
      "A coupled boundary spectral element method (BSEM) and spectral element method\n(SEM) formulation for the propagation of small-amplitude water waves over\nvariable bathymetries is presented in this work. The wave model is based on the\nmild-slope equation (MSE), which provides a good approximation of the\npropagation of water waves over irregular bottom surfaces with slopes up to\n1:3. In unbounded domains or infinite regions, space can be divided into two\ndifferent areas: a central region of interest, where an irregular bathymetry is\nincluded, and an exterior infinite region with straight and parallel\nbathymetric lines. The SEM allows us to model the central region, where any\nvariation of the bathymetry can be considered, while the exterior infinite\nregion is modelled by the BSEM which, combined with the fundamental solution\npresented by Cerrato et al. [A. Cerrato, J. A. Gonz\\'alez, L.\nRodr\\'iguez-Tembleque, Boundary element formulation of the mild-slope equation\nfor harmonic water waves propagating over unidirectional variable bathymetries,\nEng. Anal. Boundary Elem. 62 (2016) 22-34.] can include bathymetries with\nstraight and parallel contour lines. This coupled model combines important\nadvantages of both methods; it benefits from the flexibility of the SEM for the\ninterior region and, at the same time, includes the fulfilment of the\nSommerfeld's radiation condition for the exterior problem, that is provided by\nthe BSEM. The solution approximation inside the elements is constructed by high\norder Legendre polynomials associated with Legendre-Gauss-Lobatto quadrature\npoints, providing a spectral convergence for both methods. The proposed\nformulation has been validated in three different benchmark cases with\ndifferent shapes of the bottom surface. The solutions exhibit the typical\np-convergence of spectral methods."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math-ph",
        "math.MP",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-3",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14901",
    "b_title":[
      "Oscillatory Line-Driven Winds: The Role of Atmospheric Stratification"
    ],
    "b_abstract":[
      "In a recent study, Dannen et al. surveyed a large parameter space to study\nthe transition from efficient to inefficient line driving. They found that when\nthe line force significantly weakens due to ionization, the winds are variable,\nwith a characteristic frequency comparable to the Lamb cut-off frequency of a\nstratified atmosphere, {\\omega}c. In this work, we present a set of simulations\nand perturbation analyses that elucidate the variability source and\ncharacteristics. We found that the line force adds wave energy and amplifies\nperturbations with frequencies near {\\omega}c. This selective amplification\nresults from the coupling between the natural tendency of velocity\nperturbations to grow in a stratified atmosphere and the dependence of the line\nforce on the velocity gradient, per the Castor-Abbott-Klein line-driven wind\ntheory. We also found that the variability stems from self-excitation that\noccurs in the exponential atmosphere due to the non-linearity introduced by the\nabsolute value of the velocity gradient in the line force prescription. We\nconclude that self-consistently calculating ionization is insufficient for\nmodeling the dynamics in the subsonic atmosphere. Instead future wind models\nshould relax the Sobolev approximation, or model the radiative transfer to\ncapture the dynamics and instabilities at the base of the wind."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04292",
    "c_title":[
      "MADUV: The 1st INTERSPEECH Mice Autism Detection via Ultrasound\n  Vocalization Challenge"
    ],
    "c_abstract":[
      "The Mice Autism Detection via Ultrasound Vocalization (MADUV) Challenge\nintroduces the first INTERSPEECH challenge focused on detecting autism spectrum\ndisorder (ASD) in mice through their vocalizations. Participants are tasked\nwith developing models to automatically classify mice as either wild-type or\nASD models based on recordings with a high sampling rate. Our baseline system\nemploys a simple CNN-based classification using three different spectrogram\nfeatures. Results demonstrate the feasibility of automated ASD detection, with\nthe considered audible-range features achieving the best performance (UAR of\n0.600 for segment-level and 0.625 for subject-level classification). This\nchallenge bridges speech technology and biomedical research, offering\nopportunities to advance our understanding of ASD models through machine\nlearning approaches. The findings suggest promising directions for vocalization\nanalysis and highlight the potential value of audible and ultrasound\nvocalizations in ASD detection."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-4",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04612",
    "b_title":[
      "On the distribution of the angle between Oseledets spaces"
    ],
    "b_abstract":[
      "This note is concerned with the distribution of the angles between Oseledets\nsubspaces for linear cocycles driven by an ergodic transformation. We restrict\nourselves to dimension $2$, and give particular attention to the question of\nlog-integrability of those angles. In the setting of random i.i.d.\\ products of\nmatrices, we construct examples of probability measures on \\(\\GL_2(\\R)\\) with\nfinite first moment, for which the angle between Oseledets directions of the\nassociated cocycle is not log-integrable. Building on work for the totally\nirreducible case by Benoist and Quint, we show that for probability measures\nwith finite second moment the angle between Oseledets subspaces is always\nlog-integrable. Then we pivot to general measurable \\(\\GL_2(\\R)\\)-cocycles over\nan arbitrary ergodic automorphism of a non-atomic Lebesgue space. We show that\nno integrability condition on the distribution of the matrices is sufficient to\nguarantee log-integrability of the angle between Oseledets spaces. In fact, in\nthis context we show that the joint distribution of the Oseledets spaces may be\nchosen arbitrarily. We also obtain a similar flexibility result for bounded\ncocycles under the proper condition on the distribution of angles."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17909",
    "c_title":[
      "Financial Wind Tunnel: A Retrieval-Augmented Market Simulator"
    ],
    "c_abstract":[
      "Market simulator tries to create high-quality synthetic financial data that\nmimics real-world market dynamics, which is crucial for model development and\nrobust assessment. Despite continuous advancements in simulation methodologies,\nmarket fluctuations vary in terms of scale and sources, but existing frameworks\noften excel in only specific tasks. To address this challenge, we propose\nFinancial Wind Tunnel (FWT), a retrieval-augmented market simulator designed to\ngenerate controllable, reasonable, and adaptable market dynamics for model\ntesting. FWT offers a more comprehensive and systematic generative capability\nacross different data frequencies. By leveraging a retrieval method to discover\ncross-sectional information as the augmented condition, our diffusion-based\nsimulator seamlessly integrates both macro- and micro-level market patterns.\nFurthermore, our framework allows the simulation to be controlled with wide\napplicability, including causal generation through \"what-if\" prompts or\nunprecedented cross-market trend synthesis. Additionally, we develop an\nautomated optimizer for downstream quantitative models, using stress testing of\nsimulated scenarios via FWT to enhance returns while controlling risks.\nExperimental results demonstrate that our approach enables the generalizable\nand reliable market simulation, significantly improve the performance and\nadaptability of downstream models, particularly in highly complex and volatile\nmarket conditions. Our code and data sample is available at\nhttps:\/\/anonymous.4open.science\/r\/fwt_-E852"
    ],
    "c_categories":[
      [
        "cs.CE",
        "cs.LG",
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-5",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05710",
    "b_title":[
      "EmotiCrafter: Text-to-Emotional-Image Generation based on\n  Valence-Arousal Model"
    ],
    "b_abstract":[
      "Recent research shows that emotions can enhance users' cognition and\ninfluence information communication. While research on visual emotion analysis\nis extensive, limited work has been done on helping users generate emotionally\nrich image content. Existing work on emotional image generation relies on\ndiscrete emotion categories, making it challenging to capture complex and\nsubtle emotional nuances accurately. Additionally, these methods struggle to\ncontrol the specific content of generated images based on text prompts. In this\nwork, we introduce the new task of continuous emotional image content\ngeneration (C-EICG) and present EmotiCrafter, an emotional image generation\nmodel that generates images based on text prompts and Valence-Arousal values.\nSpecifically, we propose a novel emotion-embedding mapping network that embeds\nValence-Arousal values into textual features, enabling the capture of specific\nemotions in alignment with intended input prompts. Additionally, we introduce a\nloss function to enhance emotion expression. The experimental results show that\nour method effectively generates images representing specific emotions with the\ndesired content and outperforms existing techniques."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02478",
    "c_title":[
      "Anomalous bulk-edge correspondence of nonlinear Rice-Mele model"
    ],
    "c_abstract":[
      "Bulk-edge correspondence (BEC) constitutes a fundamental concept within the\ndomain of topological physics, elucidating the profound interplay between the\ntopological invariants that characterize the bulk states and the emergent edge\nstates. A recent highlight along this research line consists of establishing\nBEC under the eigenvalue's nonlinearity in a linear Hamiltonian by introducing\nauxiliary eigenvalues [\\href{https:\/\/doi.org\/10.1103\/PhysRevLett.132.126601}{\nT. Isobe {\\it et al.,} Phys. Rev. Lett. 132, 126601 (2024)}]. The purpose of\nthis work aims to extend Isobe's analysis to uncover BEC of eigenvalue's\nnonlinearity in intrinsic nonlinear Hamiltonians. To achieve this, we\nnumerically solve the nonlinear Rice-Mele (RM) model and identify two distinct\ntypes of nonlinear eigenvalues: the intrinsically nonlinear eigenvalues and the\neigenvalue's nonlinearity introduced through the incorporation of auxiliary\neigenvalues. Furthermore, we establish a novel form of BEC based on these\nauxiliary nonlinear eigenvalues, which we term the anomalous BEC of a nonlinear\nphysical system. The concept of the anomalous BEC defined herein provides a\nnovel perspective on the intricate interplay between topology and nonlinearity\nin the context of BEC."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas",
        "nlin.PS",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-6",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09389",
    "b_title":[
      "Canonical equilibrium of mean-field $O(n)$~models in presence of random\n  fields"
    ],
    "b_abstract":[
      "We study canonical-equilibrium properties of Random Field $O(n)$ Models\ninvolving classical continuous vector spins of $n$ components with mean-field\ninteractions and subject to disordered fields acting on individual spins. To\nthis end, we employ two complementary approaches: the mean-field approximation,\nvalid for any disorder distribution, and the replica trick, applicable when the\ndisordered fields are sampled from a Gaussian distribution. On the basis of an\nexact analysis, we demonstrate that when replica symmetry holds, both the\napproaches yield identical expression for the free energy per spin of the\nsystem. As consequences, we study the case of $n=2$ ($XY$ spins) and that of\n$n=3$ (Heisenberg spins) for two representative choices of the disorder\ndistribution, namely, a Gaussian and a symmetric bimodal distribution. For both\n$n=2$ and $n=3$, we demonstrate that while the magnetization exhibits a\ncontinuous phase transition as a function of temperature for the Gaussian case,\nthe transition could be either continuous or first-order with an emergent\ntricriticality when the disorder distribution is bimodal. We also discuss in\nthe context of our models the issue of self-averaging of extensive variables\nnear the critical point of a continuous phase transition."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01662",
    "c_title":[
      "Scanning HTML at Tens of Gigabytes per Second on ARM Processors"
    ],
    "c_abstract":[
      "Modern processors have instructions to process 16 bytes or more at once.\nThese instructions are called SIMD, for single instruction, multiple data.\nRecent advances have leveraged SIMD instructions to accelerate parsing of\ncommon Internet formats such as JSON and base64. During HTML parsing, they\nquickly identify specific characters with a strategy called vectorized\nclassification. We review their techniques and compare them with a faster\nalternative. We measure a 20-fold performance improvement in HTML scanning\ncompared to traditional methods on recent ARM processors. Our findings\nhighlight the potential of SIMD-based algorithms for optimizing Web browser\nperformance."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.DS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-7",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20450",
    "b_title":[
      "Universal electronic structure of layered nickelates via oxygen-centered\n  planar orbitals"
    ],
    "b_abstract":[
      "Superconductivity has recently been demonstrated in La$_3$Ni$_2$O$_7$ up to\n91K under moderate pressure in bulk crystals, and up to 48K at ambient pressure\nin thin films grown under compressive strain. Key questions remain open\nregarding the crystal structure and low-energy electronic states that support\nsuperconductivity in these compounds. Here we take advantage of the natural\npolymorphism between bilayer (2222) or alternating monolayer-trilayer (1313)\nstacking sequences that arises in bulk La$_3$Ni$_2$O$_7$ crystals to identify\nuniversal features in this family of materials. Employing angle-resolved\nphotoemission spectroscopy (ARPES) we observe the fingerprint of a spin-density\nwave (SDW) instability, strong and coherent enough to modify the electronic\nstructure. We demonstrate that this feature is a `translated' $\\beta$ Fermi\nsurface associated with a scattering vector $Q_{t\\beta}$ which matches the\n$Q_{SDW}$ detected by neutron and x-ray scattering experiments. This\nobservation provides an important link between surface and bulk probes, and\ndemonstrates a universal connection between magnetism and fermiology in\nLa$_3$Ni$_2$O$_7$ as well as La$_4$Ni$_3$O$_{10}$. We simulate the spectral\nweight distribution observed in our ARPES dichroism experiments and establish\nthat the low-energy electronic phenomenology is dominated by oxygen-centered\nplanar orbitals, which -- upon moving along the Fermi surface away from the\nNi-O-Ni bond directions -- evolve from the $d_{3x^2-r^2}$ and $d_{3y^2-r^2}$\nsymmetry characteristic of 3-spin polarons to the familiar $d_{x^2-y^2}$\nZhang-Rice singlets that support high-temperature superconductivity in\ncuprates. Despite the multiorbital nature of the nickelates, our work\nestablishes an empirical correspondence between the low-energy electronic\nstructure of cuprates and nickelates, thus suggesting a common origin for their\nunconventional superconductivity."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07200",
    "c_title":[
      "Color-Quality Invariance for Robust Medical Image Segmentation"
    ],
    "c_abstract":[
      "Single-source domain generalization (SDG) in medical image segmentation\nremains a significant challenge, particularly for images with varying color\ndistributions and qualities. Previous approaches often struggle when models\ntrained on high-quality images fail to generalize to low-quality test images\ndue to these color and quality shifts. In this work, we propose two novel\ntechniques to enhance generalization: dynamic color image normalization (DCIN)\nmodule and color-quality generalization (CQG) loss. The DCIN dynamically\nnormalizes the color of test images using two reference image selection\nstrategies. Specifically, the DCIN utilizes a global reference image selection\n(GRIS), which finds a universal reference image, and a local reference image\nselection (LRIS), which selects a semantically similar reference image per test\nsample. Additionally, CQG loss enforces invariance to color and quality\nvariations by ensuring consistent segmentation predictions across transformed\nimage pairs. Experimental results show that our proposals significantly improve\nsegmentation performance over the baseline on two target domain datasets,\ndespite being trained solely on a single source domain. Notably, our model\nachieved up to a 32.3-point increase in Dice score compared to the baseline,\nconsistently producing robust and usable results even under substantial domain\nshifts. Our work contributes to the development of more robust medical image\nsegmentation models that generalize across unseen domains. The implementation\ncode is available at https:\/\/github.com\/RaviShah1\/DCIN-CQG."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-8",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01185",
    "b_title":[
      "Deep Active Speech Cancellation with Multi-Band Mamba Network"
    ],
    "b_abstract":[
      "We present a novel deep learning network for Active Speech Cancellation\n(ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively\ncanceling both noise and speech signals. The proposed Multi-Band Mamba\narchitecture segments input audio into distinct frequency bands, enabling\nprecise anti-signal generation and improved phase alignment across frequencies.\nAdditionally, we introduce an optimization-driven loss function that provides\nnear-optimal supervisory signals for anti-signal generation. Experimental\nresults demonstrate substantial performance gains, achieving up to 7.2dB\nimprovement in ANC scenarios and 6.2dB in ASC, significantly outperforming\nexisting methods. Audio samples are available at\nhttps:\/\/mishalydev.github.io\/DeepASC-Demo"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14152",
    "c_title":[
      "Multimodal Prescriptive Deep Learning"
    ],
    "c_abstract":[
      "We introduce a multimodal deep learning framework, Prescriptive Neural\nNetworks (PNNs), that combines ideas from optimization and machine learning,\nand is, to the best of our knowledge, the first prescriptive method to handle\nmultimodal data. The PNN is a feedforward neural network trained on embeddings\nto output an outcome-optimizing prescription. In two real-world multimodal\ndatasets, we demonstrate that PNNs prescribe treatments that are able to\nsignificantly improve estimated outcomes in transcatheter aortic valve\nreplacement (TAVR) procedures by reducing estimated postoperative complication\nrates by 32% and in liver trauma injuries by reducing estimated mortality rates\nby over 40%. In four real-world, unimodal tabular datasets, we demonstrate that\nPNNs outperform or perform comparably to other well-known, state-of-the-art\nprescriptive models; importantly, on tabular datasets, we also recover\ninterpretability through knowledge distillation, fitting interpretable Optimal\nClassification Tree models onto the PNN prescriptions as classification\ntargets, which is critical for many real-world applications. Finally, we\ndemonstrate that our multimodal PNN models achieve stability across randomized\ndata splits comparable to other prescriptive methods and produce realistic\nprescriptions across the different datasets."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-9",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04442",
    "b_title":[
      "A Survey on Path Planning Problem of Rolling Contacts: Approaches,\n  Applications and Future Challenges"
    ],
    "b_abstract":[
      "This paper explores an eclectic range of path-planning methodologies\nengineered for rolling surfaces. Our focus is on the kinematic intricacies of\nrolling contact systems, which are investigated through a motion planning lens.\nBeyond summarizing the approaches to single-contact rotational surfaces, we\nexplore the challenging domain of spin-rolling multi-contact systems. Our work\nproposes solutions for the higher-dimensional problem of multiple rotating\nobjects in contact. Venturing beyond kinematics, these methodologies find\napplication across a spectrum of domains, including rolling robots,\nreconfigurable swarm robotics, micro\/nano manipulation, and nonprehensile\nmanipulations. Through meticulously examining established planning strategies,\nwe unveil their practical implementations in various real-world scenarios, from\nintricate dexterous manipulation tasks to the nimble manoeuvring of rolling\nrobots and even shape planning of multi-contact swarms of particles. This study\nintroduces the persistent challenges and unexplored frontiers of robotics,\nintricately linked to both path planning and mechanism design. As we illuminate\nexisting solutions, we also set the stage for future breakthroughs in this\ndynamic and rapidly evolving field by highlighting the critical importance of\naddressing rolling contact problems."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19893",
    "c_title":[
      "A Multiple Transferable Neural Network Method with Domain Decomposition\n  for Elliptic Interface Problems"
    ],
    "c_abstract":[
      "The transferable neural network (TransNet) is a two-layer shallow neural\nnetwork with pre-determined and uniformly distributed neurons in the hidden\nlayer, and the least-squares solvers can be particularly used to compute the\nparameters of its output layer when applied to the solution of partial\ndifferential equations. In this paper, we integrate the TransNet technique with\nthe nonoverlapping domain decomposition and the interface conditions to develop\na novel multiple transferable neural network (Multi-TransNet) method for\nsolving elliptic interface problems, which typically contain discontinuities in\nboth solutions and their derivatives across interfaces. We first propose an\nempirical formula for the TransNet to characterize the relationship between the\nradius of the domain-covering ball, the number of hidden-layer neurons, and the\noptimal neuron shape. In the Multi-TransNet method, we assign each subdomain\none distinct TransNet with an adaptively determined number of hidden-layer\nneurons to maintain the globally uniform neuron distribution across the entire\ncomputational domain, and then unite all the subdomain TransNets together by\nincorporating the interface condition terms into the loss function. The\nempirical formula is also extended to the Multi-TransNet and further employed\nto estimate appropriate neuron shapes for the subdomain TransNets, greatly\nreducing the parameter tuning cost. Additionally, we propose a normalization\napproach to adaptively select the weighting parameters for the terms in the\nloss function. Ablation studies and extensive experiments with comparison tests\non different types of elliptic interface problems with low to high contrast\ndiffusion coefficients in two and three dimensions are carried out to\nnumerically demonstrate the superior accuracy, efficiency, and robustness of\nthe proposed Multi-TransNet method."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-10",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06079",
    "b_title":[
      "Set-valued evenly convex functions: characterizations and c-conjugacy"
    ],
    "b_abstract":[
      "In this work we deal with set-valued functions with values in the power set\nof a separated locally convex space where a nontrivial pointed convex cone\ninduces a partial order relation. A set-valued function is evenly convex if its\nepigraph is an evenly convex set, i.e., it is the intersection of an arbitrary\nfamily of open half-spaces. In this paper we characterize evenly convex\nset-valued functions as the pointwise supremum of its set-valued e-affine\nminorants. Moreover, a suitable conjugation pattern will be developed for these\nfunctions, as well as the counterpart of the biconjugation Fenchel-Moreau\ntheorem."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17999",
    "c_title":[
      "GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in\n  Smart Homes"
    ],
    "c_abstract":[
      "Sensor-based Human Activity Recognition (HAR) in smart home environments is\ncrucial for several applications, especially in the healthcare domain. The\nmajority of the existing approaches leverage deep learning models. While these\napproaches are effective, the rationale behind their outputs is opaque.\nRecently, eXplainable Artificial Intelligence (XAI) approaches emerged to\nprovide intuitive explanations to the output of HAR models. To the best of our\nknowledge, these approaches leverage classic deep models like CNNs or RNNs.\nRecently, Graph Neural Networks (GNNs) proved to be effective for sensor-based\nHAR. However, existing approaches are not designed with explainability in mind.\nIn this work, we propose the first explainable Graph Neural Network explicitly\ndesigned for smart home HAR. Our results on two public datasets show that this\napproach provides better explanations than state-of-the-art methods while also\nslightly improving the recognition rate."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-11",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09802",
    "b_title":[
      "Batch List-Decodable Linear Regression via Higher Moments"
    ],
    "b_abstract":[
      "We study the task of list-decodable linear regression using batches. A batch\nis called clean if it consists of i.i.d. samples from an unknown linear\nregression distribution. For a parameter $\\alpha \\in (0, 1\/2)$, an unknown\n$\\alpha$-fraction of the batches are clean and no assumptions are made on the\nremaining ones. The goal is to output a small list of vectors at least one of\nwhich is close to the true regressor vector in $\\ell_2$-norm. [DJKS23] gave an\nefficient algorithm, under natural distributional assumptions, with the\nfollowing guarantee. Assuming that the batch size $n$ satisfies $n \\geq\n\\tilde{\\Omega}(\\alpha^{-1})$ and the number of batches is $m = \\mathrm{poly}(d,\nn, 1\/\\alpha)$, their algorithm runs in polynomial time and outputs a list of\n$O(1\/\\alpha^2)$ vectors at least one of which is\n$\\tilde{O}(\\alpha^{-1\/2}\/\\sqrt{n})$ close to the target regressor. Here we\ndesign a new polynomial time algorithm with significantly stronger guarantees\nunder the assumption that the low-degree moments of the covariates distribution\nare Sum-of-Squares (SoS) certifiably bounded. Specifically, for any constant\n$\\delta>0$, as long as the batch size is $n \\geq\n\\Omega_{\\delta}(\\alpha^{-\\delta})$ and the degree-$\\Theta(1\/\\delta)$ moments of\nthe covariates are SoS certifiably bounded, our algorithm uses $m =\n\\mathrm{poly}((dn)^{1\/\\delta}, 1\/\\alpha)$ batches, runs in polynomial-time, and\noutputs an $O(1\/\\alpha)$-sized list of vectors one of which is\n$O(\\alpha^{-\\delta\/2}\/\\sqrt{n})$ close to the target. That is, our algorithm\nachieves substantially smaller minimum batch size and final error, while\nachieving the optimal list size. Our approach uses higher-order moment\ninformation by carefully combining the SoS paradigm interleaved with an\niterative method and a novel list pruning procedure. In the process, we give an\nSoS proof of the Marcinkiewicz-Zygmund inequality that may be of broader\napplicability."
    ],
    "b_categories":[
      [
        "cs.DS",
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12693",
    "c_title":[
      "Coupling between small polarons and ferroelectricity in BaTiO3"
    ],
    "c_abstract":[
      "In this study, we investigate the formation of electron and hole small\npolarons in the prototypical ferroelectric material BaTiO3, with a focus on\ntheir interaction with ferroelectric distortive fields. To accurately describe\nthe ferroelectric phase in electronically correlated BaTiO3, we employ the\nHSE06 hybrid functional, which addresses the limitations of conventional DFT\nand DFT+U models, providing a more precise depiction of both ferroelectric and\npolaronic behaviors. Our analysis spans three structural phases of BaTiO3:\ncubic, tetragonal, and orthorhombic. We uncover a unique phase-dependent trend\nin electron polaron stability, which progressively increases across the\nstructural phases, peaking in the rhombohedral phase due to the constructive\ncoupling between the polaron and ferroelectric phonon fields. In contrast, hole\npolarons exhibit a stability pattern largely unaffected by the phase\ntransitions. Furthermore, we observe that polaron self-trapping significantly\nalters the local ferroelectric distortive pattern, which propagates to\nneighboring sites but has a minimal effect on the long-range macroscopic\nspontaneous polarization. Charge trapping is also associated with localized\nspin formation, opening new possibilities for enhanced functionalities in\nmultiferroic materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-12",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08062",
    "b_title":[
      "How Does CP Length Affect the Sensing Range for OFDM-ISAC?"
    ],
    "b_abstract":[
      "Orthogonal frequency division multiplexing (OFDM), which has been the\ndominating waveform for contemporary wireless communications, is also regarded\nas a competitive candidate for future integrated sensing and communication\n(ISAC) systems. Existing works on OFDM-ISAC usually assume that the maximum\nsensing range should be limited by the cyclic prefix (CP) length since\ninter-symbol interference (ISI) and inter-carrier interference (ICI) should be\navoided. However, in this paper, we provide rigorous analysis to reveal that\nthe random data embedded in OFDM-ISAC signal can actually act as a free ``mask\"\nfor ISI, which makes ISI\/ICI random and hence greatly attenuated after radar\nsignal processing. The derived signal-to-interference-plus-noise ratio (SINR)\nin the range profile demonstrates that the maximum sensing range of OFDM-ISAC\ncan greatly exceed the ISI-free distance that is limited by the CP length,\nwhich is validated by simulation results. To further mitigate power degradation\nfor long-range targets, a novel sliding window sensing method is proposed,\nwhich iteratively detects and cancels short-range targets before shifting the\ndetection window. The shifted detection window can effectively compensate the\npower degradation due to insufficient CP length for long-range targets. Such\nresults provide valuable guidance for the CP length design in OFDM-ISAC\nsystems."
    ],
    "b_categories":[
      [
        "cs.ET",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.14032",
    "c_title":[
      "Hierarchical Verification of Non-Gaussian Coherence in Bosonic Quantum\n  States"
    ],
    "c_abstract":[
      "Non-Gaussianity, a distinctive characteristic of bosonic quantum states, is\npivotal in advancing quantum networks, fault-tolerant quantum computing, and\nhigh-precision metrology. Verifying the quantum nature of a state, particularly\nits non-Gaussian features, is essential for ensuring the reliability and\nperformance of these technologies. However, the specific properties required\nfor each application demand tailored validation thresholds. Here, we introduce\na hierarchical framework comprising absolute, relative, and qubit-specific\nthresholds to assess the non-Gaussianity of local coherences. We illustrate\nthis framework using heralded optical non-Gaussian states with the highest\npurities available in optical platforms. This comprehensive framework presents\nthe first detailed evaluation of number state coherences and can be extended to\na wide range of bosonic states."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-13",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05055",
    "b_title":[
      "Charge transport limited by nonlocal electron-phonon interaction. II.\n  Numerically exact quantum dynamics in the slow-phonon regime"
    ],
    "b_abstract":[
      "Transport of charge carriers in mechanically soft semiconductors is mainly\nlimited by their interaction with slow intermolecular phonons. Carrier motion\nexhibits a crossover from superdiffusive to subdiffusive, producing a distinct\nlow-frequency peak in the dynamical-mobility profile. These features can be\nunderstood within approaches relying on the timescale separation between\ncarrier and phonon dynamics, such as the transient localization scenario (TLS).\nHowever, recovering them from fully quantum dynamics has proved elusive. Using\nthe hierarchical equations of motion (HEOM)-based approach exposed in a\ncompanion paper (arXiv:2501.05054), we study carrier transport in the\none-dimensional Peierls model near the adiabatic limit. We find that the TLS\napproximates HEOM dynamics very well at higher temperatures and for stronger\ninteractions. Then, the transport is predominantly phonon-assisted, and turns\ndiffusive from the subdiffusive side well before one phonon period. In\ncontrast, the band current dominates at moderate temperatures and interactions,\nrelevant for transport in realistic materials. We then conclude that the\nsuper-to-subdiffusive crossover is transient, so that the diffusive motion sets\nin from the superdiffusive side after a couple of phonon periods. The\nlow-frequency dynamical mobility then additionally exhibits a dip at\napproximately one phonon frequency, and the zero-frequency peak. Our findings\nin this moderate regime show limitations of the TLS, and support the results of\nthe most advanced quantum-classical simulations. We expect that the qualitative\ndifferences between HEOM and TLS dynamics would diminish for a more realistic\nphonon density of states."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "physics.chem-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10023",
    "c_title":[
      "Using Context to Improve Word Segmentation"
    ],
    "c_abstract":[
      "An important step in understanding how children acquire languages is studying\nhow infants learn word segmentation. It has been established in previous\nresearch that infants may use statistical regularities in speech to learn word\nsegmentation. The research of Goldwater et al., demonstrated that incorporating\ncontext in models improves their ability to learn word segmentation. We\nimplemented two of their models, a unigram and bigram model, to examine how\ncontext can improve statistical word segmentation. The results are consistent\nwith our hypothesis that the bigram model outperforms the unigram model at\npredicting word segmentation. Extending the work of Goldwater et al., we also\nexplored basic ways to model how young children might use previously learned\nwords to segment new utterances."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-14",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02844",
    "b_title":[
      "Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text\n  Classification"
    ],
    "b_abstract":[
      "Text classification is a fundamental task in data mining, pivotal to various\napplications such as tabular understanding and recommendation. Although neural\nnetwork-based models, such as CNN and BERT, have demonstrated remarkable\nperformance in text classification, their effectiveness heavily relies on\nabundant labeled training data. This dependency makes these models less\neffective in dynamic few-shot text classification, where labeled data is\nscarce, and new target labels frequently appear based on application needs.\nRecently, large language models (LLMs) have shown promise due to their\nextensive pretraining and contextual understanding ability. Current approaches\nprovide LLMs with text inputs, candidate labels, and additional side\ninformation (e.g., descriptions) to classify texts. However, their\neffectiveness is hindered by the increased input size and the noise introduced\nthrough side information processing. To address these limitations, we propose a\ngraph-based online retrieval-augmented generation framework, namely GORAG, for\ndynamic few-shot text classification. Rather than treating each input\nindependently, GORAG constructs and maintains a weighted graph by extracting\nside information across all target texts. In this graph, text keywords and\nlabels are represented as nodes, with edges indicating the correlations between\nthem. To model these correlations, GORAG employs an edge weighting mechanism to\nprioritize the importance and reliability of extracted information and\ndynamically retrieves relevant context using a minimum-cost spanning tree\ntailored for each text input. Empirical evaluations demonstrate that GORAG\noutperforms existing approaches by providing more comprehensive and precise\ncontextual information."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00971",
    "c_title":[
      "Open Questions and Future Directions in Titan Science"
    ],
    "c_abstract":[
      "In this chapter we attempt to distill the very large number of possible\nfuture inquiries of Titan into a relatively concise list of twenty high level\nquestions - each of which of would necessarily entail a multitude of more\nspecific investigations and studies. While this list does not encompass all\npossible open questions, and is divided into topics according to our preference\nand not in any way uniquely, we believe that it does however span a wide range\nof the most intriguing topics about Titan, and may form some sort of guide\nespecially for those embarking into Titan studies for the first time. At the\nend of this chapter we return to explore how these four techniques may be used\nto answer the large, high-level open questions in Titan science."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-15",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01922",
    "b_title":[
      "LAST SToP For Modeling Asynchronous Time Series"
    ],
    "b_abstract":[
      "We present a novel prompt design for Large Language Models (LLMs) tailored to\nAsynchronous Time Series. Unlike regular time series, which assume values at\nevenly spaced time points, asynchronous time series consist of timestamped\nevents occurring at irregular intervals, each described in natural language.\nOur approach effectively utilizes the rich natural language of event\ndescriptions, allowing LLMs to benefit from their broad world knowledge for\nreasoning across different domains and tasks. This allows us to extend the\nscope of asynchronous time series analysis beyond forecasting to include tasks\nlike anomaly detection and data imputation. We further introduce Stochastic\nSoft Prompting, a novel prompt-tuning mechanism that significantly improves\nmodel performance, outperforming existing fine-tuning methods such as QLoRA.\nThrough extensive experiments on real world datasets, we demonstrate that our\napproach achieves state-of-the-art performance across different tasks and\ndatasets."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15645",
    "c_title":[
      "Engineered Zwitterion-Infused Clay Composites with Antibacterial and\n  Antifungal Efficacy"
    ],
    "c_abstract":[
      "Microbes and pathogens play a detrimental role in healing wounds, causing\ninfections like impetigo through bodily fluids and skin and entering the\nbloodstream through the wounds, thereby hindering the healing process and\ntissue regeneration. Clay, known for its long history of natural therapeutic\nuse, has emerged as one of the most promising candidates for biomedical\napplications due to its non-toxic nature, porosity, high surface area,\nubiquity, and excellent cation exchange capacity. This study demonstrates an\ninnovative approach to engineering an organo-functionalized,\ninfection-resistant, easy-to-use bandage material from clay, an environmentally\nbenign and sustainable material. The hybrid membranes have been developed using\nclays, zwitterions, silver ions, and terbinafine hydrochloride (TBH) to impart\nantibacterial and antifungal efficacy. A critical aspect of this study is\nembedding organic molecules and metal ions with the clays and releasing them to\nresist the growth and kill the pathogens. The antimicrobial efficacy of the\nmembranes has been tested using a zone of inhibition study against the most\ncommon microbes in skin wounds, viz. S. aureus, E. coli, and C. albicans.\nResults from our studies not only demonstrate the potential of these hybrid\nclay membranes as a cost-effective, scalable, and effective solution for\ntreating microbial infections but also instill newer avenues for point-of-care\nwound-healing treatments, offering hope for improved patient outcomes."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-16",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17882",
    "b_title":[
      "Science Across Languages: Assessing LLM Multilingual Translation of\n  Scientific Papers"
    ],
    "b_abstract":[
      "Scientific research is inherently global. However, the vast majority of\nacademic journals are published exclusively in English, creating barriers for\nnon-native-English-speaking researchers. In this study, we leverage large\nlanguage models (LLMs) to translate published scientific articles while\npreserving their native JATS XML formatting, thereby developing a practical,\nautomated approach for implementation by academic journals. Using our approach,\nwe translate articles across multiple scientific disciplines into 28 languages.\nTo evaluate translation accuracy, we introduce a novel question-and-answer (QA)\nbenchmarking method, in which an LLM generates comprehension-based questions\nfrom the original text and then answers them based on the translated text. Our\nbenchmark results show an average performance of 95.9%, showing that the key\nscientific details are accurately conveyed. In a user study, we translate the\nscientific papers of 15 researchers into their native languages, finding that\nthe authors consistently found the translations to accurately capture the\noriginal information in their articles. Interestingly, a third of the authors\nfound many technical terms \"overtranslated,\" expressing a preference to keep\nterminology more familiar in English untranslated. Finally, we demonstrate how\nin-context learning techniques can be used to align translations with\ndomain-specific preferences such as mitigating overtranslation, highlighting\nthe adaptability and utility of LLM-driven scientific translation. The code and\ntranslated articles are available at https:\/\/hankleid.github.io\/ProjectMundo."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04306",
    "c_title":[
      "EP240801a\/XRF 240801B: An X-ray Flash Detected by the Einstein Probe and\n  Implications of its Multiband Afterglow"
    ],
    "c_abstract":[
      "We present multiband observations and analysis of EP240801a, a low-energy,\nextremely soft gamma-ray burst (GRB) discovered on August 1, 2024 by the\nEinstein Probe (EP) satellite, with a weak contemporaneous signal also detected\nby Fermi\/GBM. Optical spectroscopy of the afterglow, obtained by GTC and Keck,\nidentified the redshift of $z = 1.6734$. EP240801a exhibits a burst duration of\n148 s in X-rays and 22.3 s in gamma-rays, with X-rays leading by 80.61 s.\nSpectral lag analysis indicates the gamma-ray signal arrived 8.3 s earlier than\nthe X-rays. Joint spectral fitting of EP\/WXT and Fermi\/GBM data yields an\nisotropic energy $E_{\\gamma,\\rm{iso}} = (5.57^{+0.54}_{-0.50})\\times\n10^{51}\\,\\rm{erg}$, a peak energy $E_{\\rm{peak}} =\n14.90^{+7.08}_{-4.71}\\,\\rm{keV}$, a fluence ratio $\\rm\nS(25-50\\,\\rm{keV})\/S(50-100\\,\\rm{keV}) = 1.67^{+0.74}_{-0.46}$, classifying\nEP240801a as an X-ray flash (XRF). The host-galaxy continuum spectrum, inferred\nusing Prospector, was used to correct its contribution for the observed\noutburst optical data. Unusual early $R$-band behavior and EP\/FXT observations\nsuggest multiple components in the afterglow. Three models are considered:\ntwo-component jet model, forward-reverse shock model and forward-shock model\nwith energy injection. Both three provide reasonable explanations. The\ntwo-component jet model and the energy injection model imply a relatively small\ninitial energy and velocity of the jet in the line of sight, while the\nforward-reverse shock model remains typical. Under the two-component jet model,\nEP240801a may resemble GRB 221009A (BOAT) if the bright narrow beam is viewed\non-axis. Therefore, EP240801a can be interpreted as an off-beam (narrow) jet or\nan intrinsically weak GRB jet. Our findings provide crucial clues for\nuncovering the origin of XRFs."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-17",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03870",
    "b_title":[
      "Add Noise, Tasks, or Layers? MaiNLP at the VarDial 2025 Shared Task on\n  Norwegian Dialectal Slot and Intent Detection"
    ],
    "b_abstract":[
      "Slot and intent detection (SID) is a classic natural language understanding\ntask. Despite this, research has only more recently begun focusing on SID for\ndialectal and colloquial varieties. Many approaches for low-resource scenarios\nhave not yet been applied to dialectal SID data, or compared to each other on\nthe same datasets. We participate in the VarDial 2025 shared task on slot and\nintent detection in Norwegian varieties, and compare multiple set-ups: varying\nthe training data (English, Norwegian, or dialectal Norwegian), injecting\ncharacter-level noise, training on auxiliary tasks, and applying Layer\nSwapping, a technique in which layers of models fine-tuned on different\ndatasets are assembled into a model. We find noise injection to be beneficial\nwhile the effects of auxiliary tasks are mixed. Though some experimentation was\nrequired to successfully assemble a model from layers, it worked surprisingly\nwell; a combination of models trained on English and small amounts of dialectal\ndata produced the most robust slot predictions. Our best models achieve 97.6%\nintent accuracy and 85.6% slot F1 in the shared task."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13990",
    "c_title":[
      "Variable smoothing algorithm for inner-loop-free DC composite\n  optimizations"
    ],
    "c_abstract":[
      "We propose a variable smoothing algorithm for minimizing a nonsmooth and\nnonconvex cost function. The cost function is the sum of a smooth function and\na composition of a difference-of-convex (DC) function with a smooth mapping. At\neach step of our algorithm, we generate a smooth surrogate function by using\nthe Moreau envelope of each weakly convex function in the DC function, and then\nperform the gradient descent update of the surrogate function. The proposed\nalgorithm does not require any inner loop unlike many existing algorithms for\nDC problem. We also present a convergence analysis in terms of a DC critical\npoint for the proposed algorithm as well as its application to robust phase\nretrieval."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-18",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12300",
    "b_title":[
      "On the Chermak-Delgado lattice of a finite group"
    ],
    "b_abstract":[
      "By imposing conditions upon the index of a self-centralizing subgroup of a\ngroup, and upon the index of the center of the group, we are able to classify\nthe Chermak-Delgado lattice of the group. This is our main result. We use this\nresult to classify the Chermak-Delgado lattices of dicyclic groups and of\nmetabelian $p$-groups of maximal class."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01563",
    "c_title":[
      "Massive Values in Self-Attention Modules are the Key to Contextual\n  Knowledge Understanding"
    ],
    "c_abstract":[
      "Large language models (LLMs) have achieved remarkable success in contextual\nknowledge understanding. In this paper, we show that these concentrated massive\nvalues consistently emerge in specific regions of attention queries (Q) and\nkeys (K) while not having such patterns in values (V) in various modern\ntransformer-based LLMs (Q, K, and V mean the representations output by the\nquery, key, and value layers respectively). Through extensive experiments, we\nfurther demonstrate that these massive values play a critical role in\ninterpreting contextual knowledge (knowledge obtained from the current context\nwindow) rather than in retrieving parametric knowledge stored within the\nmodel's parameters. Our further investigation of quantization strategies\nreveals that ignoring these massive values leads to a pronounced drop in\nperformance on tasks requiring rich contextual understanding, aligning with our\nanalysis. Finally, we trace the emergence of concentrated massive values and\nfind that such concentration is caused by Rotary Positional Encoding (RoPE),\nwhich has appeared since the first layers. These findings shed new light on how\nQ and K operate in LLMs and offer practical insights for model design and\noptimization. The Code is Available at\nhttps:\/\/github.com\/MingyuJ666\/Rope_with_LLM."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-19",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20008",
    "b_title":[
      "Joint Fusion and Encoding: Advancing Multimodal Retrieval from the\n  Ground Up"
    ],
    "b_abstract":[
      "Information retrieval is indispensable for today's Internet applications, yet\ntraditional semantic matching techniques often fall short in capturing the\nfine-grained cross-modal interactions required for complex queries. Although\nlate-fusion two-tower architectures attempt to bridge this gap by independently\nencoding visual and textual data before merging them at a high level, they\nfrequently overlook the subtle interplay essential for comprehensive\nunderstanding. In this work, we rigorously assess these limitations and\nintroduce a unified retrieval framework that fuses visual and textual cues from\nthe ground up, enabling early cross-modal interactions for enhancing context\ninterpretation. Through a two-stage training process--comprising post-training\nadaptation followed by instruction tuning--we adapt MLLMs as retrievers using a\nsimple one-tower architecture. Our approach outperforms conventional methods\nacross diverse retrieval scenarios, particularly when processing complex\nmulti-modal inputs. Notably, the joint fusion encoder yields greater\nimprovements on tasks that require modality fusion compared to those that do\nnot, underscoring the transformative potential of early integration strategies\nand pointing toward a promising direction for contextually aware and effective\ninformation retrieval."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07521",
    "c_title":[
      "Magnetically arrested disk flux eruption events to describe SgrA* flares"
    ],
    "c_abstract":[
      "Context. Magnetically arrested disks are among the most suitable candidates\nfor describing the gas accretion and observed emission in the vicinity of\nsupermassive black holes. Aims. This work aims to provide a direct correlation\nbetween the quasi-periodic flux eruption events, characteristic of MAD\naccretion disk simulations, and the observed flaring behavior in the Galactic\ncenter. Methods. We employ a MAD accretion disk with a distinct\ncounter-clockwise rotation and investigate the evolution of magnetized flux\ntubes generated during a prominent flux eruption event. Although these flux\ntubes demonstrate a clockwise pattern, they experience significant dragging by\nthe accretion disk's rotation. This study models the motion of hot spots,\nformed on the disk's equatorial plane due to magnetic reconnection, as they\ntravel along the magnetized flux tubes at a fraction of the speed of light.\nResults. Hot spots with a relativistic ejection velocity are able to balance\nout the counter-clockwise dragging of the flux tube's foot-point on the disk\nand demonstrate a clockwise motion in the sky, that is in good agreement with\nthe NIR flares in the Galactic center. In addition, our flare models favor\nface-on inclinations in the range $[0^\\circ, 34^\\circ]$ and $[163^\\circ,\n180^\\circ]$ for SgrA*. Conclusions. The flux eruption events that arise\nnaturally in the MAD accretion state provide a promising framework for\nreproducing the observed flaring behavior in the vicinity of SgrA*."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-20",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02520",
    "b_title":[
      "Predicting IoT Device Vulnerability Fix Times with Survival and Failure\n  Time Models"
    ],
    "b_abstract":[
      "The rapid integration of Internet of Things (IoT) devices into enterprise\nenvironments presents significant security challenges. Many IoT devices are\nreleased to the market with minimal security measures, often harbouring an\naverage of 25 vulnerabilities per device. To enhance cybersecurity measures and\naid system administrators in managing IoT patches more effectively, we propose\nan innovative framework that predicts the time it will take for a vulnerable\nIoT device to receive a fix or patch. We developed a survival analysis model\nbased on the Accelerated Failure Time (AFT) approach, implemented using the\nXGBoost ensemble regression model, to predict when vulnerable IoT devices will\nreceive fixes or patches. By constructing a comprehensive IoT vulnerabilities\ndatabase that combines public and private sources, we provide insights into\naffected devices, vulnerability detection dates, published CVEs, patch release\ndates, and associated Twitter activity trends. We conducted thorough\nexperiments evaluating different combinations of features, including\nfundamental device and vulnerability data, National Vulnerability Database\n(NVD) information such as CVE, CWE, and CVSS scores, transformed textual\ndescriptions into sentence vectors, and the frequency of Twitter trends related\nto CVEs. Our experiments demonstrate that the proposed model accurately\npredicts the time to fix for IoT vulnerabilities, with data from VulDB and NVD\nproving particularly effective. Incorporating Twitter trend data offered\nminimal additional benefit. This framework provides a practical tool for\norganisations to anticipate vulnerability resolutions, improve IoT patch\nmanagement, and strengthen their cybersecurity posture against potential\nthreats."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18896",
    "c_title":[
      "A notion of fractality for a class of states and noncommutative relative\n  distance zeta functional"
    ],
    "c_abstract":[
      "In this work, we first recall the definition of the relative distance zeta\nfunction in [36, 37, 38, 40, 41] and slightly generalize this notion from sets\nto probability measures, and then move on to propose a novel definition a\nrelative distance (and tube) zeta functional for a class of states over a C*\nalgebra. With such an extension, we look into the chance to define relative\nMinkowski dimensions in this context, and explore the notion of fractality for\nthis class of states. Relative complex dimensions as poles of this newly\nproposed relative distance zeta functional, as well as its geometric and\ntransformation properties, decomposition rules and properties that respects\ntensor products are discussed. We then explore some examples that possess\nfractal properties with this new zeta functional and propose functional\nequations similar to [9]."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-21",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02196",
    "b_title":[
      "CPTuning: Contrastive Prompt Tuning for Generative Relation Extraction"
    ],
    "b_abstract":[
      "Generative relation extraction (RE) commonly involves first reformulating RE\nas a linguistic modeling problem easily tackled with pre-trained language\nmodels (PLM) and then fine-tuning a PLM with supervised cross-entropy loss.\nAlthough having achieved promising performance, existing approaches assume only\none deterministic relation between each pair of entities without considering\nreal scenarios where multiple relations may be valid, i.e., entity pair\noverlap, causing their limited applications. To address this problem, we\nintroduce a novel contrastive prompt tuning method for RE, CPTuning, which\nlearns to associate a candidate relation between two in-context entities with a\nprobability mass above or below a threshold, corresponding to whether the\nrelation exists. Beyond learning schema, CPTuning also organizes RE as a\nverbalized relation generation task and uses Trie-constrained decoding to\nensure a model generates valid relations. It adaptively picks out the generated\ncandidate relations with a high estimated likelihood in inference, thereby\nachieving multi-relation extraction. We conduct extensive experiments on four\nwidely used datasets to validate our method. Results show that T5-large\nfine-tuned with CPTuning significantly outperforms previous methods, regardless\nof single or multiple relations extraction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11275",
    "c_title":[
      "High efficiency veto hadron calorimeter in the NA64 experiment at CERN"
    ],
    "c_abstract":[
      "NA64 is a fixed-target experiment at the CERN SPS designed to search for\nLight particle Dark Matter (LDM) candidates with masses in the sub-GeV range.\nDuring the 2016-2022 runs, the experiment obtained the world-leading\nconstraints, leaving however part of the well-motivated region of parameter\nspace suggested by benchmark LDM models still unexplored. To further improve\nsensitivity, as part of the upgrades to the setup of NA64 at the CERN SPS H4\nbeamline, a prototype veto hadron calorimeter (VHCAL) was installed in the\ndownstream region of the experiment during the 2023 run. The VHCAL, made of\nCu-Sc layers, was expected to be an efficient veto against upstream\nelectroproduction of large-angle hadrons or photon-nuclear interactions,\nreducing the background from secondary particles escaping the detector\nacceptance. With the collected statistics of $4.4\\times10^{11}$ electrons on\ntarget (EOT), we demonstrate the effectiveness of this approach by rejecting\nthis background by more than an order of magnitude. This result provides an\nessential input for designing a full-scale optimized VHCAL to continue running\nbackground-free during LHC Run 4, when we expect to collect $10^{13}$ EOT.\nFurthermore, this technique combined with improvements in the analysis enables\nus to decrease our missing energy threshold from 50 GeV to 40 GeV thereby\nenhancing the signal sensitivity of NA64."
    ],
    "c_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-22",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18013",
    "b_title":[
      "Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models\n  via Vision-Guided Reinforcement Learning"
    ],
    "b_abstract":[
      "Large Vision-Language Models (LVLMs) typically follow a two-stage training\nparadigm-pretraining and supervised fine-tuning. Recently, preference\noptimization, derived from the language domain, has emerged as an effective\npost-training reinforcement strategy to enhance capabilities of LVLMs. However,\nconstructing high-quality human-annotated preference data and developing robust\nreward models to mimic these preferences are both costly and challenging.\nMotivated by this observation, we propose Vision-R1, a novel vision-guided\nR1-like reinforcement learning algorithm for LVLMs that rewards models with\ndefinitive vision feedback. It only leverages curated instruction data,\neliminating the need for specialized reward models and handcrafted preference\ndatasets. We incorporate a criterion-driven reward function that further\nintegrates multi-dimensional feedback to evaluate model completions\ncomprehensively based on the vision task logic. Furthermore, we introduce a\nprogressive rule refinement strategy that dynamically adjusts the reward\ncriteria during training, enabling continuous model improvement and mitigating\nreward hacking. Extensive experiments on both in-distribution and\nout-of-distribution benchmarks demonstrate that fine-tuning the 7B LVLMs with\nVision-R1 achieves consistent performance gains, with even up to 50%\nimprovement and surpassing the state-of-the-art 10x size model."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15446",
    "c_title":[
      "Development and Performance Validation of a Versatile VLBI Digital\n  Backend Using the ROACH2 Platform"
    ],
    "c_abstract":[
      "Customized digital backends for Very Long Baseline Interferometry (VLBI) are\ncritical components for radio astronomy observatories. There are several\nserialized products such as the Digital Baseband Converter (DBBC),\nReconfigurable Open Architecture Computing Hardware (ROACH) Digital BackEnd\n(RDBE), and Chinese Data Acquisition System (CDAS). However, the reliance on\nhigh-speed analog-to-digital converters (ADC) and Field Programmable Gate\nArrays (FPGAs) often necessitates dedicated hardware platforms with long\ndevelopment cycles and prohibitive cost, limiting scalability and adaptability\nto evolving observational needs. To address these challenges, we propose a\ndesign leveraging the versatile and cost-effective ROACH2 hardware platform,\ndeveloped by CASPER (Collaboration for Astronomy Signal Processing and\nElectronics Research). ROACH2's mature technology and streamlined firmware\ndevelopment capabilities significantly reduce the hardware platform's\ndevelopment cycle and cost, making it ideal for modern astronomical\napplications. This VLBI digital backend, based on the ROACH2 platform,\nincorporates key technologies such as Polyphase Filter Banks (PFB) algorithm\nimplementation, digital complex-to-real baseband signal conversion, Mark5B data\nformatter design and two-bit optimal threshold quantization. These features\nensure compatibility with existing systems while providing enhanced\nperformance. The backend's performance was validated through multi-station VLBI\nexperiments, demonstrating its ability to achieve good correlation fringes\ncompared to the customized CDAS2-D system. Furthermore, this platform offers\nflexibility for rapid deployment of additional digital backends, such as those\nfor spectral line observations, showcasing its potential for broader\nastronomical applications."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-23",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06813",
    "b_title":[
      "Pareto Optimization with Robust Evaluation for Noisy Subset Selection"
    ],
    "b_abstract":[
      "Subset selection is a fundamental problem in combinatorial optimization,\nwhich has a wide range of applications such as influence maximization and\nsparse regression. The goal is to select a subset of limited size from a ground\nset in order to maximize a given objective function. However, the evaluation of\nthe objective function in real-world scenarios is often noisy. Previous\nalgorithms, including the greedy algorithm and multi-objective evolutionary\nalgorithms POSS and PONSS, either struggle in noisy environments or consume\nexcessive computational resources. In this paper, we focus on the noisy subset\nselection problem with a cardinality constraint, where the evaluation of a\nsubset is noisy. We propose a novel approach based on Pareto Optimization with\nRobust Evaluation for noisy subset selection (PORE), which maximizes a robust\nevaluation function and minimizes the subset size simultaneously. PORE can\nefficiently identify well-structured solutions and handle computational\nresources, addressing the limitations observed in PONSS. Our experiments,\nconducted on real-world datasets for influence maximization and sparse\nregression, demonstrate that PORE significantly outperforms previous methods,\nincluding the classical greedy algorithm, POSS, and PONSS. Further validation\nthrough ablation studies confirms the effectiveness of our robust evaluation\nfunction."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16580",
    "c_title":[
      "Procrustes Wasserstein Metric: A Modified Benamou-Brenier Approach with\n  Applications to Latent Gaussian Distributions"
    ],
    "c_abstract":[
      "We introduce a modified Benamou-Brenier type approach leading to a\nWasserstein type distance that allows global invariance, specifically,\nisometries, and we show that the problem can be summarized to orthogonal\ntransformations. This distance is defined by penalizing the action with a\ncostless movement of the particle that does not change the direction and speed\nof its trajectory. We show that for Gaussian distribution resume to measuring\nthe Euclidean distance between their ordered vector of eigenvalues and we show\na direct application in recovering Latent Gaussian distributions."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC",
        "math.PR",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-24",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00372",
    "b_title":[
      "Nucleolus Credit Assignment for Effective Coalitions in Multi-agent\n  Reinforcement Learning"
    ],
    "b_abstract":[
      "In cooperative multi-agent reinforcement learning (MARL), agents typically\nform a single grand coalition based on credit assignment to tackle a composite\ntask, often resulting in suboptimal performance. This paper proposed a\nnucleolus-based credit assignment grounded in cooperative game theory, enabling\nthe autonomous partitioning of agents into multiple small coalitions that can\neffectively identify and complete subtasks within a larger composite task.\nSpecifically, our designed nucleolus Q-learning could assign fair credits to\neach agent, and the nucleolus Q-operator provides theoretical guarantees with\ninterpretability for both learning convergence and the stability of the formed\nsmall coalitions. Through experiments on Predator-Prey and StarCraft scenarios\nacross varying difficulty levels, our approach demonstrated the emergence of\nmultiple effective coalitions during MARL training, leading to faster learning\nand superior performance in terms of win rate and cumulative rewards especially\nin hard and super-hard environments, compared to four baseline methods. Our\nnucleolus-based credit assignment showed the promise for complex composite\ntasks requiring effective subteams of agents."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17685",
    "c_title":[
      "Design of resilient structures by randomization and bistability"
    ],
    "c_abstract":[
      "This paper examines various ways of improving the impact resilience of\nprotective structures. Such structures' purpose is to dissipate an impact's\nenergy while avoiding cracking and failure. We have tested the reaction of\nplane elastic-brittle lattices to an impulse. Four topologies are compared:\nperiodic triangular, square, and hexagonal topologies, and aperiodic Penrose\ntopology. Then, structures with random variations of the links' stiffness, node\npositions, and random holes are compared. Combinations of these random factors\nare also considered, as well as the resilience of bistable elastic-brittle\nlattices with sacrificial links. Several parameters are introduced to measure\nthe structural resilience of the compared designs: (i) the amount of dissipated\nimpact energy, (ii) the size of broken clusters of links, and (iii) the spread\nof damage. The results suggest new routes for rationally designing protective\nstructures using nonperiodic topology, bistability, and structural randomness.\nIn particular, we find that some quantities of interest can be maximized by\ntuning the randomized design appropriately -- for example, randomly removing\n8\\% of links maximizes energy dissipation. We also find that randomization of\nbistable lattices can offer superior energy dissipation while reducing the\nconnectivity between broken clusters of links."
    ],
    "c_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-25",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17180",
    "b_title":[
      "Bound Domains"
    ],
    "b_abstract":[
      "How much energy is required to unbind baryons from the cosmological\nstructures that originally bind them? This tutorial article explains why trying\nto answer this question using just a halo model can be misleading. Instead, it\nrecommends parsing the universe into ``bound domains,'' which are the\ngravitationally bound structures that ultimately become widely separated\nislands as the universe evolves. It explains why a bound domain's potential\nwell was about as deep ~1 Gyr after the Big Bang as it is now, and it outlines\nhow future research might take advantage of a bound-domain approach to make\nprogress on some open questions about the baryon distributions in and around\ngalaxy groups and clusters."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06083",
    "c_title":[
      "T-CBF: Traversability-based Control Barrier Function to Navigate\n  Vertically Challenging Terrain"
    ],
    "c_abstract":[
      "Safety has been of paramount importance in motion planning and control\ntechniques and is an active area of research in the past few years. Most safety\nresearch for mobile robots target at maintaining safety with the notion of\ncollision avoidance. However, safety goes beyond just avoiding collisions,\nespecially when robots have to navigate unstructured, vertically challenging,\noff-road terrain, where vehicle rollover and immobilization is as critical as\ncollisions. In this work, we introduce a novel Traversability-based Control\nBarrier Function (T-CBF), in which we use neural Control Barrier Functions\n(CBFs) to achieve safety beyond collision avoidance on unstructured vertically\nchallenging terrain by reasoning about new safety aspects in terms of\ntraversability. The neural T-CBF trained on safe and unsafe observations\nspecific to traversability safety is then used to generate safe trajectories.\nFurthermore, we present experimental results in simulation and on a physical\nVerti-4 Wheeler (V4W) platform, demonstrating that T-CBF can provide\ntraversability safety while reaching the goal position. T-CBF planner\noutperforms previously developed planners by 30\\% in terms of keeping the robot\nsafe and mobile when navigating on real world vertically challenging terrain."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-26",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13793",
    "b_title":[
      "The link between Microstructural Heterogeneity, Diffusivity, and\n  Hydrogen Embrittlement"
    ],
    "b_abstract":[
      "Green hydrogen is likely to play a major role in decarbonising the aviation\nindustry. It is crucial to understand the effects of microstructure on hydrogen\nredistribution, which may be implicated in the embrittlement of candidate fuel\nsystem metals. We have developed a stochastic multiscale finite element\nmodelling framework that integrates micromechanical and hydrogen transport\nmodels, such that the dominant microstructural effects can be efficiently\naccounted for at millimetre length scales. Our results show that microstructure\nhas a significant effect on hydrogen localisation in elastically anisotropic\nmaterials, which exhibit an interesting interplay between microstructure and\nmillimetre-scale hydrogen redistribution at various loading rates. Considering\n316L stainless steel and nickel, a direct comparison of model predictions\nagainst experimental hydrogen embrittlement data reveals that the reported\nsensitivity to loading rate is strongly linked with rate-dependent grain scale\ndiffusion. These findings highlight the need to incorporate microstructural\ncharacteristics in the design of hydrogen resistant materials."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01521",
    "c_title":[
      "R2VF: A Two-Step Regularization Algorithm to Cluster Categories in GLMs"
    ],
    "c_abstract":[
      "Over recent decades, extensive research has aimed to overcome the restrictive\nunderlying assumptions required for a Generalized Linear Model to generate\naccurate and meaningful predictions. These efforts include regularizing\ncoefficients, selecting features, and clustering ordinal categories, among\nother approaches. Despite these advances, efficiently clustering nominal\ncategories in GLMs without incurring high computational costs remains a\nchallenge. This paper introduces Ranking to Variable Fusion (R2VF), a two-step\nmethod designed to efficiently fuse nominal and ordinal categories in GLMs. By\nfirst transforming nominal features into an ordinal framework via regularized\nregression and then applying variable fusion, R2VF strikes a balance between\nmodel complexity and interpretability. We demonstrate the effectiveness of R2VF\nthrough comparisons with other methods, highlighting its performance in\naddressing overfitting and finding a proper set of covariates."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-27",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05488",
    "b_title":[
      "KIEval: Evaluation Metric for Document Key Information Extraction"
    ],
    "b_abstract":[
      "Document Key Information Extraction (KIE) is a technology that transforms\nvaluable information in document images into structured data, and it has become\nan essential function in industrial settings. However, current evaluation\nmetrics of this technology do not accurately reflect the critical attributes of\nits industrial applications. In this paper, we present KIEval, a novel\napplication-centric evaluation metric for Document KIE models. Unlike prior\nmetrics, KIEval assesses Document KIE models not just on the extraction of\nindividual information (entity) but also of the structured information\n(grouping). Evaluation of structured information provides assessment of\nDocument KIE models that are more reflective of extracting grouped information\nfrom documents in industrial settings. Designed with industrial application in\nmind, we believe that KIEval can become a standard evaluation metric for\ndeveloping or applying Document KIE models in practice. The code will be\npublicly available."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13627",
    "c_title":[
      "Optimal compound downselection to promote diversity and parallel\n  chemistry"
    ],
    "c_abstract":[
      "Early stage drug discovery and molecular design projects often follow\niterative design-make-test cycles. The selection of which compounds to\nsynthesize from all possible candidate compounds is a complex decision inherent\nto these design cycles that must weigh multiple factors. We build upon the\nalgorithmic downselection framework SPARROW that considers synthetic cost,\nsynthetic feasibility, and compound utility, extending it to address additional\ncritical factors related to the risk of synthesis failure, molecular diversity,\nand parallel chemistry capabilities. These design considerations further align\nalgorithmic compound selection with the true complexity of this decision-making\nprocess, allowing SPARROW to capture a broader set of principles typically\nreliant on expert chemist intuition. The application of these formulations to\nan exemplary case study highlights SPARROW's ability to promote the selection\nof diverse batches of compounds whose syntheses are amenable to parallel\nchemistry."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-28",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14064",
    "b_title":[
      "AIGVE-Tool: AI-Generated Video Evaluation Toolkit with Multifaceted\n  Benchmark"
    ],
    "b_abstract":[
      "The rapid advancement in AI-generated video synthesis has led to a growth\ndemand for standardized and effective evaluation metrics. Existing metrics lack\na unified framework for systematically categorizing methodologies, limiting a\nholistic understanding of the evaluation landscape. Additionally, fragmented\nimplementations and the absence of standardized interfaces lead to redundant\nprocessing overhead. Furthermore, many prior approaches are constrained by\ndataset-specific dependencies, limiting their applicability across diverse\nvideo domains. To address these challenges, we introduce AIGVE-Tool\n(AI-Generated Video Evaluation Toolkit), a unified framework that provides a\nstructured and extensible evaluation pipeline for a comprehensive AI-generated\nvideo evaluation. Organized within a novel five-category taxonomy, AIGVE-Tool\nintegrates multiple evaluation methodologies while allowing flexible\ncustomization through a modular configuration system. Additionally, we propose\nAIGVE-Bench, a large-scale benchmark dataset created with five SOTA video\ngeneration models based on hand-crafted instructions and prompts. This dataset\nsystematically evaluates various video generation models across nine critical\nquality dimensions. Extensive experiments demonstrate the effectiveness of\nAIGVE-Tool in providing standardized and reliable evaluation results,\nhighlighting specific strengths and limitations of current models and\nfacilitating the advancements of next-generation AI-generated video techniques."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18083",
    "c_title":[
      "Polarization-Resolved Core Exciton Dynamics in LiF Using Attosecond\n  Transient Absorption Spectroscopy"
    ],
    "c_abstract":[
      "The ability to control absorption by modifying the polarization of light\npresents an exciting opportunity to experimentally determine the orbital\nalignment of absorption features. Here, attosecond extreme ultraviolet (XUV)\ntransient absorption spectroscopy is used to investigate the polarization\ndependence of core exciton dynamics in LiF thin films at the Li+ K edge. XUV\npulses excite electrons from the Li 1s core level into the conduction band,\nallowing for the formation of a p-orbital-like core exciton, aligned along the\nXUV light polarization axis. A sub-5 fs near-infrared (NIR) probe pulse then\narrives at variable time delays, perturbing the XUV-excited states and allowing\nthe coherence decay of the core exciton to be mapped. The coherence lifetimes\nare found to be ~2.4 +- 0.4 fs, which is attributed to a phonon-mediated\ndephasing mechanism as in previous core exciton studies. The differential\nabsorption features are also shown to be sensitive to the relative polarization\nof the XUV and NIR fields. The parallel NIR probe induces couplings between the\ninitial XUV-excited p-like bright exciton and s-like dark excitons. When\ncrossed pump and probe polarizations are used, the coupling between the bright\nand dark states is no longer dipole-allowed, and the transient absorption\nsignal associated with the coupling is suppressed by approximately 90%. This\ninterpretation is supported by simulations of a few-level model system, as well\nas analysis of the calculated band structure. The results indicate that laser\npolarization can serve as a powerful experimental tool for exploring the\norbital alignment of core excitonic states in solid-state materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.chem-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-29",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01515",
    "b_title":[
      "DiagrammaticLearning: A Graphical Language for Compositional Training\n  Regimes"
    ],
    "b_abstract":[
      "Motivated by deep learning regimes with multiple interacting yet distinct\nmodel components, we introduce learning diagrams, graphical depictions of\ntraining setups that capture parameterized learning as data rather than code. A\nlearning diagram compiles to a unique loss function on which component models\nare trained. The result of training on this loss is a collection of models\nwhose predictions ``agree\" with one another. We show that a number of popular\nlearning setups such as few-shot multi-task learning, knowledge distillation,\nand multi-modal learning can be depicted as learning diagrams. We further\nimplement learning diagrams in a library that allows users to build diagrams of\nPyTorch and Flux.jl models. By implementing some classic machine learning use\ncases, we demonstrate how learning diagrams allow practitioners to build\ncomplicated models as compositions of smaller components, identify\nrelationships between workflows, and manipulate models during or after\ntraining. Leveraging a category theoretic framework, we introduce a rigorous\nsemantics for learning diagrams that puts such operations on a firm\nmathematical foundation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06160",
    "c_title":[
      "Spin polarised quantised transport via one-dimensional nanowire-graphene\n  contacts"
    ],
    "c_abstract":[
      "Graphene spintronics offers a promising route to achieve low power 2D\nelectronics for next generation classical and quantum computation. As device\nlength scales are reduced to the limit of the electron mean free path, the\ntransport mechanism crosses over to the ballistic regime. However, ballistic\ntransport has yet to be shown in a graphene spintronic device, a necessary step\ntowards realising ballistic spintronics. Here, we report ballistic injection of\nspin polarised carriers via one-dimensional contacts between magnetic nanowires\nand a high mobility graphene channel. The nanowire-graphene interface defines\nan effective constriction that confines charge carriers over a length scale\nsmaller than that of their mean free path. This is evidenced by the observation\nof quantised conductance through the contacts with no applied magnetic field\nand a transition into the quantum Hall regime with increasing field strength.\nThese effects occur in the absence of any constriction in the graphene itself\nand occur across several devices with transmission probability in the range T =\n0.08 - 0.30."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-30",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11482",
    "b_title":[
      "DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free\n  Continual Learning"
    ],
    "b_abstract":[
      "Continual learning (CL) is essential for Large Language Models (LLMs) to\nadapt to evolving real-world demands, yet they are susceptible to catastrophic\nforgetting (CF). While traditional CF solutions rely on expensive data\nrehearsal, recent rehearsal-free methods employ model-based and\nregularization-based strategies to address this issue. However, these\napproaches often neglect the model's plasticity, which is crucial to achieving\noptimal performance on newly learned tasks. Consequently, a key challenge in CL\nis striking a balance between preserving plasticity and mitigating CF. To\ntackle this challenge, we propose the $\\textbf{D}$ecomposed\n$\\textbf{A}$ttention-based $\\textbf{T}$ask $\\textbf{A}$daptation (DATA), which\nexplicitly decouples and learns both task-specific and task-shared knowledge\nusing high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA\ndynamically adjusts the weights of adapters of different ranks based on their\nrelevance and distinction from previous tasks, allowing the model to acquire\nnew task-specific skills while effectively retaining previously learned\nknowledge. Specifically, we implement a decomposed component weighting strategy\ncomprising learnable components that collectively generate attention-based\nweights, allowing the model to integrate and utilize diverse knowledge from\neach DATA. Extensive experiments on three widely used benchmarks demonstrate\nthat our proposed method achieves state-of-the-art performance. Notably, our\napproach significantly enhances model plasticity and mitigates CF by extending\nlearnable components and employing stochastic restoration during training\niterations."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10210",
    "c_title":[
      "Light-based Chromatic Aberration Correction of Ultrafast Electron\n  Microscopes"
    ],
    "c_abstract":[
      "We propose and theoretically demonstrate a technique that allows one to\ncompensate for chromatic aberrations of traditional electron lenses in\nultrafast electron microscopes. The technique is based on space- and\ntime-dependent phase modulation of a pulsed electron beam using interaction\nwith a shaped pulsed ponderomotive lens. The energy-selective focal distance is\nreached by combining the electron temporal chirp with the time-dependent size\nof the effective potential, with which the electrons interact. As a result,\nchromatic aberration can be reduced by up to a factor of seven. This approach\npaves the way for advanced transverse and longitudinal wavefront shaping of\nelectrons in free space."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-31",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00868",
    "b_title":[
      "Gorenstein analogues of a projectivity criterion over group algebras"
    ],
    "b_abstract":[
      "We formulate and answer Gorenstein projective, flat, and injective analogues\nof a classical projectivity question for group rings under some mild additional\nassumptions. Although the original question, that was proposed by Jang-Hyun Jo\nin 2007, was for integral group rings, in this article, we deal with more\ngeneral commutative base rings. We make use of the vast developments that have\nhappened in the field of Gorenstein homological algebra over group rings in\nrecent years, and we also improve and generalize several existing results from\nthis area along the way."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06117",
    "c_title":[
      "NeuraLoc: Visual Localization in Neural Implicit Map with Dual\n  Complementary Features"
    ],
    "c_abstract":[
      "Recently, neural radiance fields (NeRF) have gained significant attention in\nthe field of visual localization. However, existing NeRF-based approaches\neither lack geometric constraints or require extensive storage for feature\nmatching, limiting their practical applications. To address these challenges,\nwe propose an efficient and novel visual localization approach based on the\nneural implicit map with complementary features. Specifically, to enforce\ngeometric constraints and reduce storage requirements, we implicitly learn a 3D\nkeypoint descriptor field, avoiding the need to explicitly store point-wise\nfeatures. To further address the semantic ambiguity of descriptors, we\nintroduce additional semantic contextual feature fields, which enhance the\nquality and reliability of 2D-3D correspondences. Besides, we propose\ndescriptor similarity distribution alignment to minimize the domain gap between\n2D and 3D feature spaces during matching. Finally, we construct the matching\ngraph using both complementary descriptors and contextual features to establish\naccurate 2D-3D correspondences for 6-DoF pose estimation. Compared with the\nrecent NeRF-based approaches, our method achieves a 3$\\times$ faster training\nspeed and a 45$\\times$ reduction in model storage. Extensive experiments on two\nwidely used datasets demonstrate that our approach outperforms or is highly\ncompetitive with other state-of-the-art NeRF-based visual localization methods.\nProject page:\n\\href{https:\/\/zju3dv.github.io\/neuraloc}{https:\/\/zju3dv.github.io\/neuraloc}"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-32",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13728",
    "b_title":[
      "Secure Federated Data Distillation"
    ],
    "b_abstract":[
      "Dataset Distillation (DD) is a powerful technique for reducing large datasets\ninto compact, representative synthetic datasets, accelerating Machine Learning\ntraining. However, traditional DD methods operate in a centralized manner,\nwhich poses significant privacy threats and reduces its applicability. To\nmitigate these risks, we propose a Secure Federated Data Distillation (SFDD)\nframework to decentralize the distillation process while preserving privacy.\nUnlike existing Federated Distillation techniques that focus on training global\nmodels with distilled knowledge, our approach aims to produce a distilled\ndataset without exposing local contributions. We leverage the\ngradient-matching-based distillation method, adapting it for a distributed\nsetting where clients contribute to the distillation process without sharing\nraw data. The central aggregator iteratively refines a synthetic dataset by\nintegrating client-side updates while ensuring data confidentiality. To make\nour approach resilient to inference attacks perpetrated by the server that\ncould exploit gradient updates to reconstruct private data, we create an\noptimized Local Differential Privacy approach, called LDPO-RLD. Furthermore, we\nassess the framework's resilience against malicious clients executing backdoor\nattacks (such as Doorping) and demonstrate robustness under the assumption of a\nsufficient number of participating clients. Our experimental results\ndemonstrate the effectiveness of SFDD and that the proposed defense concretely\nmitigates the identified vulnerabilities, with minimal impact on the\nperformance of the distilled dataset. By addressing the interplay between\nprivacy and federation in dataset distillation, this work advances the field of\nprivacy-preserving Machine Learning making our SFDD framework a viable solution\nfor sensitive data-sharing applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02887",
    "c_title":[
      "Variations on the Expectation Due to Changes in the Probability Measure"
    ],
    "c_abstract":[
      "Closed-form expressions are presented for the variation of the expectation of\na given function due to changes in the probability measure used for the\nexpectation. They unveil interesting connections with Gibbs probability\nmeasures, the mutual information, and the lautum information."
    ],
    "c_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT",
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-33",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19176",
    "b_title":[
      "Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer\n  Using Generative Artificial Intelligence"
    ],
    "b_abstract":[
      "Full-Field Digital Mammography (FFDM) is the primary imaging modality for\nroutine breast cancer screening; however, its effectiveness is limited in\npatients with dense breast tissue or fibrocystic conditions. Contrast-Enhanced\nSpectral Mammography (CESM), a second-level imaging technique, offers enhanced\naccuracy in tumor detection. Nonetheless, its application is restricted due to\nhigher radiation exposure, the use of contrast agents, and limited\naccessibility. As a result, CESM is typically reserved for select cases,\nleaving many patients to rely solely on FFDM despite the superior diagnostic\nperformance of CESM. While biopsy remains the gold standard for definitive\ndiagnosis, it is an invasive procedure that can cause discomfort for patients.\nWe introduce a multimodal, multi-view deep learning approach for virtual\nbiopsy, integrating FFDM and CESM modalities in craniocaudal and mediolateral\noblique views to classify lesions as malignant or benign. To address the\nchallenge of missing CESM data, we leverage generative artificial intelligence\nto impute CESM images from FFDM scans. Experimental results demonstrate that\nincorporating the CESM modality is crucial to enhance the performance of\nvirtual biopsy. When real CESM data is missing, synthetic CESM images proved\neffective, outperforming the use of FFDM alone, particularly in multimodal\nconfigurations that combine FFDM and CESM modalities. The proposed approach has\nthe potential to improve diagnostic workflows, providing clinicians with\naugmented intelligence tools to improve diagnostic accuracy and patient care.\nAdditionally, as a contribution to the research community, we publicly release\nthe dataset used in our experiments, facilitating further advancements in this\nfield."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09398",
    "c_title":[
      "Domain Overlapping Algorithm with Nonlinear Mapping for\n  Collocation-Based Solutions of Eigenvalue Problems"
    ],
    "c_abstract":[
      "This paper presents four novel domain decomposition algorithms integrated\nwith nonlinear mapping techniques to address collocation-based solutions of\neigenvalue problems involving sharp interfaces or steep gradients. The proposed\nmethods leverage the spectral accuracy of Chebyshev polynomials while\novercoming limitations of existing tools like Chebfun, particularly in\npreserving higher-order derivative continuity and enabling flexible node\nclustering near discontinuities. Key findings include the following: for\nalgorithm Performance: The one-point overlap method demonstrated significant\nimprovements over global mapping approaches, reducing required grid points by\norders of magnitude while maintaining spectral convergence. The two-point\noverlap method further methods generalized the approach, allowing arbitrary\nnode distributions and nonlinear mappings. These achieved exponential error\nreduction for Burgers equation) by combining Taylor expansions with Chebyshev\nderivatives in overlap regions. While Chebfun splitting strategy automates\ndomain decomposition, it enforces only C0 continuity, leading to discontinuous\nhigher derivatives. In contrast, the proposed algorithms preserved smoothness\nup to CN continuity, critical for eigenvalue problems in hydrodynamic stability\nand nonlinear BVPs. Validation on 3D channel flow with viscosity stratification\nand Burgers equation highlighted the methods robustness. For instance,\neigenvalue calculations for miscible core-annular flows matched prior results\nwhile resolving sharp viscosity gradients with fewer nodes."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math-ph",
        "math.MP",
        "math.NA",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-34",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04970",
    "b_title":[
      "Gradient-based Explanations for Deep Learning Survival Models"
    ],
    "b_abstract":[
      "Deep learning survival models often outperform classical methods in\ntime-to-event predictions, particularly in personalized medicine, but their\n\"black box\" nature hinders broader adoption. We propose a framework for\ngradient-based explanation methods tailored to survival neural networks,\nextending their use beyond regression and classification. We analyze the\nimplications of their theoretical assumptions for time-dependent explanations\nin the survival setting and propose effective visualizations incorporating the\ntemporal dimension. Experiments on synthetic data show that gradient-based\nmethods capture the magnitude and direction of local and global feature\neffects, including time dependencies. We introduce GradSHAP(t), a\ngradient-based counterpart to SurvSHAP(t), which outperforms SurvSHAP(t) and\nSurvLIME in a computational speed vs. accuracy trade-off. Finally, we apply\nthese methods to medical data with multi-modal inputs, revealing relevant\ntabular features and visual patterns, as well as their temporal dynamics."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.13026",
    "c_title":[
      "HiMTok: Learning Hierarchical Mask Tokens for Image Segmentation with\n  Large Multimodal Model"
    ],
    "c_abstract":[
      "The remarkable performance of large multimodal models (LMMs) has attracted\nsignificant interest from the image segmentation community. To align with the\nnext-token-prediction paradigm, current LMM-driven segmentation methods either\nuse object boundary points to represent masks or introduce special segmentation\ntokens, whose hidden states are decoded by a segmentation model requiring the\noriginal image as input. However, these approaches often suffer from inadequate\nmask representation and complex architectures, limiting the potential of LMMs.\nIn this work, we propose the Hierarchical Mask Tokenizer (HiMTok), which\nrepresents segmentation masks with up to 32 tokens and eliminates the need for\nthe original image during mask de-tokenization. HiMTok allows for compact and\ncoarse-to-fine mask representations, aligning well with the LLM\nnext-token-prediction paradigm and facilitating the direct acquisition of\nsegmentation capabilities. We develop a 3-stage training recipe for progressive\nlearning of segmentation and visual capabilities, featuring a hierarchical mask\nloss for effective coarse-to-fine learning. Additionally, we enable\nbidirectional information flow, allowing conversion between bounding boxes and\nmask tokens to fully leverage multi-task training potential. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross various segmentation tasks,while also enhancing visual grounding and\nmaintaining overall visual understanding."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-35",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11362",
    "b_title":[
      "On the exact order of the discrepancy of low discrepancy digital van der\n  Corput--Kronecker sequences"
    ],
    "b_abstract":[
      "In this paper we give the exact order of the discrepancy of the digital van\nder Corput--Kronecker sequences that are based on recent counterexamples of the\n$X$-adic Littlewood conjecture in positive characteristics. Our result supports\nonce again the well-established conjecture in the theory of uniform\ndistribution which states that $D^*_N\\leq c \\frac{\\log^s N}{N},\\,c>0$ is the\nbest possible upper bound for the star discrepancy $D^*_N$ of a sequence in\n$[0,1)^s$ or in other words for every sequence in $[0,1)^s$\n$\\limsup_{N\\to\\infty}ND^*_N\/\\log^s N>0$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07185",
    "c_title":[
      "Expansion-history preferences of DESI and external data"
    ],
    "c_abstract":[
      "We explore the origin of the preference of DESI Year-1 baryon acoustic\noscillation (BAO) measurements and external data from cosmic microwave\nbackground (CMB) and type Ia supernovae (SNIa) that dark energy behavior\ndeparts from that expected in the standard cosmological model with vacuum\nenergy ($\\Lambda$CDM). In our analysis, we allow a flexible scaling of the\nexpansion rate with redshift that nevertheless allows reasonably tight\nconstraints on the quantities of interest, and adopt and validate a simple yet\naccurate compression of the CMB data that allows us to constrain our\nphenomenological model of the expansion history. We find that data consistently\nshow a preference for a $\\sim$3-5% increase in the expansion rate at $z\\simeq\n0.5$ relative to that predicted by the standard $\\Lambda$CDM model, in\nexcellent agreement with results from the less flexible $(w_0, w_a)$\nparameterization which was used in previous analyses. Even though our model\nallows a departure from the best-fit $\\Lambda$CDM model at zero redshift, we\nfind no evidence for such a signal. We also find no evidence (at greater than\n1$\\sigma$ significance) for a departure of the expansion rate from the\n$\\Lambda$CDM predictions at higher redshifts for any of the data combinations\nthat we consider. Overall, our results strengthen the robustness of the\nfindings using the combination of DESI, CMB, and SNIa data to dark-energy\nmodeling assumptions."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-36",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04228",
    "b_title":[
      "Totally bounded ultrametric spaces and locally finite trees"
    ],
    "b_abstract":[
      "We investigate the interrelations between the metric properties, order\nproperties and combinatorial properties of the set of balls in totally bounded\nultrametric space. In particular, the Gurvich-Vyalyi representation of finite,\nultrametric spaces by monotone rooted trees is generalized to the case of\ntotally bounded ultrametric spaces. It is shown that such spaces have isometric\ncompletions if and only if their labeled representing trees are isomorphic. We\ncharacterize up to isomorphism the representing trees of these spaces and, up\nto order isomorphism, the posets of open balls in such spaces."
    ],
    "b_categories":[
      [
        "math.GN"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16753",
    "c_title":[
      "EarlyStopping: Implicit Regularization for Iterative Learning Procedures\n  in Python"
    ],
    "c_abstract":[
      "Iterative learning procedures are ubiquitous in machine learning and modern\nstatistics.\n  Regularision is typically required to prevent inflating the expected loss of\na procedure in\n  later iterations via the propagation of noise inherent in the data.\n  Significant emphasis has been placed on achieving this regularisation\nimplicitly by stopping\n  procedures early.\n  The EarlyStopping-package provides a toolbox of (in-sample) sequential early\nstopping rules for\n  several well-known iterative estimation procedures, such as truncated SVD,\nLandweber (gradient\n  descent), conjugate gradient descent, L2-boosting and regression trees.\n  One of the central features of the package is that the algorithms allow the\nspecification of the\n  true data-generating process and keep track of relevant theoretical\nquantities.\n  In this paper, we detail the principles governing the implementation of the\nEarlyStopping-package and provide\n  a survey of recent foundational advances in the theoretical literature.\n  We demonstrate how to use the EarlyStopping-package to explore core features\nof implicit regularisation\n  and replicate results from the literature."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.MS",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-37",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18276",
    "b_title":[
      "Learning Orientation Field for OSM-Guided Autonomous Navigation"
    ],
    "b_abstract":[
      "OpenStreetMap (OSM) has gained popularity recently in autonomous navigation\ndue to its public accessibility, lower maintenance costs, and broader\ngeographical coverage. However, existing methods often struggle with noisy OSM\ndata and incomplete sensor observations, leading to inaccuracies in trajectory\nplanning. These challenges are particularly evident in complex driving\nscenarios, such as at intersections or facing occlusions. To address these\nchallenges, we propose a robust and explainable two-stage framework to learn an\nOrientation Field (OrField) for robot navigation by integrating LiDAR scans and\nOSM routes. In the first stage, we introduce the novel representation, OrField,\nwhich can provide orientations for each grid on the map, reasoning jointly from\nnoisy LiDAR scans and OSM routes. To generate a robust OrField, we train a deep\nneural network by encoding a versatile initial OrField and output an optimized\nOrField. Based on OrField, we propose two trajectory planners for OSM-guided\nrobot navigation, called Field-RRT* and Field-Bezier, respectively, in the\nsecond stage by improving the Rapidly Exploring Random Tree (RRT) algorithm and\nBezier curve to estimate the trajectories. Thanks to the robustness of OrField\nwhich captures both global and local information, Field-RRT* and Field-Bezier\ncan generate accurate and reliable trajectories even in challenging conditions.\nWe validate our approach through experiments on the SemanticKITTI dataset and\nour own campus dataset. The results demonstrate the effectiveness of our\nmethod, achieving superior performance in complex and noisy conditions. Our\ncode for network training and real-world deployment is available at\nhttps:\/\/github.com\/IMRL\/OriField."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16475",
    "c_title":[
      "Symmetry- and Gradient-enhanced Gaussian Process Regression for the\n  Active Learning of Potential Energy Surfaces in Porous Materials"
    ],
    "c_abstract":[
      "The theoretical investigation of gas adsorption, storage, separation,\ndiffusion and related transport processes in porous materials relies on a\ndetailed knowledge of the potential energy surface of molecules in a stationary\nenvironment. In this article, a new algorithm is presented, specifically\ndeveloped for gas transport phenomena, which allows for a highly cost-effective\ndetermination of molecular potential energy surfaces. It is based on a\nsymmetry-enhanced version of Gaussian Process Regression with embedded gradient\ninformation and employs an active learning strategy to keep the number of\nsingle point evaluations as low as possible. The performance of the algorithm\nis tested for a selection of gas sieving scenarios on porous, N-functionalized\ngraphene and for the intermolecular interaction of CH$_4$ and N$_2$."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.chem-ph",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-38",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19680",
    "b_title":[
      "M-LLM Based Video Frame Selection for Efficient Video Understanding"
    ],
    "b_abstract":[
      "Recent advances in Multi-Modal Large Language Models (M-LLMs) show promising\nresults in video reasoning. Popular Multi-Modal Large Language Model (M-LLM)\nframeworks usually apply naive uniform sampling to reduce the number of video\nframes that are fed into an M-LLM, particularly for long context videos.\nHowever, it could lose crucial context in certain periods of a video, so that\nthe downstream M-LLM may not have sufficient visual information to answer a\nquestion. To attack this pain point, we propose a light-weight M-LLM -based\nframe selection method that adaptively select frames that are more relevant to\nusers' queries. In order to train the proposed frame selector, we introduce two\nsupervision signals (i) Spatial signal, where single frame importance score by\nprompting a M-LLM; (ii) Temporal signal, in which multiple frames selection by\nprompting Large Language Model (LLM) using the captions of all frame\ncandidates. The selected frames are then digested by a frozen downstream video\nM-LLM for visual reasoning and question answering. Empirical results show that\nthe proposed M-LLM video frame selector improves the performances various\ndownstream video Large Language Model (video-LLM) across medium (ActivityNet,\nNExT-QA) and long (EgoSchema, LongVideoBench) context video question answering\nbenchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06913",
    "c_title":[
      "Data-Driven Sequential Sampling for Tail Risk Mitigation"
    ],
    "c_abstract":[
      "Given a finite collection of stochastic alternatives, we study the problem of\nsequentially allocating a fixed sampling budget to identify the optimal\nalternative with a high probability, where the optimal alternative is defined\nas the one with the smallest value of extreme tail risk. We particularly\nconsider a situation where these alternatives generate heavy-tailed losses\nwhose probability distributions are unknown and may not admit any specific\nparametric representation. In this setup, we propose data-driven sequential\nsampling policies that maximize the rate at which the likelihood of falsely\nselecting suboptimal alternatives decays to zero. We rigorously demonstrate the\nsuperiority of the proposed methods over existing approaches, which is further\nvalidated via numerical studies."
    ],
    "c_categories":[
      [
        "math.OC",
        "stat.ME",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-39",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12504",
    "b_title":[
      "Shapes of unit lattices in $D_p$-number fields"
    ],
    "b_abstract":[
      "The unit group of the ring of integers of a number field, modulo torsion, is\na lattice via the logarithmic Minkowski embedding. We examine the shape of this\nlattice, which we call the unit shape, within the family of prime degree $p$\nnumber fields whose Galois closure has dihedral Galois group $D_p$ and a unique\nreal embedding. In the case $p = 5$, we prove that the unit shapes lie on a\nsingle hypercycle on the modular surface (in this case, the modular surface is\nthe space of shapes of rank $2$ lattices). For general $p$, we show that the\nunit shapes are contained in a finite union of translates of periodic torus\norbits in the space of shapes."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06847",
    "c_title":[
      "A Deep Learning Framework Integrating CNN and BiLSTM for Financial\n  Systemic Risk Analysis and Prediction"
    ],
    "c_abstract":[
      "This study proposes a deep learning model based on the combination of\nconvolutional neural network (CNN) and bidirectional long short-term memory\nnetwork (BiLSTM) for discriminant analysis of financial systemic risk. The\nmodel first uses CNN to extract local patterns of multidimensional features of\nfinancial markets, and then models the bidirectional dependency of time series\nthrough BiLSTM, to comprehensively characterize the changing laws of systemic\nrisk in spatial features and temporal dynamics. The experiment is based on real\nfinancial data sets. The results show that the model is significantly superior\nto traditional single models (such as BiLSTM, CNN, Transformer, and TCN) in\nterms of accuracy, recall, and F1 score. The F1-score reaches 0.88, showing\nextremely high discriminant ability. This shows that the joint strategy of\ncombining CNN and BiLSTM can not only fully capture the complex patterns of\nmarket data but also effectively deal with the long-term dependency problem in\ntime series data. In addition, this study also explores the robustness of the\nmodel in dealing with data noise and processing high-dimensional data,\nproviding strong support for intelligent financial risk management. In the\nfuture, the research will further optimize the model structure, introduce\nmethods such as reinforcement learning and multimodal data analysis, and\nimprove the efficiency and generalization ability of the model to cope with a\nmore complex financial environment."
    ],
    "c_categories":[
      [
        "cs.CE",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-40",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03763",
    "b_title":[
      "3D Printable Gradient Lattice Design for Multi-Stiffness Robotic Fingers"
    ],
    "b_abstract":[
      "Human fingers achieve exceptional dexterity and adaptability by combining\nstructures with varying stiffness levels, from soft tissues (low) to tendons\nand cartilage (medium) to bones (high). This paper explores developing a\nrobotic finger with similar multi-stiffness characteristics. Specifically, we\npropose using a lattice configuration, parameterized by voxel size and unit\ncell geometry, to optimize and achieve fine-tuned stiffness properties with\nhigh granularity. A significant advantage of this approach is the feasibility\nof 3D printing the designs in a single process, eliminating the need for manual\nassembly of elements with differing stiffness. Based on this method, we present\na novel, human-like finger, and a soft gripper. We integrate the latter with a\nrigid manipulator and demonstrate the effectiveness in pick and place tasks."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18761",
    "c_title":[
      "Probabilistic Joint Recovery Method for CO$_2$ Plume Monitoring"
    ],
    "c_abstract":[
      "Reducing CO$_2$ emissions is crucial to mitigating climate change. Carbon\nCapture and Storage (CCS) is one of the few technologies capable of achieving\nnet-negative CO$_2$ emissions. However, predicting fluid flow patterns in CCS\nremains challenging due to uncertainties in CO$_2$ plume dynamics and reservoir\nproperties. Building on existing seismic imaging methods like the Joint\nRecovery Method (JRM), which lacks uncertainty quantification, we propose the\nProbabilistic Joint Recovery Method (pJRM). By estimating posterior\ndistributions across surveys using a shared generative model, pJRM provides\nuncertainty information to improve risk assessment in CCS projects."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-41",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01847",
    "b_title":[
      "Complete function space for planar two-loop six-particle scattering\n  amplitudes"
    ],
    "b_abstract":[
      "We derive the full system of canonical differential equations for all planar\ntwo-loop massless six-particle master integrals, and determine analytically the\nboundary conditions. This fully specifies the solutions, which may be written\nas Chen iterated integrals. We argue that this is sufficient information for\nevaluating any scattering amplitude in four dimensions up to the finite part.\nWe support this claim by reducing, for the most complicated integral\ntopologies, integrals with typical Yang-Mills numerators. We use the analytic\nsolutions to the differential equations, together with dihedral symmetry, to\nprovide the full solution space relevant for two-loop six-particle\ncomputations. This includes the relevant function alphabet, as well as the\nindependent set of iterated integrals up to weight four. We also provide the\nanswer for all master integrals in terms of iterated integrals that can be\nreadily evaluated numerically. As a proof of concept, we provide a numerical\nimplementation that evaluates the integrals in part of the Euclidean region,\nand validate this against numerical evaluation of the Feynman integrals. Our\nresult removes the bottleneck of Feynman integral evaluation, paving the way to\nfuture analytic evaluations of six-particle scattering amplitudes."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.19178",
    "c_title":[
      "No Foundations without Foundations -- Why semi-mechanistic models are\n  essential for regulatory biology"
    ],
    "c_abstract":[
      "Despite substantial efforts, deep learning has not yet delivered a\ntransformative impact on elucidating regulatory biology, particularly in the\nrealm of predicting gene expression profiles. Here, we argue that genuine\n\"foundation models\" of regulatory biology will remain out of reach unless\nguided by frameworks that integrate mechanistic insight with principled\nexperimental design. We present one such ground-up, semi-mechanistic framework\nthat unifies perturbation-based experimental designs across both in vitro and\nin vivo CRISPR screens, accounting for differentiating and non-differentiating\ncellular systems. By revealing previously unrecognised assumptions in published\nmachine learning methods, our approach clarifies links with popular techniques\nsuch as variational autoencoders and structural causal models. In practice,\nthis framework suggests a modified loss function that we demonstrate can\nimprove predictive performance, and further suggests an error analysis that\ninforms batching strategies. Ultimately, since cellular regulation emerges from\ninnumerable interactions amongst largely uncharted molecular components, we\ncontend that systems-level understanding cannot be achieved through structural\nbiology alone. Instead, we argue that real progress will require a\nfirst-principles perspective on how experiments capture biological phenomena,\nhow data are generated, and how these processes can be reflected in more\nfaithful modelling architectures."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-42",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14873",
    "b_title":[
      "Refining local-type primordial non-Gaussianity: Sharpened $b_\\phi$\n  constraints through bias expansion"
    ],
    "b_abstract":[
      "Local-type primordial non-Gaussianity (PNG), predicted by many non-minimal\nmodels of inflation, creates a scale-dependent contribution to the power\nspectrum of large-scale structure (LSS) tracers. Its amplitude is characterized\nby the product $b_\\phi f_{\\rm NL}^{\\rm loc}$, where $b_\\phi$ is an\nastrophysical parameter dependent on the properties of the tracer. However,\n$b_\\phi$ exhibits significant secondary dependence on halo concentration and\nother astrophysical properties, which may bias and weaken the constraints on\n$f_{\\rm NL}^{\\rm loc}$. In this work, we demonstrate that incorporating\nknowledge of the relation between Lagrangian bias parameters and $b_\\phi$ can\nsignificantly enhance PNG constraints. We employ the Hybrid Effective Field\nTheory (HEFT) approach at the field-level and a linear regression model to seek\na connection between the bias parameters and $b_{\\phi}$ for halo and galaxy\nsamples, constructed using the \\textsc{AbacusSummit} simulation suite and\nmimicking the luminous red galaxies (LRGs) and quasi-stellar objects (QSOs) of\nthe Dark Energy Spectroscopic Instrument (DESI) survey. For the fixed-mass halo\nsamples, our full bias model reduces the uncertainty by more than 70\\%, with\nmost of that improvement coming from $b_\\nabla$, which we find to be an\nexcellent proxy for concentration. For the galaxy samples, our model reduces\nthe uncertainty on $b_\\phi$ by 80\\% for all tracers. By adopting\nLagrangian-bias informed priors on the parameter $b_\\phi$, future analyses can\nthus constrain $f_{\\rm NL}^{\\rm loc}$ with less bias and smaller errors."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02311",
    "c_title":[
      "Target Return Optimizer for Multi-Game Decision Transformer"
    ],
    "c_abstract":[
      "Achieving autonomous agents with robust generalization capabilities across\ndiverse games and tasks remains one of the ultimate goals in AI research.\nRecent advancements in transformer-based offline reinforcement learning,\nexemplified by the MultiGame Decision Transformer [Lee et al., 2022], have\nshown remarkable performance across various games or tasks. However, these\napproaches depend heavily on human expertise, presenting substantial challenges\nfor practical deployment, particularly in scenarios with limited prior\ngame-specific knowledge. In this paper, we propose an algorithm called\nMulti-Game Target Return Optimizer (MTRO) to autonomously determine\ngame-specific target returns within the Multi-Game Decision Transformer\nframework using solely offline datasets. MTRO addresses the existing\nlimitations by automating the target return configuration process, leveraging\nenvironmental reward information extracted from offline datasets. Notably, MTRO\ndoes not require additional training, enabling seamless integration into\nexisting Multi-Game Decision Transformer architectures. Our experimental\nevaluations on Atari games demonstrate that MTRO enhances the performance of RL\npolicies across a wide array of games, underscoring its potential to advance\nthe field of autonomous agent development."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-43",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16955",
    "b_title":[
      "HEART: A New X-Ray Tracing Code for Mosaic Crystal Spectrometers"
    ],
    "b_abstract":[
      "We introduce a new open-source Python x-ray tracing code for modelling Bragg\ndiffracting mosaic crystal spectrometers: High Energy Applications Ray Tracer\n(HEART). HEART's high modularity enables customizable workflows as well as\nefficient development of novel features. Utilizing Numba's just-in-time (JIT)\ncompiler and the message-passing interface (MPI) allows running HEART in\nparallel leading to excellent performance. HEART is intended to be used for\nmodelling x-ray spectra as they would be seen in experiments that measure x-ray\nspectroscopy with a mosaic crystal spectrometer. This enables the user to, for\nexample, make predictions about what will be seen on a detector in experiment,\nperform optimizations on the design of the spectrometer setup, or to study the\neffect of the spectrometer on measured spectra. However, the code certainly has\nfurther uses beyond these example use cases. Here, we discuss the physical\nmodel used in the code, and explore a number of different mosaic distribution\nfunctions, intrinsic rocking curves, and sampling approaches which are\navailable to the user. Finally, we demonstrate its strong predictive capability\nin comparison to spectroscopic data collected at the European XFEL in Germany."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10837",
    "c_title":[
      "In the graphical Sierpinski gasket, the reverse Riesz transform is\n  unbounded on $L^p$, $p\\in (1,2)$"
    ],
    "c_abstract":[
      "In this article, we proved that the reverse Riesz transform on the graphical\nSierpinski gasket is unbounded on $L^p$ for $p\\in (1,2)$. Together with\nprevious results, it shows that the Riesz transform on the graphical Sierpinski\ngasket is bounded on $L^p$ if and only if $p\\in (1,2]$ and the reverse Riesz\ntransform is bounded on $L^p$ if and only if $p\\in [2,\\infty)$.\n  Moreover, our method is quite flexible - but requires explicit computations -\nand hints to the fact that the reverse Riesz transforms is never bounded on\n$L^p$, $p\\in (1,2)$, on graphs with slow diffusions."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-44",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12146",
    "b_title":[
      "Divisors of an Integer in a Short Interval"
    ],
    "b_abstract":[
      "Let $\\mathcal{D}_{n} \\subset \\mathbb{N}$ denote the set of the $\\tau(n)$\ndivisors of $n$. We study the function $$ D_{n}(X,Y):=|\\{d \\in\n\\mathcal{D}_{n}:\\ X \\le d \\le X+Y\\}| $$ for $Y \\le X$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09042",
    "c_title":[
      "CookingDiffusion: Cooking Procedural Image Generation with Stable\n  Diffusion"
    ],
    "c_abstract":[
      "Recent advancements in text-to-image generation models have excelled in\ncreating diverse and realistic images. This success extends to food imagery,\nwhere various conditional inputs like cooking styles, ingredients, and recipes\nare utilized. However, a yet-unexplored challenge is generating a sequence of\nprocedural images based on cooking steps from a recipe. This could enhance the\ncooking experience with visual guidance and possibly lead to an intelligent\ncooking simulation system. To fill this gap, we introduce a novel task called\n\\textbf{cooking procedural image generation}. This task is inherently\ndemanding, as it strives to create photo-realistic images that align with\ncooking steps while preserving sequential consistency. To collectively tackle\nthese challenges, we present \\textbf{CookingDiffusion}, a novel approach that\nleverages Stable Diffusion and three innovative Memory Nets to model procedural\nprompts. These prompts encompass text prompts (representing cooking steps),\nimage prompts (corresponding to cooking images), and multi-modal prompts\n(mixing cooking steps and images), ensuring the consistent generation of\ncooking procedural images. To validate the effectiveness of our approach, we\npreprocess the YouCookII dataset, establishing a new benchmark. Our\nexperimental results demonstrate that our model excels at generating\nhigh-quality cooking procedural images with remarkable consistency across\nsequential cooking steps, as measured by both the FID and the proposed Average\nProcedure Consistency metrics. Furthermore, CookingDiffusion demonstrates the\nability to manipulate ingredients and cooking methods in a recipe. We will make\nour code, models, and dataset publicly accessible."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-45",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04737",
    "b_title":[
      "Network and Kinetics-based Biosignatures: Implications for the Putative\n  Habitable World Observatory Design"
    ],
    "b_abstract":[
      "The proposed Habitable Worlds Observatory is intended to observe the\natmospheres of nearby terrestrial exoplanets with a resolution greater than\nthat of any previous instrument. While these observations present a substantial\nopportunity for astrobiology, they also incur the risk of false positives and\nfalse negatives. Here, we explore the use of systems science (in the form of\nnetwork theory and thermochemical kinetics) to mitigate these risks, and\nbriefly describe the technical specifications HWO would require in order to use\nthese methodologies."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06020",
    "c_title":[
      "Temporal Working Memory: Query-Guided Segment Refinement for Enhanced\n  Multimodal Understanding"
    ],
    "c_abstract":[
      "Multimodal foundation models (MFMs) have demonstrated significant success in\ntasks such as visual captioning, question answering, and image-text retrieval.\nHowever, these models face inherent limitations due to their finite internal\ncapacity, which restricts their ability to process extended temporal sequences,\na crucial requirement for comprehensive video and audio analysis. To overcome\nthese challenges, we introduce a specialized cognitive module, temporal working\nmemory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.\nIt selectively retains task-relevant information across temporal dimensions,\nensuring that critical details are preserved throughout the processing of video\nand audio content. The TWM uses a query-guided attention approach to focus on\nthe most informative multimodal segments within temporal sequences. By\nretaining only the most relevant content, TWM optimizes the use of the model's\nlimited capacity, enhancing its temporal modeling ability. This plug-and-play\nmodule can be easily integrated into existing MFMs. With our TWM, nine\nstate-of-the-art models exhibit significant performance improvements across\ntasks such as video captioning, question answering, and video-text retrieval.\nBy enhancing temporal modeling, TWM extends the capability of MFMs to handle\ncomplex, time-sensitive data effectively. Our code is available at\nhttps:\/\/github.com\/xid32\/NAACL_2025_TWM."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-46",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15988",
    "b_title":[
      "Rovibrational Overtone and Combination Bands of the HCNH+ Ion"
    ],
    "b_abstract":[
      "Spectra of vibrational overtone and combination bands from vibrational ground\nstate of HCNH+ were measured using an action spectroscopy technique with active\nbackground suppression in a cryogenic 22 pole radio frequency ion trap\napparatus. Spectroscopic constants for the upper vibrational levels of the\ntransitions were determined with vibrational band origins being 6846.77981(90)\n$\\text{cm}^{-1}$ ($2\\nu_1$ , NH stretch), 6640.47624(43) $\\text{cm}^{-1}$\n($\\nu_1 + \\nu_2$), 6282.03578(63) $\\text{cm}^{-1}$ ($2\\nu_2$, CH stretch), and\n6588.4894(20) $\\text{cm}^{-1}$ ($\\nu_2 + \\nu_3 + 2\\nu_5^0$). State of the art\nab initio VCI calculations up to 10000 $\\text{cm}^{-1}$ complement the\nexperimental data."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07766",
    "c_title":[
      "SegResMamba: An Efficient Architecture for 3D Medical Image Segmentation"
    ],
    "c_abstract":[
      "The Transformer architecture has opened a new paradigm in the domain of deep\nlearning with its ability to model long-range dependencies and capture global\ncontext and has outpaced the traditional Convolution Neural Networks (CNNs) in\nmany aspects. However, applying Transformer models to 3D medical image datasets\npresents significant challenges due to their high training time, and memory\nrequirements, which not only hinder scalability but also contribute to elevated\nCO$_2$ footprint. This has led to an exploration of alternative models that can\nmaintain or even improve performance while being more efficient and\nenvironmentally sustainable. Recent advancements in Structured State Space\nModels (SSMs) effectively address some of the inherent limitations of\nTransformers, particularly their high memory and computational demands.\nInspired by these advancements, we propose an efficient 3D segmentation model\nfor medical imaging called SegResMamba, designed to reduce computation\ncomplexity, memory usage, training time, and environmental impact while\nmaintaining high performance. Our model uses less than half the memory during\ntraining compared to other state-of-the-art (SOTA) architectures, achieving\ncomparable performance with significantly reduced resource demands."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-47",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08398",
    "b_title":[
      "Physically motivated analytic model of energy efficiency for EUV-driven\n  atmospheric escape of close-in exoplanets"
    ],
    "b_abstract":[
      "Extreme Ultraviolet (EUV) driven atmospheric escape is a key process in the\natmospheric evolution of close-in exoplanets. In many evolutionary models, the\nenergy-limited mass-loss rate with a constant efficiency (typically $\\sim10\\%$)\nis assumed for calculating the mass-loss rate. However, hydrodynamic\nsimulations have demonstrated that this efficiency depends on various stellar\nand planetary parameters. Comprehending the underlying physics of the\nefficiency is essential for understanding planetary atmospheric evolution and\nrecent observations of the upper atmosphere of close-in exoplanets. We\nintroduce relevant temperatures and timescales derived from physical principles\nto elucidate the mass-loss process. Our analytical mass-loss model is based on\nphenomenology and consistent across a range of planetary parameters. We compare\nour mass-loss efficiency and the radiation hydrodynamic simulations. The model\ncan predict efficiency in both energy-limited and recombination-limited\nregimes. We further apply our model to exoplanets observed with hydrogen\nabsorption (Ly$\\alpha$ and H$\\alpha$). Our findings suggest that Ly$\\alpha$\nabsorption is detectable in planets subjected to intermediate EUV flux; under\nthese conditions, the escaping outflow is insufficient in low-EUV environments,\nwhile the photoionization timescale remains short in high-EUV ranges.\nConversely, H$\\alpha$ absorption is detectable under high EUV flux conditions,\nfacilitated by the intense Ly$\\alpha$ flux exciting hydrogen atoms. According\nto our model, the non-detection of neutral hydrogen can be explained by a low\nmass-loss rate and is not necessarily due to stellar wind confinement or the\nabsence of a hydrogen-dominated atmosphere in many cases. This model assists in\nidentifying future observational targets and explicates the unusual absorption\ndetection\/non-detection patterns observed in recent studies."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09302",
    "c_title":[
      "Detecting and Preventing Data Poisoning Attacks on AI Models"
    ],
    "c_abstract":[
      "This paper investigates the critical issue of data poisoning attacks on AI\nmodels, a growing concern in the ever-evolving landscape of artificial\nintelligence and cybersecurity. As advanced technology systems become\nincreasingly prevalent across various sectors, the need for robust defence\nmechanisms against adversarial attacks becomes paramount. The study aims to\ndevelop and evaluate novel techniques for detecting and preventing data\npoisoning attacks, focusing on both theoretical frameworks and practical\napplications. Through a comprehensive literature review, experimental\nvalidation using the CIFAR-10 and Insurance Claims datasets, and the\ndevelopment of innovative algorithms, this paper seeks to enhance the\nresilience of AI models against malicious data manipulation. The study explores\nvarious methods, including anomaly detection, robust optimization strategies,\nand ensemble learning, to identify and mitigate the effects of poisoned data\nduring model training. Experimental results indicate that data poisoning\nsignificantly degrades model performance, reducing classification accuracy by\nup to 27% in image recognition tasks (CIFAR-10) and 22% in fraud detection\nmodels (Insurance Claims dataset). The proposed defence mechanisms, including\nstatistical anomaly detection and adversarial training, successfully mitigated\npoisoning effects, improving model robustness and restoring accuracy levels by\nan average of 15-20%. The findings further demonstrate that ensemble learning\ntechniques provide an additional layer of resilience, reducing false positives\nand false negatives caused by adversarial data injections."
    ],
    "c_categories":[
      [
        "cs.CR",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-48",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08834",
    "b_title":[
      "Smart Contract Fuzzing Towards Profitable Vulnerabilities"
    ],
    "b_abstract":[
      "Billions of dollars are transacted through smart contracts, making\nvulnerabilities a major financial risk. One focus in the security arms race is\non profitable vulnerabilities that attackers can exploit. Fuzzing is a key\nmethod for identifying these vulnerabilities. However, current solutions face\ntwo main limitations: a lack of profit-centric techniques for expediting\ndetection, and insufficient automation in maximizing the profitability of\ndiscovered vulnerabilities, leaving the analysis to human experts. To address\nthese gaps, we have developed VERITE, a profit-centric smart contract fuzzing\nframework that not only effectively detects those profitable vulnerabilities\nbut also maximizes the exploited profits.\n  VERITE has three key features: 1) DeFi action-based mutators for boosting the\nexploration of transactions with different fund flows; 2) potentially\nprofitable candidates identification criteria, which checks whether the input\nhas caused abnormal fund flow properties during testing; 3) a gradient\ndescent-based profit maximization strategy for these identified candidates.\n  VERITE is fully developed from scratch and evaluated on a dataset consisting\nof 61 exploited real-world DeFi projects with an average of over 1.1 million\ndollars loss. The results show that VERITE can automatically extract more than\n18 million dollars in total and is significantly better than state-of-the-art\nfuzzer ITYFUZZ in both detection (29\/10) and exploitation (134 times more\nprofits gained on average). Remarkably, in 12 targets, it gains more profits\nthan real-world attacking exploits (1.01 to 11.45 times more). VERITE is also\napplied by auditors in contract auditing, where 6 (5 high severity) zero-day\nvulnerabilities are found with over $2,500 bounty rewards."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15041",
    "c_title":[
      "Study of long-term spectral evolution and X-ray and Gamma-ray\n  correlation of blazars seen by HAWC"
    ],
    "c_abstract":[
      "The HAWC Observatory collected 6 years of extensive data, providing an ideal\nplatform for long-term monitoring of blazars in the Very High Energy (VHE)\nband, without bias towards specific flux states. HAWC continuously monitors\nblazar activity at TeV energies, focusing on sources with a redshift of {z \\lt\n0.3}, based on the Third Fermi-LAT Catalog of High-Energy sources. We\nspecifically focused our analysis on Mrk 421 and Mrk 501, as they are the\nbrightest blazars observed by the HAWC Observatory. With a dataset of 2143\ndays, this work significantly extends the monitoring previously published,\nwhich was based on 511 days of observation. By utilizing HAWC data for the VHE\n{\\gamma}-ray emission in the 300 GeV to 100 TeV energy range, in conjunction\nwith Swift-XRT data for the 0.3 to 10 keV X-ray emission, we aim to explore\npotential correlations between these two bands. For Mrk 501, we found evidence\nof a long-term correlation. Additionally, we identified a period in the light\ncurve where the flux was very low for more than two years. On the other hand,\nour analysis of Mrk 421 measured a strong linear correlation for\nquasi-simultaneous observations collected by HAWC and Swift-XRT. This result is\nconsistent with a linear dependence and a multiple-zone synchrotron\nself-Compton model to explain the X-ray and the {\\gamma}-ray emission. Finally,\nas suggested by previous findings, we confirm a harder-when-brighter behavior\nin the spectral evolution of the flux properties for Mrk 421. These findings\ncontribute to the understanding of blazar emissions and their underlying\nmechanisms."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-49",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05340",
    "b_title":[
      "Robust valuation and optimal harvesting of forestry resources in the\n  presence of catastrophe risk and parameter uncertainty"
    ],
    "b_abstract":[
      "We determine forest lease value and optimal harvesting strategies under model\nparameter uncertainty within stochastic bio-economic models that account for\ncatastrophe risk. Catastrophic events are modeled as a Poisson point process,\nwith a two-factor stochastic convenience yield model capturing the lumber spot\nprice dynamics. Using lumber futures and US wildfire data, we estimate model\nparameters through a Kalman filter and maximum likelihood estimation and define\nthe model parameter uncertainty set as the 95% confidence region. We\nnumerically determine the forest lease value under catastrophe risk and\nparameter uncertainty using reflected backward stochastic differential\nequations (RBSDEs) and establish conservative and optimistic bounds for lease\nvalues and optimal stopping boundaries for harvesting, facilitating Monte Carlo\nsimulations. Numerical experiments further explore how parameter uncertainty,\ncatastrophe intensity, and carbon sequestration impact the lease valuation and\nharvesting decision. In particular, we explore the costs arising from this form\nof uncertainty in the form of a reduction of the lease value. These are\nimplicit costs that can be attributed to climate risk and will be emphasized\nthrough the importance of forestry resources in the energy transition process.\nWe conclude that in the presence of parameter uncertainty, it is better to lean\ntoward a conservative strategy reflecting, to some extent, the worst case than\nbeing overly optimistic. Our results also highlight the critical role of\nconvenience yield in determining optimal harvesting strategies."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC",
        "q-fin.MF"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.05584",
    "c_title":[
      "QArtSR: Quantization via Reverse-Module and Timestep-Retraining in\n  One-Step Diffusion based Image Super-Resolution"
    ],
    "c_abstract":[
      "One-step diffusion-based image super-resolution (OSDSR) models are showing\nincreasingly superior performance nowadays. However, although their denoising\nsteps are reduced to one and they can be quantized to 8-bit to reduce the costs\nfurther, there is still significant potential for OSDSR to quantize to lower\nbits. To explore more possibilities of quantized OSDSR, we propose an efficient\nmethod, Quantization via reverse-module and timestep-retraining for OSDSR,\nnamed QArtSR. Firstly, we investigate the influence of timestep value on the\nperformance of quantized models. Then, we propose Timestep Retraining\nQuantization (TRQ) and Reversed Per-module Quantization (RPQ) strategies to\ncalibrate the quantized model. Meanwhile, we adopt the module and image losses\nto update all quantized modules. We only update the parameters in quantization\nfinetuning components, excluding the original weights. To ensure that all\nmodules are fully finetuned, we add extended end-to-end training after\nper-module stage. Our 4-bit and 2-bit quantization experimental results\nindicate that QArtSR obtains superior effects against the recent leading\ncomparison methods. The performance of 4-bit QArtSR is close to the\nfull-precision one. Our code will be released at\nhttps:\/\/github.com\/libozhu03\/QArtSR."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-50",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12882",
    "b_title":[
      "Efficient classical algorithms for linear optical circuits"
    ],
    "b_abstract":[
      "We present efficient classical algorithms to approximate expectation values\nand probability amplitudes in linear optical circuits. Specifically, our\nclassical algorithm efficiently approximates the expectation values of\nobservables in linear optical circuits for arbitrary product input states\nwithin an additive error under a mild condition. This result suggests that\ncertain applications of linear optical circuits relying on expectation value\nestimation, such as photonic variational algorithms, may face challenges in\nachieving quantum advantage. In addition, the (marginal) output probabilities\nof boson sampling with arbitrary product input states can be efficiently\napproximated using our algorithm, implying that boson sampling can be\nefficiently simulated if its output probability distribution is polynomially\nsparse. Moreover, our method generalizes Gurvits's algorithm, originally\ndesigned to approximate the permanent, to also approximate the hafnian of\ncomplex symmetric matrices with an additive error. The algorithm also solves a\nmolecular vibronic spectra problem for arbitrary product input states as\nprecisely as boson samplers. Finally, our method extends to near-Clifford\ncircuits, enabling the classical approximation of their expectation values of\nany observables and (marginal) output probabilities."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.09856",
    "c_title":[
      "Scalable solution chemical synthesis and comprehensive analysis of\n  Bi2Te3 and Sb2Te3"
    ],
    "c_abstract":[
      "Thermoelectric (TE) materials can directly convert heat into electrical\nenergy. However, they sustain costly production procedures and batch-to-batch\nperformance variations. Therefore, developing scalable synthetic techniques for\nlarge-scale and reproducible quality TE materials is critical for advancing TE\ntechnology. This study developed a facile, high throughput, solution-chemical\nsynthetic technique. Microwave-assisted thermolysis process, providing\nenergy-efficient volumetric heating, was used for the synthesis of bismuth and\nantimony telluride (Bi2Te3, Sb2Te3). As-made materials were characterized using\nvarious techniques, including XRPD, SEM, TEM, XAS, and XPS. Detailed\ninvestigation of the local atomic structure of the synthesized Bi2Te3 and\nSb2Te3 powder samples was conducted through synchrotron radiation XAS\nexperiments. The sintered TE materials exhibited low thermal conductivity,\nachieving the highest TE figure-of-merit values of 0.7 (573 K) and 0.9 (523 K)\nfor n-type Bi2Te3 and p-type Sb2Te3, respectively, shifted significantly to the\nhigh-temperature region when compared to earlier reports, highlighting their\npotential for power generation applications. The scalable, energyand\ntime-efficient synthetic method developed, along with the demonstration of its\npotential for TE materials, opens the door for a wider application of these\nmaterials with minimal environmental impact."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-51",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07547",
    "b_title":[
      "Instance-dependent Early Stopping"
    ],
    "b_abstract":[
      "In machine learning practice, early stopping has been widely used to\nregularize models and can save computational costs by halting the training\nprocess when the model's performance on a validation set stops improving.\nHowever, conventional early stopping applies the same stopping criterion to all\ninstances without considering their individual learning statuses, which leads\nto redundant computations on instances that are already well-learned. To\nfurther improve the efficiency, we propose an Instance-dependent Early Stopping\n(IES) method that adapts the early stopping mechanism from the entire training\nset to the instance level, based on the core principle that once the model has\nmastered an instance, the training on it should stop. IES considers an instance\nas mastered if the second-order differences of its loss value remain within a\nsmall range around zero. This offers a more consistent measure of an instance's\nlearning status compared with directly using the loss value, and thus allows\nfor a unified threshold to determine when an instance can be excluded from\nfurther backpropagation. We show that excluding mastered instances from\nbackpropagation can increase the gradient norms, thereby accelerating the\ndecrease of the training loss and speeding up the training process. Extensive\nexperiments on benchmarks demonstrate that IES method can reduce\nbackpropagation instances by 10%-50% while maintaining or even slightly\nimproving the test accuracy and transfer learning performance of a model."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01133",
    "c_title":[
      "A thermal-noise-resilient microwave quantum network traversing 4 K"
    ],
    "c_abstract":[
      "Quantum communication at microwave frequencies has been fundamentally\nconstrained by the susceptibility of microwave photons to thermal noise,\nhindering their application in scalable quantum networks. Here we demonstrate a\nthermal-noise-resilient microwave quantum network that establishes coherent\ncoupling between two superconducting qubits through a 4 K thermalized\nniobium-titanium transmission line. By overcoupling the communication channel\nto a cold load at 10 mK, we suppress the effective thermal occupancy of the\nchannel to 0.06 photons through radiative cooling -- a two-order-of-magnitude\nreduction below ambient thermal noise. We then decouple the cold load and\nrapidly transfer microwave quantum states through the channel while it\nrethermalizes, achieving a 58.5% state transfer fidelity and a 52.3% Bell\nentanglement fidelity, both exceeding the classical communication threshold.\nOur architecture overcomes the temperature-compatibility barrier for microwave\nquantum systems, providing a scalable framework for distributed quantum\ncomputing and enabling hybrid quantum networks with higher-temperature\nsemiconductor or photonic platforms."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-52",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15786",
    "b_title":[
      "Chocolate Games with a Pass"
    ],
    "b_abstract":[
      "The authors present their research on chocolate games with a pass-move.\nChocolate games are generalizations of Nim. In this work, we modify the\nstandard rules of the game to allow a one-time pass; that is, a pass-move may\nbe used at most once in the game, but not from a terminal position. Once the\npass has been used by either player, it is no longer available. In the case of\nthe classical three-pile nim with $x,y,z$ for the number of stones of each\npile, the previous player wins when the ``exclusive or'' of $x,y,z$ is $0$, and\nits Grundy number is calculated as ``exclusive or'' of $x,y,z$. However, no\nmathematical formula is known for the previous player's winning position when a\npass-move is allowed. In this study, we show a theorem to determine the Grundy\nnumber of a position with a pass where the position can be considered as a\ndisjunctive sum of two positions which have a special property. By using the\ntheorem, we show closed formulas for positions which have Grundy numbers $0,\n1,$ and $2$ for some chocolate games with a pass."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07116",
    "c_title":[
      "Confinement of 3d $\\mathcal{N}=2$ Gauge Theories from M-theory on CY4"
    ],
    "c_abstract":[
      "In this work, we present a new geometric transition in non-compact Calabi-Yau\n4-folds, specifically for the cone over the 7d Sasaki-Einstein manifold\n$Q^{\\scriptscriptstyle(1,1,1)}\/\\mathbb{Z}_{N}$. We discover a new smoothing of\nsuch Calabi-Yau 4-fold singularity via a partial resolution+deformation, which\ncan be interpreted as a confined phase for a 3d $\\mathcal{N}=2$ $SU(N)$ gauge\ntheory. The confining strings are realized as M2-branes wrapping the torsional\n1-cycles in this new geometric phase. We have also computed the generalized\nglobal symmetries and SymTFT action using the link topology and intersection\nnumbers of the resolved Calabi-Yau 4-fold."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-53",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11159",
    "b_title":[
      "Contributions of $\\rho(770,1450)\\to \\omega\\pi$ for the Cabibbo-favored\n  $D \\to h\\omega\\pi$ decays"
    ],
    "b_abstract":[
      "Recently, the BESIII Collaboration has observed three-body decays $D_s^+\\to\n\\eta \\omega\\pi^+$, $D^+\\to K^0_S\\pi^+\\omega$ and $D^0\\to K^-\\pi^+\\omega$. In\nthis work, we investigate the contributions of the subprocesses $\\rho^+\\to\n\\omega\\pi^+$ in these Cabibbo-favored decays $D \\to h\\omega\\pi$, with $\\rho^+=\n\\{\\rho(770)^+, \\rho(1450)^+, \\rho(770)^+\\&\\rho(1450)^+\\}$ and $h=\\{ \\eta,\nK^0_S, K^-\\}$, by introducing these subprocesses into the decay amplitudes of\nthe relevant decay processes via the vector form factor $F_{\\omega\\pi}$\nmeasured in the related $\\tau$ and $e^+e^-$ processes; we provide the first\ntheoretical predictions for the branching fractions of the quasi-two-body\ndecays $D_s^+\\to\\eta[\\rho^+\\to]\\omega\\pi^+$, $D^+\\to\nK^0_S[\\rho^+\\to]\\omega\\pi^+$ and $D^0\\to K^-[\\rho^+\\to]\\omega\\pi^+$. Our\nfindings reveal that the contributions from the subprocess\n$\\rho(770)^+\\to\\omega\\pi^+$ are significant in these observed three-body decays\n$D_s^+\\to\\eta \\omega\\pi^+$, $D^+\\to K^0_S \\omega\\pi^+$ and $D^0\\to K^-\n\\omega\\pi^+$, notwithstanding the contributions originating from the\nBreit-Wigner tail effect of $\\rho(770)^+$. The numerical results of this study\nsuggest that these Cabibbo-favored three-body decays are dominated by the\ncontributions come from the $P$-wave intermediate states $\\rho(770)^+$,\n$\\rho(1450)^+$ and their interference effects."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02986",
    "c_title":[
      "Bidirectional controlled quantum state preparation in high-dimensional\n  quantum system"
    ],
    "c_abstract":[
      "High-dimensional quantum system exhibits unique advantages over the qubit\nsystem in some quantum information processing tasks. We present a program for\nimplementing deterministic bidirectional controlled remote quantum state\npreparation (BCRSP) in arbitrary $N$-dimensional (quNit) system. By introducing\ntwo generalized Greenberger-Horne-Zeilinger (GHZ) states as quantum channels,\ntwo communication parties can simultaneously prepare a single-particle\nhigh-dimensional state at each other's site under the control of Charlie.\nCompared with the previous counterparts, the significant advantage of our\nscheme is that the high-dimensional CNOT operations are not required. Moreover,\nthe performance our scheme are evaluated. The evaluation of the performance\nshows that if the quNit is encoded in the spatial mode of single photons, our\nscheme can be accomplished solely using only linear optical elements."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-54",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14312",
    "b_title":[
      "Modelling Capillary Rise with a Slip Boundary Condition: Well-posedness\n  and Long-time Dynamics of Solutions to Washburn's Equation"
    ],
    "b_abstract":[
      "The aim of this paper is to extend Washburn's capillary rise equation by\nincorporating a slip condition at the pipe wall. The governing equation is\nderived using fundamental principles from continuum mechanics. A new scaling is\nintroduced, allowing for a systematic analysis of different flow regimes. We\nprove the global-in-time existence and uniqueness of a bounded positive\nsolution to Washburn's equation that includes the slip parameter, as well as\nthe continuous dependence of the solution in the maximum norm on the initial\ndata. Thus, the initial-value problem for Washburn's equation is shown to be\nwell-posed in the sense of Hadamard. Additionally, we show that the unique\nequilibrium solution may be reached either monotonically or in an oscillatory\nfashion, similarly to the no-slip case. Finally, we determine the basin of\nattraction for the system, ensuring that the equilibrium state will be reached\nfrom the initial data we impose. These results hold for any positive value of\nthe nondimensional slip parameter in the model, and for all values of the ratio\n$h_0\/h_e$ in the range $[0,3\/2]$, where $h_0$ is the initial height of the\nfluid column and $h_e$ is its equilibrium height."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.AP",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06931",
    "c_title":[
      "Searching for Inflationary Physics with the CMB Trispectrum: 3.\n  Constraints from Planck"
    ],
    "c_abstract":[
      "Is there new physics hidden in the four-point function of the cosmic\nmicrowave background (CMB)? We conduct a detailed analysis of the Planck PR4\ntemperature and polarization trispectrum for $\\ell\\in[2,2048]$. Using the\ntheoretical and computational tools developed in Paper 1 and Paper 2, we search\nfor 33 template amplitudes, encoding a variety of effects from inflationary\nself-interactions to particle exchange. We find no evidence for primordial\nnon-Gaussianity and set stringent constraints on both phenomenological\namplitudes and couplings in the inflationary Lagrangian. Due to the use of\noptimal estimators and polarization data, our constraints are highly\ncompetitive. For example, we find $\\sigma(g_{\\rm NL}^{\\rm loc})=4.8\\times 10^4$\nand $\\tau_{\\rm NL}^{\\rm loc} <1500$ (95\\% CL), a factor of two improvement on\nEffective Field Theory amplitudes, and a $43\\sigma$ detection of gravitational\nlensing. Many templates are analyzed for the first time, such as\ndirection-dependent trispectra and the collapsed limit of the `cosmological\ncollider', across a range of masses and spins. We perform a variety of\nvalidation tests; whilst our results are stable, the most relevant systematics\nare found to be lensing bias, residual foregrounds, and mismatch between\nsimulations and data. The techniques discussed in this series can be extended\nto future datasets, allowing the primordial Universe to be probed at even\nhigher sensitivity."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-55",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19238",
    "b_title":[
      "Correlations drive the attosecond response of strongly-correlated\n  insulators"
    ],
    "b_abstract":[
      "Attosecond spectroscopy of materials has provided invaluable insight into\nlight-driven coherent electron dynamics. However, attosecond spectroscopies\nhave so far been focused on weakly-correlated materials. As a result, the\nbehavior of strongly-correlated systems is largely unknown at sub- to\nfew-femtosecond timescales, even though it is typically the realm at which\nelectron-electron interactions operate. Here we conduct attosecond-resolved\nexperiments on the correlated insulator nickel oxide, and compare its response\nto a common band insulator, revealing fundamentally different behaviors. The\nresults, together with state-of-the art time-dependent $\\textit{ab initio}$\ncalculations, show that the correlated system response is governed by a\nlaser-driven quench of electron correlations. The evolution of the on-site\nelectronic interaction is measured here at its natural timescale, marking the\nfirst direct measurement of Hubbard $U$ renormalization in NiO. It is found to\ntake place within a few femtoseconds, after which structural changes slowly\nstart to take place. The resulting picture sheds light on the entire\nlight-induced response of a strongly-correlated system, from attosecond to\nlong-lived effects."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10851",
    "c_title":[
      "Exploring Siamese Networks in Self-Supervised Fast MRI Reconstruction"
    ],
    "c_abstract":[
      "Reconstructing MR images using deep neural networks from undersampled k-space\ndata without using fully sampled training references offers significant value\nin practice, which is a self-supervised regression problem calling for\neffective prior knowledge and supervision. The Siamese architectures are\nmotivated by the definition \"invariance\" and shows promising results in\nunsupervised visual representative learning. Building homologous transformed\nimages and avoiding trivial solutions are two major challenges in Siamese-based\nself-supervised model. In this work, we explore Siamese architecture for MRI\nreconstruction in a self-supervised training fashion called SiamRecon. We show\nthe proposed approach mimics an expectation maximization algorithm. The\nalternative optimization provide effective supervision signal and avoid\ncollapse. The proposed SiamRecon achieves the state-of-the-art reconstruction\naccuracy in the field of self-supervised learning on both single-coil brain MRI\nand multi-coil knee MRI."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-56",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03476",
    "b_title":[
      "Achieve equilibrium outside the contact angle hysteresis"
    ],
    "b_abstract":[
      "It is common belief that the equilibrium contact angle, corresponding to the\nminimum system energy state, lies between advancing and receding contact\nangles. Here, we derive advancing and receding contact angles considering the\nmicro contacting processes on ideal rough 2D surfaces. Equilibrium contact\nangles obtained via energy minimization can be smaller than the receding\ncontact angle and reach 0 degrees, at which hysteresis diminishes on the\nsuper-hydrophilic surface. Gibbs free energy analyses, numerical simulations\nand physical experiments all confirm these new findings."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20635",
    "c_title":[
      "Can LLM Assist in the Evaluation of the Quality of Machine Learning\n  Explanations?"
    ],
    "c_abstract":[
      "EXplainable machine learning (XML) has recently emerged to address the\nmystery mechanisms of machine learning (ML) systems by interpreting their\n'black box' results. Despite the development of various explanation methods,\ndetermining the most suitable XML method for specific ML contexts remains\nunclear, highlighting the need for effective evaluation of explanations. The\nevaluating capabilities of the Transformer-based large language model (LLM)\npresent an opportunity to adopt LLM-as-a-Judge for assessing explanations. In\nthis paper, we propose a workflow that integrates both LLM-based and human\njudges for evaluating explanations. We examine how LLM-based judges evaluate\nthe quality of various explanation methods and compare their evaluation\ncapabilities to those of human judges within an iris classification scenario,\nemploying both subjective and objective metrics. We conclude that while\nLLM-based judges effectively assess the quality of explanations using\nsubjective metrics, they are not yet sufficiently developed to replace human\njudges in this role."
    ],
    "c_categories":[
      [
        "cs.HC",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-57",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14665",
    "b_title":[
      "These Magic Moments: Differentiable Uncertainty Quantification of\n  Radiance Field Models"
    ],
    "b_abstract":[
      "This paper introduces a novel approach to uncertainty quantification for\nradiance fields by leveraging higher-order moments of the rendering equation.\nUncertainty quantification is crucial for downstream tasks including view\nplanning and scene understanding, where safety and robustness are paramount.\nHowever, the high dimensionality and complexity of radiance fields pose\nsignificant challenges for uncertainty quantification, limiting the use of\nthese uncertainty quantification methods in high-speed decision-making. We\ndemonstrate that the probabilistic nature of the rendering process enables\nefficient and differentiable computation of higher-order moments for radiance\nfield outputs, including color, depth, and semantic predictions. Our method\noutperforms existing radiance field uncertainty estimation techniques while\noffering a more direct, computationally efficient, and differentiable\nformulation without the need for post-processing. Beyond uncertainty\nquantification, we also illustrate the utility of our approach in downstream\napplications such as next-best-view (NBV) selection and active ray sampling for\nneural radiance field training. Extensive experiments on synthetic and\nreal-world scenes confirm the efficacy of our approach, which achieves\nstate-of-the-art performance while maintaining simplicity."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01594",
    "c_title":[
      "Exploring X17 and dark charges in the context of Standard Model tensions"
    ],
    "c_abstract":[
      "We report on recent results, according to which the hyphothetical X17 boson\ncould affect the muon g-2 anomaly and the Lamb Shift. Moreover by considering\nthe kinetic mixing between this new boson and the U(1)Y we establish possible\ncontribution of the X17 to the W mass."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-58",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03974",
    "b_title":[
      "Cryptographic Verifiability for Voter Registration Systems"
    ],
    "b_abstract":[
      "Voter registration systems are a critical - and surprisingly understudied -\nelement of most high-stakes elections. Despite a history of targeting by\nadversaries, relatively little academic work has been done to increase\nvisibility into how voter registration systems keep voters' data secure,\naccurate, and up to date. Enhancing transparency and verifiability could help\nelection officials and the public detect and mitigate risks to this essential\ncomponent of electoral processes worldwide.\n  This work introduces cryptographic verifiability for voter registration\nsystems. Based on consultation with diverse expert stakeholders that support\nelections systems, we precisely define the requirements for cryptographic\nverifiability in voter registration and systematize the practical challenges\nthat must be overcome for near-term deployment.\n  We then introduce VRLog, the first system to bring strong verifiability to\nvoter registration. VRLog enables election officials to provide a transparent\nlog that (1) allows voters to verify that their registration data has not been\ntampered with and (2) allows the public to monitor update patterns and database\nconsistency. We also introduce VRLog$^x$, an enhancement to VRLog that offers\ncryptographic privacy to voter deduplication between jurisdictions - a common\nmaintenance task currently performed in plaintext or using trusted third\nparties. Our designs rely on standard, efficient cryptographic primitives, and\nare backward compatible with existing voter registration systems. Finally, we\nprovide an open-source implementation of VRLog and benchmarks to demonstrate\nthat the system is practical - capable of running on low-cost commodity\nhardware and scaling to support databases the size of the largest U.S. state\nvoter registration systems."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03821",
    "c_title":[
      "The Choice of Normalization Influences Shrinkage in Regularized\n  Regression"
    ],
    "c_abstract":[
      "Regularized models are often sensitive to the scales of the features in the\ndata and it has therefore become standard practice to normalize (center and\nscale) the features before fitting the model. But there are many different ways\nto normalize the features and the choice may have dramatic effects on the\nresulting model. In spite of this, there has so far been no research on this\ntopic. In this paper, we begin to bridge this knowledge gap by studying\nnormalization in the context of lasso, ridge, and elastic net regression. We\nfocus on normal and binary features and show that the class balances of binary\nfeatures directly influences the regression coefficients and that this effect\ndepends on the combination of normalization and regularization methods used. We\ndemonstrate that this effect can be mitigated by scaling binary features with\ntheir variance in the case of the lasso and standard deviation in the case of\nridge regression, but that this comes at the cost of increased variance. For\nthe elastic net, we show that scaling the penalty weights, rather than the\nfeatures, can achieve the same effect. Finally, we also tackle mixes of binary\nand normal features as well as interactions and provide some initial results on\nhow to normalize features in these cases."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-59",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07036",
    "b_title":[
      "Automated Consistency Analysis of LLMs"
    ],
    "b_abstract":[
      "Generative AI (Gen AI) with large language models (LLMs) are being widely\nadopted across the industry, academia and government. Cybersecurity is one of\nthe key sectors where LLMs can be and\/or are already being used. There are a\nnumber of problems that inhibit the adoption of trustworthy Gen AI and LLMs in\ncybersecurity and such other critical areas. One of the key challenge to the\ntrustworthiness and reliability of LLMs is: how consistent an LLM is in its\nresponses? In this paper, we have analyzed and developed a formal definition of\nconsistency of responses of LLMs. We have formally defined what is consistency\nof responses and then develop a framework for consistency evaluation. The paper\nproposes two approaches to validate consistency: self-validation, and\nvalidation across multiple LLMs. We have carried out extensive experiments for\nseveral LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a\nsecurity benchmark consisting of several cybersecurity questions: informational\nand situational. Our experiments corroborate the fact that even though these\nLLMs are being considered and\/or already being used for several cybersecurity\ntasks today, they are often inconsistent in their responses, and thus are\nuntrustworthy and unreliable for cybersecurity."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09454",
    "c_title":[
      "Two-loop four-point amplitudes on the Coulomb branch of\n  ${\\mathcal{N}}=4$ super Yang-Mills"
    ],
    "c_abstract":[
      "We explore scattering amplitudes on the Coulomb branch of maximally\nsupersymmetric Yang-Mills theory. We introduce a particular pattern of scalar\nvacuum expectation values that allow us to define amplitudes with a different\nmass pattern compared to what was studied previously. This is motivated by an\nextension of the Amplituhedron that leads to infrared-finite four-particle\namplitudes involving massive particles. We work out the Feynman rules on the\nCoulomb branch and use them, together with generalized unitarity techniques, to\nperform consistency checks on the Amplituhedron expectations for the one- and\ntwo-loop integrands for the four-particle amplitude. We present details of the\ncomputation of the required two-loop four-point integrals via a\nfour-dimensional version of the differential equations method. Finally, we\nstudy the Regge limit of the four-point amplitude, including the first power\nsuppressed terms. We find that when organized in terms of a suitable expansion\nparameter, the subleading power term exponentiates, with the exponent matching\nthe anomalous dimension of a cusped Wilson line with a local operator\ninsertion. The latter is known from integrability, which leads to a prediction\nat higher loop orders in the Regge limit."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-60",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08397",
    "b_title":[
      "Strong bounds for large-scale Minimum Sum-of-Squares Clustering"
    ],
    "b_abstract":[
      "Clustering is a fundamental technique in data analysis and machine learning,\nused to group similar data points together. Among various clustering methods,\nthe Minimum Sum-of-Squares Clustering (MSSC) is one of the most widely used.\nMSSC aims to minimize the total squared Euclidean distance between data points\nand their corresponding cluster centroids. Due to the unsupervised nature of\nclustering, achieving global optimality is crucial, yet computationally\nchallenging. The complexity of finding the global solution increases\nexponentially with the number of data points, making exact methods impractical\nfor large-scale datasets. Even obtaining strong lower bounds on the optimal\nMSSC objective value is computationally prohibitive, making it difficult to\nassess the quality of heuristic solutions. We address this challenge by\nintroducing a novel method to validate heuristic MSSC solutions through\noptimality gaps. Our approach employs a divide-and-conquer strategy,\ndecomposing the problem into smaller instances that can be handled by an exact\nsolver. The decomposition is guided by an auxiliary optimization problem, the\n\"anticlustering problem\", for which we design an efficient heuristic.\nComputational experiments demonstrate the effectiveness of the method for\nlarge-scale instances, achieving optimality gaps below 3% in most cases while\nmaintaining reasonable computational times. These results highlight the\npracticality of our approach in assessing feasible clustering solutions for\nlarge datasets, bridging a critical gap in MSSC evaluation."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06623",
    "c_title":[
      "Nuclear Explosions for Large Scale Carbon Sequestration"
    ],
    "c_abstract":[
      "Confronting the escalating threat of climate change requires innovative and\nlarge-scale interventions. This paper presents a bold proposal to employ a\nburied nuclear explosion in a remote basaltic seabed for pulverizing basalt,\nthereby accelerating carbon sequestration through Enhanced Rock Weathering\n(ERW). By precisely locating the explosion beneath the seabed, we aim to\nconfine debris, radiation, and energy while ensuring rapid rock weathering at a\nscale substantial enough to make a meaningful dent in atmospheric carbon\nlevels. Our analysis outlines the parameters essential for efficient carbon\ncapture and minimal collateral effects, emphasizing that a yield on the order\nof gigatons is critical for global climate impact. Although this approach may\nappear radical, we illustrate its feasibility by examining safety factors,\npreservation of local ecosystems, political considerations, and financial\nviability. This work argues for reimagining nuclear technology not merely as a\ndestructive force but as a potential catalyst for decarbonization, thereby\ninviting further exploration of pioneering solutions in the fight against\nclimate change."
    ],
    "c_categories":[
      [
        "physics.ao-ph",
        "physics.soc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-61",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05712",
    "b_title":[
      "Multi-Step Reasoning in Korean and the Emergent Mirage"
    ],
    "b_abstract":[
      "We introduce HRMCR (HAE-RAE Multi-Step Commonsense Reasoning), a benchmark\ndesigned to evaluate large language models' ability to perform multi-step\nreasoning in culturally specific contexts, focusing on Korean. The questions\nare automatically generated via templates and algorithms, requiring LLMs to\nintegrate Korean cultural knowledge into sequential reasoning steps. Consistent\nwith prior observations on emergent abilities, our experiments reveal that\nmodels trained on fewer than \\(2 \\cdot 10^{25}\\) training FLOPs struggle to\nsolve any questions, showing near-zero performance. Beyond this threshold,\nperformance improves sharply. State-of-the-art models (e.g., O1) still score\nunder 50\\%, underscoring the difficulty of our tasks. Notably, stepwise\nanalysis suggests the observed emergent behavior may stem from compounding\nerrors across multiple steps rather than reflecting a genuinely new capability.\nWe publicly release the benchmark and commit to regularly updating the dataset\nto prevent contamination."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04640",
    "c_title":[
      "Coil geometry with large openings for a HSR3-like stellarator reactor\n  for fast replacement of in-vessel components"
    ],
    "c_abstract":[
      "Advanced stellarators require convoluted modular coils to produce a plasma\nwith satisfactory performance. Moreover, the number of coils is sometimes high\nto decrease the modular ripple created by the coils. For reactor stellarators,\nthese requirements imply relatively small ports for in-vessel access and\nmaintenance, i.e. in comparison with tokamaks. The blankets and divertor\nmodules will have to be replaced periodically (about each 1-4 years depending\non the design) due to neutron damage, and also erosion of divertor targets.\nBlanket modules are activated, thus, all the maintenance operations have to be\nproduced remotely. In order to reduce the shutdown time and cost during\ncomponent replacement, and to reduce the number, speed and other specifications\nof the remote maintenance equipment, the number of blanket modules in the\nreactor should be low and thus, the blanket modules should be large (in\nrelation to the minor and major radius). Nevertheless, the size of the openings\nbetween coils limits the maximum size of the blanket and divertor modules,\nthough several potential enhancements have been proposed in the past for\nstellarators, like straightening the outboard segments of the coils and the\nmovement and\/or expansion of certain coils to have wider access. The present\nwork reports on a coil geometry for the 'Helias Stellarator Reactor' (HSR) of\nthree periods (HSR3) with coils located far from the plasma at the outboard\nregion of the straight-like sector. This feature creates natural wide openings\nat such regions of the coils, which may be utilized to allow access to large\nblanket and divertor modules."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-62",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05469",
    "b_title":[
      "The largest subcritical component in inhomogeneous random graphs of\n  preferential attachment type"
    ],
    "b_abstract":[
      "We identify the size of the largest connected component in a subcritical\ninhomogeneous random graph with a kernel of preferential attachment type. The\ncomponent is polynomial in the graph size with an explicitly given exponent,\nwhich is strictly larger than the exponent for the largest degree in the graph.\nThis is in stark contrast to the behaviour of inhomogeneous random graphs with\na kernel of rank one. Our proof uses local approximation by branching random\nwalks going well beyond the weak local limit and novel results on subcritical\nkilled branching random walks."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17981",
    "c_title":[
      "Can Generative LLMs Create Query Variants for Test Collections? An\n  Exploratory Study"
    ],
    "c_abstract":[
      "This paper explores the utility of a Large Language Model (LLM) to\nautomatically generate queries and query variants from a description of an\ninformation need. Given a set of information needs described as backstories, we\nexplore how similar the queries generated by the LLM are to those generated by\nhumans. We quantify the similarity using different metrics and examine how the\nuse of each set would contribute to document pooling when building test\ncollections. Our results show potential in using LLMs to generate query\nvariants. While they may not fully capture the wide variety of human-generated\nvariants, they generate similar sets of relevant documents, reaching up to\n71.1% overlap at a pool depth of 100."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-63",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05114",
    "b_title":[
      "The ESO SupJup Survey V: Exploring Atmospheric Variability and Orbit of\n  the Super-Jupiter AB Pictoris b with CRIRES+"
    ],
    "b_abstract":[
      "A growing number of directly-imaged companions have been recently\ncharacterised, with robust constraints on carbon-to-oxygen ratios and even\nisotopic ratios. Many companions and isolated targets have also shown spectral\nvariability. In this work we observed the super-Jupiter AB~Pictoris~b across\nfour consecutive nights using VLT\/CRIRES+ as part of the ESO SupJup survey,\nexploring how the constraints on chemical composition and temperature profile\nchange over time using spectral line shape variations between nights. We\nperformed atmospheric retrievals of the high-resolution observations and found\nbroadly consistent results across all four nights, but there were differences\nfor some parameters. We clearly detect H$_2$O, $^{12}$CO and $^{13}$CO in each\nnight, but abundances varied by $\\sim2\\sigma$, which was correlated to the deep\natmosphere temperature profiles. We also found differences in the\n$^{12}$C$\/^{13}$C ratios in each night by up to $\\sim3\\sigma$, which seemed to\nbe correlated with the cloud deck pressure. Our combined retrieval\nsimultaneously analysing all nights together constrained broadly the average of\neach night individually, with the C\/O$=0.59\\pm0.01$, consistent with solar\ncomposition, and $^{12}$C$\/^{13}$C~$ = 102\\pm8$, slightly higher than the ISM\nand Solar System values. We also find a low projected rotational velocity,\nsuggesting that AB~Pictoris~b is either intrinsically a slow rotator due to its\nyoung age or that the spin axis is observed pole-on with a $\\sim90^\\circ$\nmisalignment with its orbit inclination. Future observations will be able to\nfurther explore the variability and orbit of AB~Pictoris~b as well as for other\ncompanions."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00248",
    "c_title":[
      "Human-AI Collaboration: Trade-offs Between Performance and Preferences"
    ],
    "c_abstract":[
      "Despite the growing interest in collaborative AI, designing systems that\nseamlessly integrate human input remains a major challenge. In this study, we\ndeveloped a task to systematically examine human preferences for collaborative\nagents. We created and evaluated five collaborative AI agents with strategies\nthat differ in the manner and degree they adapt to human actions. Participants\ninteracted with a subset of these agents, evaluated their perceived traits, and\nselected their preferred agent. We used a Bayesian model to understand how\nagents' strategies influence the Human-AI team performance, AI's perceived\ntraits, and the factors shaping human-preferences in pairwise agent\ncomparisons. Our results show that agents who are more considerate of human\nactions are preferred over purely performance-maximizing agents. Moreover, we\nshow that such human-centric design can improve the likability of AI\ncollaborators without reducing performance. We find evidence for\ninequality-aversion effects being a driver of human choices, suggesting that\npeople prefer collaborative agents which allow them to meaningfully contribute\nto the team. Taken together, these findings demonstrate how collaboration with\nAI can benefit from development efforts which include both subjective and\nobjective metrics."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-64",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12995",
    "b_title":[
      "Frobenius method for Mahler equations"
    ],
    "b_abstract":[
      "Using Hahn series, one can attach to any linear Mahler equation a basis of\nsolutions at 0 reminiscent of the solutions of linear differential equations at\na regular singularity. We show that such a basis of solutions can be produced\nby using a variant of Frobenius method."
    ],
    "b_categories":[
      [
        "cs.SC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10493",
    "c_title":[
      "Explanation of the observed violation of isospin symmetry in\n  relativistic nucleus-nucleus reactions"
    ],
    "c_abstract":[
      "The violation of isospin symmetry in nucleus-nucleus reactions, as shown in\nthe ratio ${R_K=(K^++K^-)\/(K^0+\\bar{K}^0)}$ presented by NA61\/SHINE, can be\nunderstood by introducing results from color-string fragmentation in $e^+e^-$\nto nuclear reactions. This novel input allows for a consistent description of\nthe $e^+e^-$ data, proton+proton data and finally nucleus-nucleus data at all\ninvestigated energies. We conclude that the observed isospin violation in\nnucleus-nucleus reactions is explained by asymmetric production of up- and\ndown-quarks in the elementary color field fragmentation process."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-65",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04364",
    "b_title":[
      "Lost in Edits? A $\\lambda$-Compass for AIGC Provenance"
    ],
    "b_abstract":[
      "Recent advancements in diffusion models have driven the growth of text-guided\nimage editing tools, enabling precise and iterative modifications of\nsynthesized content. However, as these tools become increasingly accessible,\nthey also introduce significant risks of misuse, emphasizing the critical need\nfor robust attribution methods to ensure content authenticity and traceability.\nDespite the creative potential of such tools, they pose significant challenges\nfor attribution, particularly in adversarial settings where edits can be\nlayered to obscure an image's origins. We propose LambdaTracer, a novel\nlatent-space attribution method that robustly identifies and differentiates\nauthentic outputs from manipulated ones without requiring any modifications to\ngenerative or editing pipelines. By adaptively calibrating reconstruction\nlosses, LambdaTracer remains effective across diverse iterative editing\nprocesses, whether automated through text-guided editing tools such as\nInstructPix2Pix and ControlNet or performed manually with editing software such\nas Adobe Photoshop. Extensive experiments reveal that our method consistently\noutperforms baseline approaches in distinguishing maliciously edited images,\nproviding a practical solution to safeguard ownership, creativity, and\ncredibility in the open, fast-evolving AI ecosystems."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17122",
    "c_title":[
      "Transition energy fields in the method of correlation equations"
    ],
    "c_abstract":[
      "In this paper, the well-known method of correlation equations for\nconstructing Gibbs measures is generalized based on the concept of the\ntransition energy field. Using the properties of transition energies, we obtain\nthe system of correlation equations for lattice systems with finite spin space.\nIt is shown that for a sufficiently small value of the one-point transition\nenergies, the corresponding system of correlation functions, considered in\ninfinite space, has a solution which is unique. Finally, the convergence of\nfinite-volume correlation functions to the limiting correlation function is\nshown."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-66",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03145",
    "b_title":[
      "Geometry Restoration and Dewarping of Camera-Captured Document Images"
    ],
    "b_abstract":[
      "This research focuses on developing a method for restoring the topology of\ndigital images of paper documents captured by a camera, using algorithms for\ndetection, segmentation, geometry restoration, and dewarping. Our methodology\nemploys deep learning (DL) for document outline detection, followed by computer\nvision (CV) to create a topological 2D grid using cubic polynomial\ninterpolation and correct nonlinear distortions by remapping the image. Using\nclassical CV methods makes the document topology restoration process more\nefficient and faster, as it requires significantly fewer computational\nresources and memory. We developed a new pipeline for automatic document\ndewarping and reconstruction, along with a framework and annotated dataset to\ndemonstrate its efficiency. Our experiments confirm the promise of our\nmethodology and its superiority over existing benchmarks (including mobile apps\nand popular DL solutions, such as RectiNet, DocGeoNet, and DocTr++) both\nvisually and in terms of document readability via Optical Character Recognition\n(OCR) and geometry restoration metrics. This paves the way for creating\nhigh-quality digital copies of paper documents and enhancing the efficiency of\nOCR systems. Project page: https:\/\/github.com\/HorizonParadox\/DRCCBI"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03585",
    "c_title":[
      "Combinatorics in (2,1)-categories"
    ],
    "c_abstract":[
      "Groupoid cardinality is an invariant of locally finite groupoids which has\nmany of the properties of the cardinality of finite sets, but which takes\nvalues in all non-negative real numbers, and accounts for the morphisms of a\ngroupoid. Several results on groupoid cardinality are proved, analogous to the\nrelationship between cardinality of finite sets and i.e. injective or\nsurjective functions. We also generalize to a broad class of (2,1)-categories a\nfamous theorem of Lov\\'asz which characterizes the isomorphism type of\nrelational structures by counting the number of homomorphisms into them."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.CT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-67",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07260",
    "b_title":[
      "Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion"
    ],
    "b_abstract":[
      "3D semantic scene completion is critical for multiple downstream tasks in\nautonomous systems. It estimates missing geometric and semantic information in\nthe acquired scene data. Due to the challenging real-world conditions, this\ntask usually demands complex models that process multi-modal data to achieve\nacceptable performance. We propose a unique neural model, leveraging advances\nfrom the state space and diffusion generative modeling to achieve remarkable 3D\nsemantic scene completion performance with monocular image input. Our technique\nprocesses the data in the conditioned latent space of a variational autoencoder\nwhere diffusion modeling is carried out with an innovative state space\ntechnique. A key component of our neural network is the proposed Skimba (Skip\nMamba) denoiser, which is adept at efficiently processing long-sequence data.\nThe Skimba diffusion model is integral to our 3D scene completion network,\nincorporating a triple Mamba structure, dimensional decomposition residuals and\nvarying dilations along three directions. We also adopt a variant of this\nnetwork for the subsequent semantic segmentation stage of our method. Extensive\nevaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show\nthat our approach not only outperforms other monocular techniques by a large\nmargin, it also achieves competitive performance against stereo methods. The\ncode is available at https:\/\/github.com\/xrkong\/skimba"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03942",
    "c_title":[
      "A retake on the analysis of scores truncated by terminal events"
    ],
    "c_abstract":[
      "Analysis of data from randomized controlled trials in vulnerable populations\nrequires special attention when assessing treatment effect by a score\nmeasuring, e.g., disease stage or activity together with onset of prevalent\nterminal events. In reality, it is impossible to disentangle a disease score\nfrom the terminal event, since the score is not clinically meaningful after\nthis event. In this work, we propose to assess treatment interventions\nsimultaneously on disease score and the terminal event. Our proposal is based\non a natural data-generating mechanism respecting that a disease score does not\nexist beyond the terminal event. We use modern semi-parametric statistical\nmethods to provide robust and efficient estimation of the risk of terminal\nevent and expected disease score conditional on no terminal event at a\npre-specified landmark time. We also use the simultaneous asymptotic behavior\nof our estimators to develop a powerful closed testing procedure for\nconfirmatory assessment of treatment effect on both onset of terminal event and\nlevel of disease score. A simulation study mimicking a large-scale outcome\ntrial in chronic kidney patients as well as an analysis of that trial is\nprovided to assess performance."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-68",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03756",
    "b_title":[
      "Conditions for radiative zones in the molecular hydrogen envelope of\n  Jupiter and Saturn: The role of alkali metals"
    ],
    "b_abstract":[
      "Interior models of gas giants in the Solar System traditionally assume a\nfully convective molecular hydrogen envelope. However, recent observations from\nthe Juno mission suggest a possible depletion of alkali metals in Jupiter's\nmolecular hydrogen envelope, indicating that a stable radiative layer could\nexist at the kilobar level. Recent studies propose that deep stable layers help\nreconcile various Jupiter observations, including its atmospheric water and CO\nabundances and the depth of its zonal winds. However, opacity tables used to\ninfer stable layers are often outdated and incomplete, leaving the precise\nmolecular hydrogen envelope composition required for a deep radiative zone\nuncertain. In this paper, we determine atmospheric compositions that can lead\nto the formation of a radiative zone at the kilobar level in Jupiter and Saturn\ntoday. We computed radiative opacity tables covering pressures up to $10^5$\nbar, including the most abundant molecules present in the gas giants of the\nSolar System, as well as contributions from free electrons, metal hydrides,\noxides, and atomic species, using the most up-to-date line lists published in\nthe literature. These tables were used to calculate Rosseland-mean opacities\nfor the molecular hydrogen envelopes of Jupiter and Saturn, which were then\ncompared to the critical mean opacity required to maintain convection. We find\nthat the presence of a radiative zone is controlled by the existence of K, Na,\nand NaH in the atmosphere of Jupiter and Saturn. For Jupiter, the elemental\nabundance of K and Na must be less than $\\sim 10^{-3}$ times solar to form a\nradiative zone. In contrast, for Saturn, the required abundance for K and Na is\nbelow $\\sim 10^{-4}$ times solar."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13528",
    "c_title":[
      "Diffusion-based Perceptual Neural Video Compression with Temporal\n  Diffusion Information Reuse"
    ],
    "c_abstract":[
      "Recently, foundational diffusion models have attracted considerable attention\nin image compression tasks, whereas their application to video compression\nremains largely unexplored. In this article, we introduce DiffVC, a\ndiffusion-based perceptual neural video compression framework that effectively\nintegrates foundational diffusion model with the video conditional coding\nparadigm. This framework uses temporal context from previously decoded frame\nand the reconstructed latent representation of the current frame to guide the\ndiffusion model in generating high-quality results. To accelerate the iterative\ninference process of diffusion model, we propose the Temporal Diffusion\nInformation Reuse (TDIR) strategy, which significantly enhances inference\nefficiency with minimal performance loss by reusing the diffusion information\nfrom previous frames. Additionally, to address the challenges posed by\ndistortion differences across various bitrates, we propose the Quantization\nParameter-based Prompting (QPP) mechanism, which utilizes quantization\nparameters as prompts fed into the foundational diffusion model to explicitly\nmodulate intermediate features, thereby enabling a robust variable bitrate\ndiffusion-based neural compression framework. Experimental results demonstrate\nthat our proposed solution delivers excellent performance in both perception\nmetrics and visual quality."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-69",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07090",
    "b_title":[
      "Generative Distribution Prediction: A Unified Approach to Multimodal\n  Learning"
    ],
    "b_abstract":[
      "Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.09562",
    "c_title":[
      "On extensions of Cohen Structure Theorem"
    ],
    "c_abstract":[
      "The aim of this paper is to extend Cohen structure theorem beyond local\nrings. Both Cohen structure theorem and Nagata's generalization of it are\nspecial cases of our results. We investigate for which rings $R$ there exists a\nmaximal ideal $\\mathfrak{m}$ of $R$ such that the canonical projection $R\\to\nR\/\\mathfrak{m}$ has a section, so that $R\/\\mathfrak{m}$ is isomorphic to a\nfield $\\kappa$ contained in $R$. We present two equivalent characterizations of\nthis property and use them to exhibit two classes of rings that satisfy it.\nMoreover, we provide several examples (not necessarily local or complete\nlocal), as well as methods to construct new examples."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-70",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15467",
    "b_title":[
      "Bipartite expansion beyond biparticity"
    ],
    "b_abstract":[
      "The recently suggested bipartite analysis extends the Kauffman planar\ndecomposition to arbitrary $N$, i.e. extends it from the Jones polynomial to\nthe HOMFLY polynomial. This provides a generic and straightforward\nnon-perturbative calculus in an arbitrary Chern--Simons theory. Technically,\nthis approach is restricted to knots and links which possess bipartite\nrealizations, i.e. can be entirely glued from antiparallel lock (two-vertex)\ntangles rather than single-vertex $R$-matrices. However, we demonstrate that\nthe resulting positive decomposition (PD), i.e. the representation of the\nfundamental HOMFLY polynomials as positive integer polynomials of the three\nparameters $\\phi$, $\\bar\\phi$ and $D$, exists for arbitrary knots, not only\nbipartite ones. This poses new questions about the true significance of\nbipartite expansion, which appears to make sense far beyond its original scope,\nand its generalizations to higher representations. We have provided two\nexplanations for the existence of the PD for non-bipartite knots. An\ninteresting option is to resolve a particular bipartite vertex in a\nnot-fully-bipartite diagram and reduce the HOMFLY polynomial to a linear\ncombination of those for smaller diagrams. If the resulting diagrams correspond\nto bipartite links, this option provides a PD even to an initially\nnon-bipartite knot. Another possibility for a non-bipartite knot is to have a\nbipartite clone with the same HOMFLY polynomial providing this PD. We also\nsuggest a promising criterium for the existence of a bipartite realization\nbehind a given PD, which is based on the study of the precursor Jones\npolynomials."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.GT",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14214",
    "c_title":[
      "Asymmetric Co-Training for Source-Free Few-Shot Domain Adaptation"
    ],
    "c_abstract":[
      "Source-free unsupervised domain adaptation (SFUDA) has gained significant\nattention as an alternative to traditional unsupervised domain adaptation\n(UDA), which relies on the constant availability of labeled source data.\nHowever, SFUDA approaches come with inherent limitations that are frequently\noverlooked. These challenges include performance degradation when the unlabeled\ntarget data fails to meet critical assumptions, such as having a closed-set\nlabel distribution identical to that of the source domain, or when sufficient\nunlabeled target data is unavailable-a common situation in real-world\napplications. To address these issues, we propose an asymmetric co-training\n(ACT) method specifically designed for the SFFSDA scenario. SFFSDA presents a\nmore practical alternative to SFUDA, as gathering a few labeled target\ninstances is more feasible than acquiring large volumes of unlabeled target\ndata in many real-world contexts. Our ACT method begins by employing a\nweak-strong augmentation to enhance data diversity. Then we use a two-step\noptimization process to train the target model. In the first step, we optimize\nthe label smoothing cross-entropy loss, the entropy of the class-conditional\ndistribution, and the reverse-entropy loss to bolster the model's\ndiscriminative ability while mitigating overfitting. The second step focuses on\nreducing redundancy in the output space by minimizing classifier determinacy\ndisparity. Extensive experiments across four benchmarks demonstrate the\nsuperiority of our ACT approach, which outperforms state-of-the-art SFUDA\nmethods and transfer learning techniques. Our findings suggest that adapting a\nsource pre-trained model using only a small amount of labeled target data\noffers a practical and dependable solution. The code is available at\nhttps:\/\/github.com\/gengxuli\/ACT."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-71",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02824",
    "b_title":[
      "Proteomic Learning of Gamma-Aminobutyric Acid (GABA) Receptor-Mediated\n  Anesthesia"
    ],
    "b_abstract":[
      "Anesthetics are crucial in surgical procedures and therapeutic interventions,\nbut they come with side effects and varying levels of effectiveness, calling\nfor novel anesthetic agents that offer more precise and controllable effects.\nTargeting Gamma-aminobutyric acid (GABA) receptors, the primary inhibitory\nreceptors in the central nervous system, could enhance their inhibitory action,\npotentially reducing side effects while improving the potency of anesthetics.\nIn this study, we introduce a proteomic learning of GABA receptor-mediated\nanesthesia based on 24 GABA receptor subtypes by considering over 4000 proteins\nin protein-protein interaction (PPI) networks and over 1.5 millions known\nbinding compounds. We develop a corresponding drug-target interaction network\nto identify potential lead compounds for novel anesthetic design. To ensure\nrobust proteomic learning predictions, we curated a dataset comprising 136\ntargets from a pool of 980 targets within the PPI networks. We employed three\nmachine learning algorithms, integrating advanced natural language processing\n(NLP) models such as pretrained transformer and autoencoder embeddings. Through\na comprehensive screening process, we evaluated the side effects and\nrepurposing potential of over 180,000 drug candidates targeting the GABRA5\nreceptor. Additionally, we assessed the ADMET (absorption, distribution,\nmetabolism, excretion, and toxicity) properties of these candidates to identify\nthose with near-optimal characteristics. This approach also involved optimizing\nthe structures of existing anesthetics. Our work presents an innovative\nstrategy for the development of new anesthetic drugs, optimization of\nanesthetic use, and deeper understanding of potential anesthesia-related side\neffects."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.BM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01146",
    "c_title":[
      "Quantum Machine Learning: A Hands-on Tutorial for Machine Learning\n  Practitioners and Researchers"
    ],
    "c_abstract":[
      "This tutorial intends to introduce readers with a background in AI to quantum\nmachine learning (QML) -- a rapidly evolving field that seeks to leverage the\npower of quantum computers to reshape the landscape of machine learning. For\nself-consistency, this tutorial covers foundational principles, representative\nQML algorithms, their potential applications, and critical aspects such as\ntrainability, generalization, and computational complexity. In addition,\npractical code demonstrations are provided in https:\/\/qml-tutorial.github.io\/\nto illustrate real-world implementations and facilitate hands-on learning.\nTogether, these elements offer readers a comprehensive overview of the latest\nadvancements in QML. By bridging the gap between classical machine learning and\nquantum computing, this tutorial serves as a valuable resource for those\nlooking to engage with QML and explore the forefront of AI in the quantum era."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-72",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06179",
    "b_title":[
      "Actual Achieved Gain and Optimal Perceived Gain: Modeling Human\n  Take-over Decisions Towards Automated Vehicles' Suggestions"
    ],
    "b_abstract":[
      "Driver decision quality in take-overs is critical for effective\nhuman-Autonomous Driving System (ADS) collaboration. However, current research\nlacks detailed analysis of its variations. This paper introduces two\nmetrics--Actual Achieved Gain (AAG) and Optimal Perceived Gain (OPG)--to assess\ndecision quality, with OPG representing optimal decisions and AAG reflecting\nactual outcomes. Both are calculated as weighted averages of perceived gains\nand losses, influenced by ADS accuracy. Study 1 (N=315) used a 21-point\nThurstone scale to measure perceived gains and losses-key components of AAG and\nOPG-across typical tasks: route selection, overtaking, and collision avoidance.\nStudies 2 (N=54) and 3 (N=54) modeled decision quality under varying ADS\naccuracy and decision time. Results show with sufficient time (>3.5s), AAG\nconverges towards OPG, indicating rational decision-making, while limited time\nleads to intuitive and deterministic choices. Study 3 also linked AAG-OPG\ndeviations to irrational behaviors. An intervention study (N=8) and a pilot\n(N=4) employing voice alarms and multi-modal alarms based on these deviations\ndemonstrated AAG's potential to improve decision quality."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16236",
    "c_title":[
      "Imaging the photochemical dynamics of cyclobutanone with MeV ultrafast\n  electron diffraction"
    ],
    "c_abstract":[
      "We study the photoinduced chemical dynamics of cyclobutanone upon excitation\nat 200 nm to the 3s Rydberg state using MeV ultrafast electron diffraction\n(UED). We observe both the elastic scattering signal, which contains\ninformation about the structural dynamics, and the inelastic scattering signal,\nwhich encodes information about the electronic state. Our results suggest a\nsub-picosecond timescale for the photodissociation dynamics, and an excited\nstate lifetime of about 230 femtoseconds. The dissociation is found to be\ndominated by the C3 channel where cyclopropane and CO are produced. The\nbranching ratio of the C3 channel to the C2 channel where ethene and ketene are\nproduced, is estimated to be approximately 5:3. Our data suggest that the C3\nand C2 channels account for approximately 80% of the photoproducts, with the\nremaining 20% exhibiting ring-opened structures. It is found that the timescale\nassociated with the dissociation process in the C2 channel is shorter compared\nto that in the C3 channel. Leveraging the enhanced temporal resolution of MeV\nUED, our results provide a real-time mapping of the nuclear wavepacket\ndynamics, capturing the complete photochemical dynamics from S2 minimum through\nthe S1\/S0 conical intersection, and finally to the dissociation. Our\nexperimental results provide new insights into the Norrish Type I reaction and\ncan be used to benchmark non-adiabatic dynamics simulations."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-73",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19259",
    "b_title":[
      "Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for\n  Autonomous Drone FlighT at the Edge"
    ],
    "b_abstract":[
      "The integration of human-intuitive interactions into autonomous systems has\nbeen limited. Traditional Natural Language Processing (NLP) systems struggle\nwith context and intent understanding, severely restricting human-robot\ninteraction. Recent advancements in Large Language Models (LLMs) have\ntransformed this dynamic, allowing for intuitive and high-level communication\nthrough speech and text, and bridging the gap between human commands and\nrobotic actions. Additionally, autonomous navigation has emerged as a central\nfocus in robotics research, with artificial intelligence (AI) increasingly\nbeing leveraged to enhance these systems. However, existing AI-based navigation\nalgorithms face significant challenges in latency-critical tasks where rapid\ndecision-making is critical. Traditional frame-based vision systems, while\neffective for high-level decision-making, suffer from high energy consumption\nand latency, limiting their applicability in real-time scenarios. Neuromorphic\nvision systems, combining event-based cameras and spiking neural networks\n(SNNs), offer a promising alternative by enabling energy-efficient, low-latency\nnavigation. Despite their potential, real-world implementations of these\nsystems, particularly on physical platforms such as drones, remain scarce. In\nthis work, we present Neuro-LIFT, a real-time neuromorphic navigation framework\nimplemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural\nlanguage processing, Neuro-LIFT translates human speech into high-level\nplanning commands which are then autonomously executed using event-based\nneuromorphic vision and physics-driven planning. Our framework demonstrates its\ncapabilities in navigating in a dynamic environment, avoiding obstacles, and\nadapting to human instructions in real-time."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04981",
    "c_title":[
      "Theoretical study of the Spectroscopic measurements of Kerr non-linear\n  resonators with four-body interaction"
    ],
    "c_abstract":[
      "Quantum annealing provides a promising way to solve combinational\noptimization problems where the solutions correspond to the ground state of the\nIsing Hamiltonian. We can implement quantum annealing using the Kerr non-linear\nresonators, with bifurcation phenomena emerging when subjected to a parametric\ndrive. These bifurcated states can function as bases of qubits. Moreover,\nintegrating four-body interactions between physical qubits enables the\nestablishment of effective all-to-all long-range interactions between logical\nqubits, which is essential for practical quantum annealing. While theoretical\nproposals exist for creating four-body interactions within Kerr non-linear\nresonators, there has not been experimental verification through their\nspectroscopic signatures. In this paper, we theoretically investigate the\nspectroscopic measurements of Kerr non-linear resonators featuring four-body\ninteraction. We identify six distinct frequencies exhibiting population changes\nby employing resonant driving on one resonator and weak driving on another.\nAnalytical and numerical calculations validate these findings. Our study\ndemonstrates the potential of spectroscopy in characterizing systems with\nfour-body interactions, offering insights for realizing quantum annealing with\nKerr parametric oscillators."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-74",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15704",
    "b_title":[
      "Uncertainties in the Hubble Constant from Peculiar Velocities"
    ],
    "b_abstract":[
      "Recent measurements of the Hubble constant using type Ia supernovae\nexplicitly correct for their estimated peculiar velocities using the 2M++\nreconstruction of the local density field. The amount of uncertainty from this\nreconstruction procedure has thus far been unquantified. To rectify this, we\nuse mock universe realisations of the 2M++ catalogue and generate predicted\npeculiar velocities using the same method as the predictions that are used to\ncorrect for the Pantheon+ catalogue. We find that the method yields\nuncertainties of 0.3 km\/s\/Mpc and hence subdominant to the total uncertainty in\nH0."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04746",
    "c_title":[
      "Towards resilient cities: A hybrid simulation framework for risk\n  mitigation through data driven decision making"
    ],
    "c_abstract":[
      "Providing a comprehensive view of the city operation and offering useful\nmetrics for decision making is a well known challenge for urban risk analysis\nsystems. Existing systems are, in many cases, generalizations of previous\ndomain specific tools and or methodologies that may not cover all urban\ninterdependencies and makes it difficult to have homogeneous indicators. In\norder to overcome this limitation while seeking for effective support to\ndecision makers, this article introduces a novel hybrid simulation framework\nfor risk mitigation. The framework is built on a proposed city concept that\nconsiders urban space as a Complex Adaptive System composed by interconnected\nCritical Infrastructures. In this concept, a Social System, which models daily\npatterns and social interactions of the citizens in the Urban Landscape, drives\nthe CIs demand to configure the full city picture. The frameworks hybrid design\nintegrates agent based and network based modeling by breaking down city agents\ninto system dependent subagents, to enable both inter and intra system\ninteraction simulation, respectively. A layered structure of indicators at\ndifferent aggregation levels is also developed, to ensure that decisions are\nnot only data driven but also explainable. Therefore, the proposed simulation\nframework can serve as a DSS tool that allows the quantitative analysis of the\nimpact of threats at different levels. First, system level metrics can be used\nto get a broad view on the city resilience. Then, agent level metrics back\nthose figures and provide better explainability. On implementation, the\nproposed framework enables component reusability (for eased coding), simulation\nfederation (enabling the integration of existing system oriented simulators),\ndiscrete simulation in accelerated time (for rapid scenario simulation) and\ndecision oriented visualization (for informed outputs)."
    ],
    "c_categories":[
      [
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-75",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11972",
    "b_title":[
      "Waveguide QED Analysis of Quantum-Coherent Links for Modular Quantum\n  Computing"
    ],
    "b_abstract":[
      "Waveguides potentially offer an effective medium for interconnecting quantum\nprocessors within a modular framework, facilitating the coherent quantum state\ntransfer between the qubits across separate chips. In this work, we analyze a\nquantum communication scenario where two qubits are connected to a shared\nwaveguide, whose resonance frequency may match or not match that of the qubits.\nBoth configurations are simulated from the perspective of quantum\nelectrodynamics (QED) to assess the system behavior and key factors that\ninfluence reliable inter-chip communication. The primary performance metrics\nanalyzed are quantum state transfer fidelity and latency, considering the\nimpact of key system parameters such as the qubit-waveguide detuning, coupling\nstrength, waveguide decay rate, and qubit decay rate. We present the system\ndesign requirements that yield enhanced state transmission fidelity rates and\nlowered latency, and discuss the scalability of waveguide-mediated\ninterconnects considering various configurations of the system."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2501.09977",
    "c_title":[
      "The Impossibility of the Almost Pareto Principles"
    ],
    "c_abstract":[
      "This study proposes a new efficiency requirement, a minimal almost weak\nPareto principle, which says that x is socially better than y whenever the only\none individual never prefers y to x, and all the others prefers x to y. Then, I\nshow that even if the Pareto principle is modified into this harmless form,\nthat seems sufficiently acceptable in the setting of social choice with\nvariable population sizes or incomplete preferences, it violates acyclicity.\nFurthermore, it is shown that under this framework, a modified Pareto\nindifference and usual weak Pareto are inconsistent. These results are serious\nbecause they have a wide range of applications, not only to population\neconomics and intergenerational equity analysis, but also to welfare\nevaluations of incomplete preferences and multi-dimensional well-being. In\norder to solve these problems, it is necessary to impose very strong\nassumptions on various contexts of social choice problems."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-76",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20382",
    "b_title":[
      "Physics-Driven Data Generation for Contact-Rich Manipulation via\n  Trajectory Optimization"
    ],
    "b_abstract":[
      "We present a low-cost data generation pipeline that integrates physics-based\nsimulation, human demonstrations, and model-based planning to efficiently\ngenerate large-scale, high-quality datasets for contact-rich robotic\nmanipulation tasks. Starting with a small number of embodiment-flexible human\ndemonstrations collected in a virtual reality simulation environment, the\npipeline refines these demonstrations using optimization-based kinematic\nretargeting and trajectory optimization to adapt them across various robot\nembodiments and physical parameters. This process yields a diverse, physically\nconsistent dataset that enables cross-embodiment data transfer, and offers the\npotential to reuse legacy datasets collected under different hardware\nconfigurations or physical parameters. We validate the pipeline's effectiveness\nby training diffusion policies from the generated datasets for challenging\ncontact-rich manipulation tasks across multiple robot embodiments, including a\nfloating Allegro hand and bimanual robot arms. The trained policies are\ndeployed zero-shot on hardware for bimanual iiwa arms, achieving high success\nrates with minimal human input. Project website:\nhttps:\/\/lujieyang.github.io\/physicsgen\/."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11544",
    "c_title":[
      "A Survey of Exact and Approximation Algorithms for Linear-Parametric\n  Optimization Problems"
    ],
    "c_abstract":[
      "Linear-parametric optimization, where multiple objectives are combined into a\nsingle objective using linear combinations with parameters as coefficients, has\nnumerous links to other fields in optimization and a wide range of application\nareas. In this survey, we provide a comprehensive overview of structural\nresults and algorithmic strategies for solving linear-parametric optimization\nproblems exactly and approximately. Transferring concepts from related areas\nsuch as multi-objective optimization provides further relevant results. The\nsurvey consists of two parts: First, we list strategies that work in a general\nfashion and do not rely on specific problem structures. Second, we look at\nwell-studied parametric optimization problems and cover both important\ntheoretical results and specialized algorithmic approaches for these problems.\nAmong these problems are parametric variants of shortest path problems, minimum\ncost flow and maximum flow problems, spanning tree problems, the knapsack\nproblem, and matching problems. Overall, we cover the results from 128\npublications (and refer to 33 supplemental works) published between 1963 and\n2024."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-77",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13469",
    "b_title":[
      "Conditional Electrocardiogram Generation Using Hierarchical Variational\n  Autoencoders"
    ],
    "b_abstract":[
      "Cardiovascular diseases (CVDs) are disorders impacting the heart and\ncirculatory system. These disorders are the foremost and continuously\nescalating cause of mortality worldwide. One of the main tasks when working\nwith CVDs is analyzing and identifying pathologies on a 12-lead\nelectrocardiogram (ECG) with a standard 10-second duration. Using machine\nlearning (ML) in automatic ECG analysis increases CVD diagnostics'\navailability, speed, and accuracy. However, the most significant difficulty in\ndeveloping ML models is obtaining a sufficient training dataset. Due to the\nlimitations of medical data usage, such as expensiveness, errors, the ambiguity\nof labels, imbalance of classes, and privacy issues, utilizing synthetic\nsamples depending on specific pathologies bypasses these restrictions and\nimproves algorithm quality. Existing solutions for the conditional generation\nof ECG signals are mainly built on Generative Adversarial Networks (GANs), and\nonly a few papers consider the architectures based on Variational Autoencoders\n(VAEs), showing comparable results in recent works. This paper proposes the\npublicly available conditional Nouveau VAE model for ECG signal generation\n(cNVAE-ECG), which produces high-resolution ECGs with multiple pathologies. We\nprovide an extensive comparison of the proposed model on various practical\ndownstream tasks, including transfer learning scenarios showing an area under\nthe receiver operating characteristic (AUROC) increase up to 2% surpassing\nGAN-like competitors."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04533",
    "c_title":[
      "Polarization-Dependent Loss Mitigation via Orthogonal Design Precoding\n  and Interference Cancellation"
    ],
    "c_abstract":[
      "Recent work by Shehadeh and Kschischang provides a simple capacity-achieving\nscheme for channels with polarization-dependent loss (PDL) under common\nmodeling assumptions via a careful choice of orthogonal-design-based precoding\nand interference cancellation. This letter extends that work with a\nsimulation-based demonstration showing that this scheme remains highly\neffective at mitigating PDL in the highly practical setting of 16-QAM with\nChase-decoded extended Hamming inner codes rather than the near-capacity inner\ncodes considered in the original work. An alternative near-optimal variation of\nthis scheme is also provided requiring only one inner code rather than two and\nsuffering no penalty in the absence of PDL, making it much more practical."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-78",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12202",
    "b_title":[
      "Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D\n  Assets Generation"
    ],
    "b_abstract":[
      "We present Hunyuan3D 2.0, an advanced large-scale 3D synthesis system for\ngenerating high-resolution textured 3D assets. This system includes two\nfoundation components: a large-scale shape generation model -- Hunyuan3D-DiT,\nand a large-scale texture synthesis model -- Hunyuan3D-Paint. The shape\ngenerative model, built on a scalable flow-based diffusion transformer, aims to\ncreate geometry that properly aligns with a given condition image, laying a\nsolid foundation for downstream applications. The texture synthesis model,\nbenefiting from strong geometric and diffusion priors, produces high-resolution\nand vibrant texture maps for either generated or hand-crafted meshes.\nFurthermore, we build Hunyuan3D-Studio -- a versatile, user-friendly production\nplatform that simplifies the re-creation process of 3D assets. It allows both\nprofessional and amateur users to manipulate or even animate their meshes\nefficiently. We systematically evaluate our models, showing that Hunyuan3D 2.0\noutperforms previous state-of-the-art models, including the open-source models\nand closed-source models in geometry details, condition alignment, texture\nquality, and etc. Hunyuan3D 2.0 is publicly released in order to fill the gaps\nin the open-source 3D community for large-scale foundation generative models.\nThe code and pre-trained weights of our models are available at:\nhttps:\/\/github.com\/Tencent\/Hunyuan3D-2"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01429",
    "c_title":[
      "A kinematically constrained kick distribution for isolated neutron stars"
    ],
    "c_abstract":[
      "The magnitudes of the velocity kicks that neutron stars (NSs) obtain at their\nformation have long been a topic of discussion, with the latest studies\nanalysing the velocities of young pulsars and favouring a bimodal kick\ndistribution. In previous work, a novel method was proposed to determine kicks\nbased on the eccentricity of Galactic trajectories. We applied this method to\nthe isolated pulsars with known parallax in order to kinematically constrain\nthe NS natal kick distribution and investigate its proposed bimodality. Since\nthis method is applicable to older pulsars, we effectively increase the sample\nsize with ${\\sim}50\\%$ compared to the pulsars younger than $10$ Myr. We\nassumed the velocity vectors of the pulsars to be distributed isotropically in\nthe local standard of rest frame. These velocity vectors were used to trace\nback the trajectories of the NSs through the Galaxy and estimate their\neccentricity. Then, we simulated kicked objects in order to evaluate the\nrelationship between kick magnitude and Galactic eccentricity, which was used\nto infer the kicks corresponding to the estimated eccentricities. The resulting\nkick distributions indeed show a bimodal structure for young pulsars. However,\nfor older pulsars the bimodality vanishes and instead we find a log-normal kick\ndistribution peaking at ${\\sim}200$ km\/s and a median of ${\\sim}400$ km\/s. We\ntherefore conclude that the natal kicks of these isolated NSs are best\ndescribed by log-normal distribution with $\\mu=6.38$ and $\\sigma=1.01$. This\nanalysis reveals no evidence for bimodality in the larger sample, and we\nsuggest that the bimodality found by existing literature may be caused by\nPoisson noise due to their relatively small sample size."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-79",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07841",
    "b_title":[
      "Fingerprints of triaxiality in the charge radii of neutron-rich\n  Ruthenium"
    ],
    "b_abstract":[
      "We present the first measurements with a new collinear laser spectroscopy\nsetup at the Argonne Tandem Linac Accelerator System utilizing its unique\ncapability to deliver neutron-rich refractory metal isotopes produced by the\nspontaneous fission of 252Cf. We measured isotope shifts from optical spectra\nfor nine radioactive ruthenium isotopes 106-114Ru, reaching deep into the\nmid-shell region. The extracted charge radii are in excellent agreement with\npredictions from the Brussels-Skyrme-on-a-Grid models that account for the\ntriaxial deformation of nuclear ground states in this region. We show that\ntriaxial deformation impacts charge radii in models that feature shell effects,\nin contrast to what could be concluded from a liquid drop analysis. This\nindicates that this exotic type of deformation should not be neglected in\nregions where it is known to occur, even if its presence cannot be\nunambiguously inferred through laser spectroscopy."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02738",
    "c_title":[
      "SCSC: A Novel Standards-Compatible Semantic Communication Framework for\n  Image Transmission"
    ],
    "c_abstract":[
      "Joint source-channel coding (JSCC) is a promising paradigm for\nnext-generation communication systems, particularly in challenging transmission\nenvironments. In this paper, we propose a novel standard-compatible JSCC\nframework for the transmission of images over multiple-input multiple-output\n(MIMO) channels. Different from the existing end-to-end AI-based DeepJSCC\nschemes, our framework consists of learnable modules that enable communication\nusing conventional separate source and channel codes (SSCC), which makes it\namenable for easy deployment on legacy systems. Specifically, the learnable\nmodules involve a preprocessing-empowered network (PPEN) for preserving\nessential semantic information, and a precoder \\& combiner-enhanced network\n(PCEN) for efficient transmission over a resource-constrained MIMO channel. We\ntreat existing compression and channel coding modules as non-trainable blocks.\nSince the parameters of these modules are non-differentiable, we employ a proxy\nnetwork that mimics their operations when training the learnable modules.\nNumerical results demonstrate that our scheme can save more than 29\\% of the\nchannel bandwidth, and requires lower complexity compared to the constrained\nbaselines. We also show its generalization capability to unseen datasets and\ntasks through extensive experiments."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-80",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11293",
    "b_title":[
      "Growth of Cosmic Strings beyond Kination"
    ],
    "b_abstract":[
      "A novel mechanism for the production of a cosmic network of fundamental\nsuperstrings based on a time-varying string tension has been recently proposed\nin the context of a kinating background driven by the volume modulus of string\ncompactifications. In this paper, we generalise the analysis of this growth\nmechanism by using dynamical system techniques. We first study the cosmological\ngrowth of strings in a spatially-flat Universe filled with a perfect fluid and\na field-dependent tension, finding the fixed points of the phase space of this\nsystem. We then apply this analysis to fundamental strings and EFT strings\nobtained from wrapping $p$-branes on $(p-1)$-cycles. We find a cosmological\ngrowth for fundamental strings even without kination, as in scaling fixed\npoints, and for EFT strings arising from D3- and NS5-branes wrapped around\nfibration cycles."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00037",
    "c_title":[
      "Zero-Shot Defense Against Toxic Images via Inherent Multimodal Alignment\n  in LVLMs"
    ],
    "c_abstract":[
      "Large Vision-Language Models (LVLMs) have made significant strides in\nmultimodal comprehension, thanks to extensive pre-training and fine-tuning on\nlarge-scale visual datasets. However, despite their robust textual safety\nmechanisms, they remain vulnerable to harmful visual inputs. Existing\nsafeguards-typically relying on pre-filtering or fine-tuning-incur high costs\nand diminish overall utility. To address this critical vulnerability, we\nintroduce SafeCLIP, a lightweight method that leverages LVLMs inherent\nmultimodal alignment for zero-shot toxic image detection. By projecting CLIPs\ndiscarded CLS token into its text space and matching it with toxic descriptors,\nSafeCLIP detects harmful content without any architectural changes-adding\nminimal latency and enabling dynamic safety corrections during inference and\nfine-tuning.Experiments show that SafeCLIP achieves a 66.9% defense success\nrate with only 3.2% false positive rate and 7.2% overhead. In contrast,\nstate-of-the-art methods achieve 52.9% success but have a 10.7% false positive\nrate and 210% overhead. Our work demonstrates that leveraging inherent\nmultimodal alignment can yield efficient, low-cost LVLM safety. Code is\navailable at anonymous.4open.science\/r\/safeclip-2C01."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-81",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01005",
    "b_title":[
      "Noise-resilient solid host for electron qubits above 100 mK"
    ],
    "b_abstract":[
      "Cryogenic solid neon has recently emerged as a pristine solid host for single\nelectron qubits. At ~10 mK temperatures, electron-on-solid-neon (eNe) charge\nqubits have exhibited exceptionally long coherence times and high operation\nfidelities. To advance this platform towards a scalable quantum information\narchitecture, systematic characterization of its noise feature is imperative.\nHere, we show the remarkable resilience of solid neon against charge and\nthermal noises when eNe qubits are operated away from the charge-insensitive\nsweet-spot and at elevated temperatures. Without optimizing neon growth, the\nmeasured charge (voltage) noise on solid neon is already orders of magnitude\nlower than that in most stringently grown semiconductors, rivaling the best\nrecords to date. Up to 400 mK, the eNe charge qubits operated at ~5 GHz can\nmaintain their echo coherence times over 1 microsecond. These observations\nhighlight solid neon as an ideal host for quantum information processing at\nhigher temperatures and larger scales."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14398",
    "c_title":[
      "Matrix-weighted bounds in variable Lebesgue spaces"
    ],
    "c_abstract":[
      "In this paper we prove boundedness of Calder\\'on-Zygmund operators and the\nChrist-Goldberg maximal operator in the matrix-weighted variable Lebesgue\nspaces recently introduced by Cruz-Uribe and the second author. Our main tool\nto prove these bounds is through bounding a Goldberg auxiliary maximal\noperator.\n  As an application, we obtain a quantitative extrapolation theorem for\nmatrix-weighted variable Lebesgue spaces from the recent framework of\ndirectional Banach function spaces of the first author."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-82",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14946",
    "b_title":[
      "Has the Paris Agreement Shaped Emission Trends? A Panel VECM Analysis of\n  Energy, Growth, and CO$_2$ in 106 Middle-Income Countries"
    ],
    "b_abstract":[
      "Rising CO$_2$ emissions remain a critical global challenge, particularly in\nmiddle-income countries where economic growth drives environmental degradation.\nThis study examines the long-run and short-run relationships between CO$_2$\nemissions, energy use, GDP per capita, and population across 106 middle-income\ncountries from 1980 to 2023. Using a Panel Vector Error Correction Model\n(VECM), we assess the impact of the Paris Agreement (2015) on emissions while\nconducting cointegration tests to confirm long-run equilibrium relationships.\nThe findings reveal a strong long-run relationship among the variables, with\nenergy use as the dominant driver of emissions, while GDP per capita has a\nmoderate impact. However, the Paris Agreement has not significantly altered\nemissions trends in middle-income economies. Granger causality tests indicate\nthat energy use strongly causes emissions, but GDP per capita and population do\nnot exhibit significant short-run causal effects. Variance decomposition\nconfirms that energy shocks have the most persistent effects, and impulse\nresponse functions (IRFs) show emissions trajectories are primarily shaped by\neconomic activity rather than climate agreements. Robustness checks, including\nautocorrelation tests, polynomial root stability, and Yamagata-Pesaran slope\nhomogeneity tests, validate model consistency. These results suggest that while\nglobal agreements set emissions reduction goals, their effectiveness remains\nlimited without stronger national climate policies, sectoral energy reforms,\nand financial incentives for clean energy adoption to ensure sustainable\neconomic growth."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.02872",
    "c_title":[
      "Two-Dimensional Unknown View Tomography from Unknown Angle Distributions"
    ],
    "c_abstract":[
      "This study presents a technique for 2D tomography under unknown viewing\nangles when the distribution of the viewing angles is also unknown. Unknown\nview tomography (UVT) is a problem encountered in cryo-electron microscopy and\nin the geometric calibration of CT systems. There exists a moderate-sized\nliterature on the 2D UVT problem, but most existing 2D UVT algorithms assume\nknowledge of the angle distribution which is not available usually. Our\nproposed methodology formulates the problem as an optimization task based on\ncross-validation error, to estimate the angle distribution jointly with the\nunderlying 2D structure in an alternating fashion. We explore the algorithm's\ncapabilities for the case of two probability distribution models: a\nsemi-parametric mixture of von Mises densities and a probability mass function\nmodel. We evaluate our algorithm's performance under noisy projections using a\nPCA-based denoising technique and Graph Laplacian Tomography (GLT) driven by\norder statistics of the estimated distribution, to ensure near-perfect\nordering, and compare our algorithm to intuitive baselines."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-83",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01983",
    "b_title":[
      "Diagrammatics of information"
    ],
    "b_abstract":[
      "We introduce a diagrammatic perspective for Shannon entropy created by the\nfirst author and Mikhail Khovanov and connect it to information theory and\nmutual information. We also give two complete proofs that the $5$-term\ndilogarithm deforms to the $4$-term infinitesimal dilogarithm."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math-ph",
        "math.IT",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15096",
    "c_title":[
      "When the Future Becomes the Past: Taming Temporal Correspondence for\n  Self-supervised Video Representation Learning"
    ],
    "c_abstract":[
      "The past decade has witnessed notable achievements in self-supervised\nlearning for video tasks. Recent efforts typically adopt the Masked Video\nModeling (MVM) paradigm, leading to significant progress on multiple video\ntasks. However, two critical challenges remain: 1) Without human annotations,\nthe random temporal sampling introduces uncertainty, increasing the difficulty\nof model training. 2) Previous MVM methods primarily recover the masked patches\nin the pixel space, leading to insufficient information compression for\ndownstream tasks. To address these challenges jointly, we propose a\nself-supervised framework that leverages Temporal Correspondence for video\nRepresentation learning (T-CoRe). For challenge 1), we propose a sandwich\nsampling strategy that selects two auxiliary frames to reduce reconstruction\nuncertainty in a two-side-squeezing manner. Addressing challenge 2), we\nintroduce an auxiliary branch into a self-distillation architecture to restore\nrepresentations in the latent space, generating high-level semantic\nrepresentations enriched with temporal information. Experiments of T-CoRe\nconsistently present superior performance across several downstream tasks,\ndemonstrating its effectiveness for video representation learning. The code is\navailable at https:\/\/github.com\/yafeng19\/T-CORE."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-84",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.00873",
    "b_title":[
      "Exploring Structured Semantic Priors Underlying Diffusion Score for\n  Test-time Adaptation"
    ],
    "b_abstract":[
      "Capitalizing on the complementary advantages of generative and discriminative\nmodels has always been a compelling vision in machine learning, backed by a\ngrowing body of research. This work discloses the hidden semantic structure\nwithin score-based generative models, unveiling their potential as effective\ndiscriminative priors. Inspired by our theoretical findings, we propose DUSA to\nexploit the structured semantic priors underlying diffusion score to facilitate\nthe test-time adaptation of image classifiers or dense predictors. Notably,\nDUSA extracts knowledge from a single timestep of denoising diffusion, lifting\nthe curse of Monte Carlo-based likelihood estimation over timesteps. We\ndemonstrate the efficacy of our DUSA in adapting a wide variety of competitive\npre-trained discriminative models on diverse test-time scenarios. Additionally,\na thorough ablation study is conducted to dissect the pivotal elements in DUSA.\nCode is publicly available at https:\/\/github.com\/BIT-DA\/DUSA."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09558",
    "c_title":[
      "The Topological form is the Pfaffian form"
    ],
    "c_abstract":[
      "For a given graph $G$, Budzik, Gaiotto, Kulp, Wang, Williams, Wu, Yu, and the\nfirst author studied a ''topological'' differential form $\\alpha_G$, which\nexpresses violations of BRST-closedness of a quantum field theory along a\nsingle topological direction. In a seemingly unrelated context, Brown, Panzer,\nand the second author studied a ''Pfaffian'' differential form $\\phi_G$, which\nis used to construct cohomology classes of the odd commutative graph complex.\nWe give an explicit combinatorial proof that $\\alpha_G$ coincides with\n$\\phi_G$. We also discuss the equivalence of several properties of these forms,\nwhich had been established independently for both contexts in previous work."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.CO",
        "math.MP",
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-85",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13911",
    "b_title":[
      "Application of autoresonance in rapid beam extraction of synchrotrons"
    ],
    "b_abstract":[
      "In recent years, ultra-high dose rate (FLASH) radiotherapy has become a novel\ncancer treatment technique because of its similar tumor-killing efficacy as\nconventional particle therapy while significantly protecting normal tissues.\nHowever, due to the limitation of particle number, achieving FLASH condition in\na compact heavy-ion synchrotron requires a short extraction time of tens of\nmilliseconds, which is challenging for the conventional RF-KO method. To tackle\nthis challenge, we introduce autoresonance into the third-order resonant\nextraction for the first time, offering an alternative to the conventional\napproach of merely increasing the excitation strength. By leveraging a strong\ndetuning effect, a frequency sweeping excitation with small amplitude can drive\nthe entire beam into the autoresonant state, thus enabling rapid beam\nextraction within a single sweeping period. Compared with the conventional\nmethod, this innovative method requires only the addition of an octupole\nmagnet. At the same time, it shows that the conventional RF-KO method has a\nhigh autoresonance threshold, so that only a small number of particles that\nmeet the threshold can be excited to large amplitude and be extracted in each\nsweeping period. In this paper, the autoresonance threshold of a particle in\nthe presence of sextupole and octupole magnetic fields is analyzed, and the\nsingle particle simulation shows good agreement with the theoretical formula.\nFurthermore, the autoresonance based rapid extraction process is simulated and\nstudied, revealing the possibility of millisecond scale beam extraction."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04783",
    "c_title":[
      "Embedding loose trees in $k$-uniform hypergraphs"
    ],
    "c_abstract":[
      "A classical result of Koml\\'os, S\\'ark\\\"ozy and Szemer\\'edi shows that every\nlarge $n$-vertex graph with minimum degree at least $(1\/2+\\gamma)n$ contains\nall spanning trees of bounded degree. We generalised this result to loose\nspanning hypertrees in $k$-uniform hypergraphs, that is, linear hypergraphs\nobtained by subsequently adding edges sharing a single vertex with a previous\nedge.\n  We give a general sufficient condition for embedding loose trees with bounded\ndegree. In particular, we show that for all $k\\ge 4$, every $n$-vertex\n$k$-uniform hypergraph with $n\\ge n_0(k,\\gamma, \\Delta)$ and minimum\n$(k-2)$-degree at least $(1\/2+\\gamma)\\binom{n}{k-2}$ contains every spanning\nloose tree with maximum vertex degree at most $\\Delta$. This bound is\nasymptotically tight. This generalises a result of Pehova and Petrova, who\nproved the case when $k=3$ and of Pavez-Sign\\'e, Sanhueza-Matamala and Stein,\nwho considered the codegree threshold for bounded degree tight trees."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-86",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05214",
    "b_title":[
      "Gaussian Random Fields as an Abstract Representation of Patient Metadata\n  for Multimodal Medical Image Segmentation"
    ],
    "b_abstract":[
      "The growing rate of chronic wound occurrence, especially in patients with\ndiabetes, has become a concerning trend in recent years. Chronic wounds are\ndifficult and costly to treat, and have become a serious burden on health care\nsystems worldwide. Chronic wounds can have devastating consequences for the\npatient, with infection often leading to reduced quality of life and increased\nmortality risk. Innovative deep learning methods for the detection and\nmonitoring of such wounds have the potential to reduce the impact to both\npatient and clinician. We present a novel multimodal segmentation method which\nallows for the introduction of patient metadata into the training workflow\nwhereby the patient data are expressed as Gaussian random fields. Our results\nindicate that the proposed method improved performance when utilising multiple\nmodels, each trained on different metadata categories. Using the Diabetic Foot\nUlcer Challenge 2022 test set, when compared to the baseline results\n(intersection over union = 0.4670, Dice similarity coefficient = 0.5908) we\ndemonstrate improvements of +0.0220 and +0.0229 for intersection over union and\nDice similarity coefficient respectively. This paper presents the first study\nto focus on integrating patient data into a chronic wound segmentation\nworkflow. Our results show significant performance gains when training\nindividual models using specific metadata categories, followed by average\nmerging of prediction masks using distance transforms. All source code for this\nstudy is available at:\nhttps:\/\/github.com\/mmu-dermatology-research\/multimodal-grf"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05145",
    "c_title":[
      "Direct Gradient Computation of Parameterized Quantum Circuits"
    ],
    "c_abstract":[
      "The barren plateau phenomenon, where the gradients of parametrized quantum\ncircuits become vanishingly small, poses a significant challenge in quantum\nmachine learning. While previous studies attempted to explain the barren\nplateau phenomenon using the Weingarten formula, the reliance on the Weingarten\nformula leads to inaccurate conclusions. In this study, we consider a unitary\noperator \\(U\\) consisting of rotation gates and perform an exact calculation of\nthe expectation required for the gradient computation. Our approach allows us\nto obtain the gradient expectation and variance directly. Our analysis reveals\nthat gradient expectations are not zero, as opposed to the results derived\nusing the Weingarten formula, but depend on the number of qubits in the system.\nFurthermore, we demonstrate how the number of effective parameters, circuit\ndepth, and gradient variance are interconnected in deep parameterized quantum\ncircuits. Numerical simulations further confirm the validity of our theoretical\nresults. Our approach provides a more accurate framework for analyzing quantum\ncircuit optimization."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-87",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15633",
    "b_title":[
      "RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes"
    ],
    "b_abstract":[
      "3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can\nproduce high-fidelity novel views. However, previous GS-based methods primarily\ntarget indoor scenes and rely on RGB-D sensors or pre-trained depth estimation\nmodels, hence underperforming in outdoor scenarios. To address this issue, we\npropose a RGB-only gaussian splatting SLAM method for unbounded outdoor\nscenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network\nto generate consistent pointmaps between frames for pose estimation. Compared\nto commonly used depth maps, pointmaps include spatial relationships and scene\ngeometry across multiple views, enabling robust camera pose estimation. Then,\nwe propose integrating the estimated camera poses with 3DGS rendering as an\nend-to-end differentiable pipeline. Our method achieves simultaneous\noptimization of camera poses and 3DGS scene parameters, significantly enhancing\nsystem tracking accuracy. Specifically, we also design an adaptive scale mapper\nfor the pointmap regression network, which provides more accurate pointmap\nmapping to the 3DGS map representation. Our experiments on the Waymo dataset\ndemonstrate that OpenGS-SLAM reduces tracking error to 9.8\\% of previous 3DGS\nmethods, and achieves state-of-the-art results in novel view synthesis. Project\nPage: https:\/\/3dagentworld.github.io\/opengs-slam\/"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02078",
    "c_title":[
      "Einstein multiply warped products and generalized Kasner manifolds with\n  multidimensional base"
    ],
    "c_abstract":[
      "The purpose of this paper is to provide conditions for the existence or non\nexistence of non trivial Einstein multiply warped products, specially of\ngeneralised Kasner type; as well as to show estimates of the Einstein parameter\nthat condition the existence of such metrics."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-88",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03864",
    "b_title":[
      "Temporal regularity for the stochastic heat equation with rough\n  dependence in space"
    ],
    "b_abstract":[
      "Consider the nonlinear stochastic heat equation $$\n  \\frac{\\partial u (t,x)}{\\partial t}=\\frac{\\partial^2 u (t,x)}{\\partial x^2}+\n\\sigma(u (t,x))\\dot{W}(t,x),\\quad t> 0,\\,\n  x\\in \\mathbb{R}, $$ where $\\dot W$ is a Gaussian noise which is white in time\nand has the covariance of a fractional Brownian motion with Hurst parameter\n$H\\in(\\frac 14,\\frac 12)$ in the space variable. When $\\sigma(0)=0$, the\nwell-posedness of the solution and its H\\\"older continuity have been proved by\nHu et al. \\cite{HHLNT2017}. In this paper, we study the asymptotic properties\nof the temporal gradient $u(t+\\varepsilon, x)-u(t, x)$ at any fixed $t \\ge 0$\nand $x\\in \\mathbb R$, as $\\varepsilon\\downarrow 0$. As applications, we deduce\nKhintchine's law of iterated logarithm, Chung's law of iterated logarithm, and\na result on the $q$-variations of the temporal process $\\{u(t, x)\\}_{t \\ge 0}$,\nwhere $x\\in \\mathbb R$ is fixed."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00070",
    "c_title":[
      "Systematic Review of Cybersecurity in Banking: Evolution from\n  Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain,\n  Policies and Practice"
    ],
    "c_abstract":[
      "Throughout the history from pre-industry 4.0 to post-industry 4.0,\ncybersecurity at banks has undergone significant changes. Pre-industry 4.0\ncyber security at banks relied on individual security methods that were highly\nmanual and had low accuracy. When moving to post-industry 4.0, cybersecurity at\nbanks had a major turning point with security methods that combined different\ntechnologies such as Artificial Intelligence (AI), Blockchain, IoT, automating\nnecessary processes and significantly increasing the defence layer for banks.\nHowever, along with the development of new technologies, the current challenge\nof cybersecurity at banks lies in scalability, high costs and resources in both\nmoney and time for R&D of defence methods along with the threat of high-tech\ncybercriminals growing and expanding. This report goes from introducing the\nimportance of cybersecurity at banks, analyzing their management, operational\nand business objectives, evaluating pre-industry 4.0 technologies used for\ncybersecurity at banks to assessing post-industry 4.0 technologies focusing on\nArtificial Intelligence and Blockchain, discussing current policies and\npractices and ending with discussing key advantages and challenges for 4.0\ntechnologies and recommendations for further developing cybersecurity at banks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CE",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-89",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06678",
    "b_title":[
      "Quantile Multi-Armed Bandits with 1-bit Feedback"
    ],
    "b_abstract":[
      "In this paper, we study a variant of best-arm identification involving\nelements of risk sensitivity and communication constraints. Specifically, the\ngoal of the learner is to identify the arm with the highest quantile reward,\nwhile the communication from an agent (who observes rewards) and the learner\n(who chooses actions) is restricted to only one bit of feedback per arm pull.\nWe propose an algorithm that utilizes noisy binary search as a subroutine,\nallowing the learner to estimate quantile rewards through 1-bit feedback. We\nderive an instance-dependent upper bound on the sample complexity of our\nalgorithm and provide an algorithm-independent lower bound for specific\ninstances, with the two matching to within logarithmic factors under mild\nconditions, or even to within constant factors in certain low error probability\nscaling regimes. The lower bound is applicable even in the absence of\ncommunication constraints, and thus we conclude that restricting to 1-bit\nfeedback has a minimal impact on the scaling of the sample complexity."
    ],
    "b_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16801",
    "c_title":[
      "Measurement Uncertainty in Infrared Spectroscopy with Entangled Photon\n  Pairs"
    ],
    "c_abstract":[
      "Spectroscopy with entanglement has shown great potential to break limitations\nof traditional spectroscopic measurements, yet the role of entanglement in\nspectroscopic multi-parameter joint measurement, particularly in the infrared\noptical range, remains elusive. Here, we find an uncertain relation that\nconstrains the precision of infrared spectroscopic multi-parameter measurements\nusing entangled photon pairs. Under such a relation, we demonstrate a trade-off\nbetween the measurement precisions of the refractive index and absorption\ncoefficient of the medium in the infrared range, and also illustrate how to\nbalance their respective estimation errors. Our work shall provide guidance\ntowards the future experimental designs and applications in\nentanglement-assisted spectroscopy."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-90",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09690",
    "b_title":[
      "Operator models and analytic subordination for operator-valued free\n  convolution powers"
    ],
    "b_abstract":[
      "We revisit the theory of operator-valued free convolution powers given by a\ncompletely positive map $\\eta$. We first give a general result, with a new\nanalytic proof, that the $\\eta$-convolution power of the law of $X$ is realized\nby $V^*XV$ for any operator $V$ satisfying certain conditions, which unifies\nNica and Speicher's construction in the scalar-valued setting and\nShlyakhtenko's construction in the operator-valued setting. Second, we provide\nan analog, for the setting of $\\eta$-valued convolution powers, of the analytic\nsubordination for conditional expectations that holds for additive free\nconvolution. Finally, we describe a Hilbert-space manipulation that explains\nthe equivalence between the $n$-fold additive free convolution and the\nconvolution power with respect to $\\eta = n \\operatorname{id}$."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.21245",
    "c_title":[
      "TimesBERT: A BERT-Style Foundation Model for Time Series Understanding"
    ],
    "c_abstract":[
      "Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-91",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08689",
    "b_title":[
      "Mining Diamonds in labeled Transition Systems"
    ],
    "b_abstract":[
      "Labeled transition systems can be a great way to visualize the complex\nbehavior of parallel and communicating systems. However, if, during a\nparticular timeframe, no synchronization or communication between processes\noccurs, then multiple parallel sequences of actions are able to interleave\narbitrarily, and the resulting graph quickly becomes too complex for the human\neye to understand easily. With that in mind, we propose an exact formalization\nof these arbitrary interleavings, and an algorithm to find all said\ninterleavings in deterministic LTSs, to reduce the visual complexity of labeled\ntransition systems."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03189",
    "c_title":[
      "Equations of motion for compact binary systems in general relativity: Do\n  they depend on the bodies' internal structure at the third post-Newtonian\n  order?"
    ],
    "c_abstract":[
      "We present and discuss the possibility, derived from work carried out 20\nyears ago, that the equations of motion for compact binary neutron stars at the\nthird post-Newtonian (3PN) order in general relativity might actually depend on\nthe internal structure of the bodies. These effects involve integrals over the\ndensity and internal gravitational potentials of the bodies that are\nindependent of the mass and radius of the bodies, but dependent on their\nequations of state. These effects could alter the coefficients in the 3PN\nequations derived using ``point mass'' methods by as much as 100 percent. They\nwere found in independent calculations done at Washington University using the\nDirect Integration of the Relaxed Einstein Equations (DIRE) approach, and at\nthe Institut d'Astrophysique de Paris using the Multipolar post-Minkowskian\n(MPPM) approach. Neither calculation was completed because of the enormous\ncomplexity of the algebraic computations and the limitations of software of the\nday (Maple, Mathematica), and because of an assumption (hope) that the effects\nwould somehow cancel or be removable by some transformation. If these\nstructure-dependent effects are real, but are not incorporated into\ngravitational waveforms, they could severely impact efforts using\nnext-generation gravitational-wave interferometers to extract information about\nthe equation of state for neutron star matter from gravitational-wave signals\nfrom binary neutron star or black hole-neutron star mergers. Conversely, if\nthey exactly cancel or can be absorbed into renormalized masses or shifted\npositions of each body, this would provide further support for the Strong\nEquivalence Principle of general relativity."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-92",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06135",
    "b_title":[
      "Phase structure analysis of CP(1) model with $\\theta$ term by tensor\n  renormalization group"
    ],
    "b_abstract":[
      "We analyze the phase structure of 2d lattice CP(1) model with $\\theta$ term\nby using the bond-weighted tensor renormalization group method. We propose a\nnew tensor network representation for the model using the quadrature scheme and\nconfirm that its accuracy is better than that of the conventional\ncharacter-like expansion. As a probe to study the phase structure, we adopt the\ncentral charge and the scaling dimensions. The numerical results indicate an\nexistence of critical point at $\\theta=\\pi$, which is consistent with the\nHaldane's conjecture."
    ],
    "b_categories":[
      [
        "hep-lat"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07823",
    "c_title":[
      "Runtime Tunable Tsetlin Machines for Edge Inference on eFPGAs"
    ],
    "c_abstract":[
      "Embedded Field-Programmable Gate Arrays (eFPGAs) allow for the design of\nhardware accelerators of edge Machine Learning (ML) applications at a lower\npower budget compared with traditional FPGA platforms. However, the limited\neFPGA logic and memory significantly constrain compute capabilities and model\nsize. As such, ML application deployment on eFPGAs is in direct contrast with\nthe most recent FPGA approaches developing architecture-specific\nimplementations and maximizing throughput over resource frugality. This paper\nfocuses on the opposite side of this trade-off: the proposed eFPGA accelerator\nfocuses on minimizing resource usage and allowing flexibility for on-field\nrecalibration over throughput. This allows for runtime changes in model size,\narchitecture, and input data dimensionality without offline resynthesis. This\nis made possible through the use of a bitwise compressed inference architecture\nof the Tsetlin Machine (TM) algorithm. TM compute does not require any\nmultiplication operations, being limited to only bitwise AND, OR, NOT,\nsummations and additions. Additionally, TM model compression allows the entire\nmodel to fit within the on-chip block RAM of the eFPGA. The paper uses this\naccelerator to propose a strategy for runtime model tuning in the field. The\nproposed approach uses 2.5x fewer Look-up-Tables (LUTs) and 3.38x fewer\nregisters than the current most resource-fugal design and achieves up to 129x\nenergy reduction compared with low-power microcontrollers running the same ML\napplication."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-93",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03361",
    "b_title":[
      "Strong Lensing analysis of SPT-CLJ2325$-$4111 and SPT-CLJ0049$-$2440,\n  two Powerful Cosmic Telescopes ($R_E > 40''$) from the SPT Clusters Sample"
    ],
    "b_abstract":[
      "We report the results from a study of two massive ($M_{500c} > 6.0 \\times\n10^{14} M_{\\odot}$) strong lensing clusters selected from the South Pole\nTelescope cluster survey for their high Einstein radius ($R_E > 40''$),\nSPT-CLJ2325$-$4111 and SPT-CLJ0049$-$2440. Ground-based and shallow HST imaging\nindicated extensive strong lensing evidence in these fields, with giant arcs\nspanning 18\\arcsec\\ and 31\\arcsec, respectively, motivating further space-based\nimaging followup. Here, we present multiband HST imaging and ground-based\nMagellan spectroscopy of the fields, from which we compile detailed strong\nlensing models. The lens models of SPT-CL\\,J2325$-$4111 and\nSPT-CL\\,J0049$-$2440 were optimized using 9, and 8 secure multiple-imaged\nsystems with a final image-plane rms of 0\\farcs63 and 0\\farcs73, respectively.\nFrom the lensing analysis, we measure the projected mass density within 500~kpc\nof $M(<500 ~{\\rm kpc}) = 7.30\\pm0.07 \\times 10^{14}$$M_{\\odot}$, and $M(<500\n~{\\rm kpc})=7.12^{+0.16}_{-0.19}\\times 10^{14}$ $M_{\\odot}$ for these two\nclusters, and a sub-halos mass ratio of $0.12\\pm{0.01}$ and\n$0.21^{+0.07}_{-0.05}$, respectively. Both clusters produce a large area with\nhigh magnification ($\\mu\\geq 3$) for a source at $z=9$, $A^{lens}_{| \\mu | \\geq\n3 }=4.93^{+0.03}_{-0.04} arcmin^2$, and $A^{lens}_{| \\mu | \\geq 3\n}=3.64^{+0.14}_{-0.10} arcmin^2$ respectively, placing them in the top tier of\nstrong lensing clusters. We conclude that these clusters are spectacular\nsightlines for further observations that will reduce the systematic\nuncertainties due to cosmic variance. This paper provides the community with\ntwo additional well-calibrated cosmic telescopes, as strong as the Frontier\nFields, suitable for studies of the highly magnified background Universe."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07802",
    "c_title":[
      "The Hellinger-Kantorovich metric measure geometry on spaces of measures"
    ],
    "c_abstract":[
      "Let $(M,g)$ be a Riemannian manifold with Riemannian distance $\\mathsf{d}_g$,\nand $\\mathcal{M}(M)$ be the space of all non-negative Borel measures on $M$,\nendowed with the Hellinger-Kantorovich distance $\\mathsf{H\\! K}_{\\mathsf{d}_g}$\ninduced by $\\mathsf{d}_g$.\n  Firstly, we prove that $\\left(\\mathcal{M}(M),\\mathsf{H\\!\nK}_{\\mathsf{d}_g}\\right)$ is a universally infinitesimally Hilbertian metric\nspace, and that a natural class of cylinder functions is dense in energy in the\nSobolev space of every finite Borel measure on $\\mathcal{M}(M)$.\n  Secondly, we endow $\\mathcal{M}(M)$ with its canonical reference measure,\nnamely A.M. Vershik's multiplicative infinite-dimensional Lebesgue measure\n$\\mathcal{L}_\\theta$, $\\theta>0$, and we consider: (a) the geometric structure\non $\\mathcal{M}(M)$ induced by the natural action on $\\mathcal{M}(M)$ of the\nsemi-direct product of diffeomorphisms and densities on $M$, under which\n$\\mathcal{L}_\\theta$ is the unique invariant measure; and (b) the metric\nmeasure structure of $\\left(\\mathcal{M}(M),\\mathsf{H\\!\nK}_{\\mathsf{d}_g},\\mathcal{L}_{\\theta}\\right)$, inherited from that of\n$(M,\\mathsf{d}_g,\\mathrm{vol}_g)$. We identify the canonical Dirichlet form\n$\\left(\\mathcal{E},\\mathscr{D}(\\mathcal{E})\\right)$ of (a) with the Cheeger\nenergy of (b), thus proving that these two structures coincide. We further\nprove that $\\left(\\mathcal{E},\\mathscr{D}(\\mathcal{E})\\right)$ is a\nconservative quasi-regular strongly local Dirichlet form on $\\mathcal{M}(M)$,\nrecurrent if and only if $\\theta\\in (0,1]$, and properly associated with the\nBrownian motion of the Hellinger-Kantorovich geometry on $\\mathcal{M}(M)$."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.MG",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-94",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11761",
    "b_title":[
      "Strong and weak dynamo regimes in Taylor-Couette flows"
    ],
    "b_abstract":[
      "We reveal a nonlinear magnetic dynamo in a Taylor-Couette flow at small\nmagnetic Prandtl numbers $Pm\\leq 1$, which has been previously believed to\nexist only at higher $Pm\\gtrsim 10$ in this flow. Both the amplitude of initial\nperturbations and $Pm$ play a critical role in its onset and evolution. It is\nshown that this dynamo exists in two main states -- a weak state dominated by\nlarge-scale modes and a strong, more turbulent state with higher amplitude\ndominated by small-scale modes. These findings can be important for dynamo\nprocesses in many astrophysical settings with small $Pm$."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.flu-dyn",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09960",
    "c_title":[
      "Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine\n  Learning Techniques"
    ],
    "c_abstract":[
      "Fire safety practices are important to reduce the extent of destruction\ncaused by fire. While smoke alarms help save lives, firefighters struggle with\nthe increasing number of false alarms. This paper presents a precise and\nefficient Weighted ensemble model for decreasing false alarms. It estimates the\ndensity, computes weights according to the high and low-density regions,\nforwards the high region weights to KNN and low region weights to XGBoost and\ncombines the predictions. The proposed model is effective at reducing response\ntime, increasing fire safety, and minimizing the damage that fires cause. A\nspecifically designed dataset for smoke detection is utilized to test the\nproposed model. In addition, a variety of ML models, such as Logistic\nRegression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB),\nK-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient\nBoosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To\nmaximize the use of the smoke detection dataset, all the algorithms utilize the\nSMOTE re-sampling technique. After evaluating the assessment criteria, this\npaper presents a concise summary of the comprehensive findings obtained by\ncomparing the outcomes of all models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-95",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15299",
    "b_title":[
      "On type 1 active galactic nuclei with double-peaked [O~{\\sc iii}]. I.\n  data sample and basic results"
    ],
    "b_abstract":[
      "Double-peaked narrow emission lines (DPNELs) might be evidence for the\nexistence of kpc-scale dual AGNs. There are so far large samples of objects\nwith DPNELs in narrow emission line galaxies. Here, a systematic search is made\nto build a sample of type 1 AGNs with double-peaked [O~{\\sc~iii}] from Data\nRelease 16 of the Sloan Digital Sky Survey (SDSS). Through visually inspecting\nand fitting [O~{\\sc~iii}], fitting broad H$\\alpha$ emission lines, performing\nF-test for [O~{\\sc~iii}] profiles, and checking broad H$\\beta$ and\n[O~{\\sc~iii}] emission lines, we select 62 type 1 AGNs with reliable\ndouble-peaked [O~{\\sc~iii}] from 11557 QSOs with z < 0.3. After visually\nchecking the 62 SDSS multi-color images, we find only seven objects with signs\nof merging. Four possible models for the double-peaked [O~{\\sc~iii}] observed\nin our sample are discussed: the superposition model, AGN outflow model, dual\nAGN model, and rotating disk model. However, the current results can not\nprovide any one explanation conclusively, and additional observational data are\nneeded to provide the details of narrow line regions. But at least 22 objects\nwith different velocity offsets between double-peaked [O~{\\sc~iii}] and narrow\nH$\\alpha$ emission lines could be excluded as dual AGN candidates. The relative\nvelocity offsets of the [O~{\\sc~iii}] blue-shifted\/red-shifted components are\nnegative to their line flux ratios, which is consistent with dual AGN model.\nThis work provides a new sample of 62 type 1 AGNs with double-peaked\n[O~{\\sc~iii}] for further study."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17697",
    "c_title":[
      "State-witness contraction"
    ],
    "c_abstract":[
      "We present a method to construct entanglement witnesses for arbitrarily large\nmultipartite systems, by tensoring and partial tracing existing states and\nwitnesses. As a proof of principle we show that, using little shared quantum\nresources, the method allows to reuse witnesses unable to detect states with\nlocal positive partial transpositions into new ones able to do so. Moreover, we\nshow that this technique allows to tailor both linear and nonlinear witnesses\nto specific states using semidefinite programming with comparatively\nlow-dimensional variables. As an example, existing trace polynomial witnesses\nare significantly improved while preserving their symmetries and\nimplementability with randomized measurements. Besides detecting entanglement,\nthe method is shown to detect $k$-copy distillability. A recipe for the\nsingle-copy case is shown to be effective for generic and Werner states."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-96",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05241",
    "b_title":[
      "Contrast-Free Myocardial Scar Segmentation in Cine MRI using Motion and\n  Texture Fusion"
    ],
    "b_abstract":[
      "Late gadolinium enhancement MRI (LGE MRI) is the gold standard for the\ndetection of myocardial scars for post myocardial infarction (MI). LGE MRI\nrequires the injection of a contrast agent, which carries potential side\neffects and increases scanning time and patient discomfort. To address these\nissues, we propose a novel framework that combines cardiac motion observed in\ncine MRI with image texture information to segment the myocardium and scar\ntissue in the left ventricle. Cardiac motion tracking can be formulated as a\nfull cardiac image cycle registration problem, which can be solved via deep\nneural networks. Experimental results prove that the proposed method can\nachieve scar segmentation based on non-contrasted cine images with comparable\naccuracy to LGE MRI. This demonstrates its potential as an alternative to\ncontrast-enhanced techniques for scar detection."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08436",
    "c_title":[
      "Experimental observation of Dirac exceptional point"
    ],
    "c_abstract":[
      "The energy level degeneracies, also known as exceptional points (EPs), are\ncrucial for comprehending emerging phenomena in materials and enabling\ninnovative functionalities for devices. Since EPs were proposed over half a\ncentury age, only two types of EPs have been experimentally discovered,\nrevealing intriguing phases of materials such as Dirac and Weyl semimetals.\nThese discoveries have showcased numerous exotic topological properties and\nnovel applications, such as unidirectional energy transfer. Here we report the\nobservation of a novel type of EP, named the Dirac EP, utilizing a\nnitrogen-vacancy center in diamond. Two of the eigenvalues are measured to be\ndegenerate at the Dirac EP and remain real in its vicinity. This exotic band\ntopology associated with the Dirac EP enables the preservation of the symmetry\nwhen passing through, and makes it possible to achieve adiabatic evolution in\nnon-Hermitian systems. We examined the degeneracy between the two eigenstates\nby quantum state tomography, confirming that the degenerate point is a Dirac EP\nrather than a Hermitian degeneracy. Our research of the distinct type of EP\ncontributes a fresh perspective on dynamics in non-Hermitian systems and is\npotentially valuable for applications in quantum control in non-Hermitian\nsystems and the study of the topological properties of EP."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-97",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04879",
    "b_title":[
      "Statistical Collusion by Collectives on Learning Platforms"
    ],
    "b_abstract":[
      "As platforms increasingly rely on learning algorithms, collectives may form\nand seek ways to influence these platforms to align with their own interests.\nThis can be achieved by coordinated submission of altered data. To evaluate the\npotential impact of such behavior, it is essential to understand the\ncomputations that collectives must perform to impact platforms in this way. In\nparticular, collectives need to make a priori assessments of the effect of the\ncollective before taking action, as they may face potential risks when\nmodifying their data. Moreover they need to develop implementable coordination\nalgorithms based on quantities that can be inferred from observed data. We\ndevelop a framework that provides a theoretical and algorithmic treatment of\nthese issues and present experimental results in a product evaluation domain."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.11016",
    "c_title":[
      "Quantum Parameter Estimation for Detectors in Constantly Accelerated\n  Motion"
    ],
    "c_abstract":[
      "We investigate quantum parameter estimation by analyzing the dynamics of\nquantum Fisher information (QFI) for the state parameters of accelerated\ndetectors undergoing four different acceleration scenarios: linear, cusped,\ncatenary, and circular motions. Our results show that QFI for the acceleration\nparameter converges to a nonnegative asymptotic value over long evolution\ntimes, with this value strongly dependent on the specific acceleration\nscenario. In contrast, QFI for the weight parameter degrades to zero over time.\nNotably, for sufficiently large accelerations, optimal precision in estimating\nthe acceleration parameter can be achieved within a finite evolution time\nrather than requiring an infinitely long measurement duration. Comparing\ndifferent scenarios, we find that for small accelerations relative to the\ndetector's energy gap, linear motion provides the most accurate estimation of\nthe weight parameter, introducing the least noise among all scenarios. However,\nfor large accelerations, circular motion becomes the optimal scenario for\nestimating the weight parameter. This behavior stands in sharp contrast to the\nestimation of the acceleration parameter, where circular motion is optimal both\nfor small accelerations and for large accelerations over extremely long\nevolution times. These distinctions in QFI may provide a new tool for\nidentifying the specific acceleration scenario of an accelerated detector."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-98",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14368",
    "b_title":[
      "Langevin model for soliton molecules in ultrafast fiber ring laser\n  cavity: investigating experimentally the interplay between noise and inertia"
    ],
    "b_abstract":[
      "The dynamics of soliton molecules in ultrafast fiber ring laser cavity is\nstrongly influenced by noise. We show how a parsimonious Langevin model can be\nconstructed from experimental data, resulting in a mathematical description\nthat encompasses both the deterministic and stochastic properties of the\nevolution of the soliton molecules. In particular, we were able to probe the\nresponse dynamics of the soliton molecule to an external kick in a sub-critical\napproach, namely without the need to actually disturb the systems under\ninvestigation. Moreover, the noise experienced by the dissipative solitonic\nsystem, including its distribution and correlation, can now be also analyzed in\ndetails. Our strategy can be applied to any systems where the individual motion\nof its constitutive particles can be traced; the case of optical\nsolitonic-system laser presented here serving as a proof-of-principle\ndemonstration."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.19364",
    "c_title":[
      "CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation"
    ],
    "c_abstract":[
      "Multivariate Time Series Imputation (MTSI) is crucial for many applications,\nsuch as healthcare monitoring and traffic management, where incomplete data can\ncompromise decision-making. Existing state-of-the-art methods, like Denoising\nDiffusion Probabilistic Models (DDPMs), achieve high imputation accuracy;\nhowever, they suffer from significant computational costs and are notably\ntime-consuming due to their iterative nature. In this work, we propose CoSTI,\nan innovative adaptation of Consistency Models (CMs) for the MTSI domain. CoSTI\nemploys Consistency Training to achieve comparable imputation quality to DDPMs\nwhile drastically reducing inference times, making it more suitable for\nreal-time applications. We evaluate CoSTI across multiple datasets and missing\ndata scenarios, demonstrating up to a 98% reduction in imputation time with\nperformance on par with diffusion-based models. This work bridges the gap\nbetween efficiency and accuracy in generative imputation tasks, providing a\nscalable solution for handling missing data in critical spatio-temporal\nsystems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-99",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17484",
    "b_title":[
      "Capacity Expansion Planning under Uncertainty subject to Expected Energy\n  Not Served Constraints"
    ],
    "b_abstract":[
      "We present a method for solving a large-scale stochastic capacity expansion\nproblem which explicitly considers reliability constraints, in particular\nconstraints on expected energy not served. Our method tackles this problem by a\nLagrange relaxation of the expected energy not served constraints. We solve the\nrelaxed formulation in an iterative manner, using a subgradient-based method.\nEach iteration requires the solution of a stochastic capacity expansion\nproblem, for which we implement a subgradient decomposition scheme in a\nhigh-performance computing infrastructure. We apply the proposed methodology on\nthe Economic Viability Assessment model that is used by ENTSO-E in the annual\nEuropean Resource Adequacy Assessment, extended to include explicit reliability\nconstraints. The approach is able to solve this model achieving a 1.3%\noptimality gap. We compare our approach against accounting for reliability\nthrough penalizing load shedding at VOLL, and find that the former results in\n1.6% savings in total cost. We are also able to quantify the cost savings from\nallowing some load curtailment in the capacity planning process, which ranges\nfrom 1.6 to 6% in the cases analyzed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14057",
    "c_title":[
      "The Motzkin subproduct system"
    ],
    "c_abstract":[
      "We introduce a subproduct system of finite-dimensional Hilbert spaces using\nthe Motzkin planar algebra and its Jones-Wenzl idempotents, which generalizes\nthe Temperley-Lieb subproduct system of Habbestad and Neshveyev. We provide a\ndescription of the corresponding Toeplitz C$^*$-algebra as a universal\nC$^*$-algebra, defined in terms of generators and relations, and we highlight\nproperties of its representation theory."
    ],
    "c_categories":[
      [
        "math.OA",
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-100",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12568",
    "b_title":[
      "A Cognitive Writing Perspective for Constrained Long-Form Text\n  Generation"
    ],
    "b_abstract":[
      "Like humans, Large Language Models (LLMs) struggle to generate high-quality\nlong-form text that adheres to strict requirements in a single pass. This\nchallenge is unsurprising, as successful human writing, according to the\nCognitive Writing Theory, is a complex cognitive process involving iterative\nplanning, translating, reviewing, and monitoring. Motivated by these cognitive\nprinciples, we aim to equip LLMs with human-like cognitive writing capabilities\nthrough CogWriter, a novel training-free framework that transforms LLM\nconstrained long-form text generation into a systematic cognitive writing\nparadigm. Our framework consists of two key modules: (1) a Planning Agent that\nperforms hierarchical planning to decompose the task, and (2) multiple\nGeneration Agents that execute these plans in parallel. The system maintains\nquality via continuous monitoring and reviewing mechanisms, which evaluate\noutputs against specified requirements and trigger necessary revisions.\nCogWriter demonstrates exceptional performance on LongGenBench, a benchmark for\ncomplex constrained long-form text generation. Even when using Qwen-2.5-14B as\nits backbone, CogWriter surpasses GPT-4o by 22% in complex instruction\ncompletion accuracy while reliably generating texts exceeding 10,000 words. We\nhope this cognitive science-inspired approach provides a paradigm for LLM\nwriting advancements:\n\\href{https:\/\/github.com\/KaiyangWan\/CogWriter}{CogWriter}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00082",
    "c_title":[
      "Gravitational Lensing Phenomena of Ellis-Bronnikov-Morris-Thorne\n  Wormhole with Global Monopole and Cosmic String"
    ],
    "c_abstract":[
      "In this paper, we theoretically investigate gravitational lensing within the\nspace-time framework of traversable wormholes, focusing on the combined effects\nof a global monopole and a cosmic string. Specifically, we examine the\nEllis-Bronnikov-Morris-Thorne wormhole metric and analyze how these topological\ndefects influence photon trajectories. By considering the weak-field limit, we\nderive analytical expressions for the photon deflection angle, highlighting how\nfactors such as the wormhole throat radius, the global monopole charge, and the\ncosmic string influence the gravitational lensing phenomenon. We also examine\nthe weak-field limit of lensing phenomena for a zero wormhole throat radius and\nderive an analytical expression for the deflection angle of photon light in\nthis scenario."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-101",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12233",
    "b_title":[
      "Robust Full-Space Physical Layer Security for STAR-RIS-Aided Wireless\n  Networks: Eavesdropper with Uncertain Location and Channel"
    ],
    "b_abstract":[
      "A robust full-space physical layer security (PLS) transmission scheme is\nproposed in this paper considering the full-space wiretapping challenge of\nwireless networks supported by simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS). Different from the existing\nschemes, the proposed PLS scheme takes account of the uncertainty on the\neavesdropper's position within the 360$^\\circ$ service area offered by the\nSTAR-RIS. Specifically, the large system analytical method is utilized to\nderive the asymptotic expression of the average security rate achieved by the\nsecurity user, considering that the base station (BS) only has the statistical\ninformation of the eavesdropper's channel state information (CSI) and the\nuncertainty of its location. To evaluate the effectiveness of the proposed PLS\nscheme, we first formulate an optimization problem aimed at maximizing the\nweighted sum rate of the security user and the public user. This optimization\nis conducted under the power allocation constraint, and some practical\nlimitations for STAR-RIS implementation, through jointly designing the active\nand passive beamforming variables. A novel iterative algorithm based on the\nminimum mean-square error (MMSE) and cross-entropy optimization (CEO) methods\nis proposed to effectively address the established non-convex optimization\nproblem with discrete variables. Simulation results indicate that the proposed\nrobust PLS scheme can effectively mitigate the information leakage across the\nentire coverage area of the STAR-RIS-assisted system, leading to superior\nperformance gain when compared to benchmark schemes encompassing traditional\nRIS-aided scheme."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.03776",
    "c_title":[
      "StarMAP: Global Neighbor Embedding for Faithful Data Visualization"
    ],
    "c_abstract":[
      "Neighbor embedding is widely employed to visualize high-dimensional data;\nhowever, it frequently overlooks the global structure, e.g., intercluster\nsimilarities, thereby impeding accurate visualization. To address this problem,\nthis paper presents Star-attracted Manifold Approximation and Projection\n(StarMAP), which incorporates the advantage of principal component analysis\n(PCA) in neighbor embedding. Inspired by the property of PCA embedding, which\ncan be viewed as the largest shadow of the data, StarMAP introduces the concept\nof \\textit{star attraction} by leveraging the PCA embedding. This approach\nyields faithful global structure preservation while maintaining the\ninterpretability and computational efficiency of neighbor embedding. StarMAP\nwas compared with existing methods in the visualization tasks of toy datasets,\nsingle-cell RNA sequencing data, and deep representation. The experimental\nresults show that StarMAP is simple but effective in realizing faithful\nvisualizations."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-102",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07687",
    "b_title":[
      "The PLATO field selection process. II. Characterization of LOPS2, the\n  first long-pointing field"
    ],
    "b_abstract":[
      "PLAnetary Transits and Oscillations of stars (PLATO) is an ESA M-class\nmission to be launched by the end of 2026 to discover and characterize\ntransiting planets around bright and nearby stars, and in particular habitable\nrocky planets hosted by solar-like stars. Over the mission lifetime, an average\nof 8% of the science data rate will be allocated to Guest Observer programs\n(GOs) selected by ESA through public calls, hence it is essential for the\ncommunity to know in advance where the observing fields will be located. In a\nprevious paper, we identified two preliminary long-pointing fields (LOPN1 and\nLOPS1) for PLATO, respectively in the northern and southern hemisphere. Here we\npresent LOPS2, a slightly adjusted version of the southern field that has\nrecently been selected by the PLATO Science Working Team as the first field to\nbe observed by PLATO for at least two continuous years, following the\nscientific requirements. In this paper, we describe the astrophysical content\nof LOPS2 in detail, including known planetary systems, bright\/variable\/binary\nstars, clusters and synergies with other current and future facilities."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03058",
    "c_title":[
      "Finitary Ryan's and local $\\mathcal{Q}$ entropy for $\\mathbb{Z}^{d}$\n  subshifts"
    ],
    "c_abstract":[
      "For the action of a group $G$ by homeomorphisms on a space $X$, the\nautomorphism group $\\mathrm{Aut}(X,G)$ consists of all self-homeomorphisms of\n$X$ which commute with $x \\mapsto g \\cdot x$ for every $g \\in G$. A theorem of\nRyan shows that for an irreducible $\\mathbb{Z}$-shift of finite type\n$(X,\\sigma_{X})$, the center of $\\mathrm{Aut}(X,\\sigma_{X})$ is generated by\nthe shift $\\sigma_{X}$. A finitary version of this for $\\mathbb{Z}$-shifts of\nfinite type was proved by the second author for certain full shifts, and later\ngeneralized by Kopra to irreducible $\\mathbb{Z}$-shifts of finite type. We\ngeneralize these finitary Ryan's theorems to shifts of finite type over more\ngeneral groups. We prove that for contractible $\\mathbb{Z}^{d}$-shifts of\nfinite type with a fixed point, there is a finitely generated subgroup of the\nautomorphism group whose centralizer in the group of homeomorphisms is the\nsubgroup of shifts. We also prove versions of this for full shifts over any\ninfinite, finitely generated group on sufficiently nice alphabet sizes.\n  The stabilized automorphism group $\\mathrm{Aut}^{(\\infty)}(X,G)$ is the union\nof $\\mathrm{Aut}(X,H)$ over all finite index subgroups $H \\subset G$. Aimed at\nstudying stabilized automorphism groups for shifts of finite type, we introduce\nan entropy-like quantity for pointed groups which we call local $\\mathcal{Q}$\nentropy, a generalization of a notion called local $\\mathcal{P}$ entropy\npreviously introduced by the first author. Using the finitary Ryan's theorems,\nwe prove that the local $\\mathcal{Q}$ entropy of the stabilized automorphism\ngroup of a contractible $\\mathbb{Z}^{d}$-shift of finite type recovers the\ntopological entropy of the underlying shift system up to a rational multiple.\nWe then use this to give a complete classification up to isomorphism of the\nstabilized automorphism groups of full shifts over $\\mathbb{Z}^{d}$."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-103",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01626",
    "b_title":[
      "Treatment of Thermal Non-Equilibrium Dissociation Rates: Application to\n  $\\rm H_2$"
    ],
    "b_abstract":[
      "This work presents a detailed description of the thermochemical\nnon-equilibrium dissociation of diatomic molecules, and applies this theory to\nthe case of $\\rm H_2$ dissociation. The master equations are used to derive\ncorresponding aggregate rate constant expressions that hold for any degree of\nthermochemical non-equilibrium. These general expressions are analyzed in three\nkey limits\/ regimes: the thermal equilibrium limit, the quasi-steady-state\n(QSS) regime, and the pre-QSS regime. Under several simplifying assumptions, an\nanalytical source term expression that holds in all of these regimes, and is\nonly a function of the translational temperature, $T_{\\rm t}$, and the fraction\nof dissociation, $\\phi_{\\rm A}$, is proposed. This expression has two input\nparameters: the QSS dissociation rate constant in the absence of recombination,\n$k_{\\rm d,nr}(T_{\\rm t})$, and a pre-QSS correction factor, $\\eta(T_{\\rm t})$.\nThe value of $\\eta(T_{\\rm t})$ is evaluated by comparing the predictions of the\nproposed expression against existing master equation simulations of a 0-D\nisothermal and isochoric reactor for the case of $\\rm H_2$ dissociation with\nthe third-bodies $\\rm H_2$, $\\rm H$, and $\\rm He$. Despite its simple\nfunctional form, the proposed expression is able to reproduce the master\nequation results for the majority of the tested conditions. The best fit of\n$k_{\\rm d,nr}(T_{\\rm t})$ is then evaluated by conducting a detailed literature\nreview. Data from a wide range of experimental and computational studies are\nconsidered for the third-bodies $\\rm H_2$, $\\rm H$, and inert gases, and fits\nthat are valid from 200 to 20,000 K are proposed. From this review, the\nuncertainty of the proposed fits are estimated to be less than a factor of two."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16839",
    "c_title":[
      "Minimum saturated graphs without $4$-cycles and $5$-cycles"
    ],
    "c_abstract":[
      "Given a family of graphs $\\mathcal{F}$, a graph $G$ is said to be\n$\\mathcal{F}$-saturated if $G$ does not contain a copy of $F$ as a subgraph for\nany $F\\in\\mathcal{F}$, but the addition of any edge $e\\notin E(G)$ creates at\nleast one copy of some $F\\in\\mathcal{F}$ within $G$. The minimum size of an\n$\\mathcal{F}$-saturated graph on $n$ vertices is called the saturation number,\ndenoted by $\\mbox{sat}(n, \\mathcal{F})$. Let $C_r$ be the cycle of length $r$.\nIn this paper, we study on $\\mbox{sat}(n, \\mathcal{F})$ when $\\mathcal{F}$ is a\nfamily of cycles. In particular, we determine that $\\mbox{sat}(n,\n\\{C_4,C_5\\})=\\lceil\\frac{5n}{4}-\\frac{3}{2}\\rceil$ for any positive integer\n$n$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-104",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16185",
    "b_title":[
      "On the equation of state of U(1) lattice gauge theory in three\n  dimensions"
    ],
    "b_abstract":[
      "We study the equation of state of three-dimensional compact U(1) gauge theory\non the lattice by means of numerical simulations, and discuss the implications\nof our results for the spectrum of the theory, in connection with previous\nresults from the literature. We also compare our findings to the case of\nnon-Abelian gauge theories and comment on the continuum limit."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01347",
    "c_title":[
      "AdaptVC: High Quality Voice Conversion with Adaptive Learning"
    ],
    "c_abstract":[
      "The goal of voice conversion is to transform the speech of a source speaker\nto sound like that of a reference speaker while preserving the original\ncontent. A key challenge is to extract disentangled linguistic content from the\nsource and voice style from the reference. While existing approaches leverage\nvarious methods to isolate the two, a generalization still requires further\nattention, especially for robustness in zero-shot scenarios. In this paper, we\nachieve successful disentanglement of content and speaker features by tuning\nself-supervised speech features with adapters. The adapters are trained to\ndynamically encode nuanced features from rich self-supervised features, and the\ndecoder fuses them to produce speech that accurately resembles the reference\nwith minimal loss of content. Moreover, we leverage a conditional flow matching\ndecoder with cross-attention speaker conditioning to further boost the\nsynthesis quality and efficiency. Subjective and objective evaluations in a\nzero-shot scenario demonstrate that the proposed method outperforms existing\nmodels in speech quality and similarity to the reference speech."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-105",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13142",
    "b_title":[
      "Computational modelling of biological systems now and then: revisiting\n  tools and visions from the beginning of the century"
    ],
    "b_abstract":[
      "Since the turn of the millennium, computational modelling of biological\nsystems has evolved remarkably and sees matured use spanning basic and clinical\nresearch. While the topic of the peri-millennial debate about the virtues and\nlimitations of 'reductionism and integrationism' seems less controversial\ntoday, a new apparent dichotomy dominates discussions: mechanistic vs.\ndata-driven modelling. In light of this distinction, we provide an overview of\nrecent achievements and new challenges with a focus on the cardiovascular\nsystem. Attention has shifted from generating a universal model of the human to\neither models of individual humans (digital twins) or entire cohorts of models\nrepresentative of clinical populations to enable in silico clinical trials.\nDisease-specific parameterisation, inter-individual and intra-individual\nvariability, uncertainty quantification as well as interoperable, standardised,\nand quality-controlled data are important issues today, which call for open\ntools, data and metadata standards, as well as strong community interactions.\nThe quantitative, biophysical, and highly controlled approach provided by in\nsilico methods has become an integral part of physiological and medical\nresearch. In silico methods have the potential to accelerate future progress\nalso in the fields of integrated multi-physics modelling, multi-scale models,\nvirtual cohort studies, and machine learning beyond what is feasible today. In\nfact, mechanistic and data-driven modelling can complement each other\nsynergistically and fuel tomorrow's artificial intelligence applications to\nfurther our understanding of physiology and disease mechanisms, to generate new\nhypotheses and assess their plausibility, and thus to contribute to the\nevolution of preventive, diagnostic, and therapeutic approaches."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.13892",
    "c_title":[
      "Intrinsic Donaldson-Thomas theory. I. Component lattices of stacks"
    ],
    "c_abstract":[
      "This is the first paper in a series on intrinsic Donaldson-Thomas theory, a\ngeneralization of Donaldson-Thomas theory from the linear case, or the case of\nmoduli stacks of objects in $3$-Calabi-Yau abelian categories, to the\nnon-linear case of general $(-1)$-shifted symplectic stacks. This is done by\ndeveloping a new framework for studying the enumerative geometry of general\nalgebraic stacks, and we expect that this framework can also be applied to\nextending other types of enumerative theories for linear stacks to the\nnon-linear case.\n  In this paper, we establish the foundations of our framework. We introduce\nthe component lattice of an algebraic stack, which is the key combinatorial\nobject in our theory. It generalizes and globalizes the cocharacter lattice and\nthe Weyl group of an algebraic group, and is defined as the set of connected\ncomponents of the stack of graded points of the original stack.\n  We prove several results on the structure of graded and filtered points of a\nstack using the component lattice. The first is the constancy theorem, which\nstates that there is a wall-and-chamber structure on the component lattice,\nsuch that the isomorphism types of connected components of the stacks of graded\nand filtered points stay constant within each chamber. The second is the\nfiniteness theorem, providing a criterion for the finiteness of the number of\npossible isomorphism types of these components. The third is the associativity\ntheorem, generalizing the structure of Hall algebras from linear stacks to\ngeneral stacks, involving a notion of Hall categories.\n  Finally, we discuss some applications of these results outside\nDonaldson-Thomas theory, including a construction of stacks of real-weighted\nfiltrations, and a generalization of the semistable reduction theorem to\nreal-weighted filtrations."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-106",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07095",
    "b_title":[
      "The devasting economic impact of Callinectes sapidus on the clam fishing\n  in the Po Delta (Italy): Striking evidence from novel field data"
    ],
    "b_abstract":[
      "Invasive species are a growing threat to marine ecosystems, and the recent\nproliferation of the Atlantic blue crab (Callinectes sapidus) in the Po Delta\n(Italy) has had significant ecological and economic impacts, particularly on\nclam farming. This study explores the influence of C. sapidus on clam\nproduction in the Po Delta, combining biological and ecological data with\nsocio-economic analysis. Field data collected between August and December 2023\nfrom the Canarin and Scardovari Lagoons revealed seasonal fluctuations in crab\nabundance, with a peak in captures during the warmer months. The predatory\nbehaviour of C. sapidus has led to a sharp decline in clam production, reaching\nnear-zero levels in early 2024. Statistical analysis confirmed a strong\ncorrelation between the increase of the invasive crab population and the\ndecrease in clam yields. This study also explores potential management\nstrategies, including the economic valorisation of C. sapidus as a commercial\nresource, turning an ecological challenge into an opportunity. These findings\nhighlight the urgent need for targeted management interventions to mitigate the\nimpact of this invasive species on local fisheries and ecosystems."
    ],
    "b_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2501.16495",
    "c_title":[
      "Explaining GitHub Actions Failures with Large Language Models:\n  Challenges, Insights, and Limitations"
    ],
    "c_abstract":[
      "GitHub Actions (GA) has become the de facto tool that developers use to\nautomate software workflows, seamlessly building, testing, and deploying code.\nYet when GA fails, it disrupts development, causing delays and driving up\ncosts. Diagnosing failures becomes especially challenging because error logs\nare often long, complex and unstructured. Given these difficulties, this study\nexplores the potential of large language models (LLMs) to generate correct,\nclear, concise, and actionable contextual descriptions (or summaries) for GA\nfailures, focusing on developers' perceptions of their feasibility and\nusefulness. Our results show that over 80\\% of developers rated LLM\nexplanations positively in terms of correctness for simpler\/small logs.\nOverall, our findings suggest that LLMs can feasibly assist developers in\nunderstanding common GA errors, thus, potentially reducing manual analysis.\nHowever, we also found that improved reasoning abilities are needed to support\nmore complex CI\/CD scenarios. For instance, less experienced developers tend to\nbe more positive on the described context, while seasoned developers prefer\nconcise summaries. Overall, our work offers key insights for researchers\nenhancing LLM reasoning, particularly in adapting explanations to user\nexpertise."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-107",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17275",
    "b_title":[
      "Time-dependent global sensitivity analysis of the Doyle-Fuller-Newman\n  model"
    ],
    "b_abstract":[
      "The Doyle-Fuller-Newman model is arguably the most ubiquitous electrochemical\nmodel in lithium-ion battery research. Since it is a highly nonlinear model,\nits input-output relations are still poorly understood. Researchers therefore\noften employ sensitivity analyses to elucidate relative parametric importance\nfor certain use cases. However, some methods are ill-suited for the complexity\nof the model and appropriate methods often face the downside of only being\napplicable to scalar quantities of interest. We implement a novel framework for\nglobal sensitivity analysis of time-dependent model outputs and apply it to a\ndrive cycle simulation. We conduct a full and a subgroup sensitivity analysis\nto resolve lowly sensitive parameters and explore the model error when\nunimportant parameters are set to arbitrary values. Our findings suggest that\nthe method identifies insensitive parameters whose variations cause only small\ndeviations in the voltage response of the model. By providing the methodology,\nwe hope research questions related to parametric sensitivity for time-dependent\nquantities of interest, such as voltage responses, can be addressed more easily\nand adequately in simulative battery research and beyond."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00308",
    "c_title":[
      "Abstract Rendering: Computing All that is Seen in Gaussian Splat Scenes"
    ],
    "c_abstract":[
      "We introduce abstract rendering, a method for computing a set of images by\nrendering a scene from a continuously varying range of camera positions. The\nresulting abstract image-which encodes an infinite collection of possible\nrenderings-is represented using constraints on the image matrix, enabling\nrigorous uncertainty propagation through the rendering process. This capability\nis particularly valuable for the formal verification of vision-based autonomous\nsystems and other safety-critical applications. Our approach operates on\nGaussian splat scenes, an emerging representation in computer vision and\nrobotics. We leverage efficient piecewise linear bound propagation to abstract\nfundamental rendering operations, while addressing key challenges that arise in\nmatrix inversion and depth sorting-two operations not directly amenable to\nstandard approximations. To handle these, we develop novel linear relational\nabstractions that maintain precision while ensuring computational efficiency.\nThese abstractions not only power our abstract rendering algorithm but also\nprovide broadly applicable tools for other rendering problems. Our\nimplementation, AbstractSplat, is optimized for scalability, handling up to\n750k Gaussians while allowing users to balance memory and runtime through tile\nand batch-based computation. Compared to the only existing abstract image\nmethod for mesh-based scenes, AbstractSplat achieves 2-14x speedups while\npreserving precision. Our results demonstrate that continuous camera motion,\nrotations, and scene variations can be rigorously analyzed at scale, making\nabstract rendering a powerful tool for uncertainty-aware vision applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-108",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08434",
    "b_title":[
      "One loop analysis of the cubic action for gravity"
    ],
    "b_abstract":[
      "We analyze some aspects of the cubic action for gravity recently proposed by\nCheung and Remmen, which is a particular instance of a first order (Palatini)\naction. In this approach both the spacetime metric and the connection are\ntreated as independent fields. We discuss its BRST invariance and compute\nexplicitly the one-loop contribution of quantum fluctuations around flat space,\nchecking that the corresponding Slavnov-Taylor identities are fulfilled.\nFinally, our results on a first order action are compared with the existing\nones corresponding to a second order action."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01250",
    "c_title":[
      "Beyond Win Rates: A Clustering-Based Approach to Character Balance\n  Analysis in Team-Based Games"
    ],
    "c_abstract":[
      "Character diversity in competitive games, while enriching gameplay, often\nintroduces balance challenges that can negatively impact player experience and\nstrategic depth. Traditional balance assessments rely on aggregate metrics like\nwin rates and pick rates, which offer limited insight into the intricate\ndynamics of team-based games and nuanced character roles. This paper proposes a\nnovel clustering-based methodology to analyze character balance, leveraging\nin-game data from Valorant to account for team composition influences and\nreveal latent character roles. By applying hierarchical agglomerative\nclustering with Jensen-Shannon Divergence to professional match data from the\nValorant Champions Tour 2022, our approach identifies distinct clusters of\nagents exhibiting similar co-occurrence patterns within team compositions. This\nmethod not only complements existing quantitative metrics but also provides a\nmore holistic and interpretable perspective on character synergies and\npotential imbalances, offering game developers a valuable tool for informed and\ncontext-aware balance adjustments."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-109",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05497",
    "b_title":[
      "$t$+$t$ cluster states in $^{6}$He"
    ],
    "b_abstract":[
      "The study of $t$+$t$ cluster states in $^{6}$He provides valuable insights\ninto exotic nuclear structures and the behavior of fermionic cluster systems.\nThis study shows rich cluster resonant state structures above the threshold,\nidentified by experimental reconstruction and theoretical calculations. The\nexcitation energy spectrum above the $t$+$t$ threshold in $^{6}$He is measured\nvia the fragmentation excitation process during the breakup reaction of\n$^{9}$Li on a $^{208}$Pb target at an incident energy of 32.7 MeV\/nucleon. The\nresonant states are reconstructed from the final state coincident particles\n$t$+$t$ using the invariant mass method, while the non-resonant background is\nestimated using the event mixing method. The two new states of energy level\npeaks at $17.016\\pm0.002$ and $19.4\\pm0.6$ MeV are observed in addition to the\npreviously observed energy level peaks at $13.9\\pm0.3$ and $15.0\\pm0.3$ MeV.\nMicroscopic cluster model calculations exploring the $t+t$ resonance states in\n$^6\\mathrm{He}$ yield theoretical energy spectra which are then compared with\nthe current experimental results. The calculated reduced width amplitudes (RWA)\nof the $t+t$ channels further confirm the clustering structure of the\nidentified $t+t$ resonance states."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06994",
    "c_title":[
      "SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software\n  Engineering"
    ],
    "c_abstract":[
      "Software engineering (SE) is increasingly collaborative, with developers\nworking together on shared complex codebases. Effective collaboration in shared\nenvironments requires participants -- whether humans or AI agents -- to stay on\nthe same page as their environment evolves. When a collaborator's understanding\ndiverges from the current state -- what we term the out-of-sync challenge --\nthe collaborator's actions may fail, leading to integration issues. In this\nwork, we introduce SyncMind, a framework that systematically defines the\nout-of-sync problem faced by large language model (LLM) agents in collaborative\nsoftware engineering (CSE). Based on SyncMind, we create SyncBench, a benchmark\nfeaturing 24,332 instances of agent out-of-sync scenarios in real-world CSE\nderived from 21 popular GitHub repositories with executable verification tests.\nExperiments on SyncBench uncover critical insights into existing LLM agents'\ncapabilities and limitations. Besides substantial performance gaps among agents\n(from Llama-3.1 agent <= 3.33% to Claude-3.5-Sonnet >= 28.18%), their\nconsistently low collaboration willingness (<= 4.86%) suggests fundamental\nlimitations of existing LLM in CSE. However, when collaboration occurs, it\npositively correlates with out-of-sync recovery success. Minimal performance\ndifferences in agents' resource-aware out-of-sync recoveries further reveal\ntheir significant lack of resource awareness and adaptability, shedding light\non future resource-efficient collaborative systems. Code and data are openly\navailable on our project website: https:\/\/xhguo7.github.io\/SyncMind\/."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-110",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03879",
    "b_title":[
      "First-order CP phase transition in two-flavor QCD at $\\theta = \\pi$\n  under electromagnetic scale anomaly via a Nambu-Jona-Lasinio description"
    ],
    "b_abstract":[
      "We discuss the thermal CP phase transition in QCD at $\\theta=\\pi$ under a\nweak magnetic field background, where the electromagnetic scale anomaly gets\nsignificant. To explicitize, we work on a two-flavor Nambu-Jona-Lasinio model\nat $\\theta=\\pi$ in the mean field approximation, including the\nelectromagnetic-scale anomaly term. We find that the thermal CP phase\ntransition becomes first order and the strength of the first order gets more\nprominent as the magnetic field increases. The associated potential barrier is\nthermally created by the electromagnetic scale anomaly and gives rise to\ncriticality due to the induced potential of a non-perturbative form $\\sim\n\\frac{|eB|^3}{f_\\pi} \\frac{|P|}{P^2 + m_0^2}$, where $eB$ denotes the magnetic\nfield strength; $P$ the CP order parameter, and $m_0$ the isospin-symmetric\ncurrent-quark mass."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05533",
    "c_title":[
      "Exploiting Inexact Computations in Multilevel Sampling Methods"
    ],
    "c_abstract":[
      "Multilevel sampling methods, such as multilevel and multifidelity Monte\nCarlo, multilevel stochastic collocation, or delayed acceptance Markov chain\nMonte Carlo, have become standard uncertainty quantification tools for a wide\nclass of forward and inverse problems. The underlying idea is to achieve faster\nconvergence by leveraging a hierarchy of models, such as partial differential\nequation (PDE) or stochastic differential equation (SDE) discretisations with\nincreasing accuracy. By optimally redistributing work among the levels,\nmultilevel methods can achieve significant performance improvement compared to\nsingle level methods working with one high-fidelity model. Intuitively,\napproximate solutions on coarser levels can tolerate large computational error\nwithout affecting the overall accuracy. We show how this can be used in\nhigh-performance computing applications to obtain a significant performance\ngain.\n  As a use case, we analyse the computational error in the standard multilevel\nMonte Carlo method and formulate an adaptive algorithm which determines a\nminimum required computational accuracy on each level of discretisation. We\nshow two examples of how the inexactness can be converted into actual gains\nusing an elliptic PDE with lognormal random coefficients. Using a low precision\nsparse direct solver combined with iterative refinement results in a simulated\ngain in memory references of up to $3.5\\times$ compared to the reference double\nprecision solver; while using a MINRES iterative solver, a practical speedup of\nup to $1.5\\times$ in terms of FLOPs is achieved. These results provide a step\nin the direction of energy-aware scientific computing, with significant\npotential for energy savings."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-111",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15270",
    "b_title":[
      "Automating Comment Generation for Smart Contract from Bytecode"
    ],
    "b_abstract":[
      "Recently, smart contracts have played a vital role in automatic financial and\nbusiness transactions. To help end users without programming background to\nbetter understand the logic of smart contracts, previous studies have proposed\nmodels for automatically translating smart contract source code into their\ncorresponding code summaries. However, in practice, only 13% of smart contracts\ndeployed on the Ethereum blockchain are associated with source code. The\npractical usage of these existing tools is significantly restricted.\nConsidering that bytecode is always necessary when deploying smart contracts,\nin this paper, we first introduce the task of automatically generating smart\ncontract code summaries from bytecode. We propose a novel approach, named\nSmartBT (Smart contract Bytecode Translator) for automatically translating\nsmart contract bytecode into fine-grained natural language description\ndirectly. Two key challenges are posed for this task: structural code logic\nhidden in bytecode and the huge semantic gap between bytecode and natural\nlanguage descriptions. To address the first challenge, we transform bytecode\ninto CFG (Control-Flow Graph) to learn code structural and logic details.\nRegarding the second challenge, we introduce an information retrieval component\nto fetch similar comments for filling the semantic gap. Then the structural\ninput and semantic input are used to build an attentional sequence-to-sequence\nneural network model. The copy mechanism is employed to copy rare words\ndirectly from similar comments and the coverage mechanism is employed to\neliminate repetitive outputs. The automatic evaluation results show that\nSmartBT outperforms a set of baselines by a large margin, and the human\nevaluation results show the effectiveness and potential of SmartBT in producing\nmeaningful and accurate comments for smart contract code from bytecode\ndirectly."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16230",
    "c_title":[
      "Modulated phases in Ising systems with long-range antiferromagnetic and\n  short-range ferromagnetic interactions"
    ],
    "c_abstract":[
      "We consider large spin systems with short-range ferromagnetic interactions\nand long-range antiferromagnetic interactions subjected to periodic boundary\nconditions which have been proved by Giuliani, Lebowitz and Lieb to have\nminimizers that tend to alternate groups of $1$ and $-1$ of the same length\n$h^\\star$. We consider states with energy of the same order as that of\nminimizers and show that they consist of a finite number of modulated phases of\nthe same form as minimizers with some interfacial defects. The analysis is\ncarried out using the notation of Gamma-convergence by exhibiting an\ninterfacial energy that describes the minimal defect energy between different\nmodulated phases."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.AP",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-112",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01694",
    "b_title":[
      "Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of\n  Search, RL and Distillation"
    ],
    "b_abstract":[
      "A key paradigm to improve the reasoning capabilities of large language models\n(LLMs) is to allocate more inference-time compute to search against a verifier\nor reward model. This process can then be utilized to refine the pretrained\nmodel or distill its reasoning patterns into more efficient models. In this\npaper, we study inference-time compute by viewing chain-of-thought (CoT)\ngeneration as a metastable Markov process: easy reasoning steps (e.g.,\nalgebraic manipulations) form densely connected clusters, while hard reasoning\nsteps (e.g., applying a relevant theorem) create sparse, low-probability edges\nbetween clusters, leading to phase transitions at longer timescales. Under this\nframework, we prove that implementing a search protocol that rewards sparse\nedges improves CoT by decreasing the expected number of steps to reach\ndifferent clusters. In contrast, we establish a limit on reasoning capability\nwhen the model is restricted to local information of the pretrained graph. We\nalso show that the information gained by search can be utilized to obtain a\nbetter reasoning model: (1) the pretrained model can be directly finetuned to\nfavor sparse edges via policy gradient methods, and moreover (2) a compressed\nmetastable representation of the reasoning dynamics can be distilled into a\nsmaller, more efficient model."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04716",
    "c_title":[
      "Some recent results on the punctual Quot schemes"
    ],
    "c_abstract":[
      "Let $C$ be a smooth projective curve defined over the field of complex\nnumbers. Let $E$ be a vector bundle on $C$, and fix an integer $d\\geqslant 1$.\nLet $\\mc Q:={\\rm Quot}(E,d)$ be the Quot Scheme which parameterizes all torsion\nquotients of $E$ of degree $d$. In this article, we survey some recent results\non various invariants of $\\mc Q$."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-113",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07383",
    "b_title":[
      "Diagnostic-free onboard battery health assessment"
    ],
    "b_abstract":[
      "Diverse usage patterns induce complex and variable aging behaviors in\nlithium-ion batteries, complicating accurate health diagnosis and prognosis.\nSeparate diagnostic cycles are often used to untangle the battery's current\nstate of health from prior complex aging patterns. However, these same\ndiagnostic cycles alter the battery's degradation trajectory, are\ntime-intensive, and cannot be practically performed in onboard applications. In\nthis work, we leverage portions of operational measurements in combination with\nan interpretable machine learning model to enable rapid, onboard battery health\ndiagnostics and prognostics without offline diagnostic testing and the\nrequirement of historical data. We integrate mechanistic constraints within an\nencoder-decoder architecture to extract electrode states in a physically\ninterpretable latent space and enable improved reconstruction of the\ndegradation path. The health diagnosis model framework can be flexibly applied\nacross diverse application interests with slight fine-tuning. We demonstrate\nthe versatility of this model framework by applying it to three battery-cycling\ndatasets consisting of 422 cells under different operating conditions,\nhighlighting the utility of an interpretable diagnostic-free, onboard battery\ndiagnosis and prognosis model."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14539",
    "c_title":[
      "ALMA 360 pc high-frequency observations reveal warm dust in the center\n  of a $z=6.9$ quasar"
    ],
    "c_abstract":[
      "The temperature of the cold dust in z>6 galaxies is a potential tracer of\nActive Galactic Nucleus (AGN) and stellar feedback, and is the dominant source\nof uncertainty in inferring properties from the far-infrared (FIR) emission of\nthese galaxies. We present the first resolved dust temperature map in a $z>6$\nquasar host galaxy. We combine new 360 pc resolution ALMA Band 9 continuum\nobservations with literature 190 pc Band 6 observations to derive the dust\ntemperature and opacity at 0.1<r<0.5 kpc scales in a $z=6.9$ luminous quasar\nhost galaxy (J2348-3054). We find that the dust temperature (and opacity)\nincreases at the center (r<216 pc) of the galaxy up to $T_d=73-88$ K, and\npotentially up to $T_d<149$ K at r<110 pc. The combination of the resolved and\nintegrated FIR Spectral Energy Distribution (SED) further reveal a dust\ntemperature gradient and a significant contribution of the AGN hot dust torus\nat $\\nu_{\\rm{obs}}\\gtrsim 700$ GHz. By taking into account the torus\ncontribution and resolved optically-thick emission, we derive a total infrared\nluminosity ($L_{TIR}=8.78\\pm0.10)\\times 10^{12}L_\\odot$) and corresponding\nstar-formation rate (SFR$=1307\\pm15\\ M_\\odot\\ \\rm{yr}^{-1}$), that are at least\na factor $\\sim 3.6$ ($\\sim0.56$ dex) lower than previous measurements assuming\noptically-thin emission. We compare the resolved dust temperature, mass and IR\nluminosity profiles to simulations where they are only reproduced by models in\nwhich the AGN radiation heats the dust in the center of the galaxy. Our\nobservations provide evidence that dust in J2348--3054 cannot be assumed to be\nuniformly cold and optically thin. Whether J2348-3054 is representative of the\nlarger population of high-redshift quasars and galaxies remains to be\ndetermined with dedicated high-resolution and high-frequency ALMA observations."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-114",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01187",
    "b_title":[
      "Skewed Memorization in Large Language Models: Quantification and\n  Decomposition"
    ],
    "b_abstract":[
      "Memorization in Large Language Models (LLMs) poses privacy and security\nrisks, as models may unintentionally reproduce sensitive or copyrighted data.\nExisting analyses focus on average-case scenarios, often neglecting the highly\nskewed distribution of memorization. This paper examines memorization in LLM\nsupervised fine-tuning (SFT), exploring its relationships with training\nduration, dataset size, and inter-sample similarity. By analyzing memorization\nprobabilities over sequence lengths, we link this skewness to the token\ngeneration process, offering insights for estimating memorization and comparing\nit to established metrics. Through theoretical analysis and empirical\nevaluation, we provide a comprehensive understanding of memorization behaviors\nand propose strategies to detect and mitigate risks, contributing to more\nprivacy-preserving LLMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15371",
    "c_title":[
      "A Lyapunov function for a Synchronisation diffeomorphism of three clocks"
    ],
    "c_abstract":[
      "Lyapunov functions are essential tools in dynamical systems, as they allow\nthe stability analysis of equilibrium points without the need to explicitly\nsolve the system's equations. Despite their importance, no systematic method\nexists for constructing Lyapunov functions. In a previous paper, we examined a\ndiffeomorphism arising from the problem of Huygens Synchronisation for three\nidentical limit cycle clocks arranged in a line, proving that the system\npossesses a unique asymptotically stable fixed point on the torus T2,\ncorresponding to synchronisation in phase opposition. In this paper, we\nre-derive this result by constructing a discrete Lyapunov function for the\nsystem. The closure of the basin of attraction of the asymptotically stable\nattractor is the torus T2, showing that Huygens Synchronisation exhibits\ngeneric and robust behaviour, occurring with probability one with respect to\ninitial conditions."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-115",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10636",
    "b_title":[
      "Efficient and Safe Trajectory Planning for Autonomous Agricultural\n  Vehicle Headland Turning in Cluttered Orchard Environments"
    ],
    "b_abstract":[
      "Autonomous agricultural vehicles (AAVs), including field robots and\nautonomous tractors, are becoming essential in modern farming by improving\nefficiency and reducing labor costs. A critical task in AAV operations is\nheadland turning between crop rows. This task is challenging in orchards with\nlimited headland space, irregular boundaries, operational constraints, and\nstatic obstacles. While traditional trajectory planning methods work well in\narable farming, they often fail in cluttered orchard environments. This letter\npresents a novel trajectory planner that enhances the safety and efficiency of\nAAV headland maneuvers, leveraging advancements in autonomous driving. Our\napproach includes an efficient front-end algorithm and a high-performance\nback-end optimization. Applied to vehicles with various implements, it\noutperforms state-of-the-art methods in both standard and challenging orchard\nfields. This work bridges agricultural and autonomous driving technologies,\nfacilitating a broader adoption of AAVs in complex orchards."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19695",
    "c_title":[
      "Breakdown of time-independent methods in non-Hermitian scattering\n  systems"
    ],
    "c_abstract":[
      "Time-independent methods, such as the transfer matrix method, are widely used\nto analyze the scattering properties of non-Hermitian systems. However, we\ndemonstrate that these methods become invalid when the scattering matrix\n(S-matrix) exhibits poles in the first quadrant of the complex wave-number\nplane, indicating the presence of time-growing bound states within the system.\nThe breakdown of time-independent approaches is attributed to their inherent\nomission of these bound states. We illustrate this using tight-binding models\nwhere non-Hermiticity is introduced through imaginary on-site potentials or\nasymmetric hopping terms. In all the models considered, parameter regimes exist\nwhere time-independent methods fail. Our findings highlight the critical\nimportance of examining the distribution of S-matrix poles when applying\ntime-independent methods to non-Hermitian scattering systems. Inappropriate\napplication of these methods can lead to unphysical results and erroneous\nconclusions."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-116",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01924",
    "b_title":[
      "TAET: Two-Stage Adversarial Equalization Training on Long-Tailed\n  Distributions"
    ],
    "b_abstract":[
      "Adversarial robustness is a critical challenge in deploying deep neural\nnetworks for real-world applications. While adversarial training is a widely\nrecognized defense strategy, most existing studies focus on balanced datasets,\noverlooking the prevalence of long-tailed distributions in real-world data,\nwhich significantly complicates robustness. This paper provides a comprehensive\nanalysis of adversarial training under long-tailed distributions and identifies\nlimitations in the current state-of-the-art method, AT-BSL, in achieving robust\nperformance under such conditions. To address these challenges, we propose a\nnovel training framework, TAET, which integrates an initial stabilization phase\nfollowed by a stratified equalization adversarial training phase. Additionally,\nprior work on long-tailed robustness has largely ignored the crucial evaluation\nmetric of balanced accuracy. To bridge this gap, we introduce the concept of\nbalanced robustness, a comprehensive metric tailored for assessing robustness\nunder long-tailed distributions. Extensive experiments demonstrate that our\nmethod surpasses existing advanced defenses, achieving significant improvements\nin both memory and computational efficiency. This work represents a substantial\nadvancement in addressing robustness challenges in real-world applications. Our\ncode is available at:\nhttps:\/\/github.com\/BuhuiOK\/TAET-Two-Stage-Adversarial-Equalization-Training-on-Long-Tailed-Distributions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15843",
    "c_title":[
      "Implicit Neural Representations for Chemical Reaction Paths"
    ],
    "c_abstract":[
      "We show that neural networks can be optimized to represent minimum energy\npaths as continuous functions, offering a flexible alternative to discrete\npath-search methods like Nudged Elastic Band (NEB). Our approach parameterizes\nreaction paths with a network trained on a loss function that discards\ntangential energy gradients and enables instant estimation of the transition\nstate. We first validate the method on two-dimensional potentials and then\ndemonstrate its advantages over NEB on challenging atomistic systems where (i)\npoor initial guesses yield unphysical paths, (ii) multiple competing paths\nexist, or (iii) the reaction follows a complex multi-step mechanism. Results\nhighlight the versatility of the method -- for instance, a simple adjustment to\nthe sampling strategy during optimization can help escape local-minimum\nsolutions. Finally, in a low-dimensional setting, we demonstrate that a single\nneural network can learn from existing paths and generalize to unseen systems,\nshowing promise for a universal reaction path representation."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-117",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05503",
    "b_title":[
      "Steady bubbles and drops in inviscid fluids"
    ],
    "b_abstract":[
      "We construct steady non-spherical bubbles and drops, which are traveling wave\nsolutions to the axisymmetric two-phase Euler equations with surface tension,\nwhose inner phase is a bounded connected domain. The solutions have a uniform\nvorticity distribution in this inner phase and they have a vortex sheet on its\nsurface.\n  Our construction relies on a perturbative approach around an explicit\nspherical solution, given by Hill's vortex enclosed by a spherical vortex\nsheet. The construction is sensitive to the Weber numbers describing the flow.\nAt critical Weber numbers, we perform a bifurcation analysis utilizing the\nCrandall-Rabinowitz theorem in Sobolev spaces on the 2-sphere. Away from these\ncritical numbers, our construction relies on the implicit function theorem.\n  Our results imply that the model containing surface tension is richer than\nthe ordinary one-phase Euler equations, in the sense that for the latter,\nHill's spherical vortex is unique (modulo translations) among all axisymmetric\nsimply connected uniform vortices of a given circulation."
    ],
    "b_categories":[
      [
        "math.AP",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01855",
    "c_title":[
      "UAV-DETR: Efficient End-to-End Object Detection for Unmanned Aerial\n  Vehicle Imagery"
    ],
    "c_abstract":[
      "Unmanned aerial vehicle object detection (UAV-OD) has been widely used in\nvarious scenarios. However, most existing UAV-OD algorithms rely on manually\ndesigned components, which require extensive tuning. End-to-end models that do\nnot depend on such manually designed components are mainly designed for natural\nimages, which are less effective for UAV imagery. To address such challenges,\nthis paper proposes an efficient detection transformer (DETR) framework\ntailored for UAV imagery, i.e., UAV-DETR. The framework includes a multi-scale\nfeature fusion with frequency enhancement module, which captures both spatial\nand frequency information at different scales. In addition, a frequency-focused\ndown-sampling module is presented to retain critical spatial details during\ndown-sampling. A semantic alignment and calibration module is developed to\nalign and fuse features from different fusion paths. Experimental results\ndemonstrate the effectiveness and generalization of our approach across various\nUAV imagery datasets. On the VisDrone dataset, our method improves AP by 3.1\\%\nand $\\text{AP}_{50}$ by 4.2\\% over the baseline. Similar enhancements are\nobserved on the UAVVaste dataset. The project page:\nhttps:\/\/github.com\/ValiantDiligent\/UAV-DETR"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-118",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19632",
    "b_title":[
      "The Non-Uniform Expansion of the Crab Nebula"
    ],
    "b_abstract":[
      "We present extensive proper motion measurements of the Crab Nebula made from\nCanada-France-Hawaii Telescope MegaPrime\/MegaCam images taken in 2007, 2016,\nand 2019. A total of 19974 proper motion vectors with uncertainty\n$<10$\\,mas\\,yr$^{-1}$ located over the majority of the Crab Nebula are used to\nmap the supernova remnant's two-dimensional expansion properties that reflect\nthe dynamics of the original explosion, acceleration of ejecta imparted by\nspin-down energy from the pulsar, and interaction between the ejecta and\nsurrounding cicumstellar material (CSM). The average convergence date we derive\nis 1105.5 $\\pm$ 0.5 CE, which is 15-35 yr earlier compared to most previous\nestimates. We find that it varies as a function of position angle around the\nnebula, with the earliest date and smallest proper motions measured along the\nequator defined by the east and west bays. The lower acceleration of material\nalong the equatorial plane may be indicative of the supernova's interaction\nwith a disk-like CSM geometry. Comparing our measurements to previous\nanalytical solutions of the Crab's expansion and our own numerical simulation\nusing the moving mesh hydrodynamics code \\texttt{Sprout}, we conclude that the\nejecta have relaxed closer to homologous expansion than expected for the\ncommonly adopted pulsar spindown age of $\\tau \\sim 700$ yr and a pulsar wind\nnebula (PWN) still evolving inside the flat part of the ejecta density profile.\nThese findings provide further evidence that the PWN has broken out of the\ninner flat part of the supernova ejecta density profile and has experienced\n``blowout''."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12559",
    "c_title":[
      "AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for\n  Video-language Understanding"
    ],
    "c_abstract":[
      "Multimodal Large Language Models (MLLMs) have revolutionized video\nunderstanding, yet are still limited by context length when processing long\nvideos. Recent methods compress videos by leveraging visual redundancy\nuniformly, yielding promising results. Nevertheless, our quantitative analysis\nshows that redundancy varies significantly across time and model layers,\nnecessitating a more flexible compression strategy. We propose AdaReTaKe, a\ntraining-free method that flexibly reduces visual redundancy by allocating\ncompression ratios among time and layers with theoretical guarantees.\nIntegrated into state-of-the-art MLLMs, AdaReTaKe improves processing capacity\nfrom 256 to 2048 frames while preserving critical information. Experiments on\nVideoMME, MLVU, LongVideoBench, and LVBench datasets demonstrate that AdaReTaKe\noutperforms existing methods by 2.3% and 2.8% for 7B and 72B models,\nrespectively, with even greater improvements of 5.9% and 6.0% on the longest\nLVBench. Our code is available at\nhttps:\/\/github.com\/SCZwangxiao\/video-FlexReduc.git."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-119",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11989",
    "b_title":[
      "Nontrivial nonnegative weak solutions to fractional $p$-Laplace\n  inequalities and equations"
    ],
    "b_abstract":[
      "For the nonlocal quasilinear fractional $p$-Laplace operator $(-\\Delta)^s_p$\nwith $s\\in (0,1)$ and $p\\in(1,\\infty)$, we investigate the nonexistence and\nexistence of nontrivial nonnegative solutions $u$ in the local fractional\nSobolev space $W_{\\rm loc}^{s,p}(\\mathbb R^n)$ that satisfies the inequality\n$(-\\Delta)^s_p u\\ge u^q$ weakly in $\\mathbb R^n$, where $q\\in(0,\\infty)$. In\naddition, nonexistence of nontrivial nonnegative weak solutions in the global\nfractional Sobolev space $W^{s,p}(\\mathbb R^n)$ to the fractional $p$-Laplace\nequation $(-\\Delta)^s_p u= u^q$ are also investigated. The approach taken in\nthis paper is mainly based on some delicate analysis of the fundamental\nsolutions to the fractional $p$-Laplace operator $(-\\Delta)^s_p$."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10325",
    "c_title":[
      "DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image\n  Restoration"
    ],
    "c_abstract":[
      "Diffusion models (DMs) have achieved promising performance in image\nrestoration but haven't been explored for stereo images. The application of DM\nin stereo image restoration is confronted with a series of challenges. The need\nto reconstruct two images exacerbates DM's computational cost. Additionally,\nexisting latent DMs usually focus on semantic information and remove\nhigh-frequency details as redundancy during latent compression, which is\nprecisely what matters for image restoration. To address the above problems, we\npropose a high-frequency aware diffusion model, DiffStereo for stereo image\nrestoration as the first attempt at DM in this domain. Specifically, DiffStereo\nfirst learns latent high-frequency representations (LHFR) of HQ images. DM is\nthen trained in the learned space to estimate LHFR for stereo images, which are\nfused into a transformer-based stereo image restoration network providing\nbeneficial high-frequency information of corresponding HQ images. The\nresolution of LHFR is kept the same as input images, which preserves the\ninherent texture from distortion. And the compression in channels alleviates\nthe computational burden of DM. Furthermore, we devise a position encoding\nscheme when integrating the LHFR into the restoration network, enabling\ndistinctive guidance in different depths of the restoration network.\nComprehensive experiments verify that by combining generative DM and\ntransformer, DiffStereo achieves both higher reconstruction accuracy and better\nperceptual quality on stereo super-resolution, deblurring, and low-light\nenhancement compared with state-of-the-art methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-120",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08782",
    "b_title":[
      "A comparative study of different TSO-DSO coordination in the reserve\n  market"
    ],
    "b_abstract":[
      "The increasing penetration of Distributed Energy Resources (DERs) in the\ndistribution system has led to the emergence of a new market actor - the\naggregator. The aggregator serves as a facilitator, enabling flexibility asset\nowners to get access to different markets. In which, EVs aggregators are\ngaining more attention due to their expanding use and potential to provide\nservices in various types of markets, particularly in the reserve market.\nCurrently, TSO indirectly utilizes these resources under the management of the\ndistribution system operators (DSO), which can negatively impact the\ndistribution grid. Conversely, adjustments from DSOs can impact service\nprovision to TSO due to the shortage of TSO usage information. These factors\nhighlight the importance of evaluating the service provision from aggregators\nunder different TSO-DSO coordination schemes. This paper focuses on the\nprovision of flexibility from electric vehicles (EVs) aggregators for balancing\nservice in the TSO-DSO hybrid-managed and compares it with the DSO-managed\ncoordination schemes. The behavior of aggregators reacting to price\nfluctuations and TSO requests under different coordination schemes and\nsimulation scenarios is thoroughly evaluated. Additionally, their impact on the\ngrid is analyzed through the DSO's congestion management process and validated\nusing data from a real part of the Dutch distribution network. Results find\nthat the hybrid-managed coordination scheme gives more benefit to the\naggregator than the DSO-managed scheme and the EVs aggregator will gain more\nprofit in winter than summer due to more upward regulation service is needed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13735",
    "c_title":[
      "Kinetic modelling of economic markets with individual and collective\n  transactions"
    ],
    "c_abstract":[
      "Two kinetic exchange models are proposed to explore the dynamics of closed\neconomic markets characterized by random exchanges, saving propensities, and\ncollective transactions. Model I simulates a system where individual\ntransactions occur among agents with saving tendencies, along with collective\ntransactions between groups. Model II restricts individual transactions to\nagents within the same group, but allows for collective transactions between\ngroups. A three-step trading process--comprising intergroup transactions,\nintragroup redistribution, and individual exchanges--is developed to capture\nthe dual-layered market dynamics. The saving propensity is incorporated using\nthe Chakraborti-Chakrabarti model, applied to both individual and collective\ntransactions. Results reveal that collective transactions increase wealth\ninequality by concentrating wealth within groups, as indicated by higher Gini\ncoefficients and Kolkata indices. In contrast, individual transactions across\ngroups mitigate inequality through more uniform wealth redistribution. The\ninterplay between saving propensities and collective transactions governs\ndeviation degree and entropy, which display inverse trends. Higher saving\npropensities lead to deviations from the Boltzmann-Gibbs equilibrium, whereas\nspecific thresholds result in collective transaction dominance, producing\nnotable peaks or troughs in these metrics. These findings underscore the\ncritical influence of dual-layered market interactions on wealth distribution\nand economic dynamics."
    ],
    "c_categories":[
      [
        "nlin.CG"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-121",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06296",
    "b_title":[
      "MoEMoE: Question Guided Dense and Scalable Sparse Mixture-of-Expert for\n  Multi-source Multi-modal Answering"
    ],
    "b_abstract":[
      "Question Answering (QA) and Visual Question Answering (VQA) are well-studied\nproblems in the language and vision domain. One challenging scenario involves\nmultiple sources of information, each of a different modality, where the answer\nto the question may exist in one or more sources. This scenario contains richer\ninformation but is highly complex to handle. In this work, we formulate a novel\nquestion-answer generation (QAG) framework in an environment containing\nmulti-source, multimodal information. The answer may belong to any or all\nsources; therefore, selecting the most prominent answer source or an optimal\ncombination of all sources for a given question is challenging. To address this\nissue, we propose a question-guided attention mechanism that learns attention\nacross multiple sources and decodes this information for robust and unbiased\nanswer generation. To learn attention within each source, we introduce an\nexplicit alignment between questions and various information sources, which\nfacilitates identifying the most pertinent parts of the source information\nrelative to the question. Scalability in handling diverse questions poses a\nchallenge. We address this by extending our model to a sparse\nmixture-of-experts (sparse-MoE) framework, enabling it to handle thousands of\nquestion types. Experiments on T5 and Flan-T5 using three datasets demonstrate\nthe model's efficacy, supported by ablation studies."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07756",
    "c_title":[
      "Nonabelian Yang-Mills-Higgs and Plateau's problem in codimension three"
    ],
    "c_abstract":[
      "We investigate the asymptotic behavior of the\n$\\mathrm{SU}(2)$-Yang-Mills-Higgs energy $E(\\Phi,A)=\\int_M|d_A\\Phi|^2+|F_A|^2$\nin the large mass limit, proving convergence to the codimension-three area\nfunctional in the sense of De Giorgi's $\\Gamma$-convergence. More precisely,\nfor a compact manifold with boundary $M$ and any family of pairs\n$\\Phi_m\\in\\Omega^0(M;\\mathfrak{su}(2))$ and $A_m\\in\n\\Omega^1(M;\\mathfrak{su}(2))$ indexed by a mass parameter $m\\to\\infty$,\nsatisfying $$E(\\Phi_m,A_m)\\leq\nCm\\quad\\text{and}\\quad\\lim_{m\\to\\infty}\\frac{1}{m}\\int_M(m-|\\Phi_m|)^2=0,$$ we\nprove that the $(n-3)$-currents dual to $\\frac{1}{2\\pi\nm}\\mathrm{tr}(d_{A_m}\\Phi_m\\wedge F_{A_m})$ converge subsequentially to a\nrelative integral $(n-3)$-cycle $T$ of mass \\begin{equation}\n  \\mathbb{M}(T)\\leq \\liminf_{m\\to\\infty}\\frac{1}{4\\pi m}E(\\Phi_m,A_m),\n\\end{equation} and show conversely that any integral $(n-3)$-current $T$ with\n$[T]=0\\in H_{n-3}(M,\\partial M;\\mathbb{Z})$ admits such an approximation, with\nequality in the above inequality. In the special case of pairs $(\\Phi_m,A_m)$\nsatisfying the generalized monopole equation $*d_{A_m}\\Phi_m=F_{A_m}\\wedge\n\\Theta$ for a calibration form $\\Theta\\in \\Omega^{n-3}(M)$, we deduce that the\nlimit $\\nu=\\lim_{m\\to\\infty}\\frac{1}{2\\pi m}|d_{A_m}\\Phi_m|^2$ of the Dirichlet\nenergy measures satisfies $\\nu\\leq |T|$, with equality if and only if $T$ is\ncalibrated by $\\Theta$, giving evidence for predictions of Donaldson-Segal in\nthe settings of $G_2$-manifolds and Calabi-Yau $3$-folds."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-122",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14006",
    "b_title":[
      "Asymmetrical Latent Representation for Individual Treatment Effect\n  Modeling"
    ],
    "b_abstract":[
      "Conditional Average Treatment Effect (CATE) estimation, at the heart of\ncounterfactual reasoning, is a crucial challenge for causal modeling both\ntheoretically and applicatively, in domains such as healthcare, sociology, or\nadvertising. Borrowing domain adaptation principles, a popular design maps the\nsample representation to a latent space that balances control and treated\npopulations while enabling the prediction of the potential outcomes. This paper\npresents a new CATE estimation approach based on the asymmetrical search for\ntwo latent spaces called Asymmetrical Latent Representation for Individual\nTreatment Effect (ALRITE), where the two latent spaces are respectively\nintended to optimize the counterfactual prediction accuracy on the control and\nthe treated samples. Under moderate assumptions, ALRITE admits an upper bound\non the precision of the estimation of heterogeneous effects (PEHE), and the\napproach is empirically successfully validated compared to the state-of-the-art"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08971",
    "c_title":[
      "Improved bounds on collapse models from rotational noise of LISA\n  Pathfinder"
    ],
    "c_abstract":[
      "Spontaneous wavefunction collapse models offer a solution to the quantum\nmeasurement problem, by modifying the Schr\\\"odinger equation with nonlinear and\nstochastic terms. The Continuous Spontaneous Localisation (CSL) model is the\nmost studied among these models, with phenomenological parameters that are\nconstrained by experiments. Here, we exploit the recent analysis of LISA\nPathfinder's angular motion data to derive a tighter constraint than previously\nachieved with translational motion. Moreover, we identify the general\nconditions for preferring rotational measurement over translational ones for\nconstraining the CSL model."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-123",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05638",
    "b_title":[
      "Mim-Width is paraNP-complete"
    ],
    "b_abstract":[
      "We show that it is NP-hard to distinguish graphs of linear mim-width at most\n1211 from graphs of sim-width at least 1216. This implies that Mim-Width,\nSim-Width, One-Sided Mim-Width, and their linear counterparts are all\nparaNP-complete, i.e., NP-complete to compute even when upper bounded by a\nconstant."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.DM",
        "cs.DS",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18772",
    "c_title":[
      "Dissociated Neuronal Cultures as Model Systems for Self-Organized\n  Prediction"
    ],
    "c_abstract":[
      "Dissociated neuronal cultures provide a simplified yet effective model system\nfor investigating self-organized prediction and information processing in\nneural networks. This review consolidates current research demonstrating that\nthese in vitro networks display fundamental computational capabilities,\nincluding predictive coding, adaptive learning, goal-directed behavior, and\ndeviance detection. We examine how these cultures develop critical dynamics\noptimized for information processing, detail the mechanisms underlying learning\nand memory formation, and explore the relevance of the free energy principle\nwithin these systems. Building on these insights, we discuss how findings from\ndissociated neuronal cultures inform the design of neuromorphic and reservoir\ncomputing architectures, with the potential to enhance energy efficiency and\nadaptive functionality in artificial intelligence. The reduced complexity of\nneuronal cultures allows for precise manipulation and systematic investigation,\nbridging theoretical frameworks with practical implementations in bio-inspired\ncomputing. Finally, we highlight promising future directions, emphasizing\nadvancements in three-dimensional culture techniques, multi-compartment models,\nand brain organoids that deepen our understanding of hierarchical and\npredictive processes in both biological and artificial systems. This review\naims to provide a comprehensive overview of how dissociated neuronal cultures\ncontribute to neuroscience and artificial intelligence, ultimately paving the\nway for biologically inspired computing solutions."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-124",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14714",
    "b_title":[
      "Authenticity as Aesthetics: Enabling the Client to Dominate\n  Decision-making in Co-design"
    ],
    "b_abstract":[
      "This paper revises aesthetics theory through the lens of authenticity and\ninvestigates practical applications using a co-design approach. We encourage\ndesigners to include ordinary clients as co-creators in the co-design process,\nguiding them in expressing their aesthetics, values, and preferences while\nstimulating their creativity. This paper proposes a bespoke design process\nframework for authenticity aesthetics that incorporates empathy, defining,\nideating, prototyping, and testing. This framework delineates the roles and\nresponsibilities of clients and designers at different phases and highlights\nevolving material mediums that enable their communication. The paper concludes\nby reflecting on consumerist aesthetics, advocating for designers to focus on\nthe insights of ordinary clients, design for their authentic uniqueness, and\nrecognize the broad prospects of bespoke design methods."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02538",
    "c_title":[
      "Global 21 cm signal: a promising probe of primordial features"
    ],
    "c_abstract":[
      "Inflationary models that involve bursts of particle production generate\nbump-like features in the primordial power spectrum of density perturbations.\nThese features influence the evolution of density fluctuations, leaving their\nunique signatures in cosmological observations. A detailed investigation of\nsuch signatures would help constrain physical processes during inflation. With\nthis motivation, the goal of this paper is two-fold. First, we conduct a\ndetailed analysis of the effects of bump-like primordial features on the\nsky-averaged 21 cm signal. Using semi-numerical simulations, we demonstrate\nthat the primordial features can significantly alter the ionization history and\nthe global 21 cm profile, making them a promising probe of inflationary models.\nWe found a special scale (namely, the turnover wavenumber, $k^{\\rm turn}$) at\nwhich the effect of primordial bump-like features on the global 21 cm profile\nvanishes. Also, we found that the behaviour of the primordial features on the\nglobal profile and ionization history are quite opposite for $k > k^{\\rm turn}$\nand $k < k^{\\rm turn}$. We trace the root cause of these behaviours to the\neffects of primordial features on the halo mass function at high redshifts.\nFurthermore, we discuss the degeneracy between the astrophysical parameters and\nthe primordial features in detail. Secondly, for a fixed set of astrophysical\nparameters, we derive upper limits on the amplitude of bump-like features in\nthe range $10^{-1} < k\\,[{\\rm Mpc}^{-1}] < 10^2$ using current limits on\noptical depth to reionization from CMB data by Planck."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-125",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12179",
    "b_title":[
      "Fitting regular point patterns with a hyperuniform perturbed lattice"
    ],
    "b_abstract":[
      "We introduce a new methodology for modeling regular spatial data using\nhyperuniform point processes. We show that, under some mixing conditions on the\nperturbations, perturbed lattices in general dimension are hyperuniform. Due to\ntheir inherent repulsive structure, they serve as an effective baseline model\nfor data sets in which points exhibit repulsiveness. Specifically, we derive an\nexplicit formula for the $K$-function of lattices perturbed by a Gaussian\nrandom field, which proves particularly useful in conjunction with the minimal\ncontrast method. We apply this approach to a data set representing the grain\ncenters of a polycrystalline metallic material composed of nickel and titanium."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07071",
    "c_title":[
      "TRADES: Generating Realistic Market Simulations with Diffusion Models"
    ],
    "c_abstract":[
      "Financial markets are complex systems characterized by high statistical\nnoise, nonlinearity, and constant evolution. Thus, modeling them is extremely\nhard. We address the task of generating realistic and responsive Limit Order\nBook (LOB) market simulations, which are fundamental for calibrating and\ntesting trading strategies, performing market impact experiments, and\ngenerating synthetic market data. Previous works lack realism, usefulness, and\nresponsiveness of the generated simulations. To bridge this gap, we propose a\nnovel TRAnsformer-based Denoising Diffusion Probabilistic Engine for LOB\nSimulations (TRADES). TRADES generates realistic order flows conditioned on the\nstate of the market, leveraging a transformer-based architecture that captures\nthe temporal and spatial characteristics of high-frequency market data. There\nis a notable absence of quantitative metrics for evaluating generative market\nsimulation models in the literature. To tackle this problem, we adapt the\npredictive score, a metric measured as an MAE, by training a stock price\npredictive model on synthetic data and testing it on real data. We compare\nTRADES with previous works on two stocks, reporting an x3.27 and x3.47\nimprovement over SoTA according to the predictive score, demonstrating that we\ngenerate useful synthetic market data for financial downstream tasks. We assess\nTRADES's market simulation realism and responsiveness, showing that it\neffectively learns the conditional data distribution and successfully reacts to\nan experimental agent, giving sprout to possible calibrations and evaluations\nof trading strategies and market impact experiments. We developed DeepMarket,\nthe first open-source Python framework for market simulation with deep\nlearning. Our repository includes a synthetic LOB dataset composed of TRADES's\ngenerates simulations. We release the code at\ngithub.com\/LeonardoBerti00\/DeepMarket."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-fin.CP",
        "q-fin.TR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-126",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12270",
    "b_title":[
      "A Bayesian location-scale joint model for time-to-event and multivariate\n  longitudinal data with association based on within-individual variability"
    ],
    "b_abstract":[
      "Within-individual variability of health indicators measured over time is\nbecoming commonly used to inform about disease progression. Simple summary\nstatistics (e.g. the standard deviation for each individual) are often used but\nthey are not suited to account for time changes. In addition, when these\nsummary statistics are used as covariates in a regression model for\ntime-to-event outcomes, the estimates of the hazard ratios are subject to\nregression dilution. To overcome these issues, a joint model is built where the\nassociation between the time-to-event outcome and multivariate longitudinal\nmarkers is specified in terms of the within-individual variability of the\nlatter. A mixed-effect location-scale model is used to analyse the longitudinal\nbiomarkers, their within-individual variability and their correlation. The time\nto event is modelled using a proportional hazard regression model, with a\nflexible specification of the baseline hazard, and the information from the\nlongitudinal biomarkers is shared as a function of the random effects. The\nmodel can be used to quantify within-individual variability for the\nlongitudinal markers and their association with the time-to-event outcome. We\nshow through a simulation study the performance of the model in comparison with\nthe standard joint model with constant variance. The model is applied on a\ndataset of adult women from the UK cystic fibrosis registry, to evaluate the\nassociation between lung function, malnutrition and mortality."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12954",
    "c_title":[
      "Efficient Detection of Statistical RF Fields at High Magnetic Field with\n  a Quantum Sensor"
    ],
    "c_abstract":[
      "Nuclear magnetic resonance (NMR) spectroscopy is widely used in fields\nranging from chemistry, material science to neuroscience. Nanoscale NMR\nspectroscopy using Nitrogen-vacancy (NV) centers in diamond has emerged as a\npromising platform due to an unprecedented sensitivity down to the single spin\nlevel. At the nanoscale, high nuclear spin polarization through spin\nfluctuations (statistical polarization) far outweighs thermal polarization.\nHowever, until now efficient NMR detection using coherent averaging techniques\ncould not be applied to the detection of statistical polarization, leading to\nlong measurement times. Here we present two protocols to enable coherent\naveraging of statistical oscillating signals through rectification. We\ndemonstrate these protocols on an artificial radiofrequency signal detected\nwith a single NV center at 2.7 T. Through this, the signal-to-noise scaling\nwith number of measurements $N$ is improved from $N^{0.5}$ to $N^1$, improving\nthe measurement time significantly. The relevance of rectification for the\ndetection of statistical polarization using NV ensembles is outlined, paving\nthe way for efficient nanoscale NMR spectroscopy."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-127",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01261",
    "b_title":[
      "Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical\n  Codebook-Text Alignment with Long Text"
    ],
    "b_abstract":[
      "Image quantization is a crucial technique in image generation, aimed at\nlearning a codebook that encodes an image into a discrete token sequence.\nRecent advancements have seen researchers exploring learning multi-modal\ncodebook (i.e., text-aligned codebook) by utilizing image caption semantics,\naiming to enhance codebook performance in cross-modal tasks. However, existing\nimage-text paired datasets exhibit a notable flaw in that the text descriptions\ntend to be overly concise, failing to adequately describe the images and\nprovide sufficient semantic knowledge, resulting in limited alignment of text\nand codebook at a fine-grained level. In this paper, we propose a novel\nText-Augmented Codebook Learning framework, named TA-VQ, which generates longer\ntext for each image using the visual-language model for improved text-aligned\ncodebook learning. However, the long text presents two key challenges: how to\nencode text and how to align codebook and text. To tackle two challenges, we\npropose to split the long text into multiple granularities for encoding, i.e.,\nword, phrase, and sentence, so that the long text can be fully encoded without\nlosing any key semantic knowledge. Following this, a hierarchical encoder and\nnovel sampling-based alignment strategy are designed to achieve fine-grained\ncodebook-text alignment. Additionally, our method can be seamlessly integrated\ninto existing VQ models. Extensive experiments in reconstruction and various\ndownstream tasks demonstrate its effectiveness compared to previous\nstate-of-the-art approaches."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14289",
    "c_title":[
      "Analyzing Heat Transport in Crystalline Polymers in Real and Reciprocal\n  Space"
    ],
    "c_abstract":[
      "Heat transport can be modelled with a variety of approaches in real space\n(using molecular dynamics) or in reciprocal space (using the Boltzmann\ntransport equation). Employing two conceptually different approaches of each\ntype, we study heat transport in crystalline polyethylene and polythiophene. We\nfind that consistent results can be obtained when using highly efficient and\naccurate machine-learned potentials, provided that the physical intricacies of\nthe considered materials and methods are correctly accounted for. For\npolythiophene this turns out to be comparably straightforward, while for\npolyethylene we find that the inclusion of higher-order anharmonicities is\ncrucial to avoid a massive overestimation of the thermal conductivity. The\nresponsible long-lived phonons are found at relatively high frequencies between\n11 THz and 16 THz. This complicates the use of classical statistics in all\nmolecular-dynamics-based approaches."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-128",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13217",
    "b_title":[
      "Complexity and Algorithm for the Matching vertex-cutset Problem"
    ],
    "b_abstract":[
      "In 1985, Chv\\'{a}tal introduced the concept of star cutsets as a means to\ninvestigate the properties of perfect graphs, which inspired many researchers\nto study cutsets with some specific structures, for example, star cutsets,\nclique cutsets, stable cutsets. In recent years, approximation algorithms have\ndeveloped rapidly, the computational complexity associated with determining the\nminimum vertex cut possessing a particular structural property have attracted\nconsiderable academic attention.\n  In this paper, we demonstrate that determining whether there is a matching\nvertex-cutset in $H$ with size at most $k$, is $\\mathbf{NP}$-complete, where\n$k$ is a given positive integer and $H$ is a connected graph. Furthermore, we\ndemonstrate that for a connected graph $H$, there exists a $2$-approximation\nalgorithm in $O(nm^2)$ for us to find a minimum matching vertex-cutset.\nFinally, we show that every plane graph $H$ satisfying $H\\not\\in\\{K_2, K_4\\}$\ncontains a matching vertex-cutset with size at most three, and this bound is\ntight."
    ],
    "b_categories":[
      [
        "cs.DS",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06193",
    "c_title":[
      "A Never-Ending Story: Revisiting Requirements Major Misunderstandings"
    ],
    "c_abstract":[
      "A magic medallion is central in Michael Ender novel, and it is depicted as\ntwo snakes biting each other, in a loop. Folk tale says that the design of the\nmedallion changed for the Wolfgang Petersen movie, depicting an even deeper\nimage of infinity. The medallion turned out to be an icon for the story fans.\nThis paper will unleash a broad view of the realm of requirements and\nrequirements engineering, comparing it to Percival quest for the Holy Grail.\nUsing literate and pop metaphors the paper posits that requirements engineering\nis an education process, which must be performed with transparency. Historical\nmisunderstandings of requirements are reviewed, pitfalls to avoid are signaled\nand new trails to be built are proposed."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-129",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02077",
    "b_title":[
      "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback\n  of Mixed Quality"
    ],
    "b_abstract":[
      "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality (M3HF),\na novel framework that integrates multi-phase human feedback of mixed quality\ninto the MARL training process. By involving humans with diverse expertise\nlevels to provide iterative guidance, M3HF leverages both expert and non-expert\nfeedback to continuously refine agents' policies. During training, we\nstrategically pause agent learning for human evaluation, parse feedback using\nlarge language models to assign it appropriately and update reward functions\nthrough predefined templates and adaptive weight by using weight decay and\nperformance-based adjustments. Our approach enables the integration of nuanced\nhuman insights across various levels of quality, enhancing the interpretability\nand robustness of multi-agent cooperation. Empirical results in challenging\nenvironments demonstrate that M3HF significantly outperforms state-of-the-art\nmethods, effectively addressing the complexities of reward design in MARL and\nenabling broader human participation in the training process."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09886",
    "c_title":[
      "Holographic Bound of Casimir Effect in General Dimensions"
    ],
    "c_abstract":[
      "Recently, it has been proposed that holography imposes a universal lower\nbound on the Casimir effect for 3d BCFTs. This paper generalizes the\ndiscussions to higher dimensions. We find Einstein gravity, DGP gravity, and\nGauss-Bonnet gravity sets a universal lower bound of the strip Casimir effect\nin general dimensions. We verify the holographic bound by free theories and\n$O(N)$ models in the $\\epsilon$ expansions. We also derive the holographic\nbound of the Casimir effect for a wedge and confirm free theories obey it. It\nimplies holography sets a lower bound of the Casimir effect for general\nboundary shapes, not limited to the strip. Finally, we briefly comment on the\nimpact of mass and various generalizations and applications of our results."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-130",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10786",
    "b_title":[
      "Epidemic-guided deep learning for spatiotemporal forecasting of\n  Tuberculosis outbreak"
    ],
    "b_abstract":[
      "Tuberculosis (TB) remains a formidable global health challenge, driven by\ncomplex spatiotemporal transmission dynamics and influenced by factors such as\npopulation mobility and behavioral changes. We propose an Epidemic-Guided Deep\nLearning (EGDL) approach that fuses mechanistic epidemiological principles with\nadvanced deep learning techniques to enhance early warning systems and\nintervention strategies for TB outbreaks. Our framework is built upon a\nnetworked Susceptible-Infectious-Recovered (SIR) model augmented with a\nsaturated incidence rate and graph Laplacian diffusion, capturing both\nlong-term transmission dynamics and region-specific population mobility\npatterns. Compartmental model parameters are rigorously estimated using\nBayesian inference via the Markov Chain Monte Carlo (MCMC) approach.\nTheoretical analysis leveraging the comparison principle and Green's formula\nestablishes global stability properties of the disease-free and endemic\nequilibria. Building on these epidemiological insights, we design two\nforecasting architectures, EGDL-Parallel and EGDL-Series, that integrate the\nmechanistic outputs of the networked SIR model within deep neural networks.\nThis integration mitigates the overfitting risks commonly encountered in\ndata-driven methods and filters out noise inherent in surveillance data,\nresulting in reliable forecasts of real-world epidemic trends. Experiments\nconducted on TB incidence data from 47 prefectures in Japan demonstrate that\nour approach delivers robust and accurate predictions across multiple time\nhorizons (short to medium-term forecasts). Additionally, incorporating\nuncertainty quantification through conformal prediction enhances the model's\npractical utility for guiding targeted public health interventions."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07255",
    "c_title":[
      "GazeGrasp: DNN-Driven Robotic Grasping with Wearable Eye-Gaze Interface"
    ],
    "c_abstract":[
      "We present GazeGrasp, a gaze-based manipulation system enabling individuals\nwith motor impairments to control collaborative robots using eye-gaze. The\nsystem employs an ESP32 CAM for eye tracking, MediaPipe for gaze detection, and\nYOLOv8 for object localization, integrated with a Universal Robot UR10 for\nmanipulation tasks. After user-specific calibration, the system allows\nintuitive object selection with a magnetic snapping effect and robot control\nvia eye gestures. Experimental evaluation involving 13 participants\ndemonstrated that the magnetic snapping effect significantly reduced gaze\nalignment time, improving task efficiency by 31%. GazeGrasp provides a robust,\nhands-free interface for assistive robotics, enhancing accessibility and\nautonomy for users."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-131",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10561",
    "b_title":[
      "VisiMark: Characterizing and Augmenting Landmarks for People with Low\n  Vision in Augmented Reality to Support Indoor Navigation"
    ],
    "b_abstract":[
      "Landmarks are critical in navigation, supporting self-orientation and mental\nmodel development. Similar to sighted people, people with low vision (PLV)\nfrequently look for landmarks via visual cues but face difficulties identifying\nsome important landmarks due to vision loss. We first conducted a formative\nstudy with six PLV to characterize their challenges and strategies in landmark\nselection, identifying their unique landmark categories (e.g., area\nsilhouettes, accessibility-related objects) and preferred landmark\naugmentations. We then designed VisiMark, an AR interface that supports\nlandmark perception for PLV by providing both overviews of space structures and\nin-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found\nthat VisiMark enabled PLV to perceive landmarks they preferred but could not\neasily perceive before, and changed PLV's landmark selection from only\nvisually-salient objects to cognitive landmarks that are more important and\nmeaningful. We further derive design considerations for AR-based landmark\naugmentation systems for PLV."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14398",
    "c_title":[
      "Circular sorting"
    ],
    "c_abstract":[
      "We determine the maximal number of steps required to sort $n$ labeled points\non a circle by adjacent swaps. Lower bounds for sorting by all swaps, not\nnecessarily adjacent, are given as well."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-132",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06971",
    "b_title":[
      "Fluorescent Biomolecules Detectable in Near-Surface Ice on Europa"
    ],
    "b_abstract":[
      "Europa, Jupiter's second Galilean moon, is believed to host a subsurface\nocean in contact with a rocky mantle, where hydrothermal activity may drive the\nsynthesis of organic molecules. Of these molecules, abiotic synthesis of\naromatic amino acids is unlikely, and their detection on Europa could be\nconsidered a biosignature. Fluorescence from aromatic amino acids, with\ncharacteristic emissions in the 200-400 nanometer wavelength range, can be\ninduced by a laser and may be detectable where ocean material has been\nrelatively recently emplaced on Europa's surface, as indicated by geologically\nyoung terrain and surface features. However, surface bombardment by charged\nparticles from the Jovian magnetosphere and solar ultraviolet (UV) radiation\ndegrades organic molecules, limiting their longevity. We model radiolysis and\nphotolysis of aromatic amino acids embedded in ice, showing dependencies on\nhemispheric and latitudinal patterns of charged particle bombardment and ice\nphase. We demonstrate that biosignatures contained within freshly deposited ice\nin high-latitude regions on the surface of Europa are detectable using\nlaser-induced UV fluorescence, even from an orbiting spacecraft."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02392",
    "c_title":[
      "Syntactic Evolution in Language Usage"
    ],
    "c_abstract":[
      "This research aims to investigate the dynamic nature of linguistic style\nthroughout various stages of life, from post teenage to old age. By employing\nlinguistic analysis tools and methodologies, the study will delve into the\nintricacies of how individuals adapt and modify their language use over time.\nThe research uses a data set of blogs from blogger.com from 2004 and focuses on\nEnglish for syntactic analysis. The findings of this research can have\nimplications for linguistics, psychology, and communication studies, shedding\nlight on the intricate relationship between age and language."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-133",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02945",
    "b_title":[
      "The Tabular Foundation Model TabPFN Outperforms Specialized Time Series\n  Forecasting Models Based on Simple Features"
    ],
    "b_abstract":[
      "Foundation models have become popular in forecasting due to their ability to\nmake accurate predictions, even with minimal fine-tuning on specific datasets.\nIn this paper, we demonstrate how the newly released regression variant of\nTabPFN, a general tabular foundation model, can be applied to time series\nforecasting. We propose a straightforward approach, TabPFN-TS, which pairs\nTabPFN with simple feature engineering to achieve strong forecasting\nperformance. Despite its simplicity and with only 11M parameters, TabPFN-TS\noutperforms Chronos-Mini, a model of similar size, and matches or even slightly\noutperforms Chronos-Large, which has 65-fold more parameters. A key strength of\nour method lies in its reliance solely on artificial data during pre-training,\navoiding the need for large training datasets and eliminating the risk of\nbenchmark contamination."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04271",
    "c_title":[
      "Steady vortex patches on flat torus with a constant background vorticity"
    ],
    "c_abstract":[
      "We construct a series of vortex patch solutions in a doubly-periodic\nrectangular domain (flat torus), which is accomplished by studying the contour\ndynamic equation for patch boundaries. We will illustrate our key idea by\ndiscussing the single-layered patches as the most fundamental configuration,\nand then investigate the general construction for $N$ patches near a point\nvortex equilibrium. Different with the case of bounded domains in $\\mathbb\nR^2$, a constant background vorticity will arise from the compact nature of\nflat torus, and the $2$-dimensional translational invariance will bring\ntroubles on determining patch locations. To overcome these two difficulties, we\nwill add additional terms for background vorticity and introduce a centralized\ncondition for location vector. By utilizing the regularity difference of terms\nin contour dynamic equations, we also obtain the $C^\\infty$ regularity and\nconvexity of boundary curves."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-134",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16731",
    "b_title":[
      "On the acceleration of gradient methods: the triangle steepest descent\n  method"
    ],
    "b_abstract":[
      "The gradient type of methods has been a competitive choice in solving large\nscale problems arising from various applications such as machine learning.\nHowever, there is still space to accelerate the gradient methods. To this end,\nin this paper, we pay attention to the cyclic steepest descent method (CSD),\nand prove that the CSD method has a gradient subsequence that is\nR-superlinearly convergent for the 2-dimensional strictly convex quadratic\ncase. Moreover, we propose a new gradient method called triangle steepest\ndescent method (TSD) which has a parameter $j$ to control the number of cycles.\nThis method is motivated by utilizing a geometric property of the steepest\ndescent method (SD) method to get around the zigzag behavior. We show that the\nTSD method is at least R-linearly convergent for strictly convex quadratic\nproblems. The advantage of the TSD method is that it is not sensitive to the\ncondition number of a strictly convex quadratic problem. For example, it\nperforms better than other competitive gradient methods when the condition\nnumber reaches 1e20 or 1e100 for some strictly convex quadratic problems.\nExtensive numerical results verify the efficiency of the TSD method compared to\nother types of gradient methods."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06658",
    "c_title":[
      "Comparing Few-Shot Prompting of GPT-4 LLMs with BERT Classifiers for\n  Open-Response Assessment in Tutor Equity Training"
    ],
    "c_abstract":[
      "Assessing learners in ill-defined domains, such as scenario-based human\ntutoring training, is an area of limited research. Equity training requires a\nnuanced understanding of context, but do contemporary large language models\n(LLMs) have a knowledge base that can navigate these nuances? Legacy\ntransformer models like BERT, in contrast, have less real-world knowledge but\ncan be more easily fine-tuned than commercial LLMs. Here, we study whether\nfine-tuning BERT on human annotations outperforms state-of-the-art LLMs (GPT-4o\nand GPT-4-Turbo) with few-shot prompting and instruction. We evaluate\nperformance on four prediction tasks involving generating and explaining\nopen-ended responses in advocacy-focused training lessons in a higher education\nstudent population learning to become middle school tutors. Leveraging a\ndataset of 243 human-annotated open responses from tutor training lessons, we\nfind that BERT demonstrates superior performance using an offline fine-tuning\napproach, which is more resource-efficient than commercial GPT models. We\nconclude that contemporary GPT models may not adequately capture nuanced\nresponse patterns, especially in complex tasks requiring explanation. This work\nadvances the understanding of AI-driven learner evaluation under the lens of\nfine-tuning versus few-shot prompting on the nuanced task of equity training,\ncontributing to more effective training solutions and assisting practitioners\nin choosing adequate assessment methods."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-135",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08257",
    "b_title":[
      "DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with\n  Physics Awareness"
    ],
    "b_abstract":[
      "A dexterous hand capable of grasping any object is essential for the\ndevelopment of general-purpose embodied intelligent robots. However, due to the\nhigh degree of freedom in dexterous hands and the vast diversity of objects,\ngenerating high-quality, usable grasping poses in a robust manner is a\nsignificant challenge. In this paper, we introduce DexGrasp Anything, a method\nthat effectively integrates physical constraints into both the training and\nsampling phases of a diffusion-based generative model, achieving\nstate-of-the-art performance across nearly all open datasets. Additionally, we\npresent a new dexterous grasping dataset containing over 3.4 million diverse\ngrasping poses for more than 15k different objects, demonstrating its potential\nto advance universal dexterous grasping. The code of our method and our dataset\nwill be publicly released soon."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05690",
    "c_title":[
      "Managing Geological Uncertainty in Critical Mineral Supply Chains: A\n  POMDP Approach with Application to U.S. Lithium Resources"
    ],
    "c_abstract":[
      "The world is entering an unprecedented period of critical mineral demand,\ndriven by the global transition to renewable energy technologies and electric\nvehicles. This transition presents unique challenges in mineral resource\ndevelopment, particularly due to geological uncertainty-a key characteristic\nthat traditional supply chain optimization approaches do not adequately\naddress. To tackle this challenge, we propose a novel application of Partially\nObservable Markov Decision Processes (POMDPs) that optimizes critical mineral\nsourcing decisions while explicitly accounting for the dynamic nature of\ngeological uncertainty. Through a case study of the U.S. lithium supply chain,\nwe demonstrate that POMDP-based policies achieve superior outcomes compared to\ntraditional approaches, especially when initial reserve estimates are\nimperfect. Our framework provides quantitative insights for balancing domestic\nresource development with international supply diversification, offering\npolicymakers a systematic approach to strategic decision-making in critical\nmineral supply chains."
    ],
    "c_categories":[
      [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-136",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18033",
    "b_title":[
      "OmnimatteZero: Training-free Real-time Omnimatte with Pre-trained Video\n  Diffusion Models"
    ],
    "b_abstract":[
      "Omnimatte aims to decompose a given video into semantically meaningful\nlayers, including the background and individual objects along with their\nassociated effects, such as shadows and reflections. Existing methods often\nrequire extensive training or costly self-supervised optimization. In this\npaper, we present OmnimatteZero, a training-free approach that leverages\noff-the-shelf pre-trained video diffusion models for omnimatte. It can remove\nobjects from videos, extract individual object layers along with their effects,\nand composite those objects onto new videos. We accomplish this by adapting\nzero-shot image inpainting techniques for video object removal, a task they\nfail to handle effectively out-of-the-box. We then show that self-attention\nmaps capture information about the object and its footprints and use them to\ninpaint the object's effects, leaving a clean background. Additionally, through\nsimple latent arithmetic, object layers can be isolated and recombined\nseamlessly with new video layers to produce new videos. Evaluations show that\nOmnimatteZero not only achieves superior performance in terms of background\nreconstruction but also sets a new record for the fastest Omnimatte approach,\nachieving real-time performance with minimal frame runtime."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02848",
    "c_title":[
      "Direct observation of $\\beta$ and $\\gamma$ decay from a high-spin\n  long-lived isomer in $^{187}$Ta"
    ],
    "c_abstract":[
      "$^{187}$Ta ($Z=73$, $N=114$) is located in the neutron-rich $A \\approx 190$\nregion where a prolate-to-oblate shape transition via triaxial softness is\npredicted to take place. A preceding work on the $K^{\\pi} = (25\/2^-)$ isomer\nand a rotational band to which the isomer decays carried out by the same\ncollaboration revealed that axial symmetry is slightly violated in this\nnucleus. This paper focuses on a higher-lying isomer, which was previously\nidentified at 2933(14) keV by mass measurements with the Experimental Storage\nRing at GSI. The isomer of interest has been populated by a multi-nucleon\ntransfer reaction with a $^{136}$Xe primary beam incident on a natural tungsten\ntarget, using the KEK Isotope Separation System at RIKEN. New experimental\nfindings obtained in the present paper include the internal and external\n$\\beta$-decay branches from the high-spin isomer and a revised half-life of\n136(24) s. The evaluated hindrances for $K$-forbidden transitions put\nconstraints on the spin-parity assignment, which can be interpreted as being\nascribed to a prolate shape with a five-quasiparticle configuration by model\ncalculations."
    ],
    "c_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-137",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03872",
    "b_title":[
      "Universal self-gravitating skyrmions"
    ],
    "b_abstract":[
      "The self-gravitating skyrmion is an exact solution of the Einstein\n$SU(2)$-Skyrme model describing a topological soliton with baryon number $B=1$,\nliving in a $4$-dimensional space-time in the presence of a cosmological\nconstant. Here we show that, using the maximal embedding Ansatz of $SU(2)$ into\n$SU(N)$ in the Euler angles parametrization, this solution can be generalized\nto include arbitrary values of the flavor number and, consequently, allowing\nhigher values of the topological charge. Also, we show that higher-order\ncorrections in the 't Hooft expansion can be considered while still preserving\nthe analytical nature of the solutions. Finally we will show that from the\ngravitational solutions it is possible to construct skyrmions in flat\nspace-time at a finite volume."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00789",
    "c_title":[
      "Development of a Five-Fingerd Biomimetic Soft Robotic Hand by 3D\n  Printing the Skin and Skeleton as One Unit"
    ],
    "c_abstract":[
      "Robot hands that imitate the shape of the human body have been actively\nstudied, and various materials and mechanisms have been proposed to imitate the\nhuman body. Although the use of soft materials is advantageous in that it can\nimitate the characteristics of the human body's epidermis, it increases the\nnumber of parts and makes assembly difficult in order to perform complex\nmovements. In this study, we propose a skin-skeleton integrated robot hand that\nhas 15 degrees of freedom and consists of four parts. The developed robotic\nhand is mostly composed of a single flexible part produced by a 3D printer, and\nwhile it can be easily assembled, it can perform adduction, flexion, and\nopposition of the thumb, as well as flexion of four fingers."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-138",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09614",
    "b_title":[
      "Reversing the Computing Research Workforce Shortfall: Bolstering\n  Domestic Student Pathways to PhDs"
    ],
    "b_abstract":[
      "To sustain innovation and safeguard national security, the U.S. must\nstrengthen domestic pathways to computing PhDs by engaging talented\nundergraduates early - before they are committed to industry - with research\nexperiences, mentorship, and financial support for graduate studies."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18869",
    "c_title":[
      "Dark Matter and Neutrino Phenomenology in Doublet Left-Right Symmetric\n  Model"
    ],
    "c_abstract":[
      "Considering the fact that no Standard Model (SM) particle can account as a\nsuitable dark matter candidate in the relevant studies, several Beyond Standard\nModel (BSM) frameworks incorporate within itself some extra fields depending\nupon the model taken into account. Left-Right Symmetric Model (LRSM) is one\nsuch BSM framework which can successfully explain the origin of neutrino masses\nand also give an elaborative elucidation of the associated phenomenology like\nNeutrinoless Double Beta Decay $(0\\nu\\beta\\beta)$, Lepton Flavor Violation\n(LFV), baryogenesis via leptogenesis etc. However, in spite of the presence of\nseveral new fields within the model, none of them can stand as a suitable dark\nmatter candidate. This compels us to extend LRSM with extra scalars or fermions\ndepending upon the type of study to be taken into account. In the current work,\nwe extend LRSM with a sterile fermion per generation and the lightest of which\nacts as the Dark Matter (DM) candidate. The realization of the model has been\ndone using modular symmetry, where we have used modular group $\\Gamma(3)$ of\nweight 2 which is isomorphic to non-abelian discrete symmetry group $A_{4}$. We\nhave then calculated the relic abundance as well the decay rate of the\ncorresponding DM candidate and also studied $0\\nu\\beta\\beta$ and LFV within the\nmodel and the results have been discussed in detail within the manuscript."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-139",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20563",
    "b_title":[
      "Mean-field approximation and phase transitions in an Ising-voter model\n  on directed regular random graphs"
    ],
    "b_abstract":[
      "It is known that on directed graphs, the correlations between neighbours of a\ngiven site vanish and thus simple mean-field-like arguments can be used to\ndescribe exactly the behaviour of Ising-like systems. We analyse heterogeneous\nmodifications of such models where a fraction of agents is driven by the voter\nor the antivoter dynamics. It turns out that voter agents do not affect the\ndynamics of the model and it behaves like a pure Ising model. Antivoter agents\nhave a stronger impact since they act as a kind of noise, which weakens a\nferromagnetic ordering. Only when Ising spins are driven by the heat-bath\ndynamics, the behaviour of the model is correctly described by the mean-field\napproximation. The Metropolis dynamics generates some additional correlations\nthat render the mean-field approach approximate. Simulations on annealed\nnetworks agree with the mean-field approximation but for the model with\nantivoters and with the Metropolis dynamics only its heterogeneous version\nprovides such an agreement. Calculation of the Binder cumulant confirms that\ncritical points in our models with the heat-bath dynamics belong to the Ising\nmean-field universality class. For the Metropolis dynamics, the phase\ntransition is most likely discontinuous, at least for not too many antivoters."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05216",
    "c_title":[
      "Chasing puppies on orthogonal straight-line plane graphs"
    ],
    "c_abstract":[
      "Assume that you have lost your puppy on an embedded graph. You can walk\naround on the graph and the puppy will run towards you at infinite speed,\nalways locally minimizing the distance to your current position. Is it always\npossible for you to reunite with the puppy? We show that if the embedded graph\nis an orthogonal straight-line embedding the answer is yes."
    ],
    "c_categories":[
      [
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-140",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08334",
    "b_title":[
      "Navier-Stokes\/Allen-Cahn system with moving contact line"
    ],
    "b_abstract":[
      "In this paper, we study a diffuse interface model for two-phase immiscible\nflows coupled by Navier-Stokes equations and mass-conserving Allen-Cahn\nequations. The contact line (the intersection of the fluid-fluid interface with\nthe solid wall) moves along the wall when one fluid replaces the other, such as\nin liquid spreading or oil-water displacement. The system is equipped with the\ngeneralized Navier boundary conditions (GNBC) for the fluid velocity\n${\\boldsymbol u}$, and dynamic boundary condition or relaxation boundary\ncondition for the phase field variable $\\phi$. We first obtain the\nlocal-in-time existence of unique strong solutions to the 2D and 3D\nNavier-Stokes\/Allen-Cahn (NSAC) system with generalized Navier boundary\nconditions and dynamic boundary condition. For the 2D case in channels, we\nfurther show these solutions can be extended to any large time $T$.\nAdditionally, we prove the local-in-time strong solutions for systems with\ngeneralized Navier boundary conditions and relaxation boundary condition in 3D\nchannels. Finally, we establish a global unique strong solution accompany with\nsome exponential decay estimates when the fluids are near phase separation\nstates and the contact angle closes to 90 degrees or the fluid-fluid interface\ntension constant is small."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17547",
    "c_title":[
      "Towards Training-Free Open-World Classification with 3D Generative\n  Models"
    ],
    "c_abstract":[
      "3D open-world classification is a challenging yet essential task in dynamic\nand unstructured real-world scenarios, requiring both open-category and\nopen-pose recognition. To address these challenges, recent wisdom often takes\nsophisticated 2D pre-trained models to provide enriched and stable\nrepresentations. However, these methods largely rely on how 3D objects can be\nprojected into 2D space, which is unfortunately not well solved, and thus\nsignificantly limits their performance. Unlike these present efforts, in this\npaper we make a pioneering exploration of 3D generative models for 3D\nopen-world classification. Drawing on abundant prior knowledge from 3D\ngenerative models, we additionally craft a rotation-invariant feature\nextractor. This innovative synergy endows our pipeline with the advantages of\nbeing training-free, open-category, and pose-invariant, thus well suited to 3D\nopen-world classification. Extensive experiments on benchmark datasets\ndemonstrate the potential of generative models in 3D open-world classification,\nachieving state-of-the-art performance on ModelNet10 and McGill with 32.0% and\n8.7% overall accuracy improvement, respectively."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-141",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07190",
    "b_title":[
      "Epitaxial thin films of pyrochlore iridates: a forward looking approach"
    ],
    "b_abstract":[
      "Topological quantum materials that show strongly correlated electrons as well\nas topological order, for which spin-orbit coupling is a key ingredient,\nexhibit novel states of matter. One such example is the family of pyrochlore\niridates, featuring strong spin-orbital coupling, strong electron interactions\nas well as geometric frustration, making them an ideal platform to study novel\ntopological phases. High-quality epitaxial pyrochlore iridate films, although\nchallenging to produce, provide a pathway to explore unconventional behaviours\nand unravel the intrinsic properties of these largely unexplored materials.\nAdditionally, designing interfaces with specific properties is crucial to\ncreate multilayered devices that can achieve significant technological\nbreakthroughs using topological states of these materials. This article reviews\nexperimental work on epitaxial pyrochlore iridate thin films, discussing\nevidence of topological phases found in them. Future research directions are\noutlined, which include exploring the rich tunability offered by chemical\ndoping, especially when combined with the design of epitaxial heterostructures."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18221",
    "c_title":[
      "Decentralized Navigation of a Cable-Towed Load using Quadrupedal Robot\n  Team via MARL"
    ],
    "c_abstract":[
      "This work addresses the challenge of enabling a team of quadrupedal robots to\ncollaboratively tow a cable-connected load through cluttered and unstructured\nenvironments while avoiding obstacles. Leveraging cables allows the multi-robot\nsystem to navigate narrow spaces by maintaining slack when necessary. However,\nthis introduces hybrid physical interactions due to alternating taut and slack\nstates, with computational complexity that scales exponentially as the number\nof agents increases. To tackle these challenges, we developed a scalable and\ndecentralized system capable of dynamically coordinating a variable number of\nquadrupedal robots while managing the hybrid physical interactions inherent in\nthe load-towing task. At the core of this system is a novel multi-agent\nreinforcement learning (MARL)-based planner, designed for decentralized\ncoordination. The MARL-based planner is trained using a centralized training\nwith decentralized execution (CTDE) framework, enabling each robot to make\ndecisions autonomously using only local (ego) observations. To accelerate\nlearning and ensure effective collaboration across varying team sizes, we\nintroduce a tailored training curriculum for MARL. Experimental results\nhighlight the flexibility and scalability of the framework, demonstrating\nsuccessful deployment with one to four robots in real-world scenarios and up to\ntwelve robots in simulation. The decentralized planner maintains consistent\ninference times, regardless of the team size. Additionally, the proposed system\ndemonstrates robustness to environment perturbations and adaptability to\nvarying load weights. This work represents a step forward in achieving flexible\nand efficient multi-legged robotic collaboration in complex and real-world\nenvironments."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-142",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12966",
    "b_title":[
      "Optimal Denoising in Score-Based Generative Models: The Role of Data\n  Regularity"
    ],
    "b_abstract":[
      "Score-based generative models achieve state-of-the-art sampling performance\nby denoising a distribution perturbed by Gaussian noise. In this paper, we\nfocus on a single deterministic denoising step, and compare the optimal\ndenoiser for the quadratic loss, we name ''full-denoising'', to the alternative\n''half-denoising'' introduced by Hyv{\\\"a}rinen (2024). We show that looking at\nthe performances in term of distance between distribution tells a more nuanced\nstory, with different assumptions on the data leading to very different\nconclusions. We prove that half-denoising is better than full-denoising for\nregular enough densities, while full-denoising is better for singular densities\nsuch as mixtures of Dirac measures or densities supported on a low-dimensional\nsubspace. In the latter case, we prove that full-denoising can alleviate the\ncurse of dimensionality under a linear manifold hypothesis."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15161",
    "c_title":[
      "Iron-Arsenide monolayer as an anode materials for Lithium-ion batteries:\n  A first-principles study"
    ],
    "c_abstract":[
      "This theoretical investigation delves into the structural, electronic, and\nelectrochemical properties of two hexagonal iron-arsenide monolayers, 1T-FeAs\nand 1H-FeAs, focusing on their potential as anode materials for Lithium-ion\nbatteries. Previous studies have highlighted the ferromagnetic nature of\n1T-FeAs at room temperature.Our calculations reveal that both phases exhibit\nmetallic behaviour with spin-polarized electronic band structures.\nElectrochemical studies show that the 1T-FeAs monolayer has better ionic\nconductivity for Li ions than the 1H-FeAs phase, attributed to a lower\nactivation barrier of 0.38 eV. This characteristic suggests a faster\ncharge\/discharge rate. Both FeAs phases exhibit comparable theoretical\ncapacities 374 mAh\/g, outperforming commercial graphite anodes. The average\nopen-circuit voltage for maximum Li atom adsorption is 0.61 V for 1H-FeAs and\n0.44 V for 1T-FeAs. The volume expansion over the maximum adsorption of Li\natoms on both phases is also remarkably less than the commercially used anode\nmaterial such as graphite. Further, the adsorption of Li atoms onto 1H-FeAs\ninduces a remarkable transition from ferromagnetism to anti-ferromagnetism,\nwith minimal impact on the electronic band structure. In contrast, the original\nstate of 1T-FeAs remains unaffected by Li adsorption. To summarize, the\npotential of both 1T-FeAs and 1H-FeAs monolayers as promising anode materials\nfor Lithium-ion batteries, offering valuable insights into their\nelectrochemical performance and phase transition behaviour upon Li adsorption."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-143",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12683",
    "b_title":[
      "AC nuclear Stark effect in H-atom via super-intense laser-atom\n  interaction"
    ],
    "b_abstract":[
      "We investigate the nuclear Stark effect induced in hydrogen-like atomic\nnuclei under super-intense laser fields. Since laser wavelengths are generally\nlarger than nuclear dimensions, direct laser-nucleus interaction is unfeasible.\nInstead, this effect is induced indirectly through electron oscillations in the\nlaser field, which produce a periodic electric field that shifts the nuclear\nenergy levels. Using perturbation theory, we derive an expression for the\nenergy shift and dynamic polarizability of the nucleus as a function of laser\nparameters. Our findings reveal that the Nuclear Stark effect can be controlled\nby adjusting the laser frequency and intensity, potentially enabling\napplications in nuclear and quantum optical systems."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18621",
    "c_title":[
      "Controllability for a One-Dimensional Wave Equation in a Non-cylindrical\n  Domain"
    ],
    "c_abstract":[
      "This paper deals with the controllability for a one-dimensional wave equation\nwith mixed boundary conditions in a non-cylindrical domain. This equation\nmodels small vibrations of a string where an endpoint is fixed and the other is\nmoving. As usual, we consider one main control (the leader) and an additional\nsecondary control (the follower). We use Stackelberg-Nash strategies."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-144",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04889",
    "b_title":[
      "Exceptional Topology on Nonorientable Manifolds"
    ],
    "b_abstract":[
      "We classify gapped and gapless phases of non-Hermitian band structures on\ntwo-dimensional nonorientable parameter spaces. Such spaces arise in a wide\nrange of physical systems in the presence of non-symmorphic parameter space\nsymmetries. For gapped phases, we find that nonorientable spaces provide a\nnatural setting for exploring fundamental structural problems in braid group\ntheory, such as torsion and conjugacy. Gapless phases, which host exceptional\npoints (EPs), explicitly violate the fermion doubling theorem, even in two-band\nmodels. We demonstrate that EPs traversing the nonorientable parameter space\nexhibit non-Abelian charge inversion. These braided phases and their\ntransitions leave distinct signatures in the form of bulk Fermi arc\ndegeneracies, offering a concrete route toward experimental realization and\nverification."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "math-ph",
        "math.MP",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17255",
    "c_title":[
      "MDN: Mamba-Driven Dualstream Network For Medical Hyperspectral Image\n  Segmentation"
    ],
    "c_abstract":[
      "Medical Hyperspectral Imaging (MHSI) offers potential for computational\npathology and precision medicine. However, existing CNN and Transformer\nstruggle to balance segmentation accuracy and speed due to high\nspatial-spectral dimensionality. In this study, we leverage Mamba's global\ncontext modeling to propose a dual-stream architecture for joint\nspatial-spectral feature extraction. To address the limitation of Mamba's\nunidirectional aggregation, we introduce a recurrent spectral sequence\nrepresentation to capture low-redundancy global spectral features. Experiments\non a public Multi-Dimensional Choledoch dataset and a private Cervical Cancer\ndataset show that our method outperforms state-of-the-art approaches in\nsegmentation accuracy while minimizing resource usage and achieving the fastest\ninference speed. Our code will be available at\nhttps:\/\/github.com\/DeepMed-Lab-ECNU\/MDN."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-145",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04071",
    "b_title":[
      "The vertexing challenge at FCC-ee"
    ],
    "b_abstract":[
      "Following in the footsteps of the LHC, the Future Circular Collider (FCC)\nplans to be the next multi-generational collider project. In the first stage,\nFCC-ee will collide intense beams of electrons and positrons at centre of mass\nenergies between 88 and 365 GeV, making it an electroweak, flavour, Higgs and\ntop factory. The unprecedented statistical precision requires FCC-ee\nexperiments to limit their systematic uncertainties to the very minimum.\n  The precise reconstruction of the interaction vertices is central to most\nmeasurements at FCC-ee, such as rare flavour physics processes and the\nmeasurement of Higgs and Z decays to bottom and charm quarks and taus. This\ncontribution will discuss the requirements of FCC-ee vertex detectors, from the\nnecessary impact parameter resolution via the challenging collision environment\nat the Z pole to the tight requirement on the material budget, which should be\nkept below 0.3% of a radiation length per detection layer. Next, the proposed\nvertex detector designs for FCC-ee are shortly presented, and an outlook is\ngiven on novel detector designs and features.\n  The requirements for the vertexing performance translate into requirements\nfor the sensors used for the vertex detector. As discussed in this\ncontribution, they need to feature a spatial resolution of about 3 $\\mu$m and\nprovide timing information of O($\\mu$s-ns) while keeping power consumption\nminimal to allow for air-cooling of the detector - minimising the detector\nmaterial budget.\n  The only type of sensor capable of aiming to fulfil such requirements are\nCMOS Monolithic Active Pixel Sensors (MAPS), which combine signal generation,\namplification and readout into a single silicon die. Therefore, the rest of\nthis contribution will present an overview of existing and planned MAPS\ntechnologies and prototypes aiming to fulfil the stringent FCC-ee vertex\ndetector requirements."
    ],
    "b_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16448",
    "c_title":[
      "Advances in Continuous Variable Measurement-Device-Independent Quantum\n  Key Distribution"
    ],
    "c_abstract":[
      "Continuous variable quantum key distribution (CV-QKD), utilizes continuous\nvariables encoding such as the quadra-ture components of the quantized\nelectromagnetic field and coherent detection decoding, offering good\ncompatibility with the existing telecommunications technology and components.\nContinuous variable measurement-device-independent QKD (CV-MDI-QKD) can\neliminate all the security threats arising from the receiver effectively, the\ncrucial security loophole of CV-QKD implementations. Recently, CV-MDI-QKD has\nattracted extensive attentions and witnessed rapid progress. Here, we review\nthe achievements that have been made in the field of CV-MDI-QKD, including the\nbasic principle, advancements in theoretical protocols and experimental\ndemonstrations. Finally, we discuss the challenges faced in practical\napplications and future research directions."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-146",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12378",
    "b_title":[
      "Identification and estimation of structural vector autoregressive models\n  via LU decomposition"
    ],
    "b_abstract":[
      "Structural vector autoregressive (SVAR) models are widely used to analyze the\nsimultaneous relationships between multiple time-dependent data. Various\nstatistical inference methods have been studied to overcome the identification\nproblems of SVAR models. However, most of these methods impose strong\nassumptions for innovation processes such as the uncorrelation of components.\nIn this study, we relax the assumptions for innovation processes and propose an\nidentification method for SVAR models under the zero-restrictions on the\ncoefficient matrices, which correspond to sufficient conditions for LU\ndecomposition of the coefficient matrices of the reduced form of the SVAR\nmodels. Moreover, we establish asymptotically normal estimators for the\ncoefficient matrices and impulse responses, which enable us to construct test\nstatistics for the simultaneous relationships of time-dependent data. The\nfinite-sample performance of the proposed method is elucidated by numerical\nsimulations. We also present an example of an empirical study that analyzes the\nimpact of policy rates on unemployment and prices."
    ],
    "b_categories":[
      [
        "econ.EM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.01312",
    "c_title":[
      "CleanPose: Category-Level Object Pose Estimation via Causal Learning and\n  Knowledge Distillation"
    ],
    "c_abstract":[
      "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be released."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-147",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06374",
    "b_title":[
      "AFRIDOC-MT: Document-level MT Corpus for African Languages"
    ],
    "b_abstract":[
      "This paper introduces AFRIDOC-MT, a document-level multi-parallel translation\ndataset covering English and five African languages: Amharic, Hausa, Swahili,\nYor\\`ub\\'a, and Zulu. The dataset comprises 334 health and 271 information\ntechnology news documents, all human-translated from English to these\nlanguages. We conduct document-level translation benchmark experiments by\nevaluating neural machine translation (NMT) models and large language models\n(LLMs) for translations between English and these languages, at both the\nsentence and pseudo-document levels. These outputs are realigned to form\ncomplete documents for evaluation. Our results indicate that NLLB-200 achieved\nthe best average performance among the standard NMT models, while GPT-4o\noutperformed general-purpose LLMs. Fine-tuning selected models led to\nsubstantial performance gains, but models trained on sentences struggled to\ngeneralize effectively to longer documents. Furthermore, our analysis reveals\nthat some LLMs exhibit issues such as under-generation, repetition of words or\nphrases, and off-target translations, especially for African languages."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07934",
    "c_title":[
      "Monotonicity and convergence of two-relaxation-times lattice Boltzmann\n  schemes for a non-linear conservation law"
    ],
    "c_abstract":[
      "We address the convergence analysis of lattice Boltzmann methods for scalar\nnon-linear conservation laws, focusing on two-relaxation-times (TRT) schemes.\nUnlike Finite Difference\/Finite Volume methods, lattice Boltzmann schemes offer\nexceptional computational efficiency and parallelization capabilities. However,\ntheir monotonicity and $L^{\\infty}$-stability remain underexplored. Extending\nexisting results on simpler BGK schemes, we derive conditions ensuring that TRT\nschemes are monotone and stable by leveraging their unique relaxation\nstructure. Our analysis culminates in proving convergence of the numerical\nsolution to the weak entropy solution of the conservation law. Compared to BGK\nschemes, TRT schemes achieve reduced numerical diffusion while retaining\nprovable convergence. Numerical experiments validate and illustrate the\ntheoretical findings."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-148",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08019",
    "b_title":[
      "An AI-driven framework for rapid and localized optimizations of urban\n  open spaces"
    ],
    "b_abstract":[
      "As urbanization accelerates, open spaces are increasingly recognized for\ntheir role in enhancing sustainability and well-being, yet they remain\nunderexplored compared to built spaces. This study introduces an AI-driven\nframework that integrates machine learning models (MLMs) and explainable AI\ntechniques to optimize Sky View Factor (SVF) and visibility, key spatial\nmetrics influencing thermal comfort and perceived safety in urban spaces.\nUnlike global optimization methods, which are computationally intensive and\nimpractical for localized adjustments, this framework supports incremental\ndesign improvements with lower computational costs and greater flexibility. The\nframework employs SHapley Adaptive Explanations (SHAP) to analyze feature\nimportance and Counterfactual Explanations (CFXs) to propose minimal design\nchanges. Simulations tested five MLMs, identifying XGBoost as the most\naccurate, with building width, park area, and heights of surrounding buildings\nas critical for SVF, and distances from southern buildings as key for\nvisibility. Compared to Genetic Algorithms, which required approximately 15\/30\nminutes across 3\/4 generations to converge, the tested CFX approach achieved\noptimized results in 1 minute with a 5% RMSE error, demonstrating significantly\nfaster performance and suitability for scalable retrofitting strategies. This\ninterpretable and computationally efficient framework advances urban\nperformance optimization, providing data-driven insights and practical\nretrofitting solutions for enhancing usability and environmental quality across\ndiverse urban contexts."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05103",
    "c_title":[
      "Investigating Primordial Black Hole Accretion through Cosmic Optical\n  Depth"
    ],
    "c_abstract":[
      "Primordial black holes (PBH) accretion in the late Universe can lead to\nsignificant mass growth. A larger mass further accelerates the accretion\nradiation output for PBHs with initial masses greater than one solar mass,\npotentially leading to a stringent energy-dumping constraint derived from\nobservations of the cosmic microwave background. The energy injected via PBH\naccretion is capable of ionizing and heating the intergalactic medium (IGM),\nultimately affecting the optical depth of cosmic reionization and the 21-cm\nsignal. This work investigates primordial black hole mass growth using the\nBondi-Hoyle accretion model and accounts for additional ionization and heating\ninduced by PBHs. We derive stringent PBH abundance limits using an upper limit\non optical depth set by Planck 2018 CMB measurements. We find that accretion\ngrowth significantly strengthens late-time observational constraints for\nprimordial black holes with initial masses ranging from several solar masses up\nto $10^4$ solar masses. The PBH fraction of the Universe's unobserved mass\ncontent can be constrained to $f_\\mathrm{PBH, ini}\\sim 10^{-2}$ to $10^{-7}$ in\nthis mass range, and when not accounting for mass evolution our constraints can\nbe weakened by up to one order of magnitude. In addition, we show that PBH mass\ngrowth will lead to an observable impact on the predicted hydrogen 21-cm\nbrightness temperature."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-149",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03434",
    "b_title":[
      "RASD: Retrieval-Augmented Speculative Decoding"
    ],
    "b_abstract":[
      "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18688",
    "c_title":[
      "Quantum Phase Transitions between Symmetry-Enriched Fracton Phases"
    ],
    "c_abstract":[
      "Phases with topological order exhibit further complexity in the presence of\nglobal symmetries: States with the same topological order are distinguished by\nhow their anyonic excitations transform under these symmetries, leading to a\nclassification in terms of symmetry-enriched topological phases. In this work,\nwe develop a generic scheme to study an analogous situation for\nthree-dimensional fracton phases by means of isometric tensor network states\n(isoTNS) with finite bond dimension, which allow us to tune between\nwavefunctions of different symmetry fractionalization. We focus on the X-Cube\nmodel, a paradigmatic fracton model hosting two types of excitations: lineons,\nwhich are mobile in a single direction only, and fractons that are completely\nimmobile as individual particles. By deforming the local tensors that describe\nthe ground state of the fixed point model, we find a family of exact\nwavefunctions for which the symmetry fractionalization under an anti-unitary\nsymmetry on both types of excitations is directly visible. These wavefunctions\nhave non-vanishing correlation lengths and are non-stabilizer states. At the\ncritical points between the phases, power-law correlations are supported in\ncertain spatial directions. Furthermore, based on the isoTNS description of the\nwavefunction, we determine a linear-depth quantum circuit to sequentially\nrealize these states on a quantum processor, including a holographic scheme for\nwhich a pair of two-dimensional qubit arrays suffices to encode the\nthree-dimensional state using measurements. Our approach provides a\nconstruction to enrich phases with exotic topological or fracton order based on\nthe language of tensor networks and offers a tractable route to implement and\ncharacterize fracton order with quantum processors."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-150",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14381",
    "b_title":[
      "dtaianomaly: A Python library for time series anomaly detection"
    ],
    "b_abstract":[
      "dtaianomaly is an open-source Python library for time series anomaly\ndetection, designed to bridge the gap between academic research and real-world\napplications. Our goal is to (1) accelerate the development of novel\nstate-of-the-art anomaly detection techniques through simple extensibility; (2)\noffer functionality for large-scale experimental validation; and thereby (3)\nbring cutting-edge research to business and industry through a standardized\nAPI, similar to scikit-learn to lower the entry barrier for both new and\nexperienced users. Besides these key features, dtaianomaly offers (1) a broad\nrange of built-in anomaly detectors, (2) support for time series preprocessing,\n(3) tools for visual analysis, (4) confidence prediction of anomaly scores, (5)\nruntime and memory profiling, (6) comprehensive documentation, and (7)\ncross-platform unit testing.\n  The source code of dtaianomaly, documentation, code examples and installation\nguides are publicly available at https:\/\/github.com\/ML-KULeuven\/dtaianomaly."
    ],
    "b_categories":[
      [
        "cs.DB",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09942",
    "c_title":[
      "Hardy-Hilbert type inequalities on homogeneous groups-An introduction\n  and generalization to the kernel case"
    ],
    "c_abstract":[
      "There is a lot of information available concerning Hardy-Hilbert type\ninequalities in one or more dimensions. In this paper we introduce the\ndevelopment of such inequalities on homogeneous groups. Moreover, we point out\na unification of several of the Hardy-Hilbert type inequalities in the\nclassical case to a general kernel case. Finally, we generalize these results\nto the homogeneous group case."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-151",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13320",
    "b_title":[
      "Toward Ethical AI: A Qualitative Analysis of Stakeholder Perspectives"
    ],
    "b_abstract":[
      "As Artificial Intelligence (AI) systems become increasingly integrated into\nvarious aspects of daily life, concerns about privacy and ethical\naccountability are gaining prominence. This study explores stakeholder\nperspectives on privacy in AI systems, focusing on educators, parents, and AI\nprofessionals. Using qualitative analysis of survey responses from 227\nparticipants, the research identifies key privacy risks, including data\nbreaches, ethical misuse, and excessive data collection, alongside perceived\nbenefits such as personalized services, enhanced efficiency, and educational\nadvancements. Stakeholders emphasized the need for transparency,\nprivacy-by-design, user empowerment, and ethical oversight to address privacy\nconcerns effectively. The findings provide actionable insights into balancing\nthe benefits of AI with robust privacy protections, catering to the diverse\nneeds of stakeholders. Recommendations include implementing selective data use,\nfostering transparency, promoting user autonomy, and integrating ethical\nprinciples into AI development. This study contributes to the ongoing discourse\non ethical AI, offering guidance for designing privacy-centric systems that\nalign with societal values and build trust among users. By addressing privacy\nchallenges, this research underscores the importance of developing AI\ntechnologies that are not only innovative but also ethically sound and\nresponsive to the concerns of all stakeholders."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14266",
    "c_title":[
      "Divisibility Relations Between Ring Homomorphisms and Surjective Group\n  Homomorphisms in Finite Cyclic Structures"
    ],
    "c_abstract":[
      "In this article, we delve into the intricate relationship between the number\nof ring homomorphisms and surjective group homomorphisms between two finite\ncyclic structures, specifically $\\mathbb{Z}_m$ and $\\mathbb{Z}_n$. We\ndemonstrate that the number of ring homomorphisms from $\\mathbb{Z}_m$ to\n$\\mathbb{Z}_n$ is a divisor of the number of surjective group homomorphisms\nfrom $\\mathbb{Z}_m$ to $\\mathbb{Z}_n$, provided that $n$ is not of the form $2\n\\cdot \\alpha$, where each prime factor $p$ of $\\alpha$ satisfies $p \\equiv 3\n\\pmod{4}$."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-152",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05023",
    "b_title":[
      "Euclid: Detecting Solar System objects in Euclid images and classifying\n  them using Kohonen self-organising maps"
    ],
    "b_abstract":[
      "The ESA Euclid mission will survey more than 14,000 deg$^2$ of the sky in\nvisible and near-infrared wavelengths, mapping the extra-galactic sky to\nconstrain our cosmological model of the Universe. Although the survey focusses\non regions further than 15 deg from the ecliptic, it should allow for the\ndetection of more than about $10^5$ Solar System objects (SSOs). After\nsimulating the expected signal from SSOs in Euclid images acquired with the\nvisible camera (VIS), we describe an automated pipeline developed to detect\nmoving objects with an apparent velocity in the range of 0.1-10 arcsec\/h,\ntypically corresponding to sources in the outer Solar System (from Centaurs to\nKuiper-belt objects). In particular, the proposed detection scheme is based on\nSourcextractor software and on applying a new algorithm capable of associating\nmoving objects amongst different catalogues. After applying a suite of filters\nto improve the detection quality, we study the expected purity and completeness\nof the SSO detections. We also show how a Kohonen self-organising neural\nnetwork can be successfully trained (in an unsupervised fashion) to classify\nstars, galaxies, and SSOs. By implementing an early-stopping method in the\ntraining scheme, we show that the network can be used in a predictive way,\nallowing one to assign the probability of each detected object being a member\nof each considered class."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01400",
    "c_title":[
      "Hyperspectral image segmentation with a machine learning model trained\n  using quantum annealer"
    ],
    "c_abstract":[
      "Training of machine learning models consumes large amounts of energy. Since\nthe energy consumption becomes a major problem in the development and\nimplementation of artificial intelligence systems there exists a need to\ninvestigate the ways to reduce use of the resources by these systems. In this\nwork we study how application of quantum annealers could lead to reduction of\nenergy cost in training models aiming at pixel-level segmentation of\nhyperspectral images. Following the results of QBM4EO team, we propose a\nclassical machine learning model, partially trained using quantum annealer, for\nhyperspectral image segmentation. We show that the model trained using quantum\nannealer is better or at least comparable with models trained using alternative\nalgorithms, according to the preselected, common metrics. While direct energy\nuse comparison does not make sense at the current stage of quantum computing\ntechnology development, we believe that our work proves that quantum annealing\nshould be considered as a tool for training at least some machine learning\nmodels."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-153",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09700",
    "b_title":[
      "The bright, dusty aftermath of giant eruptions & H-rich supernovae. Late\n  interaction of supernova shocks & dusty circumstellar shells"
    ],
    "b_abstract":[
      "The late-stage evolution of massive stars is marked by intense instability as\nthey approach core-collapse. During these phases, giant stellar eruptions lead\nto exceptionally high mass-loss rates, forming significant amounts of dust.\nHowever, the survival of these dust grains is challenged by the powerful shock\nwaves generated when the progenitor explodes as a supernova (SN). We explore\nthe impact of hydrogen-rich SN explosions from 45, 50, and 60 M$_\\odot$\nprogenitors on dust formed after these eruptions, focusing on interactions with\ncircumstellar shells occurring from a few years to centuries after the event.\nUsing 3D hydrodynamical simulations, we track the evolution of dust particles\nin a scenario that includes the progenitor's stellar wind, a giant eruption,\nand the subsequent SN explosion, following the mass budgets predicted by\nstellar evolution models. For a standard SN ejecta mass of 10 M$_\\odot$ and\nkinetic energy of $10^{51}$ erg, only 25% of the dust mass survives 250 years\npost-explosion in a spherical circumstellar medium (CSM), while merely 2%\nremains a century after the explosion in a bipolar CSM. If the SN follows the\neruption within a dozen years, 75% of the dust survives for a standard\nexplosion, dropping to 20% for more massive ejecta (15-20 M$_\\odot$) with\nkinetic energy of $5 \\times 10^{51}$ erg. The geometry of the CSM and the early\ntransition of the SN remnant into a radiative phase significantly influence\ndust survival. As the shock wave weakens and efficiently converts kinetic\nenergy into thermal radiation (up to half of the injected kinetic energy) the\nlikelihood of dust survival increases, affecting not only pre-existing dust in\nthe CSM but also SN-condensed dust and ambient interstellar dust. Contrary to\nexpectations, a larger fraction of the dust mass can survive if the SN occurs\nonly a few years after the eruption."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01865",
    "c_title":[
      "Equivariant algebraic models for relative self-equivalences and block\n  diffeomorphisms"
    ],
    "c_abstract":[
      "We construct rational models for classifying spaces of self-equivalences of\nbundles over simply connected finite CW-complexes relative to a given simply\nconnected subcomplex. Via work of Berglund-Madsen and Krannich this specializes\nto rational models for classifying spaces of block diffeomorphism groups of\nsimply connected smooth manifolds of dimension at least 6 with simply connected\nboundary. The main application is a formula for the rational cohomology of\nthese classifying spaces in terms of the cohomology of arithmetic groups and dg\nLie algebras. We furthermore prove that our models are compatible with gluing\nconstructions, and deduce that the model for block diffeomorphisms is\ncompatible with boundary connected sums of manifolds whose boundary is a\nsphere. As in preceding work of Berglund-Zeman on spaces of self-homotopy\nequivalences, a key idea is to study equivariant algebraic models for nilpotent\ncoverings of the classifying spaces."
    ],
    "c_categories":[
      [
        "math.AT",
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-154",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10708",
    "b_title":[
      "Exploration of Hepatitis B Virus Infection Dynamics through\n  Virology-Informed Neural Network: A Novel Artificial Intelligence Approach"
    ],
    "b_abstract":[
      "In this work, we introduce Virology-Informed Neural Networks (VINNs), a\npowerful tool for capturing the intricate dynamics of viral infection when data\nof some compartments of the model are not available. VINNs, an extension of the\nwidely known Physics-Informed Neural Networks (PINNs), offer an alternative\napproach to traditional numerical methods for solving system of differential\nequations. We apply this VINN technique on a recently proposed hepatitis B\nvirus (HBV) infection dynamics model to predict the transmission of the\ninfection within the liver more accurately. This model consists of four\ncompartments, namely uninfected and infected hepatocytes, rcDNA-containing\ncapsids, and free viruses, along with the consideration of capsid recycling.\nLeveraging the power of VINNs, we study the impacts of variations in parameter\nrange, experimental noise, data variability, network architecture, and learning\nrate in this work. In order to demonstrate the robustness and effectiveness of\nVINNs, we employ this approach on the data collected from nine HBV-infceted\nchimpanzees, and it is observed that VINNs can effectively estimate the model\nparameters. VINNs reliably capture the dynamics of infection spread and\naccurately predict their future progression using real-world data. Furthermore,\nVINNs efficiently identify the most influential parameters in HBV dynamics\nbased solely on experimental data from the capsid component. It is also\nexpected that this framework can be extended beyond viral dynamics, providing a\npowerful tool for uncovering hidden patterns and complex interactions across\nvarious scientific and engineering domains."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02029",
    "c_title":[
      "Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large\n  Vision-Language Models"
    ],
    "c_abstract":[
      "With the integration of an additional modality, large vision-language models\n(LVLMs) exhibit greater vulnerability to safety risks (e.g., jailbreaking)\ncompared to their language-only predecessors. Although recent studies have\ndevoted considerable effort to the post-hoc alignment of LVLMs, the inner\nsafety mechanisms remain largely unexplored. In this paper, we discover that\ninternal activations of LVLMs during the first token generation can effectively\nidentify malicious prompts across different attacks. This inherent safety\nperception is governed by sparse attention heads, which we term ``safety\nheads.\" Further analysis reveals that these heads act as specialized shields\nagainst malicious prompts; ablating them leads to higher attack success rates,\nwhile the model's utility remains unaffected. By locating these safety heads\nand concatenating their activations, we construct a straightforward but\npowerful malicious prompt detector that integrates seamlessly into the\ngeneration process with minimal extra inference overhead. Despite its simple\nstructure of a logistic regression model, the detector surprisingly exhibits\nstrong zero-shot generalization capabilities. Experiments across various\nprompt-based attacks confirm the effectiveness of leveraging safety heads to\nprotect LVLMs. Code is available at \\url{https:\/\/github.com\/Ziwei-Zheng\/SAHs}."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-155",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14989",
    "b_title":[
      "Morphology and kinematics of the gas in M51: How interaction with\n  NGC5195 has moulded the structure of its arms"
    ],
    "b_abstract":[
      "The Whirlpool Galaxy is a well studied grand design galaxy with two major\nspiral arms, and a large satellite NGC 5195. The arms both show long uniform\nsections with perturbations ('kinks' or sharp turns) in specific regions.\nComparing the two arms shows a small radial offset between the main kinked\nregions. We analysed the morphology and also the velocity field in the disk of\nM51 using kinematic maps based on H$\\alpha$ and CO line emission. These sample\ncomplementary radial ranges, with the CO map covering the central zone and the\nH$\\alpha$ map extending to cover the outer zone. We looked for indicators of\ndensity wave resonance, zones where radial flows of gas in the disk plane\nreverse their sign. These were present in both velocity maps; their\ntwo-dimensional localization placed them along or closely parallel to the\nspiral arms, at a set of well defined galactocentric radii, and notably more\nconcentrated along the southern, stronger arm. The results can be well\ninterpreted quantitatively, using a numerical model of the interaction of M51\nand NGC5195 in which the satellite has made two relatively recent passes\nthrough the disk plane of M51. During the first pass the pair of dominant\nspiral arms was stimulated, and during the second pass the strong kinks in both\narms were formed at about the same time. The second interaction is particularly\nwell characterised, because the timescale corresponding to the production of\nthe kinks and the recovery of the original pitch angle is identical for the two\narms."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20568",
    "c_title":[
      "A Tutorial on Multi-time Scale Optimization Models and Algorithms"
    ],
    "c_abstract":[
      "Systems across different industries consist of interrelated processes and\ndecisions in different time scales including long-time decisions and short-term\ndecisions. To optimize such systems, the most effective approach is to\nformulate and solve multi-time scale optimization models that integrate various\ndecision layers. In this tutorial, we provide an overview of multi-time scale\noptimization models and review the algorithms used to solve them. We also\ndiscuss the metric Value of the Multi-scale Model (VMM) introduced to quantify\nthe benefits of using multi-time scale optimization models as opposed to\nsequentially solving optimization models from high-level to low-level. Finally,\nwe present an illustrative example of a multi-time scale capacity expansion\nplanning model and showcase how it can be solved using some of the algorithms\n(https:\/\/github.com\/li-group\/MultiScaleOpt-Tutorial.git). This tutorial serves\nas both an introductory guide for beginners with no prior experience and a\nhigh-level overview of current algorithms for solving multi-time scale\noptimization models, catering to experts in process systems engineering."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-156",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10171",
    "b_title":[
      "Area estimates for capillary cmc hypersurfaces with nonpositive Yamabe\n  invariant"
    ],
    "b_abstract":[
      "We prove area estimates for stable capillary $cmc$ (minimal) hypersurfaces\n$\\Sigma$ with nonpositive Yamabe invariant that are properly immersed in a\nRiemannian $n$-dimensional manifold $M$ with scalar curvature $R^M$ and mean\ncurvature of the boundary $H^{\\partial M}$ bounded from below. We also prove a\nlocal rigidity result in the case $\\Sigma$ is embedded and\n$\\mathcal{J}$-energy-minimizing. In this case, we show that $M$ locally splits\nalong $\\Sigma$ and is isometric to $(-\\varepsilon,\\varepsilon)\\times \\Sigma,\ndt^2 + e^{-2Ht}g)$, where $g$ is Einstein, or Ricci flat, $H\\geq 0$ and\n$\\partial\\Sigma$ is totally geodesic."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16986",
    "c_title":[
      "Generative quantum combinatorial optimization by means of a novel\n  conditional generative quantum eigensolver"
    ],
    "c_abstract":[
      "Quantum computing is entering a transformative phase with the emergence of\nlogical quantum processors, which hold the potential to tackle complex problems\nbeyond classical capabilities. While significant progress has been made,\napplying quantum algorithms to real-world problems remains challenging. Hybrid\nquantum-classical techniques have been explored to bridge this gap, but they\noften face limitations in expressiveness, trainability, or scalability. In this\nwork, we introduce conditional Generative Quantum Eigensolver\n(conditional-GQE), a context-aware quantum circuit generator powered by an\nencoder-decoder Transformer. Focusing on combinatorial optimization, we train\nour generator for solving problems with up to 10 qubits, exhibiting nearly\nperfect performance on new problems. By leveraging the high expressiveness and\nflexibility of classical generative models, along with an efficient\npreference-based training scheme, conditional-GQE provides a generalizable and\nscalable framework for quantum circuit generation. Our approach advances hybrid\nquantum-classical computing and contributes to accelerate the transition toward\nfault-tolerant quantum computing."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-157",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20332",
    "b_title":[
      "Emergent Symbolic Mechanisms Support Abstract Reasoning in Large\n  Language Models"
    ],
    "b_abstract":[
      "Many recent studies have found evidence for emergent reasoning capabilities\nin large language models, but debate persists concerning the robustness of\nthese capabilities, and the extent to which they depend on structured reasoning\nmechanisms. To shed light on these issues, we perform a comprehensive study of\nthe internal mechanisms that support abstract rule induction in an open-source\nlanguage model (Llama3-70B). We identify an emergent symbolic architecture that\nimplements abstract reasoning via a series of three computations. In early\nlayers, symbol abstraction heads convert input tokens to abstract variables\nbased on the relations between those tokens. In intermediate layers, symbolic\ninduction heads perform sequence induction over these abstract variables.\nFinally, in later layers, retrieval heads predict the next token by retrieving\nthe value associated with the predicted abstract variable. These results point\ntoward a resolution of the longstanding debate between symbolic and neural\nnetwork approaches, suggesting that emergent reasoning in neural networks\ndepends on the emergence of symbolic mechanisms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15543",
    "c_title":[
      "The First Particles"
    ],
    "c_abstract":[
      "After cosmic inflation, the universe is cold and almost empty. Thus, the\ninflation field should decay to the particles for BBN through the so-called\nreheating process. Later, the matter-antimatter asymmetry and dark matter are\nproduced. In this chapter, the ``first particle\" production between the\ninflation phase and BBN phase is introduced. We focus on the reheating,\nelectroweak baryogenesis, and leptogenesis."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-158",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16637",
    "b_title":[
      "On the Li\\'enard's type equation: an icon of the Nonlinear Analysis"
    ],
    "b_abstract":[
      "In this note, we review the latest qualitative results, referring to the\nLi\\'enard Equation, in the framework of non-conformable, generalized and\nfractional differential operators."
    ],
    "b_categories":[
      [
        "math.GM"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15903",
    "c_title":[
      "Computation Offloading Strategies in Integrated Terrestrial and\n  Non-Terrestrial Networks"
    ],
    "c_abstract":[
      "The rapid growth of computation-intensive applications like augmented\nreality, autonomous driving, remote healthcare, and smart cities has exposed\nthe limitations of traditional terrestrial networks, particularly in terms of\ninadequate coverage, limited capacity, and high latency in remote areas. This\nchapter explores how integrated terrestrial and non-terrestrial networks\n(IT-NTNs) can address these challenges and enable efficient computation\noffloading. We examine mobile edge computing (MEC) and its evolution toward\nmultiple-access edge computing, highlighting the critical role computation\noffloading plays for resource-constrained devices. We then discuss the\narchitecture of IT-NTNs, focusing on how terrestrial base stations, unmanned\naerial vehicles (UAVs), high-altitude platforms (HAPs), and LEO satellites work\ntogether to deliver ubiquitous connectivity. Furthermore, we analyze various\ncomputation offloading strategies, including edge, cloud, and hybrid\noffloading, outlining their strengths and weaknesses. Key enabling technologies\nsuch as NOMA, mmWave\/THz communication, and reconfigurable intelligent surfaces\n(RIS) are also explored as essential components of existing algorithms for\nresource allocation, task offloading decisions, and mobility management.\nFinally, we conclude by highlighting the transformative impact of computation\noffloading in IT-NTNs across diverse application areas and discuss key\nchallenges and future research directions, emphasizing the potential of these\nnetworks to revolutionize communication and computation paradigms."
    ],
    "c_categories":[
      [
        "cs.DC",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-159",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18848",
    "b_title":[
      "Reinforcement Learning of Flexible Policies for Symbolic Instructions\n  with Adjustable Mapping Specifications"
    ],
    "b_abstract":[
      "Symbolic task representation is a powerful tool for encoding human\ninstructions and domain knowledge. Such instructions guide robots to accomplish\ndiverse objectives and meet constraints through reinforcement learning (RL).\nMost existing methods are based on fixed mappings from environmental states to\nsymbols. However, in inspection tasks, where equipment conditions must be\nevaluated from multiple perspectives to avoid errors of oversight, robots must\nfulfill the same symbol from different states. To help robots respond to\nflexible symbol mapping, we propose representing symbols and their mapping\nspecifications separately within an RL policy. This approach imposes on RL\npolicy to learn combinations of symbolic instructions and mapping\nspecifications, requiring an efficient learning framework. To cope with this\nissue, we introduce an approach for learning flexible policies called Symbolic\nInstructions with Adjustable Mapping Specifications (SIAMS). This paper\nrepresents symbolic instructions using linear temporal logic (LTL), a formal\nlanguage that can be easily integrated into RL. Our method addresses the\ndiversified completion patterns of instructions by (1) a specification-aware\nstate modulation, which embeds differences in mapping specifications in state\nfeatures, and (2) a symbol-number-based task curriculum, which gradually\nprovides tasks according to the learning's progress. Evaluations in 3D\nsimulations with discrete and continuous action spaces demonstrate that our\nmethod outperforms context-aware multitask RL comparisons."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16434",
    "c_title":[
      "Optically Detected Magnetic Resonance Imaging and Sensing Within\n  Functionalized Additively Manufactured Microporous Structures"
    ],
    "c_abstract":[
      "Quantum sensing with nitrogen-vacancy centers in diamond has emerged as a\npowerful tool for measuring diverse physical parameters, yet the versatility of\nthese measurement approaches is often limited by the achievable layout and\ndimensionality of bulk-crystal platforms. Here, we demonstrate a versatile\napproach to creating designer quantum sensors by surface-functionalizing\nmultiphoton lithography microstructures with NV-containing nanodiamonds. We\nshowcase this capability by fabricating a 150 $\\mu$m x 150 $\\mu$m x 150 $\\mu$m\ntriply periodic minimal surface gyroid structure with millions of attached\nnanodiamonds. We demonstrate a means to volumetrically image these structures\nusing a refractive index matching confocal imaging technique, and extract ODMR\nspectra from 1.86 $\\mu$m x 1.86 $\\mu$m areas of highly concentrated\nnanodiamonds across a cross section of the gyroid. Furthermore, the high\ndensity of sensing elements enables ensemble temperature measurements with\nsensitivity of 0.548 {\\deg}K\/$\\sqrt{Hz}$ at 5 mW excitation power. This\napproach to creating quantum-enabled microarchitectures opens new possibilities\nfor multimodal sensing in complex three-dimensional environments."
    ],
    "c_categories":[
      [
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-160",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01891",
    "b_title":[
      "Training and Evaluating with Human Label Variation: An Empirical Study"
    ],
    "b_abstract":[
      "Human label variation (HLV) challenges the standard assumption that a\nlabelled instance has a single ground truth, instead embracing the natural\nvariation in human annotation to train and evaluate models. While various\ntraining methods and metrics for HLV have been proposed, it is still unclear\nwhich methods and metrics perform best in what settings. We propose new\nevaluation metrics for HLV leveraging fuzzy set theory. Since these new\nproposed metrics are differentiable, we then in turn experiment with employing\nthese metrics as training objectives. We conduct an extensive study over 6 HLV\ndatasets testing 14 training methods and 6 evaluation metrics. We find that\ntraining on either disaggregated annotations or soft labels performs best\nacross metrics, outperforming training using the proposed training objectives\nwith differentiable metrics. We also show that our proposed soft metric is more\ninterpretable and correlates best with human preference."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02779",
    "c_title":[
      "Image-charge detection of electrons on helium in an on-chip trapping\n  device"
    ],
    "c_abstract":[
      "Electrons trapped on the surface of superfluid helium have been thought of as\na useful resource for quantum computing. Such electrons show long coherence of\ntheir surface-bound (Rydberg) states combined with their easy electrostatic\nmanipulation. Recent proposals explored the possibility of coupling the spin\nstate of an electron and the state of its quantized motion with a promise of a\nhighly scalable 2D architecture for a quantum computer. However, despite recent\nprogress in the detection of quantized lateral motion of electrons using a\ncircuit-QED setup, the manipulation of a small number of electrons and their\nquantum state detection remains a challenging problem. Here, we report on the\ndetection of the Rydberg transition of electrons on superfluid helium in an\non-chip microchannel device in which electrons are moved and trapped by a set\nof electrostatic gates. A highly sensitive image-charge detection system allows\nus not only to resolve the transition spectra of such electrons, but also to\nperform the device characterization. The demonstrated sensitivity shows the\nfeasibility of detecting the Rydberg transition of a single electron, which can\nopen a new pathway for a non-destructive spin-state readout."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-161",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17217",
    "b_title":[
      "Supersymmetric Grey Galaxies, Dual Dressed Black Holes and the\n  Superconformal Index"
    ],
    "b_abstract":[
      "Motivated by the recent construction of grey galaxy and Dual Dressed Black\nHole solutions in $AdS_5\\times S^5$, we present two conjectures relating to the\nlarge $N$ entropy of supersymmetric states in ${\\cal N}=4$ Yang-Mills theory.\nOur first conjecture asserts the existence of a large number of supersymmetric\nstates which can be thought of as a non interacting mix of supersymmetric black\nholes and supersymmetric `gravitons'. It predicts a microcanonical phase\ndiagram of supersymmetric states with eleven distinct phases, and makes a sharp\nprediction for the supersymmetric entropy (as a function of 5 charges) in each\nof these phases. The microcanonical version of the superconformal index\ninvolves a sum over states - with alternating signs - over a line in 5\nparameter charge space. Our second conjecture asserts that this sum is\ndominated by the point on the line that has the largest supersymmetric entropy.\nThis conjecture predicts a large $N$ formula for the superconformal index as a\nfunction of indicial charges, and predicts a microcanonical indicial phase\ndiagram with nine distinct phases. It predicts agreement between the\nsuperconformal index and black hole entropy in one phase (so over one range of\ncharges), but disagreement in other phases (and so at other values of charges).\nWe compare our predictions against numerically evaluated superconformal index\nat $N\\leq10$, and find qualitative agreement."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12201",
    "c_title":[
      "A theory of $q$-transversals"
    ],
    "c_abstract":[
      "Given an indexed family ${\\cal A} = (A_1, A_2, \\dotsc, A_n)$ of subsets of\nsome given set $S$, a \\emph{transversal} is a set of distinct elements $x_1,\nx_2, \\dotsc, x_n$ with each $x_i \\in A_i$. Transversals have been studied since\n1935 and have many attractive properties, with a deep connection to matroids. A\n$q$-analog is formed by replacing the notion of a set by the notion of a vector\nspace, with a corresponding replacement of other concepts. In this paper we\ndefine a $q$-analog of the theory of transversals, and show that many of the\nmain properties of ordinary transversals are shared by this analog."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-162",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11843",
    "b_title":[
      "Can LLM Agents Maintain a Persona in Discourse?"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are widely used as conversational agents,\nexploiting their capabilities in various sectors such as education, law,\nmedicine, and more. However, LLMs are often subjected to context-shifting\nbehaviour, resulting in a lack of consistent and interpretable\npersonality-aligned interactions. Adherence to psychological traits lacks\ncomprehensive analysis, especially in the case of dyadic (pairwise)\nconversations. We examine this challenge from two viewpoints, initially using\ntwo conversation agents to generate a discourse on a certain topic with an\nassigned personality from the OCEAN framework (Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism) as High\/Low for each trait. This\nis followed by using multiple judge agents to infer the original traits\nassigned to explore prediction consistency, inter-model agreement, and\nalignment with the assigned personality. Our findings indicate that while LLMs\ncan be guided toward personality-driven dialogue, their ability to maintain\npersonality traits varies significantly depending on the combination of models\nand discourse settings. These inconsistencies emphasise the challenges in\nachieving stable and interpretable personality-aligned interactions in LLMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17745",
    "c_title":[
      "Resonant Modes of Electromagnetic Waves Confined in Dielectric Rings:\n  Formulation and Examples"
    ],
    "c_abstract":[
      "Dielectric ring resonators are fundamental components in integrated\nphotonics, enabling various applications. Accurate prediction of their resonant\nmodes and effective refractive indices is crucial for optimal device\nperformance. This paper presents a novel numerical method for analyzing\nelectromagnetic wave propagation in dielectric rings. By exploiting the\ninherent symmetry of the problem and the phase continuity condition for\nresonance, we derive a set of coupled wave equations in cylindrical\ncoordinates. These equations are then discretized using finite-difference\nmethods. Since the unknown azimuthal mode number ($m$) appears on both sides of\nthe equations, we propose a simple two-step numerical algorithm to determine\n$m$. First, we introduce a trial azimuthal mode number that is calculated from\nthe ring radius and wave number to obtain the initial eigen-solutions. In the\nsecond step, we identify the azimuthal mode numbers corresponding to the\ndesired resonant modes and refine the Hamiltonian matrix accordingly. Our\napproach offers an easy-to-implement and accurate alternative to full-wave\nelectromagnetic solvers. We demonstrate the effectiveness of our method through\nseveral numerical examples. The results obtained from our method exhibit very\ngood agreement with those from commercial full-wave solvers, validating its\naccuracy."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-163",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12289",
    "b_title":[
      "Evaluating Step-by-step Reasoning Traces: A Survey"
    ],
    "b_abstract":[
      "Step-by-step reasoning is widely used to enhance the reasoning ability of\nlarge language models (LLMs) in complex problems. Evaluating the quality of\nreasoning traces is crucial for understanding and improving LLM reasoning.\nHowever, the evaluation criteria remain highly unstandardized, leading to\nfragmented efforts in developing metrics and meta-evaluation benchmarks. To\naddress this gap, this survey provides a comprehensive overview of step-by-step\nreasoning evaluation, proposing a taxonomy of evaluation criteria with four\ntop-level categories (groundedness, validity, coherence, and utility). We then\ncategorize metrics based on their implementations, survey which metrics are\nused for assessing each criterion, and explore whether evaluator models can\ntransfer across different criteria. Finally, we identify key directions for\nfuture research."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01740",
    "c_title":[
      "Intrinsic width of the flux tube in 2+1 dimensional Yang-Mills therories"
    ],
    "c_abstract":[
      "We study the shape of the flux tube in lattice Yang-Mills theories and in\nparticular its intrinsic width. In the framework of the Effective String Theory\ndescription of the confining flux tube this intrinsic width has no measurable\neffects on the inter-quark static potential, but it can be precisely detected\nlooking at the profile of the flux tube. We address this problem with a set of\nhigh precision simulations in the (2+1) dimensional SU(2) model. We find two\ndifferent behaviours as a function of the temperature. In the low temperature\nregime ($T \\ll T_c$) we find a good agreement with an expression inspired by\nthe dual superconductive model of confinement. In the high temperature regime\n($T \\lesssim T_c$) our data agree with a model based on the Svetitsky-Yaffe\nmapping. All our data in this regime can be described in terms of only one\nlength scale, the intrinsic width, which turns out to be the same scale\nappearing in the confining inter-quark static potential."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-164",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17547",
    "b_title":[
      "Learning Multi-Level Features with Matryoshka Sparse Autoencoders"
    ],
    "b_abstract":[
      "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nneural networks by extracting the concepts represented in their activations.\nHowever, choosing the size of the SAE dictionary (i.e. number of learned\nconcepts) creates a tension: as dictionary size increases to capture more\nrelevant concepts, sparsity incentivizes features to be split or absorbed into\nmore specific features, leaving high-level features missing or warped. We\nintroduce Matryoshka SAEs, a novel variant that addresses these issues by\nsimultaneously training multiple nested dictionaries of increasing size,\nforcing the smaller dictionaries to independently reconstruct the inputs\nwithout using the larger dictionaries. This organizes features hierarchically -\nthe smaller dictionaries learn general concepts, while the larger dictionaries\nlearn more specific concepts, without incentive to absorb the high-level\nfeatures. We train Matryoshka SAEs on Gemma-2-2B and TinyStories and find\nsuperior performance on sparse probing and targeted concept erasure tasks, more\ndisentangled concept representations, and reduced feature absorption. While\nthere is a minor tradeoff with reconstruction performance, we believe\nMatryoshka SAEs are a superior alternative for practical tasks, as they enable\ntraining arbitrarily large SAEs while retaining interpretable features at\ndifferent levels of abstraction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13359",
    "c_title":[
      "Optimal intrinsic formation using exogenous systems"
    ],
    "c_abstract":[
      "This paper investigates the intrinsic formation problem of a multi-agent\nsystem using an exogenous system. The problem is formulated as an intrinsic\ninfinite time-horizon linear quadratic optimal control problem, namely, no\nformation error information is incorporated in the performance index.\nConvergence to the formation is achieved by utilizing an exogenous system, thus\nexpanding the steady-state formation space of the system. For the forward\nproblem, we provide the existence condition for a nonzero steady state and\ncharacterize the steady-state space. For the inverse problem, we design both\nthe input matrix and the exogenous system so that the desired formation can be\nachieved. Finally, numerical simulations are provided to illustrate the\neffectiveness of the proposed results."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-165",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15959",
    "b_title":[
      "A Knowledge Distillation-Based Approach to Enhance Transparency of\n  Classifier Models"
    ],
    "b_abstract":[
      "With the rapid development of artificial intelligence (AI), especially in the\nmedical field, the need for its explainability has grown. In medical image\nanalysis, a high degree of transparency and model interpretability can help\nclinicians better understand and trust the decision-making process of AI\nmodels. In this study, we propose a Knowledge Distillation (KD)-based approach\nthat aims to enhance the transparency of the AI model in medical image\nanalysis. The initial step is to use traditional CNN to obtain a teacher model\nand then use KD to simplify the CNN architecture, retain most of the features\nof the data set, and reduce the number of network layers. It also uses the\nfeature map of the student model to perform hierarchical analysis to identify\nkey features and decision-making processes. This leads to intuitive visual\nexplanations. We selected three public medical data sets (brain tumor, eye\ndisease, and Alzheimer's disease) to test our method. It shows that even when\nthe number of layers is reduced, our model provides a remarkable result in the\ntest set and reduces the time required for the interpretability analysis."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14424",
    "c_title":[
      "Distribution Matching for Self-Supervised Transfer Learning"
    ],
    "c_abstract":[
      "In this paper, we propose a novel self-supervised transfer learning method\ncalled Distribution Matching (DM), which drives the representation distribution\ntoward a predefined reference distribution while preserving augmentation\ninvariance. The design of DM results in a learned representation space that is\nintuitively structured and offers easily interpretable hyperparameters.\nExperimental results across multiple real-world datasets and evaluation metrics\ndemonstrate that DM performs competitively on target classification tasks\ncompared to existing self-supervised transfer learning methods. Additionally,\nwe provide robust theoretical guarantees for DM, including a population theorem\nand an end-to-end sample theorem. The population theorem bridges the gap\nbetween the self-supervised learning task and target classification accuracy,\nwhile the sample theorem shows that, even with a limited number of samples from\nthe target domain, DM can deliver exceptional classification performance,\nprovided the unlabeled sample size is sufficiently large."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-166",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11951",
    "b_title":[
      "Qubit-Based Framework for Quantum Machine Learning: Bridging Classical\n  Data and Quantum Algorithms"
    ],
    "b_abstract":[
      "This paper dives into the exciting and rapidly growing field of quantum\ncomputing, explaining its core ideas, current progress, and how it could\nrevolutionize the way we solve complex problems. It starts by breaking down the\nbasics, like qubits, quantum circuits, and how principles like superposition\nand entanglement make quantum computers fundamentally different-and far more\npowerful for certain tasks-than the classical computers we use today. We also\nexplore how quantum computing deals with complex problems and why it is\nuniquely suited for challenges classical systems struggle to handle. A big part\nof this paper focuses on Quantum Machine Learning (QML), where the strengths of\nquantum computing meet the world of artificial intelligence. By processing\nmassive datasets and optimizing intricate algorithms, quantum systems offer new\npossibilities for machine learning. We highlight different approaches to\ncombining quantum and classical computing, showing how they can work together\nto produce faster and more accurate results. Additionally, we explore the tools\nand platforms available-like TensorFlow Quantum, Qiskit and PennyLane-that are\nhelping researchers and developers bring these theories to life. Of course,\nquantum computing has its hurdles. Challenges like scaling up hardware,\ncorrecting errors, and keeping qubits stable are significant roadblocks. Yet,\nwith rapid advancements in cloud-based platforms and innovative technologies,\nthe potential of quantum computing feels closer than ever. This paper aims to\noffer readers a clear and comprehensive introduction to quantum computing, its\nrole in machine learning, and the immense possibilities it holds for the future\nof technology."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01234",
    "c_title":[
      "Impact of QCD sum rules coupling constants on neutron stars structure"
    ],
    "c_abstract":[
      "We present a detailed investigation on the structure of neutron stars,\nincorporating the presence of hyperons within a relativistic model under the\nmean-field approximation. Employing coupling constants derived from QCD sum\nrules, we explore the particle fraction in beta equilibrium and establish the\nmass-radius relationship for neutron stars with hyperonic matter. Additionally,\nwe compute the stellar Love number ($\\mathcal{K}_{2}$) and the tidal\ndeformability parameter ($\\varLambda$), providing valuable insights into the\ndynamical properties of these celestial objects. Through comparison with\ntheoretical predictions and observational data, our results exhibit good\nagreement, affirming the validity of our approach. These findings contribute\nsignificantly to refining the understanding of neutron star physics,\nparticularly in environments containing hyperons, and offer essential\nconstraints on the equation of state governing such extreme astrophysical\nconditions."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-167",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19693",
    "b_title":[
      "Accurate and Scalable Graph Neural Networks via Message Invariance"
    ],
    "b_abstract":[
      "Message passing-based graph neural networks (GNNs) have achieved great\nsuccess in many real-world applications. For a sampled mini-batch of target\nnodes, the message passing process is divided into two parts: message passing\nbetween nodes within the batch (MP-IB) and message passing from nodes outside\nthe batch to those within it (MP-OB). However, MP-OB recursively relies on\nhigher-order out-of-batch neighbors, leading to an exponentially growing\ncomputational cost with respect to the number of layers. Due to the neighbor\nexplosion, the whole message passing stores most nodes and edges on the GPU\nsuch that many GNNs are infeasible to large-scale graphs. To address this\nchallenge, we propose an accurate and fast mini-batch approach for large graph\ntransductive learning, namely topological compensation (TOP), which obtains the\noutputs of the whole message passing solely through MP-IB, without the costly\nMP-OB. The major pillar of TOP is a novel concept of message invariance, which\ndefines message-invariant transformations to convert costly MP-OB into fast\nMP-IB. This ensures that the modified MP-IB has the same output as the whole\nmessage passing. Experiments demonstrate that TOP is significantly faster than\nexisting mini-batch methods by order of magnitude on vast graphs (millions of\nnodes and billions of edges) with limited accuracy degradation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16041",
    "c_title":[
      "Binary Outcome Models with Extreme Covariates: Estimation and Prediction"
    ],
    "c_abstract":[
      "This paper presents a novel semiparametric method to study the effects of\nextreme events on binary outcomes and subsequently forecast future outcomes.\nOur approach, based on Bayes' theorem and regularly varying (RV) functions,\nfacilitates a Pareto approximation in the tail without imposing parametric\nassumptions beyond the tail. We analyze cross-sectional as well as static and\ndynamic panel data models, incorporate additional covariates, and accommodate\nthe unobserved unit-specific tail thickness and RV functions in panel data. We\nestablish consistency and asymptotic normality of our tail estimator, and show\nthat our objective function converges to that of a panel Logit regression on\ntail observations with the log extreme covariate as a regressor, thereby\nsimplifying implementation. The empirical application assesses whether small\nbanks become riskier when local housing prices sharply decline, a crucial\nchannel in the 2007--2008 financial crisis."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-168",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15654",
    "b_title":[
      "Machine-generated text detection prevents language model collapse"
    ],
    "b_abstract":[
      "As Large Language Models (LLMs) become increasingly prevalent, their\ngenerated outputs are proliferating across the web, risking a future where\nmachine-generated content dilutes human-authored text. Since online data is the\nprimary resource for LLM pre-training, subsequent models could be trained on an\nunknown portion of synthetic samples. This will lead to model collapse, a\ndegenerative process whereby LLMs reinforce their own errors, and ultimately\nyield a declining performance. In this study, we investigate the impact of\ndecoding strategy on model collapse, analysing the characteristics of text at\neach model generation, the similarity to human references, and the resulting\nmodel performance. Using the decoding strategies that lead to the most\nsignificant degradation, we evaluate model collapse in more realistic scenarios\nwhere the origin of the data (human or synthetic) is unknown. We train a\nmachine-generated text detector and propose an importance sampling approach to\nalleviate model collapse. Our method is validated on two LLM variants (GPT-2\nand SmolLM2) on the open-ended text generation task. We demonstrate that it can\nnot only prevent model collapse but also improve performance when sufficient\nhuman-authored samples are present."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17712",
    "c_title":[
      "Constructing self-similar subsets within the fractal support of Lacunary\n  Wavelet Series for their multifractal analysis"
    ],
    "c_abstract":[
      "Given a fractal $\\mathcal{I}$ whose Hausdorff dimension matches with the\nupper-box dimension, we propose a new method which consists in selecting inside\n$\\mathcal{I}$ some subsets (called quasi-Cantor sets) of almost same dimension\nand with controled properties of self-similarties at prescribed scales. It\nallows us to estimate below the Hausdorff dimension $\\mathcal{I}$ intersected\nto limsup sets of contracted balls selected according a Bernoulli law, in\ncontexts where classical Mass Transference Principles cannot be applied. We\napply this result to the computation of the increasing multifractal spectrum of\nlacunary wavelet series supported on $\\mathcal{I}$."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.MG",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-169",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16494",
    "b_title":[
      "The impact of artificial intelligence: from cognitive costs to global\n  inequality"
    ],
    "b_abstract":[
      "In this paper, we examine the wide-ranging impact of artificial intelligence\non society, focusing on its potential to both help and harm global equity,\ncognitive abilities, and economic stability. We argue that while artificial\nintelligence offers significant opportunities for progress in areas like\nhealthcare, education, and scientific research, its rapid growth -- mainly\ndriven by private companies -- may worsen global inequalities, increase\ndependence on automated systems for cognitive tasks, and disrupt established\neconomic paradigms. We emphasize the critical need for strong governance and\nethical guidelines to tackle these issues, urging the academic community to\nactively participate in creating policies that ensure the benefits of\nartificial intelligence are shared fairly and its risks are managed\neffectively."
    ],
    "b_categories":[
      [
        "cs.CY",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05909",
    "c_title":[
      "2-extendability of (4,5,6)-fullerenes"
    ],
    "c_abstract":[
      "A (4,5,6)-fullerene is a plane cubic graph whose faces are only\nquadrilaterals, pentagons and hexagons, which includes all (4,6)- and\n(5,6)-fullerenes. A connected graph $G$ with at least $2k+2$ vertices is\n$k$-extendable if $G$ has perfect matchings and any matching of size $k$ is\ncontained in a perfect matching of $G$. We know that each (4,5,6)-fullerene\ngraph is 1-extendable and at most 2-extendable. It is natural to wonder which\n(4,5,6)-fullerene graphs are 2-extendable. In this paper, we completely solve\nthis problem (see Theorem 3.3): All non-2-extendable (4,5,6)-fullerenes consist\nof four sporadic (4,5,6)-fullerenes ($F_{12},F_{14},F_{18}$ and $F_{20}$) and\nfive classes of (4,5,6)-fullerenes. As a surprising consequence, we find that\nall (4,5,6)-fullerenes with the anti-Kekul\\'{e} number 3 are non-2-extendable.\nFurther, there also always exists a non-2-extendable (4,5,6)-fullerene with\narbitrarily even $n\\geqslant10$ vertices."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-170",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03123",
    "b_title":[
      "Disentanglement in Difference: Directly Learning Semantically\n  Disentangled Representations by Maximizing Inter-Factor Differences"
    ],
    "b_abstract":[
      "In this study, Disentanglement in Difference(DiD) is proposed to address the\ninherent inconsistency between the statistical independence of latent variables\nand the goal of semantic disentanglement in disentanglement representation\nlearning. Conventional disentanglement methods achieve disentanglement\nrepresentation by improving statistical independence among latent variables.\nHowever, the statistical independence of latent variables does not necessarily\nimply that they are semantically unrelated, thus, improving statistical\nindependence does not always enhance disentanglement performance. To address\nthe above issue, DiD is proposed to directly learn semantic differences rather\nthan the statistical independence of latent variables. In the DiD, a Difference\nEncoder is designed to measure the semantic differences; a contrastive loss\nfunction is established to facilitate inter-dimensional comparison. Both of\nthem allow the model to directly differentiate and disentangle distinct\nsemantic factors, thereby resolving the inconsistency between statistical\nindependence and semantic disentanglement. Experimental results on the dSprites\nand 3DShapes datasets demonstrate that the proposed DiD outperforms existing\nmainstream methods across various disentanglement metrics."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16855",
    "c_title":[
      "On weak sequential completeness of spaces where weakly compact sets are\n  super weakly compact"
    ],
    "c_abstract":[
      "We show that every Banach space in which weakly compact sets are super weakly\ncompact in automatically weakly sequentially complete answering a question by\nSilber (2024). In the proof we show how to build a weakly compact set which is\nnot super weakly compact from an arbitrary nontrivial weakly Cauchy sequence\nusing the notion of a summing subsequence of Rosenthal or Singer."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-171",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10337",
    "b_title":[
      "Bifurcation of global energy minimizers for a diffusion-aggregation\n  model on sphere"
    ],
    "b_abstract":[
      "We consider a free energy functional defined on probability densities on the\nunit sphere $\\mathbb{S}^d$, and investigate its global minimizers. The energy\nconsists of two components: an entropy and a nonlocal interaction energy, which\nfavour spreading and aggregation behaviour, respectively. We find a threshold\nvalue for the size of the attractive interactions, and establish the global\nenergy minimizers in each case. The bifurcation at this threshold value is\ninvestigated. We also generalize the results to spaces consisting of an\narbitrary number of spheres (e.g., the flat torus $\\mathbb{S}^1 \\times\n\\mathbb{S}^1$)."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12733",
    "c_title":[
      "A quantitative comparison of high-order asymptotic-preserving and\n  asymptotically-accurate IMEX methods for the Euler equations with non-ideal\n  gases"
    ],
    "c_abstract":[
      "We present a quantitative comparison between two different Implicit-Explicit\nRunge-Kutta (IMEX-RK) approaches for the Euler equations of gas dynamics,\nspecifically tailored for the low Mach limit. In this regime, a classical\nIMEX-RK approach involves an implicit coupling between the momentum and energy\nbalance so as to avoid the acoustic CFL restriction, while the density can be\ntreated in a fully explicit fashion. This approach leads to a mildly nonlinear\nequation for the pressure, which can be solved according to a fixed point\nprocedure. An alternative strategy consists of employing a semi-implicit\ntemporal integrator based on IMEX-RK methods (SI-IMEX-RK). The stiff dependence\nis carefully analyzed, so as to avoid the solution of a nonlinear equation for\nthe pressure also for equations of state (EOS) of non-ideal gases. The spatial\ndiscretization is based on a Discontinuous Galerkin (DG) method, which\nnaturally allows high-order accuracy. The asymptotic-preserving (AP) and the\nasymptotically-accurate (AA) properties of the two approaches are assessed on a\nnumber of classical benchmarks for ideal gases and on their extension to\nnon-ideal gases."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-172",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02958",
    "b_title":[
      "Position: Editing Large Language Models Poses Serious Safety Risks"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) contain large amounts of facts about the world.\nThese facts can become outdated over time, which has led to the development of\nknowledge editing methods (KEs) that can change specific facts in LLMs with\nlimited side effects. This position paper argues that editing LLMs poses\nserious safety risks that have been largely overlooked. First, we note the fact\nthat KEs are widely available, computationally inexpensive, highly performant,\nand stealthy makes them an attractive tool for malicious actors. Second, we\ndiscuss malicious use cases of KEs, showing how KEs can be easily adapted for a\nvariety of malicious purposes. Third, we highlight vulnerabilities in the AI\necosystem that allow unrestricted uploading and downloading of updated models\nwithout verification. Fourth, we argue that a lack of social and institutional\nawareness exacerbates this risk, and discuss the implications for different\nstakeholders. We call on the community to (i) research tamper-resistant models\nand countermeasures against malicious model editing, and (ii) actively engage\nin securing the AI ecosystem."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07053",
    "c_title":[
      "A New Concept of optimal control for epidemic spreading by Vaccination\n  Technique for Assessing social optimum employing Pontryagins Maximum\n  Principle"
    ],
    "c_abstract":[
      "This research introduces a new approach utilizing optimal control theory\n(OCT) to assess the Social Optimum (SO) of a vaccination game, navigating the\nintricate considerations of cost, availability, and distribution policies. By\nintegrating an SIRS\/V epidemic model with a behavior model, the study analyzes\nindividual vaccination strategies. A unique optimal control framework, centered\non vaccination costs, is proposed, diverging significantly from previous\nmethods. Our findings confirm the effectiveness and feasibility of this\napproach in managing vaccination strategies. Moreover, we examine the\nunderlying social dilemma of the vaccination game, investigating key\nparameters. By calculating the Nash equilibrium (NE) through the behavior model\nand determining the SO using our approach, we measure the Social Efficiency\nDeficit (SED), quantifying the overall cost gap between the NE and SO. Results\nindicate that an increased waning immunity rate exacerbates the social dilemma,\nalthough higher vaccination costs partially mitigate it. This research provides\nvaluable insights into optimizing vaccination strategies amidst complex\nsocietal dynamics."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-173",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17498",
    "b_title":[
      "Improving Value-based Process Verifier via Structural Prior Injection"
    ],
    "b_abstract":[
      "In the Large Language Model(LLM) reasoning scenario, people often estimate\nstate value via Monte Carlo sampling. Though Monte Carlo estimation is an\nelegant method with less inductive bias, noise and errors are inevitably\nintroduced due to the limited sampling. To handle the problem, we inject the\nstructural prior into the value representation and transfer the scalar value\ninto the expectation of a pre-defined categorical distribution, representing\nthe noise and errors from a distribution perspective. Specifically, by treating\nthe result of Monte Carlo sampling as a single sample from the prior\nground-truth Binomial distribution, we quantify the sampling error as the\nmismatch between posterior estimated distribution and ground-truth\ndistribution, which is thus optimized via distribution selection optimization.\nWe test the performance of value-based process verifiers on Best-of-N task and\nBeam search task. Compared with the scalar value representation, we show that\nreasonable structural prior injection induced by different objective functions\nor optimization methods can improve the performance of value-based process\nverifiers for about 1$\\sim$2 points at little-to-no cost. We also show that\nunder different structural prior, the verifiers' performances vary greatly\ndespite having the same optimal solution, indicating the importance of\nreasonable structural prior injection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15694",
    "c_title":[
      "A Statistical Learning Approach to Mediterranean Cyclones"
    ],
    "c_abstract":[
      "Mediterranean cyclones are extreme meteorological events of which much less\nis known compared to their tropical, oceanic counterparts. The raising interest\nin such phenomena is due to their impact on a region increasingly more affected\nby climate change, but a precise characterization remains a non trivial task.\nIn this work we showcase how a Bayesian algorithm (Latent Dirichlet Allocation)\ncan classify Mediterranean cyclones relying on wind velocity data, leading to a\ndrastic dimensional reduction that allows the use of supervised statistical\nlearning techniques for detecting and tracking new cyclones."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-174",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08401",
    "b_title":[
      "Mean resolvent analysis of periodic flows"
    ],
    "b_abstract":[
      "The mean resolvent operator predicts, in the frequency domain, the mean\nlinear response to forcing, and, as such, it provides the optimal LTI\napproximation of the input-output dynamics of flows in the statistically steady\nregime (Leclercq & Sipp 2023). In this paper, we aim at providing numerical\nframeworks to extract optimal forcings and responses of the mean resolvent,\nalso known as mean resolvent modes. For periodic flows, we rewrite the mean\nresolvent operator in terms of a harmonic resolvent operator (Wereley & Hall\n1990; Padovan & Rowley 2022) to obtain reference mean resolvent modes.\nSuccessively, we propose a projection algorithm approximating those modes\nwithin a subspace of mean-flow resolvent modes. The projected problem is\ndirectly solved in the frequency domain, but we also discuss a time-stepper\nversion that can bypass the explicit construction of the operator without\nrecurring to direct-adjoint looping. We evaluate the algorithms on an\nincompressible axisymmetric laminar jet periodically forced at the inlet. For a\nweakly unsteady case, the mean-flow resolvent correctly approximates the main\nreceptivity peak of the mean resolvent, but completely fails to capture a\nsecondary receptivity peak. For a strongly unsteady case, even the main\nreceptivity peak of the mean resolvent is incorrectly captured by the mean-flow\nresolvent. Although the present algorithms are currently restricted to periodic\nflows, input projection may be a key ingredient to extend mean resolvent\nanalysis to more complex statistically steady flows."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14402",
    "c_title":[
      "Diffusion-based Facial Aesthetics Enhancement with 3D Structure Guidance"
    ],
    "c_abstract":[
      "Facial Aesthetics Enhancement (FAE) aims to improve facial attractiveness by\nadjusting the structure and appearance of a facial image while preserving its\nidentity as much as possible. Most existing methods adopted deep feature-based\nor score-based guidance for generation models to conduct FAE. Although these\nmethods achieved promising results, they potentially produced excessively\nbeautified results with lower identity consistency or insufficiently improved\nfacial attractiveness. To enhance facial aesthetics with less loss of identity,\nwe propose the Nearest Neighbor Structure Guidance based on Diffusion\n(NNSG-Diffusion), a diffusion-based FAE method that beautifies a 2D facial\nimage with 3D structure guidance. Specifically, we propose to extract FAE\nguidance from a nearest neighbor reference face. To allow for less change of\nfacial structures in the FAE process, a 3D face model is recovered by referring\nto both the matched 2D reference face and the 2D input face, so that the depth\nand contour guidance can be extracted from the 3D face model. Then the depth\nand contour clues can provide effective guidance to Stable Diffusion with\nControlNet for FAE. Extensive experiments demonstrate that our method is\nsuperior to previous relevant methods in enhancing facial aesthetics while\npreserving facial identity."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-175",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20594",
    "b_title":[
      "Kinematical Modeling of the Resolved Stellar Outskirts of M32:\n  Constraints on Tidal Stripping Scenarios"
    ],
    "b_abstract":[
      "As the only compact elliptical close enough to resolve into individual stars,\nthe satellite dwarf galaxy M32 provides a unique opportunity for exploring the\norigins of such rare galaxies. In this work, we combined archival and novel\nKeck\/DEIMOS spectroscopy from a southern extension of the Spectroscopic and\nPhotometric Landscape of Andromeda's Stellar Halo (SPLASH) survey with optical\nHST imaging from the Panchromatic Hubble Andromeda Southern Treasury (PHAST)\nsurvey. The resulting sample of 2525 giant stars is unprecedented both in size\nand spatial coverage (0.9-15.5 arcmin, or out to $\\sim$23$r_{\\rm eff}$ and\n$\\sim$30$r_{\\rm eff}$ along M32's major and minor axes) for probing the\nresolved stellar outskirts of M32. Given the structurally complex region near\nM32 on the sky, we modeled M32's line-of-sight kinematics simultaneously\nalongside M31's rotating stellar disk and potential outliers corresponding to\nM31's kinematically hot stellar halo and\/or tidal substructure. Inside the\nradius corresponding to the observed twisting of isophotal contours in M32's\nsurface brightness profile ($R_{\\rm iso} \\sim$ 5$r_{\\rm eff}$ $\\sim$ 150'' or\n0.56 kpc), M32 exhibits a line-of-sight velocity distribution characteristic of\nordered rotation, transitioning to a distribution with heavier outliers beyond\nthis radius. Within $R_{\\rm iso}$, the rotational direction is aligned with\nM32's major-axis rotation, but shifts to become roughly aligned with M32's\nminor axis beyond $R_{\\rm iso}$. We interpret these kinematical signatures in\nthe stellar outskirts of M32 as evidence of tidal distortion from interactions\nwith M31 and discuss their implications for M32 formation pathways."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09764",
    "c_title":[
      "Localised frames for tensor product spaces"
    ],
    "c_abstract":[
      "In this paper, we investigate whether the tensor product of two frames, each\nindividually localised with respect to a spectral matrix algebra, is also\nlocalised with respect to a suitably chosen tensor product algebra. We provide\na partial answer by constructing an involutive Banach algebra of rank-four\ntensors that is built from two solid spectral matrix algebras. We show that\nthis algebra is inverse-closed, given that the original algebras satisfy a\nspecific property related to operator-valued versions of these algebras. This\ncondition is satisfied by all commonly used solid spectral matrix algebras. We\nthen prove that the tensor product of two self-localised frames remains\nself-localised with respect to our newly constructed tensor algebra.\nAdditionally, we discuss generalisations to localised frames of Hilbert-Schmidt\noperators, which may not necessarily consist of rank-one operators."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-176",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08106",
    "b_title":[
      "Photodetachment of negative hydrogen ion beam"
    ],
    "b_abstract":[
      "The method of H- photoionization is interesting for laser assisted charge\nexchange injection. In this paper, the model and computation of photoionization\nof negative hydrogen ion by using strong lasers is considered. The development\nof this work is motivated by using pure lasers for photodetachment of electron\nfrom negative hydrogen ion when it is not convenient or not possible to use\nstripping magnet. Herein we develop a method of calculation of high efficiency\nphotoionization using time dependent wave equation with application of powerful\nlasers. We compare this precise method of calculation with simplified method of\ncalculation through linear model of cross section interaction. Another\nmechanism of photodetachment through excitation of the Feshbach resonance is\nalso considered."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04819",
    "c_title":[
      "The Wideband Analysis of the Impact of I\/Q Imbalance on THz\n  Communication"
    ],
    "c_abstract":[
      "The terahertz (THz) band is a promising solution to the increasing data\ntraffic demands of future wireless networks. However, developing transceivers\nfor THz communication is a complex and toilsome task due to the difficulty in\ndesigning devices that operate at this frequency and the impact of hardware\nimpairments on performance. This paper investigates the impact of radio\nfrequency (RF) impairment, in-phase\/quadrature imbalance (IQI). To this end, we\nexpress an IQI model for the THzspecific array-of-subarrays (AoSA) architecture\nconsidering the unique features of THz communication; vast bandwidth, severe\npower drawdown, and pencil-like beams. We further model the impact of IQI in\nthe power limited regime in order to investigate the power and ultra-wideband\ntrade-off. To achieve this, we express the spectral efficiency in terms of\nwideband slope and bit energy to noise ratio which are the two important\ninformation theoretic metrics that reveals the performance of the ultrawideband\nsystems as in THz communication. Our results show that THz systems with IQI\nhave a strict limit in achievable rate although they provide immense spectrum.\nWe also demonstrate with our simulation results that compared to low\nfrequencies, IQI is a more serious concern in THz links."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-177",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08085",
    "b_title":[
      "Interactive Holographic Visualization for 3D Facial Avatar"
    ],
    "b_abstract":[
      "Traditional methods for visualizing dynamic human expressions, particularly\nin medical training, often rely on flat-screen displays or static mannequins,\nwhich have proven inefficient for realistic simulation. In response, we propose\na platform that leverages a 3D interactive facial avatar capable of displaying\nnon-verbal feedback, including pain signals. This avatar is projected onto a\nstereoscopic, view-dependent 3D display, offering a more immersive and\nrealistic simulated patient experience for pain assessment practice. However,\nthere is no existing solution that dynamically predicts and projects\ninteractive 3D facial avatars in real-time. To overcome this, we emphasize the\nneed for a 3D display projection system that can project the facial avatar\nholographically, allowing users to interact with the avatar from any viewpoint.\nBy incorporating 3D Gaussian Splatting (3DGS) and real-time view-dependent\ncalibration, we significantly improve the training environment for accurate\npain recognition and assessment."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00839",
    "c_title":[
      "A large-scale ring galaxy at z = 2.2 revealed by JWST\/NIRCam: kinematic\n  observations and analytical modelling"
    ],
    "c_abstract":[
      "A unique galaxy at z = 2.2, zC406690, has a striking clumpy large-scale ring\nstructure that persists from rest UV to near-infrared, yet has an ordered\nrotation and lies on the star-formation main sequence. We combine new\nJWST\/NIRCam and ALMA band 4 observations, together with previous VLT\/SINFONI\nintegral field spectroscopy and HST imaging to re-examine its nature. The\nhigh-resolution H$\\alpha$ kinematics are best fitted if the mass is distributed\nwithin a ring with total mass $M_{\\rm{ring}} = 2 \\times 10^{10} M_\\odot$ and\nradius $R_{ring}$ = 4.6 kpc, together with a central undetected mass component\n(e.g., a \"bulge\") with a dynamical mass of $M_{bulge} = 8 \\times 10^{10}\nM_\\odot$. We also consider a purely flux emitting ring superposed over a faint\nexponential disk, or a highly \"cuspy\" dark matter halo, both disfavored against\na massive ring model. The low-resolution CO(4-3) line and 142GHz continuum\nemission imply a total molecular and dust gas masses of $M_{mol,gas} = 7.1\n\\times 10^{10}M_\\odot$ and $M_{dust} = 3 \\times 10^8 M_\\odot$ over the entire\ngalaxy, giving a dust-to-mass ratio of 0.7%. We estimate that roughly half the\ngas and dust mass lie inside the ring, and that $\\sim 10\\%$ of the total dust\nis in a foreground screen that attenuates the stellar light of the bulge in the\nrest-UV to near-infrared. Sensitive high-resolution ALMA observations will be\nessential to confirm this scenario and study the gas and dust distribution."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-178",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14509",
    "b_title":[
      "MultiSlav: Using Cross-Lingual Knowledge Transfer to Combat the Curse of\n  Multilinguality"
    ],
    "b_abstract":[
      "Does multilingual Neural Machine Translation (NMT) lead to The Curse of the\nMultlinguality or provides the Cross-lingual Knowledge Transfer within a\nlanguage family? In this study, we explore multiple approaches for extending\nthe available data-regime in NMT and we prove cross-lingual benefits even in\n0-shot translation regime for low-resource languages. With this paper, we\nprovide state-of-the-art open-source NMT models for translating between\nselected Slavic languages. We released our models on the HuggingFace Hub\n(https:\/\/hf.co\/collections\/allegro\/multislav-6793d6b6419e5963e759a683) under\nthe CC BY 4.0 license. Slavic language family comprises morphologically rich\nCentral and Eastern European languages. Although counting hundreds of millions\nof native speakers, Slavic Neural Machine Translation is under-studied in our\nopinion. Recently, most NMT research focuses either on: high-resource languages\nlike English, Spanish, and German - in WMT23 General Translation Task 7 out of\n8 task directions are from or to English; massively multilingual models\ncovering multiple language groups; or evaluation techniques."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14712",
    "c_title":[
      "Does Ideological Polarization Lead to Policy Polarization?"
    ],
    "c_abstract":[
      "I analyze an election involving two parties who are both office- and\npolicy-motivated and who are ideologically polarized. One party may possess a\nvalence advantage. The parties compete by proposing policies on a second policy\nissue. The analysis reveals a subtle relationship between ideological\npolarization and policy polarization. If ideologies are highly dispersed, there\nis a U-shaped relationship between ideological polarization and platform\npolarization. In contrast, if ideological dispersion is limited, increasing\nideological polarization generally results in policy moderation. In both cases,\nvalence plays no role in policy polarization. Finally, as in Buisseret and van\nWeelden (2022), adding ideological polarization adds nuance on the effects of\nincreasing valence: both high- and low-valence candidates may adopt more\nextreme positions, depending on the electorate's degree of ideological\npolarization."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-179",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17875",
    "b_title":[
      "5G Direct Position Estimation for Precise Localization in Dense Urban\n  Area"
    ],
    "b_abstract":[
      "In recent years, the fifth-generation (5G) new radio (NR) signals have\nemerged as a promising supplementary resource for urban navigation. However, a\nmajor challenge in utilizing 5G signals lies in their vulnerability to\nnon-line-of-sight (NLoS) propagation effects, which are especially prevalent in\nurban street canyons. This paper applies the direct position estimation (DPE)\nmethod to 5G cellular signals to mitigate the NLoS bias as well as the\nmultipath effects, thereby enabling precise localization in urbanized\nenvironments. The feasibility of applying the DPE method to NR positioning is\nanalyzed, followed by a discussion of the tapped delay line (TDL) channel\npropagation model provided by the 3rd Generation Partnership Project (3GPP).\nThe positioning performance is then evaluated through large-scale system-level\nsimulations. The simulation results demonstrate that 5G DPE achieves\nsatisfactory positioning accuracy in a 10 dB noisy channel, with an overall\nroot mean square error (RMSE) constrained within 6 m. In addition, 5G DPE\noutperforms the observed time difference of arrival (OTDoA) method by 95.24% in\nterms of positioning accuracy in an NLoS-dominated propagation environment."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08784",
    "c_title":[
      "Elastic Response and Instabilities of Anomalous Hall Crystals"
    ],
    "c_abstract":[
      "Anomalous Hall crystals (AHCs) are exotic phases of matter that\nsimultaneously break continuous translation symmetry and exhibit the quantum\nanomalous Hall effect. AHCs have recently been proposed as an explanation for\nthe observation of an integer quantum anomalous Hall phase in a multilayer\ngraphene system. Despite intense theoretical and experimental interest, little\nis known about the mechanical properties of AHCs. We study the elastic\nproperties of AHCs, first by utilizing a continuum model with uniform Berry\ncurvature. In contrast to Wigner crystals, we find that the stiffness of the\nAHC weakens and eventually vanishes as electronic interactions are increased.\nFurthermore, we demonstrate that the triangular lattice AHC arising in an\nexperimentally relevant parameter regime of a realistic model of rhombohedral\npentalayer graphene is unstable, emphasizing the importance of understanding\nthe mechanical properties of AHCs for interpreting experiments."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-180",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13101",
    "b_title":[
      "AI and the Transformation of Accountability and Discretion in Urban\n  Governance"
    ],
    "b_abstract":[
      "The integration of Artificial Intelligence (AI) in urban governance presents\nsignificant opportunities to transform decision-making and enhance\naccountability. The paper highlights AI's potential to reposition human\ndiscretion and reshape specific types of accountability, elevating the\ndecision-making capabilities of both frontline bureaucrats and managers while\nensuring ethical standards and public trust are maintained. While AI can\nenhance bureaucratic flexibility and efficiency, its integration will also\nnecessitate new governance frameworks to mitigate risks associated with uneven\ncapacity distribution, ethical concerns, and public trust. Following the\nliterature review and theoretical discussion, this study introduces a set of\nguiding principles for AI-assisted urban governance, emphasizing equitable AI\ndeployment, adaptive administrative structures, robust data governance,\ntransparent human-AI collaboration, and citizen engagement in oversight\nmechanisms. By critically evaluating AI's dual role in expanding discretion and\nreinforcing accountability, this paper advances a framework for responsible AI\nadoption, ensuring that urban governance remains adaptive, transparent, and\naligned with public values."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02711",
    "c_title":[
      "Branching fraction measurement of the decay $B^+ \\to \\psi(2S) \\phi(1020)\n  K^+$"
    ],
    "c_abstract":[
      "The branching fraction of the decay $B^+\\to \\psi(2S)\\phi(1020)K^+$, relative\nto the topologically similar decay $B^+\\to J\/\\psi \\phi(1020) K^+$, is measured\nusing proton-proton collision data collected by the LHCb experiment at\ncenter-of-mass energies of 7, 8, and 13 TeV, corresponding to an integrated\nluminosity of $9\\,\\mathrm{fb}^{-1}$. The ratio is found to be $0.061 \\pm 0.004\n\\pm 0.009$, where the first uncertainty is statistical and the second\nsystematic. Using the world-average branching fraction for $B^+ \\to J\/\\psi\n\\phi(1020) K^+$, the branching fraction for the decay $B^+\\to \\psi(2S)\n\\phi(1020) K^+$ is found to be $ (3.0 \\pm 0.2 \\pm 0.5 \\pm 0.2) \\times 10^{-6}$,\nwhere the first uncertainty is statistical, the second systematic, and the\nthird is due to the branching fraction of the normalization channel."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-181",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06187",
    "b_title":[
      "MSConv: Multiplicative and Subtractive Convolution for Face Recognition"
    ],
    "b_abstract":[
      "In Neural Networks, there are various methods of feature fusion. Different\nstrategies can significantly affect the effectiveness of feature\nrepresentation, consequently influencing the ability of model to extract\nrepresentative and discriminative features. In the field of face recognition,\ntraditional feature fusion methods include feature concatenation and feature\naddition. Recently, various attention mechanism-based fusion strategies have\nemerged. However, we found that these methods primarily focus on the important\nfeatures in the image, referred to as salient features in this paper, while\nneglecting another equally important set of features for image recognition\ntasks, which we term differential features. This may cause the model to\noverlook critical local differences when dealing with complex facial samples.\nTherefore, in this paper, we propose an efficient convolution module called\nMSConv (Multiplicative and Subtractive Convolution), designed to balance the\nlearning of model about salient and differential features. Specifically, we\nemploy multi-scale mixed convolution to capture both local and broader\ncontextual information from face images, and then utilize Multiplication\nOperation (MO) and Subtraction Operation (SO) to extract salient and\ndifferential features, respectively. Experimental results demonstrate that by\nintegrating both salient and differential features, MSConv outperforms models\nthat only focus on salient features."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07964",
    "c_title":[
      "Derivation of Output Correlation Inferences for Multi-Output (aka\n  Multi-Task) Gaussian Process"
    ],
    "c_abstract":[
      "Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-182",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04112",
    "b_title":[
      "A Class of Non-Contracting Branch Groups with Non-Torsion Rigid Kernels"
    ],
    "b_abstract":[
      "In this work, we provide the first example of an infinite family of branch\ngroups in the class of non-contracting self-similar groups. We show that these\ngroups are very strongly fractal, not regular branch, and of exponential\ngrowth. Further, we prove that these groups do not have the congruence subgroup\nproperty by explicitly calculating the structure of their rigid kernels. This\nclass of groups is also the first example of branch groups with non-torsion\nrigid kernels. As a consequence of these results, we also determine the\nHausdorff dimension of these groups."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11489",
    "c_title":[
      "The nature of gravitational wave events with host environment escape\n  velocities"
    ],
    "c_abstract":[
      "We propose a novel method to probe the parameters and origin channels of\ngravitational wave events using the escape velocities of their host\nenvironments. This method could lead to more convergent posterior distributions\noffering additional insights into the physical properties, formation, and\nevolution of the sources. It also enables testing general relativity and\nimproves source localization, which the latter is instrumental in\nmulti-messenger astronomy. The method provides more accurate parameter\nestimation for events that represent previous mergers in the hierarchical\ntriple merger scenario and is valuable for the search for such mergers with\nthird-generation ground-based detectors. To demonstrate this approach, we take\nsix recently identified events in LIGO-Virgo-KAGRA data, considered as\npotential previous mergers in hierarchical triple mergers, as examples. The use\nof escape velocities results in posterior spin distributions that are\nconcentrated near zero, aligning with the expected birth spins of\nfirst-generation black holes formed from the collapse of stars. The uncertainty\nin the posterior primary mass distribution is significantly reduced comparing\nwith the LIGO-Virgo-KAGRA distributions, especially for events originating from\nglobular clusters. We rule out the possibility that GW190512, GW170729, and\nGW190708 originates from globular clusters as previous mergers in the\nhierarchical triple merger scenario."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "astro-ph.SR",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-183",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01940",
    "b_title":[
      "Spin-period variations in the intermediate polar RX J2133.7+5107"
    ],
    "b_abstract":[
      "We report the results of long-term time series photometry on RX J2133.7+5107\n(also known as 1RXS J213344.1+510725) obtained at several observatories. Using\ndata taken during 17 years, we determined the current value of the spin period\nof $570.811470$ seconds with the formal accuracy of $0.000006$ seconds and a\nspin-up of the white dwarf with a characteristic time of $1.483(1)\\times10^5$\nyears. This is even faster than that reported previously and, if confirmed,\nmakes this object have one of the fastest spin-up timescales of all known\nintermediate polars. We derived an improved value of the superhump period of\nthe system to be $0^d.280130(1)$. Superhump maxima timings are moving on the\nphase curve from season to season, showing non-monotonic changes, without a\nchange in superhump period."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16817",
    "c_title":[
      "Enhancing Non-Intrusive Load Monitoring with Features Extracted by\n  Independent Component Analysis"
    ],
    "c_abstract":[
      "In this paper, a novel neural network architecture is proposed to address the\nchallenges in energy disaggregation algorithms. These challenges include the\nlimited availability of data and the complexity of disaggregating a large\nnumber of appliances operating simultaneously. The proposed model utilizes\nindependent component analysis as the backbone of the neural network and is\nevaluated using the F1-score for varying numbers of appliances working\nconcurrently. Our results demonstrate that the model is less prone to\noverfitting, exhibits low complexity, and effectively decomposes signals with\nmany individual components. Furthermore, we show that the proposed model\noutperforms existing algorithms when applied to real-world data."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-184",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15576",
    "b_title":[
      "Interpreting and Steering LLMs with Mutual Information-based\n  Explanations on Sparse Autoencoders"
    ],
    "b_abstract":[
      "Large language models (LLMs) excel at handling human queries, but they can\noccasionally generate flawed or unexpected responses. Understanding their\ninternal states is crucial for understanding their successes, diagnosing their\nfailures, and refining their capabilities. Although sparse autoencoders (SAEs)\nhave shown promise for interpreting LLM internal representations, limited\nresearch has explored how to better explain SAE features, i.e., understanding\nthe semantic meaning of features learned by SAE. Our theoretical analysis\nreveals that existing explanation methods suffer from the frequency bias issue,\nwhere they emphasize linguistic patterns over semantic concepts, while the\nlatter is more critical to steer LLM behaviors. To address this, we propose\nusing a fixed vocabulary set for feature interpretations and designing a mutual\ninformation-based objective, aiming to better capture the semantic meaning\nbehind these features. We further propose two runtime steering strategies that\nadjust the learned feature activations based on their corresponding\nexplanations. Empirical results show that, compared to baselines, our method\nprovides more discourse-level explanations and effectively steers LLM behaviors\nto defend against jailbreak attacks. These findings highlight the value of\nexplanations for steering LLM behaviors in downstream applications. We will\nrelease our code and data once accepted."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04089",
    "c_title":[
      "Revisiting symbiotic binaries with interferometry. I. The PIONIER\n  archival collection"
    ],
    "c_abstract":[
      "Symbiotic stars serve as exceptional laboratories for investigating mass\ntransfer processes in binary systems. However, the dominant mechanism of mass\ntransfer from the red giant donor to the compact accretor - typically a white\ndwarf or, in rare cases, a neutron star - remains unclear. It is uncertain\nwhether it is driven primarily by the stellar wind, Roche-lobe overflow, or a\ncombination of the two. While radii inferred from rotational velocities or\nspectral types suggest smaller Roche-lobe filling factors, the presence of\nellipsoidal variability, presumably caused by tidally deformed giants in many\nsymbiotic systems, indicates the opposite. Interferometric observations of\nsymbiotic giants, combined with distance measurements provided by the Gaia\nmission, offer a promising avenue to resolve this discrepancy. In this first\npaper of the series, we (re)analyze VLTI\/PIONIER observations of six symbiotic\nstars: AG Peg, FG Ser, ER Del, V1261 Ori, RW Hya, and V399 Pav. With the\nexception of the uncertain case of V399 Pav, we find that the giants in these\nsystems remain well within their canonical Roche lobes, even in V1261 Ori and\nRW Hya, where ellipsoidal variability is observed. All six stars appear to be\nrather luminous and likely located on the asymptotic giant branch, although the\npossibility of some of them being at the tip of the first red giant branch\ncannot be ruled out."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-185",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00700",
    "b_title":[
      "S2CFormer: Revisiting the RD-Latency Trade-off in Transformer-based\n  Learned Image Compression"
    ],
    "b_abstract":[
      "Transformer-based Learned Image Compression (LIC) suffers from a suboptimal\ntrade-off between decoding latency and rate-distortion (R-D) performance.\nMoreover, the critical role of the FeedForward Network (FFN)-based channel\naggregation module has been largely overlooked. Our research reveals that\nefficient channel aggregation-rather than complex and time-consuming spatial\noperations-is the key to achieving competitive LIC models. Based on this\ninsight, we initiate the ``S2CFormer'' paradigm, a general architecture that\nsimplifies spatial operations and enhances channel operations to overcome the\nprevious trade-off. We present two instances of the S2CFormer: S2C-Conv, and\nS2C-Attention. Both models demonstrate state-of-the-art (SOTA) R-D performance\nand significantly faster decoding speed. Furthermore, we introduce S2C-Hybrid,\nan enhanced variant that maximizes the strengths of different S2CFormer\ninstances to achieve a better performance-latency trade-off. This model\noutperforms all the existing methods on the Kodak, Tecnick, and CLIC\nProfessional Validation datasets, setting a new benchmark for efficient and\nhigh-performance LIC. The code is at\n\\href{https:\/\/github.com\/YunuoChen\/S2CFormer}{https:\/\/github.com\/YunuoChen\/S2CFormer}."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17532",
    "c_title":[
      "Wireless Network Topology Inference: A Markov Chains Approach"
    ],
    "c_abstract":[
      "In this work, we address the problem of inferring the topology of a wireless\nnetwork using limited observational data. Specifically, we assume that we can\ndetect when a node is transmitting, but no further information regarding the\ntransmission is available. We propose a novel network estimation procedure\ngrounded in the following abstract problem: estimating the parameters of a\nfinite discrete-time Markov chain by observing, at each time step, which states\nare visited by multiple ``anonymous'' copies of the chain. We develop a\nconsistent estimator that approximates the transition matrix of the chain in\nthe operator norm, with the number of required samples scaling roughly linearly\nwith the size of the state space. Applying this estimation procedure to\nwireless networks, our numerical experiments demonstrate that the proposed\nmethod accurately infers network topology across a wide range of parameters,\nconsistently outperforming transfer entropy, particularly under conditions of\nhigh network congestion."
    ],
    "c_categories":[
      [
        "cs.NI",
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-186",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17295",
    "b_title":[
      "Mitigating Hallucinated Translations in Large Language Models with\n  Hallucination-focused Preference Optimization"
    ],
    "b_abstract":[
      "Machine Translation (MT) is undergoing a paradigm shift, with systems based\non fine-tuned large language models (LLM) becoming increasingly competitive\nwith traditional encoder-decoder models trained specifically for translation\ntasks. However, LLM-based systems are at a higher risk of generating\nhallucinations, which can severely undermine user's trust and safety. Most\nprior research on hallucination mitigation focuses on traditional MT models,\nwith solutions that involve post-hoc mitigation - detecting hallucinated\ntranslations and re-translating them. While effective, this approach introduces\nadditional complexity in deploying extra tools in production and also increases\nlatency. To address these limitations, we propose a method that intrinsically\nlearns to mitigate hallucinations during the model training phase.\nSpecifically, we introduce a data creation framework to generate hallucination\nfocused preference datasets. Fine-tuning LLMs on these preference datasets\nreduces the hallucination rate by an average of 96% across five language pairs,\nwhile preserving overall translation quality. In a zero-shot setting our\napproach reduces hallucinations by 89% on an average across three unseen target\nlanguages."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12496",
    "c_title":[
      "Crystal growth, measurement and modeling of the optical activity of\n  $\\alpha$-GeO$_2$. Comparison with $\\alpha$-SiO$_2$"
    ],
    "c_abstract":[
      "This work aimed first at growing high quality bulk $\\alpha$-GeO$_2$ crystals\nin their Quartz iso-structural form ($\\alpha$-SiO$_2$), using a high\ntemperature flux method. By optimizing the flux composition and the geometry\nand orientation of the seeds, it has been possible to achieve growth yields up\nto 90 % leading for the first time to bulk single crystals up to 3.5 cm$^3$.\nThanks to the optical quality and size of the obtained crystals, the second\nstep of this study was the measurement of the optical activity of\n$\\alpha$-GeO$_2$ between 0.3 and 2 $\\mu$m. This gave access to the value of one\nof the independent components of the gyration tensor (g33) as a function of the\nwavelength. An $\\alpha$-SiO$_2$ slab have been used to validate our\nmethodology. Both crystals show a magnitude of optical activity of\n3.4x10$^{-5}$ rad\/$\\mu$m in the near IR range and great variations where the\nhigher values are 3.4x10$^{-3}$ rad\/$\\mu$m and 1.7x10$^{-3}$ rad\/$\\mu$m at 0.3\n$\\mu$m for $\\alpha$-GeO$_2$ and $\\alpha$-SiO$_2$, respectively. The\nmeasurements are perfectly described by an empirical model that we propose and\nwhich relies on the macroscopic first-order electrical susceptibility and on\nthe pitch of the structural helix compared to the wavelength of light."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-187",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17881",
    "b_title":[
      "RayLoc: Wireless Indoor Localization via Fully Differentiable\n  Ray-tracing"
    ],
    "b_abstract":[
      "Wireless indoor localization has been a pivotal area of research over the\nlast two decades, becoming a cornerstone for numerous sensing applications.\nHowever, conventional wireless localization methods rely on channel state\ninformation to perform blind modelling and estimation of a limited set of\nlocalization parameters. This oversimplification neglects many sensing scene\ndetails, resulting in suboptimal localization accuracy. To address this\nlimitation, this paper presents a novel approach to wireless indoor\nlocalization by reformulating it as an inverse problem of wireless ray-tracing,\ninferring scene parameters that generates the measured CSI. At the core of our\nsolution is a fully differentiable ray-tracing simulator that enables\nbackpropagation to comprehensive parameters of the sensing scene, allowing for\nprecise localization. To establish a robust localization context, RayLoc\nconstructs a high-fidelity sensing scene by refining coarse-grained background\nmodel. Furthermore, RayLoc overcomes the challenges of sparse gradient and\nlocal minima by convolving the signal generation process with a Gaussian\nkernel. Extensive experiments showcase that RayLoc outperforms traditional\nlocalization baselines and is able to generalize to different sensing\nenvironments."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18185",
    "c_title":[
      "MetaWFN: A Platform for Unified Implementation of Many-Electron\n  Wavefunctions"
    ],
    "c_abstract":[
      "\\texttt{MetaWFN} is a C++ template-based architecture designed for flexible\nand rapid development of wavefunction-based quantum chemical methods. It is\nhighly modular, extendable, and efficient. This is achieved by decoupling the\nthree distinct aspects of quantum chemical methods\n  (i.e., nature of Hamiltonian, structure of wavefunction, and strategy of\nparallelization ), thereby allowing for separate treatment of them through\ntheir internal type-trait and tagging systems furnished by C++ metaprogramming.\nOnce the second-quantized Hamiltonians, whether nonrelativistic (spin-free) or\nrelativistic (spin-dependent), are decomposed into topologically equivalent\ndiagrams for a unified evaluation of the basic coupling coefficients between\n(randomly selected) spin-free or spin-dependent configuration state functions\nor Slater determinants incorporating full molecular symmetry (including single\nor double point group and spin or time reversal symmetry), the many-electron\nwavefunctions, whether built up with scalar or spinor orbitals, can be\nassembled with the same templates. As for parallelization, \\texttt{MetaWFN}\nsupports both OpenMP and MPI, with the majority of the latter being translated\nautomatically from its OpenMP counterparts. The whole structure of\n\\texttt{MetaWFN} is reviewed here, with some showcases for illustrating its\nperformance."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-188",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09137",
    "b_title":[
      "Gradient Descent Converges Linearly to Flatter Minima than Gradient Flow\n  in Shallow Linear Networks"
    ],
    "b_abstract":[
      "We study the gradient descent (GD) dynamics of a depth-2 linear neural\nnetwork with a single input and output. We show that GD converges at an\nexplicit linear rate to a global minimum of the training loss, even with a\nlarge stepsize -- about $2\/\\textrm{sharpness}$. It still converges for even\nlarger stepsizes, but may do so very slowly. We also characterize the solution\nto which GD converges, which has lower norm and sharpness than the gradient\nflow solution. Our analysis reveals a trade off between the speed of\nconvergence and the magnitude of implicit regularization. This sheds light on\nthe benefits of training at the ``Edge of Stability'', which induces additional\nregularization by delaying convergence and may have implications for training\nmore complex models."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06921",
    "c_title":[
      "Task Vector Quantization for Memory-Efficient Model Merging"
    ],
    "c_abstract":[
      "Model merging enables efficient multi-task models by combining task-specific\nfine-tuned checkpoints. However, storing multiple task-specific checkpoints\nrequires significant memory, limiting scalability and restricting model merging\nto larger models and diverse tasks. In this paper, we propose quantizing task\nvectors (i.e., the difference between pre-trained and fine-tuned checkpoints)\ninstead of quantizing fine-tuned checkpoints. We observe that task vectors\nexhibit a narrow weight range, enabling low precision quantization (up to 4\nbit) within existing task vector merging frameworks. To further mitigate\nquantization errors within ultra-low bit precision (e.g., 2 bit), we introduce\nResidual Task Vector Quantization, which decomposes the task vector into a base\nvector and offset component. We allocate bits based on quantization\nsensitivity, ensuring precision while minimizing error within a memory budget.\nExperiments on image classification and dense prediction show our method\nmaintains or improves model merging performance while using only 8% of the\nmemory required for full-precision checkpoints."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-189",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13297",
    "b_title":[
      "RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question\n  Answering"
    ],
    "b_abstract":[
      "Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text\nand images, has gained significant attention in information retrieval (IR) and\nnatural language processing (NLP). Traditional ranking methods rely on small\nencoder-based language models, which are incompatible with modern decoder-based\ngenerative large language models (LLMs) that have advanced various NLP tasks.\nTo bridge this gap, we propose RAMQA, a unified framework combining\nlearning-to-rank methods with generative permutation-enhanced ranking\ntechniques. We first train a pointwise multi-modal ranker using LLaVA as the\nbackbone. Then, we apply instruction tuning to train a LLaMA model for\nre-ranking the top-k documents using an innovative autoregressive multi-task\nlearning approach. Our generative ranking model generates re-ranked document\nIDs and specific answers from document candidates in various permutations.\nExperiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant\nimprovements over strong baselines, highlighting the effectiveness of our\napproach. Code and data are available at: https:\/\/github.com\/TonyBY\/RAMQA"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07709",
    "c_title":[
      "Towards a self-consistent hydrodynamical model of the solar tachocline"
    ],
    "c_abstract":[
      "The solar tachocline is an internal boundary layer in the Sun located between\nthe differentially-rotating convection zone and the uniformly-rotating\nradiative interior beneath. Spiegel and Zahn (1992) proposed the first\nhydrodynamical model, which here we call SZ92, arguing that the tachocline is\nessentially in a steady state of thermal-wind balance, angular-momentum\nbalance, and thermal equilibrium. Angular momentum transport in their model is\nassumed to be dominated by strongly anisotropic turbulence, primarily\nhorizontal owing to the strong stable stratification of the radiative interior.\nBy contrast, the heat transport is assumed to be dominated by a predominantly\nvertical diffusive heat flux owing to the thinness of the tachocline. In this\npaper, we demonstrate that these assumptions are not consistent with the new\nmodel of stratified turbulence recently proposed by Chini et al. (2022) and\nShah et al. (2024), which has been numerically validated by Garaud et al.\n(2024). We then propose a simple self-consistent alternative to the SZ92 model,\nnamely, a scenario wherein angular momentum and heat transport are both\ndominated by horizontal turbulent diffusion. The thickness of the tachocline in\nthe new model scales as $\\Omega_\\odot \/ N_m$, where $\\Omega_\\odot$ is the mean\nangular velocity of the Sun, and $N_m$ the buoyancy frequency in the tachocline\nregion. We discuss other properties of the model, and show that it has several\ndesirable features, but does not resolve some of the other well-known problems\nof the SZ92 model."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-190",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15775",
    "b_title":[
      "Fast Calculation of Nonuniform Plane Waves at Arbitrarily Oriented and\n  Charged Planar Interfaces of Isotropic Lossy Media"
    ],
    "b_abstract":[
      "A fast method for calculating the reflected and transmitted waves for a given\nnonuniform plane wave incident on an arbitrarily oriented and charged planar\ninterface between two isotropic and possibly lossy media is proposed based on\nthe decomposition of the complex wave vector and complex wave numbers with\nrespect to the unit normal vector of the interface. According to the complex\nvector analysis, the exact definition of the complex angles of incidence,\nreflection and refraction are presented and applied in the complex forms of\nSnell's law and Fresnel equations to quickly and correctly calculate the\ncomplex wave vectors and the complex electric fields of the reflected and\nrefracted waves at a charged interface where the surface charge and current\ndensities are considered. The calculation procedure and two practical examples\nare also given to demonstrate the validity and powerfulness of the proposed\nmethodology."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02106",
    "c_title":[
      "A new stochastic SIS-type modelling framework for analysing epidemic\n  dynamics in continuous space"
    ],
    "c_abstract":[
      "We propose a new stochastic epidemiological model defined in a continuous\nspace of arbitrary dimension, based on SIS dynamics implemented in a spatial\n$\\Lambda$-Fleming-Viot (SLFV) process. The model can be described by as little\nas three parameters, and is dual to a spatial branching process with\ncompetition linked to genealogies of infected individuals. Therefore, it is a\npossible modelling framework to develop computationally tractable inference\ntools for epidemics in a continuous space using demographic and genetic data.\n  We provide mathematical constructions of the process based on well-posed\nmartingale problems as well as driving space-time Poisson point processes. With\nthese devices and the duality relation in hand, we unveil some of the drivers\nof the transition between extinction and survival of the epidemic. In\nparticular, we show that extinction is in large parts independent of the\ninitial condition, and identify a strong candidate for the reproduction number\n$R_0$ of the epidemic in such a model."
    ],
    "c_categories":[
      [
        "math.PR",
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-191",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08051",
    "b_title":[
      "Screening rho-meson mass in the presence of strong magnetic fields"
    ],
    "b_abstract":[
      "We study the screening mass of the neutral rho-meson in the presence of\nstrong magnetic fields using the Kroll-Lee-Zumino (KLZ) model. The rho-meson\nself-energy is computed at one-loop order within the lowest Landau level (LLL)\napproximation, considering the magnetic field as the dominant energy scale. Due\nto Lorentz symmetry breaking induced by the external field, we decompose the\nself-energy into three independent tensor structures, which give rise to three\ndistinct modes. Additionally, the four-momentum splits into parallel and\nperpendicular components, leading to two types of screening masses: the\nparallel screening mass ( $p_0=0$ and $p_\\perp \\to 0$ ) and the perpendicular\nscreening mass ( $p_0=0$ and $p_\\parallel \\to 0$ ). Our results show that the\nzero and perpendicular modes exhibit a monotonically increasing behavior with\nthe magnetic field strength, whereas the parallel mode remains essentially\nconstant. These findings provide new insights into the behavior of vector\nmesons in strongly magnetized media, with implications for QCD under extreme\nconditions."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01129",
    "c_title":[
      "Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless\n  Networks"
    ],
    "c_abstract":[
      "This report investigates the application of deep reinforcement learning (DRL)\nalgorithms for dynamic resource allocation in wireless communication systems.\nAn environment that includes a base station, multiple antennas, and user\nequipment is created. Using the RLlib library, various DRL algorithms such as\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.\nThese algorithms are compared based on their ability to optimize resource\nallocation, focusing on the impact of different learning rates and scheduling\npolicies. The findings demonstrate that the choice of algorithm and learning\nrate significantly influences system performance, with DRL providing more\nefficient resource allocation compared to traditional methods."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-192",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09522",
    "b_title":[
      "Quantum Synchronizing Words: Resetting and Preparing Qutrit States"
    ],
    "b_abstract":[
      "Synchronizing words in classical automata theory provide a mechanism to reset\nany state of a deterministic automaton to a specific target state via a\ncarefully chosen finite sequence of transition rules. In this work, we extend\nthe concept of synchronizing words to quantum information theory. Specifically,\nwe show that with only two quantum channels, it is possible to bring an\narbitrary qutrit state close to a designated target state. Furthermore, we\ndemonstrate that following this reset, any pure real qutrit state can be\nclosely approximated using the same two channels. These findings establish a\nquantum analogue of synchronizing words, highlighting their potential\napplications in constructing minimal sets of universal quantum gates capable of\nboth resetting and preparing arbitrary states."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2501.04357",
    "c_title":[
      "Generators of top cohomology"
    ],
    "c_abstract":[
      "Let $R$ be a commutative noetherian ring and $f: X \\to \\mathrm{Spec} R$ a\nproper smooth morphism, of relative dimension $n$. From Hartshorne,\n\\emph{Residues and Duality}, Springer, 1966, one knows that the trace map\n$\\mathrm{Tr}_f : \\mathrm{H}^n(X, \\omega_{X\/R}) \\to R$ is an isomorphism when\n$f$ has geometrically connected fibres. We construct an exact sequence that\ngenerates $\\mathrm{Ext}_X^n(\\mathcal{O}_X, \\omega_{X\/R}) = \\mathrm{H}^n(X,\n\\omega_{X\/R})$ as an $R$-module in the following cases: \\begin{enumerate}\n  \\item when $R$ is a DVR and $f$ has a section;\n  \\item when $R=\\mathbb{Z}$ and $X$ is the Grassmannian $G_{2,m}$ for some $m\n\\geq 4$. \\end{enumerate} This partially answers a question raised by Lipman."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-193",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12751",
    "b_title":[
      "R3-Avatar: Record and Retrieve Temporal Codebook for Reconstructing\n  Photorealistic Human Avatars"
    ],
    "b_abstract":[
      "We present R3-Avatar, incorporating a temporal codebook, to overcome the\ninability of human avatars to be both animatable and of high-fidelity rendering\nquality. Existing video-based reconstruction of 3D human avatars either focuses\nsolely on rendering, lacking animation support, or learns a pose-appearance\nmapping for animating, which degrades under limited training poses or complex\nclothing. In this paper, we adopt a \"record-retrieve-reconstruct\" strategy that\nensures high-quality rendering from novel views while mitigating degradation in\nnovel poses. Specifically, disambiguating timestamps record temporal appearance\nvariations in a codebook, ensuring high-fidelity novel-view rendering, while\nnovel poses retrieve corresponding timestamps by matching the most similar\ntraining poses for augmented appearance. Our R3-Avatar outperforms cutting-edge\nvideo-based human avatar reconstruction, particularly in overcoming visual\nquality degradation in extreme scenarios with limited training human poses and\ncomplex clothing."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05627",
    "c_title":[
      "Unidentified Aerial Phenomena. Characterization of Dark UAPs"
    ],
    "c_abstract":[
      "We use high-tech observations of Unidentified Aerial Phenomena (UAP) class\nobjects to evaluate their characteristics. We present data in three cases. (1)\nMulti-side daytime observations of UAPs over Kiev. (2) Night observations of a\ngroup of objects in the vicinity of the Moon. (3) UAP observations in the\ncombat zone in Ukraine. Dark UAPs in the visible wavelength range are observed\nonly during the day. At night they can only be seen in the infrared wavelength\nrange. We note large sizes of UAPs, from three to six kilometers.They exhibit\nlarge velocities, from 2.5 Mach and much larger. They have low albedo, from\nthree percent and below, that is, they actually exhibit features of a\ncompletely black body."
    ],
    "c_categories":[
      [
        "physics.pop-ph",
        "physics.space-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-194",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09765",
    "b_title":[
      "Pooling Liquidity Pools in AMMs"
    ],
    "b_abstract":[
      "Market fragmentation across multiple Automated Market Makers (AMMs) creates\ninefficiencies such as costly arbitrage, unnecessarily high slippage and\ndelayed incorporation of new information into prices. These inefficiencies\nraise trading costs, reduce liquidity provider profits, and degrade overall\nmarket efficiency. To address these issues, we propose a modification of the\nConstant Product Market Maker (CPMM) pricing mechanism, called the Global\nMarket Maker (GMM), which aggregates liquidity information from all AMMs to\nmitigate these inefficiencies. Through theoretical and numerical analyses, we\ndemonstrate that the GMM enhances profits for both AMMs and traders by\neliminating arbitrage opportunities. Additionally, it reduces the profitability\nof sandwich attacks and minimizes impermanent losses."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.08299",
    "c_title":[
      "Distillation-PPO: A Novel Two-Stage Reinforcement Learning Framework for\n  Humanoid Robot Perceptive Locomotion"
    ],
    "c_abstract":[
      "In recent years, humanoid robots have garnered significant attention from\nboth academia and industry due to their high adaptability to environments and\nhuman-like characteristics. With the rapid advancement of reinforcement\nlearning, substantial progress has been made in the walking control of humanoid\nrobots. However, existing methods still face challenges when dealing with\ncomplex environments and irregular terrains. In the field of perceptive\nlocomotion, existing approaches are generally divided into two-stage methods\nand end-to-end methods. Two-stage methods first train a teacher policy in a\nsimulated environment and then use distillation techniques, such as DAgger, to\ntransfer the privileged information learned as latent features or actions to\nthe student policy. End-to-end methods, on the other hand, forgo the learning\nof privileged information and directly learn policies from a partially\nobservable Markov decision process (POMDP) through reinforcement learning.\nHowever, due to the lack of supervision from a teacher policy, end-to-end\nmethods often face difficulties in training and exhibit unstable performance in\nreal-world applications. This paper proposes an innovative two-stage perceptive\nlocomotion framework that combines the advantages of teacher policies learned\nin a fully observable Markov decision process (MDP) to regularize and supervise\nthe student policy. At the same time, it leverages the characteristics of\nreinforcement learning to ensure that the student policy can continue to learn\nin a POMDP, thereby enhancing the model's upper bound. Our experimental results\ndemonstrate that our two-stage training framework achieves higher training\nefficiency and stability in simulated environments, while also exhibiting\nbetter robustness and generalization capabilities in real-world applications."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-195",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18399",
    "b_title":[
      "T3ST code: Turbulent Transport in Tokamaks via Stochastic Trajectories"
    ],
    "b_abstract":[
      "We introduce the Turbulent Transport in Tokamaks via Stochastic Trajectories\n(T3ST) code, designed to address the problem of turbulent transport using a\nstatistical approach complementary to gyrokinetics. The code employs\ntest-particle methods to track the dynamics of charged particles in\naxisymmetric magnetic equilibria, accounting for both turbulence and Coulomb\ncollisions. The turbulence is decoupled from plasma dynamics and represented\nthrough a statistical ensemble of synthetic random fields with specified\nspectral properties. This approach enables T3ST to compute transport\ncoefficients as Lagrangian correlations - orders of magnitude faster than\ngyrokinetic codes."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16688",
    "c_title":[
      "MME-Industry: A Cross-Industry Multimodal Evaluation Benchmark"
    ],
    "c_abstract":[
      "With the rapid advancement of Multimodal Large Language Models (MLLMs),\nnumerous evaluation benchmarks have emerged. However, comprehensive assessments\nof their performance across diverse industrial applications remain limited. In\nthis paper, we introduce MME-Industry, a novel benchmark designed specifically\nfor evaluating MLLMs in industrial settings.The benchmark encompasses 21\ndistinct domain, comprising 1050 question-answer pairs with 50 questions per\ndomain. To ensure data integrity and prevent potential leakage from public\ndatasets, all question-answer pairs were manually crafted and validated by\ndomain experts. Besides, the benchmark's complexity is effectively enhanced by\nincorporating non-OCR questions that can be answered directly, along with tasks\nrequiring specialized domain knowledge. Moreover, we provide both Chinese and\nEnglish versions of the benchmark, enabling comparative analysis of MLLMs'\ncapabilities across these languages. Our findings contribute valuable insights\ninto MLLMs' practical industrial applications and illuminate promising\ndirections for future model optimization research."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-196",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09533",
    "b_title":[
      "Large Language Models for Multi-Facility Location Mechanism Design"
    ],
    "b_abstract":[
      "Designing strategyproof mechanisms for multi-facility location that optimize\nsocial costs based on agent preferences had been challenging due to the\nextensive domain knowledge required and poor worst-case guarantees. Recently,\ndeep learning models have been proposed as alternatives. However, these models\nrequire some domain knowledge and extensive hyperparameter tuning as well as\nlacking interpretability, which is crucial in practice when transparency of the\nlearned mechanisms is mandatory. In this paper, we introduce a novel approach,\nnamed LLMMech, that addresses these limitations by incorporating large language\nmodels (LLMs) into an evolutionary framework for generating interpretable,\nhyperparameter-free, empirically strategyproof, and nearly optimal mechanisms.\nOur experimental results, evaluated on various problem settings where the\nsocial cost is arbitrarily weighted across agents and the agent preferences may\nnot be uniformly distributed, demonstrate that the LLM-generated mechanisms\ngenerally outperform existing handcrafted baselines and deep learning models.\nFurthermore, the mechanisms exhibit impressive generalizability to\nout-of-distribution agent preferences and to larger instances with more agents."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09736",
    "c_title":[
      "Tilted sensitivity analysis in matched observational studies"
    ],
    "c_abstract":[
      "We present a new procedure for conducting a sensitivity analysis in matched\nobservational studies. For any candidate test statistic, the approach defines\ntilted modifications dependent upon the proposed strength of unmeasured\nconfounding. The framework subsumes both (i) existing approaches to sensitivity\nanalysis for sign-score statistics; and (ii) sensitivity analyses using\nconditional inverse probability weighting, wherein one weights the observed\ntest statistic based upon the worst-case assignment probabilities for a\nproposed strength of hidden bias. Unlike the prevailing approach to sensitivity\nanalysis after matching, there is a closed form expression for the limiting\nworst-case distribution when matching with multiple controls. Moreover, the\napproach admits a closed form for its design sensitivity, a measure used to\ncompare competing test statistics and research designs, for matching with\nmultiple controls, whereas the conventional approach generally only does so for\npair matching. The tilted sensitivity analysis improves design sensitivity\nunder a host of generative models. The proposal may also be adaptively combined\nwith the conventional approach to attain a design sensitivity no smaller than\nthe maximum of the individual design sensitivities. Data illustrations indicate\nthat tilting can provide meaningful improvements in the reported robustness of\nmatched observational studies."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-197",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18295",
    "b_title":[
      "Quantization of the Momentum Map via $\\frak{g}$-adapted Formalities"
    ],
    "b_abstract":[
      "In this note, we provide a proof of the existence and complete classification\nof $G$-invariant star products with quantum momentum maps on Poisson manifolds\nby means of an equivariant version of the formality theorem."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.QA",
        "math.SG"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01486",
    "c_title":[
      "Tail-induced equilibration in long-range interacting quantum lattices"
    ],
    "c_abstract":[
      "We examine the relation between inter-particle interactions and real-time\nequilibration in one-dimensional lattice systems with hard-core constraints.\nFocusing on the roles of interactions, our results demonstrate that in the\npresence of interaction tails, any power-law exponent (including the limit\nones) can encode the random particle configurations to the Hamiltonian, leaving\nthe latter characterized by random matrices. Through an experimental-accessible\nsetup using dipolar-interacting particles in optical lattices, the quenched\nrelaxations are demonstrated resulting in equilibrium, and the relation between\neigenstate thermalization is confirmed. Our study directly unveiled the role of\ninter-particle interactions in quantum many-body dynamics, offering a new\nscheme to address equilibration in closed quantum many-body problem based on\nthe manifesting of random particle configurations in the model Hamiltonian."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-198",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03859",
    "b_title":[
      "A Synergistic Framework for Learning Shape Estimation and Shape-Aware\n  Whole-Body Control Policy for Continuum Robots"
    ],
    "b_abstract":[
      "In this paper, we present a novel synergistic framework for learning shape\nestimation and a shape-aware whole-body control policy for tendon-driven\ncontinuum robots. Our approach leverages the interaction between two Augmented\nNeural Ordinary Differential Equations (ANODEs) -- the Shape-NODE and\nControl-NODE -- to achieve continuous shape estimation and shape-aware control.\nThe Shape-NODE integrates prior knowledge from Cosserat rod theory, allowing it\nto adapt and account for model mismatches, while the Control-NODE uses this\nshape information to optimize a whole-body control policy, trained in a Model\nPredictive Control (MPC) fashion. This unified framework effectively overcomes\nlimitations of existing data-driven methods, such as poor shape awareness and\nchallenges in capturing complex nonlinear dynamics. Extensive evaluations in\nboth simulation and real-world environments demonstrate the framework's robust\nperformance in shape estimation, trajectory tracking, and obstacle avoidance.\nThe proposed method consistently outperforms state-of-the-art end-to-end,\nNeural-ODE, and Recurrent Neural Network (RNN) models, particularly in terms of\ntracking accuracy and generalization capabilities."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01760",
    "c_title":[
      "Di-decay signature of new physics particles at intensity frontier\n  experiments"
    ],
    "c_abstract":[
      "We explore the potential of intensity frontier experiments to search for\nunstable feebly interacting particles (FIPs) via signatures that offer deeper\ninsights than the standard signature of a single FIP decay. Specifically, we\nstudy models where FIPs are produced in pairs in a single event, so both can\nsimultaneously decay in the detector. These ``di-decay'' events allow us to\nidentify the mother particle decaying into the FIP pair and reconstruct its\nproperties, provide further insights into the dark sector couplings to the SM,\nand are much cleaner against backgrounds. As a concrete example, we focus on\nthe class of models where the FIPs couple quadratically to the Higgs boson and\nderive the sensitivities of SHiP and Belle II to di-decays of Higgs-like\nscalars. In particular, at Belle II, finite backgrounds for the single decay\nsignature make di-decays competitive, providing a distinctive handle on FIP\nproduction and lifetime."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-199",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16389",
    "b_title":[
      "Attentional Triple-Encoder Network in Spatiospectral Domains for Medical\n  Image Segmentation"
    ],
    "b_abstract":[
      "Retinal Optical Coherence Tomography (OCT) segmentation is essential for\ndiagnosing pathology. Traditional methods focus on either spatial or spectral\ndomains, overlooking their combined dependencies. We propose a triple-encoder\nnetwork that integrates CNNs for spatial features, Fast Fourier Convolution\n(FFC) for spectral features, and attention mechanisms to capture global\nrelationships across both domains. Attention fusion modules integrate\nconvolution and cross-attention to further enhance features. Our method\nachieves an average Dice score improvement from 0.855 to 0.864, outperforming\nprior work."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10552",
    "c_title":[
      "Mathematical and numerical methods for understanding immune cell motion\n  during wound healing"
    ],
    "c_abstract":[
      "In this paper, we propose a new workflow to analyze macrophage motion during\nwound healing. These immune cells are attracted to the wound after an injury\nand they move showing both directional and random motion. Thus, first, we\nsmooth the trajectories and we separate the random from the directional parts\nof the motion. The smoothing model is based on curve evolution where the curve\nmotion is influenced by the smoothing term and the attracting term. Once we\nobtain the random sub-trajectories, we analyze them using the mean squared\ndisplacement to characterize the type of diffusion. Finally, we compute the\nvelocities on the smoothed trajectories and use them as sparse samples to\nreconstruct the wound attractant field. To do that, we consider a minimization\nproblem for the vector components and lengths, which leads to solving the\nLaplace equation with Dirichlet conditions for the sparse samples and zero\nNeumann boundary conditions on the domain boundary."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-200",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02496",
    "b_title":[
      "To Hedge or Not to Hedge: Optimal Strategies for Stochastic Trade Flow\n  Management"
    ],
    "b_abstract":[
      "This paper addresses the trade-off between internalisation and\nexternalisation in the management of stochastic trade flows. We consider agents\nwho must absorb flows and manage risk by deciding whether to warehouse it or\nhedge in the market, thereby incurring transaction costs and market impact.\nUnlike market makers, these agents cannot skew their quotes to attract\noffsetting flows and deter risk-increasing ones, leading to a fundamentally\ndifferent problem. Within the Almgren-Chriss framework, we derive\nalmost-closed-form solutions in the case of quadratic execution costs, while\nmore general cases require numerical methods. In particular, we discuss the\nchallenges posed by artificial boundary conditions when using classical\ngrid-based numerical PDE techniques and propose reinforcement learning methods\nas an alternative."
    ],
    "b_categories":[
      [
        "q-fin.TR"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.11861",
    "c_title":[
      "Banking on Feedback: Text Analysis of Mobile Banking iOS and Google App\n  Reviews"
    ],
    "c_abstract":[
      "The rapid growth of mobile banking (m-banking), especially after the COVID-19\npandemic, has reshaped the financial sector. This study analyzes consumer\nreviews of m-banking apps from five major Canadian banks, collected from Google\nPlay and iOS App stores. Sentiment analysis and topic modeling classify reviews\nas positive, neutral, or negative, highlighting user preferences and areas for\nimprovement. Data pre-processing was performed with NLTK, a Python language\nprocessing tool, and topic modeling used Latent Dirichlet Allocation (LDA).\nSentiment analysis compared methods, with Long Short-Term Memory (LSTM)\nachieving 82\\% accuracy for iOS reviews and Multinomial Naive Bayes 77\\% for\nGoogle Play. Positive reviews praised usability, reliability, and features,\nwhile negative reviews identified login issues, glitches, and dissatisfaction\nwith updates.This is the first study to analyze both iOS and Google Play\nm-banking app reviews, offering insights into app strengths and weaknesses.\nFindings underscore the importance of user-friendly designs, stable updates,\nand better customer service. Advanced text analytics provide actionable\nrecommendations for improving user satisfaction and experience."
    ],
    "c_categories":[
      [
        "cs.HC",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-201",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08949",
    "b_title":[
      "Self-Supervised Graph Contrastive Pretraining for Device-level\n  Integrated Circuits"
    ],
    "b_abstract":[
      "Self-supervised graph representation learning has driven significant\nadvancements in domains such as social network analysis, molecular design, and\nelectronics design automation (EDA). However, prior works in EDA have mainly\nfocused on the representation of gate-level digital circuits, failing to\ncapture analog and mixed-signal circuits. To address this gap, we introduce\nDICE: Device-level Integrated Circuits Encoder, the first self-supervised\npretrained graph neural network (GNN) model for any circuit expressed at the\ndevice level. DICE is a message-passing neural network (MPNN) trained through\ngraph contrastive learning, and its pretraining process is simulation-free,\nincorporating two novel data augmentation techniques. Experimental results\ndemonstrate that DICE achieves substantial performance gains across three\ndownstream tasks, underscoring its effectiveness for both analog and digital\ncircuits."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11487",
    "c_title":[
      "Non-Binary LDPC Arithmetic Error Correction For Processing-in-Memory"
    ],
    "c_abstract":[
      "Processing-in-memory (PIM) based on emerging devices such as memristors is\nmore vulnerable to noise than traditional memories, due to the physical\nnon-idealities and complex operations in analog domains. To ensure high\nreliability, efficient error-correcting code (ECC) is highly desired. However,\nstate-of-the-art ECC schemes for PIM suffer drawbacks including dataflow\ninterruptions, low code rates, and limited error correction patterns. In this\nwork, we propose non-binary low-density parity-check (NB-LDPC) error correction\nrunning over the Galois field. Such NB-LDPC scheme with a long word length of\n1024 bits can correct up to 8-bit errors with a code rate over 88%. Nonbinary\nGF operations can support both memory mode and PIM mode even with multi-level\nmemory cells. We fabricate a 40nm prototype PIM chip equipped with our proposed\nNB-LDPC scheme for validation purposes. Experiments show that PIM with NB-LDPC\nerror correction demonstrates up to 59.65 times bit error rate (BER)\nimprovement over the original PIM without such error correction. The test chip\ndelivers 2.978 times power efficiency enhancement over prior works."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-202",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19720",
    "b_title":[
      "Analysis of Linear Consensus Algorithm on Strongly Connected Graph Using\n  Effective Resistance"
    ],
    "b_abstract":[
      "We study the performance of the linear consensus algorithm on strongly\nconnected graphs using the linear quadratic (LQ) cost as a performance measure.\n  In particular, we derive bounds on the LQ cost by leveraging effective\nresistance. Our results extend previous analyses -- which were limited to\nreversible cases -- to the nonreversible setting. To facilitate this\ngeneralization, we introduce novel concepts, termed the back-and-forth path and\nthe pivot node, which serve as effective alternatives to traditional techniques\nthat require reversibility. Moreover, we apply our approach to geometric graphs\nto estimate the LQ cost without the reversibility assumption. The proposed\napproach provides a framework that can be adapted to other contexts where\nreversibility is typically assumed."
    ],
    "b_categories":[
      [
        "cs.MA",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.04283",
    "c_title":[
      "The Young Ages of 70 {\\mu}m-dark Clumps Inferred from Carbon Chain\n  Chemistry"
    ],
    "c_abstract":[
      "The physical conditions of the earliest environment of high-mass star\nformation are currently poorly understood. To that end, we present observations\nof the carbon chain molecules HC$_5$N , CCS, and HC$_7$N in the 22-25 GHz band\ntowards 12 high-mass 70 micron-dark clumps (SMDC) with the Jansky Very Large\nArray (VLA). We detect HC$_5$N and CCS towards 11 of these SMDC sources. We\ncalculate column densities and abundances relative to H$_2$ for HC$_5$N and\nCCS. We do not find any clear HC$_7$N detections in the 11 sources\nindividually, but by stacking the HC$_7$N spectra, we do detect HC$_7$N on\naverage in these sources. We also calculate the ratio of the column densities\nof HC$_5$N to HC$_7$N using the stacked spectra of both species. We compare our\nmeasured abundances of HC$_5$N and our measured ratio of HC$_5$N to HC$_7$N to\nthe UMIST dark cloud chemistry models to constrain an age for the gas assuming\na fixed volume density and temperature. The chemical models favor a chemical\nevolutionary age less than 1 Myr at densities of n(H2) = 2 x 10$^4$ cm$^{-3}$.\nThe consistent carbon-chain detections and young model-derived ages support the\nconclusion that these 11 70 micron-dark clumps lack high mass protostars\nbecause they are young and not because they are inefficient and incapable of\nhigh mass star formation."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-203",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03705",
    "b_title":[
      "Correlation time in extremal self-organized critical models"
    ],
    "b_abstract":[
      "We investigate correlation time numerically in extremal self-organized\ncritical models, namely, the Bak-Sneppen evolution and the Robin Hood dynamics.\nThe (fitness) correlation time is the duration required for the extinction or\nmutation of species over the entire spatial region in the critical state. We\napply the methods of finite-size scaling and extreme value theory to understand\nthe statistics of the correlation time. We find power-law system size scaling\nbehaviors for the mean, the variance, the mode, and the peak probability of the\ncorrelation time. We obtain data collapse for the correlation time cumulative\nprobability distribution, and the scaling function follows the generalized\nextreme value density close to the Gumbel function."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18013",
    "c_title":[
      "A comprehensive numerical investigation of a coupled mathematical model\n  of neuronal excitability"
    ],
    "c_abstract":[
      "Being an example for a relaxation oscillator, the FitzHugh-Nagumo model has\nbeen widely employed for describing the generation of action potentials. In\nthis paper, we begin with a biological interpretation of what the subsequent\nmathematical and numerical analyses of the model entail. The interaction\nbetween action potential variable and recovery variable is then revisited\nthrough linear stability analysis around the equilibrium and local stability\nconditions are determined. Analytical results are compared with numerical\nsimulations. The study aims to show an alternative approach regarding Taylor\npolynomials and constructed difference scheme which play a key role in the\nnumerical approach for the problem. The robustness of the schemes is\ninvestigated in terms of convergency and stability of the techniques. This\nsystematic approach by the combination of numerical techniques provides\nbeneficial results which are uniquely designed for the FitzHugh-Nagumo model.\nWe describe the matrix representations with the collocation points. Then the\nmethod is applied in order to acquire a system of nonlinear algebraic\nequations. On the other hand, we apply finite difference scheme and its\nstability is also performed. Moreover, the numerical simulations are shown.\nConsequently, a comprehensive investigation of the related model is examined."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.DS",
        "math.NA",
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-204",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07515",
    "b_title":[
      "The Paradox of Success in Evolutionary and Bioinspired Optimization:\n  Revisiting Critical Issues, Key Studies, and Methodological Pathways"
    ],
    "b_abstract":[
      "Evolutionary and bioinspired computation are crucial for efficiently\naddressing complex optimization problems across diverse application domains. By\nmimicking processes observed in nature, like evolution itself, these algorithms\noffer innovative solutions beyond the reach of traditional optimization\nmethods. They excel at finding near-optimal solutions in large, complex search\nspaces, making them invaluable in numerous fields. However, both areas are\nplagued by challenges at their core, including inadequate benchmarking,\nproblem-specific overfitting, insufficient theoretical grounding, and\nsuperfluous proposals justified only by their biological metaphor. This\noverview recapitulates and analyzes in depth the criticisms concerning the lack\nof innovation and rigor in experimental studies within the field. To this end,\nwe examine the judgmental positions of the existing literature in an informed\nattempt to guide the research community toward directions of solid contribution\nand advancement in these areas. We summarize guidelines for the design of\nevolutionary and bioinspired optimizers, the development of experimental\ncomparisons, and the derivation of novel proposals that take a step further in\nthe field. We provide a brief note on automating the process of creating these\nalgorithms, which may help align metaheuristic optimization research with its\nprimary objective (solving real-world problems), provided that our identified\npathways are followed. Our conclusions underscore the need for a sustained push\ntowards innovation and the enforcement of methodological rigor in prospective\nstudies to fully realize the potential of these advanced computational\ntechniques."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00713",
    "c_title":[
      "Using Individualized Treatment Effects to Assess Treatment Effect\n  Heterogeneity"
    ],
    "c_abstract":[
      "Assessing treatment effect heterogeneity (TEH) in clinical trials is crucial,\nas it provides insights into the variability of treatment responses among\npatients, influencing important decisions related to drug development.\nFurthermore, it can lead to personalized medicine by tailoring treatments to\nindividual patient characteristics. This paper introduces novel methodologies\nfor assessing treatment effects using the individual treatment effect as a\nbasis. To estimate this effect, we use a Double Robust (DR) learner to infer a\npseudo-outcome that reflects the causal contrast. This pseudo-outcome is then\nused to perform three objectives: (1) a global test for heterogeneity, (2)\nranking covariates based on their influence on effect modification, and (3)\nproviding estimates of the individualized treatment effect. We compare our\nDR-learner with various alternatives and competing methods in a simulation\nstudy, and also use it to assess heterogeneity in a pooled analysis of five\nPhase III trials in psoriatic arthritis. By integrating these methods with the\nrecently proposed WATCH workflow (Workflow to Assess Treatment Effect\nHeterogeneity in Drug Development for Clinical Trial Sponsors), we provide a\nrobust framework for analyzing TEH, offering insights that enable more informed\ndecision-making in this challenging area."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-205",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07150",
    "b_title":[
      "Simulating programmable morphing of shape memory polymer beam systems\n  with complex geometry and topology"
    ],
    "b_abstract":[
      "We propose a novel approach to the analysis of programmable geometrically\nexact shear deformable beam systems made of shape memory polymers. The proposed\nmethod combines the viscoelastic Generalized Maxwell model with the Williams,\nLandel and Ferry relaxation principle, enabling the reproduction of the shape\nmemory effect of structural systems featuring complex geometry and topology.\nVery high efficiency is pursued by discretizing the differential problem in\nspace through the isogeometric collocation (IGA-C) method. The method, in\naddition to the desirable attributes of isogeometric analysis (IGA), such as\nexactness of the geometric reconstruction of complex shapes and high-order\naccuracy, circumvents the need for numerical integration since it discretizes\nthe problem in the strong form. Other distinguishing features of the proposed\nformulation are: i) ${\\rm SO}(3)$-consistency for the linearization of the\nproblem and for the time stepping; ii) minimal (finite) rotation\nparametrization, that means only three rotational unknowns are used; iii) no\nadditional unknowns are needed to account for the rate-dependent material\ncompared to the purely elastic case. Through different numerical applications\ninvolving challenging initial geometries, we show that the proposed formulation\npossesses all the sought attributes in terms of programmability of complex\nsystems, geometric flexibility, and high order accuracy."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06286",
    "c_title":[
      "A 7T fMRI dataset of synthetic images for out-of-distribution modeling\n  of vision"
    ],
    "c_abstract":[
      "Large-scale visual neural datasets such as the Natural Scenes Dataset (NSD)\nare boosting NeuroAI research by enabling computational models of the brain\nwith performances beyond what was possible just a decade ago. However, these\ndatasets lack out-of-distribution (OOD) components, which are crucial for the\ndevelopment of more robust models. Here, we address this limitation by\nreleasing NSD-synthetic, a dataset consisting of 7T fMRI responses from the\neight NSD subjects for 284 carefully controlled synthetic images. We show that\nNSD-synthetic's fMRI responses reliably encode stimulus-related information and\nare OOD with respect to NSD. Furthermore, OOD generalization tests on\nNSD-synthetic reveal differences between models of the brain that are not\ndetected with NSD - specifically, self-supervised deep neural networks better\nexplain neural responses than their task-supervised counterparts. These results\nshowcase how NSD-synthetic enables OOD generalization tests that facilitate the\ndevelopment of more robust models of visual processing, and the formulation of\nmore accurate theories of human vision."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-206",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02267",
    "b_title":[
      "A unified framework for pointwise convergence to the initial data of\n  heat equations in metric measure spaces"
    ],
    "b_abstract":[
      "Given a metric measure space $(\\mathcal{X}, d, \\mu)$ satisfying the volume\ndoubling condition, we consider a semigroup $\\{S_t\\}$ and the associated heat\noperator. We propose general conditions on the heat kernel so that the\nsolutions of the associated heat equations attain the initial data pointwise.\nWe demonstrate that these conditions are satisfied by a broad class of\noperators, including the Laplace operators perturbed by a gradient, fractional\nLaplacian, mixed local-nonlocal operators, Laplacian on Riemannian manifolds,\nDunkl Laplacian and many more. In addition, we consider the Laplace operator in\n$\\mathbb{R}^n$ with the Hardy potential and establish a characterization for\nthe pointwise convergence to the initial data. We also prove similar results\nfor the nonhomogeneous equations and showcase an application for the power-type\nnonlinearities."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.04316",
    "c_title":[
      "Shape-asymmetry and flexibility in active cross-stream migration in\n  nonuniform shear"
    ],
    "c_abstract":[
      "We show that the interplay of activity and broken fore-aft symmetry of shapes\nhelps microswimmers to migrate across streamlines in nonuniform shear,\nemphasizing a hitherto overlooked fundamental cause of active cross-stream\nmigration in imposed flows. Using a framework on model flagellated\nmicroswimmers in a microchannel flow, we find that besides the broken head-tail\nshape symmetry, extended hydrodynamic coupling is vital for cross-stream\nmigration, whereas flagellar flexibility significantly affects the same.\nFurthermore, by simplifying the problem to a basic analytical model, we are\nable to identify the fundamental factors affecting the observed rich nonlinear\ndynamics and predict the sorting and control of microswimmer populations inside\na microchannel. Our predictions are general and apply to both living and\nartificial microswimmers, whereas the hydrodynamic framework developed here is\nnecessary to probe other scenarios, such as in dense suspensions, where\nnon-uniform shear and near-field flows become important."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.bio-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-207",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04949",
    "b_title":[
      "Charge sensing of few-electron ZnO double quantum dots probed by\n  radio-frequency reflectometry"
    ],
    "b_abstract":[
      "Zinc oxide (ZnO) has garnered much attention as a promising material for\nquantum devices due to its unique characteristics. To utilize the potential of\nZnO for quantum devices, the development of fundamental technological elements\nsuch as high-speed readout and charge sensing capabilities has become\nessential. In this study, we address these challenges by demonstrating\nradio-frequency (rf) reflectometry and charge sensing in ZnO quantum dots, thus\nadvancing the potential for qubit applications. A device is fabricated on a\nhigh-quality ZnO heterostructure, featuring gate-defined target and sensor\nquantum dots. The sensor dot, integrated into an rf resonator circuit, enables\nthe detection of single-electron charges in the target dots. Using this setup,\nthe formation of few-electron double quantum dots is observed by obtaining\ntheir charge stability diagram. Also, a charge stability diagram with a gate\npulse sequence is measured. We discuss the strong electron correlation in ZnO,\nwhich leads to nearly degenerate spin-singlet and -triplet two-electron states\nin the (0, 2) charge state, and the perspectives on spin-state readout."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00071",
    "c_title":[
      "Including frameworks of public health ethics in computational modelling\n  of infectious disease interventions"
    ],
    "c_abstract":[
      "Decisions on public health interventions to control infectious disease are\noften informed by computational models. Interpreting the predicted outcomes of\na public health decision requires not only high-quality modelling, but also an\nethical framework for assessing the benefits and harms associated with\ndifferent options. The design and specification of ethical frameworks matured\nindependently of computational modelling, so many values recognised as\nimportant for ethical decision-making are missing from computational models. We\ndemonstrate a proof-of-concept approach to incorporate multiple public health\nvalues into the evaluation of a simple computational model for vaccination\nagainst a pathogen such as SARS-CoV-2. By examining a bounded space of\nalternative prioritisations of values (outcome equity and aggregate benefit) we\nidentify value trade-offs, where the outcomes of optimal strategies differ\ndepending on the ethical framework. This work demonstrates an approach to\nincorporating diverse values into decision criteria used to evaluate outcomes\nof models of infectious disease interventions."
    ],
    "c_categories":[
      [
        "cs.CY",
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-208",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10221",
    "b_title":[
      "Modelling Activity Scheduling Behaviour with Deep Generative Machine\n  Learning"
    ],
    "b_abstract":[
      "We model human activity scheduling behaviour using a deep generative machine\nlearning approach. Activity schedules, which represent the activities and\nassociated travel behaviours of individuals, are a core component of many\napplied models in the transport, energy and epidemiology domains. Our data\ndriven approach learns human preferences and scheduling logic without the need\nfor complex interacting combinations of sub-models and custom-rules, this makes\nour approach significantly faster and simpler to operate that existing\napproaches. We find activity schedule data combines aspects of both continuous\nimage data and also discrete text data, requiring novel approaches. We\nadditionally contribute a novel schedule representation and comprehensive\nevaluation framework for generated schedules. Evaluation shows our approach is\nable to rapidly generate large, diverse and realistic synthetic samples of\nactivity schedules."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08732",
    "c_title":[
      "A Quasi-Optimal Stacking Method for Up-the-Ramp Readout Images"
    ],
    "c_abstract":[
      "The non-destructive readout mode of a detector allows its pixels to be read\nmultiple times during integration, generating a series of \"up-the-ramp\" images\nthat keep accumulating photons between successive frames. Since the noise is\ncorrelated across these images, an optimal stacking generally requires\nweighting them unequally to achieve the best signal-to-noise ratio (SNR) for\nthe target. Objects in the sky show wildly different brightness, and the counts\nin the pixels of the same object also span a wide range. Therefore, a single\nset of weights cannot be optimal for all cases. To keep the stacked image more\neasily calibratable, however, we choose to apply the same weight to all the\npixels in the same frame. In practice, we find that the results of high-SNR\ncases degrade only slightly by adopting weights derived for low-SNR cases,\nwhereas the low-SNR cases are more sensitive to the weights applied. We\ntherefore propose a quasi-optimal stacking method that maximizes the stacked\nSNR for the case of SNR=1 per pixel in the last frame and demonstrate with\nsimulated data that it always enhances the SNR more than the equal-weight\nstacking method and the ramp fitting method. Furthermore, we give an estimate\nof the improvement of limiting magnitudes for the China Space Station Telescope\n(CSST) based on this method. Compared with the conventional readout mode, which\nis equivalent to taking the last frame of the non-destructive readout, stacking\n30 up-the-ramp images can improve the limiting magnitude by about 0.5 mag for\nCSST near-infrared observations, effectively reducing the readout noise by\nabout 62%."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-209",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10417",
    "b_title":[
      "Simultaneous extension of generalized BT-inverses and core-EP inverses"
    ],
    "b_abstract":[
      "In this paper we introduce the generalized inverse of complex square matrix\nwith respect to other matrix having same size. Some of its representations,\nproperties and characterizations are obtained. Also some new representation\nmatrices of W-weighted BT-inverse and W-weighted core-EP inverse are determined\nas well as characterizations of generalized inverses A A^\\odagger,\nA^{odagger,W}, A^\\diamond, A^{\\diamond,W}."
    ],
    "b_categories":[
      [
        "math.FA",
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00108",
    "c_title":[
      "Tracking Most Significant Shifts in Infinite-Armed Bandits"
    ],
    "c_abstract":[
      "We study an infinite-armed bandit problem where actions' mean rewards are\ninitially sampled from a reservoir distribution. Most prior works in this\nsetting focused on stationary rewards (Berry et al., 1997; Wang et al., 2008;\nBonald and Proutiere, 2013; Carpentier and Valko, 2015) with the more\nchallenging adversarial\/non-stationary variant only recently studied in the\ncontext of rotting\/decreasing rewards (Kim et al., 2022; 2024). Furthermore,\noptimal regret upper bounds were only achieved using parameter knowledge of\nnon-stationarity and only known for certain regimes of regularity of the\nreservoir. This work shows the first parameter-free optimal regret bounds for\nall regimes while also relaxing distributional assumptions on the reservoir.\n  We first introduce a blackbox scheme to convert a finite-armed MAB algorithm\ndesigned for near-stationary environments into a parameter-free algorithm for\nthe infinite-armed non-stationary problem with optimal regret guarantees. We\nnext study a natural notion of significant shift for this problem inspired by\nrecent developments in finite-armed MAB (Suk & Kpotufe, 2022). We show that\ntighter regret bounds in terms of significant shifts can be adaptively attained\nby employing a randomized variant of elimination within our blackbox scheme.\nOur enhanced rates only depend on the rotting non-stationarity and thus exhibit\nan interesting phenomenon for this problem where rising rewards do not factor\ninto the difficulty of non-stationarity."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-210",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09507",
    "b_title":[
      "When and How Does CLIP Enable Domain and Compositional Generalization?"
    ],
    "b_abstract":[
      "The remarkable generalization performance of contrastive vision-language\nmodels like CLIP is often attributed to the diversity of their training\ndistributions. However, key questions remain unanswered: Can CLIP generalize to\nan entirely unseen domain when trained on a diverse mixture of domains (domain\ngeneralization)? Can it generalize to unseen classes within partially seen\ndomains (compositional generalization)? What factors affect such\ngeneralization? To answer these questions, we trained CLIP models on\nsystematically constructed training distributions with controlled domain\ndiversity and object class exposure. Our experiments show that domain diversity\nis essential for both domain and compositional generalization, yet\ncompositional generalization can be surprisingly weaker than domain\ngeneralization when the training distribution contains a suboptimal subset of\nthe test domain. Through data-centric and mechanistic analyses, we find that\nsuccessful generalization requires learning of shared representations already\nin intermediate layers and shared circuitry."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06398",
    "c_title":[
      "VIX options in the SABR model"
    ],
    "c_abstract":[
      "We study the pricing of VIX options in the SABR model $dS_t = \\sigma_t\nS_t^\\beta dB_t, d\\sigma_t = \\omega \\sigma_t dZ_t$ where $B_t,Z_t$ are standard\nBrownian motions correlated with correlation $\\rho<0$ and $0 \\leq \\beta < 1$.\nVIX is expressed as a risk-neutral conditional expectation of an integral over\nthe volatility process $v_t = S_t^{\\beta-1} \\sigma_t$. We show that $v_t$ is\nthe unique solution to a one-dimensional diffusion process. Using the Feller\ntest, we show that $v_t$ explodes in finite time with non-zero probability. As\na consequence, VIX futures and VIX call prices are infinite, and VIX put prices\nare zero for any maturity. As a remedy, we propose a capped volatility process\nby capping the drift and diffusion terms in the $v_{t}$ process such that it\nbecomes non-explosive and well-behaved, and study the short-maturity\nasymptotics for the pricing of VIX options."
    ],
    "c_categories":[
      [
        "q-fin.PR"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-211",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13154",
    "b_title":[
      "Evolution of a trait distributed over a large fragmented population:\n  Propagation of chaos meets adaptive dynamics"
    ],
    "b_abstract":[
      "We consider a metapopulation made up of $K$ demes, each containing $N$\nindividuals bearing a heritable quantitative trait. Demes are connected by\nmigration and undergo independent Moran processes with mutation and selection\nbased on trait values. Mutation and migration rates are tuned so that each deme\nreceives a migrant or a mutant in the same slow timescale and is thus\nessentially monomorphic at all times for the trait (adaptive dynamics). In the\ntimescale of mutation\/migration, the metapopulation can then be seen as a giant\nspatial Moran model with size $K$ that we characterize. As $K\\to \\infty$ and\nphysical space becomes continuous, the empirical distribution of the trait\n(over the physical and trait spaces) evolves deterministically according to an\nintegro-differential evolution equation. In this limit, the trait of every\nmigrant is drawn from this global distribution, so that conditional on its\ninitial state, traits from finitely many demes evolve independently\n(propagation of chaos). Under mean-field dispersal, the value $X_t$ of the\ntrait at time $t$ and at any given location has a law denoted $\\mu_t$ and a\njump kernel with two terms: a mutation-fixation term and a migration-fixation\nterm involving $\\mu_{t-}$ (McKean-Vlasov equation). In the limit where\nmutations have small effects and migration is further slowed down accordingly,\nwe obtain the convergence of $X$, in the new migration timescale, to the\nsolution of a stochastic differential equation which can be referred to as a\nnew canonical equation of adaptive dynamics. This equation includes an\nadvection term representing selection, a diffusive term due to genetic drift,\nand a jump term, representing the effect of migration, to a state distributed\naccording to its own law."
    ],
    "b_categories":[
      [
        "math.PR",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17318",
    "c_title":[
      "Modelling conductive thermal transport in three-dimensional fibrous\n  media with fiber-to-fiber contacts"
    ],
    "c_abstract":[
      "Understanding heat transfers in fibrous materials, particularly conduction,\nis a major challenge due to their heterogeneous and multiscale nature, and the\nunknown contribution of fiber-to-fiber contacts. In most previous modelling\nstudies, the existence of thermal contact resistance is not considered, and the\ncomputational complexity often limits the size of simulated samples, which\nleads to imprecise of inaccurate predictions. The same problem arises when\nconsidering electrical conduction through fibrous materials. In this work, we\ndescribe a computationally efficient simulation approach based on multi-nodal\nrepresentation to analyze the steady-state heat conduction through the solid\nstructure in numerically generated 3D nanofiber networks, including contact\nresistance. We show that the solid conductivity in these networks is governed\nby a master curve that depends on a single parameter: a characteristic ratio\nrepresenting the interplay between fiber intrinsic conductivity and contact\nresistance as well as the influence of other geometric parameters, which\nnumerically validates previous theoretical studies. However, we observe a\ndeviation to this established theory for poorly-connected networks. We derive\nan expression for a correction factor, considering the influence of\ncorrelations between fiber temperatures, and we find then good agreement with\nour simulation data. Our results demonstrate that the solid conductivity can be\nfully predicted based on geometric quantities, regardless of the extent of\nnetwork connectivity, thus generalizing previous studies on this topic. This\nwork, contributing to improve our understanding of conductive heat transport in\nfibrous media, may prove useful in the development of accurate predictive\nmodels and optimization strategies for fibrous insulation materials."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-212",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12698",
    "b_title":[
      "A Continual Learning-driven Model for Accurate and Generalizable\n  Segmentation of Clinically Comprehensive and Fine-grained Whole-body\n  Anatomies in CT"
    ],
    "b_abstract":[
      "Precision medicine in the quantitative management of chronic diseases and\noncology would be greatly improved if the Computed Tomography (CT) scan of any\npatient could be segmented, parsed and analyzed in a precise and detailed way.\nHowever, there is no such fully annotated CT dataset with all anatomies\ndelineated for training because of the exceptionally high manual cost, the need\nfor specialized clinical expertise, and the time required to finish the task.\nTo this end, we proposed a novel continual learning-driven CT model that can\nsegment complete anatomies presented using dozens of previously partially\nlabeled datasets, dynamically expanding its capacity to segment new ones\nwithout compromising previously learned organ knowledge. Existing multi-dataset\napproaches are not able to dynamically segment new anatomies without\ncatastrophic forgetting and would encounter optimization difficulty or\ninfeasibility when segmenting hundreds of anatomies across the whole range of\nbody regions. Our single unified CT segmentation model, CL-Net, can highly\naccurately segment a clinically comprehensive set of 235 fine-grained\nwhole-body anatomies. Composed of a universal encoder, multiple optimized and\npruned decoders, CL-Net is developed using 13,952 CT scans from 20 public and\n16 private high-quality partially labeled CT datasets of various vendors,\ndifferent contrast phases, and pathologies. Extensive evaluation demonstrates\nthat CL-Net consistently outperforms the upper limit of an ensemble of 36\nspecialist nnUNets trained per dataset with the complexity of 5% model size and\nsignificantly surpasses the segmentation accuracy of recent leading Segment\nAnything-style medical image foundation models by large margins. Our continual\nlearning-driven CL-Net model would lay a solid foundation to facilitate many\ndownstream tasks of oncology and chronic diseases using the most widely adopted\nCT imaging."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08756",
    "c_title":[
      "Effect of spontaneous emission on a tanh model"
    ],
    "c_abstract":[
      "This study examines the impact of spontaneous emission on a tanh model. The\neffect is characterized by introducing an imaginary term and a shift in the\nmodel, resulting in its non-Hermitian nature. This leads to the appearance of\nlight beams in the population evolution, primarily influenced by the coupling\nstrength and the shift. We derive the necessary conditions to identify the\nallowed and forbidden regions in the diagram of the real part of the energy.\nAdditionally, we analyze how sweep velocity and time affect the imaginary part\nof the energy. Furthermore, we demonstrate the similarities between our model\nand the Rabi and Landau-Zener models. Throughout this work, we confirm that our\ntheoretical predictions align well with numerical simulations."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-213",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12047",
    "b_title":[
      "Quantum Byzantine Multiple Access Channels"
    ],
    "b_abstract":[
      "In communication theory, attacks like eavesdropping or jamming are typically\nassumed to occur at the channel level, while communication parties are expected\nto follow established protocols. But what happens if one of the parties turns\nmalicious? In this work, we investigate a compelling scenario: a\nmultiple-access channel with two transmitters and one receiver, where one\ntransmitter deviates from the protocol and acts dishonestly. To address this\nchallenge, we introduce the Byzantine multiple-access classical-quantum channel\nand derive an achievable communication rate for this adversarial setting."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12222",
    "c_title":[
      "Strong phonon-mediated high temperature superconductivity in\n  Li$_2$AuH$_6$ under ambient pressure"
    ],
    "c_abstract":[
      "We used our developed AI search engine~(InvDesFlow) to perform extensive\ninvestigations regarding ambient stable superconducting hydrides. A cubic\nstructure Li$_2$AuH$_6$ with Au-H octahedral motifs is identified to be a\ncandidate. After performing thermodynamical analysis, we provide a feasible\nroute to experimentally synthesize this material via the known LiAu and LiH\ncompounds under ambient pressure. The further first-principles calculations\nsuggest that Li$_2$AuH$_6$ shows a high superconducting transition temperature\n($T_c$) $\\sim$ 140 K under ambient pressure. The H-1$s$ electrons strongly\ncouple with phonon modes of vibrations of Au-H octahedrons as well as\nvibrations of Li atoms, where the latter is not taken seriously in other\npreviously similar cases. Hence, different from previous claims of searching\nmetallic covalent bonds to find high-$T_c$ superconductors, we emphasize here\nthe importance of those phonon modes with strong electron-phonon coupling\n(EPC). And we suggest that one can intercalate atoms into binary or ternary\nhydrides to introduce more potential phonon modes with strong EPC, which is an\neffective approach to find high-$T_c$ superconductors within multicomponent\ncompounds."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con",
        "cs.AI",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-214",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06314",
    "b_title":[
      "Observation of Two Cascading Screening Processes in an Iron-based\n  Superconductor"
    ],
    "b_abstract":[
      "Understanding how renormalized quasiparticles emerge in strongly correlated\nelectron materials provides a challenge for both experiment and theory. It has\nbeen predicted that distinctive spin and orbital screening mechanisms drive\nthis process in multiorbital materials with strong Coulomb and Hund's\ninteractions. Here, we provide the experimental evidence of both mechanisms\nfrom angle-resolved photoemission spectroscopy on RbFe$_2$As$_2$. We observe\nthat the emergence of low-energy Fe 3$d_{xy}$ quasiparticles below 90K is tied\nto spin screening. A second process changes the spectral weight at high\nenergies up to room temperature. Supported by theoretical calculations we\nattribute it to orbital screening of Fe 3d atomic excitations. These two\ncascading screening processes drive the temperature evolution from a bad metal\nto a correlated Fermi liquid."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01100",
    "c_title":[
      "Long-range Brain Graph Transformer"
    ],
    "c_abstract":[
      "Understanding communication and information processing among brain regions of\ninterest (ROIs) is highly dependent on long-range connectivity, which plays a\ncrucial role in facilitating diverse functional neural integration across the\nentire brain. However, previous studies generally focused on the short-range\ndependencies within brain networks while neglecting the long-range\ndependencies, limiting an integrated understanding of brain-wide communication.\nTo address this limitation, we propose Adaptive Long-range aware TransformER\n(ALTER), a brain graph transformer to capture long-range dependencies between\nbrain ROIs utilizing biased random walk. Specifically, we present a novel\nlong-range aware strategy to explicitly capture long-range dependencies between\nbrain ROIs. By guiding the walker towards the next hop with higher correlation\nvalue, our strategy simulates the real-world brain-wide communication.\nFurthermore, by employing the transformer framework, ALERT adaptively\nintegrates both short- and long-range dependencies between brain ROIs, enabling\nan integrated understanding of multi-level communication across the entire\nbrain. Extensive experiments on ABIDE and ADNI datasets demonstrate that ALTER\nconsistently outperforms generalized state-of-the-art graph learning methods\n(including SAN, Graphormer, GraphTrans, and LRGNN) and other graph learning\nbased brain network analysis methods (including FBNETGEN, BrainNetGNN,\nBrainGNN, and BrainNETTF) in neurological disease diagnosis. Cases of\nlong-range dependencies are also presented to further illustrate the\neffectiveness of ALTER. The implementation is available at\nhttps:\/\/github.com\/yushuowiki\/ALTER."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-215",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07358",
    "b_title":[
      "Deep Generative Clustering with VAEs and Expectation-Maximization"
    ],
    "b_abstract":[
      "We propose a novel deep clustering method that integrates Variational\nAutoencoders (VAEs) into the Expectation-Maximization (EM) framework. Our\napproach models the probability distribution of each cluster with a VAE and\nalternates between updating model parameters by maximizing the Evidence Lower\nBound (ELBO) of the log-likelihood and refining cluster assignments based on\nthe learned distributions. This enables effective clustering and generation of\nnew samples from each cluster. Unlike existing VAE-based methods, our approach\neliminates the need for a Gaussian Mixture Model (GMM) prior or additional\nregularization techniques. Experiments on MNIST and FashionMNIST demonstrate\nsuperior clustering performance compared to state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.08709",
    "c_title":[
      "Constraining Axion Dark Matter with Galactic-Centre Resonant Dynamics"
    ],
    "c_abstract":[
      "We study the influence of axion dark-matter cores on the orbits of stars at\nthe Galactic centre. This dark matter candidate condenses into dense, solitonic\ncores, and, if a super-massive black hole is present at the centre of such a\ncore, its central part forms a 'gravitational atom'. Here, we calculate the\natom's contribution to the gravitational potential felt by a Galactic-centre\nstar, for a generic quantum state of the atom. We study the angular-momentum\ndynamics this potential induces, and show that it is similar to vector resonant\nrelaxation. Its influence is found to be sufficiently strong that such a\ndynamical component should be accounted for in Galactic-centre modelling. For\nthe Milky Way, the atom is expected to have some spherical asymmetry, and we\nuse this to derive a stability condition for the disc of young, massive stars\nat the Galactic centre - if the atom's mass is too large, then the disc would\nbe destroyed. Thus, the existence of this disc constrains the mass of the axion\nparticles comprising the solitonic core; for plausible parameter values, such a\ncore is found to be in tension with the existence of the clockwise stellar disc\nat $2\\sigma$ for $4.4\\times 10^{-20}\\,\\textrm{eV} \\leq m_a \\leq 5.3\\times\n10^{-20}\\,\\textrm{eV}$. These constraints will tighten significantly with\nfuture, improved data."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-216",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00392",
    "b_title":[
      "RefDrone: A Challenging Benchmark for Referring Expression Comprehension\n  in Drone Scenes"
    ],
    "b_abstract":[
      "Drones have become prevalent robotic platforms with diverse applications,\nshowing significant potential in Embodied Artificial Intelligence (Embodied\nAI). Referring Expression Comprehension (REC) enables drones to locate objects\nbased on natural language expressions, a crucial capability for Embodied AI.\nDespite advances in REC for ground-level scenes, aerial views introduce unique\nchallenges including varying viewpoints, occlusions and scale variations. To\naddress this gap, we introduce RefDrone, a REC benchmark for drone scenes.\nRefDrone reveals three key challenges in REC: 1) multi-scale and small-scale\ntarget detection; 2) multi-target and no-target samples; 3) complex environment\nwith rich contextual expressions. To efficiently construct this dataset, we\ndevelop RDAgent (referring drone annotation framework with multi-agent system),\na semi-automated annotation tool for REC tasks. RDAgent ensures high-quality\ncontextual expressions and reduces annotation cost. Furthermore, we propose\nNumber GroundingDINO (NGDINO), a novel method designed to handle multi-target\nand no-target cases. NGDINO explicitly learns and utilizes the number of\nobjects referred to in the expression. Comprehensive experiments with\nstate-of-the-art REC methods demonstrate that NGDINO achieves superior\nperformance on both the proposed RefDrone and the existing gRefCOCO datasets.\nThe dataset and code will be publicly at\nhttps:\/\/github.com\/sunzc-sunny\/refdrone."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20185",
    "c_title":[
      "Love numbers beyond GR from the modified Teukolsky equation"
    ],
    "c_abstract":[
      "We obtain the full set of tidal Love numbers of non-rotating black holes in\nan effective field theory extension of general relativity. We achieve our\nresults using a recently introduced modified Teukolsky equation that describes\nthe perturbations of black holes in this theory. We show how to identify the\nLove numbers and their beta functions in a systematic and gauge invariant way,\napplying analytic continuation on the angular number $\\ell$ when necessary. We\nobserve that there are three types of Love numbers: electric, magnetic, and a\n``mixing'' type, associated to parity-breaking theories, that we identify here\nfor the first time. The modified Teukolsky equation proves to be very useful as\nit allows us to obtain all the different Love numbers in a unified framework.\nWe compare our results with previous literature that utilized the\nRegge-Wheeler-Zerilli equations to compute Love numbers, finding perfect\nagreement. The method introduced here paves the way towards the computation of\nLove numbers of rotating black holes beyond general relativity."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-217",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03656",
    "b_title":[
      "A Study in Dataset Distillation for Image Super-Resolution"
    ],
    "b_abstract":[
      "Dataset distillation is the concept of condensing large datasets into smaller\nbut highly representative synthetic samples. While previous research has\nprimarily focused on image classification, its application to image\nSuper-Resolution (SR) remains underexplored. This exploratory work studies\nmultiple dataset distillation techniques applied to SR, including pixel- and\nlatent-space approaches under different aspects. Our experiments demonstrate\nthat a 91.12% dataset size reduction can be achieved while maintaining\ncomparable SR performance to the full dataset. We further analyze\ninitialization strategies and distillation methods to optimize memory\nefficiency and computational costs. Our findings provide new insights into\ndataset distillation for SR and set the stage for future advancements."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00726",
    "c_title":[
      "Enhancing Unsupervised Feature Selection via Double Sparsity Constrained\n  Optimization"
    ],
    "c_abstract":[
      "Unsupervised feature selection (UFS) is widely applied in machine learning\nand pattern recognition. However, most of the existing methods only consider a\nsingle sparsity, which makes it difficult to select valuable and discriminative\nfeature subsets from the original high-dimensional feature set. In this paper,\nwe propose a new UFS method called DSCOFS via embedding double sparsity\nconstrained optimization into the classical principal component analysis (PCA)\nframework. Double sparsity refers to using $\\ell_{2,0}$-norm and $\\ell_0$-norm\nto simultaneously constrain variables, by adding the sparsity of different\ntypes, to achieve the purpose of improving the accuracy of identifying\ndifferential features. The core is that $\\ell_{2,0}$-norm can remove irrelevant\nand redundant features, while $\\ell_0$-norm can filter out irregular noisy\nfeatures, thereby complementing $\\ell_{2,0}$-norm to improve discrimination. An\neffective proximal alternating minimization method is proposed to solve the\nresulting nonconvex nonsmooth model. Theoretically, we rigorously prove that\nthe sequence generated by our method globally converges to a stationary point.\nNumerical experiments on three synthetic datasets and eight real-world datasets\ndemonstrate the effectiveness, stability, and convergence of the proposed\nmethod. In particular, the average clustering accuracy (ACC) and normalized\nmutual information (NMI) are improved by at least 3.34% and 3.02%,\nrespectively, compared with the state-of-the-art methods. More importantly, two\ncommon statistical tests and a new feature similarity metric verify the\nadvantages of double sparsity. All results suggest that our proposed DSCOFS\nprovides a new perspective for feature selection."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-218",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15246",
    "b_title":[
      "Variational Message Passing-based Multiobject Tracking for MIMO-Radars\n  using Raw Sensor Signals"
    ],
    "b_abstract":[
      "In this paper, we propose a direct multiobject tracking (MOT) approach for\nMIMO-radar signals that operates on raw sensor data via variational message\npassing (VMP). Unlike classical track-before-detect (TBD) methods, which often\nrely on simplified likelihood models and exclude nuisance parameters (e.g.,\nobject amplitudes, noise variance), our method adopts a superimposed signal\nmodel and employs a mean-field approximation to jointly estimate both object\nexistence and object states. By considering correlations within in the radar\nsignal due to closely spaced objects and jointly estimating nuisance\nparameters, the proposed method achieves robust performance for close-by\nobjects and in low-signal-to-noise ratio (SNR) regimes. Our numerical\nevaluation based on MIMO-radar signals demonstrate that our VMP-based\ndirect-MOT method outperforms a detect-then-track (DTT) pipeline comprising a\nsuper-resolution sparse Bayesian learning (SBL)-based estimation stage followed\nby classical MOT using global nearest neighbour data association and a Kalman\nfilter."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04840",
    "c_title":[
      "Coherent Local Explanations for Mathematical Optimization"
    ],
    "c_abstract":[
      "The surge of explainable artificial intelligence methods seeks to enhance\ntransparency and explainability in machine learning models. At the same time,\nthere is a growing demand for explaining decisions taken through complex\nalgorithms used in mathematical optimization. However, current explanation\nmethods do not take into account the structure of the underlying optimization\nproblem, leading to unreliable outcomes. In response to this need, we introduce\nCoherent Local Explanations for Mathematical Optimization (CLEMO). CLEMO\nprovides explanations for multiple components of optimization models, the\nobjective value and decision variables, which are coherent with the underlying\nmodel structure. Our sampling-based procedure can provide explanations for the\nbehavior of exact and heuristic solution algorithms. The effectiveness of CLEMO\nis illustrated by experiments for the shortest path problem, the knapsack\nproblem, and the vehicle routing problem."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-219",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13806",
    "b_title":[
      "Organ-aware Multi-scale Medical Image Segmentation Using Text Prompt\n  Engineering"
    ],
    "b_abstract":[
      "Accurate segmentation is essential for effective treatment planning and\ndisease monitoring. Existing medical image segmentation methods predominantly\nrely on uni-modal visual inputs, such as images or videos, requiring\nlabor-intensive manual annotations. Additionally, medical imaging techniques\ncapture multiple intertwined organs within a single scan, further complicating\nsegmentation accuracy. To address these challenges, MedSAM, a large-scale\nmedical segmentation model based on the Segment Anything Model (SAM), was\ndeveloped to enhance segmentation accuracy by integrating image features with\nuser-provided prompts. While MedSAM has demonstrated strong performance across\nvarious medical segmentation tasks, it primarily relies on geometric prompts\n(e.g., points and bounding boxes) and lacks support for text-based prompts,\nwhich could help specify subtle or ambiguous anatomical structures. To overcome\nthese limitations, we propose the Organ-aware Multi-scale Text-guided Medical\nImage Segmentation Model (OMT-SAM) for multi-organ segmentation. Our approach\nintroduces CLIP encoders as a novel image-text prompt encoder, operating with\nthe geometric prompt encoder to provide informative contextual guidance. We\npair descriptive textual prompts with corresponding images, processing them\nthrough pre-trained CLIP encoders and a cross-attention mechanism to generate\nfused image-text embeddings. Additionally, we extract multi-scale visual\nfeatures from MedSAM, capturing fine-grained anatomical details at different\nlevels of granularity. We evaluate OMT-SAM on the FLARE 2021 dataset,\nbenchmarking its performance against existing segmentation methods. Empirical\nresults demonstrate that OMT-SAM achieves a mean Dice Similarity Coefficient of\n0.937, outperforming MedSAM (0.893) and other segmentation models, highlighting\nits superior capability in handling complex medical image segmentation tasks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18351",
    "c_title":[
      "Fitting multivariate Hawkes processes to interval count data with an\n  application to terrorist activity modelling -- a particle Markov chain Monte\n  Carlo approach"
    ],
    "c_abstract":[
      "Terrorist activities often exhibit temporal and spatial clustering, making\nthe multivariate Hawkes process (MHP) a useful statistical model for analysing\nterrorism across different geographic regions. However, terror attack data from\nthe Global Terrorism Database is reported as total event counts in disjoint\nobservation periods, with precise event times unknown. When the MHP is only\nobserved discretely, the likelihood function becomes intractable, hindering\nlikelihood-based inference. To address this, we design an unbiased estimate of\nthe intractable likelihood function using sequential Monte Carlo (SMC) based on\na representation of the unobserved event times as latent variables in a\nstate-space model. The unbiasedness of the SMC estimate allows for its use in\nplace of the true likelihood in a Metropolis-Hastings algorithm, from which we\nconstruct a Markov Chain Monte Carlo sample of the distribution over the\nparameters of the MHP. Using simulated data, we assess the performance of our\nmethod and demonstrate that it outperforms an alternative method in the\nliterature based on mean squared error. Terrorist activity in Afghanistan and\nPakistan from 2018 to 2021 is analysed based on daily count data to examine the\nself- and cross-excitation effects of terrorism events."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-220",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04164",
    "b_title":[
      "Efficient Distributed Optimization under Heavy-Tailed Noise"
    ],
    "b_abstract":[
      "Distributed optimization has become the default training paradigm in modern\nmachine learning due to the growing scale of models and datasets. To mitigate\ncommunication overhead, local updates are often applied before global\naggregation, resulting in a nested optimization approach with inner and outer\nsteps. However, heavy-tailed stochastic gradient noise remains a significant\nchallenge, particularly in attention-based models, hindering effective\ntraining. In this work, we propose TailOPT, an efficient framework designed to\naddress heavy-tailed noise by leveraging adaptive optimization or clipping\ntechniques. We establish convergence guarantees for the TailOPT framework under\nheavy-tailed noise with potentially unbounded gradient variance and local\nupdates. Among its variants, we highlight a memory and communication efficient\ninstantiation which we call $Bi^2Clip$, which performs coordinate-wise clipping\nat both the inner and outer optimizers, achieving adaptive-like performance\n(e.g., Adam) without the cost of maintaining or transmitting additional\ngradient statistics. Empirically, TailOPT, including $Bi^2Clip$, demonstrates\nsuperior performance on several language tasks and models, outperforming\nstate-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13496",
    "c_title":[
      "Quasinormal Modes, Grebody Factors, and Hawking Radiation Sparsity of\n  Black Holes Influenced by a Global Monopole Charge in Kalb-Ramond Gravity"
    ],
    "c_abstract":[
      "Kalb-Ramond (KR) gravity is an intriguing model incorporating local Lorentz\nviolation, and black hole (BH) solutions are known to exist. In this study, we\ninvestigate some crucial aspects of BHs endowed with a global monopole charge\nin the self-interacting KR field. Specifically, we study the quasinormal modes\n(QNMs) corresponding to scalar, electromagnetic, and gravitational\nperturbations; derive rigorous bounds for the greybody factors (GBFs); and\nexamine the sparsity of Hawking radiation. The effects of the model parameters\n$\\ell$ (Lorentz-violating parameter in KR gravity) and $\\eta$ (monopole charge)\non these phenomena are elaborated. First, QNMs are evaluated with high\nprecision using the 13\\textsuperscript{th}-order Pad\\'{e}-averaged WKB method\nand cross-examined via time-domain analyses within an acceptable parameter\nspace. The results show that the estimated QNMs are more sensitive to $\\ell$;\nhowever, both model parameters influence the frequency spectra. The derived\nbounds on the GBFs aid in further constraining the parameter space. It is shown\nthat $\\ell$ and $\\eta$ have a similar effect on the greybody bounds.\nFurthermore, positive and negative values of $\\ell$ have opposing effects in\nthat the bounds are reversed for the two cases. The analyses of the Hawking\nradiation sparsity highlight the effect of $\\ell$, and two scenarios are noted:\neither the radiation emitted is less sparse than Hawking radiation, or it is\nmore sparse during the evaporation phase. Thus, this work presents a\ncomprehensive account of BHs in KR gravity with a global monopole charge."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-221",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16639",
    "b_title":[
      "Whenever, Wherever: Towards Orchestrating Crowd Simulations with\n  Spatio-Temporal Spawn Dynamics"
    ],
    "b_abstract":[
      "Realistic crowd simulations are essential for immersive virtual environments,\nrelying on both individual behaviors (microscopic dynamics) and overall crowd\npatterns (macroscopic characteristics). While recent data-driven methods like\ndeep reinforcement learning improve microscopic realism, they often overlook\ncritical macroscopic features such as crowd density and flow, which are\ngoverned by spatio-temporal spawn dynamics, namely, when and where agents enter\na scene. Traditional methods, like random spawn rates, stochastic processes, or\nfixed schedules, are not guaranteed to capture the underlying complexity or\nlack diversity and realism. To address this issue, we propose a novel approach\ncalled nTPP-GMM that models spatio-temporal spawn dynamics using Neural\nTemporal Point Processes (nTPPs) that are coupled with a spawn-conditional\nGaussian Mixture Model (GMM) for agent spawn and goal positions. We evaluate\nour approach by orchestrating crowd simulations of three diverse real-world\ndatasets with nTPP-GMM. Our experiments demonstrate the orchestration with\nnTPP-GMM leads to realistic simulations that reflect real-world crowd scenarios\nand allow crowd analysis."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17476",
    "c_title":[
      "Hybrid Channel- and Coding-Based Challenge-Response Physical-Layer\n  Authentication"
    ],
    "c_abstract":[
      "This letter proposes a new physical layer authentication mechanism operating\nat the physical layer of a communication system where the receiver has partial\ncontrol of the channel conditions (e.g., using an intelligent reflecting\nsurface). We aim to exploit both instantaneous channel state information (CSI)\nand a secret shared key for authentication. This is achieved by both\ntransmitting an identifying key by wiretap coding (to conceal the key from the\nattacker) and checking that the instantaneous CSI corresponds to the channel\nconfiguration randomly selected by the receiver. We investigate the trade-off\nbetween the pilot signals used for CSI estimation and the coding rate (or key\nlength) to improve the overall security of the authentication procedure."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-222",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12624",
    "b_title":[
      "Implicit Repair with Reinforcement Learning in Emergent Communication"
    ],
    "b_abstract":[
      "Conversational repair is a mechanism used to detect and resolve\nmiscommunication and misinformation problems when two or more agents interact.\nOne particular and underexplored form of repair in emergent communication is\nthe implicit repair mechanism, where the interlocutor purposely conveys the\ndesired information in such a way as to prevent misinformation from any other\ninterlocutor. This work explores how redundancy can modify the emergent\ncommunication protocol to continue conveying the necessary information to\ncomplete the underlying task, even with additional external environmental\npressures such as noise. We focus on extending the signaling game, called the\nLewis Game, by adding noise in the communication channel and inputs received by\nthe agents. Our analysis shows that agents add redundancy to the transmitted\nmessages as an outcome to prevent the negative impact of noise on the task\nsuccess. Additionally, we observe that the emerging communication protocol's\ngeneralization capabilities remain equivalent to architectures employed in\nsimpler games that are entirely deterministic. Additionally, our method is the\nonly one suitable for producing robust communication protocols that can handle\ncases with and without noise while maintaining increased generalization\nperformance levels."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16661",
    "c_title":[
      "Voltage Noise Thermometry in Integrated Circuits at Millikelvin\n  Temperatures"
    ],
    "c_abstract":[
      "This paper demonstrates the use of voltage noise thermometry, with a\ncross-correlation technique, as a dissipation-free method of thermometry inside\na CMOS integrated circuit (IC). We show that this technique exhibits broad\nagreement with the refrigerator temperature range from 300 mK to 8 K.\nFurthermore, it shows substantial agreement with both an independent in-IC\nthermometry technique and a simple thermal model as a function of power\ndissipation inside the IC. As the device under test (DUT) is a resistor, it is\nfeasible to extend this technique by placing many resistors in an IC to monitor\nthe local temperatures, without increasing IC design complexity. This could\nlead to better understanding of the thermal profile of ICs at cryogenic\ntemperatures. This has its greatest potential application in quantum computing,\nwhere the temperature at the cold classical-quantum boundary must be carefully\ncontrolled to maintain qubit performance."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-223",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09559",
    "b_title":[
      "Threshold Quantum Secret Sharing"
    ],
    "b_abstract":[
      "One crucial and basic method for disclosing a secret to every participant in\nquantum cryptography is quantum secret sharing. Numerous intricate protocols,\nincluding secure multiparty summation, multiplication, sorting, voting, and\nmore, can be designed with it. A quantum secret sharing protocol with a $(t,n)$\nthreshold approach and modulo d, where t and n represent the threshold number\nof participants and the total number of participants, respectively was recently\ndiscussed by Song et al. Kao et al. notes that without the information of other\nparticipants, the secret in Song {\\em et al.'s}protocol cannot be\nreconstructed. We address a protocol that solves this issue in this paper."
    ],
    "b_categories":[
      [
        "cs.CR",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09446",
    "c_title":[
      "Drivers of cooperation in social dilemmas on higher-order networks"
    ],
    "c_abstract":[
      "Understanding cooperation in social dilemmas requires models that capture the\ncomplexity of real-world interactions. While network frameworks have provided\nvaluable insights to model the evolution of cooperation, they are unable to\nencode group interactions properly. Here, we introduce a general higher-order\nnetwork framework for multi-player games on structured populations. Our model\nconsiders multi-dimensional strategies, based on the observation that social\nbehaviours are affected by the size of the group interaction. We investigate\ndynamical and structural coupling between different orders of interactions,\nrevealing the crucial role of nested multilevel interactions, and showing how\nsuch features can enhance cooperation beyond the limit of traditional models\nwith uni-dimensional strategies. Our work identifies the key drivers promoting\ncooperative behaviour commonly observed in real-world group social dilemmas."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.SI",
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-224",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13606",
    "b_title":[
      "LaVCa: LLM-assisted Visual Cortex Captioning"
    ],
    "b_abstract":[
      "Understanding the property of neural populations (or voxels) in the human\nbrain can advance our comprehension of human perceptual and cognitive\nprocessing capabilities and contribute to developing brain-inspired computer\nmodels. Recent encoding models using deep neural networks (DNNs) have\nsuccessfully predicted voxel-wise activity. However, interpreting the\nproperties that explain voxel responses remains challenging because of the\nblack-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex\nCaptioning (LaVCa), a data-driven approach that uses large language models\n(LLMs) to generate natural-language captions for images to which voxels are\nselective. By applying LaVCa for image-evoked brain activity, we demonstrate\nthat LaVCa generates captions that describe voxel selectivity more accurately\nthan the previously proposed method. Furthermore, the captions generated by\nLaVCa quantitatively capture more detailed properties than the existing method\nat both the inter-voxel and intra-voxel levels. Furthermore, a more detailed\nanalysis of the voxel-specific properties generated by LaVCa reveals\nfine-grained functional differentiation within regions of interest (ROIs) in\nthe visual cortex and voxels that simultaneously represent multiple distinct\nconcepts. These findings offer profound insights into human visual\nrepresentations by assigning detailed captions throughout the visual cortex\nwhile highlighting the potential of LLM-based methods in understanding brain\nrepresentations. Please check out our webpage at\nhttps:\/\/sites.google.com\/view\/lavca-llm\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06499",
    "c_title":[
      "ExGes: Expressive Human Motion Retrieval and Modulation for Audio-Driven\n  Gesture Synthesis"
    ],
    "c_abstract":[
      "Audio-driven human gesture synthesis is a crucial task with broad\napplications in virtual avatars, human-computer interaction, and creative\ncontent generation. Despite notable progress, existing methods often produce\ngestures that are coarse, lack expressiveness, and fail to fully align with\naudio semantics. To address these challenges, we propose ExGes, a novel\nretrieval-enhanced diffusion framework with three key designs: (1) a Motion\nBase Construction, which builds a gesture library using training dataset; (2) a\nMotion Retrieval Module, employing constrative learning and momentum\ndistillation for fine-grained reference poses retreiving; and (3) a Precision\nControl Module, integrating partial masking and stochastic masking to enable\nflexible and fine-grained control. Experimental evaluations on BEAT2\ndemonstrate that ExGes reduces Fr\\'echet Gesture Distance by 6.2\\% and improves\nmotion diversity by 5.3\\% over EMAGE, with user studies revealing a 71.3\\%\npreference for its naturalness and semantic relevance. Code will be released\nupon acceptance."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-225",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03618",
    "b_title":[
      "The Logical Implication Steering Method for Conditional Interventions on\n  Transformer Generation"
    ],
    "b_abstract":[
      "The field of mechanistic interpretability in pre-trained transformer models\nhas demonstrated substantial evidence supporting the ''linear representation\nhypothesis'', which is the idea that high level concepts are encoded as vectors\nin the space of activations of a model. Studies also show that model generation\nbehavior can be steered toward a given concept by adding the concept's vector\nto the corresponding activations. We show how to leverage these properties to\nbuild a form of logical implication into models, enabling transparent and\ninterpretable adjustments that induce a chosen generation behavior in response\nto the presence of any given concept. Our method, Logical Implication Model\nSteering (LIMS), unlocks new hand engineered reasoning capabilities by\nintegrating neuro-symbolic logic into pre-trained transformer models."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00987",
    "c_title":[
      "Probability of Transition to Turbulence in a Reduced Stochastic Model of\n  Pipe Flow"
    ],
    "c_abstract":[
      "We study the phenomenon of turbulence initiation in pipe flow under different\nnoise structures by estimating the probability of initiating metastable\ntransitions. We establish lower bounds on turbulence transition probabilities\nusing linearized models with multiplicative noise near the laminar state.\nFirst, we consider the case of stochastic perturbations by It\\^o white noise;\nthen, through the Stratonovich interpretation, we extend the analysis to noise\ntypes such as white and red noise in time. Our findings demonstrate the\nviability of detecting the onset of turbulence as rare events under diverse\nnoise assumptions. The results also contribute to applied SPDE theory and offer\nvaluable methodologies for understanding turbulence across application areas."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-226",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09905",
    "b_title":[
      "Towards personalised assessment of abdominal aortic aneurysm structural\n  integrity"
    ],
    "b_abstract":[
      "Abdominal aortic aneurysm (AAA) is a life-threatening condition involving the\npermanent dilation of the aorta, often detected incidentally through imaging\nfor some other condition. The standard clinical approach to managing AAA\nfollows a one-size-fits-all model based on aneurysm size and growth rate,\nleading to underestimation or overestimation of rupture risk in individual\npatients. The widely studied stress-based rupture risk estimation using\ncomputational biomechanics requires wall strength information. However,\nnon-invasive methods for local patient-specific wall strength measurement have\nnot yet been developed. Recently, we introduced an image-based approach for\npatient-specific, in vivo, non-invasive AAA kinematic analysis using\ntime-resolved 3D computed tomography angiography (4D-CTA) images to measure\nwall strain throughout the cardiac cycle. In the present study, we integrated\nwall tension computation and strain measurement to develop a novel measure of\nlocal structural integrity of AAA wall - Relative Structural Integrity Index\n(RSII), independent of material properties and thickness of the wall and\nconditions of blood pressure measurement. Our methods provide a visual map of\nAAA wall structural integrity for individual patients using only their medical\nimages and blood pressure data. We applied our methods to twelve patients.\nAdditionally, we compared our measure of structural integrity of aneurysmal and\nnon-aneurysmal aortas. Our results show similar values of the wall structural\nintegrity measure across the patients, indicating the reliability of our\nmethods. In line with experimental observations reported in the literature, our\nanalysis revealed that localized low stiffness areas are primarily found in the\nmost dilated AAA regions. Our results clearly demonstrate that the AAA wall is\nstiffer than the non-aneurysmal aorta."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10796",
    "c_title":[
      "Outlier eigenvalues for full rank deformed single ring random matrices"
    ],
    "c_abstract":[
      "Let $A_n$ be an $n \\times n$ deterministic matrix and $\\Sigma_n$ be a\ndeterministic non-negative matrix such that $A_n$ and $\\Sigma_n$ converge in\n$*$-moments to operators $a$ and $\\Sigma$ respectively in some\n$W^*$-probability space. We consider the full rank deformed model $A_n + U_n\n\\Sigma_n V_n,$ where $U_n$ and $V_n$ are independent Haar-distributed random\nunitary matrices. In this paper, we investigate the eigenvalues of $A_n +\nU_n\\Sigma_n V_n$ in two domains that are outside the support of the Brown\nmeasure of $a +u \\Sigma$. We give a sufficient condition to guarantee that\noutliers are stable in one domain, and we also prove that there are no outliers\nin the other domain. When $A_n$ has a bounded rank, the first domain is exactly\nthe one outside the outer boundary of the single ring, and the second domain is\nthe inner disk of the single ring. Our results generalize the results of\nBenaych-Georges and Rochet (Probab. Theory Relat. Fields, 2016)."
    ],
    "c_categories":[
      [
        "math.OA",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-227",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07019",
    "b_title":[
      "Coupled poro-elastic behavior of hyper-elastic membranes"
    ],
    "b_abstract":[
      "This study investigates the coupled deformation and flow behavior through\nthin, hyper-elastic, porous membranes subjected to pressure loading. Using\nbulge test experiments, optical deformation measurements, and flow rate\ncharacterization, we analyze the structural and fluid dynamic responses of\nmembranes with varying material stiffness and porosity patterns. A\ntwo-parameter Gent model captures the hyper-elastic deformation, while local\nstretch analyses reveal the evolution of pore sizes across the membrane. We\nfind that membrane stretch is primarily governed by material stiffness and\napplied pressure, independent of porosity. A gradient of increasing pore size\ntoward the membrane center emerges due to higher local stretch, while the total\nopen pore area remains approximately constant across radial layers of the\nmembrane. Flow rate scaling is characterized using a discharge coefficient that\naccounts for pore area expansion and pressure losses. While the initial scaling\ncompares well in most cases, it breaks down for scenarios with significantly\ndifferent pore Reynolds numbers, driven by large variations in initial\nporosity. To address this, we introduce a Reynolds-dependent correction term\nthat unifies discharge coefficient predictions across diverse porosity and flow\nvelocity conditions. These findings enhance the understanding of poro-elastic\nsystems and provide robust scaling relationships for designing thin, flexible,\nporous structures in applications such as bio-inspired aerodynamic systems and\nadaptive flow regulation devices."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01543",
    "c_title":[
      "Exo-ViHa: A Cross-Platform Exoskeleton System with Visual and Haptic\n  Feedback for Efficient Dexterous Skill Learning"
    ],
    "c_abstract":[
      "Imitation learning has emerged as a powerful paradigm for robot skills\nlearning. However, traditional data collection systems for dexterous\nmanipulation face challenges, including a lack of balance between acquisition\nefficiency, consistency, and accuracy. To address these issues, we introduce\nExo-ViHa, an innovative 3D-printed exoskeleton system that enables users to\ncollect data from a first-person perspective while providing real-time haptic\nfeedback. This system combines a 3D-printed modular structure with a slam\ncamera, a motion capture glove, and a wrist-mounted camera. Various dexterous\nhands can be installed at the end, enabling it to simultaneously collect the\nposture of the end effector, hand movements, and visual data. By leveraging the\nfirst-person perspective and direct interaction, the exoskeleton enhances the\ntask realism and haptic feedback, improving the consistency between\ndemonstrations and actual robot deployments. In addition, it has cross-platform\ncompatibility with various robotic arms and dexterous hands. Experiments show\nthat the system can significantly improve the success rate and efficiency of\ndata collection for dexterous manipulation tasks."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-228",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07126",
    "b_title":[
      "Decision theory and the \"almost implies near\" phenomenon"
    ],
    "b_abstract":[
      "We propose to relax traditional axioms in decision theory by incorporating a\nmeasurement, or degree, of satisfaction. For example, if the independence axiom\nof expected utility theory is violated, we can measure the size of the\nviolation. This measure allows us to derive an approximation guarantee for a\nutility representation that aligns with the unmodified version of the axiom.\nAlmost satisfying the axiom implies, then, a utility that is near a utility\nrepresentation. We develop specific examples drawn from expected utility theory\nunder risk and uncertainty."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.06073",
    "c_title":[
      "The interplay of user preference and precision in different gaze-based\n  interaction methods"
    ],
    "c_abstract":[
      "In this study, we investigated gaze-based interaction methods within a\nvirtual reality game with a visual search task with 52 participants. We\ncompared four different interaction techniques: Selection by dwell time or\nconfirmation of selection by head orientation, nodding or smooth pursuit eye\nmovements. We evaluated both subjective and objective performance metrics,\nincluding NASA-TLX for subjective task load as well as time to find the correct\ntargets and points achieved for objective analysis. The results showed\nsignificant differences between the interaction methods in terms of NASA TLX\ndimensions, time to find the right targets, and overall performance scores,\nsuggesting differential effectiveness of gaze-based approaches in improving\nintuitive system communication. Interestingly, the results revealed\ngender-specific differences, suggesting interesting implications for the design\nof gaze-based interaction paradigms that are optimized for different user needs\nand preferences. These findings could help to develop more customized and\neffective gaze interaction systems that can improve accessibility and user\nsatisfaction."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-229",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04162",
    "b_title":[
      "The Eisenstein ideal at prime-square level has constant rank"
    ],
    "b_abstract":[
      "Let $N$ and $p$ be prime numbers with $p \\geq 5$ such that $p || (N + 1)$. In\na previous paper, we showed that there is a cuspform $f$ of weight 2 and level\n$\\Gamma_0(N^2)$ whose $\\ell$-th Fourier coefficient is congruent to $\\ell + 1$\nmodulo a prime above $p$ for all primes $\\ell$. In this paper, we prove that\nthis form $f$ is unique up to Galois conjugacy, and the extension of\n$\\mathbb{Z}_p$ generated by the coefficients of $f$ is exactly\n$\\mathbb{Z}_p[\\zeta_p + \\zeta_p^{-1}]$. We also prove similar results when a\nhigher power of $p$ divides $N + 1$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07880",
    "c_title":[
      "The Impact of Digitalisation and Sustainability on Inclusiveness:\n  Inclusive Growth Determinants"
    ],
    "c_abstract":[
      "Inclusiveness and economic development have been slowed by the pandemics and\nmilitary conflicts. This study investigates the main determinants of\ninclusiveness at the European level. A multi-method approach is used, with\nPrincipal Component Analysis (PCA) applied to create the Inclusiveness Index\nand Generalised Method of Moments (GMM) analysis used to investigate the\ndeterminants of inclusiveness. The data comprises a range of 22 years, from\n2000 to 2021, for 32 European countries. The determinants of inclusiveness and\ntheir effects were identified. First, economic growth, industrial upgrading,\nelectricity consumption, digitalisation, and the quantitative aspect of\ngovernance, all have a positive impact on inclusive growth in Europe. Second,\nthe level of CO2 emissions and inflation have a negative impact on\ninclusiveness. Tomorrow's inclusive and sustainable growth must include\ninvestments in renewable energy, digital infrastructure, inequality policies,\nsustainable governance, human capital, and inflation management. These findings\ncan help decision makers design inclusive growth policies."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-230",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13568",
    "b_title":[
      "WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot\n  Positioning"
    ],
    "b_abstract":[
      "Autonomous mobile robots are widely used for navigation, transportation, and\ninspection tasks indoors and outdoors. In practical situations of limited\nsatellite signals or poor lighting conditions, navigation depends only on\ninertial sensors. In such cases, the navigation solution rapidly drifts due to\ninertial measurement errors. In this work, we propose WMINet a wheel-mounted\ninertial deep learning approach to estimate the mobile robot's position based\nonly on its inertial sensors. To that end, we merge two common practical\nmethods to reduce inertial drift: a wheel-mounted approach and driving the\nmobile robot in periodic trajectories. Additionally, we enforce a wheelbase\nconstraint to further improve positioning performance. To evaluate our proposed\napproach we recorded using the Rosbot-XL a wheel-mounted initial dataset\ntotaling 190 minutes, which is made publicly available. Our approach\ndemonstrated a 66\\% improvement over state-of-the-art approaches. As a\nconsequence, our approach enables navigation in challenging environments and\nbridges the pure inertial gap. This enables seamless robot navigation using\nonly inertial sensors for short periods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03369",
    "c_title":[
      "Symmetry-Preserving Finite-Difference Schemes and Auto-B\\\"acklund\n  Transformations for the Schwarz Equation"
    ],
    "c_abstract":[
      "It is demonstrated that one of the equations from the Lie classification list\nof second-order ODEs is a first integral of the Schwarz equation. As\nsymmetry-preserving finite-difference schemes have been previously constructed\nfor both equations, the preservation of a similar connection between these\nschemes is studied. It is shown that the schemes for the Schwarz equation and\nthe second-order ODE can be related through a B\\\"acklund-type difference\ntransformation. In addition, previously unexamined aspects of the difference\nscheme for the second-order ODE are discussed, including its singular solution\nand the complete set of difference first integrals for the case $C^2=4$."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-231",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01854",
    "b_title":[
      "On extending the class of convex functions"
    ],
    "b_abstract":[
      "In this brief note, it is shown that the function p^TW log(p) is convex in p\nif W is a diagonally dominant positive definite M-matrix. The techniques used\nto prove convexity are well-known in linear algebra and essentially involves\nfactoring the Hessian in a way that is amenable to martix analysis. Using\nsimilar techniques, two classes of convex homogeneous polynomials is derived -\nnamely, p^TW p2 and (p^k)^TW p^k - the latter also happen to be SOS-convex.\nLastly, usign the same techniques, it is also shown that the function p^TW ep\nis convex over the positive reals only if W is a non-negative diagonal matrix.\nDiscussions regarding the utility of these functions and examples accompany the\nresults presented."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18027",
    "c_title":[
      "Spectral-statistics properties of the experimental and theoretical light\n  baryon and meson spectra"
    ],
    "c_abstract":[
      "We compare the statistical fluctuation properties of the baryon and meson\nexperimental mass spectra with those obtained from theoretical models (quark\nmodels and lattice QCD). We find that for the experimental spectra the\nstatistical properties are close to those predicted by Random Matrix Theory for\nchaotic systems, while for the theoretical ones they are in general closer to\nthose predicted for integrable systems and safely incompatible with those of\nchaotic systems. We stress the importance of the agreement of the fluctuation\nproperties between experiment and theoretical models, as they determine the\ndynamical regime and the complexity of the real interactions. We emphasize the\nnew statistical method we use, adapted for properly analyzing the fluctuation\nproperties for very short spectral sequences."
    ],
    "c_categories":[
      [
        "hep-ph",
        "nlin.CD",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-232",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06103",
    "b_title":[
      "Several combinatorial results generalized from one large subset of\n  semigroups to infinitely many"
    ],
    "b_abstract":[
      "In 2015, Phulara established a generalization of the famous central set\ntheorem by an original idea. Roughly speaking, this idea extends a\ncombinatorial result from one large subset of the given semigroup to countably\nmany. In this paper, we apply this idea to other combinatorial results to\nobtain corresponding generalizations, and do some further investigation.\nMoreover, we find that Phulara's generalization can be generalized further that\ncan deal with uncountably many C-sets."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08134",
    "c_title":[
      "An Empirical Wall-Pressure Spectrum Model for Aeroacoustic Predictions\n  Based on Symbolic Regression"
    ],
    "c_abstract":[
      "Fast-turn around methods to predict airfoil trailing-edge noise are crucial\nfor incorporating noise limitations into design optimization loops of several\napplications. Among these aeroacoustic predictive models, Amiet's theory offers\nthe best balance between accuracy and simplicity. The accuracy of the model\nrelies heavily on precise wall-pressure spectrum predictions, which are often\nbased on single-equation formulations with adjustable parameters. These\nparameters are calibrated for particular airfoils and flow conditions and\nconsequently tend to fail when applied outside their calibration range. This\npaper introduces a new wall-pressure spectrum empirical model designed to\nenhance the robustness and accuracy of current state-of-the-art predictions\nwhile widening the range of applicability of the model to different airfoils\nand flow conditions. The model is developed using AI-based symbolic regression\nvia a genetic-algorithm-based approach, and applied to a dataset of\nwall-pressure fluctuations measured on NACA 0008 and NACA 63018 airfoils at\nmultiple angles of attack and inflow velocities, covering turbulent boundary\nlayers with both adverse and favorable pressure gradients. Validation against\nexperimental data (outside the training dataset) demonstrates the robustness of\nthe model compared to well-accepted semi-empirical models. Finally, the model\nis integrated with Amiet's theory to predict the aeroacoustic noise of a\nfull-scale wind turbine, showing good agreement with experimental measurements."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-233",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11283",
    "b_title":[
      "Set-Based Position Ambiguity Reduction Method for Zonotope Shadow\n  Matching in Urban Areas Using Estimated Multipath Errors"
    ],
    "b_abstract":[
      "In urban areas, the quality of global navigation satellite system (GNSS)\nsignals deteriorates, leading to reduced positioning accuracy. To address this\nissue, 3D-mapping-aided (3DMA) techniques, such as shadow matching and zonotope\nshadow matching (ZSM), have been proposed. However, these methods can introduce\na problem known as multi-modal position ambiguity, making it challenging to\nselect the exact mode in which the receiver is located. Accurately selecting\nthe correct mode is essential for improving positioning accuracy. A previous\nstudy proposed a method that uses satellite-pseudorange consistency (SPC),\ncalculated from pseudorange measurements, to select the mode containing the\nreceiver. This method achieved a mode selection accuracy of approximately 78%.\nTo further enhance accuracy, the study utilized pseudorange measurements\ncollected at multiple timesteps from a fixed location and a trained\nline-of-sight (LOS) classifier. However, in practice, collecting data at\nmultiple timesteps from the same location in dynamic environments is\nchallenging. Moreover, the performance of the trained LOS classifier heavily\ndepends on the surrounding environment, leading to low reliability. In this\nstudy, we propose a method that estimates and corrects multipath errors based\non the mode distribution obtained from the output of ZSM and extract an\nenhanced SPC using the corrected pseudorange measurements. This enables high\nmode selection accuracy using only single-timestep pseudorange measurements,\nwithout requiring a trained LOS classifier."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12540",
    "c_title":[
      "The topological spectrum of high dimensional quantum states"
    ],
    "c_abstract":[
      "Topology has emerged as a fundamental property of many systems, manifesting\nin cosmology, condensed matter, high-energy physics and waves. Despite the rich\ntextures, the topology has largely been limited to low dimensional systems that\ncan be characterised by a single topological number, e.g., a Chern number in\nmatter or a Skyrme number in waves. Here, using photonic quantum states as an\nexample, we harness the synthetic dimensions of orbital angular momentum (OAM)\nto discover a rich tapestry of topological maps in high dimensional spaces.\nMoving beyond spin textured fields, we demonstrate topologies using only one\ndegree of freedom, the OAM of light. By interpreting the density matrix as a\nnon-Abelian Higgs potential, we are able to predict topologies that exist as\nhigh dimensional manifolds which remarkably can be deconstructed into a\nmultitude of simpler maps from disks to disks and spheres to spheres, giving\nrise to the notion of a topological spectrum rather than a topological number.\nWe confirm this experimentally using quantum wave functions with an underlying\ntopology of 48 dimensions and a topological spectrum spanning over 17000 maps,\nan encoding alphabet with enormous potential. We show that the topological\nspectrum allows the simultaneous ability to be robust to and probe for\nperturbation, the latter made possible by observing emergent signatures in the\nnon-topological (trivial) spaces of the spectrum. Our experimental approach\nbenefits from easy implementation, while our theoretical framework is cast in a\nmanner that can be extrapolated to any particle type, dimension and degree of\nfreedom. Our work opens exciting future possibilities for quantum sensing and\ncommunication with topology."
    ],
    "c_categories":[
      [
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-234",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10148",
    "b_title":[
      "Leptogenesis in the presence of density perturbations"
    ],
    "b_abstract":[
      "We point out a new effect on the freeze-out process of heavy particles\ninduced by density perturbations in the early universe, which we call\n``acoustically driven freeze-out.'' This beyond-linear effect is caused by the\nexponential decoupling of heavy particles from the thermal bath in the presence\nof density perturbations, and already at moderately large values $\\delta T \/\n\\bar{T} = O (10^{-2})$ it cannot be captured by linear perturbation theory. We\nillustrate this effect with leptogenesis taking the decay and inverse decay of\nheavy neutrinos into account, and discuss its phenomenological implications. We\nfound that perturbations always enhance the (spatially averaged) values of the\nfinal lepton asymmetry, and as a result, constraints on the mass of heavy\nneutrinos are found to be relaxed in the presence of perturbations."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10020",
    "c_title":[
      "Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions"
    ],
    "c_abstract":[
      "The 2D cartoon style is a prominent art form in digital character creation,\nparticularly popular among younger audiences. While advancements in digital\nhuman technology have spurred extensive research into photorealistic digital\nhumans and 3D characters, interactive 2D cartoon characters have received\ncomparatively less attention. Unlike 3D counterparts, which require\nsophisticated construction and resource-intensive rendering, Live2D, a\nwidely-used format for 2D cartoon characters, offers a more efficient\nalternative, which allows to animate 2D characters in a manner that simulates\n3D movement without the necessity of building a complete 3D model. Furthermore,\nLive2D employs lightweight HTML5 (H5) rendering, improving both accessibility\nand efficiency. In this technical report, we introduce Textoon, an innovative\nmethod for generating diverse 2D cartoon characters in the Live2D format based\non text descriptions. The Textoon leverages cutting-edge language and vision\nmodels to comprehend textual intentions and generate 2D appearance, capable of\ncreating a wide variety of stunning and interactive 2D characters within one\nminute. The project homepage is https:\/\/human3daigc.github.io\/Textoon_webpage\/."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-235",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01708",
    "b_title":[
      "Aspects of Artificial Intelligence: Transforming Machine Learning\n  Systems Naturally"
    ],
    "b_abstract":[
      "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.DB",
        "cs.DM",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03037",
    "c_title":[
      "The Lehmer complex of a Bruhat interval"
    ],
    "c_abstract":[
      "We introduce Lehmer codes, with immersions in the Bruhat order, for several\nfinite Coxeter groups, including all the classical Weyl groups. This allows to\nassociate to each lower Bruhat interval of these groups a multicomplex whose\nf-polynomial is the Poincar\\'e polynomial of the interval. Via a general\nconstruction, we prove that these polynomials are h-polynomials of\nvertex-decomposable simplicial complexes. Moreover we provide a classification,\nin terms of unimodal permutations, of Poincar\\'e polynomials of smooth Schubert\nvarieties in flag manifolds."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-236",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08430",
    "b_title":[
      "Fully numerical Hartree-Fock Calculations with Quantized Tensor Trains"
    ],
    "b_abstract":[
      "We present a fully numerical framework for the optimization of\nmolecule-specific quantum chemical basis functions within the quantics tensor\ntrain format using a finite-difference scheme. The optimization is driven by\nsolving the Hartree-Fock equations (HF) with the density-matrix renormalization\ngroup (DMRG) algorithm on Cartesian grids that are iteratively refined. In\ncontrast to the standard way of tackling the mean-field problem by expressing\nthe molecular orbitals as linear combinations of atomic orbitals (LCAO) our\nmethod only requires as much basis functions as there are electrons within the\nsystem. Benchmark calculations for atoms and molecules with up to ten electrons\nshow excellent agreement with LCAO calculations with large basis sets\nsupporting the validity of the tensor network approach. Our work therefore\noffers a promising alternative to well-established HF-solvers and could pave\nthe way to define highly accurate, fully numerical, molecule-adaptive basis\nsets, which, in the future, could lead to benefits for post-HF calculations."
    ],
    "b_categories":[
      [
        "physics.chem-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00374",
    "c_title":[
      "A Unit-based System and Dataset for Expressive Direct Speech-to-Speech\n  Translation"
    ],
    "c_abstract":[
      "Current research in speech-to-speech translation (S2ST) primarily\nconcentrates on translation accuracy and speech naturalness, often overlooking\nkey elements like paralinguistic information, which is essential for conveying\nemotions and attitudes in communication. To address this, our research\nintroduces a novel, carefully curated multilingual dataset from various movie\naudio tracks. Each dataset pair is precisely matched for paralinguistic\ninformation and duration. We enhance this by integrating multiple prosody\ntransfer techniques, aiming for translations that are accurate,\nnatural-sounding, and rich in paralinguistic details. Our experimental results\nconfirm that our model retains more paralinguistic information from the source\nspeech while maintaining high standards of translation accuracy and\nnaturalness."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-237",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01945",
    "b_title":[
      "Cryogenic Thermal Modeling of Microwave High Density Signaling"
    ],
    "b_abstract":[
      "Superconducting quantum computers require microwave control lines running\nfrom room temperature to the mixing chamber of a dilution refrigerator. Adding\nmore lines without preliminary thermal modeling to make predictions risks\noverwhelming the cooling power at each thermal stage. In this paper, we\ninvestigate the thermal load of SC-086\/50-SCN-CN semi-rigid coaxial cable,\nwhich is commonly used for the control and readout lines of a superconducting\nquantum computer, as we increase the number of lines to a quantum processor. We\ninvestigate the makeup of the coaxial cables, verify the materials and\ndimensions, and experimentally measure the total thermal conductivity of a\nsingle cable as a function of the temperature from cryogenic to room\ntemperature values. We also measure the cryogenic DC electrical resistance of\nthe inner conductor as a function of temperature, allowing for the calculation\nof active thermal loads due to Ohmic heating. Fitting this data produces a\nnumerical thermal conductivity function used to calculate the static heat loads\ndue to thermal transfer within the wires resulting from a temperature gradient.\nThe resistivity data is used to calculate active heat loads, and we use these\nfits in a cryogenic model of a superconducting quantum processor in a typical\nBluefors XLD1000-SL dilution refrigerator, investigating how the thermal load\nincreases with processor sizes ranging from 100 to 225 qubits. We conclude that\nthe theoretical upper limit of the described architecture is approximately 200\nqubits. However, including an engineering margin in the cooling power and the\navailable space for microwave readout circuitry at the mixing chamber, the\npractical limit will be approximately 140 qubits."
    ],
    "b_categories":[
      [
        "physics.ins-det",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07336",
    "c_title":[
      "Subtype-Aware Registration of Longitudinal Electronic Health Records"
    ],
    "c_abstract":[
      "Electronic Health Records (EHRs) contain extensive patient information that\ncan inform downstream clinical decisions, such as mortality prediction, disease\nphenotyping, and disease onset prediction. A key challenge in EHR data analysis\nis the temporal gap between when a condition is first recorded and its actual\nonset time. Such timeline misalignment can lead to artificially distinct\nbiomarker trends among patients with similar disease progression, undermining\nthe reliability of downstream analysis and complicating tasks like disease\nsubtyping. To address this challenge, we provide a subtype-aware timeline\nregistration method that leverages data projection and discrete optimization to\nsimultaneously correct timeline misalignment and improve disease subtyping.\nThrough simulation and real-world data analyses, we demonstrate that the\nproposed method effectively aligns distorted observed records with the true\ndisease progression patterns, enhancing subtyping clarity and improving\nperformance in downstream clinical analyses."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-238",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09013",
    "b_title":[
      "Prompt to Restore, Restore to Prompt: Cyclic Prompting for Universal\n  Adverse Weather Removal"
    ],
    "b_abstract":[
      "Universal adverse weather removal (UAWR) seeks to address various weather\ndegradations within a unified framework. Recent methods are inspired by prompt\nlearning using pre-trained vision-language models (e.g., CLIP), leveraging\ndegradation-aware prompts to facilitate weather-free image restoration,\nyielding significant improvements. In this work, we propose CyclicPrompt, an\ninnovative cyclic prompt approach designed to enhance the effectiveness,\nadaptability, and generalizability of UAWR. CyclicPrompt Comprises two key\ncomponents: 1) a composite context prompt that integrates weather-related\ninformation and context-aware representations into the network to guide\nrestoration. This prompt differs from previous methods by marrying learnable\ninput-conditional vectors with weather-specific knowledge, thereby improving\nadaptability across various degradations. 2) The erase-and-paste mechanism,\nafter the initial guided restoration, substitutes weather-specific knowledge\nwith constrained restoration priors, inducing high-quality weather-free\nconcepts into the composite prompt to further fine-tune the restoration\nprocess. Therefore, we can form a cyclic \"Prompt-Restore-Prompt\" pipeline that\nadeptly harnesses weather-specific knowledge, textual contexts, and reliable\ntextures. Extensive experiments on synthetic and real-world datasets validate\nthe superior performance of CyclicPrompt. The code is available at:\nhttps:\/\/github.com\/RongxinL\/CyclicPrompt."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06009",
    "c_title":[
      "Nearly Optimal Differentially Private ReLU Regression"
    ],
    "c_abstract":[
      "In this paper, we investigate one of the most fundamental nonconvex learning\nproblems, ReLU regression, in the Differential Privacy (DP) model. Previous\nstudies on private ReLU regression heavily rely on stringent assumptions, such\nas constant bounded norms for feature vectors and labels. We relax these\nassumptions to a more standard setting, where data can be i.i.d. sampled from\n$O(1)$-sub-Gaussian distributions. We first show that when $\\varepsilon =\n\\tilde{O}(\\sqrt{\\frac{1}{N}})$ and there is some public data, it is possible to\nachieve an upper bound of $\\Tilde{O}(\\frac{d^2}{N^2 \\varepsilon^2})$ for the\nexcess population risk in $(\\epsilon, \\delta)$-DP, where $d$ is the dimension\nand $N$ is the number of data samples. Moreover, we relax the requirement of\n$\\epsilon$ and public data by proposing and analyzing a one-pass mini-batch\nGeneralized Linear Model Perceptron algorithm (DP-MBGLMtron). Additionally,\nusing the tracing attack argument technique, we demonstrate that the minimax\nrate of the estimation error for $(\\varepsilon, \\delta)$-DP algorithms is lower\nbounded by $\\Omega(\\frac{d^2}{N^2 \\varepsilon^2})$. This shows that\nDP-MBGLMtron achieves the optimal utility bound up to logarithmic factors.\nExperiments further support our theoretical results."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-239",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15433",
    "b_title":[
      "Testing strong-field QED to second-order in the highly correlated atomic\n  system berylliumlike Pb78+ by electron-ion recombination spectroscopy"
    ],
    "b_abstract":[
      "A low-energy storage ring with an ultracold electron cooler has been coupled\nwith a heavy-ion accelerator facilitating high-resolution electron-ion\ncollision spectroscopy of the heaviest few-electron ions. In the present work\nresonant electron-ion recombination of berylliumlike Pb$^{78+}$ ions was\nmeasured in the collision-energy range 9.3-16.5eV and a value of 244.937(30) eV\nis derived for the Pb$^{78+}$($2s^2\\;^1S_0 - 2s\\,2p\\;^3P_1$) excitation energy.\nThis result agrees with the most recent (less accurate) theoretical value of\n244.942(52) eV [Malyshev et al., Physical Review A 110, 062824 (2024)], which\nhas been calculated by applying strong-field QED rigorously up to the second\norder. The present investigation suggests that further technical improvements\ncan potentially increase the experimental accuracy by an order of magnitude."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.08379",
    "c_title":[
      "Cartan Quantum Metrology"
    ],
    "c_abstract":[
      "We address the characterization of two-qubit gates, focusing on bounds to\nprecision in the joint estimation of the three parameters that define their\nCartan decomposition. We derive the optimal probe states that jointly maximize\nprecision, minimize sloppiness, and eliminate quantum incompatibility.\nAdditionally, we analyze the properties of the set of optimal probes and\nevaluate their robustness against noise."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-240",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10160",
    "b_title":[
      "Coupling and Acceleration of Externally Injected Electron Beams in\n  Laser-Driven Plasma Wakefields"
    ],
    "b_abstract":[
      "The multi-stage method of laser wakefield acceleration (LWFA) presents a\npromising approach for developing stable, full-optical, high-energy electron\naccelerators. By segmenting the acceleration process into several booster\nstages, each powered by independent laser drivers, this technique effectively\nmitigates challenges such as electron dephasing, pump depletion, and laser\ndiffraction. A critical aspect of multi-stage LWFA is the nonlinear interaction\nbetween the injected electron beam and the laser-driven wakefields in the\nbooster stage. This study investigates the injection and acceleration of\nexternal electron beams within wakefields in the booster stage using\nmulti-dimensional Particle-In-Cell (PIC) simulations. We provide both\nqualitative and quantitative descriptions of the observed physical processes.\nKey parameters influencing charge coupling process and the resultant beam\nquality have been identified. Furthermore, we have examined how off-axis\ninjection relative to the driver laser influences the acceleration process and\nbeam quality. Our findings provide valuable insights for advancing and\noptimizing multi-stage plasma-based accelerators."
    ],
    "b_categories":[
      [
        "physics.acc-ph",
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17445",
    "c_title":[
      "Separating complexity classes of LCL problems on grids"
    ],
    "c_abstract":[
      "We study the complexity of locally checkable labeling (LCL) problems on\n$\\mathbb{Z}^n$ from the point of view of descriptive set theory, computability\ntheory, and factors of i.i.d. Our results separate various complexity classes\nthat were not previously known to be distinct and serve as counterexamples to a\nnumber of natural conjectures in the field."
    ],
    "c_categories":[
      [
        "cs.CC",
        "math.CO",
        "math.LO",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-241",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11955",
    "b_title":[
      "Simultaneously decoding the unknown stationary state and function\n  parameters for mean field games"
    ],
    "b_abstract":[
      "Mean field games (MFGs) offer a versatile framework for modeling large-scale\ninteractive systems across multiple domains. This paper builds upon a previous\nwork, by developing a state-of-the-art unified approach to decode or design the\nunknown stationary state of MFGs, in addition to the underlying parameter\nfunctions governing their behavior. This result is novel, even in the general\nrealm of inverse problems for nonlinear PDEs. By enabling agents to distill\ncrucial insights from observed data and unveil intricate hidden structures and\nunknown states within MFG systems, our approach surmounts a significant\nobstacle, enhancing the applicability of MFGs in real-world scenarios. This\nadvancement not only enriches our understanding of MFG dynamics but also\nbroadens the scope for their practical deployment in various contexts."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.10117",
    "c_title":[
      "Kalman Filter in the Problem of the Exchange and the Inflation Rates\n  Adequacy To Determining Factors"
    ],
    "c_abstract":[
      "Using introduced concept of the exchange and inflation rates adequacy, the\nrelevance of them to the determining factors is found. We established close\npositive relation between hryvnia \/ dollar exchange and inflation rates, fiscal\ndeficit, price level of energy sources, and money supply. On this basis, we\ngive proposals for state macroeconomic policy to stabilize Ukrainian economy."
    ],
    "c_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-242",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06509",
    "b_title":[
      "Crossover from BKT to first-order transition induced by higher-order\n  terms in 2D XY models"
    ],
    "b_abstract":[
      "We study phase transitions in $XY$ models, generalized by inclusion of $n$\nhigher-order pairwise interactions of equal strength, by Monte Carlo\nsimulation. It is found that by adding new terms the\nBerezinskii-Kosterlitz-Thouless (BKT) transition, observed in the standard $XY$\nmodel, gradually changes to the first-order phase transition. We determine the\ncritical number of terms for which the first-order transition appears as\n$n_c=6$. It is also found that for $n=5$ the transition is pseudo-first-order\nbut it becomes true first-order if the couplings are allowed to increase. In\ngeneral, a more rapid increase of the coupling intensity supports the\nfirst-order transition, however, a too fast increase may result in splitting of\nthe single transition to multiple transitions. Consequently, the minimal number\nof the terms required for the change of the BKT phase transition to first order\nin the present model with arbitrary couplings is estimated to be $2 < n_c \\leq\n5$."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.14250",
    "c_title":[
      "Siren: A Learning-Based Multi-Turn Attack Framework for Simulating\n  Real-World Human Jailbreak Behaviors"
    ],
    "c_abstract":[
      "Large language models (LLMs) are widely used in real-world applications,\nraising concerns about their safety and trustworthiness. While red-teaming with\njailbreak prompts exposes the vulnerabilities of LLMs, current efforts focus\nprimarily on single-turn attacks, overlooking the multi-turn strategies used by\nreal-world adversaries. Existing multi-turn methods rely on static patterns or\npredefined logical chains, failing to account for the dynamic strategies during\nattacks. We propose Siren, a learning-based multi-turn attack framework\ndesigned to simulate real-world human jailbreak behaviors. Siren consists of\nthree stages: (1) training set construction utilizing Turn-Level LLM feedback\n(Turn-MF), (2) post-training attackers with supervised fine-tuning (SFT) and\ndirect preference optimization (DPO), and (3) interactions between the\nattacking and target LLMs. Experiments demonstrate that Siren achieves an\nattack success rate (ASR) of 90% with LLaMA-3-8B as the attacker against\nGemini-1.5-Pro as the target model, and 70% with Mistral-7B against GPT-4o,\nsignificantly outperforming single-turn baselines. Moreover, Siren with a\n7B-scale model achieves performance comparable to a multi-turn baseline that\nleverages GPT-4o as the attacker, while requiring fewer turns and employing\ndecomposition strategies that are better semantically aligned with attack\ngoals. We hope Siren inspires the development of stronger defenses against\nadvanced multi-turn jailbreak attacks under realistic scenarios. Code is\navailable at https:\/\/github.com\/YiyiyiZhao\/siren. Warning: This paper contains\npotentially harmful text."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-243",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17132",
    "b_title":[
      "Applications of Large Models in Medicine"
    ],
    "b_abstract":[
      "This paper explores the advancements and applications of large-scale models\nin the medical field, with a particular focus on Medical Large Models (MedLMs).\nThese models, encompassing Large Language Models (LLMs), Vision Models, 3D\nLarge Models, and Multimodal Models, are revolutionizing healthcare by\nenhancing disease prediction, diagnostic assistance, personalized treatment\nplanning, and drug discovery. The integration of graph neural networks in\nmedical knowledge graphs and drug discovery highlights the potential of Large\nGraph Models (LGMs) in understanding complex biomedical relationships. The\nstudy also emphasizes the transformative role of Vision-Language Models (VLMs)\nand 3D Large Models in medical image analysis, anatomical modeling, and\nprosthetic design. Despite the challenges, these technologies are setting new\nbenchmarks in medical innovation, improving diagnostic accuracy, and paving the\nway for personalized healthcare solutions. This paper aims to provide a\ncomprehensive overview of the current state and future directions of large\nmodels in medicine, underscoring their significance in advancing global health."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17755",
    "c_title":[
      "AI Governance through Markets"
    ],
    "c_abstract":[
      "This paper argues that market governance mechanisms should be considered a\nkey approach in the governance of artificial intelligence (AI), alongside\ntraditional regulatory frameworks. While current governance approaches have\npredominantly focused on regulation, we contend that market-based mechanisms\noffer effective incentives for responsible AI development. We examine four\nemerging vectors of market governance: insurance, auditing, procurement, and\ndue diligence, demonstrating how these mechanisms can affirm the relationship\nbetween AI risk and financial risk while addressing capital allocation\ninefficiencies. While we do not claim that market forces alone can adequately\nprotect societal interests, we maintain that standardised AI disclosures and\nmarket mechanisms can create powerful incentives for safe and responsible AI\ndevelopment. This paper urges regulators, economists, and machine learning\nresearchers to investigate and implement market-based approaches to AI\ngovernance."
    ],
    "c_categories":[
      [
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-244",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01888",
    "b_title":[
      "Enhancing Transformer with GNN Structural Knowledge via Distillation: A\n  Novel Approach"
    ],
    "b_abstract":[
      "Integrating the structural inductive biases of Graph Neural Networks (GNNs)\nwith the global contextual modeling capabilities of Transformers represents a\npivotal challenge in graph representation learning. While GNNs excel at\ncapturing localized topological patterns through message-passing mechanisms,\ntheir inherent limitations in modeling long-range dependencies and\nparallelizability hinder their deployment in large-scale scenarios. Conversely,\nTransformers leverage self-attention mechanisms to achieve global receptive\nfields but struggle to inherit the intrinsic graph structural priors of GNNs.\nThis paper proposes a novel knowledge distillation framework that\nsystematically transfers multiscale structural knowledge from GNN teacher\nmodels to Transformer student models, offering a new perspective on addressing\nthe critical challenges in cross-architectural distillation. The framework\neffectively bridges the architectural gap between GNNs and Transformers through\nmicro-macro distillation losses and multiscale feature alignment. This work\nestablishes a new paradigm for inheriting graph structural biases in\nTransformer architectures, with broad application prospects."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15568",
    "c_title":[
      "Mixed precision accumulation for neural network inference guided by\n  componentwise forward error analysis"
    ],
    "c_abstract":[
      "This work proposes a mathematically founded mixed precision accumulation\nstrategy for the inference of neural networks. Our strategy is based on a new\ncomponentwise forward error analysis that explains the propagation of errors in\nthe forward pass of neural networks. Specifically, our analysis shows that the\nerror in each component of the output of a layer is proportional to the\ncondition number of the inner product between the weights and the input,\nmultiplied by the condition number of the activation function. These condition\nnumbers can vary widely from one component to the other, thus creating a\nsignificant opportunity to introduce mixed precision: each component should be\naccumulated in a precision inversely proportional to the product of these\ncondition numbers. We propose a practical algorithm that exploits this\nobservation: it first computes all components in low precision, uses this\noutput to estimate the condition numbers, and recomputes in higher precision\nonly the components associated with large condition numbers. We test our\nalgorithm on various networks and datasets and confirm experimentally that it\ncan significantly improve the cost--accuracy tradeoff compared with uniform\nprecision accumulation baselines."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-245",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19075",
    "b_title":[
      "Incomplete Information Robustness"
    ],
    "b_abstract":[
      "Consider an analyst who models a strategic situation using an incomplete\ninformation game. The true game may involve correlated, duplicated belief\nhierarchies, but the analyst lacks knowledge of the correlation structure and\ncan only approximate each belief hierarchy. To make predictions in this\nsetting, the analyst uses belief-invariant Bayes correlated equilibria (BIBCE)\nand seeks to determine which one is justifiable. We address this question by\nintroducing the notion of robustness: a BIBCE is robust if, for every nearby\nincomplete information game, there exists a BIBCE close to it. Our main result\nprovides a sufficient condition for robustness using a generalized potential\nfunction. In a supermodular potential game, a robust BIBCE is a Bayes Nash\nequilibrium, whereas this need not hold in other classes of games."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.21010",
    "c_title":[
      "Analytic Formulas for Quantum Discord of Special Families of N-Qubit\n  States"
    ],
    "c_abstract":[
      "Quantum discord, a key indicator of non-classical correlations in bipartite\nsystems, has been recently extended to multipartite scenarios [Phys. Rev. Lett.\n2020, 124:110401]. We present exact analytic formulas for the quantum discord\nof special families of N-qubit states, including generalized class of GHZ\nstates. Our formulations span $2$, $3$, $4n$, $4n+1$, $4n+2$, and $4n+3$-qubit\nconfigurations where $n\\in 1, 2, \\ldots$, which refine the assessment of\nquantum correlations and provide an analytical tool in quantum computation.\nMoreover, we uncover a ``discord freezing'' in even-qubit systems under phase\nflip decoherence which provides a means for preserving quantum coherence in\nenvironmental perturbations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-246",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01623",
    "b_title":[
      "Instrumental Variables with Time-Varying Exposure: New Estimates of\n  Revascularization Effects on Quality of Life"
    ],
    "b_abstract":[
      "The ISCHEMIA Trial randomly assigned patients with ischemic heart disease to\nan invasive treatment strategy centered on revascularization with a control\ngroup assigned non-invasive medical therapy. As is common in such ``strategy\ntrials,'' many participants assigned to treatment remained untreated while many\nassigned to control crossed over into treatment. Intention-to-treat (ITT)\nanalyses of strategy trials preserve randomization-based comparisons, but ITT\neffects are diluted by non-compliance. Conventional per-protocol analyses that\ncondition on treatment received are likely biased by discarding random\nassignment. In trials where compliance choices are made shortly after\nassignment, instrumental variables (IV) methods solve both problems --\nrecovering an undiluted average causal effect of treatment for treated subjects\nwho comply with trial protocol. In ISCHEMIA, however, some controls were\nrevascularized as long as five years after random assignment. This paper\nextends the IV framework for strategy trials, allowing for such dynamic\nnon-random compliance behavior. IV estimates of long-run revascularization\neffects on quality of life are markedly larger than previously reported ITT and\nper-protocol estimates. We also show how to estimate complier characteristics\nin a dynamic-treatment setting. These estimates reveal increasing selection\nbias in naive time-varying per-protocol estimates of revascularization effects.\nCompliers have baseline health similar to that of the study population, while\ncontrol-group crossovers are far sicker."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.16758",
    "c_title":[
      "Nonlinear stability of compressible vortex sheets in three-dimensional\n  elastodynamics"
    ],
    "c_abstract":[
      "We investigate the nonlinear stability of compressible vortex sheet solutions\nfor three-dimensional (3D) isentropic elastic flows. Building upon previous\nresults on the weakly linear stability of elastic vortex sheets [19], we\nperform a detailed study of the roots of the Lopatinskii determinant and\nidentify a geometric stability condition associated with the deformation\ngradient. We employ an upper triangularization technique that isolates the\noutgoing modes into a closed system, where they appear only at the leading\norder. This enables us to derive energy estimates despite derivative loss. The\nmajor novelty of our approach includes the following two key aspects: (1) For\nthe 3D compressible Euler vortex sheets, the front symbol exhibits degenerate\nellipticity in certain frequency directions, which makes it challenging to\nensure the front's regularity using standard energy estimates. Our analysis\nreveals that the non-parallel structure of the deformation gradient tensor\nplays a crucial role in recovering ellipticity in the front symbol, thereby\nenhancing the regularity of the free interface. (2) Another significant\nchallenge in 3D arises from the strong degeneracy caused by the collision of\nrepeated roots and poles. Unlike in 2D, where such interactions are absent, we\nencounter a co-dimension one set in frequency space where a double root\ncoincides with a double pole. To resolve this, we refine Coulombel's\ndiagonalization framework [21] and construct a suitable transformation that\nreduces the degeneracy order of the Lopatinskii matrix, enabling the use of\nlocalized Garding-type estimates to control the characteristic components.\nFinally, we employ a Nash-Moser iteration scheme to establish the local\nexistence and nonlinear stability of vortex sheets under small initial\nperturbations, showing stability within a subsonic regime."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-247",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.00986",
    "b_title":[
      "Photometric Objects Around Cosmic Webs (PAC). VII. Disentangling Mass\n  and Environment Quenching with the Aid of Galaxy-halo Connection in\n  Simulations"
    ],
    "b_abstract":[
      "Star formation quenching in galaxies is a critical process in galaxy\nformation. It is widely believed that the quenching process is dominated by the\nmass of galaxies and\/or their environment. In Paper V, we addressed the\nchallenge to disentangle the effects of mass and environment by employing the\nPAC method, which combines spectroscopic and deep photometric surveys. This\napproach enabled us to measure the excess surface density of blue and red\ngalaxies around massive central galaxies down to $10^{9.0}M_{\\odot}$. However,\nit is not straightforward to completely separate the two effects. To address\nthis issue, in this paper, we derive the average quenched fraction of central\n(isolated) galaxies, $\\bar{f}_{\\mathrm{q}}^{\\mathrm{cen}}(M_{*})$, by combining\nthe 3D quenched fraction distribution $f^{\\mathrm{sat}}_{\\mathrm{q}}(r;\nM_{*,\\mathrm{cen}}, M_{*,\\mathrm{sat}})$, reconstructed from the\n$\\bar{n}_2w_{\\mathrm{p}}(r_{\\mathrm{p}})$ measurements, with the stellar\nmass-halo mass relation in N-body simulations from Paper IV, and the observed\ntotal quenched fraction, $\\bar{f}_{\\mathrm{q}}^{\\mathrm{all}}(M_{*})$. Using\n$f^{\\mathrm{sat}}_{\\mathrm{q}}(r;M_{*,\\mathrm{cen}},M_{*,\\mathrm{sat}})$,\n$\\bar{f}_{\\mathrm{q}}^{\\mathrm{cen}}(M_{*})$, and the galaxy-halo connection,\nwe assign a quenched probability to each (sub)halo in the simulation, enabling\na comprehensive study of galaxy quenching. We find that the mass-quenched\nfraction increases from 0.3 to 0.87 across the stellar mass range $[10^{9.5},\n10^{11.0}]M_{\\odot}$, while the environmental quenched fraction decreases from\n0.17 to 0.03. The mass effect dominates galaxy quenching across the entire\nstellar mass range we studied. Moreover, more massive host halos are more\neffective at quenching their satellite galaxies, while satellite stellar mass\nhas minimal influence on environmental quenching."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18195",
    "c_title":[
      "Multi-Perspective Data Augmentation for Few-shot Object Detection"
    ],
    "c_abstract":[
      "Recent few-shot object detection (FSOD) methods have focused on augmenting\nsynthetic samples for novel classes, show promising results to the rise of\ndiffusion models. However, the diversity of such datasets is often limited in\nrepresentativeness because they lack awareness of typical and hard samples,\nespecially in the context of foreground and background relationships. To tackle\nthis issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework.\nIn terms of foreground-foreground relationships, we propose in-context learning\nfor object synthesis (ICOS) with bounding box adjustments to enhance the detail\nand spatial information of synthetic samples. Inspired by the large margin\nprinciple, support samples play a vital role in defining class boundaries.\nTherefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix\nprompt embeddings at each time step of the generation process in diffusion\nmodels, producing hard novel samples. For foreground-background relationships,\nwe introduce a Background Proposal method (BAP) to sample typical and hard\nbackgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the\neffectiveness of our approach. Our framework significantly outperforms\ntraditional methods, achieving an average increase of $17.5\\%$ in nAP50 over\nthe baseline on PASCAL VOC. Code is available at\nhttps:\/\/github.com\/nvakhoa\/MPAD."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-248",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17868",
    "b_title":[
      "Hybrid Near-field and Far-field Localization with Holographic MIMO"
    ],
    "b_abstract":[
      "Due to its ability to precisely control wireless beams, holographic\nmultiple-input multiple-output (HMIMO) is expected to be a promising solution\nto achieve high-accuracy localization. However, as the scale of HMIMO increases\nto improve beam control capability, the corresponding near-field (NF) region\nexpands, indicating that users may exist in both NF and far-field (FF) regions\nwith different electromagnetic transmission characteristics. As a result,\nexisting methods for pure NF or FF localization are no longer applicable. We\nconsider a hybrid NF and FF localization scenario in this paper, where a base\nstation (BS) locates multiple users in both NF and FF regions with the aid of a\nreconfigurable intelligent surface (RIS), which is a low-cost implementation of\nHMIMO. In such a scenario, it is difficult to locate the users and optimize the\nRIS phase shifts because whether the location of the user is in the NF or FF\nregion is unknown, and the channels of different users are coupled. To tackle\nthis challenge, we propose a RIS-enabled localization method that searches the\nusers in both NF and FF regions and tackles the coupling issue by jointly\nestimating all user locations. We derive the localization error bound by\nconsidering the channel coupling and propose an RIS phase shift optimization\nalgorithm that minimizes the derived bound. Simulations show the effectiveness\nof the proposed method and demonstrate the performance gain compared to pure NF\nand FF techniques."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07615",
    "c_title":[
      "$(G,F)$-points on $\\mathbb{Q}$-algebraic varieties"
    ],
    "c_abstract":[
      "Let $G\\in \\mathbb{Q}[x,y,z]$ be a polynomial, and let $V(G)$ be the\n$\\mathbb{Q}$-algebraic variety corresponding to $G$, i.e.,\n$V(G)=\\{P\\in\\mathbb{Q}^3~|~G(P)=0\\}$. Let \\[\\begin{split} F:\\quad\n&\\mathbb{Q}^3\\rightarrow \\mathbb{Q}^3,\\\\ &(x,y,z)\\mapsto (f(x),f(y),f(z))\n\\end{split}\\] be a vector function, where $f\\in \\mathbb{Q}[x]$. It is easy to\nknow that the function obtained by the composition of $G$ and $F$, denoted as\n$G\\circ F$, is still in $\\mathbb{Q}[x,y,z]$. Moreover, let $V(G\\circ F)$ be the\n$\\mathbb{Q}$-algebraic variety corresponding to $G\\circ F$, i.e., $V(G\\circ\nF)=\\{P\\in\\mathbb{Q}^3~|~G\\circ F(P)=0\\}$. A rational point $P$ is called a\n$(G,F)$-point on $V(G)$ if $P$ belongs to the intersection of $V(G)$ and\n$V(G\\circ F)$, that is $P\\in V(G)\\cap V(G\\circ F)$. Denote $\\langle G,F\\rangle$\nas the set consisting of all $(G,F)$-points on $V(G)$. Obviously, $\\langle\nG,F\\rangle$ is a $\\mathbb{Q}$-algebraic variety. In this paper, we consider the\nalgebraic variety $\\langle G,F\\rangle$ for some specific functions $G$ and $F$.\nFor these specific functions $G$ and $F$, we prove that $\\langle G,F\\rangle$\nwill be isomorphic to a certain elliptic curve. We also analyze some properties\nof these elliptic curves."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-249",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11962",
    "b_title":[
      "HInter: Exposing Hidden Intersectional Bias in Large Language Models"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) may portray discrimination towards certain\nindividuals, especially those characterized by multiple attributes (aka\nintersectional bias). Discovering intersectional bias in LLMs is challenging,\nas it involves complex inputs on multiple attributes (e.g. race and gender). To\naddress this challenge, we propose HInter, a test technique that\nsynergistically combines mutation analysis, dependency parsing and metamorphic\noracles to automatically detect intersectional bias in LLMs. HInter generates\ntest inputs by systematically mutating sentences using multiple mutations,\nvalidates inputs via a dependency invariant and detects biases by checking the\nLLM response on the original and mutated sentences. We evaluate HInter using\nsix LLM architectures and 18 LLM models (GPT3.5, Llama2, BERT, etc) and find\nthat 14.61% of the inputs generated by HInter expose intersectional bias.\nResults also show that our dependency invariant reduces false positives\n(incorrect test inputs) by an order of magnitude. Finally, we observed that\n16.62% of intersectional bias errors are hidden, meaning that their\ncorresponding atomic cases do not trigger biases. Overall, this work emphasize\nthe importance of testing LLMs for intersectional bias."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07684",
    "c_title":[
      "Tomographic Signatures of Interacting Majorana and Andreev States in\n  Superconductor-Semiconductor Transmon Qubits"
    ],
    "c_abstract":[
      "Semiconductor-based Josephson junctions embedded within a Cooper-pair-box can\nhost complex many-body states, such as interacting Andreev states and\npotentially other quasi-particles of topological origin. Here, we study the\ninsights that could be revealed from a tomographic reconstruction of the\nCooper-pair charge distribution of the junction prepared in its ground state.\nWe posit that interacting and topological states can be identified from\ndistinct signatures within the probability distribution of the charge states.\nFurthermore, the comprehensive dataset provides direct access to information\ntheory metrics elucidating the entanglement between the charge sector of the\nsuperconductor and the microscopic degrees of freedom in the junction. We\ndemonstrate how these metrics serve to further classify differences between the\ntypes of excitations in the junction."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-250",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12647",
    "b_title":[
      "Absence of superconductivity and density-wave transition in\n  ambient-pressure tetragonal La$_4$Ni$_3$O$_{10}$"
    ],
    "b_abstract":[
      "The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ and\nLa$_4$Ni$_3$O$_{10}$ under high pressure stimulates intensive research\ninterests. These nickelates crystallize in an orthogonal\/monoclinic structure\nwith tilted NiO$_6$ octahedra at ambient pressure and enter a density-wave-like\nphase at low temperatures. The application of pressure suppresses the\noctahedral tilting and triggers a transition to tetragonal structure (I4\/mmm),\nwhich is believed to be a key prerequisite for the emergence of superconducting\nstate. Here, by developing a high oxidative environment growth technology, we\nreport the first tetragonal nickelates La$_4$Ni$_3$O$_{10}$ microcrystals\nwithout octahedral tilting at ambient pressure. In tetragonal\nLa$_4$Ni$_3$O$_{10}$, transport measurements find that both density-wave and\nsuperconducting transitions are absent up to 160 GPa, indicating a robust\ntetragonal metallic ground state. Density functional theory calculations reveal\nthat the band structure of ambient-pressure tetragonal La$_4$Ni$_3$O$_{10}$\ninvolves more $d_{z2}$ orbital contribution to the Fermi surface, compared to\nthe monoclinic phase or the high-pressure superconducting tetragonal phase. The\nconcurrent absence of density-wave state and high-pressure superconductivity in\nour ambient-pressure tetragonal crystals of La$_4$Ni$_3$O$_{10}$ suggests an\nunderlying correlation between these two orders. It suggests that the\ntetragonal structure is not necessary, while the density-wave state is crucial\nfor the superconductivity in nickelates. Our findings impose important\nconstraints on the mechanism of pressure-induced superconductivity in\nnickelates and sheds new light on exploring ambient pressure high-temperature\nNi-based superconductors."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16202",
    "c_title":[
      "A Markov model for factorization of iterated cubic polynomials"
    ],
    "c_abstract":[
      "Motivated by Boston and Jones and Goksel, we propose a Markov model for the\nfactorization of PCF cubic polynomials $f$. Using the information encoded in\nthe critical orbits of cubic polynomials, we define a Markov model for PCF\ncubic polynomials with combined critical orbits of lengths one and two. A\ncomplete list of PCF cubic polynomials over $\\mathbb{Q}$ is available thanks to\nthe work of Anderson et al. Some of these polynomials have been previously\nstudied -- for example, those with colliding critical orbits analyzed by\nBenedetto et al.; the results from these studies align with our model. We\nconstruct groups $M_n$ and prove that they follow our Markov model. These\ngroups $M_n$ are conjectured to contain $\\mathrm{Gal}(f^n)$."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-251",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02564",
    "b_title":[
      "Balanced Multi-view Clustering"
    ],
    "b_abstract":[
      "Multi-view clustering (MvC) aims to integrate information from different\nviews to enhance the capability of the model in capturing the underlying data\nstructures. The widely used joint training paradigm in MvC is potentially not\nfully leverage the multi-view information, since the imbalanced and\nunder-optimized view-specific features caused by the uniform learning objective\nfor all views. For instance, particular views with more discriminative\ninformation could dominate the learning process in the joint training paradigm,\nleading to other views being under-optimized. To alleviate this issue, we first\nanalyze the imbalanced phenomenon in the joint-training paradigm of multi-view\nclustering from the perspective of gradient descent for each view-specific\nfeature extractor. Then, we propose a novel balanced multi-view clustering\n(BMvC) method, which introduces a view-specific contrastive regularization\n(VCR) to modulate the optimization of each view. Concretely, VCR preserves the\nsample similarities captured from the joint features and view-specific ones\ninto the clustering distributions corresponding to view-specific features to\nenhance the learning process of view-specific feature extractors. Additionally,\na theoretical analysis is provided to illustrate that VCR adaptively modulates\nthe magnitudes of gradients for updating the parameters of view-specific\nfeature extractors to achieve a balanced multi-view learning procedure. In such\na manner, BMvC achieves a better trade-off between the exploitation of\nview-specific patterns and the exploration of view-invariance patterns to fully\nlearn the multi-view information for the clustering task. Finally, a set of\nexperiments are conducted to verify the superiority of the proposed method\ncompared with state-of-the-art approaches on eight benchmark MvC datasets."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09558",
    "c_title":[
      "The Topological form is the Pfaffian form"
    ],
    "c_abstract":[
      "For a given graph $G$, Budzik, Gaiotto, Kulp, Wang, Williams, Wu, Yu, and the\nfirst author studied a ''topological'' differential form $\\alpha_G$, which\nexpresses violations of BRST-closedness of a quantum field theory along a\nsingle topological direction. In a seemingly unrelated context, Brown, Panzer,\nand the second author studied a ''Pfaffian'' differential form $\\phi_G$, which\nis used to construct cohomology classes of the odd commutative graph complex.\nWe give an explicit combinatorial proof that $\\alpha_G$ coincides with\n$\\phi_G$. We also discuss the equivalence of several properties of these forms,\nwhich had been established independently for both contexts in previous work."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.CO",
        "math.MP",
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-252",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18709",
    "b_title":[
      "Beamforming with Oversampled Time-Modulated Arrays"
    ],
    "b_abstract":[
      "The time-modulated array (TMA) is a simple array architecture in which each\nantenna is connected via a multi-throw switch. The switch acts as a modulator\nswitching state faster than the symbol rate. The phase shifting and beamforming\nis achieved by a cyclic shift of the periodical modulating signal across\nantennas. In this paper, the TMA mode of operation is proposed to improve the\nresolution of a conventional phase shifter. The TMAs are analyzed under\nconstrained switching frequency being a small multiple of the symbol rate. The\npresented generic signal model gives insight into the magnitude, phase and\nspacing of the harmonic components generated by the quantized modulating\nsequence. It is shown that the effective phase-shifting resolution can be\nimproved multiplicatively by the oversampling factor ($O$) at the cost of\nintroducing harmonics. Finally, the array tapering with an oversampled\nmodulating signal is proposed. The oversampling provides $O+1$ uniformly\ndistributed tapering amplitudes."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07233",
    "c_title":[
      "A birational description of the minimal exponent"
    ],
    "c_abstract":[
      "We give a description of the minimal exponent of a hypersurface using higher\ndirect images of suitably twisted sheaves of log forms on a log resolution."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-253",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11994",
    "b_title":[
      "Power Amplifier-Aware Transmit Power Optimization for OFDM and SC-FDMA\n  Systems"
    ],
    "b_abstract":[
      "The Single Carrier-Frequency Division Multiple Access (SC-FDMA) is a\ntransmission technique used in the uplink of Long Term Evolution (LTE) and 5G\nsystems, as it is characterized by reduced transmitted signal envelope\nfluctuations in comparison to Orthogonal Frequency Division Multiplexing (OFDM)\ntechnique used in the downlink. This allows for higher energy efficiency of\nUser Equipments (UEs) while maintaining sufficient signal quality, measured by\nError Vector Magnitude (EVM), at the transmitter. This paper proposes to model\na nonlinear Power Amplifier (PA) influence while optimizing the transmit power\nin order to maximize the Signal to Noise and Distortion power Ratio (SNDR) at\nthe receiver, removing the transmitter-based EVM constraint. An analytic model\nof SNDR for the OFDM system and a semi-analytical model for the SC-FDMA system\nare provided. Numerical investigations show that the proposed transmit power\noptimization allows for improved signal quality at the receiver for both OFDM\nand SC-FDMA systems. However, SC-FDMA still outperforms OFDM in this matter.\nSuch a power amplifier-aware wireless transmitter optimization should be\nconsidered to boost the performance and sustainability of next-generation\nwireless systems, including Internet of Things (IoT) ones."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07123",
    "c_title":[
      "A nested MLMC framework for efficient simulations on FPGAs"
    ],
    "c_abstract":[
      "Multilevel Monte Carlo (MLMC) reduces the total computational cost of\nfinancial option pricing by combining SDE approximations with multiple\nresolutions. This paper explores a further avenue for reducing cost and\nimproving power efficiency through the use of low precision calculations on\nconfigurable hardware devices such as Field-Programmable Gate Arrays (FPGAs).\nWe propose a new framework that exploits approximate random variables and\nfixed-point operations with optimised precision to generate most SDE paths with\na lower cost and reduce the overall cost of the MLMC framework. We first\ndiscuss several methods for the cheap generation of approximate random Normal\nincrements. To set the bit-width of variables in the path generation we then\npropose a rounding error model and optimise the precision of all variables on\neach MLMC level. With these key improvements, our proposed framework offers\nhigher computational savings than the existing mixed-precision MLMC frameworks."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-254",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11558",
    "b_title":[
      "A performance analysis of VM-based Trusted Execution Environments for\n  Confidential Federated Learning"
    ],
    "b_abstract":[
      "Federated Learning (FL) is a distributed machine learning approach that has\nemerged as an effective way to address recent privacy concerns. However, FL\nintroduces the need for additional security measures as FL alone is still\nsubject to vulnerabilities such as model and data poisoning and inference\nattacks. Confidential Computing (CC) is a paradigm that, by leveraging\nhardware-based trusted execution environments (TEEs), protects the\nconfidentiality and integrity of ML models and data, thus resulting in a\npowerful ally of FL applications. Typical TEEs offer an application-isolation\nlevel but suffer many drawbacks, such as limited available memory and debugging\nand coding difficulties. The new generation of TEEs offers a virtual machine\n(VM)-based isolation level, thus reducing the porting effort for existing\napplications. In this work, we compare the performance of VM-based and\napplication-isolation level TEEs for confidential FL (CFL) applications. In\nparticular, we evaluate the impact of TEEs and additional security mechanisms\nsuch as TLS (for securing the communication channel). The results, obtained\nacross three datasets and two deep learning models, demonstrate that the new\nVM-based TEEs introduce a limited overhead (at most 1.5x), thus paving the way\nto leverage public and untrusted computing environments, such as HPC facilities\nor public cloud, without detriment to performance."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.PF"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01104",
    "c_title":[
      "The Axial Electric Potential and Length of a Torus Knot"
    ],
    "c_abstract":[
      "Physical knot theory, where knots are treated like physical objects, is\nimportant to many fields. One natural problem is to give a knot a uniform\ncharge, and analyze the resulting electric field and electric potential. There\nhave been some results on the number of critical points of the electric\npotential from knots, such as by Lipton (2021) and Lipton, Townsend, and\nStrogatz (2022). However, little analysis has been done on the electric field\nand electric potential using calculations for specific knots.\n  We focus on torus knots, specifically a parametrization that embeds it on a\ntorus centered at the origin with rotational symmetry about the z-axis.\nParticularly, in this project, we analyze the electric field along the z-axis\nto take advantage of symmetry. We also analyze the length of the knot as a\nsimpler integral. We show that the electric field is zero only at the origin,\nand investigate the extreme points of the electric field and electric potential\nusing numerical methods and calculations. We also demonstrate a new way to\napply methods for contour integration in complex analysis to calculate the\nlength, electric potential, and electric field, and provide an explicit\napproximation for the length of a torus knot."
    ],
    "c_categories":[
      [
        "math.CV",
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-255",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09113",
    "b_title":[
      "Constraint-Guided Learning of Data-driven Health Indicator Models: An\n  Application on the Pronostia Bearing Dataset"
    ],
    "b_abstract":[
      "This paper presents a constraint-guided deep learning framework for\ndeveloping physically consistent health indicators in bearing prognostics and\nhealth management. Conventional data-driven methods often lack physical\nplausibility, while physics-based models are limited by incomplete system\nknowledge. To address this, we integrate domain knowledge into deep learning\nusing constraints to enforce monotonicity, bound output values between 1 and 0\n(representing healthy to failed states), and ensure consistency between signal\nenergy trends and health indicator estimates. This eliminates the need for\ncomplex loss term balancing. We implement constraint-guided gradient descent\nwithin an autoencoder architecture, creating a constrained autoencoder.\nHowever, the framework is adaptable to other architectures. Using\ntime-frequency representations of accelerometer signals from the Pronostia\ndataset, our constrained model generates smoother, more reliable degradation\nprofiles compared to conventional methods, aligning with expected physical\nbehavior. Performance is assessed using three metrics: trendability,\nrobustness, and consistency. Compared to a conventional baseline, the\nconstrained model improves all three. Another baseline, incorporating\nmonotonicity via a soft-ranking loss function, outperforms in trendability but\nfalls short in robustness and consistency. An ablation study confirms that the\nmonotonicity constraint enhances trendability, the boundary constraint ensures\nconsistency, and the energy-health consistency constraint improves robustness.\nThese findings highlight the effectiveness of constraint-guided deep learning\nin producing reliable, physically meaningful health indicators, offering a\npromising direction for future prognostic applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07131",
    "c_title":[
      "TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model\n  Bring? -- A Case Study on Korea Financial Texts"
    ],
    "c_abstract":[
      "Domain specificity of embedding models is critical for effective performance.\nHowever, existing benchmarks, such as FinMTEB, are primarily designed for\nhigh-resource languages, leaving low-resource settings, such as Korean,\nunder-explored. Directly translating established English benchmarks often fails\nto capture the linguistic and cultural nuances present in low-resource domains.\nIn this paper, titled TWICE: What Advantages Can Low-Resource Domain-Specific\nEmbedding Models Bring? A Case Study on Korea Financial Texts, we introduce\nKorFinMTEB, a novel benchmark for the Korean financial domain, specifically\ntailored to reflect its unique cultural characteristics in low-resource\nlanguages. Our experimental results reveal that while the models perform\nrobustly on a translated version of FinMTEB, their performance on KorFinMTEB\nuncovers subtle yet critical discrepancies, especially in tasks requiring\ndeeper semantic understanding, that underscore the limitations of direct\ntranslation. This discrepancy highlights the necessity of benchmarks that\nincorporate language-specific idiosyncrasies and cultural nuances. The insights\nfrom our study advocate for the development of domain-specific evaluation\nframeworks that can more accurately assess and drive the progress of embedding\nmodels in low-resource settings."
    ],
    "c_categories":[
      [
        "cs.CL",
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-256",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05555",
    "b_title":[
      "Improving Zero-Shot Object-Level Change Detection by Incorporating\n  Visual Correspondence"
    ],
    "b_abstract":[
      "Detecting object-level changes between two images across possibly different\nviews is a core task in many applications that involve visual inspection or\ncamera surveillance. Existing change-detection approaches suffer from three\nmajor limitations: (1) lack of evaluation on image pairs that contain no\nchanges, leading to unreported false positive rates; (2) lack of\ncorrespondences (i.e., localizing the regions before and after a change); and\n(3) poor zero-shot generalization across different domains. To address these\nissues, we introduce a novel method that leverages change correspondences (a)\nduring training to improve change detection accuracy, and (b) at test time, to\nminimize false positives. That is, we harness the supervision labels of where\nan object is added or removed to supervise change detectors, improving their\naccuracy over previous work by a large margin. Our work is also the first to\npredict correspondences between pairs of detected changes using estimated\nhomography and the Hungarian algorithm. Our model demonstrates superior\nperformance over existing methods, achieving state-of-the-art results in change\ndetection and change correspondence accuracy across both in-distribution and\nzero-shot benchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10202",
    "c_title":[
      "Provably Safeguarding a Classifier from OOD and Adversarial Samples: an\n  Extreme Value Theory Approach"
    ],
    "c_abstract":[
      "This paper introduces a novel method, Sample-efficient Probabilistic\nDetection using Extreme Value Theory (SPADE), which transforms a classifier\ninto an abstaining classifier, offering provable protection against\nout-of-distribution and adversarial samples. The approach is based on a\nGeneralized Extreme Value (GEV) model of the training distribution in the\nclassifier's latent space, enabling the formal characterization of OOD samples.\nInterestingly, under mild assumptions, the GEV model also allows for formally\ncharacterizing adversarial samples. The abstaining classifier, which rejects\nsamples based on their assessment by the GEV model, provably avoids OOD and\nadversarial samples. The empirical validation of the approach, conducted on\nvarious neural architectures (ResNet, VGG, and Vision Transformer) and medium\nand large-sized datasets (CIFAR-10, CIFAR-100, and ImageNet), demonstrates its\nfrugality, stability, and efficiency compared to the state of the art."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-257",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06795",
    "b_title":[
      "Robotic Ultrasound-Guided Femoral Artery Reconstruction of\n  Anatomically-Representative Phantoms"
    ],
    "b_abstract":[
      "Femoral artery access is essential for numerous clinical procedures,\nincluding diagnostic angiography, therapeutic catheterization, and emergency\ninterventions. Despite its critical role, successful vascular access remains\nchallenging due to anatomical variability, overlying adipose tissue, and the\nneed for precise ultrasound (US) guidance. Errors in needle placement can lead\nto severe complications, restricting the procedure to highly skilled clinicians\nin controlled hospital settings. While robotic systems have shown promise in\naddressing these challenges through autonomous scanning and vessel\nreconstruction, clinical translation remains limited due to reliance on\nsimplified phantom models that fail to capture human anatomical complexity. In\nthis work, we present a method for autonomous robotic US scanning of bifurcated\nfemoral arteries, and validate it on five vascular phantoms created from real\npatient computed tomography (CT) data. Additionally, we introduce a video-based\ndeep learning US segmentation network tailored for vascular imaging, enabling\nimproved 3D arterial reconstruction. The proposed network achieves a Dice score\nof 89.21% and an Intersection over Union of 80.54% on a newly developed\nvascular dataset. The quality of the reconstructed artery centerline is\nevaluated against ground truth CT data, demonstrating an average L2 deviation\nof 0.91+\/-0.70 mm, with an average Hausdorff distance of 4.36+\/-1.11mm. This\nstudy is the first to validate an autonomous robotic system for US scanning of\nthe femoral artery on a diverse set of patient-specific phantoms, introducing a\nmore advanced framework for evaluating robotic performance in vascular imaging\nand intervention."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06341",
    "c_title":[
      "Monolayer-Defined Flat Colloidal PbSe Quantum Dots in Extreme\n  Confinement"
    ],
    "c_abstract":[
      "Colloidal two-dimensional lead chalcogenide nanocrystals represent an\nintriguing new class of materials that push the boundaries of quantum\nconfinement by combining a crystal thickness down to the monolayer with\nconfinement in the lateral dimension. In particular flat PbSe quantum dots\nexhibit efficient telecommunication band-friendly photoluminescence (1.43 -\n0.83 eV with up to 61% quantum yield) that is highly interesting for\nfiber-optics information processing. By using cryogenic scanning tunneling\nmicroscopy and spectroscopy, we probe distinct single layer-defined PbSe\nquantum dot populations down to a monolayer with in-gap state free quantum\ndot-like density of states, in agreement with theoretical tight binding\ncalculations. Cryogenic ensemble photoluminescence spectra reveal mono-, bi-,\nand trilayer contribution, confirming the structural, electronic and\ntheoretical results. From larger timescale shifts and ratio changes in the\noptical spectra we infer Ostwald ripening in solution and fusing in deposited\nsamples of thinner flat PbSe quantum dots, which can be slowed down by surface\npassivation with PbI2. By uncovering the interplay between thickness, lateral\nsize and density of states, as well as the synthetic conditions and\npost-synthetic handling, our findings enable the target-oriented synthesis of\ntwo-dimensional PbSe quantum dots with precisely tailored optical properties at\ntelecom wavelengths."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-258",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16394",
    "b_title":[
      "Propagation Performance of Terahertz Channels in Lunar Dust"
    ],
    "b_abstract":[
      "The growing momentum in lunar exploration programs and urgent need for robust\ncommunication systems capable of operating in dust-laden lunar environments\nnecessitate comprehensive understanding of channel propagation characteristics\nin lunar conditions. In this article, we present a comprehensive analysis of\nterahertz (THz) channel propagation characteristics through lunar dust\nenvironments, critical for establishing reliable communication and sensing\ninfrastructure on the Moon. We develop an extended Mie scattering model\nincorporating the unique properties of lunar dust particles (Apollo 11 sample\n10084, Apollo 14 sample 14003, and Apollo 17 sample 70051), including their\nirregular morphology, dielectric characteristics, and charge-dependent\nbehavior. Through theoretical analysis and experimental verification, we\nexamine both power and bit error rate (BER) performance across varying dust\nconditions. Our results reveal distinct relationships between particle charge\nlevels, morphological characteristics, and channel performance with power loss\npatterns and BER evolution. Our findings provide essential guidelines for\ndeveloping robust lunar communication systems that integrate sensing\ncapabilities, contributing to the establishment of sustainable lunar\ninfrastructure."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08826",
    "c_title":[
      "Beyond Diagonal RIS-Aided Wireless Communications Systems:\n  State-of-the-Art and Future Research Directions"
    ],
    "c_abstract":[
      "Integrating BD-RIS into wireless communications systems has attracted\nsignificant interest due to its transformative potential in enhancing system\nperformance. This survey provides a comprehensive analysis of BD-RIS\ntechnology, examining its modeling, structural characteristics, and network\nintegration while highlighting its advantages over traditional diagonal RIS.\nSpecifically, we review various BD-RIS modeling approaches, including multiport\nnetwork theory, graph theory, and matrix theory, and emphasize their\napplication in diverse wireless scenarios. The survey also covers BD-RIS's\nstructural diversity, including different scattering matrix types, transmission\nmodes, intercell architectures, and circuit topologies, showing their\nflexibility in improving network performance. We delve into the potential\napplications of BD-RIS, such as enhancing wireless coverage, improving PLS,\nenabling multi-cell interference cancellation, improving precise sensing and\nlocalization, and optimizing channel manipulation. Further, we explore BD-RIS\narchitectural development, providing insights into new configurations focusing\non channel estimation, optimization, performance analysis, and circuit\ncomplexity perspectives. Additionally, we investigate the integration of BD-RIS\nwith emerging wireless technologies, such as millimeter-wave and terahertz\ncommunications, integrated sensing and communications, mobile edge computing,\nand other cutting-edge technologies. These integrations are pivotal in\nadvancing the capabilities and efficiency of future wireless networks. Finally,\nthe survey identifies key challenges, including channel state information\nestimation, interference modeling, and phase-shift designs, and outlines future\nresearch directions. The survey aims to provide valuable insights into BD-RIS's\npotential in shaping the future of wireless communications systems."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-259",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03732",
    "b_title":[
      "More Modality, More AI: Exploring Design Opportunities of AI-Based\n  Multi-modal Remote Monitoring Technologies for Early Detection of Mental\n  Health Sequelae in Youth Concussion Patients"
    ],
    "b_abstract":[
      "Anxiety, depression, and suicidality are common mental health sequelae\nfollowing concussion in youth patients, often exacerbating concussion symptoms\nand prolonging recovery. Despite the critical need for early detection of these\nmental health symptoms, clinicians often face challenges in accurately\ncollecting patients' mental health data and making clinical decision-making in\na timely manner. Today's remote patient monitoring (RPM) technologies offer\nopportunities to objectively monitor patients' activities, but they were not\nspecifically designed for youth concussion patients; moreover, the large amount\nof data collected by RPM technologies may also impose significant workloads on\nclinicians to keep up with and use the data. To address these gaps, we employed\na three-stage study consisting of a formative study, interface design, and\ndesign evaluation. We first conducted a formative study through semi-structured\ninterviews with six highly professional concussion clinicians and identified\nclinicians' key challenges in remotely collecting patient information and\naccessing patient treatment compliance. Subsequently, we proposed preliminary\nclinician-facing interface designs with the integration of AI-based RPM\ntechnologies (AI-RPM), followed by design evaluation sessions with highly\nprofessional concussion clinicians. Clinicians underscored the value of\nintegrating multi-modal AI-RPM technologies to support clinicians'\ndecision-making while emphasizing the importance of customizable interfaces\nwith explainability and multiple responsible design considerations."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03009",
    "c_title":[
      "Turbulence and energy dissipation from wave breaking"
    ],
    "c_abstract":[
      "Wave breaking is a critical process in the upper ocean: an energy sink for\nthe surface wave field and a source for turbulence in the ocean surface\nboundary layer. We apply a novel multi-layer numerical solver resolving\nupper-ocean dynamics over scales from O(50cm) to O(1km), including a\nbroad-banded wave field and wave breaking. The present numerical study isolates\nthe effect of wave breaking and allows us to study the surface layer in\nwave-influenced and wave-breaking-dominated regimes. Following our previous\nwork showing wave breaking statistics in agreement with field observations, we\nextend the analysis to underwater breaking-induced turbulence and related\ndissipation (in freely decaying conditions). We observe a rich field of\nvorticity resulting from the turbulence generation by breaking waves. We\ndiscuss the vertical profiles of dissipation rate which are compared with field\nobservations, and propose an empirical universal shape function. Good agreement\nis found, further demonstrating that wave breaking can dominate turbulence\ngeneration in the near-surface layer. We examine the dissipation from different\nangles: the global dissipation of the wave field computed from the decaying\nwave field, the spectral dissipation from the fifth moment of breaking front\ndistribution, and a turbulence dissipation estimated from the underwater strain\nrate tensor. Finally, we consider how these different estimates can be\nunderstood as part of a coherent framework."
    ],
    "c_categories":[
      [
        "physics.ao-ph",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-260",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01679",
    "b_title":[
      "LIBRA: Measuring Bias of Large Language Model from a Local Context"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have significantly advanced natural language\nprocessing applications, yet their widespread use raises concerns regarding\ninherent biases that may reduce utility or harm for particular social groups.\nDespite the advancement in addressing LLM bias, existing research has two major\nlimitations. First, existing LLM bias evaluation focuses on the U.S. cultural\ncontext, making it challenging to reveal stereotypical biases of LLMs toward\nother cultures, leading to unfair development and use of LLMs. Second, current\nbias evaluation often assumes models are familiar with the target social\ngroups. When LLMs encounter words beyond their knowledge boundaries that are\nunfamiliar in their training data, they produce irrelevant results in the local\ncontext due to hallucinations and overconfidence, which are not necessarily\nindicative of inherent bias. This research addresses these limitations with a\nLocal Integrated Bias Recognition and Assessment Framework (LIBRA) for\nmeasuring bias using datasets sourced from local corpora without crowdsourcing.\nImplementing this framework, we develop a dataset comprising over 360,000 test\ncases in the New Zealand context. Furthermore, we propose the Enhanced\nIdealized CAT Score (EiCAT), integrating the iCAT score with a beyond knowledge\nboundary score (bbs) and a distribution divergence-based bias measurement to\ntackle the challenge of LLMs encountering words beyond knowledge boundaries.\nOur results show that the BERT family, GPT-2, and Llama-3 models seldom\nunderstand local words in different contexts. While Llama-3 exhibits larger\nbias, it responds better to different cultural contexts. The code and dataset\nare available at: https:\/\/github.com\/ipangbo\/LIBRA."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05898",
    "c_title":[
      "Fractional Sobolev spaces related to an ultraparabolic operator"
    ],
    "c_abstract":[
      "We propose a functional framework of fractional Sobolev spaces for a class of\nultra-parabolic Kolmogorov type operators satisfying the weak H\\\"ormander\ncondition. We characterize these spaces as real interpolation of natural order\nintrinic Sobolev spaces recently introduced in [27], and prove continuous\nembeddings into $L^p$ and intrinsic H\\\"older spaces from [24]. These embeddings\nnaturally extend the standard Euclidean ones, coherently with the homogeneous\nstructure of the associated Kolmogorov group. Our approach to interpolation is\nbased on approximation of intrinsically regular functions, the latter heavily\nrelying on integral estimates of the intrinsic Taylor remainder. The embeddings\nexploit the aforementioned interpolation property and the corresponding\nembeddings of natural order intrinsic spaces."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-261",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08813",
    "b_title":[
      "Structure theorems for Gorenstein ideals of codimension four with small\n  number of generators"
    ],
    "b_abstract":[
      "In this article we study minimal free resolutions of Gorenstein ideals of\ncodimension four, using methods coming from representation theory. We introduce\nfamilies of higher structure maps associated with such resolution, defined\nsimilarly to the codimension three case. As our main application, we prove that\nevery Gorenstein ideal of codimension four minimally generated by six elements\nis a hyperplane section of a Gorenstein ideal of codimension three,\nstrengthening a result by Herzog-Miller and Vasconcelos-Villarreal. We state\nanalogous conjectural results for ideals minimally generated by seven and eight\nelements."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.14637",
    "c_title":[
      "Reinforcement learning-based motion imitation for physiologically\n  plausible musculoskeletal motor control"
    ],
    "c_abstract":[
      "How do humans move? The quest to understand human motion has broad\napplications in numerous fields, ranging from computer animation and motion\nsynthesis to neuroscience, human prosthetics and rehabilitation. Although\nadvances in reinforcement learning (RL) have produced impressive results in\ncapturing human motion using simplified humanoids, controlling physiologically\naccurate models of the body remains an open challenge. In this work, we present\na model-free motion imitation framework (KINESIS) to advance the understanding\nof muscle-based motor control. Using a musculoskeletal model of the lower body\nwith 80 muscle actuators and 20 DoF, we demonstrate that KINESIS achieves\nstrong imitation performance on 1.9 hours of motion capture data, is\ncontrollable by natural language through pre-trained text-to-motion generative\nmodels, and can be fine-tuned to carry out high-level tasks such as target goal\nreaching. Importantly, KINESIS generates muscle activity patterns that\ncorrelate well with human EMG activity. The physiological plausibility makes\nKINESIS a promising model for tackling challenging problems in human motor\ncontrol theory, which we highlight by investigating Bernstein's redundancy\nproblem in the context of locomotion. Code, videos and benchmarks will be\navailable at https:\/\/github.com\/amathislab\/Kinesis."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO",
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-262",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02262",
    "b_title":[
      "Analyses of features of magnetic cycles at different amounts of dynamo\n  supercriticality: Solar dynamo is about two times critical"
    ],
    "b_abstract":[
      "The growth of a large-scale magnetic field in the Sun and stars is usually\npossible when the dynamo number (D) is above a critical value Dc. As the star\nages, its rotation rate and thus D decrease. Hence, the question is how far the\nsolar dynamo is from the critical dynamo transition. To answer this question,\nwe have performed a set of simulations using Babcock-Leighton type dynamo\nmodels at different values of dynamo supercriticality and analyzed various\nfeatures of magnetic cycle. By comparing the recovery rates of the dynamo from\nthe Maunder minimum and statistics (numbers and durations) of the grand minima\nand maxima with that of observations and we show that the solar dynamo is only\nabout two times critical and thus not highly supercritical. The observed\ncorrelation between the polar field proxy and the following cycle amplitudes\nand Gnevyshev-Ohl rule are also compatible with this conclusion."
    ],
    "b_categories":[
      [
        "astro-ph.SR",
        "physics.plasm-ph",
        "physics.space-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16089",
    "c_title":[
      "Query-Efficient Fixpoints of $\\ell_p$-Contractions"
    ],
    "c_abstract":[
      "We prove that an $\\epsilon$-approximate fixpoint of a map\n$f:[0,1]^d\\rightarrow [0,1]^d$ can be found with\n$\\mathcal{O}(d^2(\\log\\frac{1}{\\epsilon} + \\log\\frac{1}{1-\\lambda}))$ queries to\n$f$ if $f$ is $\\lambda$-contracting with respect to an $\\ell_p$-metric for some\n$p\\in [1,\\infty)\\cup\\{\\infty\\}$. This generalizes a recent result of Chen, Li,\nand Yannakakis [STOC'24] from the $\\ell_\\infty$-case to all $\\ell_p$-metrics.\nPreviously, all query upper bounds for $p\\in [1,\\infty) \\setminus \\{2\\}$ were\neither exponential in $d$, $\\log\\frac{1}{\\epsilon}$, or\n$\\log\\frac{1}{1-\\lambda}$.\n  Chen, Li, and Yannakakis also show how to ensure that all queries to $f$ lie\non a discrete grid of limited granularity in the $\\ell_\\infty$-case. We provide\nsuch a rounding for the $\\ell_1$-case, placing an appropriately defined version\nof the $\\ell_1$-case in $\\textsf{FP}^{dt}$.\n  To prove our results, we introduce the notion of $\\ell_p$-halfspaces and\ngeneralize the classical centerpoint theorem from discrete geometry: for any $p\n\\in [1, \\infty) \\cup \\{\\infty\\}$ and any mass distribution (or point set), we\nprove that there exists a centerpoint $c$ such that every $\\ell_p$-halfspace\ndefined by $c$ and a normal vector contains at least a $\\frac{1}{d+1}$-fraction\nof the mass (or points)."
    ],
    "c_categories":[
      [
        "cs.CC",
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-263",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10865",
    "b_title":[
      "A theory of ecological invasions and its implications for\n  eco-evolutionary dynamics"
    ],
    "b_abstract":[
      "Predicting the outcomes of species invasions is a central goal of ecology, a\ntask made especially challenging due to ecological feedbacks. To address this,\nwe develop a general theory of ecological invasions applicable to a wide\nvariety of ecological models: including Lotka-Volterra models, consumer\nresource models, and models with cross feeding. Importantly, our framework\nremains valid even when invading evolved (non-random) communities and accounts\nfor invasion-driven species extinctions. We derive analytical expressions\nrelating invasion fitness to invader abundance, shifts in the community, and\nextinction probabilities. These results can be understood through a new\nquantity we term ``dressed invasion fitness'', which augments the traditional\nnotion of invasion fitness by incorporating ecological feedbacks. We apply our\ntheory to analyze short-term evolutionary dynamics through a series of\ninvasions by mutants whose traits are correlated with an existing parent. We\ndemonstrate that, generically, mutants and parents can coexist, often by\ndriving the extinction of low-abundance species. We validate theoretical\npredictions against experimental datasets spanning ecosystems from plants to\nmicrobial protists. Our work highlights the central role of ecological\nfeedbacks in shaping community responses to invasions and mutations, suggesting\nthat parent-mutant coexistence is widespread in eco-evolutionary dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Physics"
      ]
    ],
    "c_id":"2503.03490",
    "c_title":[
      "On the construction of polynomial Poisson algebras: a novel grading\n  approach"
    ],
    "c_abstract":[
      "In this work, we refine recent results on the explicit construction of\npolynomial algebras associated with commutants of subalgebras in enveloping\nalgebras of Lie algebras by considering an additional grading with respect to\nthe subalgebra. It is shown that such an approach simplifies and systematizes\nthe explicit derivation of the Lie--Poisson brackets of elements in the\ncommutant, and several fundamental properties of the grading are given. The\nprocedure is illustrated by revisiting three relevant reduction chains\nassociated with the rank-two complex simple Lie algebra\n$\\mathfrak{sl}(3,\\mathbb{C})$. Specifically, we analyze the reduction chains\n$\\mathfrak{so}(3) \\subset \\mathfrak{su}(3)$, corresponding to the Elliott model\nin nuclear physics, the chain $\\mathfrak{o}(3) \\subset\n\\mathfrak{sl}(3,\\mathbb{C})$ associated with the decomposition of the\nenveloping algebra of $\\mathfrak{sl}(3,\\mathbb{C})$ as a sum of modules, and\nthe reduction chain $\\mathfrak{h} \\subset \\mathfrak{sl}(3,\\mathbb{C})$\nconnected to the Racah algebra $R(3)$. In addition, a description of the\nclassification of the centralizer with respect to the Cartan subalgebra\n$\\mathfrak{h}$ associated with the classical series $A_n$ in connection with\nits root system is reconsidered. As an illustration of the procedure, the case\nof $S(A_3)^\\mathfrak{h}$ is considered in detail, which is connected with the\nrank-two Racah algebra for specific realizations of the generators as vector\nfields. This case has attracted interest with regard to orthogonal polynomials."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-264",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09156",
    "b_title":[
      "Absolute Risk Prediction for Cannabis Use Disorder Using Bayesian\n  Machine Learning"
    ],
    "b_abstract":[
      "Introduction: Substance use disorders (SUDs) have emerged as a pressing\npublic health crisis in the United States, with adolescent substance use often\nleading to SUDs in adulthood. Effective strategies are needed to prevent this\nprogression. To help in filling this need, we develop a novel and the\nfirst-ever absolute risk prediction model for cannabis use disorder (CUD) for\nadolescent or young adult cannabis users.\n  Methods: We train a Bayesian machine learning model that provides a\npersonalized CUD absolute risk for adolescent or young adult cannabis users\nusing data from the National Longitudinal Study of Adolescent to Adult Health.\nModel performance is assessed using 5-fold cross-validation (CV) with area\nunder the curve (AUC) and ratio of the expected to observed number of cases\n(E\/O). External validation of the final model is conducted using two\nindependent datasets.\n  Results: The proposed model has five risk factors: biological sex,\ndelinquency, and scores on personality traits of conscientiousness,\nneuroticism, and openness. For predicting CUD risk within five years of first\ncannabis use, AUC and E\/O, computed via 5-fold CV, were 0.68 and 0.95,\nrespectively. For the same type of prediction in external validation, AUC\nvalues were 0.64 and 0.75, with E\/O values of 0.98 and 1, indicating good\ndiscrimination and calibration performances of the model.\n  Discussion and Conclusion: The proposed model is the first absolute risk\nprediction model for an SUD. It can aid clinicians in identifying\nadolescent\/youth substance users at a high risk of developing CUD in future for\nclinically appropriate interventions."
    ],
    "b_categories":[
      [
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.14577",
    "c_title":[
      "PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose\n  Alzheimer's Disease"
    ],
    "c_abstract":[
      "The accurate diagnosis of Alzheimer's disease (AD) and prognosis of mild\ncognitive impairment (MCI) conversion are crucial for early intervention.\nHowever, existing multimodal methods face several challenges, from the\nheterogeneity of input data, to underexplored modality interactions, missing\ndata due to patient dropouts, and limited data caused by the time-consuming and\ncostly data collection process. In this paper, we propose a novel Prompted\nHypergraph Neural Network (PHGNN) framework that addresses these limitations by\nintegrating hypergraph based learning with prompt learning. Hypergraphs capture\nhigher-order relationships between different modalities, while our prompt\nlearning approach for hypergraphs, adapted from NLP, enables efficient training\nwith limited data. Our model is validated through extensive experiments on the\nADNI dataset, outperforming SOTA methods in both AD diagnosis and the\nprediction of MCI conversion."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-265",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13597",
    "b_title":[
      "A Comprehensive Survey on Spectral Clustering with Graph Structure\n  Learning"
    ],
    "b_abstract":[
      "Spectral clustering is a powerful technique for clustering high-dimensional\ndata, utilizing graph-based representations to detect complex, non-linear\nstructures and non-convex clusters. The construction of a similarity graph is\nessential for ensuring accurate and effective clustering, making graph\nstructure learning (GSL) central for enhancing spectral clustering performance\nin response to the growing demand for scalable solutions. Despite advancements\nin GSL, there is a lack of comprehensive surveys specifically addressing its\nrole within spectral clustering. To bridge this gap, this survey presents a\ncomprehensive review of spectral clustering methods, emphasizing on the\ncritical role of GSL. We explore various graph construction techniques,\nincluding pairwise, anchor, and hypergraph-based methods, in both fixed and\nadaptive settings. Additionally, we categorize spectral clustering approaches\ninto single-view and multi-view frameworks, examining their applications within\none-step and two-step clustering processes. We also discuss multi-view\ninformation fusion techniques and their impact on clustering data. By\naddressing current challenges and proposing future research directions, this\nsurvey provides valuable insights for advancing spectral clustering\nmethodologies and highlights the pivotal role of GSL in tackling large-scale\nand high-dimensional data clustering tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09516",
    "c_title":[
      "Proximal Quasi-Newton Method for Composite Optimization over the Stiefel\n  Manifold"
    ],
    "c_abstract":[
      "In this paper, we consider the composite optimization problems over the\nStiefel manifold. A successful method to solve this class of problems is the\nproximal gradient method proposed by Chen et al. Motivated by the proximal\nNewton-type techniques in the Euclidean space, we present a Riemannian proximal\nquasi-Newton method, named ManPQN, to solve the composite optimization\nproblems. The global convergence of the ManPQN method is proved and iteration\ncomplexity for obtaining an $\\epsilon$-stationary point is analyzed. Under some\nmild conditions, we also establish the local linear convergence result of the\nManPQN method. Numerical results are encouraging, which shows that the proximal\nquasi-Newton technique can be used to accelerate the proximal gradient method."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-266",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07446",
    "b_title":[
      "EigenGS Representation: From Eigenspace to Gaussian Image Space"
    ],
    "b_abstract":[
      "Principal Component Analysis (PCA), a classical dimensionality reduction\ntechnique, and 2D Gaussian representation, an adaptation of 3D Gaussian\nSplatting for image representation, offer distinct approaches to modeling\nvisual data. We present EigenGS, a novel method that bridges these paradigms\nthrough an efficient transformation pipeline connecting eigenspace and\nimage-space Gaussian representations. Our approach enables instant\ninitialization of Gaussian parameters for new images without requiring\nper-image optimization from scratch, dramatically accelerating convergence.\nEigenGS introduces a frequency-aware learning mechanism that encourages\nGaussians to adapt to different scales, effectively modeling varied spatial\nfrequencies and preventing artifacts in high-resolution reconstruction.\nExtensive experiments demonstrate that EigenGS not only achieves superior\nreconstruction quality compared to direct 2D Gaussian fitting but also reduces\nnecessary parameter count and training time. The results highlight EigenGS's\neffectiveness and generalization ability across images with varying resolutions\nand diverse categories, making Gaussian-based image representation both\nhigh-quality and viable for real-time applications."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02733",
    "c_title":[
      "Computational and Analytical Optimization of Helicon Antennas with a\n  Fast Full Wave Solver Exploiting Azimuthal Fourier Decomposition"
    ],
    "c_abstract":[
      "Plasma wakefield accelerators (PWA), such as AWAKE, require homogenous\nhigh-density plasmas. The Madison AWAKE Prototype (MAP) has been built to\ncreate a uniform argon plasma in the $10^{20}\\,\\mathrm{m^{-3}}$ density range\nusing helicon waves. Computational optimization of MAP plasmas requires\ncalculating the helicon wavefields and power deposition. This task is\ncomputationally expensive due to the geometry of high-performance half-helical\nantennas and the small wavelengths involved. We show here for the first time\nhow the 3D wavefields can be accurately calculated from a small number of\n2D-axisymmetric simulations. Our approach exploits an azimuthal Fourier\ndecomposition of the non-axisymmetric antenna currents to massively reduce\ncomputational cost and is implemented in the Comsol finite-element framework.\nThis new tool allows us to calculate the power deposition profiles for 800\ncombinations of plasma density, antenna length, and radial density profile\nshape. The results show the existence of an optimally coupling antenna length\nin dependence on the plasma density. This finding is independent of the exact\nradial profile shape. We are able to explain this relationship physically\nthrough a comparison of the antenna power spectrum with the helicon dispersion\nrelation. The result is a simple analytical expression that enables power\ncoupling and density optimization in any linear helicon device by means of\nantenna length shaping."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-267",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12118",
    "b_title":[
      "Quantum Thermodynamics on a limit cycle"
    ],
    "b_abstract":[
      "We consider a periodic quantum clock based on cooperative resonance\nfluorescence at zero temperature.\n  In the quantum case, this system has an exact steady state and the limit\ncycle appears in conditional quantum dynamics under homodyne detection. We show\nthat the intrinsic quantum phase diffusion on the limit cycle leads to\nfluctuations in the period. By simulating the stochastic master equation for\nhomodyne detection, we extract the statistical properties of the clock period.\nWe show that the precision of the clock satisfies the quantum-thermodynamic\nkinetic uncertainty relations. As energy dissipation increases, the clock\nquality improves, fully validating, in a quantum stochastic system, the link\nbetween energy dissipation and clock precision."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.05532",
    "c_title":[
      "Impact of adiabatic temperature fluctuations on the power spectrum of\n  axion density perturbations"
    ],
    "c_abstract":[
      "Axions and axion-like particles (ALPs) have gained substantial attention as\npotential candidates for cold dark matter. The ALP field can exhibit\nfluctuations stemming from initial conditions. These initial field fluctuations\nhold the potential to give rise to gravitationally bound configurations known\nas axion miniclusters (AMC). While this proposition is widely accepted in the\npost-inflationary Peccei-Quinn symmetry-breaking scenario, uncertainties\npersist regarding the pre-inflationary scenario, where the effects of the\ninitial field fluctuations may be suppressed by inflation. In this study, we\ninvestigate the influence of adiabatic temperature fluctuations of the\nprimordial plasma on the evolution of axion density perturbations and their\npower spectrum, aiming to explore the possibility of AMC formation in the\npre-inflationary scenario. Our analysis reveals that the impact of adiabatic\ntemperature fluctuations becomes significant when $f_{\\rm a} \/ H_{\\rm inf}\n\\gtrsim 1.25 \\times 10^4$ and surpasses that of quantum fluctuations by up to\nfive orders of magnitude on large scales. This emphasizes the possibility of\nalso forming AMC within the pre-inflationary scenario. Consequently, a\ndetection of AMC would not reliably differentiate between the pre- and\npost-inflationary origin of axions."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-268",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11721",
    "b_title":[
      "Identifying intermediate mass binary black hole mergers in AGN disks\n  using LISA"
    ],
    "b_abstract":[
      "We show that Laser Interferometer Space Antenna can uniquely identify the\nsites of intermediate-mass binary black hole (IMBBH) mergers if they occur in\nActive Galactic Nuclei (AGN) disks with a gas density $\\rho\\geq10^{-12} \\, {\\rm\ng\/cc}$ via measurement of dynamical friction effect in the gravitational\nwaveform. We find that even a single observation of a gravitational wave source\nwith a total mass of $10^3 M_{\\odot}$ and a mass ratio of 2 at a luminosity\ndistance of 3 Gpc is sufficient to confidently associate the merger to be in an\nAGN disk with a density $\\sim 10^{-12} \\, {\\rm g\/cc}$, as it allows estimation\nof the density with an error bar ${\\cal O}(100\\%)$. This provides a new way of\ninferring AGN disk densities that complement traditional X-ray observations.\nFurther, we find that neglecting the presence of environmental effects in the\nwaveform models used for parameter estimation can bias the chirp mass, mass\nratio and arrival time of a merger. If not corrected, this can significantly\nimpact our ability to carry out multiband data analysis of IMBBHs that combines\ninformation from LISA and the ground-based gravitational wave detectors."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09134",
    "c_title":[
      "Benchmarking Robustness of Contrastive Learning Models for Medical\n  Image-Report Retrieval"
    ],
    "c_abstract":[
      "Medical images and reports offer invaluable insights into patient health. The\nheterogeneity and complexity of these data hinder effective analysis. To bridge\nthis gap, we investigate contrastive learning models for cross-domain\nretrieval, which associates medical images with their corresponding clinical\nreports. This study benchmarks the robustness of four state-of-the-art\ncontrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We\nintroduce an occlusion retrieval task to evaluate model performance under\nvarying levels of image corruption. Our findings reveal that all evaluated\nmodels are highly sensitive to out-of-distribution data, as evidenced by the\nproportional decrease in performance with increasing occlusion levels. While\nMedCLIP exhibits slightly more robustness, its overall performance remains\nsignificantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a\ngeneral-purpose dataset, struggles with medical image-report retrieval,\nhighlighting the importance of domain-specific training data. The evaluation of\nthis work suggests that more effort needs to be spent on improving the\nrobustness of these models. By addressing these limitations, we can develop\nmore reliable cross-domain retrieval models for medical applications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-269",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15896",
    "b_title":[
      "Modeling the emission lines from r-process elements in Supernova nebulae"
    ],
    "b_abstract":[
      "The origin of heavy r-process elements in the universe is still a matter of\ngreat debate, with a confirmed scenario being neutron star (NS) mergers.\nAdditional relevant sites could be specific classes of events, such as\ngamma-ray burst (GRB) Supernovae (SNe), where a central engine could push\nneutron-rich material outwards, contributing to the ejecta of the massive\nexploding star. Here, we investigate our ability to infer the production of\nheavy elements in such scenarios, on the basis of the observed nebular\nemission. We solve the steady-state ionization, level population, and thermal\nbalance, for optically thin ejecta in non-local thermodynamic equilibrium\n(NLTE), in order to explore the role of heavy elements in cooling the gas, and\ntheir imprint in the emergent spectrum a few hundreds days post-explosion. We\nfind that heavy elements would be relevant in the cooling process of the nebula\nonly if they account for at least $\\sim1\\%$ of the total ejected mass, at the\ntypical kinetic temperatures of a few thousands K. However, even in the absence\nof such amount, a few $0.1\\%$ of the total ejected mass could be instead\nsufficient to leave a detectable imprint around $\\sim1-10~\\mathrm{\\mu m}$. This\nwavelength range, which would be relatively clean from features due to light\nelements, would be instead robustly populated by lines from heavy elements\narising from forbidden transitions in their atomic fine structures. Hence, the\nnew generation of telescopes, represented by the James Webb Space Telescope\n(JWST), will most likely allow for their detection."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13666",
    "c_title":[
      "Countably compact inverse semigroups and Nyikos problem"
    ],
    "c_abstract":[
      "A regular separable first-countable countably compact space is called a {\\em\nNyikos} space. In this paper, we give a partial solution to an old problem of\nNyikos by showing that each locally compact Nyikos inverse topological\nsemigroup is compact. Also, we show that a topological semigroup $S$ that\ncontains a dense inverse subsemigroup is a topological inverse semigroup,\nprovided (i) $S$ is compact, or (ii) $S$ is countably compact and sequential.\nThe latter result solves a problem of Banakh and Pastukhova and provides the\nautomatic continuity of inversion in certain compact-like inverse semigroups."
    ],
    "c_categories":[
      [
        "math.GN",
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-270",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16451",
    "b_title":[
      "Think-Then-React: Towards Unconstrained Human Action-to-Reaction\n  Generation"
    ],
    "b_abstract":[
      "Modeling human-like action-to-reaction generation has significant real-world\napplications, like human-robot interaction and games. Despite recent\nadvancements in single-person motion generation, it is still challenging to\nwell handle action-to-reaction generation, due to the difficulty of directly\npredicting reaction from action sequence without prompts, and the absence of a\nunified representation that effectively encodes multi-person motion. To address\nthese challenges, we introduce Think-Then-React (TTR), a large\nlanguage-model-based framework designed to generate human-like reactions.\nFirst, with our fine-grained multimodal training strategy, TTR is capable to\nunify two processes during inference: a thinking process that explicitly infers\naction intentions and reasons corresponding reaction description, which serve\nas semantic prompts, and a reacting process that predicts reactions based on\ninput action and the inferred semantic prompts. Second, to effectively\nrepresent multi-person motion in language models, we propose a unified motion\ntokenizer by decoupling egocentric pose and absolute space features, which\neffectively represents action and reaction motion with same encoding. Extensive\nexperiments demonstrate that TTR outperforms existing baselines, achieving\nsignificant improvements in evaluation metrics, such as reducing FID from 3.988\nto 1.942."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15230",
    "c_title":[
      "Turbulence modulation in particle-laden channel flow: the particle\n  inertial effects"
    ],
    "c_abstract":[
      "The particle inertial effects on turbulence modulation in particle-laden\nchannel flow are investigated through four-way coupled point-particle direct\nnumerical simulations, with the mass loading fixed at $0.6$ and friction Stokes\nnumber $St^+$ varying from $3$ to $300$. A full transition pathway is realized\nin sequence from a drag-enhanced to a drag-reduced flow regime, before\nasymptotically approaching the single-phase state as $St^+$ increases\ncontinuously up to 300. For the first time, a set of transport equations for\nthe particle phase is derived analytically to interpret the inter-phase\ncoupling, in the context of the point-based statistical description of\nparticle-laden turbulence. By virtue of this, two dominant mechanisms are\nsubstantially identified and quantified: a positive, particle-induced extra\ntransport, which decreases monotonically with $St^+$, and a negative,\nparticle-induced extra dissipation, which depends non-monotonically on $St^+$.\nThe coupling of these two mechanisms leads to a direct contribution of particle\nphase to the shear stress balance, turbulent kinetic energy, and Reynolds\nstress budgets. As a consequence, with the increase of particle inertia, the\nself-sustaining cycle of near-wall turbulence transitions from being augmented\nto being suppressed and, eventually, recovers to the single-phase situation.\nThis gives rise to an indirect effect, manifested by the non-monotonic\nmodification of Reynolds shear stress and turbulent production rate. Taken\ntogether, comprehensive interplays between particle-modified turbulent\ntransport, particle-induced extra transport and dissipation are analyzed and\nsummarized, providing a holistic physical picture composed of consistent\ninterpretations of turbulence modulation."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-271",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11337",
    "b_title":[
      "A Comparison of Human and Machine Learning Errors in Face Recognition"
    ],
    "b_abstract":[
      "Machine learning applications in high-stakes scenarios should always operate\nunder human oversight. Developing an optimal combination of human and machine\nintelligence requires an understanding of their complementarities, particularly\nregarding the similarities and differences in the way they make mistakes. We\nperform extensive experiments in the area of face recognition and compare two\nautomated face recognition systems against human annotators through a\ndemographically balanced user study. Our research uncovers important ways in\nwhich machine learning errors and human errors differ from each other, and\nsuggests potential strategies in which human-machine collaboration can improve\naccuracy in face recognition."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.CY",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09280",
    "c_title":[
      "The effect of accretion on scalar superradiant instability"
    ],
    "c_abstract":[
      "Superradiance can lead to the formation of a black hole (BH) condensate\nsystem. We thoroughly investigate the accretion effect on the evolution of this\nsystem, and the gravitational wave signals it emits in the presence of multiple\nsuperradiance modes. Assuming the multiplication of the BH mass and scalar mass\nas a small number, we obtain the analytical approximations of all important\nquantities, which can be directly applied to phenomenological studies. In\naddition, we confirm that accretion could significantly enhance the\ngravitational wave (GW) emission and reduce its duration, and show that the GW\nbeat signature is similarly modified."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-272",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01526",
    "b_title":[
      "On quivers, spectral networks and black holes"
    ],
    "b_abstract":[
      "It was recently found that connection coefficients of the Heun equation can\nbe derived in closed form using crossing symmetry in two-dimensional Liouville\ntheory via the Nekrasov-Shatashvili functions. In this work, we systematize\nthis approach to second-order linear ODEs of Fuchsian type, which arise in the\ndescription of N = 2, four-dimensional quiver gauge theories. After presenting\nthe general procedure, we focus on the specific case of Fuchsian equations with\nfive regular singularities and present some applications to black hole\nperturbation theory. First, we consider a massive scalar perturbation of the\nSchwarzschild black hole in AdS7. Next, we analyze vector type perturbations of\nthe Reissner-Nordstr\\\"om-AdS5 black hole. We also discuss the implications of\nour results in the context of the AdS\/CFT correspondence and present explicit\nresults in the large spin limit, where we make connection with the light-cone\nbootstrap. Furthermore, using the spectral network technology, we identify the\nregion of the moduli space in Seiberg-Witten theory that is relevant for the\nstudy of black hole quasinormal modes. Our results suggest that, in some cases,\nthis region corresponds to the strong-coupling regime, highlighting the\npotential applicability of the conformal GMN TBA framework to address scenarios\nwhere the gravitational dictionary implies that the instanton counting\nparameters are not parametrically small."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15834",
    "c_title":[
      "The Strong Core of Housing Markets with Partial Order Preferences"
    ],
    "c_abstract":[
      "We study the strong core of housing markets when agents' preferences over\nhouses are expressed as partial orders. We provide a structural\ncharacterization of the strong core, and propose an efficient algorithm that\nfinds an allocation in the strong core or decides that it is empty, even in the\npresence of forced and forbidden arcs. The algorithm satisfies the property of\ngroup-strategyproofness. Additionally, we show that certain results known for\nthe strong core in the case when agents' preferences are weak orders can be\nextended to the setting with partial order preferences; among others, we show\nthat the strong core in such housing markets satisfies the property of\nrespecting improvements."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-273",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16237",
    "b_title":[
      "3D radio data visualisation in open science platforms for\n  next-generation observatories"
    ],
    "b_abstract":[
      "Next-generation telescopes will bring groundbreaking discoveries but they\nwill also present new technological challenges. The Square Kilometre Array\nObservatory (SKAO) will be one of the most demanding scientific\ninfrastructures, with a projected data output of 700 PB per year to be\ndistributed to a network of SKA Regional Centres. Current tools are not fully\nsuited to manage such massive data volumes, therefore, new research is required\nto transform science archives from data providers into service providers. In\nthis paper we examine how a science archive can deliver advanced visualisation\ncapabilities for the SKA science archive. In particular, we have conducted a\nthorough exploration of existing visualisation software for astronomy and other\nfields to identify tools capable of addressing Big Data requirements. Using\nselected technologies, we have developed a prototype archive that provides\naccess to interactive visualisations of 3D radio data through web-based\ninterfaces, adhering to International Virtual Observatory Alliance (IVOA)\nrecommendations to favour interoperability and Open Science practices. In\naddition, we discuss how current IVOA recommendations support these\nvisualisation capabilities and how they could be expanded. Our prototype\narchive includes a service to generate 3D models on the fly as a server\noperation, enabling remote visualisations in a flexible manner; for instance, a\nset of parameters can be used to customise the models and their visualisation.\nWe have used SKA precursor and pathfinder data to test its usability and\nscalability, concluding that remote visualisation is a viable solution for\nhandling high-volume data. However, our prototype is constrained by memory\nlimitations, requiring techniques to reduce memory usage."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07258",
    "c_title":[
      "MC-GRU:a Multi-Channel GRU network for generalized nonlinear structural\n  response prediction across structures"
    ],
    "c_abstract":[
      "Accurate prediction of seismic responses and quantification of structural\ndamage are critical in civil engineering. Traditional approaches such as finite\nelement analysis could lack computational efficiency, especially for complex\nstructural systems under extreme hazards. Recently, artificial intelligence has\nprovided an alternative to efficiently model highly nonlinear behaviors.\nHowever, existing models face challenges in generalizing across diverse\nstructural systems. This paper proposes a novel multi-channel gated recurrent\nunit (MC-GRU) network aimed at achieving generalized nonlinear structural\nresponse prediction for varying structures. The key concept lies in the\nintegration of a multi-channel input mechanism to GRU with an extra input of\nstructural information to the candidate hidden state, which enables the network\nto learn the dynamic characteristics of diverse structures and thus empower the\ngeneralizability and adaptiveness to unseen structures. The performance of the\nproposed MC-GRU is validated through a series of case studies, including a\nsingle-degree-of-freedom linear system, a hysteretic Bouc-Wen system, and a\nnonlinear reinforced concrete column from experimental testing. Results\nindicate that the proposed MC-GRU overcomes the major generalizability issues\nof existing methods, with capability of accurately inferring seismic responses\nof varying structures. Additionally, it demonstrates enhanced capabilities in\nrepresenting nonlinear structural dynamics compared to traditional models such\nas GRU and LSTM."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-274",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00110",
    "b_title":[
      "New constraints on the evolution of the MHI-M* scaling relation\n  combining CHILES and MIGHTEE-HI data"
    ],
    "b_abstract":[
      "The improved sensitivity of interferometric facilities to the 21-cm line of\natomic hydrogen (HI) enables studies of its properties in galaxies beyond the\nlocal Universe. In this work, we perform a 21 cm line spectral stacking\nanalysis combining the MIGHTEE and CHILES surveys in the COSMOS field to derive\na robust HI-stellar mass relation at z=0.36. In particular, by stacking\nthousands of star-forming galaxies subdivided into stellar mass bins, we\noptimize the signal-to-noise ratio of targets and derive mean HI masses in the\ndifferent stellar mass intervals for the investigated galaxy population. We\ncombine spectra from the two surveys, estimate HI masses, and derive the\nscaling relation log10(MHI) = (0.32 +- 0.04)log10(M*) + (6.65 +- 0.36). Our\nfindings indicate that galaxies at z=0.36 are HI richer than those at z=0, but\nHI poorer than those at z=1, with a slope consistent across redshift,\nsuggesting that stellar mass does not significantly affect HI exchange\nmechanisms. We also observe a slower growth rate HI relative to the molecular\ngas, supporting the idea that the accretion of cold gas is slower than the rate\nof consumption of molecular gas to form stars. This study contributes to\nunderstanding the role of atomic gas in galaxy evolution and sets the stage for\nfuture development of the field in the upcoming SKA era."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09052",
    "c_title":[
      "Bipartite Tur\\'an number of trees"
    ],
    "c_abstract":[
      "We start a systematic investigation concerning bipartite Tur\\'an number for\ntrees. For a graph $F$ and integers $1 \\leq a \\leq b$ we define:\n  $(i)$\\quad $ex_b(a, b, F)$ is the largest number of edges that an $F$-free\nbipartite graph can have with part sizes $a$ and $b$. We write $ex_b(n, F)$ for\n$ex_b(n, n, F)$.\n  $(ii)$\\quad $ex_{b,c}(a, b, F)$ is the largest number of edges that an\n$F$-free connected, bipartite graph can have with part sizes $a$ and $b$. We\nwrite $ex_{b,c}(n, F)$ for $ex{b,c}(n, n, F)$.\n  Both definitions are similar for a family $\\mathcal{F}$ of graphs.\n  We prove general lower bounds depending on the maximum degree of $F$, as well\nas on the cardinalities of the two vertex classes of $F$.\n  We derive upper and lower bounds for $ex_b(n,F)$ in terms of $ex(2n,F)$ and\n$ex(n, F)$, the corresponding classical (not bipartite) Tur\\'an numbers.\n  We solve both problems for various classes of graphs, including all trees up\nto six vertices for any $n$, for double stars $D_{s ,t}$ if $a \\geq f(s,t )$,\nfor some families of spiders, and more.\n  We use these results to supply an answer to a problem raised by L. T. Yuan\nand X. D. Zhang [{\\it Graphs and Combinatorics}, 2017] concerning $ex_b( n,\n\\mathcal{T}_{k,\\ell} )$, where $\\mathcal{T}_{k,\\ell}$ is the family of all\ntrees with vertex classes of respective cardinalities $k$ and $\\ell$.\n  The asymptotic worst-case ratios between Tur\\'an-type functions are also\ninverstigated."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-275",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10658",
    "b_title":[
      "LimTopic: LLM-based Topic Modeling and Text Summarization for Analyzing\n  Scientific Articles limitations"
    ],
    "b_abstract":[
      "The limitations sections of scientific articles play a crucial role in\nhighlighting the boundaries and shortcomings of research, thereby guiding\nfuture studies and improving research methods. Analyzing these limitations\nbenefits researchers, reviewers, funding agencies, and the broader academic\ncommunity. We introduce LimTopic, a strategy where Topic generation in\nLimitation sections in scientific articles with Large Language Models (LLMs).\nHere, each topic contains the title and Topic Summary. This study focuses on\neffectively extracting and understanding these limitations through topic\nmodeling and text summarization, utilizing the capabilities of LLMs. We\nextracted limitations from research articles and applied an LLM-based topic\nmodeling integrated with the BERtopic approach to generate a title for each\ntopic and Topic Sentences. To enhance comprehension and accessibility, we\nemployed LLM-based text summarization to create concise and generalizable\nsummaries for each topic Topic Sentences and produce a Topic Summary. Our\nexperimentation involved prompt engineering, fine-tuning LLM and BERTopic, and\nintegrating BERTopic with LLM to generate topics, titles, and a topic summary.\nWe also experimented with various LLMs with BERTopic for topic modeling and\nvarious LLMs for text summarization tasks. Our results showed that the\ncombination of BERTopic and GPT 4 performed the best in terms of silhouette and\ncoherence scores in topic modeling, and the GPT4 summary outperformed other LLM\ntasks as a text summarizer."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16691",
    "c_title":[
      "Spatial-temporal models for forest inventory data"
    ],
    "c_abstract":[
      "The USDA Forest Inventory and Analysis (FIA) program conducts a national\nforest inventory for the United States through a network of permanent field\nplots. FIA produces estimates of area averages\/totals for plot-measured forest\nvariables through design-based inference, assuming a fixed population and a\nprobability sample of field plot locations. The fixed-population assumption and\ncharacteristics of the FIA sampling scheme make it difficult to estimate change\nin forest variables over time using design-based inference. We propose\nspatial-temporal models based on Gaussian processes as a flexible tool for\nforest inventory data, capable of inferring forest variables and change thereof\nover arbitrary spatial and temporal domains. It is shown to be beneficial for\nthe covariance function governing the latent Gaussian process to account for\nvariation at multiple scales, separating spatially local variation from\necosystem-scale variation. We demonstrate a model for forest biomass density,\ninferring 20 years of biomass change within two US National Forests."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-276",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11524",
    "b_title":[
      "The Scaled Polarity transform and related inequalities"
    ],
    "b_abstract":[
      "In this paper we deal with generalizations of the Mahler volume product for\nlog-concave functions. We show that the polarity transform $\\mathcal A$ can be\nrescaled so that the Mahler product it induces has upper and lower bounds of\nthe same asymptotics. We discuss a similar result for the $\\mathcal J$\ntransform.\n  As an application, we extend the K\\\"onig-Milman duality of entropy result to\nthe class of geometric log-concave functions."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10954",
    "c_title":[
      "Interactive Multiscale Modeling to Bridge Atomic Properties and\n  Electrochemical Performance in Li-CO$_2$ Battery Design"
    ],
    "c_abstract":[
      "Li-CO$_2$ batteries show promise as energy storage solutions, offering high\ntheoretical energy density and CO$_2$ fixation. Their operation is based on the\nformation and decomposition of Li$_2$CO$_3$\/C during discharge and charge\ncycles, respectively. We used a multiscale modeling framework that integrates\nDensity Functional Theory (DFT), Ab-Initio Molecular Dynamics (AIMD), classical\nMolecular Dynamics (MD), and Finite Element Analysis (FEA) to investigate\natomic and cell-level properties. The considered Li-CO$_2$ battery consists of\na lithium metal anode, an ionic liquid electrolyte, and a carbon cloth porous\ncathode with Sb$_{0.67}$Bi$_{1.33}$Te$_3$ as a catalyst. DFT and AIMD\ndetermined the electrical conductivities of Sb$_{0.67}$Bi$_{1.33}$Te$_3$ and\nLi$_2$CO$_3$ using the Kubo-Greenwood formalism and studied the CO$_2$\nreduction mechanism on the cathode catalyst. MD simulations calculated the\nCO$_2$ diffusion coefficient, Li$^+$ transference number, ionic conductivity,\nand Li$^+$ solvation structure. The FEA model, incorporating results from\natomistic simulations, reproduced experimental voltage-capacity profiles at 1\nmA\/cm$^2$ and revealed spatio-temporal variations in Li$_2$CO$_3$\/C deposition,\nporosity, and CO$_2$ concentration dependence on discharge rates in the\ncathode. Accordingly, Li$_2$CO$_3$ can form large and thin film deposits,\nleading to dispersed and local porosity changes at 0.1 mA\/cm$^2$ and 1\nmA\/cm$^2$, respectively. The capacity decreases exponentially from 81,570 mAh\/g\nat 0.1 mA\/cm$^2$ to 6,200 mAh\/g at 1 mA\/cm$^2$, due to pore clogging from\nexcessive discharge product deposition that limits CO$_2$ transport to the\ncathode interior. Therefore, the performance of Li-CO$_2$ batteries can be\nimproved by enhancing CO$_2$ transport, regulating Li$_2$CO$_3$ deposition, and\noptimizing cathode architecture."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-277",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09551",
    "b_title":[
      "Intra-day Solar and Power Forecast for Optimization of Intraday Market\n  Participation"
    ],
    "b_abstract":[
      "The prediction of solar irradiance enhances reliability in photovoltaic (PV)\nsolar plant generation and grid integration. In Colombia, PV plants face\npenalties if energy production deviates beyond governmental thresholds from\nintraday market offers. This research employs Long Short-Term Memory (LSTM) and\nBidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV\nplant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour\nhorizon and 10-minute resolution. While Bi-LSTM showed superior performance,\nthe LSTM model achieved comparable results with significantly reduced training\ntime (6 hours versus 18 hours), making it computationally advantageous. The\nLSTM predictions were averaged to create an hourly resolution model, evaluated\nusing Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square\nError, and Mean Absolute Percentage Error metrics. Comparison with the Global\nForecast System (GFS) revealed similar performance, with both models\neffectively capturing daily solar irradiance patterns. The forecast model\nintegrates with an Object-Oriented power production model, enabling accurate\nenergy offers in the intraday market while minimizing penalty costs."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05125",
    "c_title":[
      "When can we get away with using the two-way fixed effects regression?"
    ],
    "c_abstract":[
      "The use of the two-way fixed effects regression in empirical social science\nwas historically motivated by folk wisdom that it uncovers the Average\nTreatment effect on the Treated (ATT) as in the canonical two-period two-group\ncase. This belief has come under scrutiny recently due to recent results in\napplied econometrics showing that it fails to uncover meaningful averages of\nheterogeneous treatment effects in the presence of effect heterogeneity over\ntime and across adoption cohorts, and several heterogeneity-robust alternatives\nhave been proposed. However, these estimators often have higher variance and\nare therefore under-powered for many applications, which poses a bias-variance\ntradeoff that is challenging for researchers to navigate. In this paper, we\npropose simple tests of linear restrictions that can be used to test for\ndifferences in dynamic treatment effects over cohorts, which allows us to test\nfor when the two-way fixed effects regression is likely to yield biased\nestimates of the ATT. These tests are implemented as methods in the pyfixest\npython library."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-278",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16003",
    "b_title":[
      "Mechano-Bactericidal Surfaces Achieved by Epitaxial Growth of\n  Metal-Organic Frameworks"
    ],
    "b_abstract":[
      "Mechano-bactericidal (MB) surfaces have been proposed as an emerging strategy\nfor preventing biofilm formation. Unlike antibiotics and metal ions that\nchemically interfere with cellular processes, MB nanostructures cause physical\ndamage to the bacteria. The antibacterial performance of artificial MB surfaces\nrelies on rational control of surface features, which is difficult to achieve\nfor large surfaces in real-life applications. Herein, we report a facile and\nscalable method for fabricating MB surfaces based on metal-organic frameworks\n(MOFs) using epitaxial MOF-on-MOF hybrids as building blocks with nanopillars\nof less than 5 nm tip diameter, 200 nm base diameter, and 300 nm length. Two\nmethods of MOF surface assembly, in-situ growth and ex-situ dropcasting, result\nin surfaces with nanopillars in different orientations, both presenting MB\nactions (bactericidal efficiency of 83% for E. coli). Distinct MB mechanisms,\nincluding stretching, impaling, and apoptosis-like death induced by mechanical\ninjury are discussed with the observed bacterial morphology on the obtained MOF\nsurfaces."
    ],
    "b_categories":[
      [
        "physics.bio-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12587",
    "c_title":[
      "How Collective Intelligence Emerges in a Crowd of People Through Learned\n  Division of Labor: A Case Study"
    ],
    "c_abstract":[
      "This paper investigates the factors fostering collective intelligence (CI)\nthrough a case study of *LinYi's Experiment, where over 2000 human players\ncollectively controll an avatar car. By conducting theoretical analysis and\nreplicating observed behaviors through numerical simulations, we demonstrate\nhow self-organized division of labor (DOL) among individuals fosters the\nemergence of CI and identify two essential conditions fostering CI by\nformulating this problem into a stability problem of a Markov Jump Linear\nSystem (MJLS). These conditions, independent of external stimulus, emphasize\nthe importance of both elite and common players in fostering CI. Additionally,\nwe propose an index for emergence of CI and a distributed method for estimating\njoint actions, enabling individuals to learn their optimal social roles without\nglobal action information of the whole crowd."
    ],
    "c_categories":[
      [
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-279",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19402",
    "b_title":[
      "A note on spontaneous symmetry breaking in the mean-field Bose gas"
    ],
    "b_abstract":[
      "We consider the homogeneous mean-field Bose gas at positive temperature. We\nshow that spontaneous $U(1)$ symmetry breaking occurs if and only if the system\ndisplays Bose-Einstein condensation in the sense that the one-particle density\nmatrix of the Gibbs state has a macroscopic eigenvalue."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.AP",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.13047",
    "c_title":[
      "InsightDrive: Insight Scene Representation for End-to-End Autonomous\n  Driving"
    ],
    "c_abstract":[
      "Directly generating planning results from raw sensors has become increasingly\nprevalent due to its adaptability and robustness in complex scenarios. Scene\nrepresentation, as a key module in the pipeline, has traditionally relied on\nconventional perception, which focus on the global scene. However, in driving\nscenarios, human drivers typically focus only on regions that directly impact\ndriving, which often coincide with those required for end-to-end autonomous\ndriving. In this paper, a novel end-to-end autonomous driving method called\nInsightDrive is proposed, which organizes perception by language-guided scene\nrepresentation. We introduce an instance-centric scene tokenizer that\ntransforms the surrounding environment into map- and object-aware instance\ntokens. Scene attention language descriptions, which highlight key regions and\nobstacles affecting the ego vehicle's movement, are generated by a\nvision-language model that leverages the cognitive reasoning capabilities of\nfoundation models. We then align scene descriptions with visual features using\nthe vision-language model, guiding visual attention through these descriptions\nto give effectively scene representation. Furthermore, we employ self-attention\nand cross-attention mechanisms to model the ego-agents and ego-map\nrelationships to comprehensively build the topological relationships of the\nscene. Finally, based on scene understanding, we jointly perform motion\nprediction and planning. Extensive experiments on the widely used nuScenes\nbenchmark demonstrate that the proposed InsightDrive achieves state-of-the-art\nperformance in end-to-end autonomous driving. The code is available at\nhttps:\/\/github.com\/songruiqi\/InsightDrive"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-280",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17894",
    "b_title":[
      "FetchBot: Object Fetching in Cluttered Shelves via Zero-Shot Sim2Real"
    ],
    "b_abstract":[
      "Object fetching from cluttered shelves is an important capability for robots\nto assist humans in real-world scenarios. Achieving this task demands robotic\nbehaviors that prioritize safety by minimizing disturbances to surrounding\nobjects, an essential but highly challenging requirement due to restricted\nmotion space, limited fields of view, and complex object dynamics. In this\npaper, we introduce FetchBot, a sim-to-real framework designed to enable\nzero-shot generalizable and safety-aware object fetching from cluttered shelves\nin real-world settings. To address data scarcity, we propose an efficient\nvoxel-based method for generating diverse simulated cluttered shelf scenes at\nscale and train a dynamics-aware reinforcement learning (RL) policy to generate\nobject fetching trajectories within these scenes. This RL policy, which\nleverages oracle information, is subsequently distilled into a vision-based\npolicy for real-world deployment. Considering that sim-to-real discrepancies\nstem from texture variations mostly while from geometric dimensions rarely, we\npropose to adopt depth information estimated by full-fledged depth foundation\nmodels as the input for the vision-based policy to mitigate sim-to-real gap. To\ntackle the challenge of limited views, we design a novel architecture for\nlearning multi-view representations, allowing for comprehensive encoding of\ncluttered shelf scenes. This enables FetchBot to effectively minimize\ncollisions while fetching objects from varying positions and depths, ensuring\nrobust and safety-aware operation. Both simulation and real-robot experiments\ndemonstrate FetchBot's superior generalization ability, particularly in\nhandling a broad range of real-world scenarios, includ"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03709",
    "c_title":[
      "The log concavity of two graphical sequences"
    ],
    "c_abstract":[
      "We show that the large Cartesian powers of any graph have log-concave\nvalencies with respect to a ffxed vertex. We show that the series of valencies\nof distance regular graphs is log-concave, thus improving on a result of\n(Taylor, Levingston, 1978). Consequences for strongly regular graphs,\ntwo-weight codes, and completely regular codes are derived. By P-Q duality of\nassociation schemes the series of multiplicities of Q-polynomial association\nschemes is shown, under some assumption, to be log-concave."
    ],
    "c_categories":[
      [
        "cs.CR",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-281",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21220",
    "b_title":[
      "XAIxArts Manifesto: Explainable AI for the Arts"
    ],
    "b_abstract":[
      "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13157",
    "c_title":[
      "Approximate Bayesian Kernel Machine Regression via Random Fourier\n  Features for Estimating Joint Health Effects of Multiple Exposures"
    ],
    "c_abstract":[
      "Environmental epidemiology has traditionally focused on examining health\neffects of single exposures, more recently with adjustment for co-occurring\nexposures. Advancements in exposure assessments and statistical tools have\nenabled a shift towards studying multiple exposures and their combined health\nimpacts. Bayesian Kernel Machine Regression (BKMR) is a popular approach to\nflexibly estimate the joint and nonlinear effects of multiple exposures.\nHowever, BKMR faces computation challenges for large datasets, as inverting the\nkernel repeatedly in Markov chain Monte Carlo (MCMC) algorithms can be\ntime-consuming and often infeasible in practice. To address this issue, we\npropose a faster version of BKMR using supervised random Fourier features to\napproximate the Gaussian process. We use periodic functions as basis functions\nand this approximation re-frames the kernel machine regression into a linear\nmixed-effect model that facilitates computationally efficient estimation and\nprediction. Bayesian inference was conducted using MCMC with Hamiltonian Monte\nCarlo algorithms. Analytic code for implementing Fast BKMR was developed for R.\nSimulation studies demonstrated that this approximation method yields results\ncomparable to the original Gaussian process while reducing the computation time\nby 29 to 99%, depending on the number of basis functions and sample sizes. Our\napproach is also more robust to kernel misspecification in some scenarios.\nFinally, we applied this approach to analyze over 270,000 birth records,\nexamining associations between multiple ambient air pollutants and birthweight\nin Georgia."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-282",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08768",
    "b_title":[
      "Instantaneous directional channel measurements at 14 GHz and 160 GHz via\n  a virtual circular array"
    ],
    "b_abstract":[
      "In this paper a novel frequency-scalable rotary platform design is introduced\nwhich allows for flexible directional channel measurements using different\ntypes of antennas, and which can also be used with frequency extenders for\nmeasurements up to the THz region. The measurement platform has been applied to\nmeasure the channel properties including the direction of arrival at the FR3\nfrequency 14 GHz and in the D-band at 160 GHz in a large hall indoor\nenvironment with LOS distances up to 40 m. The results show very good agreement\nof strong path components for both frequencies as well as interesting\ndependencies of delay spread, angular spread, and Ricean K- factor on distance\nand frequency and can be used to parameterize a path loss model."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07665",
    "c_title":[
      "Nonparametric estimation of the multivariate Spearman's footrule: a\n  further discussion"
    ],
    "c_abstract":[
      "In this paper, we propose two new estimators of the multivariate rank\ncorrelation coefficient Spearman's footrule which are based on two general\nestimators for Average Orthant Dependence measures. We compare the new\nproposals with a previous estimator existing in the literature and show that\nthe three estimators are asymptotically equivalent, but, in small samples, one\nof the proposed estimators outperforms the others. We also analyse Pitman\nefficiency of these indices to test for multivariate independence as compared\nto multivariate versions of Kendall's tau and Spearman's rho."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-283",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10370",
    "b_title":[
      "Explicit Formulas for the Alexander Polynomial of Pretzel Knots"
    ],
    "b_abstract":[
      "We provide explicit formulas for the Alexander polynomial of Pretzel knots\nand establish several immediate corollaries, including the characterization of\nPretzel knots with a trivial Alexander polynomial."
    ],
    "b_categories":[
      [
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.10228",
    "c_title":[
      "Policy Teaching via Data Poisoning in Learning from Human Preferences"
    ],
    "c_abstract":[
      "We study data poisoning attacks in learning from human preferences. More\nspecifically, we consider the problem of teaching\/enforcing a target policy\n$\\pi^\\dagger$ by synthesizing preference data. We seek to understand the\nsusceptibility of different preference-based learning paradigms to poisoned\npreference data by analyzing the number of samples required by the attacker to\nenforce $\\pi^\\dagger$. We first propose a general data poisoning formulation in\nlearning from human preferences and then study it for two popular paradigms,\nnamely: (a) reinforcement learning from human feedback (RLHF) that operates by\nlearning a reward model using preferences; (b) direct preference optimization\n(DPO) that directly optimizes policy using preferences. We conduct a\ntheoretical analysis of the effectiveness of data poisoning in a setting where\nthe attacker is allowed to augment a pre-existing dataset and also study its\nspecial case where the attacker can synthesize the entire preference dataset\nfrom scratch. As our main results, we provide lower\/upper bounds on the number\nof samples required to enforce $\\pi^\\dagger$. Finally, we discuss the\nimplications of our results in terms of the susceptibility of these learning\nparadigms under such data poisoning attacks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-284",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17709",
    "b_title":[
      "GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration"
    ],
    "b_abstract":[
      "GUI agents hold significant potential to enhance the experience and\nefficiency of human-device interaction. However, current methods face\nchallenges in generalizing across applications (apps) and tasks, primarily due\nto two fundamental limitations in existing datasets. First, these datasets\noverlook developer-induced structural variations among apps, limiting the\ntransferability of knowledge across diverse software environments. Second, many\nof them focus solely on navigation tasks, which restricts their capacity to\nrepresent comprehensive software architectures and complex user interactions.\nTo address these challenges, we introduce GUI-Xplore, a dataset meticulously\ndesigned to enhance cross-application and cross-task generalization via an\nexploration-and-reasoning framework. GUI-Xplore integrates pre-recorded\nexploration videos providing contextual insights, alongside five hierarchically\nstructured downstream tasks designed to comprehensively evaluate GUI agent\ncapabilities. To fully exploit GUI-Xplore's unique features, we propose\nXplore-Agent, a GUI agent framework that combines Action-aware GUI Modeling\nwith Graph-Guided Environment Reasoning. Further experiments indicate that\nXplore-Agent achieves a 10% improvement over existing methods in unfamiliar\nenvironments, yet there remains significant potential for further enhancement\ntowards truly generalizable GUI agents."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10428",
    "c_title":[
      "Langevin Monte-Carlo Provably Learns Depth Two Neural Nets at Any Size\n  and Data"
    ],
    "c_abstract":[
      "In this work, we will establish that the Langevin Monte-Carlo algorithm can\nlearn depth-2 neural nets of any size and for any data and we give\nnon-asymptotic convergence rates for it. We achieve this via showing that under\nTotal Variation distance and q-Renyi divergence, the iterates of Langevin Monte\nCarlo converge to the Gibbs distribution of Frobenius norm regularized losses\nfor any of these nets, when using smooth activations and in both classification\nand regression settings. Most critically, the amount of regularization needed\nfor our results is independent of the size of the net. This result combines\nseveral recent observations, like our previous papers showing that two-layer\nneural loss functions can always be regularized by a certain constant amount\nsuch that they satisfy the Villani conditions, and thus their Gibbs measures\nsatisfy a Poincare inequality."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.FA",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-285",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13435",
    "b_title":[
      "WideRange4D: Enabling High-Quality 4D Reconstruction with Wide-Range\n  Movements and Scenes"
    ],
    "b_abstract":[
      "With the rapid development of 3D reconstruction technology, research in 4D\nreconstruction is also advancing, existing 4D reconstruction methods can\ngenerate high-quality 4D scenes. However, due to the challenges in acquiring\nmulti-view video data, the current 4D reconstruction benchmarks mainly display\nactions performed in place, such as dancing, within limited scenarios. In\npractical scenarios, many scenes involve wide-range spatial movements,\nhighlighting the limitations of existing 4D reconstruction datasets.\nAdditionally, existing 4D reconstruction methods rely on deformation fields to\nestimate the dynamics of 3D objects, but deformation fields struggle with\nwide-range spatial movements, which limits the ability to achieve high-quality\n4D scene reconstruction with wide-range spatial movements. In this paper, we\nfocus on 4D scene reconstruction with significant object spatial movements and\npropose a novel 4D reconstruction benchmark, WideRange4D. This benchmark\nincludes rich 4D scene data with large spatial variations, allowing for a more\ncomprehensive evaluation of the generation capabilities of 4D generation\nmethods. Furthermore, we introduce a new 4D reconstruction method, Progress4D,\nwhich generates stable and high-quality 4D results across various complex 4D\nscene reconstruction tasks. We conduct both quantitative and qualitative\ncomparison experiments on WideRange4D, showing that our Progress4D outperforms\nexisting state-of-the-art 4D reconstruction methods. Project:\nhttps:\/\/github.com\/Gen-Verse\/WideRange4D"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02697",
    "c_title":[
      "Consumption-portfolio choice with preferences for liquid assets"
    ],
    "c_abstract":[
      "This paper investigates an infinite horizon, discounted,\nconsumption-portfolio problem in a market with one bond, one liquid risky\nasset, and one illiquid risky asset with proportional transaction costs. We\nconsider an agent with liquidity preference, modeled by a Cobb-Douglas utility\nfunction that includes the liquid wealth. We analyze the properties of the\nvalue function and divide the solvency region into three regions: the buying\nregion, the no-trading region, and the selling region, and prove that all three\nregions are non-empty. We mathematically characterize and numerically solve the\noptimal policy and prove its optimality. Our numerical analysis sheds light on\nthe impact of various parameters on the optimal policy, and some intuition and\neconomic insights behind it are also analyzed. We find that liquidity\npreference encourages agents to retain more liquid wealth and inhibits\nconsumption, and may even result in a negative allocation to the illiquid\nasset. The liquid risky asset not only affects the location of the three\nregions but also has an impact on consumption. However, whether this impact on\nconsumption is promoted or inhibited depends on the degree of risk aversion of\nagents."
    ],
    "c_categories":[
      [
        "q-fin.PM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-286",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02432",
    "b_title":[
      "Analysis of the $ q\\bar q\\to Z^* \\to hA \\to4\\tau$ process within the\n  lepton-specific 2HDM at the LHC"
    ],
    "b_abstract":[
      "We analyse light Higgs scalar and pseudoscalar associated hadro-production in\nthe 2-Higgs Doublet Model (2HDM) Type-X (or lepton-specific) within the\nparameter space allowed by theoretical self-consistency requirements as well as\nthe latest experimental constraints from the Large Hadron Collider (LHC),\nprecision data and $B$ physics. Over the viable regions of such a scenario, the\nStandard Model-like Higgs boson discovered at the LHC in 2012 is the heavier\nCP-even state $H$. Furthermore, in the Type-X scenario, due to large\n$\\tan\\beta$, the lighter Higgs scalar $h$ and the pseudoscalar $A$ mainly decay\ninto two $\\tau$ leptons. Therefore, we concentrate on analysing the signal\nprocess $pp\\to Z^{*} \\to hA\\to \\tau^{+}\\tau^{-}\\tau^{+}\\tau^{-}\\to \\ell\n\\nu_\\ell \\ell \\nu_\\ell \\tau_h \\tau_h$ (where $\\ell= e, \\mu$ whereas $\\tau_h$\nrepresents the hadronic decay of the $\\tau$) and explore the feasibility of\nconducting such a search at the LHC with a centre-of-mass energy of\n$\\sqrt{s}~=$ 14 TeV and a luminosity of $L~=~300~fb^{-1}$. To suppress the huge\nSM background, we confine ourselves to consider the fraction of signal events\nwith two same-sign $\\tau$ leptons further decaying into same-sign leptons while\nthe other two $\\tau$ leptons decay hadronically. We find that a combination of\nkinematical selection and machine learning (ML) analysis will yields\nsignificant sensitivity to this process at the end of the LHC Run 3."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19160",
    "c_title":[
      "Detecting Linguistic Indicators for Stereotype Assessment with Large\n  Language Models"
    ],
    "c_abstract":[
      "Social categories and stereotypes are embedded in language and can introduce\ndata bias into Large Language Models (LLMs). Despite safeguards, these biases\noften persist in model behavior, potentially leading to representational harm\nin outputs. While sociolinguistic research provides valuable insights into the\nformation of stereotypes, NLP approaches for stereotype detection rarely draw\non this foundation and often lack objectivity, precision, and interpretability.\nTo fill this gap, in this work we propose a new approach that detects and\nquantifies the linguistic indicators of stereotypes in a sentence. We derive\nlinguistic indicators from the Social Category and Stereotype Communication\n(SCSC) framework which indicate strong social category formulation and\nstereotyping in language, and use them to build a categorization scheme. To\nautomate this approach, we instruct different LLMs using in-context learning to\napply the approach to a sentence, where the LLM examines the linguistic\nproperties and provides a basis for a fine-grained assessment. Based on an\nempirical evaluation of the importance of different linguistic indicators, we\nlearn a scoring function that measures the linguistic indicators of a\nstereotype. Our annotations of stereotyped sentences show that these indicators\nare present in these sentences and explain the strength of a stereotype. In\nterms of model performance, our results show that the models generally perform\nwell in detecting and classifying linguistic indicators of category labels used\nto denote a category, but sometimes struggle to correctly evaluate the\nassociated behaviors and characteristics. Using more few-shot examples within\nthe prompts, significantly improves performance. Model performance increases\nwith size, as Llama-3.3-70B-Instruct and GPT-4 achieve comparable results that\nsurpass those of Mixtral-8x7B-Instruct, GPT-4-mini and Llama-3.1-8B-Instruct."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-287",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10589",
    "b_title":[
      "Long Context Tuning for Video Generation"
    ],
    "b_abstract":[
      "Recent advances in video generation can produce realistic, minute-long\nsingle-shot videos with scalable diffusion transformers. However, real-world\nnarrative videos require multi-shot scenes with visual and dynamic consistency\nacross shots. In this work, we introduce Long Context Tuning (LCT), a training\nparadigm that expands the context window of pre-trained single-shot video\ndiffusion models to learn scene-level consistency directly from data. Our\nmethod expands full attention mechanisms from individual shots to encompass all\nshots within a scene, incorporating interleaved 3D position embedding and an\nasynchronous noise strategy, enabling both joint and auto-regressive shot\ngeneration without additional parameters. Models with bidirectional attention\nafter LCT can further be fine-tuned with context-causal attention, facilitating\nauto-regressive generation with efficient KV-cache. Experiments demonstrate\nsingle-shot models after LCT can produce coherent multi-shot scenes and exhibit\nemerging capabilities, including compositional generation and interactive shot\nextension, paving the way for more practical visual content creation. See\nhttps:\/\/guoyww.github.io\/projects\/long-context-video\/ for more details."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04615",
    "c_title":[
      "Doubly Robust and Efficient Calibration of Prediction Sets for Censored\n  Time-to-Event Outcomes"
    ],
    "c_abstract":[
      "Our objective is to construct well-calibrated prediction sets for a\ntime-to-event outcome subject to right-censoring with guaranteed coverage. Our\napproach is inspired by modern conformal inference literature in that, unlike\nclassical frameworks, we obviate the need for a well-specified parametric or\nsemiparametric survival model to accomplish our goal. In contrast to existing\nconformal prediction methods for survival data, which restrict censoring to be\nof Type I, whereby potential censoring times are assumed to be fully observed\non all units in both training and validation samples, we consider the more\ncommon right-censoring setting in which either only the censoring time or only\nthe event time of primary interest is directly observed, whichever comes first.\nUnder a standard conditional independence assumption between the potential\nsurvival and censoring times given covariates, we propose and analyze two\nmethods to construct valid and efficient lower predictive bounds for the\nsurvival time of a future observation. The proposed methods build upon modern\nsemiparametric efficiency theory for censored data, in that the first approach\nincorporates inverse-probability-of-censoring weighting to account for\ncensoring, while the second approach is based on augmenting this method with an\nadditional correction term. For both methods, we formally establish asymptotic\ncoverage guarantees and demonstrate, both theoretically and through empirical\nexperiments, that the augmented approach substantially improves efficiency over\nthe inverse-probability-of-censoring weighting method. Specifically, its\ncoverage error bound is of second-order mixed bias type, that is doubly robust,\nand therefore guaranteed to be asymptotically negligible relative to the\ncoverage error of the non-augmented method."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-288",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12915",
    "b_title":[
      "Minimal unit vector fields on oscillator groups"
    ],
    "b_abstract":[
      "In this paper, we treat minimal left-invariant unit vector fields on\noscillator group and their relations with the ones that define a harmonic map.\nParticularly, if all structure constants of the oscillator group are equal to\neach other, then all unit left invariant vector fields that define a harmonic\nmap into the unit tangent bundle with Sasaki metric are minimal."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16243",
    "c_title":[
      "Accelerating Quantum Reinforcement Learning with a Quantum Natural\n  Policy Gradient Based Approach"
    ],
    "c_abstract":[
      "We address the problem of quantum reinforcement learning (QRL) under\nmodel-free settings with quantum oracle access to the Markov Decision Process\n(MDP). This paper introduces a Quantum Natural Policy Gradient (QNPG)\nalgorithm, which replaces the random sampling used in classical Natural Policy\nGradient (NPG) estimators with a deterministic gradient estimation approach,\nenabling seamless integration into quantum systems. While this modification\nintroduces a bounded bias in the estimator, the bias decays exponentially with\nincreasing truncation levels. This paper demonstrates that the proposed QNPG\nalgorithm achieves a sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1.5})$ for queries to the quantum oracle,\nsignificantly improving the classical lower bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ for queries to the MDP."
    ],
    "c_categories":[
      [
        "cs.AI",
        "quant-ph",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-289",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17776",
    "b_title":[
      "Tip of the Tongue Query Elicitation for Simulated Evaluation"
    ],
    "b_abstract":[
      "Tip-of-the-tongue (TOT) search occurs when a user struggles to recall a\nspecific identifier, such as a document title. While common, existing search\nsystems often fail to effectively support TOT scenarios. Research on TOT\nretrieval is further constrained by the challenge of collecting queries, as\ncurrent approaches rely heavily on community question-answering (CQA) websites,\nleading to labor-intensive evaluation and domain bias. To overcome these\nlimitations, we introduce two methods for eliciting TOT queries - leveraging\nlarge language models (LLMs) and human participants - to facilitate simulated\nevaluations of TOT retrieval systems. Our LLM-based TOT user simulator\ngenerates synthetic TOT queries at scale, achieving high correlations with how\nCQA-based TOT queries rank TOT retrieval systems when tested in the Movie\ndomain. Additionally, these synthetic queries exhibit high linguistic\nsimilarity to CQA-derived queries. For human-elicited queries, we developed an\ninterface that uses visual stimuli to place participants in a TOT state,\nenabling the collection of natural queries. In the Movie domain, system rank\ncorrelation and linguistic similarity analyses confirm that human-elicited\nqueries are both effective and closely resemble CQA-based queries. These\napproaches reduce reliance on CQA-based data collection while expanding\ncoverage to underrepresented domains, such as Landmark and Person. LLM-elicited\nqueries for the Movie, Landmark, and Person domains have been released as test\nqueries in the TREC 2024 TOT track, with human-elicited queries scheduled for\ninclusion in the TREC 2025 TOT track. Additionally, we provide source code for\nsynthetic query generation and the human query collection interface, along with\ncurated visual stimuli used for eliciting TOT queries."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.HC",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09743",
    "c_title":[
      "Improvement of Data Analytics Techniques in Reflection High Energy\n  Electron Diffraction to Enable Machine Learning"
    ],
    "c_abstract":[
      "Perovskite oxides such as LaFeO$_3$ are a well-studied family of materials\nthat possess a wide range of useful and novel properties. Successfully\nsynthesizing perovskite oxide samples usually requires a significant number of\ngrowth attempts and a detailed film characterization on each sample to find the\noptimal growth window of a material. The most common real-time \\textit{in situ}\ndiagnostic technique available during molecular beam epitaxy (MBE) synthesis is\nreflection high-energy electron diffraction (RHEED). Conventional use of RHEED\nallows a highly experienced operator to determine growth rate by monitoring\nintensity osciallations and make some qualitative observations during growth,\nsuch as recognizing the sample has become amorphous or recognizing that large\nislands have formed on the surface. However, due to a lack of theoretical\nunderstanding of the diffraction patterns, finer, more precise levels of\nobservations are challenging. To address these limitations, we implement new\ndata analytics techniques in the growth of three LaFeO$_3$ samples on Nb-doped\nSrTiO$_3$ by MBE. These techniques improve our ability to perform unsupervised\nmachine learning using principal component analysis (PCA) and k-means\nclustering by using drift correction to overcome sample or stage motion during\ngrowth and intensity transformations that highlight more subtle features in the\nimages such as Kikuchi bands. With this approach, we enable the first\ndemonstration of PCA and k-means across multiple samples, allowing for\nquantitative comparison of RHEED videos for two LaFeO$_3$ film samples. These\ncapabilities set the stage for real-time processing of RHEED data during growth\nto enable machine learning-accelerated film synthesis."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-290",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18100",
    "b_title":[
      "Realizing degree sequences with $\\mathcal S_3$-connected graphs"
    ],
    "b_abstract":[
      "A graph $G$ is $\\mathcal S_3$-connected if, for any mapping $\\beta : V (G)\n\\mapsto {\\mathbb Z}_3$ with $\\sum_{v\\in V(G)} \\beta(v)\\equiv 0\\pmod3$, there\nexists a strongly connected orientation $D$ satisfying\n$d^{+}_D(v)-d^{-}_D(v)\\equiv \\beta(v)\\pmod{3}$ for any $v \\in V(G)$. It is\nknown that $\\mathcal S_3$-connected graphs are contractible configurations for\nthe property of flow index strictly less than three. In this paper, we provide\na complete characterization of graphic sequences that have an\n$\\mathcal{S}_{3}$-connected realization: A graphic sequence $\\pi=(d_1,\\,\n\\ldots,\\, d_n )$ has an $\\mathcal S_3$-connected realization if and only if\n$\\min \\{d_1,\\, \\ldots,\\, d_n\\} \\ge 4$ and $\\sum^n_{i=1}d_i \\ge 6n - 4$.\nConsequently, every graphic sequence $\\pi=(d_1,\\, \\ldots,\\, d_n )$ with $\\min\n\\{d_1,\\, \\ldots,\\, d_n\\} \\ge 6$ has a realization $G$ with flow index strictly\nless than three. This supports a conjecture of Li, Thomassen, Wu and Zhang\n[European J. Combin., 70 (2018) 164-177] that every $6$-edge-connected graph\nhas flow index strictly less than three."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18672",
    "c_title":[
      "Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation\n  for 3D Gaussian Splatting"
    ],
    "c_abstract":[
      "Recent advancements in 3D scene editing have been propelled by the rapid\ndevelopment of generative models. Existing methods typically utilize generative\nmodels to perform text-guided editing on 3D representations, such as 3D\nGaussian Splatting (3DGS). However, these methods are often limited to texture\nmodifications and fail when addressing geometric changes, such as editing a\ncharacter's head to turn around. Moreover, such methods lack accurate control\nover the spatial position of editing results, as language struggles to\nprecisely describe the extent of edits. To overcome these limitations, we\nintroduce DYG, an effective 3D drag-based editing method for 3D Gaussian\nSplatting. It enables users to conveniently specify the desired editing region\nand the desired dragging direction through the input of 3D masks and pairs of\ncontrol points, thereby enabling precise control over the extent of editing.\nDYG integrates the strengths of the implicit triplane representation to\nestablish the geometric scaffold of the editing results, effectively overcoming\nsuboptimal editing outcomes caused by the sparsity of 3DGS in the desired\nediting regions. Additionally, we incorporate a drag-based Latent Diffusion\nModel into our method through the proposed Drag-SDS loss function, enabling\nflexible, multi-view consistent, and fine-grained editing. Extensive\nexperiments demonstrate that DYG conducts effective drag-based editing guided\nby control point prompts, surpassing other baselines in terms of editing effect\nand quality, both qualitatively and quantitatively. Visit our project page at\nhttps:\/\/quyans.github.io\/Drag-Your-Gaussian."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-291",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09748",
    "b_title":[
      "PyPLUTO: a data analysis Python package for the PLUTO code"
    ],
    "b_abstract":[
      "In recent years, numerical simulations have become indispensable for\naddressing complex astrophysical problems. The MagnetoHydroDynamics (MHD)\nframework represents a key tool for investigating the dynamical evolution of\nastrophysical plasmas, which are described as a set of partial differential\nequations that enforce the conservation of mass, momentum, and energy, along\nwith Maxwell's equation for the evolution of the electromagnetic fields. Due to\nthe high nonlinearity of the MHD equations (regardless of their specifications,\ne.g., classical\/relativistic or ideal\/resistive), a general analytical solution\nis precluded, making the numerical approach crucial. Numerical simulations\nusually end up producing large sets of data files and their scientific analysis\nleans on dedicated software designed for data visualization. However, in order\nto encompass all of the code output features, specialized tools focusing on the\nnumerical code may represent a more versatile and built-in tool. Here, we\npresent PyPLUTO, a Python package tailored for efficient loading, manipulation,\nand visualization of outputs produced with the PLUTO code (Mignone et al.,\n2007; Mignone et al., 2012). PyPLUTO uses memory mapping to optimize data\nloading and provides general routines for data manipulation and visualization.\nPyPLUTO also supports the particle modules of the PLUTO code, enabling users to\nload and visualize particles, such as cosmic rays (Mignone et al., 2018),\nLagrangian (Vaidya et al., 2018), or dust (Mignone et al., 2019) particles,\nfrom hybrid simulations. A dedicated Graphical User Interface (GUI) simplifies\nthe generation of single-subplot figures, making PyPLUTO a powerful yet\nuser-friendly toolkit for astrophysical data analysis."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07984",
    "c_title":[
      "Threshold Attention Network for Semantic Segmentation of Remote Sensing\n  Images"
    ],
    "c_abstract":[
      "Semantic segmentation of remote sensing images is essential for various\napplications, including vegetation monitoring, disaster management, and urban\nplanning. Previous studies have demonstrated that the self-attention mechanism\n(SA) is an effective approach for designing segmentation networks that can\ncapture long-range pixel dependencies. SA enables the network to model the\nglobal dependencies between the input features, resulting in improved\nsegmentation outcomes. However, the high density of attentional feature maps\nused in this mechanism causes exponential increases in computational\ncomplexity. Additionally, it introduces redundant information that negatively\nimpacts the feature representation. Inspired by traditional threshold\nsegmentation algorithms, we propose a novel threshold attention mechanism\n(TAM). This mechanism significantly reduces computational effort while also\nbetter modeling the correlation between different regions of the feature map.\nBased on TAM, we present a threshold attention network (TANet) for semantic\nsegmentation. TANet consists of an attentional feature enhancement module\n(AFEM) for global feature enhancement of shallow features and a threshold\nattention pyramid pooling module (TAPP) for acquiring feature information at\ndifferent scales for deep features. We have conducted extensive experiments on\nthe ISPRS Vaihingen and Potsdam datasets. The results demonstrate the validity\nand superiority of our proposed TANet compared to the most state-of-the-art\nmodels."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-292",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03925",
    "b_title":[
      "The Small-Gain Condition for Infinite Networks"
    ],
    "b_abstract":[
      "In recent years, attempts have been made to extend ISS small-gain theorems\nfrom finite networks to countably infinite, locally finite networks. Under\nspecific assumptions about the interconnection gains and the ISS formulation,\ncorresponding infinite-dimensional small-gain results have been proven.\nHowever, concerning these assumptions, the results are still too narrow to be\nconsidered a full extension of the state-of-the-art for finite networks. We\ntake a step to closing this gap by a thorough investigation of various monotone\noperators associated with an infinite network and a specific ISS formulation.\nOur results shed more light on the theory of finite networks, yield complete\ncharacterizations of the small-gain condition for specific ISS formulations,\nand show which obstacles still have to be overcome to obtain a complete theory\nfor the most general case."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03632",
    "c_title":[
      "Rare Flat Bands for Periodic Graph Operators"
    ],
    "c_abstract":[
      "For an arbitrary connected $\\mathbb{Z}^d$-periodic graph, we treat edge\nweights and potentials as variables and prove that, generically (meaning\noutside a proper algebraic subset of the variable space) the corresponding\nperiodic graph operators do not have flat bands."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.AC",
        "math.AG",
        "math.CO",
        "math.MP",
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-293",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12982",
    "b_title":[
      "SparseAlign: A Fully Sparse Framework for Cooperative Object Detection"
    ],
    "b_abstract":[
      "Cooperative perception can increase the view field and decrease the occlusion\nof an ego vehicle, hence improving the perception performance and safety of\nautonomous driving. Despite the success of previous works on cooperative object\ndetection, they mostly operate on dense Bird's Eye View (BEV) feature maps,\nwhich are computationally demanding and can hardly be extended to long-range\ndetection problems. More efficient fully sparse frameworks are rarely explored.\nIn this work, we design a fully sparse framework, SparseAlign, with three key\nfeatures: an enhanced sparse 3D backbone, a query-based temporal context\nlearning module, and a robust detection head specially tailored for sparse\nfeatures. Extensive experimental results on both OPV2V and DairV2X datasets\nshow that our framework, despite its sparsity, outperforms the state of the art\nwith less communication bandwidth requirements. In addition, experiments on the\nOPV2Vt and DairV2Xt datasets for time-aligned cooperative object detection also\nshow a significant performance gain compared to the baseline works."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09524",
    "c_title":[
      "H-infinity and Complex Interpolation"
    ],
    "c_abstract":[
      "This note is an (exact) copy of the report of Jaak Peetre, \"H-infinity and\nComplex Interpolation\". Published as Technical Report, Lund (1981). Some more\nrecent general references have been added, some references updated though (in\nitalics) and some misprints corrected."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-294",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12662",
    "b_title":[
      "TuneNSearch: a hybrid transfer learning and local search approach for\n  solving vehicle routing problems"
    ],
    "b_abstract":[
      "This paper introduces TuneNSearch, a hybrid transfer learning and local\nsearch approach for addressing different variants of vehicle routing problems\n(VRP). Recently, multi-task learning has gained much attention for solving VRP\nvariants. However, this adaptability often compromises the performance of the\nmodels. To address this challenge, we first pre-train a reinforcement learning\nmodel on the multi-depot VRP, followed by a short fine-tuning phase to adapt it\nto different variants. By leveraging the complexity of the multi-depot VRP, the\npre-trained model learns richer node representations and gains more\ntransferable knowledge compared to models trained on simpler routing problems,\nsuch as the traveling salesman problem. TuneNSearch employs, in the first\nstage, a Transformer-based architecture, augmented with a residual edge-graph\nattention network to capture the impact of edge distances and residual\nconnections between layers. This architecture allows for a more precise capture\nof graph-structured data, improving the encoding of VRP's features. After\ninference, our model is also coupled with a second stage composed of a local\nsearch algorithm, which yields substantial performance gains with minimal\ncomputational overhead added. Results show that TuneNSearch outperforms many\nexisting state-of-the-art models trained for each VRP variant, requiring only\none-fifth of the training epochs. Our approach demonstrates strong\ngeneralization, achieving high performance across different tasks,\ndistributions and problem sizes, thus addressing a long-standing gap in the\nliterature."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03897",
    "c_title":[
      "Polarization aberrations in next-generation Giant Segmented Mirror\n  Telescopes (GSMTs). II. Influence of segment-to-segment coating variations on\n  high-contrast imaging and polarimetry"
    ],
    "c_abstract":[
      "Direct exo-Earth imaging is a key science goal for astronomy in the next\ndecade. This ambitious task imposes a target contrast of ~10^-7 at wavelengths\nfrom I to J-band. In our prior study, we determined that polarization\naberrations can limit the achievable contrast to 10^-5 to 10^-6 in the\ninfrared. However, these results assumed a perfect coronagraph coupled to a\ntelescope with an ideal coating on each of the mirrors. In this study we seek\nto understand the influence of polarization aberrations from segment-to-segment\ncoating variations on coronagraphy and polarimetry. We use the Poke open-source\npolarization ray tracing package to compute the Jones pupil of each GSMT with\nspatially-varying coatings applied to the segments. The influence of the\nresultant polarization aberrations is simulated by propagating the Jones pupil\nthrough physical optics models of coronagraphs using HCIPy. After applying\nwavefront control from an ideal adaptive optics system, we determine that the\nsegment-to-segment variations applied limit the performance of coronagraphy to\na raw contrast of approximately 10^-8 in I-band, which is 2-3 orders of\nmagnitude lower the target performance for high-contrast imaging systems on the\nground. This is a negligible addition to the nominal polarization aberrations\nfor ground-based systems. We further observe negligible degradation in\npolarimetric imaging of debris disks from segment-to-segment aberrations above\nand beyond the impact of nominal polarization aberration."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-295",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04436",
    "b_title":[
      "Planet Masses, Radii, and Orbits from NASA's K2 Mission"
    ],
    "b_abstract":[
      "We report the masses, sizes, and orbital properties of 86 planets orbiting 55\nstars observed by NASA's K2 Mission with follow-up Doppler measurements by the\nHIRES spectrometer at the W. M. Keck Observatory and the Automated Planet\nFinder at Lick Observatory. Eighty-one of the planets were discovered from\ntheir transits in the K2 photometry, while five were found based on subsequent\nDoppler measurements of transiting planet host stars. The sizes of the\ntransiting planets range from Earth-size to larger than Jupiter (1-3 REarth is\ntypical), while the orbital periods range from less than a day to a few months.\nFor 32 of the planets, the Doppler signal was detected with significance\ngreater than 5-sigma (51 were detected with >3-sigma significance). An\nimportant characteristic of this catalog is the use of uniform analysis\nprocedures to determine stellar and planetary properties. This includes the\ntransit search and fitting procedures applied to the K2 photometry, the Doppler\nfitting techniques applied to the radial velocities, and the spectral modeling\nto determine bulk stellar parameters. Such a uniform treatment will make the\ncatalog useful for statistical studies of the masses, densities, and system\narchitectures of exoplanetary systems. This work also serves as a data release\nfor all previously unpublished RVs and associated stellar activity indicators\nobtained by our team for these systems, along with derived stellar and planet\nparameters."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20353",
    "c_title":[
      "Trajectory-to-Action Pipeline (TAP): Automated Scenario Description\n  Extraction for Autonomous Vehicle Behavior Comparison"
    ],
    "c_abstract":[
      "Scenario Description Languages (SDLs) provide structured, interpretable\nembeddings that represent traffic scenarios encountered by autonomous vehicles\n(AVs), supporting key tasks such as scenario similarity searches and edge case\ndetection for safety analysis. This paper introduces the Trajectory-to-Action\nPipeline (TAP), a scalable and automated method for extracting SDL labels from\nlarge trajectory datasets. TAP applies a rules-based cross-entropy optimization\napproach to learn parameters directly from data, enhancing generalization\nacross diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD),\nTAP achieves 30% greater precision than Average Displacement Error (ADE) and\n24% over Dynamic Time Warping (DTW) in identifying behaviorally similar\ntrajectories. Additionally, TAP enables automated detection of unique driving\nbehaviors, streamlining safety evaluation processes for AV testing. This work\nprovides a foundation for scalable scenario-based AV behavior analysis, with\npotential extensions for integrating multi-agent contexts."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-296",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15879",
    "b_title":[
      "Typed-RAG: Type-aware Multi-Aspect Decomposition for Non-Factoid\n  Question Answering"
    ],
    "b_abstract":[
      "Non-factoid question-answering (NFQA) poses a significant challenge due to\nits open-ended nature, diverse intents, and the need for multi-aspect\nreasoning, which renders conventional factoid QA approaches, including\nretrieval-augmented generation (RAG), inadequate. Unlike factoid questions,\nnon-factoid questions (NFQs) lack definitive answers and require synthesizing\ninformation from multiple sources across various reasoning dimensions. To\naddress these limitations, we introduce Typed-RAG, a type-aware multi-aspect\ndecomposition framework within the RAG paradigm for NFQA. Typed-RAG classifies\nNFQs into distinct types -- such as debate, experience, and comparison -- and\napplies aspect-based decomposition to refine retrieval and generation\nstrategies. By decomposing multi-aspect NFQs into single-aspect sub-queries and\naggregating the results, Typed-RAG generates more informative and contextually\nrelevant responses. To evaluate Typed-RAG, we introduce Wiki-NFQA, a benchmark\ndataset covering diverse NFQ types. Experimental results demonstrate that\nTyped-RAG outperforms baselines, thereby highlighting the importance of\ntype-aware decomposition for effective retrieval and generation in NFQA. Our\ncode and dataset are available at https:\/\/github.com\/TeamNLP\/Typed-RAG."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03262",
    "c_title":[
      "Mie-enhanced micro-focused Brillouin light scattering with wavevector\n  resolution"
    ],
    "c_abstract":[
      "Magnons, the quanta of spin waves, are magnetic excitations of matter\nspanning through the entire crystal's Brillouin zone and covering a wide range\nof frequencies ranging from sub-gigahertz to hundreds of terahertz. Magnons\nplay a crucial role in many condensed matter phenomena, such as the reduction\nof saturation magnetization with increasing temperature or Bose-Einstein\ncondensation. However, current experimental techniques cannot resolve magnons\nwith wavevectors between 30 and 300$\\,$rad$\\,\\mu$m$^{-1}$. In this letter, we\naddress this gap by tailoring the light in Brillouin light scattering process\nwith dielectric periodic nanoresonators and thus gaining access to the\npreviously unmeasurable spin waves with full wavevector resolution using\ntable-top optical setup. Filling this gap can stimulate further experimental\ninvestigations of the fundamental phenomena associated with magnons but also\nstimulate the application of magnonics in computational and microwave devices.\nIn addition, the same methodology can be applied to other excitations of\nmatter, such as phonons, opening up new possibilities in e.g. mechanobiological\nstudies."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-297",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06974",
    "b_title":[
      "Higher-rank GBS groups: non-positive curvature and biautomaticity"
    ],
    "b_abstract":[
      "We characterise when a rank $n$ generalised Baumslag-Solitar group is CAT(0)\nand when it is biautomatic."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02921",
    "c_title":[
      "Unsupervised Tomato Split Anomaly Detection using Hyperspectral Imaging\n  and Variational Autoencoders"
    ],
    "c_abstract":[
      "Tomato anomalies\/damages pose a significant challenge in greenhouse farming.\nWhile this method of cultivation benefits from efficient resource utilization,\nanomalies can significantly degrade the quality of farm produce. A common\nanomaly associated with tomatoes is splitting, characterized by the development\nof cracks on the tomato skin, which degrades its quality. Detecting this type\nof anomaly is challenging due to dynamic variations in appearance and sizes,\ncompounded by dataset scarcity. We address this problem in an unsupervised\nmanner by utilizing a tailored variational autoencoder (VAE) with hyperspectral\ninput. Preliminary analysis of the dataset enabled us to select the optimal\nrange of wavelengths for detecting this anomaly. Our findings indicate that the\n530nm - 550nm range is suitable for identifying tomato dry splits. The analysis\non reconstruction loss allow us to not only detect the anomalies but also to\nsome degree estimate the anomalous regions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-298",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08533",
    "b_title":[
      "Practical parameter identifiability of respiratory mechanics in the\n  extremely preterm infant"
    ],
    "b_abstract":[
      "The complexity of mathematical models describing respiratory mechanics has\ngrown in recent years, however, parameter identifiability of such models has\nonly been studied in the last decade in the context of observable data. This\nstudy investigates parameter identifiability of a nonlinear respiratory\nmechanics model tuned to the physiology of an extremely preterm infant, using\nglobal Morris screening, local deterministic sensitivity analysis, and singular\nvalue decomposition-based subset selection. The model predicts airflow and\ndynamic pulmonary volumes and pressures under varying levels of continuous\npositive airway pressure, and a range of parameters characterizing both\nsurfactant-treated and surfactant-deficient lung. Sensitivity analyses\nindicated eleven parameters influence model outputs over the range of\ncontinuous positive airway pressure and lung health scenarios. The model was\nadapted to data from a spontaneously breathing 1 kg infant using gradient-based\noptimization to estimate the parameter subset characterizing the patient's\nstate of health."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.05890",
    "c_title":[
      "Uniqueness of generalized conformal restriction measures and\n  Malliavin-Kontsevich-Suhov measures for $c \\in (0,1]$"
    ],
    "c_abstract":[
      "In this paper, we present a unified approach to establish the uniqueness of\ngeneralized conformal restriction measures with central charge $c \\in (0, 1]$\nin both chordal and radial cases, by relating these measures to the Brownian\nloop soup. Our method also applies to the uniqueness of the\nMalliavin-Kontsevich-Suhov loop measures for $c \\in (0,1]$, which was recently\nobtained in [Baverez-Jego, arXiv:2407.09080] for all $c \\leq 1$ from a CFT\nframework of SLE loop measures. In contrast, though only valid for $c \\in\n(0,1]$, our approach provides additional probabilistic insights, as it directly\nlinks natural quantities of MKS measures to loop-soup observables."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-299",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12051",
    "b_title":[
      "TLUE: A Tibetan Language Understanding Evaluation Benchmark"
    ],
    "b_abstract":[
      "Large language models (LLMs) have made tremendous progress in recent years,\nbut low-resource languages, such as Tibetan, remain significantly\nunderrepresented in their evaluation. Despite Tibetan being spoken by over\nseven million people, it has largely been neglected in the development and\nassessment of LLMs. To address this gap, we present TLUE (A Tibetan Language\nUnderstanding Evaluation Benchmark), the first large-scale benchmark for\nassessing LLMs' capabilities in Tibetan. TLUE comprises two major components:\n(1) a comprehensive multi-task understanding benchmark spanning 5 domains and\n67 subdomains, and (2) a safety benchmark covering 7 subdomains. We evaluate a\ndiverse set of state-of-the-art LLMs. Experimental results demonstrate that\nmost LLMs perform below the random baseline, highlighting the considerable\nchallenges LLMs face in processing Tibetan, a low-resource language. TLUE\nprovides an essential foundation for driving future research and progress in\nTibetan language understanding and underscores the need for greater inclusivity\nin LLM development."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07406",
    "c_title":[
      "Prime Identification and Composite Filtering Using GM-(n+1) Sequences"
    ],
    "c_abstract":[
      "This paper presents a distinctive prime detection approach. This method use\nGM-(n+1) sequences to effectively eliminate complex numbers. The sequences,\nwhich consist of odd a number of (n+1), exclude all components except for the\ninitial prime integer. Only the first prime number is presented. This research\nproposes an approach using this model to identify exceptional candidates and\nexamine their distribution. This study examines the interconnections among the\nlaws of division, basic gaps, and their applications in analytical procedures.\nComputer studies may provide a novel perspective on the theory of prime\nnumbers, demonstrating the effectiveness of this approach in refining the\nsearch space for primes."
    ],
    "c_categories":[
      [
        "math.GM"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-300",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05015",
    "b_title":[
      "On Measuring Unnoticeability of Graph Adversarial Attacks: Observations,\n  New Measure, and Applications"
    ],
    "b_abstract":[
      "Adversarial attacks are allegedly unnoticeable. Prior studies have designed\nattack noticeability measures on graphs, primarily using statistical tests to\ncompare the topology of original and (possibly) attacked graphs. However, we\nobserve two critical limitations in the existing measures. First, because the\nmeasures rely on simple rules, attackers can readily enhance their attacks to\nbypass them, reducing their attack \"noticeability\" and, yet, maintaining their\nattack performance. Second, because the measures naively leverage global\nstatistics, such as degree distributions, they may entirely overlook attacks\nuntil severe perturbations occur, letting the attacks be almost \"totally\nunnoticeable.\" To address the limitations, we introduce HideNSeek, a learnable\nmeasure for graph attack noticeability. First, to mitigate the bypass problem,\nHideNSeek learns to distinguish the original and (potential) attack edges using\na learnable edge scorer (LEO), which scores each edge on its likelihood of\nbeing an attack. Second, to mitigate the overlooking problem, HideNSeek\nconducts imbalance-aware aggregation of all the edge scores to obtain the final\nnoticeability score. Using six real-world graphs, we empirically demonstrate\nthat HideNSeek effectively alleviates the observed limitations, and LEO (i.e.,\nour learnable edge scorer) outperforms eleven competitors in distinguishing\nattack edges under five different attack methods. For an additional\napplication, we show that LEO boost the performance of robust GNNs by removing\nattack-like edges."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13860",
    "c_title":[
      "A Unifying Framework for Complex-Valued Eigenfunctions via The Cartan\n  Embedding"
    ],
    "c_abstract":[
      "In this work we find a unifying scheme for the known explicit complex-valued\neigenfunctions on the classical compact Riemannian symmetric spaces. For this\nwe employ the well-known Cartan embedding for those spaces. This also leads to\nthe construction of new eigenfunctions on the quaternionic Grassmannians."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-301",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05881",
    "b_title":[
      "Smuggling unnoticed: Towards a 2D view of water and dust delivery to the\n  inner regions of protoplanetary discs"
    ],
    "b_abstract":[
      "Infrared spectroscopy, e.g., with JWST, provides a glimpse into the chemical\ninventory of the innermost region of protoplanetary discs, where terrestrial\nplanets eventually form. The chemical make-up of regions inside snowlines is\nconnected to the material drifting from the outer regions, which can be modeled\nwith dust evolution models. However, infrared observations are limited by the\nhigh dust extinction in the inner disc, and only probes the abundances of\ngaseous species in the disc surface layers. As a result, the bulk mass of\ndelivered volatiles is not directly relatable to what is measured through\ninfrared spectra. In this paper, we investigate how the delivery of dust and\nice after prolonged pebble drift affects the observable reservoir of water\nvapor in the inner disc. We develop a 1+1D approach based on dust evolution\nmodels to determine the delivery and distribution of vapor compared to the\nheight of the $\\tau = 1$ surface in the dust continuum. We find that the\nobservable column density of water vapor at wavelengths probed by JWST spans\nmany orders of magnitude over time, exhibiting different radial profiles\ndepending on dust properties, drift rate, and local processing. In the presence\nof a traffic-jam effect inside the snowline, the observable vapor reservoir\nappears constant in time despite the ongoing delivery by pebble drift, such\nthat water is effectively smuggled unnoticed. Differences in measured column\ndensities then originate not only from variations in bulk vapor content, but\nalso from differences in the properties and distribution of dust particles."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09725",
    "c_title":[
      "Parallel multi-objective metaheuristics for smart communications in\n  vehicular networks"
    ],
    "c_abstract":[
      "This article analyzes the use of two parallel multi-objective soft computing\nalgorithms to automatically search for high-quality settings of the Ad hoc On\nDemand Vector routing protocol for vehicular networks. These methods are based\non an evolutionary algorithm and on a swarm intelligence approach. The\nexperimental analysis demonstrates that the configurations computed by our\noptimization algorithms outperform other state-of-the-art optimized ones. In\nturn, the computational efficiency achieved by all the parallel versions is\ngreater than 87 %. Therefore, the line of work presented in this article\nrepresents an efficient framework to improve vehicular communications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.NE",
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-302",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03188",
    "b_title":[
      "Euska\\~nolDS: A Naturally Sourced Corpus for Basque-Spanish\n  Code-Switching"
    ],
    "b_abstract":[
      "Code-switching (CS) remains a significant challenge in Natural Language\nProcessing (NLP), mainly due a lack of relevant data. In the context of the\ncontact between the Basque and Spanish languages in the north of the Iberian\nPeninsula, CS frequently occurs in both formal and informal spontaneous\ninteractions. However, resources to analyse this phenomenon and support the\ndevelopment and evaluation of models capable of understanding and generating\ncode-switched language for this language pair are almost non-existent. We\nintroduce a first approach to develop a naturally sourced corpus for\nBasque-Spanish code-switching. Our methodology consists of identifying CS texts\nfrom previously available corpora using language identification models, which\nare then manually validated to obtain a reliable subset of CS instances. We\npresent the properties of our corpus and make it available under the name\nEuska\\~nolDS."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10959",
    "c_title":[
      "On pseudo-irreducibility and Boolean lifting property of filters in\n  residuated lattices"
    ],
    "c_abstract":[
      "In this paper, we introduce the notion of a pseudo-irreducible filter in a\nresiduated lattice and compare this concept with related notions such as prime\nand maximal filters. Then, we recall the Boolean lifting property for filters\nand present useful characterizations for this property using pseudo-irreducible\nfilters and the residuated lattice of fractions. Next, we study the Boolean\nlifting property of the radical of a filter. Furthermore, we introduce weak\nMTL-algebras and residuated lattices that have the transitional property of\nradicals decomposition (TPRD) as generalizations of several algebraic\nstructures, including Boolean algebra, MV-algebra, BL-algebra, MTL-algebra, and\nStonean residuated lattice. Moreover, by comparing weak MTL-algebras with other\nclasses of residuated lattices, we address an open question concerning the\nBoolean lifting property of the radical of a residuated lattice. Finally, we\ngive a topological answer to an open question about the Boolean lifting\nproperty of the radical of a residuated lattice. Several additional results are\nalso obtained, further enriching the understanding of the Boolean lifting\nproperty in residuated lattices."
    ],
    "c_categories":[
      [
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-303",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04962",
    "b_title":[
      "Intrinsic Spin Transport in a Topological Insulator Thin Film"
    ],
    "b_abstract":[
      "Topological insulators (TIs) are intriguing materials for advanced computing\napplications based on spintronics because they can host robust spin effects.\nFor instance, TIs have intrinsically large spin generation enabled by their\nlarge spin-orbit coupling. Furthermore, topological surface states (TSS) with\nspin-momentum locking and Dirac dispersion lead to long spin diffusion. Future\nspintronic device technology will require scalable film growth of high-quality\nmaterial. We grow epitaxial films of Bi$_{1-x}$Sb$_x$Te$_{3-y}$Se$_y$ (BSTS, $x\n= 0.58, y = 1$) and confirm the gapless band structure with optimal doping\nusing angle-resolved photoelectron spectra. The temperature dependence of\nlongitudinal resistivity shows bulk transport is suppressed as temperature is\ndecreased, and at low temperature surface transport dominates. We evaluate the\nspin transport properties in BSTS without using ferromagnetic tunnel contacts\nvia a non-local resistance experiment as a function of temperature and applied\ncharge current. As expected, these experiments reveal the necessity of\ndecreasing the bulk conduction to best enhance the spin transport. In the TSS,\nwe find high efficiency of charge-to-spin conversion (spin Hall angle,\n$\\theta_{SH} \\approx 1$) and spin diffusion over several microns. Further\ndevelopment of high-quality TIs will make them viable candidates for efficient\nand lossless spintronics."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04271",
    "c_title":[
      "On Fact and Frequency: LLM Responses to Misinformation Expressed with\n  Uncertainty"
    ],
    "c_abstract":[
      "We study LLM judgments of misinformation expressed with uncertainty. Our\nexperiments study the response of three widely used LLMs (GPT-4o, LlaMA3,\nDeepSeek-v2) to misinformation propositions that have been verified false and\nthen are transformed into uncertain statements according to an uncertainty\ntypology. Our results show that after transformation, LLMs change their\nfactchecking classification from false to not-false in 25% of the cases.\nAnalysis reveals that the change cannot be explained by predictors to which\nhumans are expected to be sensitive, i.e., modality, linguistic cues, or\nargumentation strategy. The exception is doxastic transformations, which use\nlinguistic cue phrases such as \"It is believed ...\".To gain further insight, we\nprompt the LLM to make another judgment about the transformed misinformation\nstatements that is not related to truth value. Specifically, we study LLM\nestimates of the frequency with which people make the uncertain statement. We\nfind a small but significant correlation between judgment of fact and\nestimation of frequency."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-304",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00647",
    "b_title":[
      "CAP: A Connectivity-Aware Hierarchical Coverage Path Planning Algorithm\n  for Unknown Environments using Coverage Guidance Graph"
    ],
    "b_abstract":[
      "Efficient coverage of unknown environments requires robots to adapt their\npaths in real time based on on-board sensor data. In this paper, we introduce\nCAP, a connectivity-aware hierarchical coverage path planning algorithm for\nefficient coverage of unknown environments. During online operation, CAP\nincrementally constructs a coverage guidance graph to capture essential\ninformation about the environment. Based on the updated graph, the hierarchical\nplanner determines an efficient path to maximize global coverage efficiency and\nminimize local coverage time. The performance of CAP is evaluated and compared\nwith five baseline algorithms through high-fidelity simulations as well as\nrobot experiments. Our results show that CAP yields significant improvements in\ncoverage time, path length, and path overlap ratio."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.21063",
    "c_title":[
      "The Luce Model, Regularity, and Choice Overload"
    ],
    "c_abstract":[
      "We characterize regularity (Block & Marschak, 1960) within a novel stochastic\nmodel: the General Threshold Luce model [GTLM]. We apply our results to study\nchoice overload, identified by regularity violations that impose a welfare cost\non the decision-maker. Generalizing our characterization results, we identify\nnecessary and sufficient conditions for choice overload within GTLMs and, in\ndoing so, disentangle two well-known causes: low discriminatory power (Frick,\n2016) and limited attention (Lleras et al., 2017)."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-305",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07470",
    "b_title":[
      "Sampling Theory for Function Approximation with Numerical Redundancy"
    ],
    "b_abstract":[
      "The study of numerical rounding errors is often greatly simplified in the\nanalytical treatment of mathematical problems, or even entirely separated from\nit. In sampling theory, for instance, it is standard to assume the availability\nof an orthonormal basis for computations, ensuring that numerical errors are\nnegligible. In reality, however, this assumption is often unmet. In this paper,\nwe discard it and demonstrate the advantages of integrating numerical insights\nmore deeply into sampling theory. To clearly pinpoint when the numerical\nphenomena play a significant role, we introduce the concept of numerical\nredundancy. A set of functions is numerically redundant if it spans a\nlower-dimensional space when analysed numerically rather than analytically.\nThis property makes it generally impossible to compute the best approximation\nof a function in its span using finite precision. In contrast,\n$\\ell^2$-regularized approximations are computable and, therefore, form the\nfoundation of many practical methods. Regularization generally reduces accuracy\ncompared to the best approximation, but our analysis shows that there is a\nbenefit: it also significantly reduces the amount of data needed for accurate\napproximation. Furthermore, we present a constructive method for optimally\nselecting data points for $L^2$-approximations, explicitly accounting for the\neffects of regularization. The results are illustrated for two common scenarios\nthat lead to numerical redundancy: (1) approximations on irregular domains and\n(2) approximations that incorporate specific features of the function to be\napproximated. In doing so, we obtain new results on random sampling for Fourier\nextension frames. Finally, we establish that regularization is implicit in\nnumerical orthogonalization of a numerically redundant set, indicating that its\nanalysis cannot be bypassed in a much broader range of methods."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00721",
    "c_title":[
      "A Turing Test for Artificial Nets devoted to model Human Vision"
    ],
    "c_abstract":[
      "In this 2022 work we argued that, despite claims about successful modeling of\nthe visual brain using artificial nets, the problem is far from being solved\n(even for low-level vision). Examples of open issues include: where should we\nread from ANNs in order to reproduce human behavior?, this ad-hoc read-out is\nconsidered part of the brain model or not?, should we use artificial\npsychophysics or artificial physiology?, in the case of ANNs, artificial\nexperiments should literally match the experiments done with humans?. There is\na clear need of rigorous procedures for experimental tests for ANNs devoted to\nmodel the visual brain, and more generally, to understand ANNs devoted to\ngeneric vision tasks. Following our experience in using low-level facts from\nQuantitative Visual Neuroscience in computer vision, in this work we presented\nthe idea of developing a low-level dataset compiling the basic spatio-temporal\nand chromatic facts that are known to happen in the retina-V1 pathway, and they\nare not currently available in existing databases such as BrainScore. In our\nresults we checked the behavior of three recently proposed models with similar\narchitecture: (1) A parametric model tuned via Maximum Differentiation [Malo &\nSimoncelli SPIE 15, Martinez et al. PLOS 18, Martinez et al. Front. Neurosci.\n19], (2) A non-parametric model called PerceptNet tuned to maximize the\ncorrelation with human opinion on subjective distortions [Hepburn et al. IEEE\nICIP 19], and (3) A model with the same encoder as PerceptNet, but tuned for\nimage segmentation (published as Hernandez-Camara et al. Patt.Recogn.Lett. 23).\nResults on 10 compelling psycho\/physio visual facts show that the first model\nis the one with closer behavior to the humans in terms of receptive fields, but\nmore interestingly, on the nonlinear behavior when facing complex\nspatio-chromatic patterns of a range of luminances and contrasts."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-306",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11698",
    "b_title":[
      "AstroPix: A Pixelated HVCMOS Sensor for Space-Based Gamma-Ray\n  Measurement"
    ],
    "b_abstract":[
      "A next-generation medium-energy gamma-ray telescope targeting the MeV range\nwould address open questions in astrophysics regarding how extreme conditions\naccelerate cosmic-ray particles, produce relativistic jet outflows, and more.\nOne concept, AMEGO-X, relies upon the mission-enabling CMOS Monolithic Active\nPixel Sensor silicon chip AstroPix. AstroPix is designed for space-based use,\nfeaturing low noise, low power consumption, and high scalability. Desired\nperformance of the device include an energy resolution of 5 keV (or 10% FWHM)\nat 122 keV and a dynamic range per-pixel of 25-700 keV, enabled by the addition\nof a high-voltage bias to each pixel which supports a depletion depth of 500\num. This work reports on the status of the AstroPix development process with\nemphasis on the current version under test, version three (v3), and highlights\nof version two (v2). Version 3 achieves energy resolution of 10.4 +\\- 3.2 % at\n59.5 keV and 94 +\\- 6 um depletion in a low-resistivity test silicon substrate."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18310",
    "c_title":[
      "Efficient Neural Theorem Proving via Fine-grained Proof Structure\n  Analysis"
    ],
    "c_abstract":[
      "The synergy between deep learning models and traditional automation tools\nplays a pivotal role in developing robust neural theorem provers (NTPs).\nHowever, for proof synthesis with LLMs, previous work applies automation tools\neither only when the model explicitly calls the method, or only at a single\ngranularity level, failing to fully exploit the power of built-in tactics and\noff-the-shelf automated theorem provers. In this work, we propose ProofAug, a\nnovel theorem proving method that enjoys superior sample efficiency through\nequipping proof-generation LLMs with automation methods in different\ngranularities via fine-grained structure analysis of model-generated proof\nproposals. Furthermore, ProofAug serves as a versatile plug-and-play module\nthat seamlessly integrates with any tree-search algorithm, enabling our\nconstruction of an efficient recursive proving (ERP) module to further enhance\nperformance. The superiority of our method is validated on the miniF2F-test\nbenchmark using the open-source deepseek-math-7b-base model and the Isabelle\nproof assistant. Notably, by additionally employing a mixed prompting strategy,\nwe achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9%\nfor the original version), setting a new SOTA across all proof languages with a\ntotal sample budget of only 2100. Our code is available at\nhttps:\/\/github.com\/haoxiongliu\/ProofAug."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-307",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14673",
    "b_title":[
      "ChunkFormer: Masked Chunking Conformer For Long-Form Speech\n  Transcription"
    ],
    "b_abstract":[
      "Deploying ASR models at an industrial scale poses significant challenges in\nhardware resource management, especially for long-form transcription tasks\nwhere audio may last for hours. Large Conformer models, despite their\ncapabilities, are limited to processing only 15 minutes of audio on an 80GB\nGPU. Furthermore, variable input lengths worsen inefficiencies, as standard\nbatching leads to excessive padding, increasing resource consumption and\nexecution time. To address this, we introduce ChunkFormer, an efficient ASR\nmodel that uses chunk-wise processing with relative right context, enabling\nlong audio transcriptions on low-memory GPUs. ChunkFormer handles up to 16\nhours of audio on an 80GB GPU, 1.5x longer than the current state-of-the-art\nFastConformer, while also boosting long-form transcription performance with up\nto 7.7% absolute reduction on word error rate and maintaining accuracy on\nshorter tasks compared to Conformer. By eliminating the need for padding in\nstandard batching, ChunkFormer's masked batching technique reduces execution\ntime and memory usage by more than 3x in batch processing, substantially\nreducing costs for a wide range of ASR systems, particularly regarding GPU\nresources for models serving in real-world applications."
    ],
    "b_categories":[
      [
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02847",
    "c_title":[
      "Homogenization of the stochastic double-porosity model"
    ],
    "c_abstract":[
      "This work is devoted to the homogenization of elliptic equations in\nhigh-contrast media in the so-called `double-porosity' resonant regime, for\nwhich we solve two open problems of the literature in the random setting.\nFirst, we prove qualitative homogenization under very weak conditions, that\ncover the case of inclusions that are not uniformly bounded or separated.\nSecond, under stronger assumptions, we provide sharp error estimates for the\ntwo-scale expansion."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-308",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00810",
    "b_title":[
      "Minimax Optimal Reinforcement Learning with Quasi-Optimism"
    ],
    "b_abstract":[
      "In our quest for a reinforcement learning (RL) algorithm that is both\npractical and provably optimal, we introduce EQO (Exploration via\nQuasi-Optimism). Unlike existing minimax optimal approaches, EQO avoids\nreliance on empirical variances and employs a simple bonus term proportional to\nthe inverse of the state-action visit count. Central to EQO is the concept of\nquasi-optimism, where estimated values need not be fully optimistic, allowing\nfor a simpler yet effective exploration strategy. The algorithm achieves the\nsharpest known regret bound for tabular RL under the mildest assumptions,\nproving that fast convergence can be attained with a practical and\ncomputationally efficient approach. Empirical evaluations demonstrate that EQO\nconsistently outperforms existing algorithms in both regret performance and\ncomputational efficiency, providing the best of both theoretical soundness and\npractical effectiveness."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15202",
    "c_title":[
      "A Unified Framework for Real-Time Failure Handling in Robotics Using\n  Vision-Language Models, Reactive Planner and Behavior Trees"
    ],
    "c_abstract":[
      "Robotic systems often face execution failures due to unexpected obstacles,\nsensor errors, or environmental changes. Traditional failure recovery methods\nrely on predefined strategies or human intervention, making them less\nadaptable. This paper presents a unified failure recovery framework that\ncombines Vision-Language Models (VLMs), a reactive planner, and Behavior Trees\n(BTs) to enable real-time failure handling. Our approach includes pre-execution\nverification, which checks for potential failures before execution, and\nreactive failure handling, which detects and corrects failures during execution\nby verifying existing BT conditions, adding missing preconditions and, when\nnecessary, generating new skills. The framework uses a scene graph for\nstructured environmental perception and an execution history for continuous\nmonitoring, enabling context-aware and adaptive failure handling. We evaluate\nour framework through real-world experiments with an ABB YuMi robot on tasks\nlike peg insertion, object sorting, and drawer placement, as well as in\nAI2-THOR simulator. Compared to using pre-execution and reactive methods\nseparately, our approach achieves higher task success rates and greater\nadaptability. Ablation studies highlight the importance of VLM-based reasoning,\nstructured scene representation, and execution history tracking for effective\nfailure recovery in robotics."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-309",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11889",
    "b_title":[
      "Towards shell model interactions with credible uncertainties"
    ],
    "b_abstract":[
      "Background: The nuclear shell model offers realistic predictions of nuclear\nstructure starting from (quasi-) proton and neutron degrees of freedom, but\nrelies on coupling constants (interaction matrix elements) that must be fit to\nexperiment. To extend the shell model's applicability across the nuclear chart,\nand specifically toward the driplines, we must first be able to efficiently\ntest new interaction matrix elements and assign credible uncertainties.\n  Purpose: We develop and test a framework to efficiently fit new shell model\ninteractions and obtain credible uncertainties. We further demonstrate its use\nby validating the uncertainty estimates of the known \\textit{sd}-shell\neffective interactions.\n  Methods: We use eigenvector continuation to emulate solutions to the exact\nshell model. First, we use the emulator to replicate earlier results using a\nwell-known linear-combination chi-squared minimization algorithm. Then, we\nemploy a modern Markov Chain Monte Carlo method to test for nonlinearities in\nthe observable posterior distributions, which previous sensitivity analyses\nprecluded.\n  Results: The emulator reproduces the USDB interaction within a small margin\nof error, allowing for the quantification of the matrix element uncertainty.\nHowever, we find that to obtain credible predictive intervals the model defect\nof the shell model itself, rather than experimental or emulator\nuncertainty\/error, must be taken into account.\n  Conclusions: Eigenvector continuation can be used to accelerate fitting shell\nmodel interactions. We confirm that the linear approximation used to develop\ninteractions in the past is indeed sufficient. However, we find that typical\nassumptions about the likelihood function must be modified in order to obtain a\ncredible uncertainty-quantified interaction."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02761",
    "c_title":[
      "Federated Low-Rank Tensor Estimation for Multimodal Image Reconstruction"
    ],
    "c_abstract":[
      "Low-rank tensor estimation offers a powerful approach to addressing\nhigh-dimensional data challenges and can substantially improve solutions to\nill-posed inverse problems, such as image reconstruction under noisy or\nundersampled conditions. Meanwhile, tensor decomposition has gained prominence\nin federated learning (FL) due to its effectiveness in exploiting latent space\nstructure and its capacity to enhance communication efficiency. In this paper,\nwe present a federated image reconstruction method that applies Tucker\ndecomposition, incorporating joint factorization and randomized sketching to\nmanage large-scale, multimodal data. Our approach avoids reconstructing\nfull-size tensors and supports heterogeneous ranks, allowing clients to select\npersonalized decomposition ranks based on prior knowledge or communication\ncapacity. Numerical results demonstrate that our method achieves superior\nreconstruction quality and communication compression compared to existing\napproaches, thereby highlighting its potential for multimodal inverse problems\nin the FL setting."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.DC",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-310",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12861",
    "b_title":[
      "Cubic congruences and binary quadratic forms"
    ],
    "b_abstract":[
      "Let $p>3$ be a prime, $a_1,a_2,a_3\\in\\Bbb Z$ and let\n$N_p(x^3+a_1x^2+a_2x+a_3)$ denote the number of solutions to the congruence\n$x^3+a_1x^2+a_2x+a_3\\equiv 0\\pmod p$. In this paper, we give an explicit\ncriterion for $N_p(x^3+a_1x^2+a_2x+a_3)=3$ via binary quadratic forms."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.13755",
    "c_title":[
      "GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits"
    ],
    "c_abstract":[
      "This study proposes a GPA for designing optimal Quantum Sensor Circuits\n(QSCs) to address complex quantum physics problems. The GPA consists of two\nparts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement\n(QPI). The QPE performs phase estimation to generate the search space, while\nthe QPI utilizes Grover search and amplitude amplification techniques to\nefficiently identify an optimal policy that generates optimal QSCs. The GPA\ngenerates QSCs by selecting sequences of gates that maximize the Quantum Fisher\nInformation (QFI) while minimizing the number of gates. The QSCs generated by\nthe GPA are capable of producing entangled quantum states, specifically the\nsqueezed states. High QFI indicates increased sensitivity to parameter changes,\nmaking the circuit useful for quantum state estimation and control tasks.\nEvaluation of the GPA on a QSC that consists of two qubits and a sequence of\nR_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs\nwith a QFI of 1. Compared to existing quantum agents, the GPA achieves higher\nQFI with fewer gates, demonstrating a more efficient and scalable approach to\nthe design of QSCs. This work illustrates the potential computational power of\nquantum agents for solving quantum physics problems"
    ],
    "c_categories":[
      [
        "cs.AI",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-311",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17342",
    "b_title":[
      "Comparison of dynamical dark energy with {\\Lambda}CDM in light of DESI\n  DR2"
    ],
    "b_abstract":[
      "We present an updated reconstruction of the dark energy equation of state,\n$w(a)$, using the newly released DESI DR2 Baryon Acoustic Oscillation (BAO)\ndata in combination with Pantheon+ and DES5Y Type Ia supernovae measurements,\nrespectively. Building on our previous analysis in arXiv:2503.08658, which\nemployed a nonparametric flexknot reconstruction approach, we examine whether\nthe evidence for dynamical dark energy persists with the improved precision of\nthe DESI DR2 dataset. We find that while the overall qualitative structure of\n$w(a)$ remains consistent with our earlier findings, the statistical support\nfor dynamical dark energy is reduced when considering DESI DR2 data alone,\nparticularly for more complex flexknot models with higher numbers of knots.\nHowever, the evidence for simpler dynamical models, such as $w$CDM and CPL\n(which correspond to $n=1$ and $n=2$ knots respectively), increases relative to\n$\\Lambda$CDM with DESI DR2 alone, consistent with previous DESI analyses. When\ncombined with Pantheon+ data, the conclusions remain broadly consistent with\nour earlier work, but the inclusion of DES5Y supernovae data leads to an\nincrease of preference for flexknot models with more than two knots, placing\n$w$CDM and CPL on par with $\\Lambda$CDM."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15047",
    "c_title":[
      "An essential one sided boundary singularity for a $3$-dimensional area\n  minimizing current in $\\mathbb{R}^5$"
    ],
    "c_abstract":[
      "We construct a $3$ dimensional area minimizing current $T$ in $\\mathbb{R}^5$\nwhose boundary contains a real analytic surface of multiplicity $2$ at which\n$T$ has a density $1$ essential boundary singularity with a flat tangent cone.\nThis example shows that the regularity theory we developed with Reinaldo\nResende in another paper, is dimensionally sharp.\n  The construction of $T$ relies on the prescription of boundary data with\nnon-trivial topology, which makes it an extremely flexible technique and gives\nrise to a wide family of singular examples.\n  In order to understand the examples, we develop a boundary regularity theory\nfor a class of area minimizing $m$-dimensional currents whose boundary consists\nof smooth $(m-1)$-dimensional surfaces with multiplicities meeting at an\n$(m-2)$-dimensional smooth submanifold."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-312",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00329",
    "b_title":[
      "ABC: Achieving Better Control of Multimodal Embeddings using VLMs"
    ],
    "b_abstract":[
      "Visual embedding models excel at zero-shot tasks like visual retrieval and\nclassification. However, these models cannot be used for tasks that contain\nambiguity or require user instruction. These tasks necessitate a multimodal\nembedding model, which outputs embeddings that combine visual and natural\nlanguage input. Existing CLIP-based approaches embed images and text\nindependently, and fuse the result. We find that this results in weak\ninteractions between modalities, and poor user control over the representation.\nWe introduce ABC, an open-source multimodal embedding model that uses a\nvision-language model backbone to deeply integrate image features with natural\nlanguage instructions. ABC achieves bestfor-size performance on MSCOCO\nimage-to-text retrieval and is the top performing model on classification and\nVQA tasks in the Massive Multimodal Embedding Benchmark. With a strongly\nunified vision-language representation, ABC can use natural language to solve\nsubtle and potentially ambiguous visual retrieval problems. To evaluate this\ncapability, we design CtrlBench, a benchmark that requires interleaving textual\ninstructions with image content for correct retrieval. ABC advances the state\nof multimodal embeddings by offering high-quality representations and flexible\nnatural language control. Our model and datasets are available at our project\npage."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04657",
    "c_title":[
      "Superradiance of Friedberg-Lee-Sirlin Solitons"
    ],
    "c_abstract":[
      "It has recently been pointed out that rotation in internal space can induce\nsuperradiance. We explore this effect in non-topological solitons of the\ntwo-field Friedberg-Lee-Sirlin model. This renormalizable model admits very\nlarge solitons, making the perturbative scattering equations highly sensitive\nto boundary conditions and requiring a relaxation method for their solution. We\nfind that the energy extraction rate is strongly influenced by the mass\nhierarchy of the two scalars, and solitons with lower internal frequencies lead\nto more peaks in the spectra of the amplification factors. Additionally, we\nderive absolute bounds on the amplification factors for general ingoing modes\nusing a linear fractional optimization algorithm and establish analytical\nbounds near the mass gap."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-313",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03209",
    "b_title":[
      "Percolation of Domain Walls in the Two-Higgs Doublet Model"
    ],
    "b_abstract":[
      "Domain walls formed during a phase transition in a simple field theory model\nwith $\\mathbb{Z}_2$ symmetry in a periodic box have been demonstrated to\nannihilate as fast as causality allows and their area density scales $\\propto\nt^{-1}$. We have performed numerical simulations of the dynamics of domain\nwalls in the Two-Higgs Doublet Model (2HDM) where the potential has\n$\\mathbb{Z}_2$ symmetry in two spatial dimensions. We observed significant\ndifferences with the standard case. Although the extreme long-time limit is the\nsame for the $\\approx 10^{5}$ sets of random initial configurations analysed,\nthe percolation process is much slower due to the formation of long-lived\nloops. We suggest that this is due to the build up of superconducting currents\non the walls which could lead ultimately to stationary configurations known as\nKinky Vortons. We discuss the relevance of these findings for the production of\nVortons in three spatial dimensions."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16165",
    "c_title":[
      "Iterative Optimal Attention and Local Model for Single Image Rain Streak\n  Removal"
    ],
    "c_abstract":[
      "High-fidelity imaging is crucial for the successful safety supervision and\nintelligent deployment of vision-based measurement systems (VBMS). It ensures\nhigh-quality imaging in VBMS, which is fundamental for reliable visual\nmeasurement and analysis. However, imaging quality can be significantly\nimpaired by adverse weather conditions, particularly rain, leading to blurred\nimages and reduced contrast. Such impairments increase the risk of inaccurate\nevaluations and misinterpretations in VBMS. To address these limitations, we\npropose an Expectation Maximization Reconstruction Transformer (EMResformer)\nfor single image rain streak removal. The EMResformer retains the key\nself-attention values for feature aggregation, enhancing local features to\nproduce superior image reconstruction. Specifically, we propose an Expectation\nMaximization Block seamlessly integrated into the single image rain streak\nremoval network, enhancing its ability to eliminate superfluous information and\nrestore a cleaner background image. Additionally, to further enhance local\ninformation for improved detail rendition, we introduce a Local Model Residual\nBlock, which integrates two local model blocks along with a sequence of\nconvolutions and activation functions. This integration synergistically\nfacilitates the extraction of more pertinent features for enhanced single image\nrain streak removal. Extensive experiments validate that our proposed\nEMResformer surpasses current state-of-the-art single image rain streak removal\nmethods on both synthetic and real-world datasets, achieving an improved\nbalance between model complexity and single image deraining performance.\nFurthermore, we evaluate the effectiveness of our method in VBMS scenarios,\ndemonstrating that high-quality imaging significantly improves the accuracy and\nreliability of VBMS tasks."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-314",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14296",
    "b_title":[
      "Fractional fast diffusion with initial data a Radon measure"
    ],
    "b_abstract":[
      "We establish a complete Widder Theory for the fractional fast diffusion\nequation. Our work focuses on nonnegative solutions satisfying a certain\nintegral size condition at infinity. We prove that these solutions possess a\nRadon measure as initial trace, and prove the existence and uniqueness of\nsolutions originating from such initial data. The uniqueness result is the main\nissue. Most of its difficulty comes from the singular character of the\nnonlinearity."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.08513",
    "c_title":[
      "\"You'll Be Alice Adventuring in Wonderland!\" Processes, Challenges, and\n  Opportunities of Creating Animated Virtual Reality Stories"
    ],
    "c_abstract":[
      "Animated virtual reality (VR) stories, combining the presence of VR and the\nartistry of computer animation, offer a compelling way to deliver messages and\nevoke emotions. Motivated by the growing demand for immersive narrative\nexperiences, more creators are creating animated VR stories. However, a\nholistic understanding of their creation processes and challenges involved in\ncrafting these stories is still limited. Based on semi-structured interviews\nwith 21 animated VR story creators, we identify ten common stages in their\nend-to-end creation processes, ranging from idea generation to evaluation,\nwhich form diverse workflows that are story-driven or visual-driven.\nAdditionally, we highlight nine unique issues that arise during the creation\nprocess, such as a lack of reference material for multi-element plots, the\nabsence of specific functionalities for story integration, and inadequate\nsupport for audience evaluation. We compare the creation of animated VR stories\nto general XR applications and distill several future research opportunities."
    ],
    "c_categories":[
      [
        "cs.GR",
        "cs.HC",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-315",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05805",
    "b_title":[
      "Multi-agent Auto-Bidding with Latent Graph Diffusion Models"
    ],
    "b_abstract":[
      "This paper proposes a diffusion-based auto-bidding framework that leverages\ngraph representations to model large-scale auction environments. In such\nsettings, agents must dynamically optimize bidding strategies under constraints\ndefined by key performance indicator (KPI) metrics, all while operating in\ncompetitive environments characterized by uncertain, sparse, and stochastic\nvariables. To address these challenges, we introduce a novel approach combining\nlearnable graph-based embeddings with a planning-based latent diffusion model\n(LDM). By capturing patterns and nuances underlying the interdependence of\nimpression opportunities and the multi-agent dynamics of the auction\nenvironment, the graph representation enable expressive computations regarding\nauto-bidding outcomes. With reward alignment techniques, the LDM's posterior is\nfine-tuned to generate auto-bidding trajectories that maximize KPI metrics\nwhile satisfying constraint thresholds. Empirical evaluations on both\nreal-world and synthetic auction environments demonstrate significant\nimprovements in auto-bidding performance across multiple common KPI metrics, as\nwell as accuracy in forecasting auction outcomes."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15083",
    "c_title":[
      "Chiral ground states in a nematic liquid crystal confined to a cylinder\n  with homeotropic anchoring"
    ],
    "c_abstract":[
      "The singular potential method in the Q tensor order parameter representation\nis used to determine the ground state configuration of an elastically\nanisotropic nematic liquid crystal when confined to a cylindrical geometry with\nhomeotropic anchoring. Ground states of broken chiral symmetry are found for\nsufficiently small values of the twist elastic constant relative to bend and\nsplay constants. For small cylinder radius, twisted configurations, which\nfeature two disclinations lines that wind around the long axis of the cylinder,\nare generally found to minimize the free energy of the nematic. For larger\nradii, ground state configurations are (non singular) escaped configuration.\nTwisted and untwisted escaped configurations are almost degenerate in energy in\nthis region. This near degeneracy is broken when splay-bend contrast is\nallowed."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-316",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17673",
    "b_title":[
      "Mie-resonant silicon waveguide for efficient coupling with excitonic\n  emitters in InSe"
    ],
    "b_abstract":[
      "Enhancement of radiative coupling efficiency between out-of-plane excitonic\nemitters in an indium selenide (InSe) film and an integrated waveguide formed\nby silicon (Si) Mie-resonant nanodisks is experimentally studied.\nPhotoluminescence power at the resonant waveguide output is increased by~2.5\ntimes at 950~nm in comparison with the case of a conventional rib waveguide of\nthe same geometrical parameters due to the efficient excitation of Mie-type\nmagnetic dipole resonances in individual nanoparticles. These results show\ninspiring possibilities for creating new on-chip light emitters for various\nintegrated photonics applications."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12706",
    "c_title":[
      "REX: Causal Discovery based on Machine Learning and Explainability\n  techniques"
    ],
    "c_abstract":[
      "Explainability techniques hold significant potential for enhancing the causal\ndiscovery process, which is crucial for understanding complex systems in areas\nlike healthcare, economics, and artificial intelligence. However, no causal\ndiscovery methods currently incorporate explainability into their models to\nderive causal graphs. Thus, in this paper we explore this innovative approach,\nas it offers substantial potential and represents a promising new direction\nworth investigating. Specifically, we introduce REX, a causal discovery method\nthat leverages machine learning (ML) models coupled with explainability\ntechniques, specifically Shapley values, to identify and interpret significant\ncausal relationships among variables.\n  Comparative evaluations on synthetic datasets comprising continuous tabular\ndata reveal that REX outperforms state-of-the-art causal discovery methods\nacross diverse data generation processes, including non-linear and additive\nnoise models. Moreover, REX was tested on the Sachs single-cell\nprotein-signaling dataset, achieving a precision of 0.952 and recovering key\ncausal relationships with no incorrect edges. Taking together, these results\nshowcase REX's effectiveness in accurately recovering true causal structures\nwhile minimizing false positive predictions, its robustness across diverse\ndatasets, and its applicability to real-world problems. By combining ML and\nexplainability techniques with causal discovery, REX bridges the gap between\npredictive modeling and causal inference, offering an effective tool for\nunderstanding complex causal structures. REX is publicly available at\nhttps:\/\/github.com\/renero\/causalgraph."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-317",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03038",
    "b_title":[
      "Piano Transcription by Hierarchical Language Modeling with Pretrained\n  Roll-based Encoders"
    ],
    "b_abstract":[
      "Automatic Music Transcription (AMT), aiming to get musical notes from raw\naudio, typically uses frame-level systems with piano-roll outputs or language\nmodel (LM)-based systems with note-level predictions. However, frame-level\nsystems require manual thresholding, while the LM-based systems struggle with\nlong sequences. In this paper, we propose a hybrid method combining pre-trained\nroll-based encoders with an LM decoder to leverage the strengths of both\nmethods. Besides, our approach employs a hierarchical prediction strategy,\nfirst predicting onset and pitch, then velocity, and finally offset. The\nhierarchical prediction strategy reduces computational costs by breaking down\nlong sequences into different hierarchies. Evaluated on two benchmark\nroll-based encoders, our method outperforms traditional piano-roll outputs 0.01\nand 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a\nperformance-enhancing plug-in for arbitrary roll-based music transcription\nencoder."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05126",
    "c_title":[
      "Regularity of edge ideals of powers of graphs"
    ],
    "c_abstract":[
      "We prove that the regularity of edge ideals of powers of forests is weakly\ndecreasing. We then compute the regularity of edge ideals of powers of cycles."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-318",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02086",
    "b_title":[
      "Discovery of A Low-mass Strong-lens System in SMACS J0723.3-7327"
    ],
    "b_abstract":[
      "We report the discovery of an intriguing, low-mass galaxy-scale strong-lens\nsystem in the SMACS J0723.3-7327 galaxy cluster. By modeling James Webb Space\nTelescope imaging and Very Large Telescope Multi-Unit Spectroscopic Explorer\nspectroscopic data, we find that the lens is cluster member galaxy at $z=0.397$\nwith an Einstein radius of $0^{\\prime \\prime}.424$ $\\pm$ $0^{\\prime\n\\prime}.012$, stellar mass of $M_* = (3.3 \\pm 0.8) \\times 10^{10} M_\\odot$,\nhalf-light radius of $\\sim 1$ kpc, and central stellar velocity dispersion of\n$140 \\pm 6$ km s$^{-1}$. This lens galaxy is one of the few strong lens\ngalaxies known to date that have stellar mass as low as $M_* \\sim 10^{10.5}\nM_\\odot$, offering an exceptional opportunity to peek into the population of\nlow-mass galaxies that has largely remained unexplored in the context of\nstrong-lensing studies. This strong lens system can also assist in assessing\nthe systematic uncertainty in the lens modeling of cluster member galaxies."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09747",
    "c_title":[
      "The Widespread Adoption of Large Language Model-Assisted Writing Across\n  Society"
    ],
    "c_abstract":[
      "The recent advances in large language models (LLMs) attracted significant\npublic and policymaker interest in its adoption patterns. In this paper, we\nsystematically analyze LLM-assisted writing across four domains-consumer\ncomplaints, corporate communications, job postings, and international\norganization press releases-from January 2022 to September 2024. Our dataset\nincludes 687,241 consumer complaints, 537,413 corporate press releases, 304.3\nmillion job postings, and 15,919 United Nations (UN) press releases. Using a\nrobust population-level statistical framework, we find that LLM usage surged\nfollowing the release of ChatGPT in November 2022. By late 2024, roughly 18% of\nfinancial consumer complaint text appears to be LLM-assisted, with adoption\npatterns spread broadly across regions and slightly higher in urban areas. For\ncorporate press releases, up to 24% of the text is attributable to LLMs. In job\npostings, LLM-assisted writing accounts for just below 10% in small firms, and\nis even more common among younger firms. UN press releases also reflect this\ntrend, with nearly 14% of content being generated or modified by LLMs. Although\nadoption climbed rapidly post-ChatGPT, growth appears to have stabilized by\n2024, reflecting either saturation in LLM adoption or increasing subtlety of\nmore advanced models. Our study shows the emergence of a new reality in which\nfirms, consumers and even international organizations substantially rely on\ngenerative AI for communications."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-319",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17516",
    "b_title":[
      "Spectrum of weighted composition operators. Part XI. The essential\n  spectra of some weighted composition operators on the disc algebra"
    ],
    "b_abstract":[
      "We obtain a complete description of semi-Fredholm spectra of operators of the\nform $(Tf)(z) = w(z)f(B(z)$ acting on the disc algebra in the case when $B$ is\neither elliptic or double parabolic finite Blaschke product of degree $d \\geq\n2$ and $w$ has no zeros on the unit circle. In the case when $B$ has zeros on\nthe unit circle we provide only some partial results. Our results hint on the\npossibility of interesting connections between the spectral properties of\nweighted composition operators and complex dynamics."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10340",
    "c_title":[
      "Diffraction of Light from Optical Fourier Surfaces"
    ],
    "c_abstract":[
      "Diffractive surfaces shape optical wavefronts for applications in\nspectroscopy, high-speed communication, and imaging. The performance of these\nstructures is primarily determined by how precisely they can be patterned.\nFabrication constraints commonly lead to square-shaped, \"binary\" profiles that\ncontain unwanted spatial frequencies that contaminate the diffraction.\nRecently, \"wavy\" surfaces (known as optical Fourier surfaces, OFSs) have been\nintroduced that include only the desired spatial frequencies. However, the\noptical performance and reliability of these structures have not yet been\nexperimentally tested with respect to models and simulations. Such a\nquantitative investigation could also provide previously unobtainable\ninformation about the diffraction process from the most fundamental diffractive\nsurfaces$\\unicode{x2014}$sinusoidally pure profiles. Here, we produce and study\ntwo classes of reflective OFSs: (i) single-sinusoidal profiles of varying depth\nand (ii) double-sinusoidal profiles with varying relative phase. After refining\nour fabrication procedure to obtain larger and deeper OFSs at higher yields, we\nfind that the measured optical responses from our OFSs agree quantitatively\nwith full electrodynamic simulations. In contrast, our measurements diverge\nfrom analytical scalar diffraction models routinely used by researchers to\ndescribe diffraction. Overall, our results confirm that OFSs provide a precise\nand powerful platform for Fourier-spectrum engineering, satisfying the growing\ndemand for intricately patterned interfaces for applications in holography,\naugmented reality, and optical computing."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-320",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03761",
    "b_title":[
      "UAV Cognitive Semantic Communications Enabled by Knowledge Graph for\n  Robust Object Detection"
    ],
    "b_abstract":[
      "Unmanned aerial vehicles (UAVs) are widely used for object detection.\nHowever, the existing UAV-based object detection systems are subject to severe\nchallenges, namely, their limited computation, energy and communication\nresources, which limits the achievable detection performance. To overcome these\nchallenges, a UAV cognitive semantic communication system is proposed by\nexploiting a knowledge graph. Moreover, we design a multi-scale codec for\nsemantic compression to reduce data transmission volume while guaranteeing\ndetection performance. Considering the complexity and dynamicity of UAV\ncommunication scenarios, a signal-to-noise ratio (SNR) adaptive module with\nrobust channel adaptation capability is introduced. Furthermore, an object\ndetection scheme is proposed by exploiting the knowledge graph to overcome\nchannel noise interference and compression distortion. Simulation results\nconducted on the practical aerial image dataset demonstrate that our proposed\nsemantic communication system outperforms benchmark systems in terms of\ndetection accuracy, communication robustness, and computation efficiency,\nespecially in dealing with low bandwidth compression ratios and low SNR\nregimes."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15951",
    "c_title":[
      "Rotational decoherence dynamics in ultracold molecules induced by a\n  tunable spin environment: The Central Rotor Model"
    ],
    "c_abstract":[
      "We show that quantum rotational wavepacket dynamics in molecules can be\ndescribed by a new system-environment model, which consists of a rotational\nsubsystem coupled to a magnetically tunable spin bath formed by the nuclear\nspins within the molecule. The central rotor model shares similarities with the\nparadigmatic central spin model, but features much richer rotational dynamics\nthat is sensitive to the molecule's environment, which can be initiated and\nprobed with short laser pulses used to control molecular orientation and\nalignment. We present numerical simulations of the nuclear-spin-bath-induced\nrotational decoherence dynamics of KRb molecules, which exhibit remarkable\nsensitivity to an external magnetic field. Our results show that ultracold\nmolecular gases provide a natural platform for the experimental realization of\nthe CRM."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-321",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17746",
    "b_title":[
      "Predictive Beamforming with Distributed MIMO"
    ],
    "b_abstract":[
      "In vehicle-to-everything (V2X) applications, roadside units (RSUs) can be\ntasked with both sensing and communication functions to enable sensing-assisted\ncommunications. Recent studies have demonstrated that distance, angle, and\nvelocity information obtained through sensing can be leveraged to reduce the\noverhead associated with communication beam tracking. In this work, we extend\nthis concept to scenarios involving multiple distributed RSUs and distributed\nMIMO (multiple-input multiple-output) systems. We derive the state evolution\nmodel, formulate the extended Kalman-filter equations, and implement predictive\nbeamforming for distributed MIMO. Simulation results indicate that, when\ncompared with a co-located massive MIMO antenna array, distributed antennas\nlead to more uniform and robust sensing performance, coverage, and data rates,\nwhile the vehicular user is in motion."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03823",
    "c_title":[
      "Bounds on neutrino-DM interactions from TXS 0506+056 neutrino outburst"
    ],
    "c_abstract":[
      "We constrain the neutrino-dark matter cross-section using the $13 \\pm 5$\nneutrino event excess observed by IceCube in 2014-2015 from the direction of\nthe blazar TXS 0506+056. Our analysis takes advantage of the dark matter\noverdensity spike surrounding the supermassive black hole at the center of the\nblazar. In our results, we take into account uncertainties related to the\ndifferent types of neutrino emission models and the features of the dark matter\nspike, considering cross-sections that scale with energy as $\\sigma \\propto\n(E_{\\nu} \/E_0)^n$, for values of $n = 1, 0, -1, -2$. In our best-case scenario,\nwe obtain limits competitive with those derived from other active galaxies,\ntidal disruption events (TDEs), and the IC-170922A event."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-322",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15280",
    "b_title":[
      "System of stochastic interacting wave functions that model quantum\n  measurements"
    ],
    "b_abstract":[
      "We develop a system of non-linear stochastic evolution equations that\ndescribes the continuous measurements of quantum systems with mixed initial\nstate. We address quantum systems with unbounded Hamiltonians and unbounded\ninteraction operators. Using arguments of the theory of quantum measurements we\nderive a system of stochastic interacting wave functions (SIWF for short) that\nmodels the continuous monitoring of quantum systems. We prove the existence and\nuniqueness of the solution to this system under conditions general enough for\nthe applications. We obtain that the mixed state generated by the SIWF at any\ntime does not depend on the initial state, and satisfies the diffusive\nstochastic quantum master equation, which is also known as Belavkin equation.\nWe present two physical examples. In one, the SIWF becomes a system of\nnon-linear stochastic partial differential equations. In the other, we deal\nwith a model of a circuit quantum electrodynamics."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05880",
    "c_title":[
      "Approximate Bayesian inference for joint partially linear modeling of\n  longitudinal measurements and spatial time-to-event data"
    ],
    "c_abstract":[
      "The integration of longitudinal measurements and survival time in statistical\nmodeling offers a powerful framework for capturing the interplay between these\ntwo essential outcomes, particularly when they exhibit associations. However,\nin scenarios where spatial dependencies among entities are present due to\ngeographic regions, traditional approaches may fall short. In response, this\npaper introduces a novel approximate Bayesian hierarchical model tailored for\njointly analyzing longitudinal and spatial survival outcomes. The model\nleverages a conditional autoregressive structure to incorporate spatial\neffects, while simultaneously employing a joint partially linear model to\ncapture the nonlinear influence of time on longitudinal responses. Through\nextensive simulation studies, the efficacy of the proposed method is rigorously\nevaluated. Furthermore, its practical utility is demonstrated through an\napplication to real-world HIV\/AIDS data sourced from various Brazilian states,\nshowcasing its adaptability and relevance in epidemiological research."
    ],
    "c_categories":[
      [
        "stat.CO",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-323",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.00761",
    "b_title":[
      "Giant Nonvolatile Multistate Resistance with Fully Magnetically\n  Controlled in van der Waals Multiferroic Tunnel Junctions"
    ],
    "b_abstract":[
      "Ferroelectric polarization switching in electrically controlled van der Waals\nmultiferroic tunnel junctions (vdW-MFTJs) causes atomic migration, compromising\ndevice stability and fatigue resistance. Here we propose a fully magnetically\ncontrolled vdW-MFTJ based on a \\(\\mathrm{CrBr_3\/MnPSe_3\/CrBr_3}\\) vertical\nheterostructure, which achieves ferroelectric polarization reversal without\nrelying on atomic migration driven by inversion symmetry breaking. Using\nfirst-principles calculations, we investigate the spin-polarized quantum\ntransport properties of the proposed structure. By integrating asymmetric\nPtTe$_2$\/alkali-metal (Li\/Na\/K)-doped\/intercalated CrBr$_3$ electrodes, the\ndevice demonstrates exceptional performance, with a maximum tunneling\nmagnetoresistance (TMR) exceeding $8.1\\times10^5$\\% and tunneling\nelectroresistance (TER) reaching 2499\\%, while the spin-filtering channels can\nbe flexibly controlled by the magnetization direction of the magnetic free\nlayer, achieving perfect spin-filtering over a broad bias voltage range.\nApplying an external bias voltage further enhances these metrics, increasing\nTMR to $3.6\\times 10^7$\\% and TER to 9990\\%. Notably, a pronounced negative\ndifferential resistance (NDR) effect is observed, yielding an unprecedented\npeak-to-valley ratio (PVR) of $9.55\\times10^9$\\%, representing the highest\nvalue reported for vertical tunnel junctions. These extraordinary\ncharacteristics highlight the potential of vdW-MFTJs for ultra-efficient\nelectronic switching, a key feature for next-generation spintronic devices. Our\nfindings provide a solid theoretical foundation for designing and developing\nhigh-performance magnetic storage and logic technologies."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04329",
    "c_title":[
      "An Efficient Adaptive Compression Method for Human Perception and\n  Machine Vision Tasks"
    ],
    "c_abstract":[
      "While most existing neural image compression (NIC) and neural video\ncompression (NVC) methodologies have achieved remarkable success, their\noptimization is primarily focused on human visual perception. However, with the\nrapid development of artificial intelligence, many images and videos will be\nused for various machine vision tasks. Consequently, such existing compression\nmethodologies cannot achieve competitive performance in machine vision. In this\nwork, we introduce an efficient adaptive compression (EAC) method tailored for\nboth human perception and multiple machine vision tasks. Our method involves\ntwo key modules: 1), an adaptive compression mechanism, that adaptively selects\nseveral subsets from latent features to balance the optimizations for multiple\nmachine vision tasks (e.g., segmentation, and detection) and human vision. 2),\na task-specific adapter, that uses the parameter-efficient delta-tuning\nstrategy to stimulate the comprehensive downstream analytical networks for\nspecific machine vision tasks. By using the above two modules, we can optimize\nthe bit-rate costs and improve machine vision performance. In general, our\nproposed EAC can seamlessly integrate with existing NIC (i.e., Ball\\'e2018, and\nCheng2020) and NVC (i.e., DVC, and FVC) methods. Extensive evaluation on\nvarious benchmark datasets (i.e., VOC2007, ILSVRC2012, VOC2012, COCO, UCF101,\nand DAVIS) shows that our method enhances performance for multiple machine\nvision tasks while maintaining the quality of human vision."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-324",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00550",
    "b_title":[
      "Validating Urban Scaling Laws through Mobile Phone Data: A\n  Continental-Scale Analysis of Brazil's Largest Cities"
    ],
    "b_abstract":[
      "\\abstract{Urban scaling theories posit that larger cities exhibit\ndisproportionately higher levels of socioeconomic activity and human\ninteractions. Yet, evidence from developing contexts (especially those marked\nby stark socioeconomic disparities) remains limited. To address this gap, we\nanalyse a month-long dataset of 3.1~billion voice-call records from Brazil's\n100 most populous cities, providing a continental-scale test of urban scaling\nlaws. We measure interactions using two complementary proxies: the number of\nphone-based contacts (voice-call degrees) and the number of trips inferred from\nconsecutive calls in distinct locations. Our findings reveal clear superlinear\nrelationships in both metrics, indicating that larger urban centres exhibit\nintensified remote communication and physical mobility. We further observe that\ngross domestic product (GDP) also scales superlinearly with population,\nconsistent with broader claims that economic output grows faster than city\nsize. Conversely, the number of antennas required per user scales sublinearly,\nsuggesting economies of scale in telecommunications infrastructure. Although\nthe dataset covers a single provider, its widespread coverage in major cities\nsupports the robustness of the results. We nonetheless discuss potential\nbiases, including city-specific marketing campaigns and predominantly prepaid\nusers, as well as the open question of whether higher interaction drives wealth\nor vice versa. Overall, this study enriches our understanding of urban scaling,\nemphasising how communication and mobility jointly shape the socioeconomic\nlandscapes of rapidly growing cities."
    ],
    "b_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00651",
    "c_title":[
      "Integrating Cybersecurity Frameworks into IT Security: A Comprehensive\n  Analysis of Threat Mitigation Strategies and Adaptive Technologies"
    ],
    "c_abstract":[
      "The cybersecurity threat landscape is constantly actively making it\nimperative to develop sound frameworks to protect the IT structures. Based on\nthis introduction, this paper aims to discuss the application of cybersecurity\nframeworks into the IT security with focus placed on the role of such\nframeworks in addressing the changing nature of cybersecurity threats. It\nexplores widely used models, including the NIST Cybersecurity Framework, Zero\nTrust Architecture, and the ISO\/IEC 27001, and how they apply to industries\nincluding finance, healthcare and government. The discussion also singles out\nsuch technologies as Artificial Intelligence (AI) and Machine Learning (ML) as\nthe core for real-time threat detection and response mechanisms. As these\nintegration challenges demonstrate, the study provides tangible and proven\napproaches to tackle framework implementation issues such as legitimate\nsecurity issues, limited availability of funds and resources, and compliance\nwith legal requirements. By capturing current trends and exposures, the\nfindings promote strong, portfolio-based and risk-appropriate security\napproaches adjusted for organizational goals and capable to prevent advanced\ncyber threats."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-325",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14717",
    "b_title":[
      "Towards Better Understanding Table Instruction Tuning: Decoupling the\n  Effects from Data versus Models"
    ],
    "b_abstract":[
      "Recent advances in natural language processing have leveraged instruction\ntuning to enhance Large Language Models (LLMs) for table-related tasks.\nHowever, previous works train different base models with different training\ndata, lacking an apples-to-apples comparison across the result table LLMs. To\naddress this, we fine-tune base models from the Mistral, OLMo, and Phi families\non existing public training datasets. Our replication achieves performance on\npar with or surpassing existing table LLMs, establishing new state-of-the-art\nperformance on Hitab, a table question-answering dataset. More importantly,\nthrough systematic out-of-domain evaluation, we decouple the contributions of\ntraining data and the base model, providing insight into their individual\nimpacts. In addition, we assess the effects of table-specific instruction\ntuning on general-purpose benchmarks, revealing trade-offs between\nspecialization and generalization."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13462",
    "c_title":[
      "Generalized graph codes and thier minimum distances"
    ],
    "c_abstract":[
      "Graph code is a linear code obtained from linear codes $C$ and a certain\nbipartite graph G. In this paper, I propose an expansion of the definition of\ngraph code to general $l$-partite, and give its lower bound of minimum\ndistance. I also give an example of generalized graph code and calculate its\nparameters $[n, k, d]$."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.CO",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-326",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09241",
    "b_title":[
      "In-Context Defense in Computer Agents: An Empirical Study"
    ],
    "b_abstract":[
      "Computer agents powered by vision-language models (VLMs) have significantly\nadvanced human-computer interaction, enabling users to perform complex tasks\nthrough natural language instructions. However, these agents are vulnerable to\ncontext deception attacks, an emerging threat where adversaries embed\nmisleading content into the agent's operational environment, such as a pop-up\nwindow containing deceptive instructions. Existing defenses, such as\ninstructing agents to ignore deceptive elements, have proven largely\nineffective. As the first systematic study on protecting computer agents, we\nintroduce textbf{in-context defense}, leveraging in-context learning and\nchain-of-thought (CoT) reasoning to counter such attacks. Our approach involves\naugmenting the agent's context with a small set of carefully curated exemplars\ncontaining both malicious environments and corresponding defensive responses.\nThese exemplars guide the agent to first perform explicit defensive reasoning\nbefore action planning, reducing susceptibility to deceptive attacks.\nExperiments demonstrate the effectiveness of our method, reducing attack\nsuccess rates by 91.2% on pop-up window attacks, 74.6% on average on\nenvironment injection attacks, while achieving 100% successful defenses against\ndistracting advertisements. Our findings highlight that (1) defensive reasoning\nmust precede action planning for optimal performance, and (2) a minimal number\nof exemplars (fewer than three) is sufficient to induce an agent's defensive\nbehavior."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05133",
    "c_title":[
      "A probabilistic study of the set of stationary solutions to spatial\n  kinetic-type equations"
    ],
    "c_abstract":[
      "In this paper we study multivariate kinetic-type equations in a general\nsetup, which includes in particular the spatially homogeneous Boltzmann\nequation with Maxwellian molecules, both with elastic and inelastic collisions.\nUsing a representation of the collision operator derived in Bassetti, Ladelli,\nMatthes (2015) and Dolera, Regazzini (2014), we prove the existence and\nuniqueness of time-dependent solutions with the help of continuous-time\nbranching random walks, under assumptions as weak as possible. Our main\nobjective is a characterisation of the set of stationary solutions, e.g.\nequilibrium solutions for inelastic kinetic-type equations, which we describe\nas mixtures of multidimensional stable laws."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-327",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14703",
    "b_title":[
      "Thermomechanical Processing of Pure Magnesium: Hot Extrusion, Hot\n  Rolling and Cold Drawing"
    ],
    "b_abstract":[
      "A comprehensive study on thermomechanical processing of pure Mg was conducted\nthrough sequential hot extrusion, hot rolling, and cold drawing operations.\nThree different extrusion ratios (6:1, 25:1, and 39:1) were investigated at\n350{\\deg}C, revealing that 39:1 ratio produced an optimal bimodal grain\nstructure with beneficial twin morphology. Subsequently, hot rolling\nexperiments were performed at varying linear speeds (26- and 130-mm s-1) and\ninterpass annealing times (2.5 and 10 minutes). Results demonstrated that\nhigher rolling speeds led to finer microstructure, while longer interpass\nannealing times resulted in reduced twin fraction and more inhomogeneous\nmicrostructure. The processed material was then subjected to cold drawing with\napproximately 12% true strain per pass. Different annealing conditions\n(275{\\deg}C and 375{\\deg}C for 2.5-10 minutes) between drawing passes were\nevaluated. Analysis showed that annealing at 375{\\deg}C for 2.5-5 minutes\nprovided optimal softening for subsequent deformation. Fracture analysis\nrevealed a mixed ductile-brittle behavior, with twin-matrix interfaces serving\nas preferred crack propagation paths This study establishes optimal processing\nparameters for pure Mg wire production, highlighting the critical role of twin\ncharacteristics and restoration processes in determining material formability\nduring multi-step thermomechanical processing."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06713",
    "c_title":[
      "MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation"
    ],
    "c_abstract":[
      "The growing demand for efficient and lightweight Retrieval-Augmented\nGeneration (RAG) systems has highlighted significant challenges when deploying\nSmall Language Models (SLMs) in existing RAG frameworks. Current approaches\nface severe performance degradation due to SLMs' limited semantic understanding\nand text processing capabilities, creating barriers for widespread adoption in\nresource-constrained scenarios. To address these fundamental limitations, we\npresent MiniRAG, a novel RAG system designed for extreme simplicity and\nefficiency. MiniRAG introduces two key technical innovations: (1) a\nsemantic-aware heterogeneous graph indexing mechanism that combines text chunks\nand named entities in a unified structure, reducing reliance on complex\nsemantic understanding, and (2) a lightweight topology-enhanced retrieval\napproach that leverages graph structures for efficient knowledge discovery\nwithout requiring advanced language capabilities. Our extensive experiments\ndemonstrate that MiniRAG achieves comparable performance to LLM-based methods\neven when using SLMs while requiring only 25\\% of the storage space.\nAdditionally, we contribute a comprehensive benchmark dataset for evaluating\nlightweight RAG systems under realistic on-device scenarios with complex\nqueries. We fully open-source our implementation and datasets at:\nhttps:\/\/github.com\/HKUDS\/MiniRAG."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-328",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14402",
    "b_title":[
      "On the Effectiveness of Microservices Tactics and Patterns to Reduce\n  Energy Consumption: An Experimental Study on Trade-Offs"
    ],
    "b_abstract":[
      "Context: Microservice-based systems have established themselves in the\nsoftware industry. However, sustainability-related legislation and the growing\ncosts of energy-hungry software increase the importance of energy efficiency\nfor these systems. While some proposals for architectural tactics and patterns\nexist, their effectiveness as well as potential trade-offs on other quality\nattributes (QAs) remain unclear.\n  Goal: We therefore aim to study the effectiveness of microservices tactics\nand patterns to reduce energy consumption, as well as potential trade-offs with\nperformance and maintainability.\n  Method: Using the open-source Online Boutique system, we conducted a\ncontrolled experiment with three tactics and three patterns, and analyzed the\nimpact of each technique compared to a baseline. We also tested with three\nlevels of simulated request loads (low, medium, high).\n  Results: Request load moderated the effectiveness of reducing energy\nconsumption. All techniques (tactics and patterns) reduced the energy\nconsumption for at least one load level, up to 5.6%. For performance, the\ntechniques could negatively impact response time by increasing it by up to\n25.9%, while some also decreased it by up to 72.5%. Two techniques increased\nthe throughput, by 1.9% and 34.0%. For maintainability, three techniques had a\nnegative, one a positive, and two no impact.\n  Conclusion: Some techniques reduced energy consumption while also improving\nperformance. However, these techniques usually involved a trade-off in\nmaintainability, e.g., via more code duplication and module coupling. Overall,\nall techniques significantly reduced energy consumption at higher loads, but\nmost of them sacrificed one of the other QAs. This highlights that the real\nchallenge is not simply reducing energy consumption of microservices, but to\nachieve energy efficiency."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05416",
    "c_title":[
      "Analytical control of the exchange interaction in periodically driven\n  Mott insulators"
    ],
    "c_abstract":[
      "The manipulation of electronic structure through periodic electric fields\nenables the reversible control of effective interactions in extended\nantiferromagnetic Mott insulators on ultrafast timescales. A careful analytical\nexamination of the modulated effective interactions is conducted, accurately\ncharacterising it through the use of exact summation formulas and Bessel\nfunctions. As a result, time reversals are analytically determined in terms of\nBessel zeroes. We discuss the half-filled Hubbard model, as well as\nmulti-orbital models, various characteristics of the Kitaev-Heisenberg model,\nand the emergence of chiral spin terms."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-329",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18254",
    "b_title":[
      "Normalized solutions to lower critical Choquard equation in\n  mass-supercritical setting"
    ],
    "b_abstract":[
      "We study the normalized solutions to the following Choquard equation\n  \\begin{equation*}\n  \\aligned &-\\Delta u + \\lambda u =\\mu g(u) + \\gamma (I_\\alpha *\n|u|^{\\frac{N+\\alpha}{N}})|u|^{\\frac{N+\\alpha}{N}-2}u & \\text{in\\ \\ }\n\\mathbb{R}^N \\endaligned\n  \\end{equation*} under the $L^2$-norm constraint $\\|u\\|_2=c$. Here $\\gamma>0$,\n$ N\\geq 1$, $\\alpha\\in(0,N)$, $I_{\\alpha}$ is the Riesz potential, and the\nunknown $\\lambda$ appears as a Lagrange multiplier. In a mass supercritical\nsetting on $g$, we find regions in the $(c,\\mu)$--parameter space such that the\ncorresponding equation admits a positive radial ground state solution. To\novercome the lack of compactness resulting from the nonlocal term, we present a\nnovel compactness lemma and some prior energy estimate. These results are even\nnew for the power type nonlinearity $g(u)= |u|^{q-2}u$ with\n$2+\\frac{4}{N}<q<2^*$ ($2^*:=\\frac{2N}{N-2}$, if $N\\geq 3$ and $2^* = \\infty$,\nif $N=1, 2$). We also show that as $\\mu$ or $c$ tends to $0$ (resp. $\\mu$ or\n$c$ tends to $+\\infty$), after a suitable rescaling the ground state solutions\nconverge in $H^1(\\RN)$ to a particular solution of the limit equations.\nFurther, we study the non-existence and multiplicity of positive radial\nsolutions to \\begin{equation*}\n  -\\Delta u + u = \\eta |u|^{q-2}u + (I_\\alpha *\n|u|^{\\frac{N+\\alpha}{N}})|u|^{\\frac{N+\\alpha}{N}-2}u, \\quad \\text{in}\\ \\ \\RN\n\\end{equation*} where $N \\geq 1$, $ 2< q<2^*$ and $\\eta>0$. Based on some\nanalytical ideas the limit behaviors of the normalized solutions, we verify\nsome threshold regions of $\\eta$ such that the corresponding equation has no\npositive least action solution or admits multiple positive solutions. To the\nbest of our knowledge, this seems to be the first result concerning the\nnon-existence and multiplicity of positive solutions to Choquard type equations\ninvolving the lower critical exponent."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15181",
    "c_title":[
      "From Bugs to Benefits: Improving User Stories by Leveraging Crowd\n  Knowledge with CrUISE-AC"
    ],
    "c_abstract":[
      "Costs for resolving software defects increase exponentially in late stages.\nIncomplete or ambiguous requirements are one of the biggest sources for\ndefects, since stakeholders might not be able to communicate their needs or\nfail to share their domain specific knowledge. Combined with insufficient\ndeveloper experience, teams are prone to constructing incorrect or incomplete\nfeatures. To prevent this, requirements engineering has to explore knowledge\nsources beyond stakeholder interviews. Publicly accessible issue trackers for\nsystems within the same application domain hold essential information on\nidentified weaknesses, edge cases, and potential error sources, all documented\nby actual users. Our research aims at (1) identifying, and (2) leveraging such\nissues to improve an agile requirements artifact known as a \"user story\". We\npresent CrUISE-AC (Crowd and User Informed Suggestion Engine for Acceptance\nCriteria) as a fully automated method that investigates issues and generates\nnon-trivial additional acceptance criteria for a given user story by employing\nNLP techniques and an ensemble of LLMs. CrUISE- AC was evaluated by five\nindependent experts in two distinct business domains. Our findings suggest that\nissue trackers hold valuable information pertinent to requirements engineering.\nOur evaluation shows that 80-82% of the generated acceptance criteria add\nrelevant requirements to the user stories. Limitations are the dependence on\naccessible input issues and the fact that we do not check generated criteria\nfor being conflict-free or non-overlapping with criteria from other user\nstories."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-330",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05487",
    "b_title":[
      "The Future of AI: Exploring the Potential of Large Concept Models"
    ],
    "b_abstract":[
      "The field of Artificial Intelligence (AI) continues to drive transformative\ninnovations, with significant progress in conversational interfaces, autonomous\nvehicles, and intelligent content creation. Since the launch of ChatGPT in late\n2022, the rise of Generative AI has marked a pivotal era, with the term Large\nLanguage Models (LLMs) becoming a ubiquitous part of daily life. LLMs have\ndemonstrated exceptional capabilities in tasks such as text summarization, code\ngeneration, and creative writing. However, these models are inherently limited\nby their token-level processing, which restricts their ability to perform\nabstract reasoning, conceptual understanding, and efficient generation of\nlong-form content. To address these limitations, Meta has introduced Large\nConcept Models (LCMs), representing a significant shift from traditional\ntoken-based frameworks. LCMs use concepts as foundational units of\nunderstanding, enabling more sophisticated semantic reasoning and context-aware\ndecision-making. Given the limited academic research on this emerging\ntechnology, our study aims to bridge the knowledge gap by collecting,\nanalyzing, and synthesizing existing grey literature to provide a comprehensive\nunderstanding of LCMs. Specifically, we (i) identify and describe the features\nthat distinguish LCMs from LLMs, (ii) explore potential applications of LCMs\nacross multiple domains, and (iii) propose future research directions and\npractical strategies to advance LCM development and adoption."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05994",
    "c_title":[
      "Diffusion Models for Inverse Problems in the Exponential Family"
    ],
    "c_abstract":[
      "Diffusion models have emerged as powerful tools for solving inverse problems,\nyet prior work has primarily focused on observations with Gaussian measurement\nnoise, restricting their use in real-world scenarios. This limitation persists\ndue to the intractability of the likelihood score, which until now has only\nbeen approximated in the simpler case of Gaussian likelihoods. In this work, we\nextend diffusion models to handle inverse problems where the observations\nfollow a distribution from the exponential family, such as a Poisson or a\nBinomial distribution. By leveraging the conjugacy properties of exponential\nfamily distributions, we introduce the evidence trick, a method that provides a\ntractable approximation to the likelihood score. In our experiments, we\ndemonstrate that our methodology effectively performs Bayesian inference on\nspatially inhomogeneous Poisson processes with intensities as intricate as\nImageNet images. Furthermore, we demonstrate the real-world impact of our\nmethodology by showing that it performs competitively with the current\nstate-of-the-art in predicting malaria prevalence estimates in Sub-Saharan\nAfrica."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-331",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19382",
    "b_title":[
      "LiDAR Loop Closure Detection using Semantic Graphs with Graph Attention\n  Networks"
    ],
    "b_abstract":[
      "In this paper, we propose a novel loop closure detection algorithm that uses\ngraph attention neural networks to encode semantic graphs to perform place\nrecognition and then use semantic registration to estimate the 6 DoF relative\npose constraint. Our place recognition algorithm has two key modules, namely, a\nsemantic graph encoder module and a graph comparison module. The semantic graph\nencoder employs graph attention networks to efficiently encode spatial,\nsemantic and geometric information from the semantic graph of the input point\ncloud. We then use self-attention mechanism in both node-embedding and\ngraph-embedding steps to create distinctive graph vectors. The graph vectors of\nthe current scan and a keyframe scan are then compared in the graph comparison\nmodule to identify a possible loop closure. Specifically, employing the\ndifference of the two graph vectors showed a significant improvement in\nperformance, as shown in ablation studies. Lastly, we implemented a semantic\nregistration algorithm that takes in loop closure candidate scans and estimates\nthe relative 6 DoF pose constraint for the LiDAR SLAM system. Extensive\nevaluation on public datasets shows that our model is more accurate and robust,\nachieving 13% improvement in maximum F1 score on the SemanticKITTI dataset,\nwhen compared to the baseline semantic graph algorithm. For the benefit of the\ncommunity, we open-source the complete implementation of our proposed algorithm\nand custom implementation of semantic registration at\nhttps:\/\/github.com\/crepuscularlight\/SemanticLoopClosure"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17066",
    "c_title":[
      "Formation of condensations for non-radial solutions to 3-wave kinetic\n  equations"
    ],
    "c_abstract":[
      "We consider in this work a $2$-dimensional $3$-wave kinetic equation\ndescribing the dynamics of the thermal cloud outside a Bose-Einstein\nCondensate. We construct global non-radial mild solutions for the equation.\nThose mild solutions are the summation of Dirac masses on circles. We prove\nthat in each spatial direction, either Dirac masses at the origin, which are\nthe so-called Bose-Einstein condensates, can be formed in finite time or the\nsolutions converge to Bose-Einstein condensates as time evolves to infinity. We\nalso describe a dynamics of the formation of the Bose-Einstein condensates\nlatter case. In this case, on each direction, the solutions accumulate around\ncircles close to the origin at growth rates at least linearly in time."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-332",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06055",
    "b_title":[
      "Dynamic Programming in Ordered Vector Space"
    ],
    "b_abstract":[
      "Recent approaches to the theory of dynamic programming view dynamic programs\nas families of policy operators acting on partially ordered sets. In this\npaper, we extend these ideas by shifting from arbitrary partially ordered sets\nto ordered vector space. The advantage of working in this setting is that\nordered vector spaces have well integrated algebric and order structure, which\nleads to sharper fixed point results. These fixed point results can then be\nexploited to obtain strong optimality properties. We illustrate our results\nthrough a range of applications, including new findings for several useful\nmodels."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16305",
    "c_title":[
      "New exact spatially localized solutions of the (3 + 1) -dimensional\n  nonlinear non-dissipative quasi-geostrophic potential vorticity equation for\n  an exponential atmosphere"
    ],
    "c_abstract":[
      "New exact spatially localized stationary solutions against the background of\na zonal flow are found for the (3+1)-dimensional nonlinear non-dissipative\nquasi-geostrophic potential vorticity equation, which describes Rossby waves\nand vortices in an exponential atmosphere. In total, three solutions are\npresented. The nonlinear boundary conditions with a flat bottom and a rigid lid\ngenerate an infinite discrete set of baroclinic modes for each solution. The\nsolutions show the possibility of existence of baroclinic dipoles in the\nexponential atmosphere, similar to baroclinic dipoles in the ocean. It is shown\nthat: a) a pair of vortices in the baroclinic dipole appears and disappears\nwhen the velocity of stationary motion changes; b) the baroclinic dipoles show\nthe ability to transfer warm or cold air depending on the polarity of the\nvortices in the dipole."
    ],
    "c_categories":[
      [
        "nlin.PS",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-333",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15719",
    "b_title":[
      "The Kodaira dimension of Hilbert modular threefolds"
    ],
    "b_abstract":[
      "Following a method introduced by Thomas-Vasquez and developed by Grundman, we\nprove that many Hilbert modular threefolds of arithmetic genus $0$ and $1$ are\nof general type, and that some are of nonnegative Kodaira dimension. The new\ningredient is a detailed study of the geometry and combinatorics of totally\npositive integral elements $x$ of a fractional ideal $I$ in a totally real\nnumber field $K$ with the property that $\\mathop{\\mathrm{tr}} xy <\n\\mathop{\\mathrm{min}} I \\mathop{\\mathrm{tr}} y$ for some $y \\gg 0 \\in K$."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10582",
    "c_title":[
      "Named entity recognition for Serbian legal documents: Design,\n  methodology and dataset development"
    ],
    "c_abstract":[
      "Recent advancements in the field of natural language processing (NLP) and\nespecially large language models (LLMs) and their numerous applications have\nbrought research attention to design of different document processing tools and\nenhancements in the process of document archiving, search and retrieval. Domain\nof official, legal documents is especially interesting due to vast amount of\ndata generated on the daily basis, as well as the significant community of\ninterested practitioners (lawyers, law offices, administrative workers, state\ninstitutions and citizens). Providing efficient ways for automation of everyday\nwork involving legal documents is therefore expected to have significant impact\nin different fields. In this work we present one LLM based solution for Named\nEntity Recognition (NER) in the case of legal documents written in Serbian\nlanguage. It leverages on the pre-trained bidirectional encoder representations\nfrom transformers (BERT), which had been carefully adapted to the specific task\nof identifying and classifying specific data points from textual content.\nBesides novel dataset development for Serbian language (involving public court\nrulings), presented system design and applied methodology, the paper also\ndiscusses achieved performance metrics and their implications for objective\nassessment of the proposed solution. Performed cross-validation tests on the\ncreated manually labeled dataset with mean $F_1$ score of 0.96 and additional\nresults on the examples of intentionally modified text inputs confirm\napplicability of the proposed system design and robustness of the developed NER\nsolution."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-334",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13997",
    "b_title":[
      "SigStyle: Signature Style Transfer via Personalized Text-to-Image Models"
    ],
    "b_abstract":[
      "Style transfer enables the seamless integration of artistic styles from a\nstyle image into a content image, resulting in visually striking and\naesthetically enriched outputs. Despite numerous advances in this field,\nexisting methods did not explicitly focus on the signature style, which\nrepresents the distinct and recognizable visual traits of the image such as\ngeometric and structural patterns, color palettes and brush strokes etc. In\nthis paper, we introduce SigStyle, a framework that leverages the semantic\npriors that embedded in a personalized text-to-image diffusion model to capture\nthe signature style representation. This style capture process is powered by a\nhypernetwork that efficiently fine-tunes the diffusion model for any given\nsingle style image. Style transfer then is conceptualized as the reconstruction\nprocess of content image through learned style tokens from the personalized\ndiffusion model. Additionally, to ensure the content consistency throughout the\nstyle transfer process, we introduce a time-aware attention swapping technique\nthat incorporates content information from the original image into the early\ndenoising steps of target image generation. Beyond enabling high-quality\nsignature style transfer across a wide range of styles, SigStyle supports\nmultiple interesting applications, such as local style transfer, texture\ntransfer, style fusion and style-guided text-to-image generation. Quantitative\nand qualitative evaluations demonstrate our approach outperforms existing style\ntransfer methods for recognizing and transferring the signature styles."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03221",
    "c_title":[
      "Lorentz contraction of electric field lines for a point charge in\n  uniform motion"
    ],
    "c_abstract":[
      "We examine a logical foundation of depicting a Lorentz contraction of a\nCoulomb field (an electric field of a point charge in uniform motion) by means\nof the 'Lorentz contracted' field lines. Two existing arguments for a\ncontraction of field lines sound appealing and lead to very simple calculations\nyielding the correct results. However, one of them is a victim to subtle\nlogical weaknesses, as it relies on ascribing a degree of physical reality to\nthe electric field lines. The other one correctly proves what it sets out to\nprove. But it does not provide a proof, or even a suggestion, of an additional\nresult that can be obtained by a new poof that we present here. Though our idea\nis very simple, the calculations used to prove it - based on a little known,\nhalf a century old result by Tsien - are somewhat more involved than those from\npast arguments."
    ],
    "c_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-335",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17715",
    "b_title":[
      "Bridging Information Gaps with Comprehensive Answers: Improving the\n  Diversity and Informativeness of Follow-Up Questions"
    ],
    "b_abstract":[
      "Effective conversational systems are expected to dynamically generate\ncontextual follow-up questions to elicit new information while maintaining the\nconversation flow. While humans excel at asking diverse and informative\nquestions by intuitively assessing both obtained and missing information,\nexisting models often fall short of human performance on this task. To mitigate\nthis, we propose a method that generates diverse and informative questions\nbased on targeting unanswered information using a hypothetical LLM-generated\n\"comprehensive answer\". Our method is applied to augment an existing follow-up\nquestions dataset. The experimental results demonstrate that language models\nfine-tuned on the augmented datasets produce follow-up questions of\nsignificantly higher quality and diversity. This promising approach could be\neffectively adopted to future work to augment information-seeking dialogues for\nreducing ambiguities and improving the accuracy of LLM answers."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15052",
    "c_title":[
      "Explicit modularity of K3 surfaces with complex multiplication of large\n  degree"
    ],
    "c_abstract":[
      "We consider the transcendental motive of three K3 surfaces $X$ conjectured to\nhave complex multiplication (CM). Under this assumption, we match these to\nexplicit algebraic Hecke quasi-characters $\\psi_X$, and CM abelian threefolds\n$A$. This provides substantial evidence that a power of $A$ corresponds to $X$\nunder the Kuga-Satake correspondence."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-336",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09485",
    "b_title":[
      "Flow approach on the monotonicity of shape functionals"
    ],
    "b_abstract":[
      "We develop a geometric flow framework to investigate the following two\nclassical shape functionals: the torsional rigidity and the first Dirichlet\neigenvalue of the Laplacian. First, by constructing novel deformation paths\ngoverned by stretching flows, we prove several new monotonicity properties of\nthe torsional rigidity and the first eigenvalue along the evolutions restricted\nto triangles and rhombuses. These results also lead to new and simpler proofs\nof some known results, unifying and extending prior symmetrization-based\nproofs. Second, utilizing the mean curvature flow, we give a new proof of the\nSaint-Venant inequality for smooth convex bodies. This might represent the\nfirst flow-based proof to establish geometric functional inequalities that\ncouple both the domain and the state function associated with it. Third, by\ndiscovering a gradient norm inequality for the sides of rectangles, we prove\nmonotonicity and stronger rigidity results of the torsional rigidity on\nrectangles."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16811",
    "c_title":[
      "Not Every Patch is Needed: Towards a More Efficient and Effective\n  Backbone for Video-based Person Re-identification"
    ],
    "c_abstract":[
      "This paper proposes a new effective and efficient plug-and-play backbone for\nvideo-based person re-identification (ReID). Conventional video-based ReID\nmethods typically use CNN or transformer backbones to extract deep features for\nevery position in every sampled video frame. Here, we argue that this\nexhaustive feature extraction could be unnecessary, since we find that\ndifferent frames in a ReID video often exhibit small differences and contain\nmany similar regions due to the relatively slight movements of human beings.\nInspired by this, a more selective, efficient paradigm is explored in this\npaper. Specifically, we introduce a patch selection mechanism to reduce\ncomputational cost by choosing only the crucial and non-repetitive patches for\nfeature extraction. Additionally, we present a novel network structure that\ngenerates and utilizes pseudo frame global context to address the issue of\nincomplete views resulting from sparse inputs. By incorporating these new\ndesigns, our backbone can achieve both high performance and low computational\ncost. Extensive experiments on multiple datasets show that our approach reduces\nthe computational cost by 74\\% compared to ViT-B and 28\\% compared to ResNet50,\nwhile the accuracy is on par with ViT-B and outperforms ResNet50 significantly."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-337",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18261",
    "b_title":[
      "The effect of minimum wages on employment in the presence of\n  productivity fluctuations"
    ],
    "b_abstract":[
      "Traditionally, the impact of minimum wages on employment has been studied,\nand it is generally believed to have a negative effect. Yet, some recent\nstudies have shown that the impact of minimum wages on employment can sometimes\nbe positive. In addition, certain recent proposals set a higher minimum wage\nthan the wage earned by some high-productivity workers. However, the impact of\nminimum wages on employment has been primarily studied on low-skilled workers,\nwhereas there is limited research on high-skilled workers. To address this gap\nand examine the effects of minimum wages on high-productivity workers'\nemployment, I construct a macroeconomic model incorporating productivity\nfluctuations, incomplete markets, directed search, and on-the-job search and\ncompare the steady-state distributions between the baseline model and the model\nwith a minimum wage. As a result, binding minimum wages increase the\nunemployment rate of both low and high-productivity workers."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.10617",
    "c_title":[
      "Mutual Regression Distance"
    ],
    "c_abstract":[
      "The maximum mean discrepancy and Wasserstein distance are popular distance\nmeasures between distributions and play important roles in many machine\nlearning problems such as metric learning, generative modeling, domain\nadaption, and clustering. However, since they are functions of pair-wise\ndistances between data points in two distributions, they do not exploit the\npotential manifold properties of data such as smoothness and hence are not\neffective in measuring the dissimilarity between the two distributions in the\nform of manifolds. In this paper, different from existing measures, we propose\na novel distance called Mutual Regression Distance (MRD) induced by a\nconstrained mutual regression problem, which can exploit the manifold property\nof data. We prove that MRD is a pseudometric that satisfies almost all the\naxioms of a metric. Since the optimization of the original MRD is costly, we\nprovide a tight MRD and a simplified MRD, based on which a heuristic algorithm\nis established. We also provide kernel variants of MRDs that are more effective\nin handling nonlinear data. Our MRDs especially the simplified MRDs have much\nlower computational complexity than the Wasserstein distance. We provide\ntheoretical guarantees, such as robustness, for MRDs. Finally, we apply MRDs to\ndistribution clustering, generative models, and domain adaptation. The\nnumerical results demonstrate the effectiveness and superiority of MRDs\ncompared to the baselines."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-338",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18043",
    "b_title":[
      "Microscopic study of halo nuclei through (p,t) reactions"
    ],
    "b_abstract":[
      "We analyze (p,t) two-neutron transfer reactions in a semi-microscopic model.\nThe overlap integrals of the target nucleus are calculated in a microscopic\ncluster model. The Resonating Group Method (RGM) assumes a cluster structure of\nthe nucleus, and is well adapted to halo nuclei since the long-range part of\nthe wave function is accurately described. We focus on (p,t) reactions\ninvolving 6He and 11Li, which are well known core+n+n halo nuclei. The RGM is\nbased on a nucleon-nucleon interaction, and therefore does not involve any\nfitting procedure. It also provides overlap integrals of excited states of the\ncore nucleus. We present overlap integrals and spectroscopic factors of 6He and\n11Li. We compute the 6He(p,t)alpha and 11Li(p,t)9Li cross sections at the DWBA,\nand compare them with experiments. For 11Li we also determine the 11Li(p,t)9Li*\ncross section which involves the first excited states of 9Li. A fair agreement\nwith experiment is obtained, considering that no parameter is adjusted."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00300",
    "c_title":[
      "Cauchy Random Features for Operator Learning in Sobolev Space"
    ],
    "c_abstract":[
      "Operator learning is the approximation of operators between infinite\ndimensional Banach spaces using machine learning approaches. While most\nprogress in this area has been driven by variants of deep neural networks such\nas the Deep Operator Network and Fourier Neural Operator, the theoretical\nguarantees are often in the form of a universal approximation property.\nHowever, the existence theorems do not guarantee that an accurate operator\nnetwork is obtainable in practice. Motivated by the recent kernel-based\noperator learning framework, we propose a random feature operator learning\nmethod with theoretical guarantees and error bounds. The random feature method\ncan be viewed as a randomized approximation of a kernel method, which\nsignificantly reduces the computation requirements for training. We provide a\ngeneralization error analysis for our proposed random feature operator learning\nmethod along with comprehensive numerical results. Compared to kernel-based\nmethod and neural network methods, the proposed method can obtain similar or\nbetter test errors across benchmarks examples with significantly reduced\ntraining times. An additional advantages it that our implementation is simple\nand does require costly computational resources, such as GPU."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-339",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04199",
    "b_title":[
      "MASTER: Multimodal Segmentation with Text Prompts"
    ],
    "b_abstract":[
      "RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00362",
    "c_title":[
      "Harnessing Hybrid Frequency-Entangled Qudits through Quantum\n  Interference"
    ],
    "c_abstract":[
      "High-dimensional (HD) quantum entanglement expands the Hilbert space,\noffering a robust framework for quantum information processing with enhanced\ncapacity and error resilience. In this work, we present a novel HD\nfrequency-domain entangled state, the hybrid frequency-entangled qudit (HFEQ),\ngenerated via Hong-Ou-Mandel (HOM) interference, exhibiting both\ndiscrete-variable (DV) and continuous-variable (CV) characteristics. By tuning\nHOM interference, we generate and control HFEQs with dimensions $D=5,7,9,11$,\nconfirming their DV nature. Franson interferometry confirms the global\nfrequency correlations with visibility exceeding 98% and verifies the CV\nentanglement within individual frequency modes with visibility greater than\n95%. Our findings provide deeper insight into the physical nature of\nfrequency-entangled qudits generated by quantum interference and introduce a\nnovel resource for HD time-frequency quantum information processing."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-340",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05505",
    "b_title":[
      "Towards a Non-singular Paradigm of Black Hole Physics"
    ],
    "b_abstract":[
      "The study of regular black holes and black hole mimickers as alternatives to\nstandard black holes has recently gained significant attention, driven both by\nthe need to extend general relativity to describe black hole interiors, and by\nrecent advances in observational technologies. Despite considerable progress in\nthis field, significant challenges remain in identifying and characterizing\nphysically well-motivated classes of regular black holes and black hole\nmimickers. This report provides an overview of these challenges, and outlines\nsome of the promising research directions -- as discussed during a week-long\nfocus programme held at the Institute for Fundamental Physics of the Universe\n(IFPU) in Trieste from November 11th to 15th, 2024."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16972",
    "c_title":[
      "TraFlow: Trajectory Distillation on Pre-Trained Rectified Flow"
    ],
    "c_abstract":[
      "Majorities of distillation methods on pre-trained diffusion models or on\npre-trained rectified flow, focus on either the distillation outputs or the\ntrajectories between random noises and clean images to speed up sample\ngenerations from pre-trained models. In those trajectory-based distillation\nmethods, consistency distillation requires the self-consistent trajectory\nprojection to regulate the trajectory, which might avoid the common ODE\napproximation error {while still be concerning about sampling efficiencies}. At\nthe same time, rectified flow distillations enforce straight trajectory for\nfast sampling, although an ODE solver is still required. In this work, we\npropose a trajectory distillation method, \\modelname, that enjoys the benefits\nof both and enables few-step generations. TraFlow adopts the settings of\nconsistency trajectory models, and further enforces the properties of\nself-consistency and straightness throughout the entire trajectory. These two\nproperties are pursued by reaching a balance with following three targets: (1)\nreconstruct the output from pre-trained models; (2) learn the amount of changes\nby pre-trained models; (3) satisfy the self-consistency over its trajectory.\nExtensive experimental results have shown the effectiveness of our proposed\nmethod."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-341",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05392",
    "b_title":[
      "Equilibrium and nonequilibrium steady states with the repeated\n  interaction protocol: Relaxation dynamics and energetic cost"
    ],
    "b_abstract":[
      "We study the dynamics of a qubit system interacting with thermalized\nbath-ancilla spins via a repeated interaction scheme. Considering generic\ninitial conditions for the system and employing a Heisenberg-type interaction\nbetween the system and the ancillas, we analytically prove the following: (i)\nThe population and coherences of the system qubit evolve independently toward a\nnonequilibrium steady-state solution, which is diagonal in the qubit's energy\neigenbasis. The population relaxes to this state geometrically, whereas the\ncoherences decay through a more compound behavior. (ii) In the long time limit,\nthe system approaches a steady state that generally differs from the thermal\nstate of the ancilla. We derive this steady-state solution and show its\ndependence on the interaction parameters and collision frequency. (iii) We\nbound the number of interaction steps required to achieve the steady state\nwithin a specified error tolerance, and we evaluate the energetic cost\nassociated with the process. Our key finding is that deterministic\nsystem-ancilla interactions do not typically result in the system thermalizing\nto the thermal state of the ancilla. Instead, they generate a distinct\nnonequilibrium steady state, which we explicitly derive. However, we also\nidentify an operational regime that leads to thermalization with a few long and\npossibly randomized collisions."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2501.02868",
    "c_title":[
      "The importance of shear on the collective charge transport in CDWs\n  revealed by an XFEL source"
    ],
    "c_abstract":[
      "Charge transport in materials has an impact on a wide range of devices based\non semiconductor, battery or superconductor technology. Charge transport in\nsliding Charge Density Waves (CDW) differs from all others in that the atomic\nlattice is directly involved in the transport process. To obtain an overall\npicture of the structural changes associated to the collective transport, the\nlarge coherent X-ray beam generated by an X-ray free-electron laser (XFEL)\nsource was used. The CDW phase can be retrieved over the entire sample from\ndiffracted intensities using a genetic algorithm. For currents below threshold,\nincreasing shear deformation is observed in the central part of the sample\nwhile longitudinal deformation appears above threshold when shear relaxes.\nShear thus precedes longitudinal deformation, with relaxation of one leading to\nthe appearance of the other. Moreover, strain accumulates on surface steps in\nthe sliding regime, demonstrating the strong pinning character of these surface\ndiscontinuities. The sliding process of nanometric CDW is based on an\nimpressive spatial coherence involving the macroscopic sample dimensions."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-342",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03348",
    "b_title":[
      "Composite Nonlinear Trajectory Tracking Control of Co-Driving Vehicles\n  Using Self-Triggered Adaptive Dynamic Programming"
    ],
    "b_abstract":[
      "This article presents a composite nonlinear feedback (CNF) control method\nusing self-triggered (ST) adaptive dynamic programming (ADP) algorithm in a\nhuman-machine shared steering framework. For the overall system dynamics, a\ntwo-degrees-of-freedom (2-DOF) vehicle model is established and a two-point\npreview driver model is adopted. A dynamic authority allocation strategy based\non cooperation level is proposed to combine the steering input of the human\ndriver and the automatic controller. To make further improvements in the\ncontroller design, three main contributions are put forward. Firstly, the CNF\ncontroller is designed for trajectory tracking control with refined transient\nperformance. Besides, the self-triggered rule is applied such that the system\nwill update in discrete times to save computing resources and increase\nefficiency. Moreover, by introducing the data-based ADP algorithm, the optimal\ncontrol problem can be solved through iteration using system input and output\ninformation, reducing the need for accurate knowledge of system dynamics. The\neffectiveness of the proposed control method is validated through\nCarsim-Simulink co-simulations in diverse driving scenarios."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04119",
    "c_title":[
      "The Preparation Status and Plan for the Next Physics Run of the NINJA\n  Experiment"
    ],
    "c_abstract":[
      "The NINJA experiment aims to precisely measure neutrino-nucleus interactions\nusing a nuclear emulsion detector to reduce systematic errors in neutrino\noscillation experiments. The nuclear emulsion has a sub-micron positional\nresolution, enabling the detection of low-momentum charged particles such as\nprotons with a threshold of 200 MeV\/c. In the NINJA experiment, a muon detector\nplaced downstream of the emulsion detector is used to identify muons from\n$\\nu_{\\mu}$ charged-current interactions. The majority of the tracks\naccumulated in the nuclear emulsion are from cosmic rays. Although the emulsion\ndetector provides highly accurate positional information, it lacks timing\ninformation. Therefore, the positional resolution of the muon detector is not\nenough to identify neutrino interaction tracks that match between the muon\ndetector and the emulsion detector from the enormous background of cosmic rays\nrecorded in the emulsion detector. To address this, a scintillation tracker is\nused to provide both timing and positional information for the tracks.\n  The NINJA experiment is planning a third physics run with about 130 kg water\ntarget from the autumn of 2025 to the spring of 2026. Since the target mass is\nlarger than previous runs, a larger scintillation tracker covering 1.3 m\n$\\times$ 1.4 m is needed. We are developing a newly designed scintillation\ntracker, consisting of a monolithic plastic scintillator plane including\nscatterers.\n  In this paper, we will show the preparation status and plan for the next\nphysics run, focusing particularly on the development of the new scintillation\ntracker."
    ],
    "c_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-343",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19226",
    "b_title":[
      "What is Connectivity?"
    ],
    "b_abstract":[
      "In this paper, we explore a taxonomy of connectivity for space-like\nstructures. It is inspired by isolating posets of connected pieces of a space\nand examining its embedding in the ambient space. The taxonomy includes in its\nscope all standard notions of connectivity in point-set and point-free\ncontexts, such as connectivity in graphs and hypergraphs (as well as\nk-connectivity in graphs), connectivity and path-connectivity in topology, and\nconnectivity of elements in a frame."
    ],
    "b_categories":[
      [
        "math.CT",
        "math.GN",
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15289",
    "c_title":[
      "Sol-gel transition in heteroassociative RNA-protein solutions: A\n  quantitative comparison of coarse-grained simulations and the\n  Semenov-Rubinstein theory"
    ],
    "c_abstract":[
      "Protein RNA-binding domains selectively interact with specific RNA sites, a\nkey interaction that determines the emergent cooperative behaviors in\nRNA-protein mixtures. Through molecular dynamics simulations, we investigate\nthe impact of the specific binding interactions on the phase transitions of an\nexamplary RNA-protein system and compare it with predictions of the\nSemenov-Rubinstein theory of associative polymers. Our findings reveal a\nsol-gel (percolation) transition without phase separation, characterized by\ndouble reentrant behavior as the RNA or protein concentration increases. We\nhighlight the crucial role of bridge formations in driving these transitions,\nparticularly when binding sites are saturated. The theory quantitatively\npredicts the binding numbers at equilibrium in the semidilute regime, but it\nsignificantly overestimates the size of the concentration range where\npercolation is observed. This can partly be traced back to the fact that the\nmean-field assumption in the theory is not valid in the dilute regime, and that\nthe theory neglects the existence of cycles in the connectivity graph of the\npercolating cluster at the sol-gel transition. Our study enriches the\nunderstanding of RNA-protein phase behaviors, providing valuable insights for\nthe interpretation of experimental observations."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-344",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02204",
    "b_title":[
      "Backcasting Policies in Transport Systems as an Optimal Control Problem\n  : An Example with Electric Vehicle Purchase Incentives"
    ],
    "b_abstract":[
      "This study represents a first attempt to build a backcasting methodology to\nidentify the optimal policy roadmaps in transport systems. Specifically, it\nconsiders a passenger car fleet subsystem, modelling its evolution and\ngreenhouse gas emissions. The policy decision under consideration is the\nmonetary incentive to the purchase of electric vehicles. This process is cast\nas an optimal control problem with the objective to minimize the total budget\nof the state and reach a desired CO$_2$ target. A case study applied to\nMetropolitan France is presented to illustrate the approach. Additionally,\nalternative policy scenarios are also analyzed."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07535",
    "c_title":[
      "Non-Interchangeability between Heart Rate Variability and Pulse Rate\n  Variability During Supine-to-Stand Tests"
    ],
    "c_abstract":[
      "Heart rate variability (HRV) is widely recognized as a valuable biomarker for\nassessing autonomic cardiac regulation. Pulse rate variability (PRV) is a\ncommon surrogate of HRV given the wide usability of PPG in commercially\navailable devices. However, there is no clear conclusion on whether PRV can\nreplace HRV given their different physiological mechanisms. This study\nevaluates the interchangeability of young adults HRV and PRV during\nsupine-to-stand (STS) tests which are known as common posture transitions in\ndaily life monitoring. Fifteen features from time, frequency and nonlinear\ndomains were extracted from both electrocardiography and PPG signals. Paired\nt-tests and Wilcoxon signed-rank tests examined the difference between the\nextracted HRV and PRV features during supine, transition and standing phases\nseparately. One feature showed significant difference in the supine phase, and\nthis discrepancy increased to four in the transition and standing phases. These\nfindings suggested that PRV is different from HRV in the STS tests, despite the\nfact that both metrics can reflect the sympathetic activation triggered by the\nposture changes."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-345",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01312",
    "b_title":[
      "CleanPose: Category-Level Object Pose Estimation via Causal Learning and\n  Knowledge Distillation"
    ],
    "b_abstract":[
      "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be released."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03143",
    "c_title":[
      "Quantum Geometric Engineering of Dual Hall Effects in 2D\n  Antiferromagnetic Bilayers via Interlayer Magnetic Coupling"
    ],
    "c_abstract":[
      "The interplay between quantum geometry and magnetic order offers a novel\nstrategy for designing next-generation nanodevices. Here, we demonstrate that\ninterlayer magnetic coupling in two-dimensional (2D) CoPSe3 bilayers enables\nprecise control over quantum geometric mechanisms, unlocking dual intrinsic\nHall effects. Our first-principles calculations reveal that the altermagnetic\n(AM) phase exhibits a giant anisotropic anomalous Hall effect (AHE)\n($\\sigma_{xy}$ is approximately 46 S\/cm) driven by Berry curvature localized at\ngeneric k-points, while the PT-symmetric antiferromagnetic (AFM) phase hosts an\nintrinsic second-order nonlinear anomalous Hall effect (NAHE) ($\\chi_{xyy}$ is\napproximately 160 ${\\mu}$S\/V) originating from quantum metric accumulation at\nhigh-symmetry k-points. By tuning interlayer magnetic couplings, we achieve\nreversible switching between these phases, leveraging their distinct band\nstructures and symmetry constraints. The Neel-vector-dependent AHE in the AM\nphase and the symmetry-protected NAHE in the AFM phase highlight quantum\ngeometry as a versatile tool for manipulating transport properties. Our work\nestablishes 2D antiferromagnets as a promising platform for multifunctional\ndevice architectures, bridging linear and nonlinear magnetoelectric responses\nthrough tailored quantum geometric engineering."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-346",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02768",
    "b_title":[
      "Denotational Semantics for Probabilistic and Concurrent Programs"
    ],
    "b_abstract":[
      "We develop a denotational model for programs that have standard programming\nconstructs such as conditionals and while-loops, as well as probabilistic and\nconcurrent commands. Whereas semantic models for languages with either\nconcurrency or randomization are well studied, their combination is limited to\nlanguages with bounded loops. Our work is the first to consider both\nrandomization and concurrency for a language with unbounded looping constructs.\nThe interaction between Boolean tests (arising from the control flow\nstructures), probabilistic actions, and concurrent execution creates challenges\nin generalizing previous work on pomsets and convex languages, prominent models\nfor those effects, individually. To illustrate the generality of our model, we\nshow that it recovers a typical powerdomain semantics for concurrency, as well\nas the convex powerset semantics for probabilistic nondeterminism."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07687",
    "c_title":[
      "The PLATO field selection process. II. Characterization of LOPS2, the\n  first long-pointing field"
    ],
    "c_abstract":[
      "PLAnetary Transits and Oscillations of stars (PLATO) is an ESA M-class\nmission to be launched by the end of 2026 to discover and characterize\ntransiting planets around bright and nearby stars, and in particular habitable\nrocky planets hosted by solar-like stars. Over the mission lifetime, an average\nof 8% of the science data rate will be allocated to Guest Observer programs\n(GOs) selected by ESA through public calls, hence it is essential for the\ncommunity to know in advance where the observing fields will be located. In a\nprevious paper, we identified two preliminary long-pointing fields (LOPN1 and\nLOPS1) for PLATO, respectively in the northern and southern hemisphere. Here we\npresent LOPS2, a slightly adjusted version of the southern field that has\nrecently been selected by the PLATO Science Working Team as the first field to\nbe observed by PLATO for at least two continuous years, following the\nscientific requirements. In this paper, we describe the astrophysical content\nof LOPS2 in detail, including known planetary systems, bright\/variable\/binary\nstars, clusters and synergies with other current and future facilities."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-347",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12885",
    "b_title":[
      "DreamRenderer: Taming Multi-Instance Attribute Control in Large-Scale\n  Text-to-Image Models"
    ],
    "b_abstract":[
      "Image-conditioned generation methods, such as depth- and canny-conditioned\napproaches, have demonstrated remarkable abilities for precise image synthesis.\nHowever, existing models still struggle to accurately control the content of\nmultiple instances (or regions). Even state-of-the-art models like FLUX and\n3DIS face challenges, such as attribute leakage between instances, which limits\nuser control. To address these issues, we introduce DreamRenderer, a\ntraining-free approach built upon the FLUX model. DreamRenderer enables users\nto control the content of each instance via bounding boxes or masks, while\nensuring overall visual harmony. We propose two key innovations: 1) Bridge\nImage Tokens for Hard Text Attribute Binding, which uses replicated image\ntokens as bridge tokens to ensure that T5 text embeddings, pre-trained solely\non text data, bind the correct visual attributes for each instance during Joint\nAttention; 2) Hard Image Attribute Binding applied only to vital layers.\nThrough our analysis of FLUX, we identify the critical layers responsible for\ninstance attribute rendering and apply Hard Image Attribute Binding only in\nthese layers, using soft binding in the others. This approach ensures precise\ncontrol while preserving image quality. Evaluations on the COCO-POS and\nCOCO-MIG benchmarks demonstrate that DreamRenderer improves the Image Success\nRatio by 17.7% over FLUX and enhances the performance of layout-to-image models\nlike GLIGEN and 3DIS by up to 26.8%. Project Page:\nhttps:\/\/limuloo.github.io\/DreamRenderer\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17984",
    "c_title":[
      "Generalized Decision Focused Learning under Imprecise\n  Uncertainty--Theoretical Study"
    ],
    "c_abstract":[
      "Decision Focused Learning has emerged as a critical paradigm for integrating\nmachine learning with downstream optimisation. Despite its promise, existing\nmethodologies predominantly rely on probabilistic models and focus narrowly on\ntask objectives, overlooking the nuanced challenges posed by epistemic\nuncertainty, non-probabilistic modelling approaches, and the integration of\nuncertainty into optimisation constraints. This paper bridges these gaps by\nintroducing innovative frameworks: (i) a non-probabilistic lens for epistemic\nuncertainty representation, leveraging intervals (the least informative\nuncertainty model), Contamination (hybrid model), and probability boxes (the\nmost informative uncertainty model); (ii) methodologies to incorporate\nuncertainty into constraints, expanding Decision-Focused Learning's utility in\nconstrained environments; (iii) the adoption of Imprecise Decision Theory for\nambiguity-rich decision-making contexts; and (iv) strategies for addressing\nsparse data challenges. Empirical evaluations on benchmark optimisation\nproblems demonstrate the efficacy of these approaches in improving decision\nquality and robustness and dealing with said gaps."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-348",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15239",
    "b_title":[
      "RFSoC-based radio-frequency reflectometry in gate-defined bilayer\n  graphene quantum devices"
    ],
    "b_abstract":[
      "Quantum computers require both scalability and high performance for practical\napplications. While semiconductor quantum dots are promising candidates for\nquantum bits, the complexity of measurement setups poses an important challenge\nfor scaling up these devices. Here, radio-frequency system-on-chip (RFSoC)\ntechnology is exepcted for a promising approach that combines scalability with\nflexibility. In this paper, we demonstrate RF reflectometry in gate-defined\nbilayer graphene quantum devices using RFSoC-based measurement architecture. By\ncontrolling the confinement strength through gate voltages, we achieve both\nFabry-P\\'erot interferometer and quantum dot operations in a single device.\nAlthough impedance matching conditions currently limit the measurement\nsensitivity, we identify pathways for optimization through tunnel barrier\nengineering and resonator design. These results represent a step toward\nintegrating high-bandwidth measurements with scalable quantum devices."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05380",
    "c_title":[
      "Optimal Scheduling in a Quantum Switch"
    ],
    "c_abstract":[
      "With a growing number of quantum networks in operation, there is a pressing\nneed for performance analysis of quantum switching technologies. A quantum\nswitch establishes, distributes, and maintains entanglements across a network.\nIn contrast to a classical switching fabric, a quantum switch is a two sided\nqueueing network. The switch generates Link Level Entanglements (LLEs), which\nare then fused to process the networks entanglement requests. Our proof\ntechniques analyse a two time scale separation phenomenon at the fluid scale\nfor a general switch topology. This allows us to demonstrate that the optimal\nfluid dynamics are given by a scheduling algorithm that solves a certain\naverage reward Markov Decision Process."
    ],
    "c_categories":[
      [
        "cs.NI",
        "cs.PF",
        "math.PR",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-349",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17779",
    "b_title":[
      "Gradient structures from extensions of over-extended Kac-Moody algebras"
    ],
    "b_abstract":[
      "Over-extended Kac-Moody algebras contain so-called gradient structures - a\ngl(d)-covariant level decomposition of the algebra contains strings of modules\nat different levels that can be interpreted as spatial gradients. We present an\nalgebraic origin for this phenomenon, based on the recently introduced Lie\nalgebra extension of an over-extended Kac-Moody algebra by its fundamental\nmodule, appearing in tensor hierarchy algebra super-extensions of over-extended\nKac-Moody algebras. The extensions are described in terms of Lie algebra\ncohomology, vanishing for finite-dimensional simple Lie algebras, but\nnon-vanishing in relevant infinite-dimensional cases. The extension is\ndescribed in a few different gradings, where it is given a covariant\ndescription with respect to different subalgebras. We expect the results to be\nimportant for the connection between extended geometry and cosmological\nbilliards."
    ],
    "b_categories":[
      [
        "hep-th",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14014",
    "c_title":[
      "SegRet: An Efficient Design for Semantic Segmentation with Retentive\n  Network"
    ],
    "c_abstract":[
      "With the ongoing advancement of autonomous driving technology and intelligent\ntransportation systems, research into semantic segmentation has become\nincreasingly pivotal. Accurate understanding and analysis of real-world\nscenarios are now essential for these emerging fields. However, traditional\nsemantic segmentation methods often struggle to balance high model accuracy\nwith computational efficiency, particularly in terms of parameter count. To\naddress this challenge, we introduce SegRet, a novel approach that leverages\nthe Retentive Network (RetNet) architecture and integrates a lightweight\nresidual decoder featuring zero-initialization. SegRet exhibits three key\ncharacteristics: (1) Lightweight Residual Decoder: We incorporate a\nzero-initialization layer within the residual network framework, ensuring that\nthe decoder remains computationally efficient while preserving critical\ninformation flow; (2) Robust Feature Extraction: Utilizing RetNet as the\nbackbone, our model adeptly extracts hierarchical features from input images,\nthereby enhancing the depth and breadth of feature representation; (3)\nParameter Efficiency: SegRet achieves state-of-the-art performance while\nsignificantly reducing the number of parameters, maintaining high accuracy\nwithout compromising on computational resources. Empirical evaluations on\nbenchmark datasets such as ADE20K, Cityscapes, and COCO-Stuff10K demonstrate\nthe efficacy of our approach. SegRet delivers impressive results, achieving an\nmIoU of 52.23\\% on ADE20K with only 95.81M parameters, 83.36\\% on Cityscapes,\nand 46.63\\% on COCO-Stuff. The code is available at:\nhttps:\/\/github.com\/ZhiyuanLi218\/segret."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-350",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07211",
    "b_title":[
      "Weak-coupling bound states in semi-infinite topological waveguide QED"
    ],
    "b_abstract":[
      "A striking feature of cavity quantum electrodynamics is the existence of\natom-photon bound states, which typically form when the coupling between the\natom and its environment are strong enough that after de-excitation the atom\ncan ``grab'' an emitted photon and re-absorb it, resulting in a virtual cloud\nsurrounding the atom. Here we will demonstrate the existence of bound states\nthat instead form in the case of weak coupling. Specifically, we show that when\na quantum emitter is weakly coupled to a structured reservoir exhibiting\ntopologically-protected surface states, hybridizations between these states and\nthe emitter can form, resulting in mid-gap bound states. We illustrate this\nusing a semi-infinite extension of the Su-Schrieffer-Heeger (SSH) model as our\nreservoir. First, we diagonalize the bare semi-infinite SSH chain and reveal a\nwinding number that predicts only the edge state on the finite side of the\nchain survives the semi-infinite extension. Then, after coupling the quantum\nemitter to this end of the chain, we analyze the modified emitter spectrum and\nreveal the existence of bound states in three parameter regions. Two of these\nrepresent the usual strong-coupling bound states, while the third gives the\nweak-coupling bound states with eigenvalue appearing in the SSH band gap and\nwhich exhibit partial sublattice localization. We demonstrate that oscillations\nbetween the weak-coupling bound states can be used to transfer the particle\nfrom the emitter into the lattice in a predictable and reversible manner."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2501.08734",
    "c_title":[
      "Background reduction in $^{136}$Xe double beta decay experiments through\n  direct barium ion detection"
    ],
    "c_abstract":[
      "Tagging barium ions in double beta decay experiments involving $^{136}$Xe\noffers a promising pathway to achieving an almost background-free environment,\nwhich is essential for addressing key unresolved questions in neutrino physics,\nsuch as the nature of neutrinos and their mass hierarchy. In this manuscript,\nwe present a novel detection scheme that relies exclusively on the intrinsic\nenergy levels of the barium ion. This method eliminates the need for additional\nadditives in the xenon vessel, thereby simplifying the experimental setup and\nenhancing the potential sensitivity of the experiment."
    ],
    "c_categories":[
      [
        "hep-ex",
        "nucl-ex",
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-351",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13207",
    "b_title":[
      "Beyond MESA Defaults: The Impact of Structural Resolution Uncertainty in\n  p-mode Asteroseismology"
    ],
    "b_abstract":[
      "Observations of pressure modes ($p$-modes) in stars have enabled profound\ninsights into stellar properties, and theoretical stellar evolution and\noscillation models are integral to these inferences. However, modeling\nuncertainties are often overlooked, even as they can rival or exceed\nobservational uncertainties. In this study, we quantify, for the first time,\nthe impact of structural resolution choices in 1D stellar evolution\ncalculations on predicted $p$-mode frequencies across the HR diagram, using\n\\texttt{MESA} and \\texttt{GYRE}. We present measurements of resolution-based\nmodeling uncertainty for a range of solar-like, upper main-sequence, and Mira\noscillators and compare these directly to TESS observational uncertainties. We\ndemonstrate that resolution-driven uncertainties can significantly influence\ntheoretical predictions and in some cases overwhelm observational uncertainties\nby orders of magnitude: while solar-like oscillators typically have fractional,\nresolution-based uncertainties at or below 1\\% of the test frequency,\nfractional uncertainties in Miras were as large as 20\\%. We also find that the\nlocation and morphology of the RGB bump and red clump are impacted\nsubstantially by resolution uncertainty. Stellar ages are impacted at the 10\\%\nlevel for young main-sequence stars, and the model-based correction factor for\nthe $\\Delta\\nu$--$\\sqrt{\\rho}$ scaling relation is impacted at the 2\\% level.\nOur results underscore the need to incorporate modeling uncertainties into\nasteroseismic analyses and provide a reference framework for observers\nevaluating the reliability of theoretical models."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16884",
    "c_title":[
      "Irony Detection, Reasoning and Understanding in Zero-shot Learning"
    ],
    "c_abstract":[
      "Irony is a powerful figurative language (FL) on social media that can\npotentially mislead various NLP tasks, such as recommendation systems,\nmisinformation checks, and sentiment analysis. Understanding the implicit\nmeaning of this kind of subtle language is essential to mitigate irony's\nnegative impact on NLP tasks. However, building models to understand irony\npresents a unique set of challenges, because irony is a complex form of\nlanguage that often relies on context, tone, and subtle cues to convey meaning\nthat is opposite or different from the literal interpretation. Large language\nmodels, such as ChatGPT, are increasingly able to capture implicit and\ncontextual information. In this study, we investigate the generalization,\nreasoning and understanding ability of ChatGPT on irony detection across six\ndifferent genre irony detection datasets. Our findings suggest that ChatGPT\nappears to show an enhanced language understanding and reasoning ability. But\nit needs to be very careful in prompt engineering design. Thus, we propose a\nprompt engineering design framework IDADP to achieve higher irony detection\naccuracy, improved understanding of irony, and more effective explanations\ncompared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain\nvia experiments that the practice generated under the framework is likely to be\nthe promised solution to resolve the generalization issues of LLMs."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-352",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15980",
    "b_title":[
      "Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data\n  Annotation"
    ],
    "b_abstract":[
      "Text-to-SQL models, which parse natural language (NL) questions to executable\nSQL queries, are increasingly adopted in real-world applications. However,\ndeploying such models in the real world often requires adapting them to the\nhighly specialized database schemas used in specific applications. We find that\nexisting text-to-SQL models experience significant performance drops when\napplied to new schemas, primarily due to the lack of domain-specific data for\nfine-tuning. This data scarcity also limits the ability to effectively evaluate\nmodel performance in new domains. Continuously obtaining high-quality\ntext-to-SQL data for evolving schemas is prohibitively expensive in real-world\nscenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop\ntext-to-SQL data annotation system. SQLsynth streamlines the creation of\nhigh-quality text-to-SQL datasets through human-LLM collaboration in a\nstructured workflow. A within-subjects user study comparing SQLsynth with\nmanual annotation and ChatGPT shows that SQLsynth significantly accelerates\ntext-to-SQL data annotation, reduces cognitive load, and produces datasets that\nare more accurate, natural, and diverse. Our code is available at\nhttps:\/\/github.com\/adobe\/nl_sql_analyzer."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.DB",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10610",
    "c_title":[
      "Searching for strong lensing by late-type galaxies in UNIONS"
    ],
    "c_abstract":[
      "Recent wide-field galaxy surveys have led to an explosion in numbers of\ngalaxy-scale strong gravitational lens candidates. However, the vast majority\nfeature massive luminous red galaxies as the main deflectors, with late-type\ngalaxies being vastly under-represented. This work presents a dedicated search\nfor lensing by edge-on late-type galaxies in the Ultraviolet Near Infrared\nOptical Northern Survey (UNIONS). The search covers $3600$ deg$^2$ of $r$-band\nobservations taken from the Canada-France-Hawaii Telescope. We consider all\nsources with magnitudes in the range $17 < r < 20.5$, without any colour\npreselection, yielding a parent sample of seven million sources. We\ncharacterise our parent sample via the visual inspection of $120\\,000$ sources\nselected at random. From it, we estimate, with a 68\\% confidence interval, that\n1 in every $30\\,000$ sources is an edge-on lens candidate, with at least eight\nhigh-quality candidates in the parent sample. This corresponds to 1 candidate\nper $17\\,000$ edge-on late-type galaxies. Our search relies on a convolutional\nneural network (CNN) to select a reduced sample of candidates, followed by a\nvisual inspection to curate the final sample. The CNN is trained from scratch\nusing simulated $r$-band observations of edge-on lenses, and real observations\nof non-lenses. We find 61 good edge-on lens candidates using the CNN. Moreover,\ncombining the CNN candidates with those found serendipitously, and those\nidentified while characterising the parent sample, we discovered 4 grade A, 20\ngrade B, and 58 grade C edge-on lens candidates; effectively doubling the known\nsample of these systems. We also discovered 16 grade A, 16 grade B, and 18\ngrade C lens candidates of other types. Finally, based on the characterisation\nof the parent sample, we estimate that our search found around 60\\% of the\nbright grade A and B edge-on lens candidates within the parent sample."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-353",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02503",
    "b_title":[
      "Near-Feasible Solutions to Complex Stable Matching Problems"
    ],
    "b_abstract":[
      "In this paper, we demonstrate that in many NP-complete variants of the stable\nmatching problem, such as the Stable Hypergraph Matching problem, the Stable\nMulticommodity Flow problem, and the College Admission problem with common\nquotas, a near-feasible stable solution - that is, a solution which is stable,\nbut may slightly violate some capacities - always exists. Our results provide\nstrong theoretical guarantees that even under complex constraints, stability\ncan be restored with minimal capacity modifications.\n  To achieve this, we present an iterative rounding algorithm that starts from\na stable fractional solution and systematically adjusts capacities to ensure\nthe existence of an integral stable solution. This approach leverages Scarf's\nalgorithm to compute an initial fractional stable solution, which serves as the\nfoundation for our rounding process. Notably, in the case of the Stable\nFixtures problem, where a stable fractional matching can be computed\nefficiently, our method runs in polynomial time.\n  These findings have significant practical implications for market design,\ncollege admissions, and other real-world allocation problems, where small\nadjustments to institutional constraints can guarantee stable and implementable\noutcomes."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05305",
    "c_title":[
      "Dynamics and Wong-Zakai approximations of stochastic nonlocal PDEs with\n  long time memory"
    ],
    "c_abstract":[
      "In this paper, a combination of Galerkin's method and Dafermos'\ntransformation is first used to prove the existence and uniqueness of solutions\nfor a class of stochastic nonlocal PDEs with long time memory driven by\nadditive noise. Next, the existence of tempered random attractors for such\nequations is established in an appropriate space for the analysis of problems\nwith delay and memory. Eventually, the convergence of solutions of Wong-Zakai\napproximations and upper semicontinuity of random attractors of the approximate\nrandom system, as the step sizes of approximations approach zero, are analyzed\nin a detailed way."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-354",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06117",
    "b_title":[
      "Revisiting Dynamic Graph Clustering via Matrix Factorization"
    ],
    "b_abstract":[
      "Dynamic graph clustering aims to detect and track time-varying clusters in\ndynamic graphs, revealing the evolutionary mechanisms of complex real-world\ndynamic systems. Matrix factorization-based methods are promising approaches\nfor this task; however, these methods often struggle with scalability and can\nbe time-consuming when applied to large-scale dynamic graphs. Moreover, they\ntend to lack robustness and are vulnerable to real-world noisy data. To address\nthese issues, we make three key contributions. First, to improve scalability,\nwe propose temporal separated matrix factorization, where a single matrix is\ndivided into multiple smaller matrices for independent factorization, resulting\nin faster computation. Second, to improve robustness, we introduce\nbi-clustering regularization, which jointly optimizes graph embedding and\nclustering, thereby filtering out noisy features from the graph embeddings.\nThird, to further enhance effectiveness and efficiency, we propose selective\nembedding updating, where we update only the embeddings of dynamic nodes while\nthe embeddings of static nodes are fixed among different timestamps.\nExperimental results on six synthetic and five real-world benchmarks\ndemonstrate the scalability, robustness and effectiveness of our proposed\nmethod. Source code is available at https:\/\/github.com\/Clearloveyuan\/DyG-MF."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10595",
    "c_title":[
      "Nonreciprocal Control of the Speed of Light Using Cavity Magnonics"
    ],
    "c_abstract":[
      "We demonstrate nonreciprocal control of the speed of light by sending a\nmicrowave pulse through a cavity magnonics device. In contrast to reciprocal\ngroup velocity controlled by conventional electromagnetically induced\ntransparency (EIT) effect, incorporating dissipative magnon-photon coupling\nestablishes a non-reciprocal EIT effect, allowing slow and fast light\npropagation in opposite directions at the same frequency with comparable\namplitude. Remarkably, reversing the magnetic field enables a directional\nswitch between non-reciprocal fast and slow light. This discovery may offer new\npossibilities for pulse time regulation in microwave signal communications,\nneuromorphic computing, and quantum signal processing."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-355",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11911",
    "b_title":[
      "Partial Topological Protection in C4 Lattices for Optical Communications"
    ],
    "b_abstract":[
      "In recent studies, analogs of the electronic Quantum Spin-Hall Effect have\nbeen explored within photonic crystals that incorporate spatial symmetries,\nespecially those with $ C_{6v} $ symmetry, where $ \\mathbb{Z}_2 $ topological\ninvariants are enforced by crystalline symmetry. These photonic crystals\npossess bulk states with well-defined pseudospins and exhibit helical edge\nstates, closely resembling their electronic counterparts. However, achieving\n$\\mathbb{Z}_2$ topological protection in a square lattice photonic crystal\nremains great theoretical and experimental challange. In this work, we propose\na single material photonic crystal structure based on a $ C_4 $ lattice that\nsupports partially $ \\mathbb{Z}_2 $-protected edge modes. We show that this\nstructure can host photonic band-gap that hosts $ \\mathbb{Z}_2 $-like modes,\nenabling perfect transmission in waveguide applications. Furthermore, we\ninvestigate the robustness of these modes against structural defects and\ndirectional turns, highlighting the distinctions between full $ \\mathbb{Z}_2 $\ntopological protection and partial topological protection. Finally, we analyze\nthe impact of the number of elementary cells surrounding the interface on the\nformation and stability of these protected modes."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15346",
    "c_title":[
      "Playing against a stationary opponent"
    ],
    "c_abstract":[
      "This paper investigates properties of Blackwell $\\epsilon$-optimal strategies\nin zero-sum stochastic games when the adversary is restricted to stationary\nstrategies, motivated by applications to robust Markov decision processes. For\na class of absorbing games, we show that Markovian Blackwell $\\epsilon$-optimal\nstrategies may fail to exist, yet we prove the existence of Blackwell\n$\\epsilon$-optimal strategies that can be implemented by a two-state automaton\nwhose internal transitions are independent of actions. For more general\nabsorbing games, however, there need not exist Blackwell $\\epsilon$-optimal\nstrategies that are independent of the adversary's decisions. Our findings\npoint to a contrast between absorbing games and generalized Big Match games,\nand provide new insights into the properties of optimal policies for robust\nMarkov decision processes."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-356",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08388",
    "b_title":[
      "The shadow and accretion disk images of the rotation loop quantum black\n  bounce"
    ],
    "b_abstract":[
      "In this paper, we study the shadow and observational image of the Kerr-like\nLoop Quantum Gravity (LQG) inspired black bounce with the help of the celestial\nlight source and the thin disk source by employing the backward ray-tracing\nmethod. The results indicate that both the LQG parameter alpha and the rotation\nparameter a contribute to a reduction in the shadow size; however, the\ninfluence of a is predominant, while the effect of alpha circular orbit. One\ncan find that the correlation parameter (a, alpha), along with the observer's\ninclination angle, affect the image's asymmetry and the distortion of the inner\nshadow. As the inclination increases, the direct and lensed images diverge,\ncreating a structure resembling a hat. Meanwhile, we also investigate the\nredshift distribution of the direct lensed images of the accretion disk under\ndifferent parameters and observation angle. The results show that the\ndistribution of redshift and observed intensity is obviously related to the\nbehavior of accretion flow. These results may provide a potential approach to\nlimit black hole parameters, detect quantum gravity effects, and distinguish\nthe LQG black hole from other black hole models."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03728",
    "c_title":[
      "Cohen--Macaulay ideals of codimension two and the geometry of plane\n  points"
    ],
    "c_abstract":[
      "We consider classes of codimension two Cohen--Macaulay ideals over a standard\ngraded polynomial ring over a field. We revisit Vasconcelos' problem on\n$3\\times 2$ matrices with homogeneous entries and describe the homological\ndetails of Geramita's work on plane points. An additional topic is the\nhomological discussion of minors fixing a submatrix in the context of a perfect\ncodimension two ideal. A combinatorial outcome of the results is a proof of the\nconjecture on the Jacobian ideal of a hyperplane arrangement stated by Burity,\nSimis and Toh\\v{a}neanu. The basic drive behind the present landscapes is a\nthorough analysis of the related Hilbert--Burch matrix, often without assuming\nequigeneration, linear presentation or even the popular $G_d$ condition of\nArtin--Nagata."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-357",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06822",
    "b_title":[
      "Model-based edge clustering for weighted networks with a noise component"
    ],
    "b_abstract":[
      "Clustering is a fundamental task in network analysis, essential for\nuncovering hidden structures within complex systems. Edge clustering, which\nfocuses on relationships between nodes rather than the nodes themselves, has\ngained increased attention in recent years. However, existing edge clustering\nalgorithms often overlook the significance of edge weights, which can represent\nthe strength or capacity of connections, and fail to account for noisy\nedges--connections that obscure the true structure of the network. To address\nthese challenges, the Weighted Edge Clustering Adjusting for Noise (WECAN)\nmodel is introduced. This novel algorithm integrates edge weights into the\nclustering process and includes a noise component that filters out spurious\nedges. WECAN offers a data-driven approach to distinguishing between meaningful\nand noisy edges, avoiding the arbitrary thresholding commonly used in network\nanalysis. Its effectiveness is demonstrated through simulation studies and\napplications to real-world datasets, showing significant improvements over\ntraditional clustering methods. Additionally, the R package ``WECAN'' has been\ndeveloped to facilitate its practical implementation."
    ],
    "b_categories":[
      [
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17151",
    "c_title":[
      "A Comprehensive Framework for Predictive Computational Modeling of\n  Growth and Remodeling in Tissue-Engineered Cardiovascular Implants"
    ],
    "c_abstract":[
      "Developing clinically viable tissue-engineered cardiovascular implants\nremains a formidable challenge. Achieving reliable and durable outcomes\nrequires a deeper understanding of the fundamental mechanisms driving tissue\nevolution during in vitro maturation. Although considerable progress has been\nmade in modeling soft tissue growth and remodeling, studies focused on the\nearly stages of tissue engineering remain limited. Here, we present a general,\nthermodynamically consistent model to predict tissue evolution and mechanical\nresponse throughout maturation. The formulation utilizes a stress-driven\nhomeostatic surface to capture volumetric growth, coupled with an energy-based\napproach to describe collagen densification via the strain energy of the\nfibers. We further employ a co-rotated intermediate configuration to ensure the\nmodel's consistency and generality. The framework is demonstrated with two\nnumerical examples: a uniaxially constrained tissue strip validated against\nexperimental data, and a biaxially constrained specimen subjected to a\nperturbation load. These results highlight the potential of the proposed model\nto advance the design and optimization of tissue-engineered implants with\nclinically relevant performance."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-358",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13384",
    "b_title":[
      "The bimodal distribution in the derivative of unitary polynomials"
    ],
    "b_abstract":[
      "The derivative of a polynomial with all zeros on the unit circle has the\nzeros of its derivative on or inside the unit circle. It has been observed that\nin many cases the zeros of the derivative have a bimodal distribution: there\nare two smaller circles near which it is more likely to find those zeros. We\nidentify the likely source of the second mode. This idea is supported with\nnumerical examples involving the characteristic polynomials of random unitary\nmatrices."
    ],
    "b_categories":[
      [
        "math.CV",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.04214",
    "c_title":[
      "General theory of slow non-Hermitian evolution"
    ],
    "c_abstract":[
      "Non-Hermitian systems are widespread in both classical and quantum physics.\nThe dynamics of such systems has recently become a focal point of research,\nshowcasing surprising behaviors that include apparent violation of the\nadiabatic theorem and chiral topological conversion related to encircling\nexceptional points (EPs). These have both fundamental interest and potential\npractical applications. Yet the current literature features a number of\napparently irreconcilable results. Here we develop a general theory for slow\nevolution of non-Hermitian systems and resolve these contradictions. We prove\nan analog of the adiabatic theorem for non-Hermitian systems and generalize it\nin the presence of uncontrolled environmental fluctuations (noise). The effect\nof noise turns out to be crucial due to inherent exponential instabilities\npresent in non-Hermitian systems. Disproving common wisdom, the end state of\nthe system is determined by the final Hamiltonian only, and is insensitive to\nother details of the evolution trajectory in parameter space. Our quantitative\ntheory, leading to transparent physical intuition, is amenable to experimental\ntests. It provides efficient tools to predict the outcome of the system's\nevolution, avoiding the need to follow costly time-evolution simulations. Our\napproach may be useful for designing devices based on non-Hermitian physics and\nmay stimulate analyses of classical and quantum non-Hermitian-Hamiltonian\ndynamics, as well as that of quantum Lindbladian and hybrid-Liouvillian\nsystems."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "math-ph",
        "math.MP",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-359",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09809",
    "b_title":[
      "Interpolation characterization of higher Thom polynomials"
    ],
    "b_abstract":[
      "Thom polynomials provide universal formulas for the fundamental class of\nsingularity loci in terms of characteristic classes. Ohmoto extended this\nnotion to SSM-Thom polynomials, which refine this description by capturing the\nricher Segre-Schwartz-MacPherson (SSM) class of singularity loci. While\nprevious methods for computing SSM-Thom polynomials relied on intricate\ngeometric arguments, we introduce a more efficient approach that depends solely\non the symmetries of singularities. Our method is inspired by connections to\nGeometric Representation Theory, particularly the interpolation properties of\nMaulik-Okounkov stable envelopes. By formulating SSM analogs of these axioms\nwithin a degree-bounded framework, we obtain new computational tools for\nSSM-Thom polynomials. We also present explicit examples of SSM-Thom\npolynomials, and illustrate their applications in enumerative geometry and\nsingularity theory."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05137",
    "c_title":[
      "Hierarchies from deterministic non-locality in theory space Anderson\n  localisation"
    ],
    "c_abstract":[
      "The nearest-neighbour or local mass terms in theory space among quantum\nfields, with their generic disordered values, are known to lead to the\nlocalisation of mass eigenstates, analogous to Anderson localisation in a\none-dimensional lattice. This mechanism can be used to create an exponential\nhierarchy in the coupling between two fields by placing them at opposite ends\nof the lattice chain. Extending this mechanism, we show that when copies of\nsuch fields are appropriately attached to the lattice chain, it leads to the\nemergence of multiple massless modes. These vanishing masses are a direct\nconsequence of the locality of interactions in theory space. The latter may\nbreak down in an ordered and deterministic manner through quantum effects if\nadditional interactions exist among the chain fields. Such non-locality can\ninduce small masses for the otherwise massless modes without necessarily\ndelocalising the mass eigenstates. We provide examples of interactions that\npreserve or even enhance localisation. Applications to flavour hierarchies,\nneutrino mass, and the $\\mu$-problem in supersymmetric theories are discussed."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-360",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15898",
    "b_title":[
      "Homotopy categories and fibrant model structures"
    ],
    "b_abstract":[
      "The homotopy category of a model structure on a weakly idempotent complete\nadditive category is proved to be equivalent to the additive quotient of the\ncategory of cofibrant-fibrant objects with respect to the subcategory of\ncofibrant-fibrant-trivial objects. A model structure on pointed category is\nfibrant, if every object is a fibrant object. Fibrant model structures is\nexplicitly described by trivial cofibrations, and also by fibrations. Fibrantly\nweak factorization systems are introduced, fibrant model structures are\nconstructed via fibrantly weak factorization systems, and a one-one\ncorrespondence between fibrantly weak factorization systems and fibrant model\nstructures is given. Applications are given to rediscover the $\\omega$-model\nstructures and the $\\mathcal W$-model structures, and their relations with\nexact model structures are discussed."
    ],
    "b_categories":[
      [
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00588",
    "c_title":[
      "Structural Dynamics and Strong Correlations in Dynamical Quantum Optical\n  Lattices"
    ],
    "c_abstract":[
      "When placing an ultracold atomic gas inside a cavity, the light-matter\ncoupling is enhanced and nonlinear atomic dynamics are generated, offering a\npromising platform for quantum simulation of models with short- and long-range\ninteractions. Recently, superradiant self organized phases for ultracold atomic\ngases inside a cavity, pumped by a blue detuned optical lattice, have been\nobserved. Here, we explore the formation of quantum many-body phases with\nstrongly interacting bosonic atoms inside an optical cavity, subject to\ntransverse blue detuned pumping. We analyze the interplay between superradiant\nself-organization with superfluid and Mott insulator phases, without the need\nof including higher lying bands, as the Wannier functions are dynamically\nlinked to the cavity light via backaction. We observe different kinds of\nstructural phase transitions driven by the light inside the cavity and the\ninterplay with atomic collisions. We observe the mode softening at the critical\npoints in the quantum phase transitions which can be measured in future\nexperiments."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas",
        "physics.atom-ph",
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-361",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01302",
    "b_title":[
      "Coupling of dynamical tide and orbital motion"
    ],
    "b_abstract":[
      "Dynamical tide consists of various waves that can resonate with orbital\nmotion. We test this coupling of dynamical tide and orbital motion using a\nsimple two-dimensional shallow water model, which can be applied to a rocky\nplanet covered with thin ocean or atmosphere. Then we take the earth-moon\nsystem as a fiducial model to calculate the tidal resonances and orbital\nevolution. We find that tidal dissipation can even increase with increasing\norbital separation because of the coupling of dynamical tide and orbital\nmotion. We draw the conclusion that the coupling is not negligible to study the\norbital evolution on secular timescale."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07916",
    "c_title":[
      "Convexification With the Viscocity Term for Electrical Impedance\n  Tomography"
    ],
    "c_abstract":[
      "A version of the globally convergent convexification numerical method is\nconstructed for the problem of Electrical Impedance Tomography in the 2D case.\nAn important element of this version is the presence of the viscosity term.\nGlobal convergence analysis is carried out. Results of numerical experiments\nare presented."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-362",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03460",
    "b_title":[
      "K-theoretic Tate-Poitou duality at prime 2"
    ],
    "b_abstract":[
      "We extend the result of Blumberg and Mandell on K-theoretic Tate-Poitou\nduality at odd primes which serves as a spectral refinement of the classical\narithmetic Tate-Poitou duality. The duality is formulated for the\n$K(1)$-localized algebraic K-theory of the ring of $p$-integers in a number\nfield and its completion using the $\\bZ_p$-Anderson duality. This paper\ncompletes the picture by addressing the prime 2, where the real embeddings of\nnumber fields introduce extra complexities. As an application, we identify the\nhomotopy type at prime 2 of the homotopy fiber of the cyclotomic trace for the\nsphere spectrum in terms of the algebraic K-theory of the integers."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.KT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10663",
    "c_title":[
      "PB-NBV: Efficient Projection-Based Next-Best-View Planning Framework for\n  Reconstruction of Unknown Objects"
    ],
    "c_abstract":[
      "Completely capturing the three-dimensional (3D) data of an object is\nessential in industrial and robotic applications. The task of next-best-view\n(NBV) planning is to calculate the next optimal viewpoint based on the current\ndata, gradually achieving a complete 3D reconstruction of the object. However,\nmany existing NBV planning algorithms incur heavy computational costs due to\nthe extensive use of ray-casting. Specifically, this framework refits different\ntypes of voxel clusters into ellipsoids based on the voxel structure. Then, the\nnext optimal viewpoint is selected from the candidate views using a\nprojection-based viewpoint quality evaluation function in conjunction with a\nglobal partitioning strategy. This process replaces extensive ray-casting,\nsignificantly improving the computational efficiency. Comparison experiments in\nthe simulation environment show that our framework achieves the highest point\ncloud coverage with low computational time compared to other frameworks. The\nreal-world experiments also confirm the efficiency and feasibility of the\nframework. Our method will be made open source to benefit the community."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-363",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17968",
    "b_title":[
      "The defocusing Calogero--Moser derivative nonlinear Schr{\\\"o}dinger\n  equation with a nonvanishing condition at infinity"
    ],
    "b_abstract":[
      "We consider the defocusing Calogero--Moser derivative nonlinear\nSchr{\\\"o}dinger equation\\begin{align*}i \\partial_{t} u+\\partial_{x}^2 u-2\\Pi\nD\\left(|u|^{2}\\right)u=0, \\quad (t,x ) \\in \\mathbb{R} \\times\n\\mathbb{R}\\end{align*}posed on $E := \\left\\{u \\in L^{\\infty}(\\mathbb{R}): u'\n\\in L^{2}(\\mathbb{R}), u'' \\in L^{2}(\\mathbb{R}), |u|^{2}-1 \\in\nL^{2}(\\mathbb{R})\\right\\}$. We prove the global well-posedness of this equation\nin $E$. Moreover, we give an explicit formula for the chiral solution to this\nequation."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17655",
    "c_title":[
      "FeatureGS: Eigenvalue-Feature Optimization in 3D Gaussian Splatting for\n  Geometrically Accurate and Artifact-Reduced Reconstruction"
    ],
    "c_abstract":[
      "3D Gaussian Splatting (3DGS) has emerged as a powerful approach for 3D scene\nreconstruction using 3D Gaussians. However, neither the centers nor surfaces of\nthe Gaussians are accurately aligned to the object surface, complicating their\ndirect use in point cloud and mesh reconstruction. Additionally, 3DGS typically\nproduces floater artifacts, increasing the number of Gaussians and storage\nrequirements. To address these issues, we present FeatureGS, which incorporates\nan additional geometric loss term based on an eigenvalue-derived 3D shape\nfeature into the optimization process of 3DGS. The goal is to improve geometric\naccuracy and enhance properties of planar surfaces with reduced structural\nentropy in local 3D neighborhoods.We present four alternative formulations for\nthe geometric loss term based on 'planarity' of Gaussians, as well as\n'planarity', 'omnivariance', and 'eigenentropy' of Gaussian neighborhoods. We\nprovide quantitative and qualitative evaluations on 15 scenes of the DTU\nbenchmark dataset focusing on following key aspects: Geometric accuracy and\nartifact-reduction, measured by the Chamfer distance, and memory efficiency,\nevaluated by the total number of Gaussians. Additionally, rendering quality is\nmonitored by Peak Signal-to-Noise Ratio. FeatureGS achieves a 30 % improvement\nin geometric accuracy, reduces the number of Gaussians by 90 %, and suppresses\nfloater artifacts, while maintaining comparable photometric rendering quality.\nThe geometric loss with 'planarity' from Gaussians provides the highest\ngeometric accuracy, while 'omnivariance' in Gaussian neighborhoods reduces\nfloater artifacts and number of Gaussians the most. This makes FeatureGS a\nstrong method for geometrically accurate, artifact-reduced and memory-efficient\n3D scene reconstruction, enabling the direct use of Gaussian centers for\ngeometric representation."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-364",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14105",
    "b_title":[
      "Conformal Prediction under L\\'evy-Prokhorov Distribution Shifts:\n  Robustness to Local and Global Perturbations"
    ],
    "b_abstract":[
      "Conformal prediction provides a powerful framework for constructing\nprediction intervals with finite-sample guarantees, yet its robustness under\ndistribution shifts remains a significant challenge. This paper addresses this\nlimitation by modeling distribution shifts using L\\'evy-Prokhorov (LP)\nambiguity sets, which capture both local and global perturbations. We provide a\nself-contained overview of LP ambiguity sets and their connections to popular\nmetrics such as Wasserstein and Total Variation. We show that the link between\nconformal prediction and LP ambiguity sets is a natural one: by propagating the\nLP ambiguity set through the scoring function, we reduce complex\nhigh-dimensional distribution shifts to manageable one-dimensional distribution\nshifts, enabling exact quantification of worst-case quantiles and coverage.\nBuilding on this analysis, we construct robust conformal prediction intervals\nthat remain valid under distribution shifts, explicitly linking LP parameters\nto interval width and confidence levels. Experimental results on real-world\ndatasets demonstrate the effectiveness of the proposed approach."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00251",
    "c_title":[
      "Interacted two-stage least squares with treatment effect heterogeneity"
    ],
    "c_abstract":[
      "Treatment effect heterogeneity with respect to covariates is common in\ninstrumental variable (IV) analyses. An intuitive approach, which we term the\ninteracted two-stage least squares (2SLS), is to postulate a linear working\nmodel of the outcome on the treatment, covariates, and treatment-covariate\ninteractions, and instrument it by the IV, covariates, and IV-covariate\ninteractions. We clarify the causal interpretation of the interacted 2SLS under\nthe local average treatment effect (LATE) framework when the IV is valid\nconditional on covariates. Our contributions are threefold. First, we show that\nthe interacted 2SLS with centered covariates is consistent for estimating the\nLATE if either of the following conditions holds: (i) the IV-covariate\ninteractions are linear in the covariates; (ii) the linear outcome model\nunderlying the interacted 2SLS is correct. Second, we show that the\ncoefficients of the treatment-covariate interactions from the interacted 2SLS\nare consistent for estimating treatment effect heterogeneity with regard to\ncovariates among compliers if either condition (i) or condition (ii) holds.\nMoreover, we connect the 2SLS estimator with the weighting perspective in\nAbadie (2003) and establish the necessity of condition (i) in the absence of\nadditional assumptions on potential outcomes. Third, leveraging the consistency\nguarantees of the interacted 2SLS for categorical covariates, we propose a\nstratification strategy based on the IV propensity score to approximate the\nLATE and treatment effect heterogeneity with regard to the IV propensity score\nwhen neither condition (i) nor condition (ii) holds."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-365",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13988",
    "b_title":[
      "MCRL4OR: Multimodal Contrastive Representation Learning for Off-Road\n  Environmental Perception"
    ],
    "b_abstract":[
      "Most studies on environmental perception for autonomous vehicles (AVs) focus\non urban traffic environments, where the objects\/stuff to be perceived are\nmainly from man-made scenes and scalable datasets with dense annotations can be\nused to train supervised learning models. By contrast, it is hard to densely\nannotate a large-scale off-road driving dataset manually due to the inherently\nunstructured nature of off-road environments. In this paper, we propose a\nMultimodal Contrastive Representation Learning approach for Off-Road\nenvironmental perception, namely MCRL4OR. This approach aims to jointly learn\nthree encoders for processing visual images, locomotion states, and control\nactions by aligning the locomotion states with the fused features of visual\nimages and control actions within a contrastive learning framework. The\ncausation behind this alignment strategy is that the inertial locomotion state\nis the result of taking a certain control action under the current\nlandform\/terrain condition perceived by visual sensors. In experiments, we\npre-train the MCRL4OR with a large-scale off-road driving dataset and adopt the\nlearned multimodal representations for various downstream perception tasks in\noff-road driving scenarios. The superior performance in downstream tasks\ndemonstrates the advantages of the pre-trained multimodal representations. The\ncodes can be found in \\url{https:\/\/github.com\/1uciusy\/MCRL4OR}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11994",
    "c_title":[
      "Decoherence and vibrational energy relaxation of the electronically\n  excited PtPOP complex in solution"
    ],
    "c_abstract":[
      "Understanding the ultrafast vibrational relaxation following photoexcitation\nof molecules in a condensed phase is essential to predict the outcome and\nimprove the efficiency of photoinduced molecular processes. Here, the\nvibrational decoherence and energy relaxation of a binuclear complex,\n[Pt$_2$(P$_2$O$_5$H$_2$)$_4$]$^{4-}$ (PtPOP), upon electronic excitation in\nliquid water and acetonitrile are investigated through direct adiabatic\ndynamics simulations. A quantum mechanics\/molecular mechanics (QM\/MM) scheme is\nused where the excited state of the complex is modelled with orbital-optimized\ndensity functional calculations while solvent molecules are described using\npotential energy functions. The decoherence time of the Pt-Pt vibration\ndominating the photoinduced dynamics is found to be $\\sim$1.6 ps in both\nsolvents. This is in excellent agreement with experimental measurements in\nwater, where intersystem crossing is slow ($>10$ ps). Pathways for the flow of\nexcess energy are identified by monitoring the power of the solvent on\nvibrational modes. The latter are obtained as generalized normal modes from the\nvelocity covariances, and the power is computed using QM\/MM embedding forces.\nExcess vibrational energy is found to be predominantly released through\nshort-range repulsive and attractive interactions between the ligand atoms and\nsurrounding solvent molecules, whereas solute-solvent interactions involving\nthe Pt atoms are less important. Since photoexcitation deposits most of the\nexcess energy into Pt-Pt vibrations, energy dissipation to the solvent is\ninefficient. This study reveals the mechanism behind the exceptionally long\nvibrational coherence of the photoexcited PtPOP complex in solution and\nunderscores the importance of short-range interactions for accurate simulations\nof vibrational energy relaxation of solvated molecules."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-366",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16412",
    "b_title":[
      "Dynamic Neutrino Mass Ordering and Its Imprint on the Diffuse Supernova\n  Neutrino Background"
    ],
    "b_abstract":[
      "Neutrino masses may have evolved dynamically throughout the history of the\nUniverse, potentially leading to a mass spectrum distinct from the normal or\ninverted ordering observed today. While cosmological measurements constrain the\ntotal energy density of neutrinos, they are not directly sensitive to a\ndynamically changing mass ordering unless future surveys achieve exceptional\nprecision in detecting the distinct imprints of each mass eigenstate on\nlarge-scale structures. In this work, we investigate the impact of a dynamic\nneutrino mass spectrum on the diffuse supernova neutrino background (DSNB),\nwhich is composed of neutrinos from all supernova explosions throughout cosmic\nhistory and is on the verge of experimental detection. Since neutrino\noscillations are highly sensitive to the mass spectrum, we show that the\nelectron neutrino survival probability carries distinct signatures of the\nevolving neutrino mass spectrum. Our results indicate that the resulting\nmodifications to the DSNB spectrum would exhibit unique energy-dependent\nfeatures. These features are distinguishable from the effects of significant\nastrophysical uncertainties, providing a potential avenue for probing the\ndynamic nature of neutrino masses."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16337",
    "c_title":[
      "Optimal Complexity in Byzantine-Robust Distributed Stochastic\n  Optimization with Data Heterogeneity"
    ],
    "c_abstract":[
      "In this paper, we establish tight lower bounds for Byzantine-robust\ndistributed first-order stochastic optimization methods in both strongly convex\nand non-convex stochastic optimization. We reveal that when the distributed\nnodes have heterogeneous data, the convergence error comprises two components:\na non-vanishing Byzantine error and a vanishing optimization error. We\nestablish the lower bounds on the Byzantine error and on the minimum number of\nqueries to a stochastic gradient oracle required to achieve an arbitrarily\nsmall optimization error. Nevertheless, we identify significant discrepancies\nbetween our established lower bounds and the existing upper bounds. To fill\nthis gap, we leverage the techniques of Nesterov's acceleration and variance\nreduction to develop novel Byzantine-robust distributed stochastic optimization\nmethods that provably match these lower bounds, up to logarithmic factors,\nimplying that our established lower bounds are tight."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-367",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01219",
    "b_title":[
      "Control Strategy for Generalized Synchrony in Coupled Dynamical Systems"
    ],
    "b_abstract":[
      "Dynamical systems can be coupled in a manner that is designed to drive the\nresulting dynamics onto a specified lower dimensional submanifold in the phase\nspace of the combined system. On the submanifold, the variables of the two\nsystems have a well-defined unique functional relationship. This process can\nthus be viewed as a control technique that ensures generalized synchronization.\nDepending on the nature of the dynamical systems and the specified submanifold,\ndifferent coupling functions can be derived in order to achieve a desired\ncontrol objective. We discuss the circuit implementations of this strategy in\nrepresentative examples of coupled chaotic dynamical systems, namely Lorenz\noscillators"
    ],
    "b_categories":[
      [
        "nlin.CD"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04797",
    "c_title":[
      "Parallel Corpora for Machine Translation in Low-resource Indic\n  Languages: A Comprehensive Review"
    ],
    "c_abstract":[
      "Parallel corpora play an important role in training machine translation (MT)\nmodels, particularly for low-resource languages where high-quality bilingual\ndata is scarce. This review provides a comprehensive overview of available\nparallel corpora for Indic languages, which span diverse linguistic families,\nscripts, and regional variations. We categorize these corpora into\ntext-to-text, code-switched, and various categories of multimodal datasets,\nhighlighting their significance in the development of robust multilingual MT\nsystems. Beyond resource enumeration, we critically examine the challenges\nfaced in corpus creation, including linguistic diversity, script variation,\ndata scarcity, and the prevalence of informal textual content.We also discuss\nand evaluate these corpora in various terms such as alignment quality and\ndomain representativeness. Furthermore, we address open challenges such as data\nimbalance across Indic languages, the trade-off between quality and quantity,\nand the impact of noisy, informal, and dialectal data on MT performance.\nFinally, we outline future directions, including leveraging cross-lingual\ntransfer learning, expanding multilingual datasets, and integrating multimodal\nresources to enhance translation quality. To the best of our knowledge, this\npaper presents the first comprehensive review of parallel corpora specifically\ntailored for low-resource Indic languages in the context of machine\ntranslation."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-368",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18203",
    "b_title":[
      "Joint Design and Pricing of Extended Warranties for Multiple Automobiles\n  with Different Price Bands"
    ],
    "b_abstract":[
      "Extended warranties (EWs) are significant source of revenue for\ncapital-intensive products like automobiles. Such products consist of multiple\nsubsystems, providing flexibility in EW customization, for example, bundling a\ntailored set of subsystems in an EW contract. This, in turn, enables the\ncreation of a service menu with different EW contract options. From the\nperspective of a third-party EW provider servicing a fleet of automobile\nbrands, we develop a novel model to jointly optimize the design and pricing of\nEWs in order to maximize the profit. Specifically, the problem is to determine\nwhich contracts should be included in the EW menu and identify the appropriate\nprice for each contract. As the complexity of the joint optimization problem\nincreases exponentially with the number of subsystems, two solution approaches\nare devised to solve the problem. The first approach is based on a\nmixed-integer second-order cone programming reformulation, which guarantees\noptimality but is applicable only for a small number of subsystems. The second\napproach utilizes a two-step iteration process, offering enhanced computational\nefficiency in scenarios with a large number of subsystems. Through numerical\nexperiments, the effectiveness of our model is validated, particularly in\nscenarios characterized by high failure rates and a large number of subsystems."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.05773",
    "c_title":[
      "Between Innovation and Oversight: A Cross-Regional Study of AI Risk\n  Management Frameworks in the EU, U.S., UK, and China"
    ],
    "c_abstract":[
      "As artificial intelligence (AI) technologies increasingly enter important\nsectors like healthcare, transportation, and finance, the development of\neffective governance frameworks is crucial for dealing with ethical, security,\nand societal risks. This paper conducts a comparative analysis of AI risk\nmanagement strategies across the European Union (EU), United States (U.S.),\nUnited Kingdom (UK), and China. A multi-method qualitative approach, including\ncomparative policy analysis, thematic analysis, and case studies, investigates\nhow these regions classify AI risks, implement compliance measures, structure\noversight, prioritize transparency, and respond to emerging innovations.\nExamples from high-risk contexts like healthcare diagnostics, autonomous\nvehicles, fintech, and facial recognition demonstrate the advantages and\nlimitations of different regulatory models. The findings show that the EU\nimplements a structured, risk-based framework that prioritizes transparency and\nconformity assessments, while the U.S. uses decentralized, sector-specific\nregulations that promote innovation but may lead to fragmented enforcement. The\nflexible, sector-specific strategy of the UK facilitates agile responses but\nmay lead to inconsistent coverage across domains. China's centralized\ndirectives allow rapid large-scale implementation while constraining public\ntransparency and external oversight. These insights show the necessity for AI\nregulation that is globally informed yet context-sensitive, aiming to balance\neffective risk management with technological progress. The paper concludes with\npolicy recommendations and suggestions for future research aimed at enhancing\neffective, adaptive, and inclusive AI governance globally."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-369",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07269",
    "b_title":[
      "The wreath matrix"
    ],
    "b_abstract":[
      "Let $k\\leq n$ be positive integers and $\\mathbb{Z}_{n}$ be the set of\nintegers modulo $n$. A conjecture of Baranyai from 1974 asks for a\ndecomposition of $k$-element subsets of $\\mathbb{Z}_{n}$ into particular\nfamilies of sets called \"wreaths\". We approach this conjecture from a new\nalgebraic angle by introducing the key object of this paper, the wreath matrix\n$M$. As our first result, we establish that Baranyai's conjecture is equivalent\nto the existence of a particular vector in the kernel of $M$. We then employ\nresults from representation theory to study $M$ and its spectrum in detail. In\nparticular, we find all eigenvalues of $M$ and their multiplicities, and\nidentify several families of vectors which lie in the kernel of $M$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05009",
    "c_title":[
      "A Scalable System for Visual Analysis of Ocean Data"
    ],
    "c_abstract":[
      "Oceanographers rely on visual analysis to interpret model simulations,\nidentify events and phenomena, and track dynamic ocean processes. The ever\nincreasing resolution and complexity of ocean data due to its dynamic nature\nand multivariate relationships demands a scalable and adaptable visualization\ntool for interactive exploration. We introduce pyParaOcean, a scalable and\ninteractive visualization system designed specifically for ocean data analysis.\npyParaOcean offers specialized modules for common oceanographic analysis tasks,\nincluding eddy identification and salinity movement tracking. These modules\nseamlessly integrate with ParaView as filters, ensuring a user-friendly and\neasy-to-use system while leveraging the parallelization capabilities of\nParaView and a plethora of inbuilt general-purpose visualization\nfunctionalities. The creation of an auxiliary dataset stored as a Cinema\ndatabase helps address I\/O and network bandwidth bottlenecks while supporting\nthe generation of quick overview visualizations. We present a case study on the\nBay of Bengal (BoB) to demonstrate the utility of the system and scaling\nstudies to evaluate the efficiency of the system."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.DC",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-370",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09930",
    "b_title":[
      "Human Physical Interaction based on UAV Cooperative Payload\n  Transportation System using Adaptive Backstepping and FNTSMC"
    ],
    "b_abstract":[
      "This paper presents a nonlinear control strategy for an aerial cooperative\npayload transportation system consisting of two quadrotor UAVs rigidly\nconnected to a payload. The system includes human physical interaction\nfacilitated by an admittance control. The proposed control framework integrates\nan adaptive Backstepping controller for the position subsystem and a Fast\nNonsingular Terminal Sliding Mode Control (FNTSMC) for the attitude subsystem\nto ensure asymptotic stabilization. The admittance controller interprets the\ninteraction forces from the human operator, generating reference trajectories\nfor the position controller to ensure accurate tracking of the operator's\nguidance. The system aims to assist humans in payload transportation, providing\nboth stability and responsiveness. The robustness and effectiveness of the\nproposed control scheme in maintaining system stability and performance under\nvarious conditions are presented."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09346",
    "c_title":[
      "Local Existence of a Classical Solution for Quasi-Linear Hyperbolic\n  Systems"
    ],
    "c_abstract":[
      "In this paper, we study quasi-linear hyperbolic systems. Our goal in this\npaper is to provide a new proof of local existence of a classical solution for\nthe system. Most difficult point is to prove the convergence of the derivative\nof approximate solutions by the Arzela-Ascoli theorem."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-371",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19454",
    "b_title":[
      "TransVDM: Motion-Constrained Video Diffusion Model for Transparent Video\n  Synthesis"
    ],
    "b_abstract":[
      "Recent developments in Video Diffusion Models (VDMs) have demonstrated\nremarkable capability to generate high-quality video content. Nonetheless, the\npotential of VDMs for creating transparent videos remains largely uncharted. In\nthis paper, we introduce TransVDM, the first diffusion-based model specifically\ndesigned for transparent video generation. TransVDM integrates a Transparent\nVariational Autoencoder (TVAE) and a pretrained UNet-based VDM, along with a\nnovel Alpha Motion Constraint Module (AMCM). The TVAE captures the alpha\nchannel transparency of video frames and encodes it into the latent space of\nthe VDMs, facilitating a seamless transition to transparent video diffusion\nmodels. To improve the detection of transparent areas, the AMCM integrates\nmotion constraints from the foreground within the VDM, helping to reduce\nundesirable artifacts. Moreover, we curate a dataset containing 250K\ntransparent frames for training. Experimental results demonstrate the\neffectiveness of our approach across various benchmarks."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13151",
    "c_title":[
      "J-braid groups are torus necklace groups"
    ],
    "c_abstract":[
      "We construct a family of links we call torus necklaces for which the link\ngroups are precisely the braid groups of generalised $J$-reflection groups.\nMoreover, this correspondence exhibits the meridians of the aforementioned link\ngroups as braid reflections. In particular, this construction generalises to\nall irreducible rank two complex reflection groups a well-known correspondence\nbetween some rank two complex braid groups and some torus knot groups. In\naddition, as abstract groups, we show that the family of link groups associated\nto Seifert links coincides with the family of circular groups. This shows that\nevery time a link group has a non-trivial center, it is a Garside group."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.GR",
        "math.GT",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-372",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07691",
    "b_title":[
      "Time-resolved second-order autocorrelation function of parametric\n  downconversion"
    ],
    "b_abstract":[
      "We study a possibility of measuring the time-resolved second-order\nautocorrelation function of one of two beams generated in type-II parametric\ndownconversion by means of temporal magnification of this beam, bringing its\ncorrelation time from the picosecond to the nanosecond scale, which can be\nresolved by modern photodetectors. We show that such a measurement enables one\nto infer directly the degree of global coherence of that beam, which is linked\nby a simple relation to the number of modes characterizing the entanglement\nbetween the two generated beams. We illustrate the proposed method by an\nexample of photon pairs generated in a periodically poled KTP crystal with a\nsymmetric group velocity matching for various durations of the pump pulse,\nresulting in different numbers of modes. Our theoretical model also shows that\nthe magnified double-heralded autocorrelation function of one beam exhibits a\nlocal maximum around zero delay time, corresponding to photon bunching at a\nshort time scale."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.17583",
    "c_title":[
      "Persistence and extinction dynamics in a stochastic predator-prey model\n  with emergent Allee effects"
    ],
    "c_abstract":[
      "The Allee effect describes a decline in population fitness at low densities,\npotentially leading to extinction. In predator-prey systems, an emergent Allee\neffect can arise due to interactions such as density-dependent maturation rates\nand predation constraints. This work studies a stochastic predator-prey model\nwhere the prey population is structured into juvenile and adult stages, with\nmaturation following a nonlinear function. We introduce Ito-type stochastic\nperturbations in mortality rates to account for environmental variability. We\nfirst establish the positivity of solutions and derive sufficient conditions\nfor the stability of the trivial equilibrium, prey extinction, and conditional\npredator extinction. We then analyze prey persistence under specific maturation\nrate functions. Finally, numerical simulations illustrate the theoretical\nresults and their ecological implications."
    ],
    "c_categories":[
      [
        "math.PR",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-373",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17466",
    "b_title":[
      "Global Hypoellipticity and Solvability with Loss of Derivatives on the\n  Torus"
    ],
    "b_abstract":[
      "This paper provides a complete characterization of global hypoellipticity and\nsolvability with loss of derivatives for Fourier multiplier operators on the\n$n$-dimensional torus. We establish necessary and sufficient conditions for\nthese properties and examine their connections with classical notions of global\nhypoellipticity and solvability, particularly in relation to the closedness of\nthe operator's range.\n  As an application, we explore the interplay between these properties and\nnumber theory in the context of differential operators on the two-torus.\nSpecifically, we prove that the loss of derivatives in the solvability of the\nvector field $\\partial_{x_1} - \\alpha \\partial_{x_2}$ is precisely determined\nby the well-known irrationality measure $\\mu(\\alpha)$ of its coefficient\n$\\alpha$. Furthermore, we analyze the wave operator $\\partial_{x_1}^2 - \\eta^2\n\\Delta_{\\mathbb{T}^n}$ and show how the loss of derivatives depends explicitly\non the parameter $\\eta > 0$."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.12221",
    "c_title":[
      "ReF Decompile: Relabeling and Function Call Enhanced Decompile"
    ],
    "c_abstract":[
      "The goal of decompilation is to convert compiled low-level code (e.g.,\nassembly code) back into high-level programming languages, enabling analysis in\nscenarios where source code is unavailable. This task supports various reverse\nengineering applications, such as vulnerability identification, malware\nanalysis, and legacy software migration. The end-to-end decompile method based\non large langauge models (LLMs) reduces reliance on additional tools and\nminimizes manual intervention due to its inherent properties. However, previous\nend-to-end methods often lose critical information necessary for reconstructing\ncontrol flow structures and variables when processing binary files, making it\nchallenging to accurately recover the program's logic. To address these issues,\nwe propose the \\textbf{ReF Decompile} method, which incorporates the following\ninnovations: (1) The Relabelling strategy replaces jump target addresses with\nlabels, preserving control flow clarity. (2) The Function Call strategy infers\nvariable types and retrieves missing variable information from binary files.\nExperimental results on the Humaneval-Decompile Benchmark demonstrate that ReF\nDecompile surpasses comparable baselines and achieves state-of-the-art (SOTA)\nperformance of $61.43\\%$."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-374",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01039",
    "b_title":[
      "The Role of the Schwinger Effect in Superradiant Axion Lasers"
    ],
    "b_abstract":[
      "Superradiance can cause the axion cloud around a rotating black hole to reach\nextremely high densities, and the decay of these axions can produce a powerful\nlaser. The electric field of these lasers is strong enough that the Schwinger\neffect may become significant, resulting in the production of an\nelectron-positron plasma. We explore the dynamics between axion lasers and this\nelectron-positron plasma. While there are several mechanisms by which the\ninclusion of a plasma can impact the laser's behavior, the most significant of\nthese mechanisms is that the electron-positron plasma imparts an effective mass\non the photon. As the plasma frequency increases, axion decay becomes\nenergetically unfavorable, up to the point where the axion no longer decays\ninto photons, shutting off the laser. We find that the impact of the\nelectron-positron plasma on the dynamics of the system depend heavily on the\nparameters, specifically the axion mass $m_\\phi$ and the superradiant coupling\n$\\alpha$, and that we may divide parameter space into three regimes: the\nunenhanced, enhanced, and unstable regimes. In the unenhanced and enhanced\nregime, the system will eventually settle into an equilibrium state, emitting a\nlaser of constant luminosity while the number of axions remains constant. In\nthe unenhanced regime, this equilibrium state can be calculated while\nneglecting the effects of Schwinger production; in the enhanced regime, the\nequilibrium luminosity is slightly larger than what it would be without\nSchwinger production. In the unstable regime, the electron-positron plasma\nsuppresses axion decay to the point where the system is never able to reach\nequilibrium; instead, the axions continue to grow superradiantly. In all three\ncases, the production of superradiant axions will eventually cause the black\nhole to spin down to the point where superradiance ceases."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14638",
    "c_title":[
      "NAVIG: Natural Language-guided Analysis with Vision Language Models for\n  Image Geo-localization"
    ],
    "c_abstract":[
      "Image geo-localization is the task of predicting the specific location of an\nimage and requires complex reasoning across visual, geographical, and cultural\ncontexts. While prior Vision Language Models (VLMs) have the best accuracy at\nthis task, there is a dearth of high-quality datasets and models for analytical\nreasoning. We first create NaviClues, a high-quality dataset derived from\nGeoGuessr, a popular geography game, to supply examples of expert reasoning\nfrom language. Using this dataset, we present Navig, a comprehensive image\ngeo-localization framework integrating global and fine-grained image\ninformation. By reasoning with language, Navig reduces the average distance\nerror by 14% compared to previous state-of-the-art models while requiring fewer\nthan 1000 training samples. Our dataset and code are available at\nhttps:\/\/github.com\/SparrowZheyuan18\/Navig\/."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-375",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11955",
    "b_title":[
      "A generalization of Zwegers' multivariable $\\mu$-function"
    ],
    "b_abstract":[
      "We introduce a one parameter deformation of Zwegers' multivariable\n$\\mu$-function by applying iterations of the $q$-Borel summation method, which\nis also a multivariate analogue of the generalized $\\mu$-function introduced by\nthe authors. For this deformed multivariable $\\mu$-function, we give some\nformulas, for example, forward shift formula, translation and\n$\\mathfrak{S}_{N+1}$-symmetry. Further we mention modular formulas for the\nZwegers' original multivariable $\\mu$-function."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13458",
    "c_title":[
      "Modelling the energy dependent X-ray variability of Mrk 335"
    ],
    "c_abstract":[
      "We present a technique which predicts the energy dependent fractional r.m.s\nfor linear correlated variations of a pair of spectral parameters and apply it\nto an XMM-Newton observation of Mrk 335. The broadband X-ray spectrum can be\ninterpreted as a patchy absorber partially covering the primary emission, a\nwarm and hot coronal emission or a relativistically blurred reflection along\nwith the primary emission. The fractional r.m.s has a non-monotonic behavior\nwith energy for segments of lengths 3 and 6 ksecs. For each spectral model, we\nconsider every pair of spectral parameters and fit the predicted r.m.s with the\nobserved ones, to get the pair which provides the best fit. We find that a\nvariation in at least two parameters is required for all spectral\ninterpretations. For both time segments, variations in the covering fraction of\nthe absorber and the primary power law index gives the best result for the\npartial covering model, while a variation in the normalization and spectral\nindex of the warm component gives the best fit in the two corona\ninterpretation. For the reflection model, the best fit parameters are different\nfor the two time segment lengths, and the results suggests that more than two\nparameters are required to explain the data. This, combined with the extreme\nvalues of emissivity index and reflection fraction parameters obtained from the\nspectral analysis, indicates that the blurred reflection model might not be a\nsuitable explanation for the Mrk 335 spectrum. We discuss the results as well\nas the potential of the technique to be applied to other data sets of different\nAGN."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-376",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14415",
    "b_title":[
      "Classes of simple derivations on polynomial rings $k[x_1,x_2, \\ldots\n  ,x_n]$"
    ],
    "b_abstract":[
      "Let $k$ be a field of characteristic zero. Let $m$ and $\\alpha$ be positive\nintegers. For $n\\geq 2$, let $R_n=k[x_1,x_2,\\dots,x_n]$ with the $k$-derivation\n$d_n$ given by\n$d_n=(1-x_1x_2^{\\alpha})\\partial_{x_1}+x_1^m\\partial_{x_2}+x_2\\partial_{x_3}+\\dots+x_{n-1}\\partial_{x_n}$.\nWe prove that for integers $m\\geq 2$ and $\\alpha \\geq 1$, $d_n$ is a simple\nderivation on $R_n$ and $d_n(R_n)$ contains no units. This generalizes a result\nof D. A. Jordan. We also show that the isotropy group of $d_n$ is conjugate to\na subgroup of translations."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04518",
    "c_title":[
      "Leveraging priors on distribution functions for multi-arm bandits"
    ],
    "c_abstract":[
      "We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian\nnon-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP)\npriors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e.,\nit plays an arm based on its posterior-probability of being optimal. Instead of\nassuming a parametric class for the reward generating distribution of each arm,\nand then putting a prior on the parameters, in DPPS the reward generating\ndistribution is directly modeled using DP priors. DPPS provides a principled\napproach to incorporate prior belief about the bandit environment, and in the\nnoninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover\nNon Parametric Thompson Sampling (NPTS), a popular non-parametric bandit\nalgorithm, as a special case of DPPS. We employ stick-breaking representation\nof the DP priors, and show excellent empirical performance of DPPS in\nchallenging synthetic and real world bandit environments. Finally, using an\ninformation-theoretic analysis, we show non-asymptotic optimality of DPPS in\nthe Bayesian regret setup."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-377",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15350",
    "b_title":[
      "Connecting a Magnetized Disk to a Convective Low-mass Protostar: A\n  Global Three-dimensional Model of Boundary Layer Accretion"
    ],
    "b_abstract":[
      "In the early stages of star formation, boundary layer accretion, where\nprotostars accrete material from disks extending down to their surfaces, plays\na crucial role. Understanding how a magneto-rotational-instability (MRI)-active\ndisk connects to a protostar's surface remains a significant challenge. To\ninvestigate the mechanisms of mass and angular momentum transfer, we develop a\nglobal, three-dimensional magnetohydrodynamic model of boundary layer accretion\naround a magnetized, convective low-mass protostar. Our results reveal that\nangular momentum transport mechanisms transition significantly from the outer\nMRI-active disk to the protostellar surface. Various mechanisms--MRI, spiral\nshocks, coronal accretion, jets, and disk winds--contribute to angular momentum\ntransfer, resulting in three distinct disk structures: (1) the MRI-active disk,\n(2) the transition layer, and (3) the boundary layer. The simulated protostar\nis strongly magnetized due to the accumulation of the disk fields, wrapping by\ndisk toroidal fields, and stellar dynamo activity. Magnetic concentrations\nanalogous to starspots form on the protostar and interact with the rotating\ndisk gas to generate spiral shocks. These shocks play a key role in driving\naccretion. These findings demonstrate the necessity of global MHD models for a\ncomprehensive understanding of angular momentum transport. Additionally, we\nidentify explosive events triggered by magnetic reconnection in both the\nprotostar and the disk atmosphere. We also find decretion flows in the disk\nmidplane, which may be important for the radial transport of refractory\nmaterials, such as Calcium-Aluminium-rich Inclusions (CAIs) precursor gas, to\nthe outer disk."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12813",
    "c_title":[
      "Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN-LSTM\n  With WOA-GWO Parameter Optimization: Global COVID-19 Case Study"
    ],
    "c_abstract":[
      "Effective epidemic modeling is essential for managing public health crises,\nrequiring robust methods to predict disease spread and optimize resource\nallocation. This study introduces a novel deep learning framework that advances\ntime series forecasting for infectious diseases, with its application to COVID\n19 data as a critical case study. Our hybrid approach integrates Convolutional\nNeural Networks (CNNs) and Long Short Term Memory (LSTM) models to capture\nspatial and temporal dynamics of disease transmission across diverse regions.\nThe CNN extracts spatial features from raw epidemiological data, while the LSTM\nmodels temporal patterns, yielding precise and adaptable predictions. To\nmaximize performance, we employ a hybrid optimization strategy combining the\nWhale Optimization Algorithm (WOA) and Gray Wolf Optimization (GWO) to fine\ntune hyperparameters, such as learning rates, batch sizes, and training epochs\nenhancing model efficiency and accuracy. Applied to COVID 19 case data from 24\ncountries across six continents, our method outperforms established benchmarks,\nincluding ARIMA and standalone LSTM models, with statistically significant\ngains in predictive accuracy (e.g., reduced RMSE). This framework demonstrates\nits potential as a versatile method for forecasting epidemic trends, offering\ninsights for resource planning and decision making in both historical contexts,\nlike the COVID 19 pandemic, and future outbreaks."
    ],
    "c_categories":[
      [
        "cs.LG",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-378",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08630",
    "b_title":[
      "On principal eigenvalues of linear time-periodic parabolic systems:\n  symmetric mutation case"
    ],
    "b_abstract":[
      "The paper is concerned with the effect of the spatio-temporal heterogeneity\non the principal eigenvalue of some linear time-periodic parabolic system.\nVarious asymptotic behaviors of the principal eigenvalue and its monotonicity,\nas a function of the diffusion rate and frequency, are first derived. In\nparticular, some singular behaviors of the principal eigenvalues are observed\nwhen both diffusion rate and frequency approach zero, with some scalar\ntime-periodic Hamilton-Jacobi equation as the limiting equation. Furthermore,\nwe completely classify the topological structures of the level sets for the\nprincipal eigenvalues in the plane of frequency and diffusion rate. Our results\nnot only generalize most of the findings in [S. Liu and Y. Lou, J. Funct.\nAnal., 282 (2022), 109338] for scalar periodic-parabolic operators, but also\nreveal more rich global information, for time-periodic parabolic systems, on\nthe dependence of the principal eigenvalues upon the spatio-temporal\nheterogeneity."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11385",
    "c_title":[
      "Sparse Incremental Aggregation in Satellite Federated Learning"
    ],
    "c_abstract":[
      "This paper studies Federated Learning (FL) in low Earth orbit (LEO) satellite\nconstellations, where satellites are connected via intra-orbit inter-satellite\nlinks (ISLs) to their neighboring satellites. During the FL training process,\nsatellites in each orbit forward gradients from nearby satellites, which are\neventually transferred to the parameter server (PS). To enhance the efficiency\nof the FL training process, satellites apply in-network aggregation, referred\nto as incremental aggregation. In this work, the gradient sparsification\nmethods from [1] are applied to satellite scenarios to improve bandwidth\nefficiency during incremental aggregation. The numerical results highlight an\nincrease of over 4 x in bandwidth efficiency as the number of satellites in the\norbital plane increases."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-379",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14812",
    "b_title":[
      "Byzantine Game Theory: Sun Tzus Boxes"
    ],
    "b_abstract":[
      "We introduce the Byzantine Selection Problem, living at the intersection of\ngame theory and fault-tolerant distributed computing. Here, an event organizer\nis presented with a group of $n$ agents, and wants to select $\\ell < n$ of them\nto form a team. For these purposes, each agent $i$ self-reports a positive\nskill value $v_i$, and a team's value is the sum of its members' skill values.\nIdeally, the value of the team should be as large as possible, which can be\neasily achieved by selecting agents with the highest $\\ell$ skill values.\nHowever, an unknown subset of at most $t < n$ agents are byzantine and hence\nnot to be trusted, rendering their true skill values as $0$. In the spirit of\nthe distributed computing literature, the identity of the byzantine agents is\nnot random but instead chosen by an adversary aiming to minimize the value of\nthe chosen team. Can we still select a team with good guarantees in this\nadversarial setting? As it turns out, deterministically, it remains optimal to\nselect agents with the highest $\\ell$ values. Yet, if $t \\geq \\ell$, the\nadversary can choose to make all selected agents byzantine, leading to a team\nof value zero. To provide meaningful guarantees, one hence needs to allow for\nrandomization, in which case the expected value of the selected team needs to\nbe maximized, assuming again that the adversary plays to minimize it. For this\ncase, we provide linear-time randomized algorithms that maximize the expected\nvalue of the selected team."
    ],
    "b_categories":[
      [
        "cs.DC",
        "cs.DS",
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15084",
    "c_title":[
      "A constraint on superheavy elements of the GRB-kilonova AT 2023vfi"
    ],
    "c_abstract":[
      "The discovery of the kilonova (KN) AT 2017gfo, accompanying the gravitational\nwave event GW170817, provides crucial insight into the synthesis of heavy\nelements during binary neutron star (BNS) mergers. Following this landmark\nevent, another KN was detected in association with the second-brightest\ngamma-ray burst (GRB) observed to date, GRB 230307A, and subsequently confirmed\nby observations of the James Webb Space Telescope (JWST). In this work, we\nconduct an end-to-end simulation to analyze the temporal evolution of the KN AT\n2023vfi associated with GRB 230307A, and constrain the abundances of superheavy\nelements produced. We find that the temporal evolution of AT 2023vfi is similar\nto AT 2017gfo in the first week post-burst. Additionally, the\n\\textit{r}-process nuclide abundances of lanthanide-rich ejecta, derived from\nnumerical relativity simulations of BNS mergers, can also successfully\ninterpret the temporal evolution of the KN with the lanthanide-rich ejecta mass\nof $0.02 M_\\odot$, which is consistent with the mass range of dynamical ejecta\nfrom numerical simulations in literature. Both findings strongly suggest the\nhypothesis that GRB 230307A originated from a BNS merger, similar to AT\n2017gfo. Based on the first time observation of the KN for JWST, we are able to\nconstrain the superheavy elements of another KN following AT 2017gfo. The\npre-radioactive-decay abundances of the superheavy nuclides: $^{222}$Rn,\n$^{223}$Ra, $^{224}$Ra and $^{225}$Ac, are estimated to be at least on the\norder of $1 \\times 10^{-5}$. These abundance estimates provide valuable insight\ninto the synthesis of superheavy elements in BNS mergers, contributing to our\nunderstanding of astrophysical \\textit{r}-process nucleosynthesis."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-380",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04400",
    "b_title":[
      "Adaptive Prototype Knowledge Transfer for Federated Learning with Mixed\n  Modalities and Heterogeneous Tasks"
    ],
    "b_abstract":[
      "Multimodal Federated Learning (MFL) enables multiple clients to\ncollaboratively train models on multimodal data while ensuring clients'\nprivacy. However, modality and task heterogeneity hinder clients from learning\na unified representation, weakening local model generalization, especially in\nMFL with mixed modalities where only some clients have multimodal data. In this\nwork, we propose an Adaptive prototype-based Multimodal Federated Learning\n(AproMFL) framework for mixed modalities and heterogeneous tasks to address the\naforementioned issues. Our AproMFL transfers knowledge through\nadaptively-constructed prototypes without a prior public dataset. Clients\nadaptively select prototype construction methods in line with tasks; server\nconverts client prototypes into unified multimodal prototypes and aggregates\nthem to form global prototypes, avoid clients keeping unified labels. We divide\nthe model into various modules and only aggregate mapping modules to reduce\ncommunication and computation overhead. To address aggregation issues in\nheterogeneity, we develop a client relationship graph-based scheme to\ndynamically adjust aggregation weights. Extensive experiments on representative\ndatasets evidence effectiveness of AproMFL."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.MM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17570",
    "c_title":[
      "Diving deep into the Milky Way using Anti-Reflection Coatings for\n  Astronomical CCDs"
    ],
    "c_abstract":[
      "We report two anti-reflection (AR) coatings that give better quantum\nefficiency (QE) than the existing AR coating on the Gaia astrometric field (AF)\nCCDs. Light being the core of optical astronomy is extremely important for such\nmissions, therefore, the QE of the devices that are used to capture it should\nbe substantially high. To reduce the losses due to the reflection of light from\nthe surface of the CCDs, AR coatings can be applied. Currently, the main\ncomponent of the Gaia satellite, the AF CCDs use hafnium dioxide (HfO2) AR\ncoating. In this paper, the ATLAS module of the SILVACO software has been\nemployed for simulating and studying the AF CCD pixel structure and several AR\ncoatings. Our findings evidently suggest that zirconium dioxide (ZrO2) and\ntantalum pentoxide (Ta2O5) will prove to be better AR coatings for broadband\nastronomical CCDs in the future and will open new avenues for understanding the\nevolution of the Milky Way."
    ],
    "c_categories":[
      [
        "astro-ph.IM",
        "physics.app-ph",
        "physics.ins-det",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-381",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09028",
    "b_title":[
      "Degradation-based Energy Management for Microgrids in the Presence of\n  Energy Storage Elements"
    ],
    "b_abstract":[
      "Integration of Inverter-based Resources (IBRs) such as solar-powered plants\nwhich lack the intrinsic characteristics such as the inertial response of the\ntraditional synchronous-generator (SG) based sources presents a new challenge\nin the form of analyzing the grid stability under their presence. For example,\nsolar power is available for approximately from 9 AM-5 PM. However, the result\nof the rise in power consumption after 6 PM and the reverting back to the\nnon-renewable source of power generation during that period puts immense stress\non the grid, testing the ramp limitations of the SGs. Failure to meet the\nrequired power demand due to SG ramp limitations leads to failure of the power\ngrid and other catastrophes. Numerous mitigation techniques exist in order to\naddress the ramping issues with adding the energy storage elements (ESE) to the\ngrid being one. ESEs have higher ramping capabilities compared to the\ntraditional SGs. Also, the ESEs can store the energy and supply it to the grid\nwhen required making them extremely responsive to high ramp situations.\nHowever, the rate of degradation of the ESEs is faster than the SGs. This\nraises an important issue of addressing the degradation of the ESEs while\nmeeting the required power demand objectives and constraints. This work\nproposes a battery degradation-aware model predictive energy management\nstrategy and it is tested via a numerical simulation on multiple physical\nsystems such as Shipboard Power Systems (SPS). Moreover, the risk arising due\nto the fault in the IBR is also studied by means of a numerical simulation.\nOverall, the goal of this study is to make the existing power grid more robust,\nresilient, and risk-free from component degradation and eventual failures."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00631",
    "c_title":[
      "Learning Automata of PLCs in Production Lines Using LSTM"
    ],
    "c_abstract":[
      "Production Lines and Conveying Systems are the staple of modern manufacturing\nprocesses. Manufacturing efficiency is directly related to the efficiency of\nthe means of production and conveying. Modelling in the industrial context has\nalways been a challenge due to the complexity that comes along with modern\nmanufacturing standards. Long Short-Term Memory is a pattern recognition\nRecurrent Neural Network, that is utilised on a simple pneumatic conveying\nsystem which transports a wooden block around the system. Recurrent Neural\nNetworks (RNNs) capture temporal dependencies through feedback loops, while\nLong Short-Term Memory (LSTM) networks enhance this capability by using gated\nmechanisms to effectively learn long-term dependencies. Conveying systems,\nrepresenting a major component of production lines, are chosen as the target to\nmodel to present an approach applicable in large scale production lines in a\nsimpler format. In this paper data from sensors are used to train the LSTM in\norder to output an Automaton that models the conveying system. The automaton\nobtained from the proposed LSTM approach is compared with the automaton\nobtained from OTALA. The resultant LSTM automaton proves to be a more accurate\nrepresentation of the conveying system, unlike the one obtained from OTALA."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-382",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02531",
    "b_title":[
      "Deep Linear Network Training Dynamics from Random Initialization: Data,\n  Width, Depth, and Hyperparameter Transfer"
    ],
    "b_abstract":[
      "We theoretically characterize gradient descent dynamics in deep linear\nnetworks trained at large width from random initialization and on large\nquantities of random data. Our theory captures the ``wider is better\" effect of\nmean-field\/maximum-update parameterized networks as well as hyperparameter\ntransfer effects, which can be contrasted with the neural-tangent\nparameterization where optimal learning rates shift with model width. We\nprovide asymptotic descriptions of both non-residual and residual neural\nnetworks, the latter of which enables an infinite depth limit when branches are\nscaled as $1\/\\sqrt{\\text{depth}}$. We also compare training with one-pass\nstochastic gradient descent to the dynamics when training data are repeated at\neach iteration. Lastly, we show that this model recovers the accelerated power\nlaw training dynamics for power law structured data in the rich regime observed\nin recent works."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07924",
    "c_title":[
      "NDAI Agreements"
    ],
    "c_abstract":[
      "We study a fundamental challenge in the economics of innovation: an inventor\nmust reveal details of a new idea to secure compensation or funding, yet such\ndisclosure risks expropriation. We present a model in which a seller (inventor)\nand buyer (investor) bargain over an information good under the threat of\nhold-up. In the classical setting, the seller withholds disclosure to avoid\nmisappropriation, leading to inefficiency. We show that trusted execution\nenvironments (TEEs) combined with AI agents can mitigate and even fully\neliminate this hold-up problem. By delegating the disclosure and payment\ndecisions to tamper-proof programs, the seller can safely reveal the invention\nwithout risking expropriation, achieving full disclosure and an efficient ex\npost transfer. Moreover, even if the invention's value exceeds a threshold that\nTEEs can fully secure, partial disclosure still improves outcomes compared to\nno disclosure. Recognizing that real AI agents are imperfect, we model \"agent\nerrors\" in payments or disclosures and demonstrate that budget caps and\nacceptance thresholds suffice to preserve most of the efficiency gains.\n  Our results imply that cryptographic or hardware-based solutions can function\nas an \"ironclad NDA,\" substantially mitigating the fundamental\ndisclosure-appropriation paradox first identified by Arrow (1962) and Nelson\n(1959). This has far-reaching policy implications for fostering R&D, technology\ntransfer, and collaboration."
    ],
    "c_categories":[
      [
        "cs.AI",
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-383",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14277",
    "b_title":[
      "Timing and spectral analysis of GK Persei during the 2010 dwarf nova\n  outburst"
    ],
    "b_abstract":[
      "GK Persei, an old nova and intermediate polar (IP), exhibited a dwarf nova\n(DN) outburst in 2010. This outburst was extensively observed by the Neil\nGehrels Swift Observatory, beginning 1.95 days after the eruption and\ncontinuing until 13.9 days before the maximum of the outburst in the optical.\nIn this paper, we present timing and spectral analyses, comparing the results\nwith those of other outbursts. We confirm the spin modulation in the 2 $-$ 10\nkeV X-ray range with a period of $P_{\\rm WD} = 351.325(9)$ s. Additionally, we\ndetected spin modulation in the 0.3 $-$ 2 keV band during the second half of\nthe observations, a feature not seen in the 2015 and 2018 outbursts. This\nfinding suggests that the soft X-ray emission in GK Per may originate partly\nnear the magnetic poles and partly from a wind or circumstellar material."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17836",
    "c_title":[
      "Clearing Sections of Lattice Liability Networks"
    ],
    "c_abstract":[
      "Modern financial networks involve complex obligations that transcend simple\nmonetary debts: multiple currencies, prioritized claims, supply chain\ndependencies, and more. We present a mathematical framework that unifies and\nextends these scenarios by recasting the classical Eisenberg-Noe model of\nfinancial clearing in terms of lattice liability networks. Each node in the\nnetwork carries a complete lattice of possible states, while edges encode\nnominal liabilities. Our framework generalizes the scalar-valued clearing\nvectors of the classical model to lattice-valued clearing sections, preserving\nthe elegant fixed-point structure while dramatically expanding its descriptive\npower. Our main theorem establishes that such networks possess clearing\nsections that themselves form a complete lattice under the product order. This\nstructure theorem enables tractable analysis of equilibria in diverse domains,\nincluding multi-currency financial systems, decentralized finance with\nautomated market makers, supply chains with resource transformation, and\npermission networks with complex authorization structures. We further extend\nour framework to chain-complete lattices for term structure models and\nmultivalued mappings for complex negotiation systems. Our results demonstrate\nhow lattice theory provides a natural language for understanding complex\nnetwork dynamics across multiple domains, creating a unified mathematical\nfoundation for analyzing systemic risk, resource allocation, and network\nstability."
    ],
    "c_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-384",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17202",
    "b_title":[
      "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators"
    ],
    "b_abstract":[
      "An ideal multimodal agent should be aware of the quality of its input\nmodalities. Recent advances have enabled large language models (LLMs) to\nincorporate auditory systems for handling various speech-related tasks.\nHowever, most audio LLMs remain unaware of the quality of the speech they\nprocess. This limitation arises because speech quality evaluation is typically\nexcluded from multi-task training due to the lack of suitable datasets. To\naddress this, we introduce the first natural language-based speech evaluation\ncorpus, generated from authentic human ratings. In addition to the overall Mean\nOpinion Score (MOS), this corpus offers detailed analysis across multiple\ndimensions and identifies causes of quality degradation. It also enables\ndescriptive comparisons between two speech samples (A\/B tests) with human-like\njudgment. Leveraging this corpus, we propose an alignment approach with LLM\ndistillation (ALLD) to guide the audio LLM in extracting relevant information\nfrom raw speech and generating meaningful responses. Experimental results\ndemonstrate that ALLD outperforms the previous state-of-the-art regression\nmodel in MOS prediction, with a mean square error of 0.17 and an A\/B test\naccuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of\n25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific\nmodels. This work advances the comprehensive perception of speech signals by\naudio LLMs, contributing to the development of real-world auditory and sensory\nintelligent agents."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09658",
    "c_title":[
      "A symmetry-protected topological optical lattice clock"
    ],
    "c_abstract":[
      "We theoretically propose a tunable implementation of symmetry-protected\ntopological phases in a synthetic superlattice, taking advantage of the long\ncoherence time and exquisite spectral resolutions offered by gravity-tilted\noptical lattice clocks. We describe a protocol similar to Rabi spectroscopy\nthat can be used to probe the distinct topological properties of our system. We\nthen demonstrate how the sensitivity of clocks and interferometers can be\nimproved by the topological robustness to unwanted experimental imperfections.\nThe proposed implementation opens a path to exploit the unique opportunities\noffered by symmetry-protected topological phases in state-of-the-art quantum\nsensors."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-385",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03665",
    "b_title":[
      "Lithographically-controlled liquid metal diffusion in graphene:\n  Fabrication and magneto-transport signatures of superconductivity"
    ],
    "b_abstract":[
      "Metal intercalation in epitaxial graphene enables the emergence of\nproximity-induced superconductivity and modified quantum transport properties.\nHowever, systematic transport studies of intercalated graphene have been\nhindered by challenges in device fabrication, including processing-induced\ndeintercalation and instability under standard lithographic techniques. Here,\nwe introduce a lithographically controlled intercalation approach that enables\nthe scalable fabrication of gallium-intercalated quasi-freestanding bilayer\ngraphene (QFBLG) Hall bar devices. By integrating lithographic structuring with\nsubsequent intercalation through dedicated intercalation channels, this method\nensures precise control over metal incorporation while preserving device\nintegrity. Magneto-transport measurements reveal superconductivity with a\ncritical temperature Tc,onset ~ 3.5 K and the occurrence of a transverse\nresistance, including both symmetric and antisymmetric field components, which\nis attributed to the symmetric-in-field component to non-uniform currents.\nThese results establish an advanced fabrication method for intercalated\ngraphene devices, providing access to systematic investigations of confined 2D\nsuperconductivity and emergent electronic phases in van der Waals\nheterostructures."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20902",
    "c_title":[
      "The Effect of Hop-count Modification Attack on Random Walk-based SLP\n  Schemes Developed forWSNs: a Study"
    ],
    "c_abstract":[
      "Source location privacy (SLP) has been of great concern in WSNs when deployed\nfor habitat monitoring applications. The issue is taken care of by employing\nprivacy-preserving routing schemes. In the existing works, the attacker is\nassumed to be passive in nature and backtracks to the source of information by\neavesdropping the message signals. In this work, we try to understand the\nimpact of active attacks by proposing a new hybrid attack model consisting of\nboth active and passive attacks. The proposed model is then applied to three\nexisting TTL-based random walk SLP solutions: phantom routing scheme (PRS),\nsource location privacy using randomized routes (SLP-R), and\nposition-independent section-based scheme (PSSLP). The performance of the\nalgorithms in terms of privacy metrics is compared in the case of pure passive\nattack and hybrid attack of varying intensity. The results indicate a\nsignificant degradation in the privacy protection performance of the reference\nalgorithms in the face of the proposed hybrid attack model indicating the\nimportance and relevance of such attacks. It is further observed that the\nhybrid attack can be optimized to increase the vulnerability of the existing\nsolutions."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-386",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16196",
    "b_title":[
      "Expediting quantum state transfer through long-range extended XY model"
    ],
    "b_abstract":[
      "Going beyond short-range interactions, we explore the role of long-range\ninteractions in the extended XY model for transferring quantum states through\nevolution. In particular, employing a spin-1\/2 chain with interactions decaying\nas a power law, we demonstrate that long-range interactions significantly\nenhance the efficiency of a quantum state transfer (QST) protocol, reducing the\nminimum time required to achieve fidelity beyond the classical limit. Our study\nidentifies the long-range regime as providing an optimal balance between\ninteraction range and transfer efficiency, outperforming the protocol with the\nshort-range interacting model. Our detailed analysis reveals the impact of\nsystem parameters, such as anisotropy, magnetic field strength, and\ncoordination number, on QST dynamics. Specifically, we find that intermediate\ncoordination numbers lead to a faster and more reliable state transfer, while\nextreme values diminish performance. Further, we exhibit that the presence of\nlong-range interactions also improves the achievable fidelity, mitigating its\ndecline associated with increasing system-size."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13718",
    "c_title":[
      "Multi-Scale and Multi-Objective Optimization for Cross-Lingual\n  Aspect-Based Sentiment Analysis"
    ],
    "c_abstract":[
      "Aspect-based sentiment analysis (ABSA) is a sequence labeling task that has\ngarnered growing research interest in multilingual contexts. However, recent\nstudies lack more robust feature alignment and finer aspect-level alignment. In\nthis paper, we propose a novel framework, Multi-Scale and Multi-Objective\noptimization (MSMO) for cross-lingual ABSA. During multi-scale alignment, we\nachieve cross-lingual sentence-level and aspect-level alignment, aligning\nfeatures of aspect terms in different contextual environments. Specifically, we\nintroduce code-switched bilingual sentences into the language discriminator and\nconsistency training modules to enhance the model's robustness. During\nmulti-objective optimization, we design two optimization objectives: supervised\ntraining and consistency training, aiming to enhance cross-lingual semantic\nalignment. To further improve model performance, we incorporate distilled\nknowledge of the target language into the model. Results show that MSMO\nsignificantly enhances cross-lingual ABSA by achieving state-of-the-art\nperformance across multiple languages and models."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-387",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15917",
    "b_title":[
      "RIS Assisted Wireless Communication: Advanced Modeling, Simulation, and\n  Analytical Insights"
    ],
    "b_abstract":[
      "This article presents a novel perspective to model and simulate\nreconfigurable intelligent surface (RIS)-assisted communication systems.\nTraditional methods in antenna design often rely on array method to simulate,\nwhereas communication system modeling tends to idealize antenna behavior.\nNeither approach sufficiently captures the detailed characteristics of\nRIS-assisted communication. To address this limitation, we propose a\ncomprehensive simulation framework that jointly models RIS antenna design and\nthe communication process. This framework simulates the entire communication\npipeline, encompassing signal generation, modulation, propagation, RIS-based\nradiation, signal reception, alignment, demodulation, decision, and processing.\nUsing a QPSK-modulated signal for validation, we analyze system performance and\ninvestigate the relationship between bit error rate (BER), aperture fill time,\narray size, and baseband symbol frequency. The results indicate that larger\narray sizes and higher baseband symbol frequencies exacerbate aperture fill\ntime effects, leading to increased BER. Furthermore, we examine BER variation\nwith respect to signal-to-noise ratio (SNR) and propose an optimal\nmatching-based alignment algorithm, which significantly reduces BER compared to\nconventional pilot-based alignment methods. This work demonstrates the entire\nprocess of RIS communication, and reveals the source of bit errors, which\nprovides valuable insights into the design and performance optimization of\nRIS-assisted communication systems."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13821",
    "c_title":[
      "Electron-Enabled Nanoparticle Diffraction"
    ],
    "c_abstract":[
      "We propose a scheme for generating high-mass quantum superposition states of\nan optically pre-cooled, levitated nanoparticle through electron diffraction at\nits sub-nanometer crystal lattice. When a single electron undergoes Bragg\ndiffraction at a free-falling nanoparticle, momentum conservation implies that\nthe superposition of Bragg momenta is imprinted onto the relative coordinate\nbetween electron and nanoparticle, which entangles their wavefunctions. By\nimaging the electron interferogram, one maps the nanoparticle state onto a\nsuperposition of Bragg momenta, as if it was diffracted by its own lattice.\nThis results in a coherent momentum splitting approximately 1000 times greater\nthan what is achievable with two-photon recoils in conventional standing-wave\ngratings. Self-interference of the nanoparticle can thus be observed within\ndrastically shorter free-fall times in a time-domain Talbot interferometer\nconfiguration, significantly relaxing source requirements and alleviating\ndecoherence from environmental factors such as residual gas and thermal\nradiation. Shorter interference times also allow for a recapture of the\nnanoparticle within its initial trapping volume, facilitating its reuse in many\nrapid experimental duty cycles. This opens new possibilities for experimental\ntests of macroscopic quantum effects within a transmission electron microscope."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-388",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18743",
    "b_title":[
      "Generation and Teleportation of three and four particle W state"
    ],
    "b_abstract":[
      "In this paper, we introduced circuits for three- and four-particle quantum\nsystems to generate W states with any arbitrary coefficients and phases.\nSubsequently, each qubit was transmitted separately through a four-qubit\nentangled channel. Before transmission, the sender performed pre-processing on\ntheir qubits to minimize the resources required for transmission. Additionally,\nthe receiver applied post-processing using the ancilla qubit(s) to recover the\nfinal states. To further improve efficiency, it is preferable to implement the\nprotocol in a bidirectional manner, as this allows the unknown qubits initially\nheld by the users to be utilized ancilla qubit(s). Finally, we compared our\nprotocol with similar works and validated the correctness of the protocol by\nsimulating it using Qiskit, a tool provided by IBM."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.07429",
    "c_title":[
      "From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector\n  Graphics"
    ],
    "c_abstract":[
      "Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-389",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18678",
    "b_title":[
      "NullSwap: Proactive Identity Cloaking Against Deepfake Face Swapping"
    ],
    "b_abstract":[
      "Suffering from performance bottlenecks in passively detecting high-quality\nDeepfake images due to the advancement of generative models, proactive\nperturbations offer a promising approach to disabling Deepfake manipulations by\ninserting signals into benign images. However, existing proactive perturbation\napproaches remain unsatisfactory in several aspects: 1) visual degradation due\nto direct element-wise addition; 2) limited effectiveness against face swapping\nmanipulation; 3) unavoidable reliance on white- and grey-box settings to\ninvolve generative models during training. In this study, we analyze the\nessence of Deepfake face swapping and argue the necessity of protecting source\nidentities rather than target images, and we propose NullSwap, a novel\nproactive defense approach that cloaks source image identities and nullifies\nface swapping under a pure black-box scenario. We design an Identity Extraction\nmodule to obtain facial identity features from the source image, while a\nPerturbation Block is then devised to generate identity-guided perturbations\naccordingly. Meanwhile, a Feature Block extracts shallow-level image features,\nwhich are then fused with the perturbation in the Cloaking Block for image\nreconstruction. Furthermore, to ensure adaptability across different identity\nextractors in face swapping algorithms, we propose Dynamic Loss Weighting to\nadaptively balance identity losses. Experiments demonstrate the outstanding\nability of our approach to fool various identity recognition models,\noutperforming state-of-the-art proactive perturbations in preventing face\nswapping models from generating images with correct source identities."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02716",
    "c_title":[
      "Relay synchronization and control of dynamics in multiplex networks with\n  unidirectional inter layer coupling"
    ],
    "c_abstract":[
      "Multiplex networks provide a proper framework for understanding the dynamics\nof complex systems with different types of interactions. In this study, we\nconsider the occurrence of different dynamical states in a multiplex network of\nnonlinear oscillators, with a drive layer and two identical response layers\nwhere the inter layer interactions are unidirectional. We report how the\ndirectionality in coupling can lead to relay synchronization with amplification\nin the two response layers, through the middle drive layer. Moreover, we find\nthat the dynamics of the response layers can be controlled by adjusting the\nstrength of inter layer coupling or tuning the dynamical time scale of the\ndrive layer. With nonidentical parameters between the drive and response\nlayers, the response layers get completely synchronized, with a functional\nrelation with the drive, indicating generalized synchronization between the\ndrive and response networks."
    ],
    "c_categories":[
      [
        "nlin.AO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-390",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17472",
    "b_title":[
      "Cosmic rays, gas and dust in the Central Molecular Zone I -- $X_{CO}$\n  factors, cosmic-ray densities and dust opacities"
    ],
    "b_abstract":[
      "Our goal is to estimate the total gas mass in the direction of the Central\nMolecular Zone (CMZ), quantify the various uncertainties associated, and\ndiscuss the implications for the estimates of CR energy densities and dust\nopacities. The $H_{\\rm{I}}$ 21 cm line and the carbon monoxide isotopes\n($^{12}\\rm{CO}$, $^{13}\\rm{CO}$ and $\\rm{C}^{18}\\rm{O}$) line emission maps are\nused to derive the total gas column density. The gas in the CMZ is separated\nfrom the disk contribution in position and velocity thanks to its different\nproperties in term of velocity dispersion and brightness ratio of CO isotopes.\nThe variations of the $X_{\\rm{CO}}$ factors are modelled relying on both\ntheoretical trends from simulations and empirical corrections. We use the new\ngas column density estimated together with gamma-ray and dust emission\nmeasurements to derive the CR energy density and dust opacities, respectively.\nThe $X_{\\rm{CO}}$ values in the CMZ range from $(0.32 - 1.37) \\ \\times$\n$10^{20}$ cm$^{-2}$ K$^{-1}$ km$^{-1}$ s, with a distribution that is highly\nasymmetric and skewed. The median value is $ \\rm{\\overline{X}_{CO}^{CMZ}} =\n0.39 \\ \\times$ $10^{20}$ cm$^{-2}$ K$^{-1}$ km$^{-1}$ s. The total gas mass in\nthe CMZ is estimated to be $2.3_{-0.3}^{+0.3}\\times10^{7} \\; \\rm{M_{\\odot}}$\nwith $\\sim 10 \\%$ contribution from the atomic phase. Without removing the disk\ncontamination the total mass is about twice higher, and the atomic gas fraction\nincreases to $\\sim30\\%$. The cosmic-ray (CR) energy density in the CMZ,\nassuming a 1\/r profile, is higher by a factor of two compared to the previous\ncalculations at TeV energies. Using molecular gas tracers which probes only the\ndensest molecular cores leads to an overestimation of the CR energy density,\nwhile ignoring the foreground\/background contribution leads to an\nunderestimation of the CR energy density in the CMZ."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03149",
    "c_title":[
      "Velocity Addition\/Subtraction in Special Relativity"
    ],
    "c_abstract":[
      "We reconsider velocity addition\/subtraction in Special Relativity and\nre-derive its well-known non-commutative and non-associative algebraic\nproperties in a self contained way, including various explicit expressions for\nthe Thomas angle, the derivation of which will be seen to be not as challenging\nas often suggested. All this is based on the polar-decomposition theorem in the\ntraditional component language, in which Lorentz transformations are ordinary\nmatrices. In the second part of this paper we offer a less familiar alternative\ngeometric view, that leads to an invariant definition of the concept of\nrelative velocity between two states of motion, which is based on the\nboost-link-theorem, of which we also offer an elementary proof that does not\nseem to be widely known in the relativity literature. Finally we compare this\nto the corresponding geometric definitions in Galilei-Newton spacetime,\nemphasising similarities and differences."
    ],
    "c_categories":[
      [
        "gr-qc",
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-391",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06806",
    "b_title":[
      "Logits are All We Need to Adapt Closed Models"
    ],
    "b_abstract":[
      "Many commercial Large Language Models (LLMs) are often closed-source,\nlimiting developers to prompt tuning for aligning content generation with\nspecific applications. While these models currently do not provide access to\ntoken logits, we argue that if such access were available, it would enable more\npowerful adaptation techniques beyond prompt engineering. In this paper, we\npropose a token-level probability reweighting framework that, given access to\nlogits and a small amount of task-specific data, can effectively steer\nblack-box LLMs toward application-specific content generation. Our approach\nviews next-token prediction through the lens of supervised classification. We\nshow that aligning black-box LLMs with task-specific data can be formulated as\na label noise correction problem, leading to \\emph{Plugin} model -- an\nautoregressive probability reweighting model that operates solely on logits. We\nprovide theoretical justification for why reweighting logits alone is\nsufficient for task adaptation. Extensive experiments with multiple datasets,\nLLMs, and reweighting models demonstrate the effectiveness of our method,\nadvocating for broader access to token logits in closed-source models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18059",
    "c_title":[
      "Quantum Wishlist: Lessons from Parton Showers"
    ],
    "c_abstract":[
      "We discuss general criteria that could guide us in applying quantum\nalgorithms\/computers to problems in high-energy physics. We then discuss the\nparticular example of parton showers with quantum interference. We summarize\nthe basic ideas behind the classical and quantum parton shower Monte Carlo\nalgorithms and highlight the importance of quantum\/classical hybrid algorithms.\nOur finding in quantum parton showers could serve as a useful case study for\nfurther exploration of quantum algorithms\/computers in high-energy physics."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-392",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14798",
    "b_title":[
      "Unlocking the Optoelectronic Potential of AGeX$_{3}$ (A = Ca, Sr, Ba; X\n  = S, Se): A Sustainable Alternative in Chalcogenide Perovskites"
    ],
    "b_abstract":[
      "The quest for environmentally benign and stable optoelectronic materials has\nintensified, and chalcogenide perovskites (CPs) have emerged as promising\ncandidates owing to their non-toxic composition, stability, small bandgaps,\nlarge absorption coefficients. However, a detailed theoretical study of\nexcitonic and polaronic properties of these materials remains underexplored due\nto high computational demands. Herein, we present a comprehensive theoretical\ninvestigation of Germanium-based CPs, AGeX$_{3}$ (A = Ca, Sr, Ba; X = S, Se),\nwhich adopt distorted perovskite structures (\\beta-phase) with an orthorhombic\ncrystal structure (space group : Pnma) by utilizing state-of-the-art density\nfunctional theory (DFT), density functional perturbation theory (DFPT), and\nmany-body perturbation theory (GW and Bethe-Salpeter equation). Our\ncalculations reveal that these materials are thermodynamically and mechanically\nstable, with the bandgaps calculated using G$_{0}$W$_{0}$@PBE ranging from\n0.646 to 2.001 eV - suitable for optoelectronic devices. We analyze the ionic\nand electronic contributions to dielectric screening using DFPT and BSE\nmethods, finding that the electronic component dominates. The exciton binding\nenergies range from 0.03 to 73.63 meV, indicating efficient exciton\ndissociation under ambient conditions. Additionally, these perovskites exhibit\nlow to high polaronic mobilities (1.67-167.65 cm$^{2}$V$^{-1}$s$^{-1}$),\nexceeding many lead-free CPs and halide perovskites due to reduced\ncarrier-phonon interactions. The unique combination of wide tunable bandgaps,\nlow exciton binding energies, and enhanced charge-carrier mobility highlights\nAGeX$_{3}$ as a potential material for next-generation optoelectronic\napplications. These compounds are stable, high-performing, and eco-friendly,\nshowing great promise for experimental realization and device integration."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08514",
    "c_title":[
      "Multimodal Fake News Video Explanation Generation: Dataset, Model, and\n  Evaluation"
    ],
    "c_abstract":[
      "Although existing methods have addressed fake news video detection as a\nclassification problem, it is not clear why certain news content is identified\nas fake. Without proper explanation, end users may not be able to understand\nthe potential meaning of fake news. Therefore, we propose a novel task, Fake\nNews Video Explanation (FNVE), to generate natural language explanations that\nreveal the falseness of news videos. To this end, we first developed ONVE and\nVTSE, two new datasets to explain fake news video posts. Then, we propose a\nMultimodal Relation Graph Transformer (MRGT) model to benchmark ONVE and VTSE.\nMRGT introduces a multimodal relation graph to comprehensively represent\nmultimodal relations and then introduces a BART-based decoder to explain\ngenerations. The experimental results show that the proposed MRGT outperforms\nthe strong baselines. In addition, the human evaluation on the annotated ONVE\nand VTSE also achieves high scores in terms of adequacy rating."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-393",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11446",
    "b_title":[
      "Global Exponential Stabilization for a Simplified Fluid-Particle\n  Interaction System"
    ],
    "b_abstract":[
      "This work considers a system coupling a viscous Burgers equation (aimed to\ndescribe a simplified model of $1D$ fluid flow) with the ODE describing the\nmotion of a point mass moving inside the fluid. The point mass is possibly\nunder the action of a feedback control. Our main contributions are that we\nprove two global exponential stability results. More precisely, we first show\nthat the velocity field corresponding to the free dynamics case is globally\nexponentially stable. We next show that, in the presence of the feedback\ncontrol both the velocity field and the distance from the mass point to a\nprescribed target position decay exponentially. The proofs of these results\nheavily rely on the use of a special test function allowing both to prove that\nthe mass point stays away from the boundary and to construct a perturbed\nLyapunov function."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12352",
    "c_title":[
      "Test-time regression: a unifying framework for designing sequence models\n  with associative memory"
    ],
    "c_abstract":[
      "Sequences provide a remarkably general way to represent and process\ninformation. This powerful abstraction has placed sequence modeling at the\ncenter of modern deep learning applications, inspiring numerous architectures\nfrom transformers to recurrent networks. While this fragmented development has\nyielded powerful models, it has left us without a unified framework to\nunderstand their fundamental similarities and explain their effectiveness. We\npresent a unifying framework motivated by an empirical observation: effective\nsequence models must be able to perform associative recall. Our key insight is\nthat memorizing input tokens through an associative memory is equivalent to\nperforming regression at test-time. This regression-memory correspondence\nprovides a framework for deriving sequence models that can perform associative\nrecall, offering a systematic lens to understand seemingly ad-hoc architectural\nchoices. We show numerous recent architectures -- including linear attention\nmodels, their gated variants, state-space models, online learners, and softmax\nattention -- emerge naturally as specific approaches to test-time regression.\nEach architecture corresponds to three design choices: the relative importance\nof each association, the regressor function class, and the optimization\nalgorithm. This connection leads to new understanding: we provide theoretical\njustification for QKNorm in softmax attention, and we motivate higher-order\ngeneralizations of softmax attention. Beyond unification, our work unlocks\ndecades of rich statistical tools that can guide future development of more\npowerful yet principled sequence models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-394",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02790",
    "b_title":[
      "Segmenting Text and Learning Their Rewards for Improved RLHF in Language\n  Model"
    ],
    "b_abstract":[
      "Reinforcement learning from human feedback (RLHF) has been widely adopted to\nalign language models (LMs) with human preference. Prior RLHF works typically\ntake a bandit formulation, which, though intuitive, ignores the sequential\nnature of LM generation and can suffer from the sparse reward issue. While\nrecent works propose dense token-level RLHF, treating each token as an action\nmay be oversubtle to proper reward assignment. In this paper, we seek to get\nthe best of both by training and utilizing a segment-level reward model, which\nassigns a reward to each semantically complete text segment that spans over a\nshort sequence of tokens. For reward learning, our method allows dynamic text\nsegmentation and compatibility with standard sequence-preference datasets. For\neffective RL-based LM training against segment reward, we generalize the\nclassical scalar bandit reward normalizers into location-aware normalizer\nfunctions and interpolate the segment reward for further densification. With\nthese designs, our method performs competitively on three popular RLHF\nbenchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation\nstudies are conducted to further demonstrate our method."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06615",
    "c_title":[
      "Contractive projections on $H^p$-spaces"
    ],
    "c_abstract":[
      "This paper investigates contractive projections on closed subspaces $X$ of\n$L^p$ with $0<p<\\infty$. One of the main results states that, subject to\ncertain mild conditions, every contractive projection $P$ on $X$ preserving\nconstants coincides with a conditional expectation on $L^\\infty \\cap\nP^{-1}(L^\\infty)$. It results in some interesting applications concerning\ncontractive idempotent coefficient multipliers for analytic function spaces and\ntranslation-invariant subspaces of $L^p(G),$ where $G$ is a compact Abelian\ngroup. Focusing specifically on descriptions of boundedness and contractivity\nof conditional expectations on the Hardy space $H^p(\\mathbb{T})$ with $0<p<1$,\nwe give a complete characterization of contractive idempotent coefficient\nmultipliers for $H^p(\\mathbb{T}^d)$ with $0<p<1$, which complements a\nremarkable result due to Brevig, Ortega-Cerd\\`{a}, and Seip characterizing such\nmultipliers on $H^p(\\mathbb{T}^d)$ for $1\\leq p \\leq \\infty$."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-395",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01064",
    "b_title":[
      "Scientific Reasoning: Assessment of Multimodal Generative LLMs"
    ],
    "b_abstract":[
      "Large language models (LLMs) can answer questions and reason about complex\ntasks, also from the scientific domain. We assess several multimodal LLMs\n(MLLMs) on ScienceQA and find that Gemini models show the highest accuracy with\nlittle context, and the highest textual similarity to human explanations with\nricher context. Adapter-tuning of smaller MLLMs did not lead to any reliable\nperformance. Training from Gemini outputs consistently underperformed training\nfrom the original data."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04257",
    "c_title":[
      "Statistical estimation of a mean-field FitzHugh-Nagumo model"
    ],
    "c_abstract":[
      "We consider an interacting system of particles with value in $\\mathbb{R}^d\n\\times \\mathbb{R}^d$, governed by transport and diffusion on the first\ncomponent, on that may serve as a representative model for kinetic models with\na degenerate component. In a first part, we control the fluctuations of the\nempirical measure of the system around the solution of the corresponding\nVlasov-Fokker-Planck equation by proving a Bernstein concentration inequality,\nextending a previous result of arXiv:2011.03762 in several directions. In a\nsecond part, we study the nonparametric statistical estimation of the classical\nsolution of Vlasov-Fokker-Planck equation from the observation of the empirical\nmeasure and prove an oracle inequality using the Goldenshluger-Lepski\nmethodology and we obtain minimax optimality. We then specialise on the\nFitzHugh-Nagumo model for populations of neurons. We consider a version of the\nmodel proposed in Mischler et al. arXiv:1503.00492 an optimally estimate the\n$6$ parameters of the model by moment estimators."
    ],
    "c_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-396",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03152",
    "b_title":[
      "QCD Equation of State with Strong Magnetic Fields and Nonzero Baryon\n  Density"
    ],
    "b_abstract":[
      "In this work, we have carried out lattice simulations of $(2+1)$-flavor QCD\nusing highly improved staggered quarks at the physical pion mass on $32^3\n\\times 8$ and $48^3 \\times 12$ lattices, with magnetic field strengths ranging\nup to 0.8 GeV$^2$ and nonzero baryon chemical potentials employing the Taylor\nexpansion framework. We present lattice QCD continuum estimate results, along\nwith the magnetized hadron resonance and ideal gas comparisons, for the\nleading-order Taylor expansion coefficients for bulk thermodynamic quantities\nsuch as pressure, number density, energy density, and entropy density, focusing\non the significant impact of strong magnetic fields."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20302",
    "c_title":[
      "Finite Fourier series. The class of trigonometric splines"
    ],
    "c_abstract":[
      "Finite trigonometric Fourier series on a set of discrete equidistant points\nare considered. A finite system of orthogonal functions that have interpolation\nand certain differential properties on the period is introduced. Finite Fourier\nseries based on this system of functions form a class of trigonometric splines,\nwhich includes polynomial periodic simple splines. Trigonometric splines\nsuggest generalizations in several directions and certainly require further\nresearch."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-397",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19477",
    "b_title":[
      "Causality Bounds on the Primordial Power Spectrum"
    ],
    "b_abstract":[
      "Effective field theories (EFTs) parametrize our ignorance of the underlying\nUV theory through their Wilson coefficients. However, not all values of these\ncoefficients are consistent with fundamental physical principles. In this\npaper, we explore the consequences of imposing causal propagation on the\ncomoving curvature perturbation in the EFT of inflation, particularly its\nimpact on the primordial power spectrum and the effective sound speed\n$c_s^\\text{eff}$. We investigate scenarios where $c_s^\\text{eff}$ undergoes a\ntransition, remaining consistent with CMB constraints at early times but later\nexperiencing a drastic change, becoming highly subluminal. Such scenarios allow\nthe primordial power spectrum to grow at small scales, potentially leading to\nthe formation of primordial black holes or the generation of scalar-induced\ngravitational waves. We find the generic feature that in a causal theory,\nluminal sound speeds imply a free theory, effectively constraining the\ndynamics. Additionally, we obtain that when considering natural values for the\nWilson coefficients, maintaining the validity of the EFT and the weakly coupled\nregime, and enforcing causal propagation of the EFT modes, the power spectrum\ncannot increase drastically. This imposes significant constraints on the\nparameter space of models aiming to produce such features."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.14338",
    "c_title":[
      "Correlation-Based Band Selection for Hyperspectral Image Classification"
    ],
    "c_abstract":[
      "Hyperspectral images offer extensive spectral information about ground\nobjects across multiple spectral bands. However, the large volume of data can\npose challenges during processing. Typically, adjacent bands in hyperspectral\ndata are highly correlated, leading to the use of only a few selected bands for\nvarious applications. In this work, we present a correlation-based band\nselection approach for hyperspectral image classification. Our approach\ncalculates the average correlation between bands using correlation coefficients\nto identify the relationships among different bands. Afterward, we select a\nsubset of bands by analyzing the average correlation and applying a\nthreshold-based method. This allows us to isolate and retain bands that exhibit\nlower inter-band dependencies, ensuring that the selected bands provide diverse\nand non-redundant information. We evaluate our proposed approach on two\nstandard benchmark datasets: Pavia University (PA) and Salinas Valley (SA),\nfocusing on image classification tasks. The experimental results demonstrate\nthat our method performs competitively with other standard band selection\napproaches."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-398",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17117",
    "b_title":[
      "A New Statistical Model of Star Speckles for Learning to Detect and\n  Characterize Exoplanets in Direct Imaging Observations"
    ],
    "b_abstract":[
      "The search for exoplanets is an active field in astronomy, with direct\nimaging as one of the most challenging methods due to faint exoplanet signals\nburied within stronger residual starlight. Successful detection requires\nadvanced image processing to separate the exoplanet signal from this nuisance\ncomponent. This paper presents a novel statistical model that captures nuisance\nfluctuations using a multi-scale approach, leveraging problem symmetries and a\njoint spectral channel representation grounded in physical principles. Our\nmodel integrates into an interpretable, end-to-end learnable framework for\nsimultaneous exoplanet detection and flux estimation. The proposed algorithm is\nevaluated against the state of the art using datasets from the SPHERE\ninstrument operating at the Very Large Telescope (VLT). It significantly\nimproves the precision-recall trade-off, notably on challenging datasets that\nare otherwise unusable by astronomers. The proposed approach is computationally\nefficient, robust to varying data quality, and well suited for large-scale\nobservational surveys."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.CV",
        "cs.LG",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17891",
    "c_title":[
      "Non-Markovian effects on the steady state properties of a damped\n  harmonic oscillator"
    ],
    "c_abstract":[
      "We analyze the steady-state characteristics of a damped harmonic oscillator\n(system) in presence of a non-Markovian bath characterized by Lorentzian\nspectral density. Although Markovian baths presume memoryless dynamics, the\nintroduction of complex temporal connections by a non-Markovian environment\nradically modifies the dynamics of the system and its steady-state behaviour.\nWe obtain the steady-state Green's functions and correlation functions of the\nsystem using the Schwinger-Keldysh formalism. In both rotating and non-rotating\nwave approximation, we analyzed various emergent properties like effective\ntemperature and distribution function. We also explore the impact of\ndissipation and non-Markovian bath on the quantum Zeno and anti-Zeno effects.\nWe show that a transition between Zeno to anti-Zeno effect can be tuned by bath\nspectral width and the strength of dissipation."
    ],
    "c_categories":[
      [
        "cond-mat.other",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-399",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11065",
    "b_title":[
      "Low-cost Real-world Implementation of the Swing-up Pendulum for Deep\n  Reinforcement Learning Experiments"
    ],
    "b_abstract":[
      "Deep reinforcement learning (DRL) has had success in virtual and simulated\ndomains, but due to key differences between simulated and real-world\nenvironments, DRL-trained policies have had limited success in real-world\napplications. To assist researchers to bridge the \\textit{sim-to-real gap}, in\nthis paper, we describe a low-cost physical inverted pendulum apparatus and\nsoftware environment for exploring sim-to-real DRL methods. In particular, the\ndesign of our apparatus enables detailed examination of the delays that arise\nin physical systems when sensing, communicating, learning, inferring and\nactuating. Moreover, we wish to improve access to educational systems, so our\napparatus uses readily available materials and parts to reduce cost and\nlogistical barriers. Our design shows how commercial, off-the-shelf electronics\nand electromechanical and sensor systems, combined with common metal\nextrusions, dowel and 3D printed couplings provide a pathway for affordable\nphysical DRL apparatus. The physical apparatus is complemented with a simulated\nenvironment implemented using a high-fidelity physics engine and OpenAI Gym\ninterface."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18081",
    "c_title":[
      "Charged-particle multiplicity distributions over a wide pseudorapidity\n  range in p-Pb collisions at $\\mathbf{\\sqrt{s}_{\\rm NN} = 5.02}$ TeV"
    ],
    "c_abstract":[
      "This paper presents the primary charged-particle multiplicity distributions\nin proton-lead collisions at a centre-of-mass energy per nucleon-nucleon\ncollision of $\\sqrt{s_{\\rm NN}} = 5.02$ TeV. The distributions are reported for\nnon-single diffractive collisions in different pseudorapidity ranges. The\nmeasurements are performed using the combined information from the Silicon\nPixel Detector and the Forward Multiplicity Detector of ALICE. The multiplicity\ndistributions are parametrised with a double negative binomial distribution\nfunction which provides satisfactory descriptions of the distributions for all\nthe studied pseudorapidity intervals. The data are compared to models and\nanalysed quantitatively, evaluating the first four moments (mean, standard\ndeviation, skewness, and kurtosis). The shape evolution of the measured\nmultiplicity distributions is studied in terms of KNO variables and it is found\nthat none of the considered models reproduces the measurements. This paper also\nreports on the average charged-particle multiplicity, normalised by the average\nnumber of participating nucleon pairs, as a function of the collision energy.\nThe multiplicity results are then compared to measurements made in\nproton-proton and nucleus-nucleus collisions across a wide range of collision\nenergies."
    ],
    "c_categories":[
      [
        "hep-ex",
        "nucl-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-400",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04907",
    "b_title":[
      "Prospects of future MeV telescopes in probing weak-scale Dark Matter"
    ],
    "b_abstract":[
      "Galactic weak-scale Dark Matter (DM) particles annihilating into lepton-rich\nchannels not only produce gamma-rays via prompt radiation but also generate\nabundant energetic electrons and positrons, which subsequently emit through\nbremsstrahlung or inverse Compton scattering (collectively called\n`secondary-radiation photons'). While the prompt gamma-rays concentrate at\nhigh-energy, the secondary emission falls in the MeV range, which a number of\nupcoming experiments (AMEGO, E-ASTROGAM, MAST...) will probe. We investigate\nthe sensitivity of these future telescopes for weak-scale DM, focusing for\ndefiniteness on observations of the galactic center. We find that they have the\npotential of probing a wide region of the DM parameter space which is currently\nunconstrained. Namely, in rather optimistic configurations, future MeV\ntelescopes could probe thermally-produced DM with a mass up to the TeV range,\nor GeV DM with an annihilation cross section 2 to 3 orders of magnitude smaller\nthan the current bounds, precisely thanks to the significant leverage provided\nby their sensitivity to secondary emissions. We comment on astrophysical and\nmethodological uncertainties, and compare with the reach of high-energy gamma\nray experiments."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12294",
    "c_title":[
      "The Lucie-7B LLM and the Lucie Training Dataset: Open resources for\n  multilingual language generation"
    ],
    "c_abstract":[
      "We present both the Lucie Training Dataset and the Lucie-7B foundation model.\nThe Lucie Training Dataset is a multilingual collection of textual corpora\ncentered around French and designed to offset anglo-centric biases found in\nmany datasets for large language model pretraining. Its French data is pulled\nnot only from traditional web sources, but also from French cultural heritage\ndocuments, filling an important gap in modern datasets. Beyond French, which\nmakes up the largest share of the data, we added documents to support several\nother European languages, including English, Spanish, German, and Italian.\nApart from its value as a resource for French language and culture, an\nimportant feature of this dataset is that it prioritizes data rights by\nminimizing copyrighted material. In addition, building on the philosophy of\npast open projects, it is redistributed in the form used for training and its\nprocessing is described on Hugging Face and GitHub. The Lucie-7B foundation\nmodel is trained on equal amounts of data in French and English -- roughly 33%\neach -- in an effort to better represent cultural aspects of French-speaking\ncommunities. We also describe two instruction fine-tuned models,\nLucie-7B-Instruct-v1.1 and Lucie-7B-Instruct-human-data, which we release as\ndemonstrations of Lucie-7B in use. These models achieve promising results\ncompared to state-of-the-art models, demonstrating that an open approach\nprioritizing data rights can still deliver strong performance. We see these\nmodels as an initial step toward developing more performant, aligned models in\nthe near future. Model weights for Lucie-7B and the Lucie instruct models,\nalong with intermediate checkpoints for the former, are published on Hugging\nFace, while model training and data preparation code is available on GitHub.\nThis makes Lucie-7B one of the first OSI compliant language models according to\nthe new OSI definition."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-401",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09083",
    "b_title":[
      "Ion densities of cold clouds driven by galactic outflows"
    ],
    "b_abstract":[
      "Observations of the circumgalactic medium (CGM) often display coincident\nabsorption from species with widely varying ionization states, providing direct\nevidence for complex, multiphase interactions. Motivated by these measurements,\nwe perform a series of cloud-crushing simulations that model cold clouds\ntraveling through the hot CGM. We analyze the ion distributions of these\nclouds, generate mock absorption spectra, and study their implications on\nquasar (QSO) absorption observations. Our results show interesting multiphase\nfeatures, in which ions with significantly different ionization potentials\nexist in the same absorber and share similar spectral features. However, our\nsimulations are unable to explain high ions like O \\textsc{vi} and their\ncoexistence with lower ions that appear in many observed QSO absorption\nsystems."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11183",
    "c_title":[
      "Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming\n  Tree Search Exploration Pitfalls"
    ],
    "c_abstract":[
      "Recent advancements in tree search algorithms guided by verifiers have\nsignificantly enhanced the reasoning capabilities of large language models\n(LLMs), but at the cost of increased computational resources. In this work, we\nidentify two key challenges contributing to this inefficiency:\n$\\textit{over-exploration}$ due to redundant states with semantically\nequivalent content, and $\\textit{under-exploration}$ caused by high variance in\nverifier scoring leading to frequent trajectory switching. To address these\nissues, we propose FETCH, an e$\\textbf{f}$fici$\\textbf{e}$nt $\\textbf{t}$ree\nsear$\\textbf{ch}$ framework, which is a flexible, plug-and-play system\ncompatible with various tree search algorithms. Our framework mitigates\nover-exploration by merging semantically similar states using agglomerative\nclustering of text embeddings obtained from a fine-tuned SimCSE model. To\ntackle under-exploration, we enhance verifiers by incorporating temporal\ndifference learning with adjusted $\\lambda$-returns during training to reduce\nvariance, and employing a verifier ensemble to aggregate scores during\ninference. Experiments on GSM8K, GSM-Plus, and MATH datasets demonstrate that\nour methods significantly improve reasoning accuracy and computational\nefficiency across four different tree search algorithms, paving the way for\nmore practical applications of LLM-based reasoning. The code is available at\nhttps:\/\/github.com\/Soistesimmer\/Fetch."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-402",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18884",
    "b_title":[
      "Deterministic carving of quantum states with Grover's algorithm"
    ],
    "b_abstract":[
      "We show that iteration of a few ( $\\sim N^{1\/4}$) unitary steps of Grover's\nalgorithm suffices to perfectly prepare a Dicke state of $N$ atoms in a cavity.\nWe also show that a few subsequent Grover steps can be employed to generate GHZ\nand Cat states. The Grover iteration is physically realized by global qubit\nrotations and by the phase shift of single photons reflected on the cavity. Our\nprotocols are deterministic and require no individual addressing of the atoms.\nA detailed error analysis accounting for spatial mode matching of the photon to\nthe cavity, spontaneous emission, mirror scattering, and the finite bandwidth\nof the photon mode is used to predict the fidelity of the prepared states as a\nfunction of system parameters and atom-cavity cooperativity. The fidelity can\nbe increased by heralding on detection of the reflected photon."
    ],
    "b_categories":[
      [
        "physics.atom-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11213",
    "c_title":[
      "Risk Analysis of Flowlines in the Oil and Gas Sector: A GIS and Machine\n  Learning Approach"
    ],
    "c_abstract":[
      "This paper presents a risk analysis of flowlines in the oil and gas sector\nusing Geographic Information Systems (GIS) and machine learning (ML).\nFlowlines, vital conduits transporting oil, gas, and water from wellheads to\nsurface facilities, often face under-assessment compared to transmission\npipelines. This study addresses this gap using advanced tools to predict and\nmitigate failures, improving environmental safety and reducing human exposure.\nExtensive datasets from the Colorado Energy and Carbon Management Commission\n(ECMC) were processed through spatial matching, feature engineering, and\ngeometric extraction to build robust predictive models. Various ML algorithms,\nincluding logistic regression, support vector machines, gradient boosting\ndecision trees, and K-Means clustering, were used to assess and classify risks,\nwith ensemble classifiers showing superior accuracy, especially when paired\nwith Principal Component Analysis (PCA) for dimensionality reduction. Finally,\na thorough data analysis highlighted spatial and operational factors\ninfluencing risks, identifying high-risk zones for focused monitoring. Overall,\nthe study demonstrates the transformative potential of integrating GIS and ML\nin flowline risk management, proposing a data-driven approach that emphasizes\nthe need for accurate data and refined models to improve safety in petroleum\nextraction."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-403",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16474",
    "b_title":[
      "From Voices to Worlds: Developing an AI-Powered Framework for 3D Object\n  Generation in Augmented Reality"
    ],
    "b_abstract":[
      "This paper presents Matrix, an advanced AI-powered framework designed for\nreal-time 3D object generation in Augmented Reality (AR) environments. By\nintegrating a cutting-edge text-to-3D generative AI model, multilingual\nspeech-to-text translation, and large language models (LLMs), the system\nenables seamless user interactions through spoken commands. The framework\nprocesses speech inputs, generates 3D objects, and provides object\nrecommendations based on contextual understanding, enhancing AR experiences. A\nkey feature of this framework is its ability to optimize 3D models by reducing\nmesh complexity, resulting in significantly smaller file sizes and faster\nprocessing on resource-constrained AR devices. Our approach addresses the\nchallenges of high GPU usage, large model output sizes, and real-time system\nresponsiveness, ensuring a smoother user experience. Moreover, the system is\nequipped with a pre-generated object repository, further reducing GPU load and\nimproving efficiency. We demonstrate the practical applications of this\nframework in various fields such as education, design, and accessibility, and\ndiscuss future enhancements including image-to-3D conversion, environmental\nobject detection, and multimodal support. The open-source nature of the\nframework promotes ongoing innovation and its utility across diverse\nindustries."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09444",
    "c_title":[
      "Beta-Functions and RG flows for Holographic QCD with Heavy and Light\n  Quarks: Isotropic case"
    ],
    "c_abstract":[
      "In a previous paper [arXiv:2402.14512v3], we investigated the dependence of\nthe running coupling constant on temperature and chemical potential for\nholographic models of the light and heavy quarks, supported by an\nEinstein-dilaton-Maxwell action. In this paper, we study the dependence of the\ncorresponding $\\beta$-functions on the temperature and the chemical potential.\nAs in the previous paper, we give special attention to the behavior of the\n$\\beta$-functions near the 1st order phase transitions. We consider different\ntypes of boundary conditions for the dilaton. Only one of the possible boundary\nconditions yields results that agree with lattice calculations at zero chemical\npotential. The corresponding $\\beta$-functions are negative and exhibit jumps\nat the 1st order phase transitions. We also show that the RG fluxes are\ninvariant with respect to the choice of the boundary conditions and that our\nexact solutions for the light and heavy quarks are unstable, as expected, given\ntheir negative dilaton potentials."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-404",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00398",
    "b_title":[
      "Monitoring AGNs with H$\\beta$ Asymmetry. V. Long-term Variation and\n  Evolution of the Broad H$\\beta$ Emission-Line Profiles"
    ],
    "b_abstract":[
      "The physical origins of the diverse emission-line asymmetries observed in the\nspectra of active galactic nuclei (AGNs) remain incompletely understood.\nMonitoring the temporal variations of line profiles offers a promising approach\nto investigating the underlying physics. In this study, we present an analysis\nof the broad H$\\beta$ emission line profiles of eight AGNs observed from the\nend of 2016 to May 2023 as part of the reverberation mapping campaign titled\n\"Monitoring AGNs with H$\\beta$ Asymmetry\" (MAHA), utilizing data obtained from\nthe Wyoming Infrared Observatory (WIRO) 2.3-meter telescope. We measure the\ntemporal variations of line asymmetry, width, and central velocity shift for\nthe eight objects. Our findings reveal that the variation in asymmetry is\npositively correlated with H$\\beta$ flux in five of the eight objects, while\nthe remaining objects exhibit negative or complex correlations. Furthermore, we\nobserve anti-correlations between line width and H$\\beta$ flux for most\nobjects, indicating the presence of the \"breathing\" phenomenon in their\nH$\\beta$ emission lines. In contrast, two objects demonstrate an\n\"anti-breathing\" phenomenon or complex behavior. We discuss the physical\norigins of the temporal variations in line profiles and propose the possibility\nof decomposing the variations in H$\\beta$ asymmetry and width into components:\none that corresponds to short-term variations in H$\\beta$ flux and another that\nreflects long-term variations in continuum light curves, perhaps driven by\nradiation pressure."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11126",
    "c_title":[
      "MUSS: Multilevel Subset Selection for Relevance and Diversity"
    ],
    "c_abstract":[
      "The problem of relevant and diverse subset selection has a wide range of\napplications, including recommender systems and retrieval-augmented generation\n(RAG). For example, in recommender systems, one is interested in selecting\nrelevant items, while providing a diversified recommendation. Constrained\nsubset selection problem is NP-hard, and popular approaches such as Maximum\nMarginal Relevance (MMR) are based on greedy selection. Many real-world\napplications involve large data, but the original MMR work did not consider\ndistributed selection. This limitation was later addressed by a method called\nDGDS which allows for a distributed setting using random data partitioning.\nHere, we exploit structure in the data to further improve both scalability and\nperformance on the target application. We propose MUSS, a novel method that\nuses a multilevel approach to relevant and diverse selection. We provide a\nrigorous theoretical analysis and show that our method achieves a constant\nfactor approximation of the optimal objective. In a recommender system\napplication, our method can achieve the same level of performance as baselines,\nbut 4.5 to 20 times faster. Our method is also capable of outperforming\nbaselines by up to 6 percent points of RAG-based question answering accuracy."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-405",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07334",
    "b_title":[
      "Anonymization of Documents for Law Enforcement with Machine Learning"
    ],
    "b_abstract":[
      "The steadily increasing utilization of data-driven methods and approaches in\nareas that handle sensitive personal information such as in law enforcement\nmandates an ever increasing effort in these institutions to comply with data\nprotection guidelines. In this work, we present a system for automatically\nanonymizing images of scanned documents, reducing manual effort while ensuring\ndata protection compliance. Our method considers the viability of further\nforensic processing after anonymization by minimizing automatically redacted\nareas by combining automatic detection of sensitive regions with knowledge from\na manually anonymized reference document. Using a self-supervised image model\nfor instance retrieval of the reference document, our approach requires only\none anonymized example to efficiently redact all documents of the same type,\nsignificantly reducing processing time. We show that our approach outperforms\nboth a purely automatic redaction system and also a naive copy-paste scheme of\nthe reference anonymization to other documents on a hand-crafted dataset of\nground truth redactions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00438",
    "c_title":[
      "Effect of a repulsive three-body interaction on the $DD^{(*)}K$ molecule"
    ],
    "c_abstract":[
      "The hadronic molecular picture of the observed exotic states has inspired\nnumerous investigations into few-body systems. Recently, the lattice effective\nfield theory studied the effect of a three-body interaction on the binding\nenergy of the $DD^{*}K$ system, revealing an intriguing phenomenon in the\nbinding energy. This work uses the Gaussian expansion method to explore the\nunderlying physics. Our results show that as the repulsive three-body\ninteraction strengthens, the spatial size of the $DD^{(*)}K$ bound state\ngradually increases. Further enhancement of the three-body interaction causes\nthe $DD^{(*)}K$ three-body bound state to break into a $D^{(*)}K$ two-body\nbound state, accompanied by a distant $D$ meson. The identical nature of the\ntwo $D$ mesons leads to the fact that the $DDK$ system consistently resembles\nan isosceles triangle-shaped spatial configuration."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-406",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06914",
    "b_title":[
      "Spin of fractional quantum Hall neutral modes and \"missing states\" on a\n  sphere"
    ],
    "b_abstract":[
      "A low-energy neutral quasiparticle in a fractional quantum Hall system\nappears in the latter's energy spectrum on a sphere as a series of many-body\nexcited states labeled by the angular momentum $L$ and whose energy is a smooth\nfunction of $L$ in the limit of large sphere radius. We argue that the\nsignature of a nonvanishing spin (intrinsic angular momentum) $s$ of the\nquasiparticle is the absence, in this series, of states with total angular\nmomentum less than $s$.We reinterpret the missing of certain states, observed\nin an exact-diagonalization calculation of the spectrum of the $\\nu=7\/3$ FQH\nstate in a wide quantum well as well as in many proposed wave functions for the\nexcited states as a consequence of the spin-2 nature of the zero-momentum\nmagnetoroton."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05156",
    "c_title":[
      "State-Based Disassembly Planning"
    ],
    "c_abstract":[
      "It has been shown recently that physics-based simulation significantly\nenhances the disassembly capabilities of real-world assemblies with diverse 3D\nshapes and stringent motion constraints. However, the efficiency suffers when\ntackling intricate disassembly tasks that require numerous simulations and\nincreased simulation time. In this work, we propose a State-Based Disassembly\nPlanning (SBDP) approach, prioritizing physics-based simulation with\ntranslational motion over rotational motion to facilitate autonomy, reducing\ndependency on human input, while storing intermediate motion states to improve\nsearch scalability. We introduce two novel evaluation functions derived from\nnew Directional Blocking Graphs (DBGs) enriched with state information to scale\nup the search. Our experiments show that SBDP with new evaluation functions and\nDBGs constraints outperforms the state-of-the-art in disassembly planning in\nterms of success rate and computational efficiency over benchmark datasets\nconsisting of thousands of physically valid industrial assemblies."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-407",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17967",
    "b_title":[
      "A fully adaptive, high-order, fast Poisson solver for complex\n  two-dimensional geometries"
    ],
    "b_abstract":[
      "We present a new framework for the fast solution of inhomogeneous elliptic\nboundary value problems in domains with smooth boundaries. High-order solvers\nbased on adaptive box codes or the fast Fourier transform can efficiently treat\nthe volumetric inhomogeneity, but require care to be taken near the boundary to\nensure that the volume data is globally smooth. We avoid function extension or\ncut-cell quadratures near the boundary by dividing the domain into two regions:\na bulk region away from the boundary that is efficiently treated with a\ntruncated free-space box code, and a variable-width boundary-conforming strip\nregion that is treated with a spectral collocation method and accompanying fast\ndirect solver. Particular solutions in each region are then combined with\nLaplace layer potentials to yield the global solution. The resulting solver has\nan optimal computational complexity of $O(N)$ for an adaptive discretization\nwith $N$ degrees of freedom. With an efficient two-dimensional (2D)\nimplementation we demonstrate adaptive resolution of volumetric data, boundary\ndata, and geometric features across a wide range of length scales, to typically\n10-digit accuracy. The cost of all boundary corrections remains small relative\nto that of the bulk box code. The extension to 3D is expected to be\nstraightforward in many cases because the strip ``thickens'' an existing\nboundary quadrature."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14779",
    "c_title":[
      "DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image\n  Generation with Diffusion Models"
    ],
    "c_abstract":[
      "In this paper, we introduce DC (Decouple)-ControlNet, a highly flexible and\nprecisely controllable framework for multi-condition image generation. The core\nidea behind DC-ControlNet is to decouple control conditions, transforming\nglobal control into a hierarchical system that integrates distinct elements,\ncontents, and layouts. This enables users to mix these individual conditions\nwith greater flexibility, leading to more efficient and accurate image\ngeneration control. Previous ControlNet-based models rely solely on global\nconditions, which affect the entire image and lack the ability of element- or\nregion-specific control. This limitation reduces flexibility and can cause\ncondition misunderstandings in multi-conditional image generation. To address\nthese challenges, we propose both intra-element and Inter-element Controllers\nin DC-ControlNet. The Intra-Element Controller handles different types of\ncontrol signals within individual elements, accurately describing the content\nand layout characteristics of the object. For interactions between elements, we\nintroduce the Inter-Element Controller, which accurately handles multi-element\ninteractions and occlusion based on user-defined relationships. Extensive\nevaluations show that DC-ControlNet significantly outperforms existing\nControlNet models and Layout-to-Image generative models in terms of control\nflexibility and precision in multi-condition control."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-408",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15020",
    "b_title":[
      "Enhancing Reset Control Phase with Lead Shaping Filters: Applications to\n  Precision Motion Systems"
    ],
    "b_abstract":[
      "This study presents a shaped reset feedback control strategy to enhance the\nperformance of precision motion systems. The approach utilizes a phase-lead\ncompensator as a shaping filter to tune the phase of reset instants, thereby\nshaping the nonlinearity in the first-order reset control. {The design achieves\neither an increased phase margin while maintaining gain properties or improved\ngain without sacrificing phase margin, compared to reset control without the\nshaping filter.} Then, frequency-domain design procedures are provided for both\nClegg Integrator (CI)-based and First-Order Reset Element (FORE)-based reset\ncontrol systems. Finally, the effectiveness of the proposed strategy is\ndemonstrated through two experimental case studies on a precision motion stage.\nIn the first case, the shaped reset control leverages phase-lead benefits to\nachieve zero overshoot in the transient response. In the second case, the\nshaped reset control strategy enhances the gain advantages of the previous\nreset element, resulting in improved steady-state performance, including better\ntracking precision and disturbance rejection, while reducing overshoot for an\nimproved transient response."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01564",
    "c_title":[
      "Semialgebraic Neural Networks: From roots to representations"
    ],
    "c_abstract":[
      "Many numerical algorithms in scientific computing -- particularly in areas\nlike numerical linear algebra, PDE simulation, and inverse problems -- produce\noutputs that can be represented by semialgebraic functions; that is, the graph\nof the computed function can be described by finitely many polynomial\nequalities and inequalities. In this work, we introduce Semialgebraic Neural\nNetworks (SANNs), a neural network architecture capable of representing any\nbounded semialgebraic function, and computing such functions up to the accuracy\nof a numerical ODE solver chosen by the programmer. Conceptually, we encode the\ngraph of the learned function as the kernel of a piecewise polynomial selected\nfrom a class of functions whose roots can be evaluated using a particular\nhomotopy continuation method. We show by construction that the SANN\narchitecture is able to execute this continuation method, thus evaluating the\nlearned semialgebraic function. Furthermore, the architecture can exactly\nrepresent even discontinuous semialgebraic functions by executing a\ncontinuation method on each connected component of the target function. Lastly,\nwe provide example applications of these networks and show they can be trained\nwith traditional deep-learning techniques."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "cs.NE",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-409",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16839",
    "b_title":[
      "Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans"
    ],
    "b_abstract":[
      "Among generative neural models, flow matching techniques stand out for their\nsimple applicability and good scaling properties. Here, velocity fields of\ncurves connecting a simple latent and a target distribution are learned. Then\nthe corresponding ordinary differential equation can be used to sample from a\ntarget distribution, starting in samples from the latent one. This paper\nreviews from a mathematical point of view different techniques to learn the\nvelocity fields of absolutely continuous curves in the Wasserstein geometry. We\nshow how the velocity fields can be characterized and learned via i) transport\nplans (couplings) between latent and target distributions, ii) Markov kernels\nand iii) stochastic processes, where the latter two include the coupling\napproach, but are in general broader. Besides this main goal, we show how flow\nmatching can be used for solving Bayesian inverse problems, where the\ndefinition of conditional Wasserstein distances plays a central role. Finally,\nwe briefly address continuous normalizing flows and score matching techniques,\nwhich approach the learning of velocity fields of curves from other directions."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14545",
    "c_title":[
      "An Entropic Metric for Measuring Calibration of Machine Learning Models"
    ],
    "c_abstract":[
      "Understanding the confidence with which a machine learning model classifies\nan input datum is an important, and perhaps under-investigated, concept. In\nthis paper, we propose a new calibration metric, the Entropic Calibration\nDifference (ECD). Based on existing research in the field of state estimation,\nspecifically target tracking (TT), we show how ECD may be applied to binary\nclassification machine learning models. We describe the relative importance of\nunder- and over-confidence and how they are not conflated in the TT literature.\nIndeed, our metric distinguishes under- from over-confidence. We consider this\nimportant given that algorithms that are under-confident are likely to be\n'safer' than algorithms that are over-confident, albeit at the expense of also\nbeing over-cautious and so statistically inefficient. We demonstrate how this\nnew metric performs on real and simulated data and compare with other metrics\nfor machine learning model probability calibration, including the Expected\nCalibration Error (ECE) and its signed counterpart, the Expected Signed\nCalibration Error (ESCE)."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-410",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04410",
    "b_title":[
      "Nuclear magnetic resonance spectroscopy in pulsed magnetic fields"
    ],
    "b_abstract":[
      "This article provides an introduction to nuclear magnetic resonance\nspectroscopy in pulsed magnetic fields (PFNMR), focusing on its capabilities,\napplications, and future developments in research involving high magnetic\nfields. It highlights the significance of PFNMR in enhancing the understanding\nof solid-state materials, with particular emphasis on those exhibiting complex\ninteractions and strong electronic correlations. Several technical aspects are\ndiscussed, including the challenges associated with high-frequency NMR\nexperiments. The power of PFNMR is showcased through several examples,\nincluding studies on the topical materials LiCuVO$_4$, SrCu$_2$(BO$_3$)$_2$,\nand CeIn$_3$, offering insights into their magnetic and electronic properties\nat high magnetic fields. The article also discusses possible future directions\nfor the technique, including improvements in PFNMR instrumentation and the\nexploration of materials under extreme conditions. This exposition underscores\nthe role of PFNMR in advancing the frontiers of materials-science research."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10635",
    "c_title":[
      "Privacy Preservation through Practical Machine Unlearning"
    ],
    "c_abstract":[
      "Machine Learning models thrive on vast datasets, continuously adapting to\nprovide accurate predictions and recommendations. However, in an era dominated\nby privacy concerns, Machine Unlearning emerges as a transformative approach,\nenabling the selective removal of data from trained models. This paper examines\nmethods such as Naive Retraining and Exact Unlearning via the SISA framework,\nevaluating their Computational Costs, Consistency, and feasibility using the\n$\\texttt{HSpam14}$ dataset. We explore the potential of integrating unlearning\nprinciples into Positive Unlabeled (PU) Learning to address challenges posed by\npartially labeled datasets. Our findings highlight the promise of unlearning\nframeworks like $\\textit{DaRE}$ for ensuring privacy compliance while\nmaintaining model performance, albeit with significant computational\ntrade-offs. This study underscores the importance of Machine Unlearning in\nachieving ethical AI and fostering trust in data-driven systems."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-411",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02325",
    "b_title":[
      "Revisiting Compactness for District Plans"
    ],
    "b_abstract":[
      "Modern sampling methods create ensembles of district maps that score well on\ndiscrete compactness scores, whereas the Polsby-Popper and other shape-based\nscores remain highly relevant for building fair maps and litigating unfair\nones. The aim of this paper is twofold. First, we introduce population-weighted\nversions of shape-based scores and show a precise sense in which this\ninterpolates between shape-based and discrete scores. Second, we introduce a\nmodification of the ReCom sampling method that produces ensembles of maps with\nimproved shape-based compactness scores."
    ],
    "b_categories":[
      [
        "cs.CV",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13930",
    "c_title":[
      "Diagnosing chaos with projected ensembles of process tensors"
    ],
    "c_abstract":[
      "The process tensor provides a general representation of a quantum system\nevolving under repeated interventions and is fundamental for numerical\nsimulations of local many-body dynamics. In this work, we introduce the\nprojected process ensemble, an ensemble of pure output states of a process\ntensor in a given basis of local interventions, and use it to define\nincreasingly more fine-grained probes of quantum chaos. The first moment of\nthis ensemble encapsulates numerous previously studied chaos quantifiers,\nincluding the Alicki-Fannes quantum dynamical entropy, butterfly flutter\nfidelity, and spatiotemporal entanglement. We discover characteristic\nentanglement structures within the ensemble's higher moments that can sharply\ndistinguish chaotic from integrable dynamics, overcoming deficiencies of the\nquantum dynamical and spatiotemporal entropies. These conclusions are supported\nby extensive numerical simulations of many-body dynamics for a range of\nspin-chain models, including non-interacting, interacting-integrable, chaotic,\nand many-body localized regimes. Our work elucidates the fingerprints of chaos\non spatiotemporal correlations in quantum stochastic processes, and provides a\nunified framework for analyzing the complexity of unitary and monitored\nmany-body dynamics."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "hep-th",
        "nlin.CD",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-412",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11354",
    "b_title":[
      "Towards Advancing Code Generation with Large Language Models: A Research\n  Roadmap"
    ],
    "b_abstract":[
      "Recently, we have witnessed the rapid development of large language models,\nwhich have demonstrated excellent capabilities in the downstream task of code\ngeneration. However, despite their potential, LLM-based code generation still\nfaces numerous technical and evaluation challenges, particularly when embedded\nin real-world development. In this paper, we present our vision for current\nresearch directions, and provide an in-depth analysis of existing studies on\nthis task. We propose a six-layer vision framework that categorizes code\ngeneration process into distinct phases, namely Input Phase, Orchestration\nPhase, Development Phase, and Validation Phase. Additionally, we outline our\nvision workflow, which reflects on the currently prevalent frameworks. We\nsystematically analyse the challenges faced by large language models, including\nthose LLM-based agent frameworks, in code generation tasks. With these, we\noffer various perspectives and actionable recommendations in this area. Our aim\nis to provide guidelines for improving the reliability, robustness and\nusability of LLM-based code generation systems. Ultimately, this work seeks to\naddress persistent challenges and to provide practical suggestions for a more\npragmatic LLM-based solution for future code generation endeavors."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11784",
    "c_title":[
      "Ordinal language of antipersistent binary walks"
    ],
    "c_abstract":[
      "This paper explores the effectiveness of using ordinal pattern probabilities\nto evaluate antipersistency in the sign decomposition of long-range\nanti-correlated Gaussian fluctuations. It is numerically shown that ordinal\npatterns are able to effectively measure both persistent and antipersistent\ndynamics by analyzing the sign decomposition derived from fractional Gaussian\nnoise. These findings are crucial given that traditional methods such as\nDetrended Fluctuation Analysis are unsuccessful in detecting anti-correlations\nin such sequences. The numerical results are supported by physiological and\nenvironmental data, illustrating its applicability in real-world situations."
    ],
    "c_categories":[
      [
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-413",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10222",
    "b_title":[
      "Spectral Instability of Random Fredholm Operators"
    ],
    "b_abstract":[
      "If $A \\colon D(A) \\subset \\mathcal{H} \\to \\mathcal{H}$ is an unbounded\nFredholm operator of index $0$ on a Hilbert space $\\mathcal{H}$ with a dense\ndomain $D(A)$, then its spectrum is either discrete or the entire complex\nplane. This spectral dichotomy plays a central role in the study of\n\\textit{magic angles} in twisted bilayer graphene.\n  This paper proves that if such operators (with certain additional\nassumptions) are perturbed by certain random trace-class operators, their\nspectrum is discrete with high probability."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15383",
    "c_title":[
      "Material Decomposition in Photon-Counting Computed Tomography with\n  Diffusion Models: Comparative Study and Hybridization with Variational\n  Regularizers"
    ],
    "c_abstract":[
      "Photon-counting computed tomography (PCCT) has emerged as a promising imaging\ntechnique, enabling spectral imaging and material decomposition (MD). However,\nimages typically suffer from a low signal-to-noise ratio due to constraints\nsuch as low photon counts and sparse-view settings. Variational methods\nminimize a data-fit function coupled with handcrafted regularizers but are\nhighly dependent on the choice of the regularizers. Artificial intelligence\n(AI)-based approaches and more particularly convolutional neural networks\n(CNNs) are now considered the state-of-the-art approach and can be used as an\nend-to-end method for MD or to implicitly learn an a priori. In the last few\nyears, diffusion models (DMs) became predominant in the field of generative\nmodels where a distribution function is learned. This distribution function can\nbe used as a prior for solving inverse problems. This work investigates the use\nof DMs as regularizers for MD tasks in PCCT. MD by diffusion posterior sampling\n(DPS) can be achieved. Three DPS-based approaches -- image-domain two-step DPS\n(im-TDPS), projection-domain two-step DPS (proj-TDPS), and one-step DPS (ODPS)\n-- are evaluated. The first two methods perform MD in two steps: im-TDPS\nsamples spectral images by DPS then performs image-based MD, while proj-TDPS\nperforms projection-based MD then samples material images by DPS. The last\nmethod, ODPS, samples the material images directly from the measurement data.\nThe results indicate that ODPS achieves superior performance compared to\nim-TDPS and proj-TDPS, providing sharper, noise-free and crosstalk-free images.\nFurthermore, we introduce a novel hybrid ODPS method combining DM priors with\nstandard variational regularizers for scenarios involving materials absent from\nthe training dataset. This hybrid method demonstrates improved material\nreconstruction quality compared to a standard variational method."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-414",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03170",
    "b_title":[
      "Universality in the microwave shielding of ultracold polar molecules"
    ],
    "b_abstract":[
      "Microwave shielding is an important technique that can suppress the losses\nthat arise from collisions of ultracold polar molecules. It has been\ninstrumental in achieving molecular Bose-Einstein condensation (BEC) for NaCs\n[Bigagli et al., Nature 631, 289 (2024)]. We demonstrate that microwave\nshielding is universal, in the sense that the 2-body collision properties of\ndifferent molecules are very similar when expressed in suitable reduced units\nof length and energy. This applies to rate coefficients for inelastic\nscattering and loss, to scattering lengths, and to the properties of 2-molecule\nbound states. We also explore the small deviations from universality that arise\nat very large Rabi frequencies. In general, the collision properties are\nnear-universal except when the Rabi frequency exceeds a few percent of the\nmolecular rotational constant. The universality extends to elliptically\npolarized microwaves and to combinations of multiple fields. Our results\nindicate that the methods that have been used to achieve BEC for NaCs can be\ntransferred directly to most other polar molecules."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05361",
    "c_title":[
      "Community Energy Management System for Fast Frequency Response: A\n  Hierarchical Control Approach"
    ],
    "c_abstract":[
      "The increase in renewable energy sources (RES) has reduced power system\ninertia, making frequency stabilization more challenging and highlighting the\nneed for fast frequency response (FFR) resources. While building energy\nmanagement systems (BEMS) equipped with distributed energy resources (DERs) can\nprovide FFR, individual BEMS alone cannot fully meet demand. To address this,\nwe propose a community energy management system (CEMS) operational model that\nminimizes energy costs and generates additional revenue, which is provided FFR\nthrough coordinated DERs and building loads under photovoltaic (PV) generation\nuncertainty. The model incorporates a hierarchical control framework with three\nlevels: Level 1 allocates maximum FFR capacity, Level 2 employs scenario-based\nstochastic model predictive control (SMPC) to adjust DER operations and ensure\nFFR provision despite PV uncertainties, and Level 3 performs rapid load\nadjustments in response to frequency fluctuations detected by a frequency\nmeter. Simulation results on a campus building cluster demonstrate the\neffectiveness of the proposed model, achieving a 10\\% reduction in energy costs\nand a 24\\% increase in FFR capacity, all while maintaining occupant comfort and\nenhancing frequency stabilization."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-415",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05920",
    "b_title":[
      "Full Implementation via Information Design in Nonatomic Games"
    ],
    "b_abstract":[
      "This paper studies the implementation of Bayes correlated equilibria in\nsymmetric Bayesian nonatomic games, using direct information structures and\nobedient strategies. The main results demonstrate full implementation in a\nclass of games with positive cost externalities. Specifically, if the game\nadmits a strictly convex potential in every state, then for every Bayes\ncorrelated equilibrium outcome with finite support and rational action\ndistributions, there exists a direct information structure that implements this\noutcome under all equilibria. When the potential is only weakly convex, we show\nthat all equilibria implement the same expected social cost. Additionally, all\nBayes correlated equilibria, including those with infinite support or\nirrational action distributions, are approximately implemented."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.17044",
    "c_title":[
      "Synthesizing 3D Abstractions by Inverting Procedural Buildings with\n  Transformers"
    ],
    "c_abstract":[
      "We generate abstractions of buildings, reflecting the essential aspects of\ntheir geometry and structure, by learning to invert procedural models. We first\nbuild a dataset of abstract procedural building models paired with simulated\npoint clouds and then learn the inverse mapping through a transformer. Given a\npoint cloud, the trained transformer then infers the corresponding abstracted\nbuilding in terms of a programmatic language description. This approach\nleverages expressive procedural models developed for gaming and animation, and\nthereby retains desirable properties such as efficient rendering of the\ninferred abstractions and strong priors for regularity and symmetry. Our\napproach achieves good reconstruction accuracy in terms of geometry and\nstructure, as well as structurally consistent inpainting."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-416",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04653",
    "b_title":[
      "Three-dimensional spin liquid state in the frustrated $S = 1\/2$\n  Heisenberg garnet NaCa$_{2}$Cu$_{2}$(VO$_{4}$)$_{3}$"
    ],
    "b_abstract":[
      "Three-dimensional quantum spin liquids have remained elusive, hindered by\nreduced quantum fluctuations from larger lattice connectivity inherent to\nhigh-dimensional systems. Here, we investigate the remarkable persistence of\ndynamical short-range magnetic correlations in the nearly body-centered cubic\ngarnet NaCa$_2$Cu$_2$(VO$_4$)$_3$ down to $T = 50$ mK, two orders of magnitude\nbelow its Curie-Weiss temperature. Using a combination of neutron and muon\nspectroscopies plus numerical simulations, we demonstrate that a spin-liquid\nphase emerges from the interplay of strongly frustrated exchange interactions\nand subtle temperature-dependent Jahn-Teller spin-lattice effects."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12745",
    "c_title":[
      "ProtoDepth: Unsupervised Continual Depth Completion with Prototypes"
    ],
    "c_abstract":[
      "We present ProtoDepth, a novel prototype-based approach for continual\nlearning of unsupervised depth completion, the multimodal 3D reconstruction\ntask of predicting dense depth maps from RGB images and sparse point clouds.\nThe unsupervised learning paradigm is well-suited for continual learning, as\nground truth is not needed. However, when training on new non-stationary\ndistributions, depth completion models will catastrophically forget previously\nlearned information. We address forgetting by learning prototype sets that\nadapt the latent features of a frozen pretrained model to new domains. Since\nthe original weights are not modified, ProtoDepth does not forget when\ntest-time domain identity is known. To extend ProtoDepth to the challenging\nsetting where the test-time domain identity is withheld, we propose to learn\ndomain descriptors that enable the model to select the appropriate prototype\nset for inference. We evaluate ProtoDepth on benchmark dataset sequences, where\nwe reduce forgetting compared to baselines by 52.2% for indoor and 53.2% for\noutdoor to achieve the state of the art."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-417",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16560",
    "b_title":[
      "Early Prediction of Alzheimer's and Related Dementias: A Machine\n  Learning Approach Utilizing Social Determinants of Health Data"
    ],
    "b_abstract":[
      "Alzheimer's disease and related dementias (AD\/ADRD) represent a growing\nhealthcare crisis affecting over 6 million Americans. While genetic factors\nplay a crucial role, emerging research reveals that social determinants of\nhealth (SDOH) significantly influence both the risk and progression of\ncognitive functioning, such as cognitive scores and cognitive decline. This\nreport examines how these social, environmental, and structural factors impact\ncognitive health trajectories, with a particular focus on Hispanic populations,\nwho face disproportionate risk for AD\/ADRD. Using data from the Mexican Health\nand Aging Study (MHAS) and its cognitive assessment sub study (Mex-Cog), we\nemployed ensemble of regression trees models to predict 4-year and 9-year\ncognitive scores and cognitive decline based on SDOH. This approach identified\nkey predictive SDOH factors to inform potential multilevel interventions to\naddress cognitive health disparities in this population."
    ],
    "b_categories":[
      [
        "cs.LG",
        "q-bio.QM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08719",
    "c_title":[
      "Extrapolated Hard Thresholding Algorithms with Finite Length for\n  Composite $\\ell_0$ Penalized Problems"
    ],
    "c_abstract":[
      "For a class of sparse optimization problems with the penalty function of\n$\\|(\\cdot)_+\\|_0$, we first characterize its local minimizers and then propose\nan extrapolated hard thresholding algorithm to solve such problems. We show\nthat the iterates generated by the proposed algorithm with $\\epsilon>0$ (where\n$\\epsilon$ is the dry friction coefficient) have finite length, without relying\non the Kurdyka-{\\L}ojasiewicz inequality. Furthermore, we demonstrate that the\nalgorithm converges to an $\\epsilon$-local minimizer of this problem. For the\nspecial case that $\\epsilon=0$, we establish that any accumulation point of the\niterates is a local minimizer of the problem. Additionally, we analyze the\nconvergence when an error term is present in the algorithm, showing that the\nalgorithm still converges in the same manner as before, provided that the\nerrors asymptotically approach zero. Finally, we conduct numerical experiments\nto verify the theoretical results of the proposed algorithm."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-418",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16534",
    "b_title":[
      "Multilingual != Multicultural: Evaluating Gaps Between Multilingual\n  Capabilities and Cultural Alignment in LLMs"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are becoming increasingly capable across global\nlanguages. However, the ability to communicate across languages does not\nnecessarily translate to appropriate cultural representations. A key concern is\nUS-centric bias, where LLMs reflect US rather than local cultural values. We\npropose a novel methodology that compares LLM-generated response distributions\nagainst population-level opinion data from the World Value Survey across four\nlanguages (Danish, Dutch, English, and Portuguese). Using a rigorous linear\nmixed-effects regression framework, we compare two families of models: Google's\nGemma models (2B--27B parameters) and successive iterations of OpenAI's\nturbo-series. Across the families of models, we find no consistent\nrelationships between language capabilities and cultural alignment. While the\nGemma models have a positive correlation between language capability and\ncultural alignment across languages, the OpenAI models do not. Importantly, we\nfind that self-consistency is a stronger predictor of multicultural alignment\nthan multilingual capabilities. Our results demonstrate that achieving\nmeaningful cultural alignment requires dedicated effort beyond improving\ngeneral language capabilities."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01567",
    "c_title":[
      "Scalable Language Models with Posterior Inference of Latent Thought\n  Vectors"
    ],
    "c_abstract":[
      "We propose a novel family of language models, Latent-Thought Language Models\n(LTMs), which incorporate explicit latent thought vectors that follow an\nexplicit prior model in latent space. These latent thought vectors guide the\nautoregressive generation of ground tokens through a Transformer decoder.\nTraining employs a dual-rate optimization process within the classical\nvariational Bayes framework: fast learning of local variational parameters for\nthe posterior distribution of latent vectors, and slow learning of global\ndecoder parameters. Empirical studies reveal that LTMs possess additional\nscaling dimensions beyond traditional LLMs, yielding a structured design space.\nHigher sample efficiency can be achieved by increasing training compute per\ntoken, with further gains possible by trading model size for more inference\nsteps. Designed based on these scaling properties, LTMs demonstrate superior\nsample and parameter efficiency compared to conventional autoregressive models\nand discrete diffusion models. They significantly outperform these counterparts\nin validation perplexity and zero-shot language modeling. Additionally, LTMs\nexhibit emergent few-shot in-context reasoning capabilities that scale with\nmodel and latent size, and achieve competitive performance in conditional and\nunconditional text generation."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-419",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02031",
    "b_title":[
      "A Comparative Modelling of Essential Characteristics of Volatility:\n  Simulation and Empirical Study"
    ],
    "b_abstract":[
      "This study utilised the dynamics of five time-varying models to estimate six\nessential features of financial return volatility that are relevant for robust\nrisk management. These features include pronounced persistence, mean reversion,\nleverage effect or volatility asymmetry, conditional skewness, conditional\nfat-tailedness, and the long memory behaviour of volatility decomposition into\nlong-term and short-term components. Both simulation and empirical evidence are\nprovided. Through the applications of these models using the S&P Indian index,\nthe study shows that the market returns are characterised by these volatility\nfeatures. Our findings from the long-memory behaviour revealed that although\nthe response to shocks is greater in the short-term component, it is however\nshort-lived. On the contrary, despite a high degree of persistence in the\nlong-term component, market information or unexpected news arrival only has a\nlow long-run impact on the market. Based on this, the long-run investment risks\nwithin the Indian stock market seem to be under control. Hence, our findings\nsuggest that rational investors should try to stay calm with the arrival of\nunexpected news in the market because the long-run effect of such news will not\nbe severe, and the market will eventually return to its normal state."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.11782",
    "c_title":[
      "Probing prethermal nonergodicity through measurement outcomes of\n  monitored quantum dynamics"
    ],
    "c_abstract":[
      "Projective measurements are a key element in quantum physics and enable rich\nphenomena in monitored quantum dynamics. Here, we show that the measurement\noutcomes, recorded during monitored dynamics, can provide crucial information\nabout the properties of the monitored dynamical system itself. We demonstrate\nthis for a Floquet model of many-body localization, where we find that the\nprethermal many-body localized regime becomes unstable against rare\nmeasurements, yielding an unusual enhancement of quantum entanglement. Through\nan unsupervised learning and mutual information analysis on the classical\ndataset of measurement outcomes, we find that the information loss in the\nsystem, reflected by the increased entanglement, is compensated by an emergent\nstructure in this classical dataset. Our findings highlight the crucial role of\nmeasurements and corresponding classical outcomes in capturing prethermal\nnonergodicity, offering a promising perspective for applications to other\nmonitored quantum dynamics."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-420",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01283",
    "b_title":[
      "Covariant non-perturbative pointer variables for quantum fields"
    ],
    "b_abstract":[
      "We describe the dynamics of a detector modeled by a harmonic oscillator\ncoupled with an otherwise free quantum field in a curved spacetime in terms of\ncovariant equations of motion leading to local observables. To achieve this, we\nderive and renormalize the integro-differential equation that governs the\ndetector pointer-variable dynamics, introducing phenomenological parameters\nsuch as a dispersion coefficient and a Lamb-shift parameter. Our formal\nsolution, expressed in terms of Green's functions, allows for the covariant,\nand causal analysis of induced observables on the field. This formalism can be\nused for instance to detect non-Gaussianities present in the field's state."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09383",
    "c_title":[
      "Adaptive Contextual Caching for Mobile Edge Large Language Model Service"
    ],
    "c_abstract":[
      "Mobile edge Large Language Model (LLM) deployments face inherent constraints,\nsuch as limited computational resources and network bandwidth. Although\nRetrieval-Augmented Generation (RAG) mitigates some challenges by integrating\nexternal knowledge bases, inefficient cache management can still result in high\nretrieval latency and frequent cache updates. To address these issues, we\npropose an Adaptive Contextual Caching (ACC) framework that anticipates user\nneeds by proactively caching semantically relevant data for mobile-edge LLMs.\nACC utilizes a deep reinforcement learning (DRL) module to refine cache\nreplacement policies, balancing user context, document similarity, and the\noverhead associated with cache misses. Experimental results demonstrate that\nACC increases cache hit rates to over 80\\% after only 11 training episodes,\noutperforming FIFO, LRU, and semantic-only caching while reducing retrieval\nlatency by up to 40\\%. In particular, ACC also reduces local caching overhead\n(i.e., the cost of updating the cache when a miss occurs) by as much as 55\\%,\nenabling scalable, low-latency LLM services in resource-constrained edge\nenvironments."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-421",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16601",
    "b_title":[
      "SOFIA: Singularities of Feynman Integrals Automatized"
    ],
    "b_abstract":[
      "We introduce SOFIA, a Mathematica package that automatizes the computation of\nsingularities of Feynman integrals, based on new theoretical understanding of\ntheir analytic structure. Given a Feynman diagram, SOFIA generates a list of\npotential singularities along with a candidate symbol alphabet. The package\nalso provides a comprehensive set of tools for analyzing the analytic\nproperties of Feynman integrals and related objects, such as cosmological and\nenergy correlators. We showcase its capabilities by reproducing known results\nand predicting singularities and symbol alphabets of Feynman integrals at and\nbeyond the high-precision frontier."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.19252",
    "c_title":[
      "Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search"
    ],
    "c_abstract":[
      "The remarkable progress in text-to-video diffusion models enables\nphotorealistic generations, although the contents of the generated video often\ninclude unnatural movement or deformation, reverse playback, and motionless\nscenes. Recently, an alignment problem has attracted huge attention, where we\nsteer the output of diffusion models based on some quantity on the goodness of\nthe content. Because there is a large room for improvement of perceptual\nquality along the frame direction, we should address which metrics we should\noptimize and how we can optimize them in the video generation. In this paper,\nwe propose diffusion latent beam search with lookahead estimator, which can\nselect better diffusion latent to maximize a given alignment reward, at\ninference time. We then point out that the improvement of perceptual video\nquality considering the alignment to prompts requires reward calibration by\nweighting existing metrics. When evaluating outputs by using vision language\nmodels as a proxy of humans, many previous metrics to quantify the naturalness\nof video do not always correlate with evaluation and also depend on the degree\nof dynamic descriptions in evaluation prompts. We demonstrate that our method\nimproves the perceptual quality based on the calibrated reward, without model\nparameter update, and outputs the best generation compared to greedy search and\nbest-of-N sampling. We provide practical guidelines on which axes, among search\nbudget, lookahead steps for reward estimate, and denoising steps, in the\nreverse diffusion process, we should allocate the inference-time computation."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-422",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07733",
    "b_title":[
      "In Search of the First Stars: An Ultra-Compact and Very Low Metallicity\n  Lyman-$\\alpha$ Emitter Deep Within the Epoch of Reionization"
    ],
    "b_abstract":[
      "We present {\\it JWST} observations of a gravitationally-lensed, extremely\nmetal-poor galaxy at redshift $z=8.203\\pm 0.001$ from the CANUCS survey. Based\non the low oxygen to Balmer line ratios we infer a gas-phase metallicity of\n$12+{\\rm log(O\/H)}=6.85$ (1.4\\% solar), making CANUCS-A370-z8-LAE the most\nmetal-poor galaxy known at $z>7$. With a high H$\\beta$ equivalent width of\n$225\\pm50$\\,\\AA\\ and a half-light radius of only $r_{\\rm hl} = 38 ^{+3}_{-19}\n$\\,pc, the galaxy has a high star-formation-rate density of $50 -\n100\\,M_{\\odot}$\\,yr$^{-1}$\\,kpc$^{-2}$. The galaxy shows high equivalent width\nLyman-$\\alpha$ emission with an inferred Lyman-$\\alpha$ escape fraction of\n$0.21 \\pm 0.05$. The high escape fraction of Lyman-$\\alpha$ is likely due to\nthe compact starbursting nature of the galaxy combined with its location in an\noverdensity traced by at least two other galaxies spectroscopically confirmed\nto lie within $\\delta z = 0.01$ that have helped to reionize the environment.\nThe low metallicity of CANUCS-A370-z8-LAE is best explained by a model where\ninfalling metal-poor gas dilutes the interstellar medium, rather than being a\nyoung galaxy forming its first stellar populations."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09725",
    "c_title":[
      "Parallel multi-objective metaheuristics for smart communications in\n  vehicular networks"
    ],
    "c_abstract":[
      "This article analyzes the use of two parallel multi-objective soft computing\nalgorithms to automatically search for high-quality settings of the Ad hoc On\nDemand Vector routing protocol for vehicular networks. These methods are based\non an evolutionary algorithm and on a swarm intelligence approach. The\nexperimental analysis demonstrates that the configurations computed by our\noptimization algorithms outperform other state-of-the-art optimized ones. In\nturn, the computational efficiency achieved by all the parallel versions is\ngreater than 87 %. Therefore, the line of work presented in this article\nrepresents an efficient framework to improve vehicular communications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.NE",
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-423",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07754",
    "b_title":[
      "Unveiling stellar spin: Determining inclination angles in Be stars"
    ],
    "b_abstract":[
      "The physical properties of stellar atmospheres in rapidly rotating massive\nstars, such as Be stars, are critical to understanding their evolution and\ntheir role as progenitors of supernovae. These stars, which often have\nnear-critical rotation, exhibit equatorial stretching and gravity darkening,\nwhich significantly complicates the determination of parameters such as the\ninclination angle. Be stars, characterized by their extreme rotational\nvelocities, serve as excellent candidates for exploring these phenomena.\nHowever, fundamental quantities such as polar and equatorial radii and\ninclination angles are typically derived from interferometry, which applies\nonly to a limited number of stars. This study aims to enhance the determination\nof inclination angles for Be stars using the ZPEKTR spectral synthesis code. By\nincorporating advanced models of gravity darkening and stellar deformation, we\nevaluated the effectiveness of this method with a sample of ten Be stars from\nthe BeSOS database, comparing results with established interferometric data.\nMethods. We used the ZPEKTR code to model the effects of stellar oblateness and\ngravity darkening on spectral lines, focusing on the HeI 4471 line. We applied\na chi-squared test minimization approach to identify the best-fitting models,\nand we evaluated the inclination angles derived against interferometric\nmeasurements. Our analysis reveals a robust linear correlation between the\ninclination angles derived from ZPEKTR and using interferometric techniques,\nwhich demonstrates an excellent agreement. The ZPEKTR code effectively models\nhigh rotational velocity effects, providing precise stellar parameter\ndeterminations. The results underscore the potential of advanced spectroscopic\ntechniques to yield inclination measurements comparable to interferometry,\nwhich offers a pathway to studying distant massive stars."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00754",
    "c_title":[
      "Continuity-Preserving Convolutional Autoencoders for Learning Continuous\n  Latent Dynamical Models from Images"
    ],
    "c_abstract":[
      "Continuous dynamical systems are cornerstones of many scientific and\nengineering disciplines. While machine learning offers powerful tools to model\nthese systems from trajectory data, challenges arise when these trajectories\nare captured as images, resulting in pixel-level observations that are discrete\nin nature. Consequently, a naive application of a convolutional autoencoder can\nresult in latent coordinates that are discontinuous in time. To resolve this,\nwe propose continuity-preserving convolutional autoencoders (CpAEs) to learn\ncontinuous latent states and their corresponding continuous latent dynamical\nmodels from discrete image frames. We present a mathematical formulation for\nlearning dynamics from image frames, which illustrates issues with previous\napproaches and motivates our methodology based on promoting the continuity of\nconvolution filters, thereby preserving the continuity of the latent states.\nThis approach enables CpAEs to produce latent states that evolve continuously\nwith the underlying dynamics, leading to more accurate latent dynamical models.\nExtensive experiments across various scenarios demonstrate the effectiveness of\nCpAEs."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-424",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01396",
    "b_title":[
      "CorrNetDroid: Android Malware Detector leveraging a Correlation-based\n  Feature Selection for Network Traffic features"
    ],
    "b_abstract":[
      "Copious mobile operating systems exist in the market, but Android remains the\nuser's choice. Meanwhile, its growing popularity has also attracted malware\ndevelopers. Researchers have proposed various static solutions for Android\nmalware detection. However, stealthier malware evade static analysis. This\nraises the need for a robust Android malware detection system capable of\ndealing with advanced threats and overcoming the shortcomings of static\nanalysis.\n  Hence, this work proposes a dynamic analysis-based Android malware detection\nsystem, CorrNetDroid, that works over network traffic flows. Many traffic\nfeatures exhibit overlapping ranges in normal and malware datasets. Therefore,\nwe first rank the features using two statistical measures, crRelevance and\nNormalized Mean Residue Similarity (NMRS), to assess feature-class and\nfeature-feature correlations. Thereafter, we introduce a novel\ncorrelation-based feature selection algorithm that applies NMRS on crRelevance\nrankings to identify the optimal feature subset for Android malware detection.\n  Experimental results highlight that our model effectively reduces the feature\nset while detecting Android malware with 99.50 percent accuracy when\nconsidering only two network traffic features. Furthermore, our experiments\ndemonstrate that the NMRS-based algorithm on crRelevance rankings outperforms\nstatistical tests such as chi-square, ANOVA, Mann-Whitney U test, and\nKruskal-Wallis test. In addition, our model surpasses various state-of-the-art\nAndroid malware detection techniques in terms of detection accuracy."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.MM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01853",
    "c_title":[
      "A self-learning magnetic Hopfield neural network with intrinsic gradient\n  descent adaption"
    ],
    "c_abstract":[
      "Physical neural networks using physical materials and devices to mimic\nsynapses and neurons offer an energy-efficient way to implement artificial\nneural networks. Yet, training physical neural networks are difficult and\nheavily relies on external computing resources. An emerging concept to solve\nthis issue is called physical self-learning that uses intrinsic physical\nparameters as trainable weights. Under external inputs (i.e. training data),\ntraining is achieved by the natural evolution of physical parameters that\nintrinsically adapt modern learning rules via autonomous physical process,\neliminating the requirements on external computation resources.Here, we\ndemonstrate a real spintronic system that mimics Hopfield neural networks (HNN)\nand unsupervised learning is intrinsically performed via the evolution of\nphysical process. Using magnetic texture defined conductance matrix as\ntrainable weights, we illustrate that under external voltage inputs, the\nconductance matrix naturally evolves and adapts Oja's learning algorithm in a\ngradient descent manner. The self-learning HNN is scalable and can achieve\nassociative memories on patterns with high similarities. The fast spin dynamics\nand reconfigurability of magnetic textures offer an advantageous platform\ntowards efficient autonomous training directly in materials."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-425",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02822",
    "b_title":[
      "RDD4D: 4D Attention-Guided Road Damage Detection And Classification"
    ],
    "b_abstract":[
      "Road damage detection and assessment are crucial components of infrastructure\nmaintenance. However, current methods often struggle with detecting multiple\ntypes of road damage in a single image, particularly at varying scales. This is\ndue to the lack of road datasets with various damage types having varying\nscales. To overcome this deficiency, first, we present a novel dataset called\nDiverse Road Damage Dataset (DRDD) for road damage detection that captures the\ndiverse road damage types in individual images, addressing a crucial gap in\nexisting datasets. Then, we provide our model, RDD4D, that exploits Attention4D\nblocks, enabling better feature refinement across multiple scales. The\nAttention4D module processes feature maps through an attention mechanism\ncombining positional encoding and \"Talking Head\" components to capture local\nand global contextual information. In our comprehensive experimental analysis\ncomparing various state-of-the-art models on our proposed, our enhanced model\ndemonstrated superior performance in detecting large-sized road cracks with an\nAverage Precision (AP) of 0.458 and maintained competitive performance with an\noverall AP of 0.445. Moreover, we also provide results on the CrackTinyNet\ndataset; our model achieved around a 0.21 increase in performance. The code,\nmodel weights, dataset, and our results are available on\n\\href{https:\/\/github.com\/msaqib17\/Road_Damage_Detection}{https:\/\/github.com\/msaqib17\/Road\\_Damage\\_Detection}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16539",
    "c_title":[
      "Effect of potential-energy-model inaccuracies on predictions of\n  fission-fragment mass distributions based on the Brownian shape-motion method"
    ],
    "c_abstract":[
      "Moller and Randrup presented a comprehensive calculation, based on the\nBrownian shape motion (BSM) method, of fission-fragment charge distributions\n[Phys. Rev. C 91 (2015) 044316 ] which obtained that ``a new region of\nasymmetry'' appeared for approximately $95 \\le N \\le 115$ and $ 75 \\le Z \\le 94\n$. Available experimental results at the time, except for the observation of\nsymmetric fission of $^{187}$Ir by Itkis et al. [Yad. Fiz. 52 (1990) 944],\nagreed with these predictions apart for minor differences in the transition\nregions between predicted symmetric and asymmetric fission. It was argued\n[Phys. Rev. C 91 (2015) 044316 ] that the inaccurate results for $^{187}$Ir\nwere related to inaccuracies in the calculated potential-energy surface and\nthat such inaccuracies are related to the (in)accuracies of the calculated\nground-state masses for the corresponding mass splits. We present here more\ndetailed discussions and investigate if differences between the\nfission-fragment mass yields presented in [Phys. Rev. C 91 (2015) 044316 ] and\nexperiment can occur in other regions of fissioning nuclei."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-426",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11126",
    "b_title":[
      "SIC-free Multicast Scheduling for Multi-antenna Coded Caching"
    ],
    "b_abstract":[
      "Multi-antenna coded caching (CC) with multicast beamforming typically relies\non a complex successive interference cancellation (SIC) structure to decode a\nsuperposition of multiple streams received by each user. Signal-level CC\nschemes require the regeneration and cancellation of interfering signals at the\nphysical layer of each receiver, which complicates practical implementations.\nTo address this, we propose a bit-level multicast scheduling scheme enabling\nlinear, SIC-free decoding of parallel streams by repeatedly transmitting data\nterms with linearly independent coefficients. Two reference strategies and a\nnovel sparse strategy are considered for constructing the coefficient matrix.\nThe reference cases include the random strategy, which lacks control over\nmatrix construction, and the equal-distant strategy, which balances users'\ninterference and data terms equally. In contrast, the sparse strategy minimizes\nthe number of multicast streams transmitted in parallel during each interval.\nThis approach simplifies both the decoding process and the beamforming design\nby decoupling the desired data terms for each user and reducing the number of\nSINR constraints, respectively. To further enhance the symmetric rate, a\nsuccessive projection algorithm is applied to exploit channel properties and\noptimize user ordering. With the coefficient matrix and optimized user ordering\nin place, multicast beamformers are devised to aggregate desired data from\nrelevant multicast streams. Numerical simulations validate the effectiveness of\nthe sparse strategy and user scheduling, demonstrating significant gains in\nsymmetric rate."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03842",
    "c_title":[
      "Uncovering underappreciated physical effects hidden in the cosmic-ray\n  electron spectra at very high-energy"
    ],
    "c_abstract":[
      "We show that the behavior of the cosmic ray electron spectrum in the TeV\nenergy band near the Earth is dominated by gluon condensation and anomalous\nelectron\/positron pair-production in Cygnus X."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-427",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09864",
    "b_title":[
      "Quantitative analysis of vectorial torques in thin 3d Co ferromagnet\n  using orbital-spin conversion"
    ],
    "b_abstract":[
      "Recent findings in orbitronics pointed out large current-induced torques\noriginating, in the current understanding, from incident orbital currents.\nThese are generated by orbital Rashba-Edelstein effect (OREE) produced at the\ninterface between some light metal and oxides films e.g. by naturally oxidized\ncopper layer (Cu*). In the present work, by using second harmonic Hall\ntechniques, we determine the ratio of orbital vs spin currents exerting torques\non thin transition metals Co ferromagnet in systems using an orbit-to-spin Pt\nconverter as interlayer with Cu*. Our results quantifying damping like torques\nshow that both orbital and spin currents are enhanced in these systems.\nMoreover, the experimental determination of the decoherence length in a sample\nseries with varying Co thickness clearly demonstrates the interfacial\ngeneration of the orbital currents in Cu* by Orbital Rashba-Edelstein effects\n(REE) leading to subsequent magnetic torque in Co over a typical lengthscale of\nseveral nanometers"
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05309",
    "c_title":[
      "Performance Analysis of Spatial and Temporal Learning Networks in the\n  Presence of DVL Noise"
    ],
    "c_abstract":[
      "Navigation is a critical aspect of autonomous underwater vehicles (AUVs)\noperating in complex underwater environments. Since global navigation satellite\nsystem (GNSS) signals are unavailable underwater, navigation relies on inertial\nsensing, which tends to accumulate errors over time. To mitigate this, the\nDoppler velocity log (DVL) plays a crucial role in determining navigation\naccuracy. In this paper, we compare two neural network models: an adapted\nversion of BeamsNet, based on a one-dimensional convolutional neural network,\nand a Spectrally Normalized Memory Neural Network (SNMNN). The former focuses\non extracting spatial features, while the latter leverages memory and temporal\nfeatures to provide more accurate velocity estimates while handling biased and\nnoisy DVL data. The proposed approaches were trained and tested on real AUV\ndata collected in the Mediterranean Sea. Both models are evaluated in terms of\naccuracy and estimation certainty and are benchmarked against the least squares\n(LS) method, the current model-based approach. The results show that the neural\nnetwork models achieve over a 50% improvement in RMSE for the estimation of the\nAUV velocity, with a smaller standard deviation."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-428",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12282",
    "b_title":[
      "Complexity of Jelly-No and Hanano games with various constraints"
    ],
    "b_abstract":[
      "This work shows new results on the complexity of games Jelly-No and Hanano\nwith various constraints on the size of the board and number of colours. Hanano\nand Jelly-No are one-player, 2D side-view puzzle games with a dynamic board\nconsisting of coloured, movable blocks disposed on platforms. These blocks can\nbe moved by the player and are subject to gravity. Both games somehow vary in\ntheir gameplay, but the goal is always to move the coloured blocks in order to\nreach a specific configuration and make them interact with each other or with\nother elements of the game. In Jelly-No the goal is to merge all coloured\nblocks of a same colour, which also happens when they make contact. In Hanano\nthe goal is to make all the coloured blocks bloom by making contact with\nflowers of the same colour. Jelly-No was proven by Chao Yang to be NP-Complete\nunder the restriction that all movable blocks are the same colour and NP-Hard\nfor more colours. Hanano was proven by Michael C. Chavrimootoo to be\nPSPACE-Complete under the restriction that all movable blocks are the same\ncolour. However, the question whether Jelly-No for more than one colours is\nalso PSPACE-complete or if it too stays in NP was left open. In this paper, we\nsettle this question, proving that Jelly-No is PSPACE-Complete with an\nunbounded number of colours. We further show that, if we allow black jellies\n(that is, jellies that do not need to be merged), the game is PSPACE-complete\neven for one colour. We further show that one-colour Jelly-No and Hanano remain\nNP-Hard even if the width or the height of the board are small constants."
    ],
    "b_categories":[
      [
        "cs.CC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15287",
    "c_title":[
      "Some examples of orthogonal matrix polynomials satisfying odd order\n  differential equations"
    ],
    "c_abstract":[
      "It is well known that if a finite order linear differential operator with\npolynomial coefficients has as eigenfunctions a sequence of orthogonal\npolynomials with respect to a positive measure (with support in the real line),\nthen its order has to be even. This property no longer holds in the case of\northogonal matrix polynomials. The aim of this paper is to present examples of\nweight matrices such that the corresponding sequences of matrix orthogonal\npolynomials are eigenfunctions of certain linear differential operators of odd\norder. The weight matrices are of the form $$\nW(t)=t^{\\alpha}e^{-t}e^{At}t^{B}t^{B^*}e^{A^* t}, $$ where $A$ and $B$ are\ncertain (nilpotent and diagonal, respectively) $N\\times N$ matrices. These\nweight matrices are the first examples illustrating this new phenomenon which\nare not reducible to scalar weights."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-429",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18140",
    "b_title":[
      "Trace conjunction inequalities"
    ],
    "b_abstract":[
      "Trace conjunction integrals are introduced and studied. They appear in trace\nconjunction inequalities which unify the Hardy inequality on a halfspace and\nthe classical Gagliardo trace inequality. At the endpoint they satisfy a\nBourgain-Brezis-Mironescu formula for smooth maps, which raises some new open\nproblems."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16115",
    "c_title":[
      "Detecting OOD Samples via Optimal Transport Scoring Function"
    ],
    "c_abstract":[
      "To deploy machine learning models in the real world, researchers have\nproposed many OOD detection algorithms to help models identify unknown samples\nduring the inference phase and prevent them from making untrustworthy\npredictions. Unlike methods that rely on extra data for outlier exposure\ntraining, post hoc methods detect Out-of-Distribution (OOD) samples by\ndeveloping scoring functions, which are model agnostic and do not require\nadditional training. However, previous post hoc methods may fail to capture the\ngeometric cues embedded in network representations. Thus, in this study, we\npropose a novel score function based on the optimal transport theory, named\nOTOD, for OOD detection. We utilize information from features, logits, and the\nsoftmax probability space to calculate the OOD score for each test sample. Our\nexperiments show that combining this information can boost the performance of\nOTOD with a certain margin. Experiments on the CIFAR-10 and CIFAR-100\nbenchmarks demonstrate the superior performance of our method. Notably, OTOD\noutperforms the state-of-the-art method GEN by 7.19% in the mean FPR@95 on the\nCIFAR-10 benchmark using ResNet-18 as the backbone, and by 12.51% in the mean\nFPR@95 using WideResNet-28 as the backbone. In addition, we provide theoretical\nguarantees for OTOD. The code is available in\nhttps:\/\/github.com\/HengGao12\/OTOD."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-430",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12159",
    "b_title":[
      "Paving the way to carbon neutrality: Evaluating the decarbonization of\n  residential building electrification worldwide"
    ],
    "b_abstract":[
      "In the context of increasing global climate change, decarbonizing the\nresidential building sector is crucial for sustainable development. This study\nis the first to analyze the role of various influencing factors in carbon\nintensity changes using the decomposing structural decomposition (DSD) to\nassess and compare the potential and effectiveness of electrifying end-use\nactivities during the operational phase of residential buildings worldwide for\ndecarbonization. The results show that (1) while the electrification rate\nvaried in its impact on emissions across different countries and regions, the\noverall increase in electrification contributed to higher carbon intensity. In\ncontrast, changes in the emission factor of electricity generally made a\npositive contribution to emission reduction globally. (2) The global\nelectrification level has significantly increased, with the electrification\nrate rising from 29.9% in 2000 to 40.1% in 2021. A 39.8% increase in the\nelectricity-related carbon emissions of global residential buildings was\nobserved, increasing from 1452 MtCO2 to 2032 MtCO2, 2000-2021. (3) From 2000 to\n2021, electrification of space heating was the main contributor to carbon\nreduction, whereas the contributions of electrification to cooling and lighting\nwere relatively limited. Emission reductions from appliances and others\nremained stable. The electrification of water heating and cooking had varying\neffects on emission reductions in different countries. Furthermore, this study\nproposes a series of electrification decarbonization strategies. Overall, this\nstudy analyzes and contrasts decarbonization efforts from building\nelectrification at the global and regional levels, explores the key motivations\nbehind these efforts to aid national net-zero emission targets and accelerate\nthe transition of the global residential building sector toward a\ncarbon-neutral future."
    ],
    "b_categories":[
      [
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02369",
    "c_title":[
      "JPDS-NN: Reinforcement Learning-Based Dynamic Task Allocation for\n  Agricultural Vehicle Routing Optimization"
    ],
    "c_abstract":[
      "The Entrance Dependent Vehicle Routing Problem (EDVRP) is a variant of the\nVehicle Routing Problem (VRP) where the scale of cities influences routing\noutcomes, necessitating consideration of their entrances. This paper addresses\nEDVRP in agriculture, focusing on multi-parameter vehicle planning for\nirregularly shaped fields. To address the limitations of traditional methods,\nsuch as heuristic approaches, which often overlook field geometry and entrance\nconstraints, we propose a Joint Probability Distribution Sampling Neural\nNetwork (JPDS-NN) to effectively solve the EDVRP. The network uses an\nencoder-decoder architecture with graph transformers and attention mechanisms\nto model routing as a Markov Decision Process, and is trained via reinforcement\nlearning for efficient and rapid end-to-end planning. Experimental results\nindicate that JPDS-NN reduces travel distances by 48.4-65.4%, lowers fuel\nconsumption by 14.0-17.6%, and computes two orders of magnitude faster than\nbaseline methods, while demonstrating 15-25% superior performance in dynamic\narrangement scenarios. Ablation studies validate the necessity of\ncross-attention and pre-training. The framework enables scalable, intelligent\nrouting for large-scale farming under dynamic constraints."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-431",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14948",
    "b_title":[
      "HECLIP: Histology-Enhanced Contrastive Learning for Imputation of\n  Transcriptomics Profiles"
    ],
    "b_abstract":[
      "Histopathology, particularly hematoxylin and eosin (H\\&E) staining, plays a\ncritical role in diagnosing and characterizing pathological conditions by\nhighlighting tissue morphology. However, H\\&E-stained images inherently lack\nmolecular information, requiring costly and resource-intensive methods like\nspatial transcriptomics to map gene expression with spatial resolution. To\naddress these challenges, we introduce HECLIP (Histology-Enhanced Contrastive\nLearning for Imputation of Profiles), an innovative deep learning framework\nthat bridges the gap between histological imaging and molecular profiling.\nHECLIP is specifically designed to infer gene expression profiles directly from\nH\\&E-stained images, eliminating the need for expensive spatial transcriptomics\nassays. HECLIP leverages an advanced image-centric contrastive loss function to\noptimize image representation learning, ensuring that critical morphological\npatterns in histology images are effectively captured and translated into\naccurate gene expression profiles. This design enhances the predictive power of\nthe image modality while minimizing reliance on gene expression data. Through\nextensive benchmarking on publicly available datasets, HECLIP demonstrates\nsuperior performance compared to existing approaches, delivering robust and\nbiologically meaningful predictions. Detailed ablation studies further\nunderscore its effectiveness in extracting molecular insights from histology\nimages. Additionally, HECLIP's scalable and cost-efficient approach positions\nit as a transformative tool for both research and clinical applications,\ndriving advancements in precision medicine. The source code for HECLIP is\nopenly available at https:\/\/github.com\/QSong-github\/HECLIP."
    ],
    "b_categories":[
      [
        "cs.CE",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00537",
    "c_title":[
      "Detecting Ambiguities to Guide Query Rewrite for Robust Conversations in\n  Enterprise AI Assistants"
    ],
    "c_abstract":[
      "Multi-turn conversations with an Enterprise AI Assistant can be challenging\ndue to conversational dependencies in questions, leading to ambiguities and\nerrors. To address this, we propose an NLU-NLG framework for ambiguity\ndetection and resolution through reformulating query automatically and\nintroduce a new task called \"Ambiguity-guided Query Rewrite.\" To detect\nambiguities, we develop a taxonomy based on real user conversational logs and\ndraw insights from it to design rules and extract features for a classifier\nwhich yields superior performance in detecting ambiguous queries, outperforming\nLLM-based baselines. Furthermore, coupling the query rewrite module with our\nambiguity detecting classifier shows that this end-to-end framework can\neffectively mitigate ambiguities without risking unnecessary insertions of\nunwanted phrases for clear queries, leading to an improvement in the overall\nperformance of the AI Assistant. Due to its significance, this has been\ndeployed in the real world application, namely Adobe Experience Platform AI\nAssistant."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-432",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09457",
    "b_title":[
      "Effective conductivity of conduit networks with random conductivities"
    ],
    "b_abstract":[
      "The effective conductivity ($T^{eff}$) of 2D and 3D Random Resistor Networks\n(RRNs) with random edge conductivity is studied. The combined influence of\ngeometrical disorder, which controls the overall connectivity of the medium and\nleads to percolation effects, and conductivity randomness is investigated. A\nformula incorporating connectivity aspects and second-order averaging methods,\nwidely used in the stochastic hydrology community, is derived and extrapolated\nto higher orders using a power averaging formula based on a mean-field\nargument. This approach highlights the role of the so-called resistance\ndistance introduced by graph theorists. Simulations are performed on various\nRRN geometries constructed from 2D and 3D bond-percolation lattices. The\nresults confirm the robustness of the power averaging technique and the\nrelevance of the mean-field assumption."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13908",
    "c_title":[
      "Judging the Judges: A Collection of LLM-Generated Relevance Judgements"
    ],
    "c_abstract":[
      "Using Large Language Models (LLMs) for relevance assessments offers promising\nopportunities to improve Information Retrieval (IR), Natural Language\nProcessing (NLP), and related fields. Indeed, LLMs hold the promise of allowing\nIR experimenters to build evaluation collections with a fraction of the manual\nhuman labor currently required. This could help with fresh topics on which\nthere is still limited knowledge and could mitigate the challenges of\nevaluating ranking systems in low-resource scenarios, where it is challenging\nto find human annotators. Given the fast-paced recent developments in the\ndomain, many questions concerning LLMs as assessors are yet to be answered.\nAmong the aspects that require further investigation, we can list the impact of\nvarious components in a relevance judgment generation pipeline, such as the\nprompt used or the LLM chosen.\n  This paper benchmarks and reports on the results of a large-scale automatic\nrelevance judgment evaluation, the LLMJudge challenge at SIGIR 2024, where\ndifferent relevance assessment approaches were proposed. In detail, we release\nand benchmark 42 LLM-generated labels of the TREC 2023 Deep Learning track\nrelevance judgments produced by eight international teams who participated in\nthe challenge. Given their diverse nature, these automatically generated\nrelevance judgments can help the community not only investigate systematic\nbiases caused by LLMs but also explore the effectiveness of ensemble models,\nanalyze the trade-offs between different models and human assessors, and\nadvance methodologies for improving automated evaluation techniques. The\nreleased resource is available at the following link:\nhttps:\/\/llm4eval.github.io\/LLMJudge-benchmark\/"
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-433",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03578",
    "b_title":[
      "Four-body coupler for superconducting qubits based on Josephson\n  parametric oscillators"
    ],
    "b_abstract":[
      "We theoretically propose a circuit of the four-body coupler for\nsuperconducting qubits based on Josephson parametric oscillators (JPOs). Our\ncoupler for the four-body interaction has a superconducting loop, similar to a\ncapacitively shunted flux qubit, where an external magnetic flux set to half a\nflux quantum is threaded. This coupler circuit is a specific setup of the\ncircuit called superconducting nonlinear asymmetric inductive elements (SNAIL)\nand also is a generalization of the previously proposed one for the four-body\ninteraction of JPOs. We clarify roles of circuit parameters in the four-body\ninteraction and, in particular, show that the four-body coupling constant in\nour circuit can be significantly increased by tuning capacitance of the coupler\nor the area ratio of the Josephson junctions of the coupler."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2502.21012",
    "c_title":[
      "FedDyMem: Efficient Federated Learning with Dynamic Memory and\n  Memory-Reduce for Unsupervised Image Anomaly Detection"
    ],
    "c_abstract":[
      "Unsupervised image anomaly detection (UAD) has become a critical process in\nindustrial and medical applications, but it faces growing challenges due to\nincreasing concerns over data privacy. The limited class diversity inherent to\none-class classification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant challenges\nfor preserving data privacy with federated UAD. Thus, this article proposes an\nefficient federated learning method with dynamic memory and memory-reduce for\nunsupervised image anomaly detection, called FedDyMem. Considering all client\ndata belongs to a single class (i.e., normal sample) in UAD and the\ndistribution of intra-class features demonstrates significant skewness,\nFedDyMem facilitates knowledge sharing between the client and server through\nthe client's dynamic memory bank instead of model parameters. In the local\nclients, a memory generator and a metric loss are employed to improve the\nconsistency of the feature distribution for normal samples, leveraging the\nlocal model to update the memory bank dynamically. For efficient communication,\na memory-reduce method based on weighted averages is proposed to significantly\ndecrease the scale of memory banks. On the server, global memory is constructed\nand distributed to individual clients through k-means aggregation. Experiments\nconducted on six industrial and medical datasets, comprising a mixture of six\nproducts or health screening types derived from eleven public datasets,\ndemonstrate the effectiveness of FedDyMem."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-434",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16351",
    "b_title":[
      "AquaNeRF: Neural Radiance Fields in Underwater Media with Distractor\n  Removal"
    ],
    "b_abstract":[
      "Neural radiance field (NeRF) research has made significant progress in\nmodeling static video content captured in the wild. However, current models and\nrendering processes rarely consider scenes captured underwater, which are\nuseful for studying and filming ocean life. They fail to address visual\nartifacts unique to underwater scenes, such as moving fish and suspended\nparticles. This paper introduces a novel NeRF renderer and optimization scheme\nfor an implicit MLP-based NeRF model. Our renderer reduces the influence of\nfloaters and moving objects that interfere with static objects of interest by\nestimating a single surface per ray. We use a Gaussian weight function with a\nsmall offset to ensure that the transmittance of the surrounding media remains\nconstant. Additionally, we enhance our model with a depth-based scaling\nfunction to upscale gradients for near-camera volumes. Overall, our method\noutperforms the baseline Nerfacto by approximately 7.5\\% and SeaThru-NeRF by\n6.2% in terms of PSNR. Subjective evaluation also shows a significant reduction\nof artifacts while preserving details of static targets and background compared\nto the state of the arts."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08850",
    "c_title":[
      "Measurements of the Thermal Sunyaev-Zel'dovich Effect with ACT and DESI\n  Luminous Red Galaxies"
    ],
    "c_abstract":[
      "Cosmic Microwave Background (CMB) photons scatter off the free-electron gas\nin galaxies and clusters, allowing us to use the CMB as a backlight to probe\nthe gas in and around low-redshift galaxies. The thermal Sunyaev-Zel'dovich\neffect, sourced by hot electrons in high-density environments, measures the\nthermal pressure of the target objects, shedding light on halo thermodynamics\nand galaxy formation and providing a path toward understanding the baryon\ndistribution around cosmic structures. We use a combination of high-resolution\nCMB maps from the Atacama Cosmology Telescope (ACT) and photometric luminous\nred galaxy (LRG) catalogues from the Dark Energy Spectroscopic Instrument\n(DESI) to measure the thermal Sunyaev-Zel'dovich signal in four redshift bins\nfrom $z=0.4$ to $z=1.2$, with a combined detection significance of 19$\\sigma$\nwhen stacking on the fiducial CMB Compton-$y$ map. We discuss possible sources\nof contamination, finding that residual dust emission associated with the\ntarget galaxies is important and limits current analyses. We discuss several\nmitigation strategies and quantify the residual modelling uncertainty. This\nwork complements closely-related measurements of the kinematic\nSunyaev-Zel'dovich and weak lensing of the same galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-435",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10327",
    "b_title":[
      "Klingen Eisenstein series congruences and modularity"
    ],
    "b_abstract":[
      "We construct a mod $\\ell$ congruence between a Klingen Eisenstein series\n(associated to a classical newform $\\phi$ of weight $k$) and a Siegel cusp form\n$f$ with irreducible Galois representation. We use this congruence to show\nnon-vanishing of the Bloch-Kato Selmer group $H^1_f(\\mathbf{Q},\n\\textrm{ad}^0\\rho_{\\phi}(2-k)\\otimes \\mathbf{Q}_{\\ell}\/\\mathbf{Z}_{\\ell})$\nunder certain assumptions and provide an example. We then prove an $R=dvr$\ntheorem for the Fontaine-Laffaille universal deformation ring of\n$\\overline{\\rho}_f$ under some assumptions, in particular, that the residual\nSelmer group $H^1_f(\\mathbf{Q}, \\textrm{ad}^0\\overline{\\rho}_{\\phi}(k-2))$ is\ncyclic. For this we prove a result about extensions of Fontaine-Laffaille\nmodules. We end by formulating conditions for when $H^1_f(\\mathbf{Q},\n\\textrm{ad}^0\\overline{\\rho}_{\\phi}(k-2))$ is non-cyclic and the Eisenstein\nideal is non-principal."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16064",
    "c_title":[
      "Higgs and Flavour: BSM Overview"
    ],
    "c_abstract":[
      "We discuss scenarios for BSM physics near the TeV, motivated by the hierarchy\nproblem and the flavour puzzle, and review their experimental tests at present\nand future colliders. Strong LHC constraints on couplings to light quarks\nmotivate $U(2)$-like flavour symmetries as a means of lowering the new physics\nscale: this is demonstrated by general SMEFT analyses, and is also seen in\ncomposite Higgs solutions to the hierarchy problem. We discuss flavour\nnon-universal gauge interactions as a possible origin for $U(2)$-like flavour\nsymmetries which, in addition to allowing new physics to be lighter, opens up a\nsimultaneous low-scale solution to the flavour puzzle. We focus on `flavour\ndeconstructed' gauge interactions close to the TeV, and show how this\nnon-universal gauge structure can be combined with Higgs compositeness in a way\nthat better accommodates the requisite tuning in the Higgs mass."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-436",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14963",
    "b_title":[
      "Continual Multimodal Contrastive Learning"
    ],
    "b_abstract":[
      "Multimodal contrastive learning (MCL) advances in aligning different\nmodalities and generating multimodal representations in a joint space. By\nleveraging contrastive learning across diverse modalities, large-scale\nmultimodal data enhances representational quality. However, a critical yet\noften overlooked challenge remains: multimodal data is rarely collected in a\nsingle process, and training from scratch is computationally expensive.\nInstead, emergent multimodal data can be used to optimize existing models\ngradually, \\textit{i.e.}, models are trained on a sequence of modality pair\ndata. We define this problem as Continual Multimodal Contrastive Learning\n(CMCL), an underexplored yet crucial research direction at the intersection of\nmultimodal and continual learning. In this paper, we formulate CMCL through two\nspecialized principles of stability and plasticity. We theoretically derive a\nnovel optimization-based method, which projects updated gradients from dual\nsides onto subspaces where any gradient is prevented from interfering with the\npreviously learned knowledge. Two upper bounds provide theoretical insights on\nboth stability and plasticity in our solution. Beyond our theoretical\ncontributions, we conduct experiments on multiple datasets by comparing our\nmethod against advanced continual learning baselines. The empirical results\nfurther support our claims and demonstrate the efficacy of our method. The code\nwill be publicly available."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17151",
    "c_title":[
      "Dynamics near a class of nonhyperbolic fixed points"
    ],
    "c_abstract":[
      "In this paper, we investigate some dynamical properties near a nonhyperbolic\nfixed point. Under some conditions on the higher nonlinear terms, we establish\na stable manifold theorem and a degenerate Hartman theorem. Furthermore, the\nfinite shadowing property also be discussed."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-437",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16326",
    "b_title":[
      "A mixed integer programming approach to minibeam aperture optimization\n  for multi-collimator proton minibeam radiotherapy"
    ],
    "b_abstract":[
      "Background: Multi-collimator proton minibeam radiation therapy (MC-pMBRT) has\nrecently emerged as a versatile technique for dose shaping, enabling\npeak-valley dose patterns in organs-at-risk (OAR) while maintaining a uniform\ndose distribution in tumor. MC-pMBRT leverages a set of generic multi-slit\ncollimators (MSC) with varying center-to-center distances. However, the current\nmethod for minibeam aperture optimization (MAO), i.e., the selection of MSC per\nbeam angle, is manual and heuristic, resulting in computational inefficiencies\nand no guarantee of optimality. This work introduces a novel mixed integer\nprogramming (MIP) approach to MAO for optimizing MC-pMBRT plan quality.\nMethods: The proposed MIP approach jointly optimizes dose distributions,\npeak-to-valley dose ratio (PVDR), and selects the optimal set of MSC per beam\nangle. The optimization problem includes decision variables for MSC selection\nper beam angle and spot weights. The proposed MIP approach is a two-step\nprocess: Step1: the binary variables are optimally determined to select MSC for\neach beam angle; Step 2: the continuous variables are solved to determine the\nspot weights. Both steps utilize iterative convex relaxation and the\nalternating direction method of multipliers to solve the problems. Results: The\nproposed MIP method for MAO (MIP-MAO) was validated against the conventional\nheuristic method (CONV) for MC-pMBRT treatment planning. Results indicate that\nMIP-MAO enhances the conformity index (CI) for the target and improves PVDR for\nOAR. For instance, in a head-and-neck case, CI improved from 0.61 (CONV) to\n0.70 (MIP-MAO); in an abdomen case, CI improved from 0.78 (CONV) to 0.83\n(MIP-MAO). Additionally, MIP-MAO reduced mean doses in the body and OAR.\nConclusions: A novel MIP approach for MAO in MC-pMBRT is presented, showing\ndemonstrated improvements in plan quality and PVDR compared to the heuristic\nmethod."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10523",
    "c_title":[
      "Multiclass Queue Scheduling Under Slowdown: An Approximate Dynamic\n  Programming Approach"
    ],
    "c_abstract":[
      "In many service systems, especially those in healthcare, customer waiting\ntimes can result in increased service requirements. Such service slowdowns can\nsignificantly impact system performance. Therefore, it is important to properly\naccount for their impact when designing scheduling policies. Scheduling under\nwait-dependent service times is challenging, especially when multiple customer\nclasses are heterogeneously affected by waiting. In this work, we study\nscheduling policies in multiclass, multiserver queues with wait-dependent\nservice slowdowns. We propose a simulation-based Approximate Dynamic\nProgramming (ADP) algorithm to find close-to-optimal scheduling policies. The\nADP algorithm (i) represents the policy using classifiers based on the index\npolicy structure, (ii) leverages a coupling method to estimate the differences\nof the relative value functions directly, and (iii) uses adaptive sampling for\nefficient state-space exploration. Through extensive numerical experiments, we\nillustrate that the ADP algorithm generates close-to-optimal policies that\noutperform well-known benchmarks. We also provide insights into the structure\nof the optimal policy, which reveals an important trade-off between\ninstantaneous cost reduction and preventing the system from reaching high-cost\nequilibria. Lastly, we conduct a case study on scheduling admissions into\nrehabilitation care to illustrate the effectiveness of the ADP algorithm in\npractice."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-438",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18940",
    "b_title":[
      "MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical\n  Capabilities of LLM Tutors"
    ],
    "b_abstract":[
      "Evaluating the pedagogical capabilities of AI-based tutoring models is\ncritical for making guided progress in the field. Yet, we lack a reliable,\neasy-to-use, and simple-to-run evaluation that reflects the pedagogical\nabilities of models. To fill this gap, we present MathTutorBench, an\nopen-source benchmark for holistic tutoring model evaluation. MathTutorBench\ncontains a collection of datasets and metrics that broadly cover tutor\nabilities as defined by learning sciences research in dialog-based teaching. To\nscore the pedagogical quality of open-ended teacher responses, we train a\nreward model and show it can discriminate expert from novice teacher responses\nwith high accuracy. We evaluate a wide set of closed- and open-weight models on\nMathTutorBench and find that subject expertise, indicated by solving ability,\ndoes not immediately translate to good teaching. Rather, pedagogy and subject\nexpertise appear to form a trade-off that is navigated by the degree of\ntutoring specialization of the model. Furthermore, tutoring appears to become\nmore challenging in longer dialogs, where simpler questioning strategies begin\nto fail. We release the benchmark, code, and leaderboard openly to enable rapid\nbenchmarking of future models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09869",
    "c_title":[
      "Computing the Saturation Throughput for Heterogeneous p-CSMA in a\n  General Wireless Network"
    ],
    "c_abstract":[
      "A well-known expression for the saturation throughput of heterogeneous\ntransmitting nodes in a wireless network using p-CSMA, derived from Renewal\nTheory, implicitly assumes that all transmitting nodes are in range of, and\ntherefore conflicting with, each other. This expression, as well as simple\nmodifications of it, does not correctly capture the saturation throughput\nvalues when an arbitrary topology is specified for the conflict graph between\ntransmitting links. For example, we show numerically that calculations based on\nrenewal theory can underestimate throughput by 48-62% for large packet sizes\nwhen the conflict graph is represented by a star topology. This is problematic\nbecause real-world wireless networks, such as wireless IoT mesh networks, are\noften deployed over a large area, resulting in non-complete conflict graphs.\n  To address this gap, we present a computational approach based on a novel\nMarkov chain formulation that yields the exact saturation throughput for each\nnode in the general network case for any given set of access probabilities, as\nwell as a more compact expression for the special case where the packet length\nis twice the slot length. Using our approach, we show how the transmit\nprobabilities could be optimized to maximize weighted utility functions of the\nsaturation throughput values. This would allow a wireless system designer to\nset transmit probabilities to achieve desired throughput trade-offs in any\ngiven deployment."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.NA",
        "cs.NI",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-439",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09367",
    "b_title":[
      "PICE: A Semantic-Driven Progressive Inference System for LLM Serving in\n  Cloud-Edge Networks"
    ],
    "b_abstract":[
      "Large language models (LLMs), while driving a new wave of interactive AI\napplications across numerous domains, suffer from high inference costs and\nheavy cloud dependency. Motivated by the redundancy phenomenon in linguistics,\nwe propose a progressive inference paradigm over cloud and edge, i.e., firstly\ngenerating the sketch of the answer by LLMs at cloud, and then conducting\nparallel extension to fill in details by small models (SLMs) at edge.\nProgressive inference offers potential benefits to improve throughput and\nreduce inference latency while facing key implementation challenges, including\ndecreased response quality from SLMs, a tradeoff between the brevity and\ncomprehensiveness of sketches, as well as increased latency caused by network\ntransmission and edge inference. In this work, we propose and implement PICE,\nan LLM serving system with semantic-level cloud-edge collaboration, enhancing\ninference throughput and quality through dynamic inference task scheduling,\nensemble learning, and parallel edge inference. Extensive testbed experiments\nillustrate that our approach achieves $1.5-2\\times$ throughput enhancement and\nup to 43% latency reduction, while also potentially enhancing the quality\ncompared to SOTA systems."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07789",
    "c_title":[
      "How do the professional players select their shot locations? An analysis\n  of Field Goal Attempts via Bayesian Additive Regression Trees"
    ],
    "c_abstract":[
      "Basketball analytics has significantly advanced our understanding of the\ngame, with shot selection emerging as a critical factor in both individual and\nteam performance. With the advent of player tracking technologies, a wealth of\ngranular data on shot attempts has become available, enabling a deeper analysis\nof shooting behavior. However, modeling shot selection presents unique\nchallenges due to the spatial and contextual complexities influencing shooting\ndecisions. This paper introduces a novel approach to the analysis of basketball\nshot data, focusing on the spatial distribution of shot attempts, also known as\nintensity surfaces. We model these intensity surfaces using a Functional\nBayesian Additive Regression Trees (FBART) framework, which allows for\nflexible, nonparametric regression, and uncertainty quantification while\naddressing the nonlinearity and nonstationarity inherent in shot selection\npatterns to provide a more accurate representation of the factors driving\nplayer performance; we further propose the Adaptive Functional Bayesian\nAdditive Regression Trees (AFBART) model, which builds on FBART by introducing\nadaptive basis functions for improved computational efficiency and model fit.\nAFBART is particularly well suited for the analysis of two-dimensional shot\nintensity surfaces and provides a robust tool for uncovering latent patterns in\nshooting behavior. Through simulation studies and real-world applications to\nNBA player data, we demonstrate the effectiveness of the model in quantifying\nshooting tendencies, improving performance predictions, and informing strategic\ndecisions for coaches, players, and team managers. This work represents a\nsignificant step forward in the statistical modeling of basketball shot\nselection and its applications in optimizing game strategies."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-440",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05910",
    "b_title":[
      "Interactive Visualization Framework for Forensic Bullet Comparisons"
    ],
    "b_abstract":[
      "The current method for forensic analysis of bullet comparison relies on\nmanual examination by forensic examiners to determine if bullets were\ndischarged from the same firearm. This process is highly subjective, prompting\nthe development of algorithmic methods to provide objective statistical support\nfor comparisons. However, a gap exists between the technical understanding of\nthese algorithms and the typical background of many forensic examiners. We\npresent a visualization tool designed to bridge this gap, allowing for the\npresentation of statistical information in a more familiar format to forensic\nprofessionals. The forensic bullet comparison visualizer (FBCV) features a\nvariety of plots that will enable the user to examine every step of the\nalgorithmic comparison process. We demonstrate the utility of the FBCV by\napplying it to data from the Houston Science Lab, where it helped identify an\nerror in the comparison process caused by mislabeling. This tool can be used\nfor future investigations, such as examining how distance between shots affects\nscores. The FBCV offers a user-friendly way to convey complex statistical\ninformation to forensic examiners, facilitating their understanding and\nutilization of algorithmic comparison methods."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10038",
    "c_title":[
      "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI\n  Representation Learning"
    ],
    "c_abstract":[
      "POI representation learning plays a crucial role in handling tasks related to\nuser mobility data. Recent studies have shown that enriching POI\nrepresentations with multimodal information can significantly enhance their\ntask performance. Previously, the textual information incorporated into POI\nrepresentations typically involved only POI categories or check-in content,\nleading to relatively weak textual features in existing methods. In contrast,\nlarge language models (LLMs) trained on extensive text data have been found to\npossess rich textual knowledge. However leveraging such knowledge to enhance\nPOI representation learning presents two key challenges: first, how to extract\nPOI-related knowledge from LLMs effectively, and second, how to integrate the\nextracted information to enhance POI representations. To address these\nchallenges, we propose POI-Enhancer, a portable framework that leverages LLMs\nto improve POI representations produced by classic POI learning models. We\nfirst design three specialized prompts to extract semantic information from\nLLMs efficiently. Then, the Dual Feature Alignment module enhances the quality\nof the extracted information, while the Semantic Feature Fusion module\npreserves its integrity. The Cross Attention Fusion module then fully\nadaptively integrates such high-quality information into POI representations\nand Multi-View Contrastive Learning further injects human-understandable\nsemantic information into these representations. Extensive experiments on three\nreal-world datasets demonstrate the effectiveness of our framework, showing\nsignificant improvements across all baseline representations."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-441",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06953",
    "b_title":[
      "MERLION: Marine ExploRation with Language guIded Online iNformative\n  Visual Sampling and Enhancement"
    ],
    "b_abstract":[
      "Autonomous and targeted underwater visual monitoring and exploration using\nAutonomous Underwater Vehicles (AUVs) can be a challenging task due to both\nonline and offline constraints. The online constraints comprise limited onboard\nstorage capacity and communication bandwidth to the surface, whereas the\noffline constraints entail the time and effort required for the selection of\ndesired key frames from the video data. An example use case of targeted\nunderwater visual monitoring is finding the most interesting visual frames of\nfish in a long sequence of an AUV's visual experience. This challenge of\ntargeted informative sampling is further aggravated in murky waters with poor\nvisibility. In this paper, we present MERLION, a novel framework that provides\nsemantically aligned and visually enhanced summaries for murky underwater\nmarine environment monitoring and exploration. Specifically, our framework\nintegrates (a) an image-text model for semantically aligning the visual samples\nto the users' needs, (b) an image enhancement model for murky water visual data\nand (c) an informative sampler for summarizing the monitoring experience. We\nvalidate our proposed MERLION framework on real-world data with user studies\nand present qualitative and quantitative results using our evaluation metric\nand show improved results compared to the state-of-the-art approaches. We have\nopen-sourced the code for MERLION at the following link\nhttps:\/\/github.com\/MARVL-Lab\/MERLION.git."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17891",
    "c_title":[
      "Non-Markovian effects on the steady state properties of a damped\n  harmonic oscillator"
    ],
    "c_abstract":[
      "We analyze the steady-state characteristics of a damped harmonic oscillator\n(system) in presence of a non-Markovian bath characterized by Lorentzian\nspectral density. Although Markovian baths presume memoryless dynamics, the\nintroduction of complex temporal connections by a non-Markovian environment\nradically modifies the dynamics of the system and its steady-state behaviour.\nWe obtain the steady-state Green's functions and correlation functions of the\nsystem using the Schwinger-Keldysh formalism. In both rotating and non-rotating\nwave approximation, we analyzed various emergent properties like effective\ntemperature and distribution function. We also explore the impact of\ndissipation and non-Markovian bath on the quantum Zeno and anti-Zeno effects.\nWe show that a transition between Zeno to anti-Zeno effect can be tuned by bath\nspectral width and the strength of dissipation."
    ],
    "c_categories":[
      [
        "cond-mat.other",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-442",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00858",
    "b_title":[
      "Learning to Plan with Personalized Preferences"
    ],
    "b_abstract":[
      "Effective integration of AI agents into daily life requires them to\nunderstand and adapt to individual human preferences, particularly in\ncollaborative roles. Although recent studies on embodied intelligence have\nadvanced significantly, they typically adopt generalized approaches that\noverlook personal preferences in planning. We address this limitation by\ndeveloping agents that not only learn preferences from few demonstrations but\nalso learn to adapt their planning strategies based on these preferences. Our\nresearch leverages the observation that preferences, though implicitly\nexpressed through minimal demonstrations, can generalize across diverse\nplanning scenarios. To systematically evaluate this hypothesis, we introduce\nPreference-based Planning (PbP) benchmark, an embodied benchmark featuring\nhundreds of diverse preferences spanning from atomic actions to complex\nsequences. Our evaluation of SOTA methods reveals that while symbol-based\napproaches show promise in scalability, significant challenges remain in\nlearning to generate and execute plans that satisfy personalized preferences.\nWe further demonstrate that incorporating learned preferences as intermediate\nrepresentations in planning significantly improves the agent's ability to\nconstruct personalized plans. These findings establish preferences as a\nvaluable abstraction layer for adaptive planning, opening new directions for\nresearch in preference-guided plan generation and execution."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13602",
    "c_title":[
      "Room temperature observation of the anomalous in-plane Hall effect in\n  epitaxial thin films of a Weyl ferromagnet"
    ],
    "c_abstract":[
      "Topologically nontrivial electronic states can give rise to novel anomalous\nHall effects. The potential appearance of these effects at room temperature\nholds promise for their application in magnetic sensing, spintronics, and\nenergy harvesting technology. The anomalous in-plane Hall effect (IPHE) is\npredicted to arise in topological magnetic materials when an external magnetic\nfield is applied within the sample plane. Because of stringent symmetry\nrequirements, the conclusive detection of the anomalous IPHE induced by\ntopological electronic states remains challenging, and the study of anomalous\nHall effects is often confined to cryogenic conditions. Combining molecular\nbeam epitaxy of the kagome metal Fe$_3$Sn with measurements of the electric\nHall effect and theoretical calculations, we propose and experimentally\ndemonstrate that the interplay of the kagome lattice motif with spin-orbit\ncoupling and canted ferromagnetism with large exchange interactions gives rise\nto the anomalous IPHE at room temperature that is induced by topological Weyl\npoints in the electronic band structure. Synthesizing a topological\nheterostructure including layers of Fe$_3$Sn and ferromagnetic CoFeB, we\nfurther show the enhancement of the anomalous IPHE through the magnetic stray\nfield of the CoFeB layer. Our work establishes a design paradigm for\ntopological magnets and heterostructures to discover and control novel\nanomalous Hall effects toward their use in technological applications."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-443",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14369",
    "b_title":[
      "Low-rank Prompt Interaction for Continual Vision-Language Retrieval"
    ],
    "b_abstract":[
      "Research on continual learning in multi-modal tasks has been receiving\nincreasing attention. However, most existing work overlooks the explicit\ncross-modal and cross-task interactions. In this paper, we innovatively propose\nthe Low-rank Prompt Interaction (LPI) to address this general problem of\nmulti-modal understanding, which considers both cross-modal and cross-task\ninteractions. Specifically, as for the former, we employ multi-modal\ncorrelation modules for corresponding Transformer layers. Considering that the\ntraining parameters scale to the number of layers and tasks, we propose\nlow-rank interaction-augmented decomposition to avoid memory explosion while\nenhancing the cross-modal association through sharing and separating\ncommon-specific low-rank factors. In addition, due to the multi-modal semantic\ndifferences carried by the low-rank initialization, we adopt hierarchical\nlow-rank contrastive learning to ensure training robustness. As for the latter,\nwe initially employ a visual analysis and identify that different tasks have\nclear distinctions in proximity. Therefore, we introduce explicit task\ncontrastive constraints in the prompt learning process based on task semantic\ndistances. Experiments on two retrieval tasks show performance improvements\nwith the introduction of a minimal number of parameters, demonstrating the\neffectiveness of our method. Code is available at\nhttps:\/\/github.com\/Kelvin-ywc\/LPI."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01395",
    "c_title":[
      "Impact of inter-city interactions on disease scaling"
    ],
    "c_abstract":[
      "Inter-city interactions are critical for the transmission of infectious\ndiseases, yet their effects on the scaling of disease cases remain largely\nunderexplored. Here, we use the commuting network as a proxy for inter-city\ninteractions, integrating it with a general scaling framework to describe the\nincidence of seven infectious diseases across Brazilian cities as a function of\npopulation size and the number of commuters. Our models significantly\noutperform traditional urban scaling approaches, revealing that the\nrelationship between disease cases and a combination of population and\ncommuters varies across diseases and is influenced by both factors. Although\nmost cities exhibit a less-than-proportional increase in disease cases with\nchanges in population and commuters, more-than-proportional responses are also\nobserved across all diseases. Notably, in some small and isolated cities,\nproportional rises in population and commuters correlate with a reduction in\ndisease cases. These findings suggest that such towns may experience improved\nhealth outcomes and socioeconomic conditions as they grow and become more\nconnected. However, as growth and connectivity continue, these gains diminish,\neventually giving way to challenges typical of larger urban areas - such as\nsocioeconomic inequality and overcrowding - that facilitate the spread of\ninfectious diseases. Our study underscores the interconnected roles of\npopulation size and commuter dynamics in disease incidence while highlighting\nthat changes in population size exert a greater influence on disease cases than\nvariations in the number of commuters."
    ],
    "c_categories":[
      [
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-444",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12791",
    "b_title":[
      "Topological invariant for holographic Weyl-$\\mathrm Z_2$ semimetal"
    ],
    "b_abstract":[
      "The occurrence of a topological phase transition can be demonstrated by a\ndirect observation of a change in the topological invariant. For holographic\ntopological semimetals, a topological Hamiltonian method needs to be employed\nto calculate the topological invariants due to the strong coupling nature of\nthe system. We calculate the topological invariants for the holographic Weyl\nsemimetal and the holographic Weyl-$\\mathrm Z_2$ semimetal, which correspond to\nthe chiral charge and the spin-Chern number, respectively. This is achieved by\nprobing fermions within the system and deriving the topological Hamiltonian\nfrom the zero-frequency Green's function. In both cases, we have identified an\neffective band structure characterized by an infinite number of Weyl or\n$\\mathrm Z_2$ nodes, a distinctive feature of holographic systems different\nfrom weakly coupled systems. The topological invariants of these nodes are\ncomputed numerically and found to be nonzero, thereby confirming the\ntopologically nontrivial nature of these nodes."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04477",
    "c_title":[
      "Exact first passage time distribution for nonlinear chemical reaction\n  networks II: monomolecular reactions and a A + B - C type of second-order\n  reaction with arbitrary initial conditions"
    ],
    "c_abstract":[
      "In biochemical reaction networks, the first passage time (FPT) of a reaction\nquantifies the time it takes for the reaction to first occur, from the initial\nstate. While the mean FPT historically served as a summary metric, a far more\ncomprehensive characterization of the dynamics of the network is contained\nwithin the complete FPT distribution. The relatively uncommon theoretical\ntreatments of the FPT distribution that have been given in the past have been\nconfined to linear systems, with zero and first-order processes. Recently, we\npresented theoretically exact solutions for the FPT distribution, within\nnonlinear systems involving two-particle collisions, such as A+B - C. Although\nthis research yielded invaluable results, it was based upon the assumption of\ninitial conditions in the form of a Poisson distribution. This somewhat\nrestricts its relevance to real-world biochemical systems, which frequently\ndisplay intricate behaviour and initial conditions that are non-Poisson in\nnature. Our current study extends prior analyses to accommodate arbitrary\ninitial conditions, thereby expanding the applicability of our theoretical\nframework and providing a more adaptable tool for capturing the dynamics of\nbiochemical reaction networks."
    ],
    "c_categories":[
      [
        "q-bio.MN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-445",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04312",
    "b_title":[
      "Quantum metric induced magneto-optical effects in\n  $\\mathcal{PT}$-symmetric antiferromagnets"
    ],
    "b_abstract":[
      "The magneto-optical effects (MOEs), as a fundamental physical phenomenon, can\nreveal the electronic structures of materials. The related probing methods are\nwidely used in the study of magnetic materials. However, space-time inversion\n($\\mathcal{PT}$) symmetric antiferromagnets were previously believed to be\nmagneto-optically inactive. Here, we point out that this traditional\nunderstanding is incorrect. Based on our generic formulas and symmetry\nanalysis, we find that in $\\mathcal{PT}$-symmetric antiferromagnets, it is the\nquantum metric, i.e., the real part of the quantum geometry, that induces MOEs.\nCombining a tight-binding model and first-principles calculations, we confirm\nthis observation by showing MOEs in the $\\mathcal{PT}$-symmetric\nantiferromagnet. Our work demonstrates that $\\mathcal{PT}$-symmetric\nantiferromagnets previously thought to lack MOEs can indeed exhibit MOEs and\ngreatly broaden the research on MOEs."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18731",
    "c_title":[
      "Thermalizer: Stable autoregressive neural emulation of spatiotemporal\n  chaos"
    ],
    "c_abstract":[
      "Autoregressive surrogate models (or \\textit{emulators}) of spatiotemporal\nsystems provide an avenue for fast, approximate predictions, with broad\napplications across science and engineering. At inference time, however, these\nmodels are generally unable to provide predictions over long time rollouts due\nto accumulation of errors leading to diverging trajectories. In essence,\nemulators operate out of distribution, and controlling the online distribution\nquickly becomes intractable in large-scale settings. To address this\nfundamental issue, and focusing on time-stationary systems admitting an\ninvariant measure, we leverage diffusion models to obtain an implicit estimator\nof the score of this invariant measure. We show that this model of the score\nfunction can be used to stabilize autoregressive emulator rollouts by applying\non-the-fly denoising during inference, a process we call\n\\textit{thermalization}. Thermalizing an emulator rollout is shown to extend\nthe time horizon of stable predictions by an order of magnitude in complex\nsystems exhibiting turbulent and chaotic behavior, opening up a novel\napplication of diffusion models in the context of neural emulation."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-446",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07550",
    "b_title":[
      "The Expanding 3-Kiloparsec Arms are neither Expanding nor Spiral Arms,\n  but X1 Orbits driven by the Galactic Bar"
    ],
    "b_abstract":[
      "Near the center of our Milky Way is a bar-like structure and the so-called\nExpanding 3-kpc arms. We currently have limited knowledge of this important\nregion, since we are about 8.2 kpc from the center and cannot directly observe\nit at optical wavelengths, owing to strong extinction from interstellar dust.\nHere we present extremely precise VLBI measurements of water maser sources from\nthe BeSSeL Survey, where extinction is not a problem, which accurately\ndetermine the 3-dimensional locations and motions of three massive young stars.\nCombined with previous measurements, these stars delineate a trail of orbits\noutlining the Milky Way's Galactic Bar. We present the first measurements\ncapturing the dynamics of quasi-elliptical (X1) orbits around the Galactic Bar.\nOur findings provide evidence substantiating the existence of such orbits\npopulated by massive young stars. Our measurements of the position and velocity\nof a number of massive young stars, previously identified with the Expanding\n3-kpc arms, show that they are more likely located in the X1 orbits about the\nGalactic Bar. Also, some stars previously assigned to the Norma spiral arm\nappear to be in these orbits, which suggests that this spiral arm does not\nextend past the end of the bar."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10615",
    "c_title":[
      "R1-Onevision: Advancing Generalized Multimodal Reasoning through\n  Cross-Modal Formalization"
    ],
    "c_abstract":[
      "Large Language Models have demonstrated remarkable reasoning capability in\ncomplex textual tasks. However, multimodal reasoning, which requires\nintegrating visual and textual information, remains a significant challenge.\nExisting visual-language models often struggle to effectively analyze and\nreason visual content, resulting in suboptimal performance on complex reasoning\ntasks. Moreover, the absence of comprehensive benchmarks hinders the accurate\nassessment of multimodal reasoning capabilities. In this paper, we introduce\nR1-Onevision, a multimodal reasoning model designed to bridge the gap between\nvisual perception and deep reasoning. To achieve this, we propose a cross-modal\nreasoning pipeline that transforms images into formal textural representations,\nenabling precise language-based reasoning. Leveraging this pipeline, we\nconstruct the R1-Onevision dataset which provides detailed, step-by-step\nmultimodal reasoning annotations across diverse domains. We further develop the\nR1-Onevision model through supervised fine-tuning and reinforcement learning to\ncultivate advanced reasoning and robust generalization abilities. To\ncomprehensively evaluate multimodal reasoning performance across different\ngrades, we introduce R1-Onevision-Bench, a benchmark aligned with human\neducational stages, covering exams from junior high school to university and\nbeyond. Experimental results show that R1-Onevision achieves state-of-the-art\nperformance, outperforming models such as GPT-4o and Qwen2.5-VL on multiple\nchallenging multimodal reasoning benchmarks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-447",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03818",
    "b_title":[
      "Dirichlet dynamical zeta function for billiard flow"
    ],
    "b_abstract":[
      "We study the Dirichlet dynamical zeta function $\\eta_D(s)$ for billiard flow\ncorresponding to several strictly convex disjoint obstacles. For large ${\\rm\nRe}\\: s$ we have $\\eta_D(s) =\\sum_{n= 1}^{\\infty} a_n e^{-\\lambda_n s}, \\: a_n\n\\in \\mathbb R$ and $\\eta_D$ admits a meromorphic continuation to $\\mathbb C$.\nWe obtain some conditions of the frequencies $\\lambda_n$ and some sums of\ncoefficients $a_n$ which imply that $\\eta_D$ cannot be prolonged as entire\nfunction."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13394",
    "c_title":[
      "Concurrent Learning with Aggregated States via Randomized Least Squares\n  Value Iteration"
    ],
    "c_abstract":[
      "Designing learning agents that explore efficiently in a complex environment\nhas been widely recognized as a fundamental challenge in reinforcement\nlearning. While a number of works have demonstrated the effectiveness of\ntechniques based on randomized value functions on a single agent, it remains\nunclear, from a theoretical point of view, whether injecting randomization can\nhelp a society of agents {\\it concurently} explore an environment. The\ntheoretical results %that we established in this work tender an affirmative\nanswer to this question. We adapt the concurrent learning framework to\n\\textit{randomized least-squares value iteration} (RLSVI) with\n\\textit{aggregated state representation}. We demonstrate polynomial worst-case\nregret bounds in both finite- and infinite-horizon environments. In both setups\nthe per-agent regret decreases at an optimal rate of\n$\\Theta\\left(\\frac{1}{\\sqrt{N}}\\right)$, highlighting the advantage of\nconcurent learning. Our algorithm exhibits significantly lower space complexity\ncompared to \\cite{russo2019worst} and \\cite{agrawal2021improved}. We reduce the\nspace complexity by a factor of $K$ while incurring only a $\\sqrt{K}$ increase\nin the worst-case regret bound, compared to\n\\citep{agrawal2021improved,russo2019worst}. Additionally, we conduct numerical\nexperiments to demonstrate our theoretical findings."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-448",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09231",
    "b_title":[
      "Order-by-order uncertainties of nucleon-nucleon Wolfenstein amplitudes\n  in chiral effective field theory"
    ],
    "b_abstract":[
      "Quantum mechanical invariance principles dictate the most general operator\nstructure that can be present in the nucleon-nucleon (NN) interaction. Five\nindependent operators appear in the on-shell NN amplitude together with five\ncorresponding coefficient functions. The usual choice for these coefficient\nfunctions is known as the NN Wolfenstein amplitudes. We analyze the\norder-by-order convergence of each of the five NN Wolfenstein amplitudes\npredicted by a semi-local coordinate space potential implementation of chiral\neffective field theory ($\\chi$EFT). We do this at laboratory kinetic energies\nbetween 25 and 200 MeV for both neutron-proton and proton-proton scattering.\nOur analysis uses the Gaussian-Process methods developed by the BUQEYE\ncollaboration to describe the contributions of each $\\chi$EFT order, and so\nyields truncation uncertainties for each Wolfenstein amplitude that are\ncorrelated across scattering angles. We combine information on the size of\ndifferent orders in the EFT to infer the $\\chi$EFT breakdown scale for each\namplitude, finding, on average, $\\Lambda_b$ between 750 and 800 MeV. With this\nchoice of $\\Lambda_b$, the EFT truncation uncertainties cover both higher-order\nresults and empirical Wolfenstein amplitudes well for all orders other than the\nleading order."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05919",
    "c_title":[
      "Can Generative Agent-Based Modeling Replicate the Friendship Paradox in\n  Social Media Simulations?"
    ],
    "c_abstract":[
      "Generative Agent-Based Modeling (GABM) is an emerging simulation paradigm\nthat combines the reasoning abilities of Large Language Models with traditional\nAgent-Based Modeling to replicate complex social behaviors, including\ninteractions on social media. While prior work has focused on localized\nphenomena such as opinion formation and information spread, its potential to\ncapture global network dynamics remains underexplored. This paper addresses\nthis gap by analyzing GABM-based social media simulations through the lens of\nthe Friendship Paradox (FP), a counterintuitive phenomenon where individuals,\non average, have fewer friends than their friends. We propose a GABM framework\nfor social media simulations, featuring generative agents that emulate real\nusers with distinct personalities and interests. Using Twitter datasets on the\nUS 2020 Election and the QAnon conspiracy, we show that the FP emerges\nnaturally in GABM simulations. Consistent with real-world observations, the\nsimulations unveil a hierarchical structure, where agents preferentially\nconnect with others displaying higher activity or influence. Additionally, we\nfind that infrequent connections primarily drive the FP, reflecting patterns in\nreal networks. These findings validate GABM as a robust tool for modeling\nglobal social media phenomena and highlight its potential for advancing social\nscience by enabling nuanced analysis of user behavior."
    ],
    "c_categories":[
      [
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-449",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00006",
    "b_title":[
      "Classification of states on certain orthomodular structures"
    ],
    "b_abstract":[
      "We define various type of states on implicative involutive BE algebras\n(Jauch-Piron state, (P)-state, (B)-state, subadditive state, valuation), and we\ninvestigate the relationships between these states. Moreover, we introduce the\nunital, full and rich sets of states, and we prove certain properties involving\nthese notions. In the case when an implicative involutive BE algebra possesses\na rich or a full set of states, we prove that it is an implicative-orthomodular\nlattice. If an implicative involutive BE algebra possesses a rich set of\n(P)-states or a full set of valuations, then it is an implicative-Boolean\nalgebra. Additionally, based on their deductive systems, we give\ncharacterizations of implicative-orthomodular lattices and implicative-Boolean\nalgebras."
    ],
    "b_categories":[
      [
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.18633",
    "c_title":[
      "Analysis of the application of a high order symplectic method in\n  Shardlow's method for dissipative particle dynamics"
    ],
    "c_abstract":[
      "This study investigates the efficiency and reliability of the modified\nShardlow's (M-Shardlow) method for dissipative particle dynamics (DPD). We show\nthat the M-Shardlow method in which for its construction, the second order\nvelocity Verlet method in the Shardlows method to integrate the Hamiltonian\npart has been replaced by a symplectic fourth order method, improperly uses\nsome parameters. %In other words, in this paper, it is shown that the initial\nM-Shardlow method employed some parameters improperly in the fourth order\nsymplectic method that was used for the M-Shardlow method. By numerical\nexperiments and computing, some important configurational quantities such as\nconfigurational temperature and radial distribution function (RDF), the\nM-Shardlow's method is compared with the Shardlow and ABOBA methods. These\nresults indicate that the new method obtained in this way, even with the proper\nparameters is too costly in the sense of the CPU-time that is required per each\nstep which makes it an inefficient DPD integrator. Besides, by a comparison of\nthe radial distribution function of this method with Shardlow and ABOBA for\nlarge time increments, we can observe no considerable improvement in preserving\nthe structure of the system by this new DPD solver."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-450",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15213",
    "b_title":[
      "Sig2text, a Vision-language model for Non-cooperative Radar Signal\n  Parsing"
    ],
    "b_abstract":[
      "Automatic non-cooperative analysis of intercepted radar signals is essential\nfor intelligent equipment in both military and civilian domains. Accurate\nmodulation identification and parameter estimation enable effective signal\nclassification, threat assessment, and the development of countermeasures. In\nthis paper, we propose a symbolic approach for radar signal recognition and\nparameter estimation based on a vision-language model that combines\ncontext-free grammar with time-frequency representation of radar waveforms. The\nproposed model, called Sig2text, leverages the power of vision transformers for\ntime-frequency feature extraction and transformer-based decoders for symbolic\nparsing of radar waveforms. By treating radar signal recognition as a parsing\nproblem, Sig2text can effectively recognize and parse radar waveforms with\ndifferent modulation types and parameters. We evaluate the performance of\nSig2text on a synthetic radar signal dataset and demonstrate its effectiveness\nin recognizing and parsing radar waveforms with varying modulation types and\nparameters. The training code of the model is available at\nhttps:\/\/github.com\/Na-choneko\/sig2text."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07816",
    "c_title":[
      "Simulations of Three-dimensional Nematic Guidance of Microswimmers"
    ],
    "c_abstract":[
      "It has been shown that an anisotropic liquid crystalline (LC) environment can\nbe used to guide the self-propulsion dynamics of dispersed microswimmers, such\nas bacteria. This type of composite system is named \"living nematic\" (LN). In\nthe dilute limit, bacteria are found to mainly follow the local director field.\nBeyond the dilute limit, however, they exhibit novel dynamical behaviors, from\nswirling around a spiral +1 defect pattern to forming undulating waves, and to\nactive turbulence. Our current knowledge of how these different behaviors\nemerge at different population densities remains limited. Here we develop a\nhybrid method to simulate the dynamics of microswimmers dispersed in a nematic\nLC. Specifically, we model the microswimmers using active Brownian dynamics\nmethod, which is coupled to a hydrodynamic model of nematic LCs to describe the\nevolution of the flow field and the LC structure. Our method is validated by\ncomparing to existing quasi-two-dimensional (2D) experiments, including\nundulated swirling around a spiral pattern and stabilized undulated jets on a\nperiodic C-pattern. We further extend our method to three-dimensional (3D)\nsystems by examining loop-defect dynamics. We find that the morphodynamics and\ndestiny of a loop defect not only depend on the activity (self-propulsion\nvelocity), effective size, and the initial distribution of the swimmers, but\nalso rely on its winding profile. Specifically, +1\/2 wedge and radial twist\nwinding can dictate the dynamics of loop defects. By varying the characteristic\nreversal time, we predict that microswimmers not necessarily accumulate in\nsplay regions. Taken together, our hybrid method provides a faithful tool to\nexplain and guide the experiments of LNs in both 2D and 3D, sheds light on the\ninterplay between microswimmer distribution and defect dynamics, and unravels\nthe design principles of using LCs to control active matter."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "physics.bio-ph",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-451",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07480",
    "b_title":[
      "Trapping and Transport of Inertial Particles in a Taylor-Green Vortex:\n  Effects of Added Mass and History Force"
    ],
    "b_abstract":[
      "We investigate the dynamics of small inertial particles in a two-dimensional,\nsteady Taylor-Green vortex flow. A classic study by Taylor (2022) showed that\nheavy inertial point particles (having density parameter R = 1) are trapped by\nthe flow separatrices when the particle Stokes number St, which measures the\nparticle's inertia, is less than 1\/4. Here, we consider finitely dense\nparticles, incorporating the previously neglected effects of added mass and the\nBoussinesq-Basset history force. Using linear stability analysis near\nstagnation points, we determine the critical parametric conditions in the St-R\nplane that leads to particle trapping within vortex cells. We identify\nadditional stagnation points perceived by inertial particles, beyond the\ntraditional ones at vortex cell corners, when the added mass effect is\nincluded, and we analyze their stability. Numerical analysis of the full\nnonlinear system confirms the existence of distinct particle\nbehaviours--trapped, diffusive, and ballistic--depending on initial conditions,\nconsistent with Nath et al. (2024), with modifications due to added mass\neffect. We delineate the regions in the St-R plane where these behaviours\ndominate based on the prominent particle dynamics. However, when both the\nhistory force and added mass effect are included, all particles exhibit\nballistic motion regardless of St and R."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17300",
    "c_title":[
      "The multilinear fractional sparse operator theory II: refining weighted\n  estimates via multilinear stochastic fractional sparse forms"
    ],
    "c_abstract":[
      "Building upon our study of the sparse bounds of generalized commutators of\nmultilinear fractional singular integral operators in \\cite{CenSong2412}, this\npaper seeks to further refine the main results presented in \\cite{CenSong2412}\nin the following key aspects. Firstly, we replace pointwise domination with\n($m+1$)-linear stochastic fractional reducing sparse form ${\\mathcal\nB}_{\\alpha(\\eta) ,\\mathcal{S},\\tau,\\tau',{\\vec r},t}^\\mathbf{b,k}$, thus\nproviding a new approach to the vector-valued multilinear stochastic fractional\nsparse domination principle. Additionally, the conditions required for this\nresult are relaxed from multilinear weak type boundedness in \\cite{CenSong2412}\nto multilinear locally weak type boundedness $W_{\\vec{p}, q}(X)$, which allows\nus to extend the main ideas from Lerner \\cite{Lerner2019} (2019) and Lorist et\nal. \\cite{Lorist2024} (2024). Secondly, and more importantly, we move away from\nthe original techniques of quantitatively estimating multilinear stochastic\nfractional sparse operators ${\\mathcal\nA}_{\\alpha(\\eta),\\mathcal{S},\\tau,{\\vec{r}},t}^\\mathbf{b,k,t}$, and instead\nemploy a more powerful multilinear fractional \\( \\vec{r} \\)-type maximal\noperator $\\mathscr{M}_{\\alpha(\\eta),\\vec{r}}$. This necessitates the\ndevelopment of a new class of multilinear fractional weights $\nA_{(\\vec{p},q),(\\vec{r}, s)}(X)$ to quantitatively characterize this maximal\noperator, followed by revealing the norm equivalence between this maximal\noperator and the sparse forms introduced earlier, thereby generalizing part of\nthe ideas of Nieraeth \\cite{Nier2019} (2019). ......"
    ],
    "c_categories":[
      [
        "math.AP",
        "math.CA",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-452",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14206",
    "b_title":[
      "Linear stability analysis of the Couette flow for 2D compressible\n  Navier-Stokes-Poisson system"
    ],
    "b_abstract":[
      "In this paper, we study the linear stability of Couette flow for 2D\ncompressible Navier-Stokes-Poisson system at high Reynolds number in the domain\n$\\mathbb{T}\\times\\mathbb{R}$ with initial perturbation in Sobolev spaces. We\nestablish the upper bounds for the solutions of linearized system near Couette\nflow. In particular, we show that the irrotational component of the\nperturbation may have a transient growth, after which it decays exponentially."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00722",
    "c_title":[
      "Rate Splitting Multiple Access for Simultaneous Lightwave Information\n  and Power Transfer"
    ],
    "c_abstract":[
      "This paper initiate the application of rate splitting multiple access (RSMA)\nfor simultaneous lightwave information and power transfer (SLIPT), where users\nrequire to decode information and harvest energy. We focus on a time-splitting\n(TS) mode where information decoding and energy harvesting are separated in two\ndifferent phases. Based on the proposed system model, we design a\nconstrained-concave-convex programming (CCCP) algorithm to solve the\noptimization problem of maximizing the worst-case rate among users subject to\nthe harvested energy constraint at each user. Specifically, the proposed\nalgorithm exploits transformation of the bilinear function, semidefinite\nrelaxation (SDR), CCCP, and a penalty method to effectively deal with the\nnon-convex constraints and objective function. Numerical results show that our\nproposed RSMA-aided SLIPT outperforms the existing baselines based on\nspace-division multiple access (SDMA) and non-orthogonal multiple access\n(NOMA)."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-453",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02324",
    "b_title":[
      "PromptCoT: Synthesizing Olympiad-level Problems for Mathematical\n  Reasoning in Large Language Models"
    ],
    "b_abstract":[
      "The ability of large language models to solve complex mathematical problems\nhas progressed significantly, particularly for tasks requiring advanced\nreasoning. However, the scarcity of sufficiently challenging problems,\nparticularly at the Olympiad level, hinders further advancements. In this work,\nwe introduce PromptCoT, a novel approach for automatically generating\nhigh-quality Olympiad-level math problems. The proposed method synthesizes\ncomplex problems based on mathematical concepts and the rationale behind\nproblem construction, emulating the thought processes of experienced problem\ndesigners. We provide a theoretical analysis demonstrating that an optimal\nrationale should maximize both the likelihood of rationale generation given the\nassociated concepts and the likelihood of problem generation conditioned on\nboth the rationale and the concepts. Our method is evaluated on standard\nbenchmarks including GSM8K, MATH-500, and AIME2024, where it consistently\noutperforms existing problem generation methods. Furthermore, we demonstrate\nthat PromptCoT exhibits superior data scalability, consistently maintaining\nhigh performance as the dataset size increases, outperforming the baselines.\nThe implementation is available at https:\/\/github.com\/zhaoxlpku\/PromptCoT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12717",
    "c_title":[
      "Neural network-enhanced $hr$-adaptive finite element algorithm for\n  parabolic equations"
    ],
    "c_abstract":[
      "In this paper, we present a novel enhancement to the conventional\n$hr$-adaptive finite element methods for parabolic equations, integrating\ntraditional $h$-adaptive and $r$-adaptive methods via neural networks. A major\nchallenge in $hr$-adaptive finite element methods lies in projecting the\nprevious step's finite element solution onto the updated mesh. This projection\ndepends on the new mesh and must be recomputed for each adaptive iteration. To\naddress this, we introduce a neural network to construct a mesh-free surrogate\nof the previous step finite element solution. Since the neural network is\nmesh-free, it only requires training once per time step, with its parameters\ninitialized using the optimizer from the previous time step. This approach\neffectively overcomes the interpolation challenges associated with non-nested\nmeshes in computation, making node insertion and movement more convenient and\nefficient. The new algorithm also emphasizes SIZING and GENERATE, allowing each\nrefinement to roughly double the number of mesh nodes of the previous iteration\nand then redistribute them to form a new mesh that effectively captures the\nsingularities. It significantly reduces the time required for repeated\nrefinement and achieves the desired accuracy in no more than seven\nspace-adaptive iterations per time step. Numerical experiments confirm the\nefficiency of the proposed algorithm in capturing dynamic changes of\nsingularities."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-454",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06209",
    "b_title":[
      "Enhancing Cost Efficiency in Active Learning with Candidate Set Query"
    ],
    "b_abstract":[
      "This paper introduces a cost-efficient active learning (AL) framework for\nclassification, featuring a novel query design called candidate set query.\nUnlike traditional AL queries requiring the oracle to examine all possible\nclasses, our method narrows down the set of candidate classes likely to include\nthe ground-truth class, significantly reducing the search space and labeling\ncost. Moreover, we leverage conformal prediction to dynamically generate small\nyet reliable candidate sets, adapting to model enhancement over successive AL\nrounds. To this end, we introduce an acquisition function designed to\nprioritize data points that offer high information gain at lower cost.\nEmpirical evaluations on CIFAR-10, CIFAR-100, and ImageNet64x64 demonstrate the\neffectiveness and scalability of our framework. Notably, it reduces labeling\ncost by 42% on ImageNet64x64."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16388",
    "c_title":[
      "A Mixed-FEM approximation with uniform conservation of the exponential\n  stability for a class of anisotropic port-Hamiltonian system and its\n  application to LQ control"
    ],
    "c_abstract":[
      "In this manuscript, we present a mixed finite element discretization for a\nclass of boundary-damped anisotropic port-Hamiltonian systems. Using a\nmultiplier method, we demonstrate that the resulting approximation model\nuniformly preserves the exponential stability of the uncontrolled system,\nestablishing a lower bound for the exponential decay rate that is independent\nof the mesh size. This property is illustrated through the spatial\ndiscretization of a piezoelectric beam. Furthermore, we show how the uniform\npreservation of exponential stability by the proposed model aids in the\nconvergence of controllers derived from an infinite-time linear quadratic\ncontrol design, in comparison to models obtained from the standard\nfinite-element method."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.DS",
        "math.NA",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-455",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18385",
    "b_title":[
      "Monolithic On-Chip Phononic Chiral Anomalous Bulk States on LiNbO3\n  Thin-films"
    ],
    "b_abstract":[
      "Phononic materials are crucial for developing efficient, robust mechanical\nwaveguides with strong transport properties, enabling advances in sensing,\nsignal processing, energy harvesting, and microfluidics. A key motivation is\ntheir integration into monolithic systems for on-chip applications. While\ntopological phononic materials developed in the past decade offer\nunidirectional edge states immune to backscattering, their integration requires\nlarge volumes to control localized small volumes' transport properties,\nlimiting their efficiency and application in modern phononic circuits. The\nrecently introduced chiral anomalous bulk states (CABSs) combine the advantages\nof topological materials with innovative boundary designs, overcoming\ntransmission limitations and ensuring full material utilization for superior\nwave propagation. Here, we present the first on-chip monolithic CABS device\nintegrated on a suspended LiNbO3 thin film. This breakthrough enables the\ncreation of phononic waveguides with unmatched unidirectionality, low loss, and\nhigh transmission efficiency, seamlessly integrated with broadband\npiezoelectric transducers, and showcasing their potential for high-fidelity,\nbroad-bandwidth microwave signal transmission. Additionally, we exploit the\nslow-wave characteristics of CABSs for delay lines and high-density signal\nprocessing. Tailoring wave propagation through boundary engineering opens a new\nparadigm for phononic\/photonic device design, with implications across\nmicroelectronics, high-frequency communications, radar, and advanced sensing\ntechnologies. The work sets the stage for the future development of highly\nscalable, multifunctional, and robust phononic systems, unlocking new avenues\nfor integrated acoustic technologies."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14621",
    "c_title":[
      "Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine\n  Learning Approach"
    ],
    "c_abstract":[
      "False arrhythmia alarms in intensive care units (ICUs) are a significant\nchallenge, contributing to alarm fatigue and potentially compromising patient\nsafety. Ventricular tachycardia (VT) alarms are particularly difficult to\ndetect accurately due to their complex nature. This paper presents a machine\nlearning approach to reduce false VT alarms using the VTaC dataset, a benchmark\ndataset of annotated VT alarms from ICU monitors. We extract time-domain and\nfrequency-domain features from waveform data, preprocess the data, and train\ndeep learning models to classify true and false VT alarms. Our results\ndemonstrate high performance, with ROC-AUC scores exceeding 0.96 across various\ntraining configurations. This work highlights the potential of machine learning\nto improve the accuracy of VT alarm detection in clinical settings."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-456",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04659",
    "b_title":[
      "$\\mathsf{CRATE}$: Cross-Rollup Atomic Transaction Execution"
    ],
    "b_abstract":[
      "Blockchains have revolutionized decentralized applications, with\ncomposability enabling atomic, trustless interactions across smart contracts.\nHowever, layer 2 (L2) scalability solutions like rollups introduce\nfragmentation and hinder composability. Current cross-chain protocols,\nincluding atomic swaps, bridges, and shared sequencers, lack the necessary\ncoordination mechanisms or rely on trust assumptions, and are thus not\nsufficient to support full cross-rollup composability. This paper presents\n$\\mathsf{CRATE}$, a secure protocol for cross-rollup composability that ensures\nall-or-nothing and serializable execution of cross-rollup transactions (CRTs).\n$\\mathsf{CRATE}$ supports rollups on distinct layer 1 (L1) chains, achieves\nfinality in 4 rounds on L1, and only relies on the underlying L1s and the\nliveness of L2s. We introduce two formal models for CRTs, define atomicity\nwithin them, and formally prove the security of $\\mathsf{CRATE}$. We also\nprovide an implementation of $\\mathsf{CRATE}$ along with a cross-rollup flash\nloan application; our experiments demonstrate that $\\mathsf{CRATE}$ is\npractical in terms of gas usage on L1."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18025",
    "c_title":[
      "Decision from Suboptimal Classifiers: Excess Risk Pre- and\n  Post-Calibration"
    ],
    "c_abstract":[
      "Probabilistic classifiers are central for making informed decisions under\nuncertainty. Based on the maximum expected utility principle, optimal decision\nrules can be derived using the posterior class probabilities and\nmisclassification costs. Yet, in practice only learned approximations of the\noracle posterior probabilities are available. In this work, we quantify the\nexcess risk (a.k.a. regret) incurred using approximate posterior probabilities\nin batch binary decision-making. We provide analytical expressions for\nmiscalibration-induced regret ($R^{\\mathrm{CL}}$), as well as tight and\ninformative upper and lower bounds on the regret of calibrated classifiers\n($R^{\\mathrm{GL}}$). These expressions allow us to identify regimes where\nrecalibration alone addresses most of the regret, and regimes where the regret\nis dominated by the grouping loss, which calls for post-training beyond\nrecalibration. Crucially, both $R^{\\mathrm{CL}}$ and $R^{\\mathrm{GL}}$ can be\nestimated in practice using a calibration curve and a recent grouping loss\nestimator. On NLP experiments, we show that these quantities identify when the\nexpected gain of more advanced post-training is worth the operational cost.\nFinally, we highlight the potential of multicalibration approaches as efficient\nalternatives to costlier fine-tuning approaches."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-457",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12082",
    "b_title":[
      "A Multi-annotated and Multi-modal Dataset for Wide-angle Video Quality\n  Assessment"
    ],
    "b_abstract":[
      "Wide-angle video is favored for its wide viewing angle and ability to capture\na large area of scenery, making it an ideal choice for sports and adventure\nrecording. However, wide-angle video is prone to deformation, exposure and\nother distortions, resulting in poor video quality and affecting the perception\nand experience, which may seriously hinder its application in fields such as\ncompetitive sports. Up to now, few explorations focus on the quality assessment\nissue of wide-angle video. This deficiency primarily stems from the absence of\na specialized dataset for wide-angle videos. To bridge this gap, we construct\nthe first Multi-annotated and multi-modal Wide-angle Video quality assessment\n(MWV) dataset. Then, the performances of state-of-the-art video quality methods\non the MWV dataset are investigated by inter-dataset testing and intra-dataset\ntesting. Experimental results show that these methods impose significant\nlimitations on their applicability."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06689",
    "c_title":[
      "Neumann eigenmaps for landmark embedding"
    ],
    "c_abstract":[
      "We present Neumann eigenmaps (NeuMaps), a novel approach for enhancing the\nstandard diffusion map embedding using landmarks, i.e distinguished samples\nwithin the dataset. By interpreting these landmarks as a subgraph of the larger\ndata graph, NeuMaps are obtained via the eigendecomposition of a renormalized\nNeumann Laplacian. We show that NeuMaps offer two key advantages: (1) they\nprovide a computationally efficient embedding that accurately recovers the\ndiffusion distance associated with the reflecting random walk on the subgraph,\nand (2) they naturally incorporate the Nystr\\\"om extension within the diffusion\nmap framework through the discrete Neumann boundary condition. Through examples\nin digit classification and molecular dynamics, we demonstrate that NeuMaps not\nonly improve upon existing landmark-based embedding methods but also enhance\nthe stability of diffusion map embeddings to the removal of highly significant\npoints."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-458",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21272",
    "b_title":[
      "$B_h$-sets of real and complex numbers"
    ],
    "b_abstract":[
      "Let $K = \\mathbb{R}$ or $\\mathbb{C}$. An $n$-element subset $A$ of $K$ is a\n$B_h$-set if every element of $K$ has at most one representation as the sum of\n$h$ not necessarily distinct elements of $A$. Associated to the $B_h$ set $A =\n\\{a_1,\\ldots, a_n\\}$ are the $B_h$-vectors $\\mathbf{a} = (a_1,\\ldots, a_n)$ in\n$K^n$. This paper proves that ``almost all'' $n$-element subsets of $K$ are\n$B_h$-sets in the sense that the set of all $B_h$-vectors is a dense open\nsubset of $K^n$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17032",
    "c_title":[
      "TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented\n  Reality via 3D Gaussian Splatting"
    ],
    "c_abstract":[
      "Realistic 3D full-body talking avatars hold great potential in AR, with\napplications ranging from e-commerce live streaming to holographic\ncommunication. Despite advances in 3D Gaussian Splatting (3DGS) for lifelike\navatar creation, existing methods struggle with fine-grained control of facial\nexpressions and body movements in full-body talking tasks. Additionally, they\noften lack sufficient details and cannot run in real-time on mobile devices. We\npresent TaoAvatar, a high-fidelity, lightweight, 3DGS-based full-body talking\navatar driven by various signals. Our approach starts by creating a\npersonalized clothed human parametric template that binds Gaussians to\nrepresent appearances. We then pre-train a StyleUnet-based network to handle\ncomplex pose-dependent non-rigid deformation, which can capture high-frequency\nappearance details but is too resource-intensive for mobile devices. To\novercome this, we \"bake\" the non-rigid deformations into a lightweight\nMLP-based network using a distillation technique and develop blend shapes to\ncompensate for details. Extensive experiments show that TaoAvatar achieves\nstate-of-the-art rendering quality while running in real-time across various\ndevices, maintaining 90 FPS on high-definition stereo devices such as the Apple\nVision Pro."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-459",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05549",
    "b_title":[
      "On the characterization of uniqueness polynomials: both complex and\n  p-adic versions"
    ],
    "b_abstract":[
      "The problem \"A general characterization of uniqueness polynomial for\nnon-critically injective polynomials\" has been remained open since the last two\ndecades. In this paper, we explore this open problem. To this end, we initiate\na new approach that also includes critically injective polynomials. We provide\nthis characterization for both the complex and p-adic cases. We also provide\nvarious examples as an application of our results along with the verification\nof the existing examples. Consequently, we find examples of unique range sets\ngenerated by non-critically injective polynomials with least cardinalities\nachieved so far and one of these results is sharp with respect to all the\navailable formulas in the literature. Furthermore, we cover the part of least\ndegree uniqueness polynomials. In this part, we also provide some sharp bounds."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.18463",
    "c_title":[
      "SIT-FER: Integration of Semantic-, Instance-, Text-level Information for\n  Semi-supervised Facial Expression Recognition"
    ],
    "c_abstract":[
      "Semi-supervised deep facial expression recognition (SS-DFER) has gained\nincreasingly research interest due to the difficulty in accessing sufficient\nlabeled data in practical settings. However, existing SS-DFER methods mainly\nutilize generated semantic-level pseudo-labels for supervised learning, the\nunreliability of which compromises their performance and undermines the\npractical utility. In this paper, we propose a novel SS-DFER framework that\nsimultaneously incorporates semantic, instance, and text-level information to\ngenerate high-quality pseudo-labels. Specifically, for the unlabeled data,\nconsidering the comprehensive knowledge within the textual descriptions and\ninstance representations, we respectively calculate the similarities between\nthe facial vision features and the corresponding textual and instance features\nto obtain the probabilities at the text- and instance-level. Combining with the\nsemantic-level probability, these three-level probabilities are elaborately\naggregated to gain the final pseudo-labels. Furthermore, to enhance the\nutilization of one-hot labels for the labeled data, we also incorporate text\nembeddings excavated from textual descriptions to co-supervise model training,\nenabling facial visual features to exhibit semantic correlations in the text\nspace. Experiments on three datasets demonstrate that our method significantly\noutperforms current state-of-the-art SS-DFER methods and even exceeds fully\nsupervised baselines. The code will be available at\nhttps:\/\/github.com\/PatrickStarL\/SIT-FER."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-460",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16733",
    "b_title":[
      "Testing the bloated star hypothesis in the massive young stellar object\n  IRAS 19520+2759 through optical and infrared variability"
    ],
    "b_abstract":[
      "Using optical time series with Telescopi Joan Or\\'o (TJO), Gaia, TESS, and\nNEOWISE archival data, we performed a variability study on the candidate\nbloated massive young stellar object (MYSO) IRAS 19520+2759. This is the first\ntime that a bloated star candidate has been tested for the theoretically\npredicted periodic variability. The source is found to be variable at optical\nand mid-infrared wavelengths and classified as a long-period variable MYSO. The\nobserved TJO data gives a period of the source of $\\sim$ 270$\\pm$40 days (in\nthe Rc band) and $\\sim$ 270$\\pm$50 days (in the Ic band), which is very close\nto the value predicted by the theoretical Period-Luminosity relation for a\nbloated young star of $\\sim 10^5 L\\odot$. Additionally, a large period of\n$\\sim$ 460$\\pm$80 days (in the G band) and $\\sim$ 440$\\pm$70 (in the Rp band)\nis also visible in the Gaia light curve. The physical parameters of the source,\nsuch as mass, radius, and accretion rate, based on the theoretical predictions\nfor the spherical accretion case and corresponding to a period of 270--460\ndays, are $\\sim 24$--28$\\,M\\odot$, $\\sim 650$--900$\\,R\\odot$ and $\\sim\n(6$--$9)\\times10^{-3}\\,M\\odot yr^{-1}$. However, these numbers are very\nsensitive to the effective temperatures assumed in the models. Additionally,\nthese values strongly depend on the geometry of accretion and could\nsignificantly decrease for the case of a MYSO accreting through a disc. The\nobserved periodic variability, the observed colour trend, and the nature of the\nvariability are found to be consistent with the pulsational model for a bloated\nMYSO."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11461",
    "c_title":[
      "Codes with symmetric distances"
    ],
    "c_abstract":[
      "For a code $C$ in a space with maximal distance $n$, we say that $C$ has\nsymmetric distances if its distance set $S(C)$ is symmetric with respect to $n\n\/ 2$. In this paper, we prove that if $C$ is a binary code with length $2n$,\nconstant weight $n$ and symmetric distances, then \\[\n  |C| \\leq \\binom{2 n - 1}{|S(C)|}. \\] This result can be interpreted using the\nlanguage of Johnson association schemes. More generally, we give a framework to\nstudy codes with symmetric distances in Q-bipartite Q-polynomial association\nschemes, and provide upper bounds for such codes. Moreover, we use number\ntheoretic techniques to determine when the equality holds."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-461",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11461",
    "b_title":[
      "MRS-CWC: A Weakly Constrained Multi-Robot System with Controllable\n  Constraint Stiffness for Mobility and Navigation in Unknown 3D Rough\n  Environments"
    ],
    "b_abstract":[
      "Navigating unknown three-dimensional (3D) rugged environments is challenging\nfor multi-robot systems. Traditional discrete systems struggle with rough\nterrain due to limited individual mobility, while modular systems--where rigid,\ncontrollable constraints link robot units--improve traversal but suffer from\nhigh control complexity and reduced flexibility. To address these limitations,\nwe propose the Multi-Robot System with Controllable Weak Constraints (MRS-CWC),\nwhere robot units are connected by constraints with dynamically adjustable\nstiffness. This adaptive mechanism softens or stiffens in real-time during\nenvironmental interactions, ensuring a balance between flexibility and\nmobility. We formulate the system's dynamics and control model and evaluate\nMRS-CWC against six baseline methods and an ablation variant in a benchmark\ndataset with 100 different simulation terrains. Results show that MRS-CWC\nachieves the highest navigation completion rate and ranks second in success\nrate, efficiency, and energy cost in the highly rugged terrain group,\noutperforming all baseline methods without relying on environmental modeling,\npath planning, or complex control. Even where MRS-CWC ranks second, its\nperformance is only slightly behind a more complex ablation variant with\nenvironmental modeling and path planning. Finally, we develop a physical\nprototype and validate its feasibility in a constructed rugged environment. For\nvideos, simulation benchmarks, and code, please visit\nhttps:\/\/wyd0817.github.io\/project-mrs-cwc\/."
    ],
    "b_categories":[
      [
        "cs.MA",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18058",
    "c_title":[
      "Magneto-Optics of Anisotropic Exciton Polaritons in Two-Dimensional\n  Perovskites"
    ],
    "c_abstract":[
      "Layered 2D organic-inorganic perovskite semiconductors support strongly\nconfined excitons that offer significant potential for ultrathin polaritonic\ndevices due to their tunability and huge oscillator strength. The application\nof a magnetic field has proven to be an invaluable tool for investigating the\nexciton fine structure observed in these materials. Yet, the combination of an\nin-plane magnetic field and the strong coupling regime has remained largely\nunexplored. In this work, we combine microscopic theory with a rigorous\nsolution of Maxwell's equations to model the magneto-optics of exciton\npolaritons in 2D perovskites. We predict that the brightened dark exciton state\ncan enter the strong coupling regime. Furthermore, the magnetic-field-induced\nmixing of polarization selection rules and the breaking of in-plane symmetry\nlead to highly anisotropic polariton branches. This study contributes to a\nbetter understanding of the exciton fine structure in 2D perovskites and\ndemonstrates the cavity control of highly anisotropic and\npolarization-sensitive exciton polaritons."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-462",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13051",
    "b_title":[
      "Permutation Learning with Only N Parameters: From SoftSort to\n  Self-Organizing Gaussians"
    ],
    "b_abstract":[
      "Sorting and permutation learning are key concepts in optimization and machine\nlearning, especially when organizing high-dimensional data into meaningful\nspatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N\nparameters to determine a full permutation matrix, making it computationally\nexpensive for large datasets. Low-rank matrix factorization approximations\nreduce memory requirements to 2MN (with M << N), but they still struggle with\nvery large problems. SoftSort, by providing a continuous relaxation of the\nargsort operator, allows differentiable 1D sorting, but it faces challenges\nwith multidimensional data and complex permutations. In this paper, we present\na novel method for learning permutations using only N parameters, which\ndramatically reduces storage costs. Our approach builds on SoftSort, but\nextends it by iteratively shuffling the N indices of the elements to be sorted\nthrough a separable learning process. This modification significantly improves\nsorting quality, especially for multidimensional data and complex optimization\ncriteria, and outperforms pure SoftSort. Our method offers improved memory\nefficiency and scalability compared to existing approaches, while maintaining\nhigh-quality permutation learning. Its dramatically reduced memory requirements\nmake it particularly well-suited for large-scale optimization tasks, such as\n\"Self-Organizing Gaussians\", where efficient and scalable permutation learning\nis critical."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.18259",
    "c_title":[
      "Generalization of terms via universal algebra"
    ],
    "c_abstract":[
      "We provide a new foundational approach to the generalization of terms up to\nequational theories. We interpret generalization problems in a\nuniversal-algebraic setting making a key use of projective and exact algebras\nin the variety associated to the considered equational theory. We prove that\nthe generality poset of a problem and its type (i.e., the cardinality of a\ncomplete set of least general solutions) can be studied in this algebraic\nsetting. Moreover, we identify a class of varieties where the study of the\ngenerality poset can be fully reduced to the study of the congruence lattice of\nthe 1-generated free algebra. We apply our results to varieties of algebras and\nto (algebraizable) logics. In particular we obtain several examples of unitary\ntype: abelian groups; commutative monoids and commutative semigroups; all\nvarieties whose 1-generated free algebra is trivial, e.g., lattices,\nsemilattices, varieties without constants whose operations are idempotent;\nBoolean algebras, Kleene algebras, and G\\\"odel algebras, which are the\nequivalent algebraic semantics of, respectively, classical, 3-valued Kleene,\nand G\\\"odel-Dummett logic."
    ],
    "c_categories":[
      [
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-463",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02731",
    "b_title":[
      "New investigation of the electronic and structural properties of\n  (Mg,Ti)-doped and co-doped ZnO structures: A DFT and DFT+U study"
    ],
    "b_abstract":[
      "This study investigates the novelty of the crystalline and electronic\nstructure of (Mg,Ti)-doped ZnO and the co-doped Zn1-x-yMgxTiyO structures using\nGaussian and plane-wave basis sets, as implemented in the CP2K code. The goal\nof incorporating low concentration of Mg and Ti into ZnO is to influence its\nelectronic properties without significantly altering its geometrical and\ncrystalline structure. Within the framework of density functional theory (DFT),\nwe analyze various doped and co-doped configurations. Our results show that\nTi-doped ZnO exhibits an indirect band gap, while Mg doping preserves the\ndirect semiconductor behavior of ZnO structure, with an increase in band gap\nenergy. Additionally, the co-doped Zn1-x-yMgxTiyO system, at varying\nconcentrations of Ti and Mg, displays minimal lattice deformation. These\nfindings suggest that this material could be a promising candidate for\ntransparent electronic devices, highlighting the importance of understanding\nthe electronic structure of ZnO to optimize its physical properties."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20711",
    "c_title":[
      "Periodic elements in finite type Artin-Tits groups and stability\n  conditions"
    ],
    "c_abstract":[
      "Periodic elements in finite type Artin--Tits groups are elements some\npositive power of which is central. We give a dynamical characterisation of\nperiodic elements via their action on the corresponding 2-Calabi--Yau category\nand on its space of (fusion equivariant) Bridgeland stability conditions. The\nmain theorem is that an element $\\beta$ is periodic if and only if $\\beta$ has\na fixed point in the stability manifold."
    ],
    "c_categories":[
      [
        "math.GR",
        "math.GT",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-464",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08486",
    "b_title":[
      "The NEMESIS Catalogue of Young Stellar Objects for the Orion Star\n  Formation Complex. I. General description of data curation"
    ],
    "b_abstract":[
      "The past decade has seen a rise in the use of Machine Learning methods in the\nstudy of young stellar evolution. This trend has led to a growing need for a\ncomprehensive database of young stellar objects (YSO) that goes beyond\nsurvey-specific biases and that can be employed for training, validation, and\nrefining the physical interpretation of machine learning outcomes. We reviewed\nthe literature focused on the Orion Star Formation complex (OSFC) to compile a\nthorough catalogue of previously identified YSO candidates in the region\nincluding the curation of observables relevant to probe their youth. Starting\nfrom the NASA\/ADS database, we assembled YSO candidates from more than 200\npeer-reviewed publications. We collated data products relevant to the study of\nYSOs into a dedicated catalogue, which was complemented with data from large\nphotometric and spectroscopic surveys and in the Strasbourg astronomical Data\nCenter. We also added significant value to the catalogue by homogeneously\nderiving YSO infrared classification labels and through a comprehensive\ncuration of labels concerning sources' multiplicity. Finally, we used a\npanchromatic approach to derive the probabilities that the sources in our\ncatalogue were contaminant extragalactic sources or giant stars. We present the\nNEMESIS catalogue of YSOs for the OSFC, which includes data collated for 27879\nsources covering the whole mass spectrum and the various stages of pre-Main\nSequence evolution from protostars to diskless young stars. The catalogue\nincludes a collection of panchromatic photometric data processed into spectral\nenergy distributions, stellar parameters, infrared classes, equivalent widths\nof emission lines related to YSOs accretion and star-disk interaction, and\nabsorption lines such as lithium and lines related to source's gravity, X-ray\nemission observables, photometric variability observables, and multiplicity\nlabels."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05854",
    "c_title":[
      "Accelerating Earth Science Discovery via Multi-Agent LLM Systems"
    ],
    "c_abstract":[
      "This Perspective explores the transformative potential of Multi-Agent Systems\n(MAS) powered by Large Language Models (LLMs) in the geosciences. Users of\ngeoscientific data repositories face challenges due to the complexity and\ndiversity of data formats, inconsistent metadata practices, and a considerable\nnumber of unprocessed datasets. MAS possesses transformative potential for\nimproving scientists' interaction with geoscientific data by enabling\nintelligent data processing, natural language interfaces, and collaborative\nproblem-solving capabilities. We illustrate this approach with \"PANGAEA GPT\", a\nspecialized MAS pipeline integrated with the diverse PANGAEA database for Earth\nand Environmental Science, demonstrating how MAS-driven workflows can\neffectively manage complex datasets and accelerate scientific discovery. We\ndiscuss how MAS can address current data challenges in geosciences, highlight\nadvancements in other scientific fields, and propose future directions for\nintegrating MAS into geoscientific data processing pipelines. In this\nPerspective, we show how MAS can fundamentally improve data accessibility,\npromote cross-disciplinary collaboration, and accelerate geoscientific\ndiscoveries."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-465",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01838",
    "b_title":[
      "Electronic band structures of topological kagome materials"
    ],
    "b_abstract":[
      "The kagome lattice has garnered significant attention due to its ability to\nhost quantum spin Fermi liquid states. Recently, the combination of unique\nlattice geometry, electron-electron correlations, and adjustable magnetism in\nsolid kagome materials has led to the discovery of numerous fascinating quantum\nproperties. These include unconventional superconductivity, charge and spin\ndensity waves (CDW\/SDW), pair density waves (PDW), and Chern insulator phases.\nThese emergent states are closely associated with the distinctive\ncharacteristics of the kagome lattice's electronic structure, such as van Hove\nsingularities, Dirac fermions, and flat bands, which can exhibit exotic\nquasi-particle excitations under different symmetries and magnetic conditions.\nRecently, various quantum kagome materials have been developed, typically\nconsisting of kagome layers stacked along the $z$-axis with atoms either\nfilling the geometric centers of the kagome lattice or embedded between the\nlayers. In this topical review, we begin by introducing the fundamental\nproperties of several kagome materials. To gain an in-depth understanding of\nthe relationship between topology and correlation, we then discuss the complex\nphenomena observed in these systems. These include the simplest kagome metal\n$T_3X$, kagome intercalation metal $TX$, and the ternary compounds $AT_6X_6$\nand $RT_3X_5$ ($A$ = Li, Mg, Ca, or rare earth; $T$ = V, Cr, Mn, Fe, Co, Ni;\n$X$ = Sn, Ge; $R$ = K, Rb, Cs). Finally, we provide a perspective on future\nexperimental work in this field."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17768",
    "c_title":[
      "TeamPortal: Exploring Virtual Reality Collaboration Through Shared and\n  Manipulating Parallel Views"
    ],
    "c_abstract":[
      "Virtual Reality (VR) offers a unique collaborative experience, with parallel\nviews playing a pivotal role in Collaborative Virtual Environments by\nsupporting the transfer and delivery of items. Sharing and manipulating\npartners' views provides users with a broader perspective that helps them\nidentify the targets and partner actions. We proposed TeamPortal accordingly\nand conducted two user studies with 72 participants (36 pairs) to investigate\nthe potential benefits of interactive, shared perspectives in VR collaboration.\nOur first study compared ShaView and TeamPortal against a baseline in a\ncollaborative task that encompassed a series of searching and manipulation\ntasks. The results show that TeamPortal significantly reduced movement and\nincreased collaborative efficiency and social presence in complex tasks.\nFollowing the results, the second study evaluated three variants: TeamPortal+,\nSnapTeamPortal+, and DropTeamPortal+. The results show that both\nSnapTeamPortal+ and DropTeamPortal+ improved task efficiency and willingness to\nfurther adopt these technologies, though SnapTeamPortal+ reduced co-presence.\nBased on the findings, we proposed three design implications to inform the\ndevelopment of future VR collaboration systems."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-466",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09588",
    "b_title":[
      "Atleus: Accelerating Transformers on the Edge Enabled by 3D\n  Heterogeneous Manycore Architectures"
    ],
    "b_abstract":[
      "Transformer architectures have become the standard neural network model for\nvarious machine learning applications including natural language processing and\ncomputer vision. However, the compute and memory requirements introduced by\ntransformer models make them challenging to adopt for edge applications.\nFurthermore, fine-tuning pre-trained transformers (e.g., foundation models) is\na common task to enhance the model's predictive performance on specific\ntasks\/applications. Existing transformer accelerators are oblivious to\ncomplexities introduced by fine-tuning. In this paper, we propose the design of\na three-dimensional (3D) heterogeneous architecture referred to as Atleus that\nincorporates heterogeneous computing resources specifically optimized to\naccelerate transformer models for the dual purposes of fine-tuning and\ninference. Specifically, Atleus utilizes non-volatile memory and systolic array\nfor accelerating transformer computational kernels using an integrated 3D\nplatform. Moreover, we design a suitable NoC to achieve high performance and\nenergy efficiency. Finally, Atleus adopts an effective quantization scheme to\nsupport model compression. Experimental results demonstrate that Atleus\noutperforms existing state-of-the-art by up to 56x and 64.5x in terms of\nperformance and energy efficiency respectively"
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12596",
    "c_title":[
      "Adapting OpenAI's CLIP Model for Few-Shot Image Inspection in\n  Manufacturing Quality Control: An Expository Case Study with Multiple\n  Application Examples"
    ],
    "c_abstract":[
      "This expository paper introduces a simplified approach to image-based quality\ninspection in manufacturing using OpenAI's CLIP (Contrastive Language-Image\nPretraining) model adapted for few-shot learning. While CLIP has demonstrated\nimpressive capabilities in general computer vision tasks, its direct\napplication to manufacturing inspection presents challenges due to the domain\ngap between its training data and industrial applications. We evaluate CLIP's\neffectiveness through five case studies: metallic pan surface inspection, 3D\nprinting extrusion profile analysis, stochastic textured surface evaluation,\nautomotive assembly inspection, and microstructure image classification. Our\nresults show that CLIP can achieve high classification accuracy with relatively\nsmall learning sets (50-100 examples per class) for single-component and\ntexture-based applications. However, the performance degrades with complex\nmulti-component scenes. We provide a practical implementation framework that\nenables quality engineers to quickly assess CLIP's suitability for their\nspecific applications before pursuing more complex solutions. This work\nestablishes CLIP-based few-shot learning as an effective baseline approach that\nbalances implementation simplicity with robust performance, demonstrated in\nseveral manufacturing quality control applications."
    ],
    "c_categories":[
      [
        "cs.CV",
        "stat.AP",
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-467",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08447",
    "b_title":[
      "Investigating the broadening phenomenon in two-particle correlations\n  induced by gluon saturation"
    ],
    "b_abstract":[
      "It has been found that the gluon density inside the proton grows rapidly at\nsmall momentum fractions. Quantum Chromodynamics (QCD) predicts that this\ngrowth can be regulated by nonlinear effects, ultimately leading to gluon\nsaturation. Within the color glass condensate framework, nonlinear QCD effects\nare predicted to suppress and broaden back-to-back angular correlations in\ncollisions involving heavy nuclei. While suppression has been observed in\nvarious experiments in $d\/p$$+$A collisions compared to $p$$+$$p$ collisions,\nthe predicted broadening remains unobserved. This study investigates the\ncontributions of intrinsic transverse momentum ($k_T$), which is associated\nwith saturation physics, as well as parton showers and transverse motion from\nfragmentation ($p_T^{\\mathrm{frag}}$), which are not saturation dependent, to\nthe width of the correlation function. Our findings show that the\nnon-saturation dependent effects, especially the initial-state parton shower\nand $p_T^{\\mathrm{frag}}$, which occur independently of the collision system,\nsmear the back-to-back correlation more than gluon saturation does, making the\nbroadening phenomenon difficult to observe."
    ],
    "b_categories":[
      [
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00271",
    "c_title":[
      "Scaling Flaws of Verifier-Guided Search in Mathematical Reasoning"
    ],
    "c_abstract":[
      "Large language models (LLMs) struggle with multi-step reasoning, where\ninference-time scaling has emerged as a promising strategy for performance\nimprovement. Verifier-guided search outperforms repeated sampling when sample\nsize is limited by selecting and prioritizing valid reasoning paths. However,\nwe identify a critical limitation: scaling flaws, prevalent across different\nmodels (Mistral 7B and DeepSeekMath 7B), benchmarks (GSM8K and MATH), and\nverifiers (outcome value models and process reward models). As sample size\nincreases, verifier-guided search exhibits diminishing advantages and\neventually underperforms repeated sampling. Our analysis attributes this to\nverifier failures, where imperfect verifiers misrank candidates and erroneously\nprune all valid paths. These issues are further exacerbated in challenging and\nout-of-distribution problems, restricting search effectiveness. To mitigate\nverifier failures, we explore reducing reliance on verifiers and conduct\npreliminary investigations using two simple methods. Our findings reveal\nfundamental limitations in verifier-guided search and suggest future\ndirections."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-468",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01491",
    "b_title":[
      "Memorization Inheritance in Sequence-Level Knowledge Distillation for\n  Neural Machine Translation"
    ],
    "b_abstract":[
      "In this work, we explore how instance-level memorization in the teacher\nNeural Machine Translation (NMT) model gets inherited by the student model in\nsequence-level knowledge distillation (SeqKD). We find that despite not\ndirectly seeing the original training data, students memorize more than\nbaseline models (models of the same size, trained on the original data) -- 3.4%\nfor exact matches and 57% for extractive memorization -- and show increased\nhallucination rates. Further, under this SeqKD setting, we also characterize\nhow students behave on specific training data subgroups, such as subgroups with\nlow quality and specific counterfactual memorization (CM) scores, and find that\nstudents exhibit amplified denoising on low-quality subgroups. Finally, we\npropose a modification to SeqKD named Adaptive-SeqKD, which intervenes in SeqKD\nto reduce memorization and hallucinations. Overall, we recommend caution when\napplying SeqKD: students inherit both their teachers' superior performance and\ntheir fault modes, thereby requiring active monitoring."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05522",
    "c_title":[
      "Anomalous Reynolds stress and dynamic mechanisms in two-dimensional\n  elasto-inertial turbulence of viscoelastic channel flow"
    ],
    "c_abstract":[
      "Elasto-inertial turbulence (EIT) has been demonstrated to be able to sustain\nin two-dimensional (2D) channel flow; however the systematic investigations on\n2D EIT remain scare. This study addresses this gap by examining the statistical\ncharacteristics and dynamic mechanisms of 2D EIT, while exploring its\nsimilarities to and differences from three-dimensional (3D) EIT. We demonstrate\nthat the influence of elasticity on the statistical properties of 2D EIT\nfollows distinct trends compared to those observed in 3D EIT and drag-reducing\nturbulence (DRT). These differences can be attributed to variations in the\nunderlying dynamical processes. As nonlinear elasticity increases, the dominant\ndynamic evolution in 3D flows involves the gradual suppression of inertial\nturbulence (IT). In contrast, 2D flows exhibit a progressive enhancement of\nEIT. More strikingly, we identify an anomalous Reynolds stress in 2D EIT that\ncontributes negatively to flow resistance, a behavior opposite to that of IT.\nQuadrant analysis of velocity fluctuations reveals the predominance of motions\nin the first and third quadrants. These motions are closely associated with\npolymer sheet-like extension structures, which are inclined from the near-wall\nregion toward the channel center along the streamwise direction. Finally, we\npresent the dynamical budget of 2D EIT, which shows significant similarities to\nthat of 3D EIT, thereby providing compelling evidence for the objective\nexistence of the 2D nature of EIT."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-469",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15548",
    "b_title":[
      "Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval"
    ],
    "b_abstract":[
      "The widespread adoption of Retrieval-Augmented Generation (RAG) systems in\nreal-world applications has heightened concerns about the confidentiality and\nintegrity of their proprietary knowledge bases. These knowledge bases, which\nplay a critical role in enhancing the generative capabilities of Large Language\nModels (LLMs), are increasingly vulnerable to breaches that could compromise\nsensitive information. To address these challenges, this paper proposes an\nadvanced encryption methodology designed to protect RAG systems from\nunauthorized access and data leakage. Our approach encrypts both textual\ncontent and its corresponding embeddings prior to storage, ensuring that all\ndata remains securely encrypted. This mechanism restricts access to authorized\nentities with the appropriate decryption keys, thereby significantly reducing\nthe risk of unintended data exposure. Furthermore, we demonstrate that our\nencryption strategy preserves the performance and functionality of RAG\npipelines, ensuring compatibility across diverse domains and applications. To\nvalidate the robustness of our method, we provide comprehensive security proofs\nthat highlight its resilience against potential threats and vulnerabilities.\nThese proofs also reveal limitations in existing approaches, which often lack\nrobustness, adaptability, or reliance on open-source models. Our findings\nsuggest that integrating advanced encryption techniques into the design and\ndeployment of RAG systems can effectively enhance privacy safeguards. This\nresearch contributes to the ongoing discourse on improving security measures\nfor AI-driven services and advocates for stricter data protection standards\nwithin RAG architectures."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11917",
    "c_title":[
      "On the existence of twisted Shalika periods: the Archimedean case"
    ],
    "c_abstract":[
      "Let $\\K$ be an archimedean local field. We investigate the existence of the\ntwisted Shalika functionals on irreducible admissible smooth representations of\n$\\GL_{2n}(\\K)$ in terms of their L-parameters. As part of our proof, we\nestablish a Hochschild-Serre spectral sequence for nilpotent normal subgroups\nand a Kunneth formula in the framework of Schwartz homology. We also prove the\nanalogous result for twisted linear periods using theta correspondence. The\nexistence of twisted Shalika functionals on representations of\n$\\GL_{2n}^{+}(\\R)$ is also studied, which is of independent interest."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-470",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00593",
    "b_title":[
      "Electromagnetic Electron Kelvin-Helmholtz Instability"
    ],
    "b_abstract":[
      "On electron kinetic scales, ions and electrons decouple, and electron\nvelocity shear on electron inertial length $\\sim d_e$ can trigger\nelectromagnetic (EM) electron Kelvin-Helmholtz instability (EKHI). In this\npaper, we present an analytic study of EM EKHI in an inviscid collisionless\nplasma with a step-function electron shear flow. We show that in incompressible\ncollisionless plasma the ideal electron frozen-in condition $\\mathbf{E} +\n\\mathbf{v}_e \\times \\mathbf{B}\/c = 0$ must be broken for the EM EKHI to occur.\nIn a step-function electron shear flow, the ideal electron frozen-in condition\nis replaced by magnetic flux conservation, i.e., $\\nabla \\times (\\mathbf{E} +\n\\mathbf{v}_e\\times \\mathbf{B}\/c) = 0$, resulting in a dispersion relation\nsimilar to that of the standard ideal and incompressible magnetohydrodynamics\nKHI. The magnetic field parallel to the electron streaming suppresses the EM\nEKHI due to magnetic tension. The threshold for the EM mode of the EKHI is\n$(\\mathbf{k}\\cdot\\Delta\\mathbf{U}_e)^2>\\frac{n_{e1}+n_{e2}}{n_{e1}\nn_{e2}}[n_{e1}(\\mathbf{v}_{Ae1}\\cdot\\mathbf{k})^2+n_{e2}(\\mathbf{v}_{Ae2}\\cdot\\mathbf{k})^2]$,\nwhere $\\mathbf{v}_{Ae} =\\mathbf{B}\/(4\\pi m_e n_e)^{1\/2}$, $\\Delta\\mathbf{U}_e$\nand $n_e$ are the electron streaming velocity shear and densities,\nrespectively. The growth rate of the EM mode is $\\gamma_{em} \\sim \\Omega_{ce}$,\nthe electron gyro-frequency."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06269",
    "c_title":[
      "OpenAI ChatGPT interprets Radiological Images: GPT-4 as a Medical Doctor\n  for a Fast Check-Up"
    ],
    "c_abstract":[
      "OpenAI released version GPT-4 on March 14, 2023, following the success of\nChatGPT, which was announced in November 2022. In addition to the existing\nGPT-3 features, GPT-4 can interpret images. To achieve this, the processing\npower and model have been significantly improved. The ability to process and\ninterpret images goes far beyond the applications and effectiveness of\nartificial intelligence. In this study, we first explored the interpretation of\nradiological images in healthcare using artificial intelligence (AI). Then, we\nexperimented with the image interpretation capability of the GPT-4. In this\nway, we addressed the question of whether artificial intelligence (AI) can\nreplace a healthcare professional (e.g., a medical doctor) or whether it can be\nused as a decision-support tool that makes decisions easier and more reliable.\nOur results showed that ChatGPT is not sufficient and accurate to analyze chest\nX-ray images, but it can provide interpretations that can assist medical\ndoctors or clinicians."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-471",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00562",
    "b_title":[
      "Quantum Lamb model"
    ],
    "b_abstract":[
      "H. Lamb considered the classical dynamics of a vibrating particle embedded in\nan elastic medium before the development of quantum theory. Lamb was interested\nin how the back-action of the elastic waves generated can damp the vibrations\nof the particle. We propose a quantum version of Lamb's model. We show that\nthis model is exactly solvable by using a multimode Bogoliubov transformation.\nWe show that the exact system ground state is a multimode squeezed vacuum\nstate, and we obtain the exact Bogoliubov frequencies by numerically solving a\nnonlinear integral equation. A closed-form expression for the damping rate of\nthe particle is obtained, and we find that it agrees with the result obtained\nby perturbation theory for coupling strength below a critical value. The model\nis found to break down for coupling strength above the critical value where the\nlowest Bogoliubov frequency vanishes. We show that the addition of an\nanharmonic elastic term is sufficient to stabilize the system in this strong\ncoupling regime."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11584",
    "c_title":[
      "Image Reconstruction from an Elastically Distorted Scan"
    ],
    "c_abstract":[
      "We consider the problem of inverting the artifacts associated with scanning a\npage from an open book, i.e. \"xeroxing.\" The process typically leads to a\nnon-uniform combination of distortion, blurring and darkening owing to the fact\nthat the page is bound to a stiff spine that causes the sheet of paper to be\nbent inhomogeneously. Complementing purely data-driven approaches, we use\nknowledge about the geometry and elasticity of the curved sheet to pose and\nsolve a minimal physically consistent inverse problem to reconstruct the image.\nOur results rely on 3 dimensionless parameters, all of which can be measured\nfor a scanner, and show that we can improve on the data-driven approaches. More\nbroadly, our results might serve as a \"textbook\" example and a tutorial of how\nknowledge of generative mechanisms can speed up the solution of inverse\nproblems."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-472",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05238",
    "b_title":[
      "Neutrino spin oscillations near a black hole"
    ],
    "b_abstract":[
      "In this work, we study neutrino spin oscillations in the case when they are\ngravitationally scattered off a rotating Kerr black hole surrounded by a thick\nmagnetized accretion disk. We consider only toroidal magnetic field inside the\ndisk. Neutrino spin precession is caused by the interaction of the neutrino\nmagnetic moment with the magnetic field in the disk. Our treatment of the spin\noscillations of the observed neutrino fluxes is based on numerical simulations\nof the propagation of a large number of incoming test neutrinos using High\nPerformance Parallel Computing. We briefly discuss our results and their\napplications in the observations of astrophysical neutrinos."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12435",
    "c_title":[
      "XAI-Driven Client Selection for Federated Learning in Scalable 6G\n  Network Slicing"
    ],
    "c_abstract":[
      "In recent years, network slicing has embraced artificial intelligence (AI)\nmodels to manage the growing complexity of communication networks. In such a\nsituation, AI-driven zero-touch network automation should present a high degree\nof flexibility and viability, especially when deployed in live production\nnetworks. However, centralized controllers suffer from high data communication\noverhead due to the vast amount of user data, and most network slices are\nreluctant to share private data. In federated learning systems, selecting\ntrustworthy clients to participate in training is critical for ensuring system\nperformance and reliability. The present paper proposes a new approach to\nclient selection by leveraging an XAI method to guarantee scalable and fast\noperation of federated learning based analytic engines that implement\nslice-level resource provisioning at the RAN-Edge in a non-IID scenario.\nAttributions from XAI are used to guide the selection of devices participating\nin training. This approach enhances network trustworthiness for users and\naddresses the black-box nature of neural network models. The simulations\nconducted outperformed the standard approach in terms of both convergence time\nand computational cost, while also demonstrating high scalability."
    ],
    "c_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-473",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17066",
    "b_title":[
      "Formation of condensations for non-radial solutions to 3-wave kinetic\n  equations"
    ],
    "b_abstract":[
      "We consider in this work a $2$-dimensional $3$-wave kinetic equation\ndescribing the dynamics of the thermal cloud outside a Bose-Einstein\nCondensate. We construct global non-radial mild solutions for the equation.\nThose mild solutions are the summation of Dirac masses on circles. We prove\nthat in each spatial direction, either Dirac masses at the origin, which are\nthe so-called Bose-Einstein condensates, can be formed in finite time or the\nsolutions converge to Bose-Einstein condensates as time evolves to infinity. We\nalso describe a dynamics of the formation of the Bose-Einstein condensates\nlatter case. In this case, on each direction, the solutions accumulate around\ncircles close to the origin at growth rates at least linearly in time."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02632",
    "c_title":[
      "The gravitational path integral from an observer's point of view"
    ],
    "c_abstract":[
      "One of the fundamental problems in quantum gravity is to describe the\nexperience of a gravitating observer in generic spacetimes. In this paper, we\ndevelop a framework for describing non-perturbative physics relative to an\nobserver using the gravitational path integral. We apply our proposal to an\nobserver that lives in a closed universe and one that falls behind a black hole\nhorizon. We find that the Hilbert space that describes the experience of the\nobserver is much larger than the Hilbert space in the absence of an observer.\nIn the case of closed universes, the Hilbert space is not one-dimensional, as\ncalculations in the absence of the observer suggest. Rather, its dimension\nscales exponentially with $G_N^{-1}$. Similarly, from an observer's\nperspective, the dimension of the Hilbert space in a two-sided black hole is\nincreased. We compute various observables probing the experience of a\ngravitating observer in this Hilbert space. We find that an observer\nexperiences non-trivial physics in the closed universe in contrast to what it\nwould see in a one-dimensional Hilbert space. In the two-sided black hole\nsetting, our proposal implies that non-perturbative corrections to effective\nfield theory for an infalling observer are suppressed until times exponential\nin the black hole entropy, resolving a recently raised puzzle in black hole\nphysics. While the framework that we develop is exemplified in the toy-model of\nJT gravity, most of our analysis can be extended to higher dimensions and, in\nparticular, to generic spacetimes not admitting a conventional holographic\ndescription, such as cosmological universes or black hole interiors."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-474",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02139",
    "b_title":[
      "The space writhes and signatures of polymer knots"
    ],
    "b_abstract":[
      "The space writhe of a knot is a property of its three-dimensional embedding\nthat contains information about its underlying topology, but the correspondence\nbetween space writhe and other topological invariants is not fully understood.\nWe perform Langevin dynamics simulations of knotted semiflexible polymers and\nmeasure their ensemble average space writhe. We show that for all knots up to\n10 crossings, alternating and non-alternating, the average space writhe is\nalmost equal to that of the tightest known configuration of the same knot, with\nminor differences. Using this equivalence, we show that for more complex knots\nwith up to 38 crossings, the average space writhe is strongly correlated with\nthe signature of the knot. This establishes that the connection between\nsignature and space writhe holds at larger crossing numbers."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16047",
    "c_title":[
      "Interpreting the $X(2370)$ and $X(2600)$ as light tetraquark states"
    ],
    "c_abstract":[
      "Inspired by the states $X(2370)$ and $X(2600)$ reported by the BESIII\nCollaboration, we systematically investigate the mass spectra of light compact\ntetraquark states with configurations $ud\\bar{u}\\bar{d}$, $us\\bar{u}\\bar{s}$,\nand $ss\\bar{s}\\bar{s}$ in the $J^{PC}=0^{-+}$ and $2^{-+}$ channels using the\nQCD sum rules approach. To effectively describe these tetraquark states, we\nconstruct appropriate interpolating tetraquark currents featuring three Lorentz\nindices while avoiding derivative operators. Through meticulous calculations of\ncorrelation functions up to dimension 10 condensates, we extract the mass\nspectra for both $0^{-+}$ and $2^{-+}$ states by employing the projection\noperator technique. Our results indicate that the masses of light tetraquarks\nspan $1.5-2.5~\\text{GeV}$ for $0^{-+}$ states and $2.4-2.7~\\text{GeV}$ for\n$2^{-+}$ states. Notably, our analysis suggests that the $X(2370)$ state could\nbe interpreted as a $0^{-+}$ $us\\bar{u}\\bar{s}$ or $ss\\bar{s}\\bar{s}$\ntetraquark state, while the $X(2600)$ state is likely to be a $2^{-+}$\n$us\\bar{u}\\bar{s}$ tetraquark. These intriguing findings warrant further\ndetailed investigation in future studies to better understand the nature of\nthese states."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-475",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09610",
    "b_title":[
      "Elucidating the Physical and Mathematical Properties of the\n  Prouhet-Thue-Morse Sequence in Quantum Computing"
    ],
    "b_abstract":[
      "This study explores the applications of the Prouhet-Thue-Morse (PTM) sequence\nin quantum computing, highlighting its mathematical elegance and practical\nrelevance. We demonstrate the critical role of the PTM sequence in quantum\nerror correction, in noise-resistant quantum memories, and in providing\ninsights into quantum chaos. Notably, we demonstrate how the PTM sequence\nnaturally appears in Ising X-X interacting systems, leading to a proposed\nrobust encoding of quantum memories in such systems. Furthermore, connections\nto number theory, including the Riemann zeta function, bridge quantum computing\nwith pure mathematics. Our findings emphasize the PTM sequence's importance in\nunderstanding the mathematical structure of quantum computing systems and the\ndevelopment of the full potential of quantum technologies and invite further\ninterdisciplinary research."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.18414",
    "c_title":[
      "GLEAN: Generalized Category Discovery with Diverse and Quality-Enhanced\n  LLM Feedback"
    ],
    "c_abstract":[
      "Generalized Category Discovery (GCD) is a practical and challenging\nopen-world task that aims to recognize both known and novel categories in\nunlabeled data using limited labeled data from known categories. Due to the\nlack of supervision, previous GCD methods face significant challenges, such as\ndifficulty in rectifying errors for confusing instances, and inability to\neffectively uncover and leverage the semantic meanings of discovered clusters.\nTherefore, additional annotations are usually required for real-world\napplicability. However, human annotation is extremely costly and inefficient.\nTo address these issues, we propose GLEAN, a unified framework for generalized\ncategory discovery that actively learns from diverse and quality-enhanced LLM\nfeedback. Our approach leverages three different types of LLM feedback to: (1)\nimprove instance-level contrastive features, (2) generate category\ndescriptions, and (3) align uncertain instances with LLM-selected category\ndescriptions. Extensive experiments demonstrate the superior performance of\n\\MethodName over state-of-the-art models across diverse datasets, metrics, and\nsupervision settings. Our code is available at\nhttps:\/\/github.com\/amazon-science\/Glean."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-476",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09803",
    "b_title":[
      "Graph Neural Networks for Travel Distance Estimation and Route\n  Recommendation Under Probabilistic Hazards"
    ],
    "b_abstract":[
      "Estimating the shortest travel time and providing route recommendation\nbetween different locations in a city or region can quantitatively measure the\nconditions of the transportation network during or after extreme events. One\ncommon approach is to use Dijkstra's Algorithm, which produces the shortest\npath as well as the shortest distance. However, this option is computationally\nexpensive when applied to large-scale networks. This paper proposes a novel\nfast framework based on graph neural networks (GNNs) which approximate the\nsingle-source shortest distance between pairs of locations, and predict the\nsingle-source shortest path subsequently. We conduct multiple experiments on\nsynthetic graphs of different size to demonstrate the feasibility and\ncomputational efficiency of the proposed model. In real-world case studies, we\nalso applied the proposed method of flood risk analysis of coastal urban areas\nto calculate delays in evacuation to public shelters during hurricanes. The\nresults indicate the accuracy and computational efficiency of the GNN model,\nand its potential for effective implementation in emergency planning and\nmanagement."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04187",
    "c_title":[
      "Cubic Dirac Operators and Dirac Cohomology for Basic Classical Lie\n  Superalgebras"
    ],
    "c_abstract":[
      "We study the Dirac cohomology of supermodules over basic classical Lie\nsuperalgebras, formulated in terms of cubic Dirac operators associated with\nparabolic subalgebras. Specifically, we establish a super-analog of the\nCasselman-Osborne theorem for supermodules with an infinitesimal character and\nuse it to show that the Dirac cohomology of highest-weight supermodules is\nalways non-trivial. In particular, we explicitly compute the Dirac cohomology\nof finite-dimensional simple supermodules for basic Lie superalgebras of type 1\nwith a typical highest weight, as well as of simple supermodules in the\nparabolic BGG category. We further investigate the relationship between Dirac\ncohomology and Kostant (co)homology, proving that, under suitable conditions,\nDirac cohomology embeds into Kostant (co)homology. Moreover, we show that this\nembedding lifts to an isomorphism when the supermodule is unitarizable."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-477",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14421",
    "b_title":[
      "Reasoning about Weak Isolation Levels in Separation Logic"
    ],
    "b_abstract":[
      "Isolation levels, consistency guarantees among concurrently execution\ntransactions in local- and distributed systems, have been formalized in a\nnumber of models. Thus far, no model can reason about executable\nimplementations of databases or local transaction libraries providing weak\nisolation levels. Weak isolation levels are characterized by being highly\nconcurrent and, unlike their stronger counterpart serializability, they are not\nequivalent to the consistency guarantees provided by a transaction library\nimplemented using a global lock. In this paper, we formalize three weak\nisolation levels in separation logic, namely read uncommitted, read committed,\nand snapshot isolation. We define modular separation logic specifications that\nare independent of the underlying transaction library implementation.\nHistorically, isolation levels have been specified using examples of executions\nbetween concurrent transactions that are not allowed to occur, and we\ndemonstrate that our specifications correctly prohibit such examples. To show\nthat our specifications are realizable, we formally verify that an executable\nimplementation of a key-value database running the multi-version concurrency\ncontrol algorithm from the original snapshot isolation paper satisfies our\nspecification of snapshot isolation. Moreover, we prove implications between\nthe specifications -- snapshot isolation implies read committed and read\ncommitted implies read uncommitted -- and thus the verification effort of the\ndatabase serves as proof that all of our specifications are realizable. All\nresults are mechanised in the Coq proof assistant on top of the Iris separation\nlogic framework."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00830",
    "c_title":[
      "Periodic Response Solutions to Multi-Dimensional Nonlinear Schr\\\"odinger\n  equation with unbounded perturbation"
    ],
    "c_abstract":[
      "By applying the Craig-Wayne-Bourgain (CWB) method, we establish the existence\nof periodic response solutions to multi-dimensional nonlinear Schr\\\"{o}dinger\nequations (NLS) with unbounded perturbation."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-478",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01186",
    "b_title":[
      "Unbounded rough drivers, rough PDEs and applications"
    ],
    "b_abstract":[
      "A summary of recent contributions in the field of rough partial differential\nequations is given. For that purpose we rely on the formalism of ``unbounded\nrough driver''. We present applications to concrete models including\nLandau-Lifshitz-Gilbert, Navier-Stokes and Euler equations."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16167",
    "c_title":[
      "CodeReviewQA: The Code Review Comprehension Assessment for Large\n  Language Models"
    ],
    "c_abstract":[
      "State-of-the-art large language models (LLMs) have demonstrated impressive\ncode generation capabilities but struggle with real-world software engineering\ntasks, such as revising source code to address code reviews, hindering their\npractical use. Code review comments are often implicit, ambiguous, and\ncolloquial, requiring models to grasp both code and human intent. This\nchallenge calls for evaluating large language models' ability to bridge both\ntechnical and conversational contexts. While existing work has employed the\nautomated code refinement (ACR) task to resolve these comments, current\nevaluation methods fall short, relying on text matching metrics that provide\nlimited insight into model failures and remain susceptible to training data\ncontamination. To address these limitations, we introduce a novel evaluation\nbenchmark, $\\textbf{CodeReviewQA}$ that enables us to conduct fine-grained\nassessment of model capabilities and mitigate data contamination risks. In\nCodeReviewQA, we decompose the generation task of code refinement into\n$\\textbf{three essential reasoning steps}$: $\\textit{change type recognition}$\n(CTR), $\\textit{change localisation}$ (CL), and $\\textit{solution\nidentification}$ (SI). Each step is reformulated as multiple-choice questions\nwith varied difficulty levels, enabling precise assessment of model\ncapabilities, while mitigating data contamination risks. Our comprehensive\nevaluation spans 72 recently released large language models on $\\textbf{900\nmanually curated, high-quality examples}$ across nine programming languages.\nOur results show that CodeReviewQA is able to expose specific model weaknesses\nin code review comprehension, disentangled from their generative automated code\nrefinement results."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-479",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04290",
    "b_title":[
      "Research on the Interstellar Medium and Star Formation in the Galaxy: An\n  Indian Perspective"
    ],
    "b_abstract":[
      "Although the star formation process has been studied for decades, many\nimportant aspects of the physics involved remain unsolved. Recent advancement\nof instrumentation in the infrared, far-infrared and sub-millimetre wavelength\nregimes have contributed to a significantly improved understanding of processes\nin the interstellar medium (ISM) leading to star formation. The future of\nresearch on the ISM and star formation looks exciting with instruments like the\nJWST, ALMA, etc., already contributing to the topic by gathering\nhigh-resolution high-sensitivity data and with several larger ground- and\nspace-bound facilities either being planned or constructed. India has a sizable\nnumber of astronomers engaged in research on topics related to the ISM and star\nformation. In this white paper invited by the Astronomical Society of India to\nprepare a vision document for Indian astronomy, we review the Indian\ncontributions to the global understanding of the star formation process and\nsuggest areas that require focused efforts both in creating observing\nfacilities and in theoretical front in India, in order to improve the impact of\nour research in the coming decades."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06830",
    "c_title":[
      "Strong Ramsey game on two boards"
    ],
    "c_abstract":[
      "The strong Ramsey game $R(\\mathcal{B}, H)$ is a two-player game played on a\ngraph $\\mathcal{B}$, referred to as the board, with a target graph $H$. In this\ngame, two players, $P_1$ and $P_2$, alternately claim unclaimed edges of\n$\\mathcal{B}$, starting with $P_1$. The goal is to claim a subgraph isomorphic\nto $H$, with the first player achieving this declared the winner. A fundamental\nopen question, persisting for over three decades, asks whether there exists a\ngraph $H$ such that in the game $R(K_n, H)$, $P_1$ does not have a winning\nstrategy in a bounded number of moves as $n \\to \\infty$.\n  In this paper, we shift the focus to the variant $R(K_n \\sqcup K_n, H)$,\nintroduced by David, Hartarsky, and Tiba, where the board $K_n \\sqcup K_n$\nconsists of two disjoint copies of $K_n$. We prove that there exist infinitely\nmany graphs $H$ such that $P_1$ cannot win in $R(K_n \\sqcup K_n, H)$ within a\nbounded number of moves through a concise proof. This perhaps provides evidence\nfor the existence of examples to the above longstanding open problem."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-480",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14797",
    "b_title":[
      "FACTS&EVIDENCE: An Interactive Tool for Transparent Fine-Grained Factual\n  Verification of Machine-Generated Text"
    ],
    "b_abstract":[
      "With the widespread consumption of AI-generated content, there has been an\nincreased focus on developing automated tools to verify the factual accuracy of\nsuch content. However, prior research and tools developed for fact verification\ntreat it as a binary classification or a linear regression problem. Although\nthis is a useful mechanism as part of automatic guardrails in systems, we argue\nthat such tools lack transparency in the prediction reasoning and diversity in\nsource evidence to provide a trustworthy user experience. We develop\nFacts&Evidence - an interactive and transparent tool for user-driven\nverification of complex text. The tool facilitates the intricate\ndecision-making involved in fact-verification, presenting its users a breakdown\nof complex input texts to visualize the credibility of individual claims along\nwith an explanation of model decisions and attribution to multiple, diverse\nevidence sources. Facts&Evidence aims to empower consumers of machine-generated\ntext and give them agency to understand, verify, selectively trust and use such\ntext."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12605",
    "c_title":[
      "Periodic Points of Diagonal and Permutation Operators"
    ],
    "c_abstract":[
      "We first give a condition for a normal operator on a Hilbert space to have no\nnonzero periodic points, then we give a characterization of normal operators\nwith the whole space as periodic points. We proceed to study the structure of\nperiodic points of the diagonal operators and the permutation operators with\nexamples. Moreover, it is also shown that the set of all diagonal operators\nwith the whole space as periodic points is dense in the set of all unitary\ndiagonal operators."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-481",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20639",
    "b_title":[
      "FedConv: A Learning-on-Model Paradigm for Heterogeneous Federated\n  Clients"
    ],
    "b_abstract":[
      "Federated Learning (FL) facilitates collaborative training of a shared global\nmodel without exposing clients' private data. In practical FL systems, clients\n(e.g., edge servers, smartphones, and wearables) typically have disparate\nsystem resources. Conventional FL, however, adopts a one-size-fits-all\nsolution, where a homogeneous large global model is transmitted to and trained\non each client, resulting in an overwhelming workload for less capable clients\nand starvation for other clients. To address this issue, we propose FedConv, a\nclient-friendly FL framework, which minimizes the computation and memory burden\non resource-constrained clients by providing heterogeneous customized\nsub-models. FedConv features a novel learning-on-model paradigm that learns the\nparameters of the heterogeneous sub-models via convolutional compression.\nUnlike traditional compression methods, the compressed models in FedConv can be\ndirectly trained on clients without decompression. To aggregate the\nheterogeneous sub-models, we propose transposed convolutional dilation to\nconvert them back to large models with a unified size while retaining\npersonalized information from clients. The compression and dilation processes,\ntransparent to clients, are optimized on the server leveraging a small public\ndataset. Extensive experiments on six datasets demonstrate that FedConv\noutperforms state-of-the-art FL systems in terms of model accuracy (by more\nthan 35% on average), computation and communication overhead (with 33% and 25%\nreduction, respectively)."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07753",
    "c_title":[
      "Dark matter spiral arms in Milky Way-like halos"
    ],
    "c_abstract":[
      "The coupling between the dark matter (DM) halo and the stellar disc is a key\nfactor in galactic evolution. While the interaction between structures like the\nGalactic bar and DM halos has been explored (e.g. slowing down of the bar due\nto dynamical friction), the effect of spiral arms on the DM halo distribution\nhas received limited attention. We analyze a suite of simulations featuring\nstrong stellar spiral arms, ranging in complexity from test-particle models to\nfully cosmological hydrodynamical simulations. Using Fourier transforms, we\ncharacterize the phase and amplitude of the stellar spirals at different times\nand radii. We then apply the same methodology to DM particles near the stellar\ndisc and compare trends in Fourier coefficients and phases between the two\ncomponents. We detect a clear spiral arm signal in the DM distribution,\ncorrelated with the stellar spirals, confirming the reaction of the halo. The\nstrength of the DM spirals consistently measures around 10\\% of that of the\nstellar spiral arms. In the $N$-body simulation, the DM spiral persistently\ntrails the stellar spiral arm by approximately $10^\\circ$. A strong spiral\nsignal of a few km\\,s$^{-1}$ appears in the radial, azimuthal, and vertical\nvelocities of halo particles, distinct from the stellar kinematic signature. In\na test-particle simulation with an analytical spiral potential (omitting\nself-gravity), we reproduce a similar density and kinematic response, showing\nthat the test-particle halo responds in the same way as the $N$-body halo.\nFinally, we also find the rest of the simulations, indicating that the\ndynamical signatures of the forced response in the DM halo are independent of\nthe dynamical origin of the stellar spiral arms. We reveal the ubiquitous\npresence of DM spiral arms in Milky Way-like galaxies, driven by a forced\nresponse to the stellar spiral potential. (ABR)"
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-482",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11330",
    "b_title":[
      "System Message Generation for User Preferences using Open-Source Models"
    ],
    "b_abstract":[
      "System messages play a crucial role in interactions with large language\nmodels (LLMs), often serving as prompts to initiate conversations. Through\nsystem messages, users can assign specific roles, perform intended tasks,\nincorporate background information, specify various output formats and\ncommunication styles. Despite such versatility, publicly available data are\noften lack system messages and subject to strict license constraints in the\nindustry field. Manual labeling of publicly available data with system messages\nthat align with user instructions demands significant resources. In view of\nsuch challenges, our work introduces SysGen, a pipeline for generating system\nmessages with better aligned assistant responses from the supervised\nfine-tuning dataset without system messages. Training on SysGen data has\ndemonstrated substantial improvements in the alignment of model responses with\nsystem messages and user instructions, as demonstrated across various\nopen-source models on the Multifacet benchmark, while maintaining minimal\nimpact on other unseen benchmarks such as Open LLM Leaderboard 2. Our\nqualitative analysis highlights the importance of diverse system messages to\nensure better adaptability across different contexts."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04915",
    "c_title":[
      "Design of a test rig for the investigation of falling film flows with\n  counter-current gas flows"
    ],
    "c_abstract":[
      "Geothermal phase change probes operate on the principle of falling film\nevaporation, enabling the efficient use of geothermal heat for space heating\napplications. Despite successful applications in research, their commercial use\nis limited. One of the primary reasons for this is the absence of validated\nmodels capable of accurately representing the falling film flow coupled with\ncounter-current gas flow within these probes. For this reason, a test rig has\nbeen developed to facilitate the validation of future models. This test rig\nallows for the replication of flow phenomena appearing within geothermal probes\nunder controlled conditions. The test rig was successfully tested within the\nfirst measurement campaign presented in this paper. Within the framework of\nthis measurement campaign water was used as liquid due to its similar Kapitza\nnumber compared to \\(CO_{2}\\), typically used within geothermal probes, and\nhumid air as gas. For the gas phase, velocity profiles were measured and for\nthe liquid phase high temporal resolution film thickness measurements were\nconducted. Both measurement systems show qualitative comparable results to\nliterature. Additionally, the sampled film thickness data were averaged to\nenable a time-independent interpretation. The investigation of the average film\nthickness in flow direction, without gas flow, revealed an increase in film\nthickness along flow direction for \\(Re_{film}=500\\). In contrast, for\n\\(Re_{film}\\geq 980\\), an opposing trend was observed. Furthermore, the\ninfluence of gas flow on the average film thickness was investigated. The\nmeasurement results and high-speed camera images indicate that the test rig is\ncapable of reaching flooding conditions."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-483",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18396",
    "b_title":[
      "Quantum Geometry and Many-Body Landau-Zener Tunneling in Time-dependent\n  Quantum Systems with Instantaneous Quantum Integrability"
    ],
    "b_abstract":[
      "We study quantum geometric effects in time-dependent quantum many-body\nsystems quenched from integrable systems through a unitary transformation whose\nphase operator is linear in time. We establish a theorem stating that the Berry\nconnection matrix thus all associated geometric quantities of the\ntime-dependent many-body system, can be precisely characterized by excitations\nup to two-particle processes derived from the quantum integrable system. This\ngeometric characterization provides a powerful lens for analyzing dynamical\ntransitions in driven many-body settings. To illustrate the many-body geometric\ninfluence, we analyze a prototypical time-dependent Ising chain subjected to\nboth a small longitudinal field and a slowly rotating transverse field, whose\nlow-energy physics in the scaling limit is instantaneously governed by the\nquantum $E_8$ integrable field theory. Focusing on the quantum geometric\npotential (QGP), we show the QGP continuously suppresses the instantaneous\nenergy gaps with decreasing longitudinal field, thereby enhancing many-body\nLandau-Zener tunneling as evidenced by the Loschmidt echo and its associated\nspectral entropy. The critical threshold for the longitudinal field strength is\ndetermined, where the spectral entropy linearly increases with system size and\nexhbits hyperscaling behavior when approaching to the threshold. When the\nlongitudinal field passes the threshold and decreases toward zero, the QGP\ncontinuously leads to vanishing instantaneous energy gaps involving more\nlow-energy excitations, resulting in increasing spectral entropy indicative of\nmany-body Landau-Zener tunneling. Our results unveil telltale quantum geometric\nsignatures in time-dependent many-body systems, elucidating the intricate\ninterplay between quantum geometry and dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11102",
    "c_title":[
      "Deep Learning-based OTFS Channel Estimation and Symbol Detection with\n  Plug and Play Framework"
    ],
    "c_abstract":[
      "Orthogonal Time Frequency Space (OTFS) modulation has recently attracted\nsignificant interest due to its potential for enabling reliable communication\nin high-mobility environments. One of the challenges for OTFS receivers is the\nfractional Doppler that occurs in practical systems, resulting in decreased\nchannel sparsity, and then inaccurate channel estimation and high-complexity\nequalization. In this paper, we propose a novel unsupervised deep learning\n(DL)-based OTFS channel estimation and symbol detection scheme, capable of\nhandling different channel conditions, even in the presence of fractional\nDoppler. In particular, we design a unified plug-and-play (PnP) framework,\nwhich can jointly exploit the flexibility of optimization-based methods and\nutilize the powerful data-driven capability of DL. A lightweight Unet is\nintegrated into the framework as a powerful implicit channel prior for channel\nestimation, leading to better exploitation of the channel sparsity and the\ncharacteristic of the noise simultaneously. Furthermore, to mitigate the\nchannel estimation errors, we realize the PnP framework with a fully connected\n(FC) network for symbol detection at different noise levels, thereby enhancing\nrobustness. Finally, numerical results demonstrate the effectiveness and\nrobustness of the algorithm."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-484",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04483",
    "b_title":[
      "Demystification and Near-perfect Estimation of Minimum Gas Limit and Gas\n  Used for Ethereum Smart Contracts"
    ],
    "b_abstract":[
      "The Ethereum blockchain has a \\emph{gas system} that associates operations\nwith a cost in gas units. Two central concepts of this system are the \\emph{gas\nlimit} assigned by the issuer of a transaction and the \\emph{gas used} by a\ntransaction. The former is a budget that must not be exhausted before the\ncompletion of the transaction execution; otherwise, the execution fails.\nTherefore, it seems rather essential to determine the \\emph{minimum gas limit}\nthat ensures the execution of a transaction will not abort due to the lack of\ngas. Despite its practical relevance, this concept has not been properly\naddressed. In the literature, gas used and minimum gas limit are conflated.\nThis paper proposes a precise notion of minimum gas limit and how it can differ\nfrom gas used by a transaction; this is also demonstrated with a quantitative\nstudy on real transactions of the Ethereum blockchain. Another significant\ncontribution is the proposition of a fairly precise estimator for each of the\ntwo metrics. Again, the confusion between these concepts has led to the\ncreation of estimators only for the gas used by a transaction. We demonstrate\nthat the minimum gas limit for the state of the Ethereum blockchain (after the\nblock) $t$ can serve as a near-perfect estimation for the execution of the\ntransaction at block $t + \\Delta$, where $\\Delta \\leq 11$; the same holds for\nestimating gas used. These precise estimators can be very valuable in helping\nthe users predict the gas budget of transactions and developers in optimising\ntheir smart contracts; over and underestimating gas used and minimum gas limit\ncan lead to a number of practical issues. Overall, this paper serves as an\nimportant reference for blockchain developers and users as to how the gas\nsystem really works."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.DC",
        "cs.ET",
        "cs.NI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09848",
    "c_title":[
      "Pump-intensity-scaling of Two-Photon-Absorption and Photon Statistics of\n  Entangled-Photon Fields"
    ],
    "c_abstract":[
      "We use a non-perturbative theoretical approach to the parametric\ndown-conversion (PDC) process, which generates entangled-photon field for an\narbitrarily strong pump-pulse. This approach can be used to evaluate\nmulti-point field correlation functions to compute nonlinear spectroscopic\nsignals induced by a strong pump. The entangled-photon statistics is studied\nusing Glauber's $g^{(2)}$ function, which helps understand the significance of\nthe photon entanglement-time and the pump-pulse intensity on spectroscopic\nsignals. Under the non-perturbative treatment of the entangled field, the\ntwo-photon absorption (TPA) signal shows linear to strongly non-linear growth\nwith the pump intensity, rather than linear to quadratic scaling reported\npreviously. An increase in the range of pump intensity for the linear scaling\nis observed as the pump band-width is increased. We propose an experimental\nscheme that can select contributions to the TPA signal that arise solely from\ninteractions with the entangled photons, and filter out unentangled photon\ncontributions, which are dominant at higher pump intensities, paving a way to\nexplore the entanglement effects at higher intensities."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-485",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12129",
    "b_title":[
      "When Wyner and Ziv Met Bayes in Quantum-Classical Realm"
    ],
    "b_abstract":[
      "In this work, we address the lossy quantum-classical source coding with the\nquantum side-information (QC-QSI) problem. The task is to compress the\nclassical information about a quantum source, obtained after performing a\nmeasurement while incurring a bounded reconstruction error. Here, the decoder\nis allowed to use the side information to recover the classical data obtained\nfrom measurements on the source states. We introduce a new formulation based on\na backward (posterior) channel, replacing the single-letter distortion\nobservable with a single-letter posterior channel to capture reconstruction\nerror. Unlike the rate-distortion framework, this formulation imposes a block\nerror constraint. An analogous formulation is developed for lossy classical\nsource coding with classical side information (C-CSI) problem. We derive an\ninner bound on the asymptotic performance limit in terms of single-letter\nquantum and classical mutual information quantities of the given posterior\nchannel for QC-QSI and C-CSI cases, respectively. Furthermore, we establish a\nconnection between rate-distortion and rate-channel theory, showing that a\nrate-channel compression protocol attains the optimal rate-distortion function\nfor a specific distortion measure and level."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.05607",
    "c_title":[
      "AceWGS: An LLM-Aided Framework to Accelerate Catalyst Design for\n  Water-Gas Shift Reactions"
    ],
    "c_abstract":[
      "While the Water-Gas Shift (WGS) reaction plays a crucial role in hydrogen\nproduction for fuel cells, finding suitable catalysts to achieve high yields\nfor low-temperature WGS reactions remains a persistent challenge. Artificial\nIntelligence (AI) has shown promise in accelerating catalyst design by\nexploring vast candidate spaces, however, two key gaps limit its effectiveness.\nFirst, AI models primarily train on numerical data, which fail to capture\nessential text-based information, such as catalyst synthesis methods. Second,\nthe cross-disciplinary nature of catalyst design requires seamless\ncollaboration between AI, theory, experiments, and numerical simulations, often\nleading to communication barriers. To address these gaps, we present AceWGS, a\nLarge Language Models (LLMs)-aided framework to streamline WGS catalyst design.\nAceWGS interacts with researchers through natural language, answering queries\nbased on four features: (i) answering general queries, (ii) extracting\ninformation about the database comprising WGS-related journal articles, (iii)\ncomprehending the context described in these articles, and (iv) identifying\ncatalyst candidates using our proposed AI inverse model. We presented a\npractical case study demonstrating how AceWGS can accelerate the catalyst\ndesign process. AceWGS, built with open-source tools, offers an adjustable\nframework that researchers can readily adapt for a range of AI-accelerated\ncatalyst design applications, supporting seamless integration across\ncross-disciplinary studies."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-486",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07724",
    "b_title":[
      "A Doubly-Dispersive MIMO Channel Model Parametrized with Stacked\n  Intelligent Metasurfaces"
    ],
    "b_abstract":[
      "Introduced with the advent of statistical wireless channel models for high\nmobility communications and having a profound role in communication-centric\n(CC) integrated sensing and communications (ISAC), the doubly-dispersive (DD)\nchannel structure has long been heralded as a useful tool enabling the capture\nof the most important fading effects undergone by an arbitrary time-domain\ntransmit signal propagating through some medium. However, the incorporation of\nthis model into multiple-input multiple-output (MIMO) system setups, relying on\nthe recent paradigm-shifting transceiver architecture based on stacked\nintelligent metasurfaces (SIM), in an environment with reconfigurable\nintelligent surfaces (RISs) remains an open problem due to the many intricate\ndetails that have to be accounted for. In this paper, we fill this gap by\nintroducing a novel DD MIMO channel model that incorporates an arbitrary number\nof RISs in the ambient, as well as SIMs equipping both the transmitter and\nreceiver. We then discuss how the proposed metasurfaces-parametrized DD (MPDD)\nchannel model can be seamlessly applied to waveforms that are known to perform\nwell in DD environments, namely, orthogonal frequency division multiplexing\n(OFDM), orthogonal time frequency space (OTFS), and affine frequency division\nmultiplexing (AFDM), with each having their own inherent advantages and\ndisadvantages. An illustrative application of the programmable functionality of\nthe proposed model is finally presented to showcase its potential for boosting\nthe performance of the aforementioned waveforms. Our numerical results indicate\nthat the design of waveforms suitable to mitigating the effects of DD channels\nis significantly impacted by the emerging SIM technology."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05077",
    "c_title":[
      "On coefficients of operator product expansions for quantum field\n  theories with ordinary, holomorphic, and topological spacetime dimensions"
    ],
    "c_abstract":[
      "In many quantum field theories (such as higher-dimensional holomorphic field\ntheories or raviolo theories), operator product expansions of local operators\ncan have as coefficients not only ordinary functions but also 'derived'\nfunctions with nonzero ghost number, which are certain elements of sheaf\ncohomology. We analyse the 'derived' functions that should appear in operator\nproduct expansions for a quantum field theory with an arbitrary number of\ntopological, holomorphic and\/or ordinary spacetime dimensions and identify\nnecessary and sufficient conditions for such 'derived' functions to appear. In\nparticular, theories with one topological spacetime dimension and multiple\nordinary spacetime dimensions provide a smooth analogue of the (holomorphic)\nraviolo."
    ],
    "c_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-487",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06144",
    "b_title":[
      "Exploring the usage of Probabilistic Neural Networks for Ionospheric\n  electron density estimation"
    ],
    "b_abstract":[
      "A fundamental limitation of traditional Neural Networks (NN) in predictive\nmodelling is their inability to quantify uncertainty in their outputs. In\ncritical applications like positioning systems, understanding the reliability\nof predictions is critical for constructing confidence intervals, early warning\nsystems, and effectively propagating results. For instance, Precise Point\nPositioning in satellite navigation heavily relies on accurate error models for\nancillary data (orbits, clocks, ionosphere, and troposphere) to compute precise\nerror estimates. In addition, these uncertainty estimates are needed to\nestablish robust protection levels in safety critical applications.\n  To address this challenge, the main objectives of this paper aims at\nexploring a potential framework capable of providing both point estimates and\nassociated uncertainty measures of ionospheric Vertical Total Electron Content\n(VTEC). In this context, Probabilistic Neural Networks (PNNs) offer a promising\napproach to achieve this goal. However, constructing an effective PNN requires\nmeticulous design of hidden and output layers, as well as careful definition of\nprior and posterior probability distributions for network weights and biases.\n  A key finding of this study is that the uncertainty provided by the PNN model\nin VTEC estimates may be systematically underestimated. In low-latitude areas,\nthe actual error was observed to be as much as twice the model's estimate. This\nunderestimation is expected to be more pronounced during solar maximum,\ncorrelating with increased VTEC values."
    ],
    "b_categories":[
      [
        "cs.AI",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02611",
    "c_title":[
      "Classical 1\/3 Nusselt number scaling in highly turbulent compressible\n  convection"
    ],
    "c_abstract":[
      "Planetary and stellar convection, which are compressible and turbulent,\nremain poorly understood. In this paper, we report numerical results on the\nscaling of Nusselt number ($\\mathrm{Nu}$) and Reynolds number ($\\mathrm{Re}$)\nfor extreme convection. Using computationally-efficient MacCormack-TVD finite\ndifference method, we simulate compressible turbulent convection in a\ntwo-dimensional Cartesian box up to $\\mathrm{Ra} = 10^{16}$, the highest\n$\\mathrm{Ra}$ achieved so far, and in a three-dimensional box up to\n$\\mathrm{Ra} = 10^{11}$. We show adiabatic temperature drop in the bulk flow,\nleading to the Reynolds number scaling $\\mathrm{Ra}^{1\/2}$. More significantly,\nwe show classical $1\/3$ Nusselt number scaling: $\\mathrm{Nu} \\propto\n\\mathrm{Ra}^{0.32}$ in 2D, and $\\mathrm{Nu} \\propto \\mathrm{Ra}^{0.31}$ in 3D\nup to the highest $\\mathrm{Ra}$."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-488",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15125",
    "b_title":[
      "Weighted BMO-BLO estimates for Littlewood--Paley square operators"
    ],
    "b_abstract":[
      "Let $T(f)$ denote the Littlewood--Paley square operators, including the\nLittlewood--Paley $\\mathcal{G}$-function $\\mathcal{G}(f)$, Lusin's area\nintegral $\\mathcal{S}(f)$ and Stein's function\n$\\mathcal{G}^{\\ast}_{\\lambda}(f)$ with $\\lambda>2$. We establish the\nboundedness of Littlewood--Paley square operators on the weighted spaces\n$\\mathrm{BMO}(\\omega)$ with $\\omega\\in A_1$. The weighted space\n$\\mathrm{BLO}(\\omega)$ (the space of functions with bounded lower oscillation)\nis introduced and studied in this paper. This new space is a proper subspace of\n$\\mathrm{BMO}(\\omega)$. It is proved that if $T(f)(x_0)$ is finite for a single\npoint $x_0\\in\\mathbb R^n$, then $T(f)(x)$ is finite almost everywhere in\n$\\mathbb R^n$. Moreover, it is shown that $T(f)$ is bounded from\n$\\mathrm{BMO}(\\omega)$ into $\\mathrm{BLO}(\\omega)$, provided that $\\omega\\in\nA_1$. The corresponding John--Nirenberg inequality suitable for the space\n$\\mathrm{BLO}(\\omega)$ with $\\omega\\in A_1$ is discussed. Based on this, the\nequivalent characterization of the space $\\mathrm{BLO}(\\omega)$ is also given."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06837",
    "c_title":[
      "An efficient approach to represent enterprise web application structure\n  using Large Language Model in the service of Intelligent Quality Engineering"
    ],
    "c_abstract":[
      "This paper presents a novel approach to represent enterprise web application\nstructures using Large Language Models (LLMs) to enable intelligent quality\nengineering at scale. We introduce a hierarchical representation methodology\nthat optimizes the few-shot learning capabilities of LLMs while preserving the\ncomplex relationships and interactions within web applications. The approach\nencompasses five key phases: comprehensive DOM analysis, multi-page synthesis,\ntest suite generation, execution, and result analysis. Our methodology\naddresses existing challenges around usage of Generative AI techniques in\nautomated software testing by developing a structured format that enables LLMs\nto understand web application architecture through in-context learning. We\nevaluated our approach using two distinct web applications: an e-commerce\nplatform (Swag Labs) and a healthcare application (MediBox) which is deployed\nwithin Atalgo engineering environment. The results demonstrate success rates of\n90\\% and 70\\%, respectively, in achieving automated testing, with high\nrelevance scores for test cases across multiple evaluation criteria. The\nfindings suggest that our representation approach significantly enhances LLMs'\nability to generate contextually relevant test cases and provide better quality\nassurance overall, while reducing the time and effort required for testing."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-489",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14237",
    "b_title":[
      "Make Your Training Flexible: Towards Deployment-Efficient Video Models"
    ],
    "b_abstract":[
      "Popular video training methods mainly operate on a fixed number of tokens\nsampled from a predetermined spatiotemporal grid, resulting in sub-optimal\naccuracy-computation trade-offs due to inherent video redundancy. They also\nlack adaptability to varying computational budgets for downstream tasks,\nhindering applications of the most competitive model in real-world scenes. We\nthus propose a new test setting, Token Optimization, for maximized input\ninformation across budgets, which optimizes the size-limited set of input\ntokens through token selection from more suitably sampled videos. To this end,\nwe propose a novel augmentation tool termed Flux. By making the sampling grid\nflexible and leveraging token selection, it is easily adopted in most popular\nvideo training frameworks, boosting model robustness with nearly no additional\ncost. We integrate Flux in large-scale video pre-training, and the resulting\nFluxViT establishes new state-of-the-art results across extensive tasks at\nstandard costs. Notably, with 1\/4 tokens only, it can still match the\nperformance of previous state-of-the-art models with Token Optimization,\nyielding nearly 90\\% savings. All models and data are available at\nhttps:\/\/github.com\/OpenGVLab\/FluxViT."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11819",
    "c_title":[
      "Arrangements of circles supported by small chords and compatible with\n  natural real algebraic functions"
    ],
    "c_abstract":[
      "We have previously proposed a study of arrangements of small circles which\nalso surround regions in the plane realized as the images of natural real\nalgebraic maps yielding Morse-Bott functions by projections. Among studies of\narrangements, families of smooth regular submanifolds in smooth manifolds, this\nstudy is fundamental, explicit, and new, surprisingly.\n  We have obtained a complete list of local changes of the graphs the regions\nnaturally collapse to in adding a (generic) small circle to an existing\narrangement of the proposed class. Here, we propose a similar and essentially\ndifferent class of arrangements of circles. The present study also yields real\nalgebraic maps and nice real algebraic functions similarly and we present a\nsimilar study.\n  We are interested in topological properties and combinatorics among such\narrangements and regions and applications to constructing such real algebraic\nmaps and manifolds explicitly and understanding their global structures."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.CO",
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-490",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12647",
    "b_title":[
      "Optimal Transmission Sequence Design with ISI Matching in Molecular\n  Communication"
    ],
    "b_abstract":[
      "Molecular communication (MC) offers a groundbreaking approach to\ncommunication inspired by biological signaling. It is particularly suited for\nenvironments where traditional electromagnetic methods fail, such as fluid\nmediums or within the human body. This study focuses on addressing a major\nchallenge in MC systems: inter symbol interference (ISI), which arises due to\nthe random, diffusive propagation of molecules. We propose a novel technique\nthat leverages transmission shaping to mitigate ISI effectively by designing\noptimal transmission pulse (or sequence) for symbols. Our approach centers on\nsolving a multi-objective optimization problem that aims to maximize the\nseparability of individual symbol's responses within the symbol duration while\nmatching the interference caused by molecular spillover for all symbols. By\nmaking ISI of each symbol similar, the approach reduces the effect of previous\nsymbols and thus not require any adaptive computations. We introduce a\ngeometric analogy involving two families of ellipses to derive the optimal\nsolution. Analytical insights are supported by numerical simulations to design\noptimized transmission profiles to enhance the resilience toward ISI. The\nproposed transmission shaping method is evaluated through symbol error rate\n(SER). These results mark a significant step forward in developing robust and\nefficient MC systems, opening doors to advanced applications in bio-inspired\nand nano-scale communication technologies."
    ],
    "b_categories":[
      [
        "eess.SP",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12418",
    "c_title":[
      "A Causality-Inspired Model for Intima-Media Thickening Assessment in\n  Ultrasound Videos"
    ],
    "c_abstract":[
      "Carotid atherosclerosis represents a significant health risk, with its early\ndiagnosis primarily dependent on ultrasound-based assessments of carotid\nintima-media thickening. However, during carotid ultrasound screening,\nsignificant view variations cause style shifts, impairing content cues related\nto thickening, such as lumen anatomy, which introduces spurious correlations\nthat hinder assessment. Therefore, we propose a novel causal-inspired method\nfor assessing carotid intima-media thickening in frame-wise ultrasound videos,\nwhich focuses on two aspects: eliminating spurious correlations caused by style\nand enhancing causal content correlations. Specifically, we introduce a novel\nSpurious Correlation Elimination (SCE) module to remove non-causal style\neffects by enforcing prediction invariance with style perturbations.\nSimultaneously, we propose a Causal Equivalence Consolidation (CEC) module to\nstrengthen causal content correlation through adversarial optimization during\ncontent randomization. Simultaneously, we design a Causal Transition\nAugmentation (CTA) module to ensure smooth causal flow by integrating an\nauxiliary pathway with text prompts and connecting it through contrastive\nlearning. The experimental results on our in-house carotid ultrasound video\ndataset achieved an accuracy of 86.93\\%, demonstrating the superior performance\nof the proposed method. Code is available at\n\\href{https:\/\/github.com\/xielaobanyy\/causal-imt}{https:\/\/github.com\/xielaobanyy\/causal-imt}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-491",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09476",
    "b_title":[
      "A Multi-objective Sequential Quadratic Programming Algorithm Based on\n  Low-order Smooth Penalty Function"
    ],
    "b_abstract":[
      "In this paper,we propose a Multi-Objective Sequential Quadratic Programming\n(MOSQP) algorithm for constrained multi-objective optimization problems,basd on\na low-order smooth penalty function as the merit function for line search. The\nalgorithm constructs single-objective optimization subproblems based on each\nobjective function, solves quadratic programming (QP) subproblems to obtain\ndescent directions for expanding the iterative point set within the feasible\nregion, and filters non-dominated points after expansion. A new QP problem is\nthen formulated using information from all objective functions to derive\ndescent directions. The Armijo step size rule is employed for line search,\ncombined with Powell's correction formula (1978) for B iteration updates. If QP\nsubproblems is infesible, the negative gradient of the merit function is\nadopted as the search direction. The algorithm is proven to converge to an\napproximate Pareto front for constrained multi-objective optimization. Finally,\nnumerical experiments are performed for specific multi-objective optimization\nproblems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01872",
    "c_title":[
      "FairGen: Controlling Sensitive Attributes for Fair Generations in\n  Diffusion Models via Adaptive Latent Guidance"
    ],
    "c_abstract":[
      "Text-to-image diffusion models often exhibit biases toward specific\ndemographic groups, such as generating more males than females when prompted to\ngenerate images of engineers, raising ethical concerns and limiting their\nadoption. In this paper, we tackle the challenge of mitigating generation bias\ntowards any target attribute value (e.g., \"male\" for \"gender\") in diffusion\nmodels while preserving generation quality. We propose FairGen, an adaptive\nlatent guidance mechanism which controls the generation distribution during\ninference. In FairGen, a latent guidance module dynamically adjusts the\ndiffusion process to enforce specific attributes, while a memory module tracks\nthe generation statistics and steers latent guidance to align with the targeted\nfair distribution of the attribute values. Further, given the limitations of\nexisting datasets in comprehensively assessing bias in diffusion models, we\nintroduce a holistic bias evaluation benchmark HBE, covering diverse domains\nand incorporating complex prompts across various applications. Extensive\nevaluations on HBE and Stable Bias datasets demonstrate that FairGen\noutperforms existing bias mitigation approaches, achieving substantial bias\nreduction (e.g., 68.5% gender bias reduction on Stable Diffusion 2). Ablation\nstudies highlight FairGen's ability to flexibly and precisely control\ngeneration distribution at any user-specified granularity, ensuring adaptive\nand targeted bias mitigation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-492",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07355",
    "b_title":[
      "Tools for Supergravity in the spin coframe formalism"
    ],
    "b_abstract":[
      "This paper contains a review of the theoretical foundations of Clifford\nalgebras, spinors and spinor bundles in the so-called co-frame formalism. A\ncompact index-free notation is introduced, along with a series of identities\nuseful for computations in supergravity theories."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.09436",
    "c_title":[
      "Variable Stiffness for Robust Locomotion through Reinforcement Learning"
    ],
    "c_abstract":[
      "Reinforcement-learned locomotion enables legged robots to perform highly\ndynamic motions but often accompanies time-consuming manual tuning of joint\nstiffness. This paper introduces a novel control paradigm that integrates\nvariable stiffness into the action space alongside joint positions, enabling\ngrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness\n(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness\npolicies, with grouping in per-leg stiffness (PLS), outperform position-based\ncontrol in velocity tracking and push recovery. In contrast, HJLS excels in\nenergy efficiency. Furthermore, our method showcases robust walking behaviour\non diverse outdoor terrains by sim-to-real transfer, although the policy is\nsorely trained on a flat floor. Our approach simplifies design by eliminating\nper-joint stiffness tuning while keeping competitive results with various\nmetrics."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-493",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18780",
    "b_title":[
      "Gotta Hash 'Em All! Speeding Up Hash Functions for Zero-Knowledge Proof\n  Applications"
    ],
    "b_abstract":[
      "Collision-resistant cryptographic hash functions (CRHs) are crucial for\nsecurity in modern systems but are optimized for standard CPUs. While heavily\nused in zero-knowledge proof (ZKP) applications, traditional CRHs are\ninefficient in the ZK domain. ZK-friendly hashes have been developed but\nstruggle on consumer hardware due to a lack of specialized ZK-specific\nhardware. To address this, we present HashEmAll, a novel collection of\nFPGA-based realizations of three ZK-friendly hash functions: Griffin,\nRescue-Prime, and Reinforced Concrete. Each hash offers different optimization\nfocuses, allowing users to choose based on the constraints of their\napplications. Through our ZK-optimized arithmetic functions on reconfigurable\nhardware, HashEmAll outperforms CPU implementations by up to $23\\times$ with\nlower power consumption and compatibility with accessible FPGAs."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16032",
    "c_title":[
      "Equivariant constructions of spheres with Zoll families of minimal\n  spheres"
    ],
    "c_abstract":[
      "We construct one-parameter deformations of the Euclidean sphere\n$\\mathbb{S}^n$ inside $\\mathbb{R}^{n+1}$ that admit a Zoll family of\ncodimension one embedded minimal spheres, in all dimensions $n\\geq 3$. The\nmethod of construction is equivariant with respect to the natural actions of\nthe orthogonal group. In particular, we show that the original Zoll spheres of\nrevolution in $\\mathbb{R}^3$ have counterparts in the context of minimal\nsurface theory, in all dimensions.\n  We also describe the first examples of metrics on the real projective spaces\n$\\mathbb{RP}^n$, in all dimensions $n \\geq 3$, that admit a Zoll family of\nembedded minimal projective hyperplanes, and which are not isometric to metrics\nwith minimal linear projective hyperplanes.\n  The new constructions are underpinned by equivariant versions of\nNash-Moser-Hamilton implicit function theorem, and yield new information even\nin dimension $n=2$. As an application, we also show that every finite group of\nthe orthogonal group $O(3)$ that does not contain $-Id$ is the isometry group\nof some (classical) Zoll metric on $\\mathbb{S}^2$."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-494",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06778",
    "b_title":[
      "Optical appearance of the Konoplya-Zhidenko rotating non-Kerr black hole\n  surrounded by a thin accretion disk"
    ],
    "b_abstract":[
      "In this study, we analyze the observational images of a Konoplya-Zhidenko\nrotating non-Kerr black hole, wherein a thin accretion disk, serving as the\nsole background light source, is situated on the equatorial plane of the black\nhole. The inner boundary of the thin accretion disk extends to the event\nhorizon, and the accretion material in the disk exhibits two different motion\nbehaviors, that is, it moves along the critical plunging orbit inside the\ninnermost stable circular orbit (ISCO) and follows the Keplerian orbit outside\nthe ISCO. The shadow image is captured on the imaging plane of a zero angular\nmomentum observer utilizing advanced fisheye camera ray-tracing techniques. The\nresults demonstrate that an image consistently reveals a dark region encircled\nby a narrow photon ring, which is called the inner shadow. At low observation\ninclination angles, the observation intensity is highly concentrated, with the\nlensed image of accretion disk being superimposed on the direct image. As\nobservation inclination angle increases, the direct and lensed images gradually\nseparate, becoming distinctly distinguishable and forming a hat-like structure.\nFurthermore, variations in the parameter space and observation angle will\ninfluence pertinent image characteristics, including image symmetry, the range\nor deformation degree of the inner shadow. We further examined the distinctive\ncharacteristics of images observed in both prograde and retrograde accretion\ndisk scenarios. Subsequently, we also examined the redshift distribution on the\ndisk. The findings indicate that while variations in relevant parameters do\ninfluence the redshift distribution, the primary factor is the change in\nobservational inclination. The observer can detect both redshift and blueshift\nphenomena on the screen when viewed at a higher observation angle."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.08726",
    "c_title":[
      "Unilateral vibration transmission in mechanical systems with bilinear\n  coupling"
    ],
    "c_abstract":[
      "Unilateral transmission refers to the scenario in which the waves transmitted\nthrough a system remain in pure tension or pure compression. This transmission\nphenomenon may occur in systems that exhibit different effective elasticity in\ncompression and tension; i.e. bilinear elasticity. We present a computational\ninvestigation of unilateral transmission in the steady-state response of\nharmonically driven mechanical systems with bilinear coupling. Starting with\ntwo bilinearly coupled oscillators, we find that breaking the mirror symmetry\nof the system, in either elastic or inertial properties, facilitates unilateral\ntransmission by allowing it to occur near a primary resonance. This asymmetry\nalso enables nonreciprocal transmission to occur. We then investigate the\nnonreciprocal dynamics of the system, including linear stability analysis, with\na focus on unilateral transmission. We also extend our discussion to a bilinear\nperiodic structure, for which we investigate the influence of the number of\nunits and energy dissipation on unilateral transmission. We report on the\nexistence of stable nonreciprocal unilateral transmission near primary and\ninternal resonances of the system, as well as other nonreciprocal features such\nas period-doubled and quasiperiodic response characteristics."
    ],
    "c_categories":[
      [
        "math.DS",
        "nlin.PS",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-495",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06396",
    "b_title":[
      "Optimizing Minimum Vertex Cover Solving via a GCN-assisted Heuristic\n  Algorithm"
    ],
    "b_abstract":[
      "The problem of finding a minimum vertex cover (MVC) in a graph is a\nwell-known NP-hard problem with significant practical applications in\noptimization and scheduling. Its complexity, combined with the increasing scale\nof problems, underscores the need for efficient and effective algorithms.\nHowever, existing heuristic algorithms for MVC often rely on simplistic\ninitialization strategies and overlook the impact of edge attributes and\nneighborhood information on vertex selection. In this paper, we introduce\nGCNIVC, a novel heuristic search algorithm designed to address the limitations\nof existing methods for solving MVC problems in large-scale graphs. Our\napproach features two main innovations. First, it utilizes a Graph\nConvolutional Network (GCN) to capture the global structure of graphs, which\nenables the generation of high-quality initial solutions that enhance the\nefficiency of the subsequent search process. Second, GCNIVC introduces a new\nheuristic that employs three containers and the concept of double-covered edges\n(dc-edges), improving search efficiency and providing greater flexibility for\nadding and removing operations based on edge attributes. Through extensive\nexperiments on benchmark datasets, we demonstrate that GCNIVC outperforms\nstate-of-the-art MVC algorithms in terms of both accuracy and efficiency. Our\nresults highlight the effectiveness of GCNIVC's GCN-assisted initialization and\nits edge-informed search strategy. This study not only advances the\nunderstanding of MVC problem-solving but also contributes a new tool for\naddressing large-scale graph optimization challenges."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13664",
    "c_title":[
      "Dynamics of defects and interfaces for interacting quantum hard disks"
    ],
    "c_abstract":[
      "Defects and interfaces are essential to understand the properties of matter.\nHowever, studying their dynamics in the quantum regime remains a challenge in\nparticular concerning the regime of two spatial dimensions. Recently, it has\nbeen shown that a quantum counterpart of the hard-disk problem on a lattice\nyields defects and interfaces, which are stable just due to quantum effects\nwhile they delocalize and dissolve classically. Here, we study in more detail\nthe properties of defects and interfaces in this quantum hard-disk problem with\na particular emphasis on the stability of these quantum effects upon including\nperturbations. Specifically, we introduce short-range soft-core interactions\nbetween the hard disks. From both analytical arguments and numerical\nsimulations we find that large classes of defects and interfaces remain stable\neven under such perturbations suggesting that the quantum nature of the\ndynamics exhibits a large range of robustness. Our findings demonstrate the\nstability and non-classical behavior of quantum interface dynamics, offering\ninsights into the dynamics of two-dimensional quantum matter and establishing\nthe quantum hard-disk model as a platform for studying unconventional\nconstrained quantum dynamics."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-496",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12301",
    "b_title":[
      "One Goal, Many Challenges: Robust Preference Optimization Amid\n  Content-Aware and Multi-Source Noise"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have made significant strides in generating\nhuman-like responses, largely due to preference alignment techniques. However,\nthese methods often assume unbiased human feedback, which is rarely the case in\nreal-world scenarios. This paper introduces Content-Aware Noise-Resilient\nPreference Optimization (CNRPO), a novel framework that addresses multiple\nsources of content-dependent noise in preference learning. CNRPO employs a\nmulti-objective optimization approach to separate true preferences from\ncontent-aware noises, effectively mitigating their impact. We leverage backdoor\nattack mechanisms to efficiently learn and control various noise sources within\na single model. Theoretical analysis and extensive experiments on different\nsynthetic noisy datasets demonstrate that CNRPO significantly improves\nalignment with primary human preferences while controlling for secondary noises\nand biases, such as response length and harmfulness."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07936",
    "c_title":[
      "On a Class of Self-Similar Polycyclic Groups"
    ],
    "c_abstract":[
      "A group $G$ is self-similar if it admits a triple $(G,H,f)$ where $H$ is a\nsubgroup of $G$ and $f: H \\to G$ a simple homomorphism, that is, the only\nsubgroup $K$ of $H$, normal in $G$ and $f$-invariant ($K^f \\leq K$) is trivial.\nThe group $G$ then has two chains of subgroups: \\[ G_0 = G,\\ H_0 = H,\\ G_k =\n(H_{k-1})^f,\\ H_k = H \\cap G_{k}\\ \\text{for } (k \\geq 1). \\]\n  We define a family of self-similar polycyclic groups, denoted $SSP$, where\neach subgroup $G_k$ is self-similar with respect to the triple $(G_k , H_k, f)$\nfor all $k$. By definition, a group $G$ belongs to this $SSP$ family provided\n$f: H \\rightarrow G$ is a monomorphism, $H_k$ and $G_{k+1}$ are normal\nsubgroups of index $p$ in $G_k$ ($p$ a prime or infinite) and $G_k=H_kG_{k+1}$.\nWhen $G$ is a finite $p$-group in the class $SSP$, we show that the above\nconditions follow simply from $[G:H] = p$ and $f$ is a simple monomorphism.\n  We show that if the Hirsch length of $G$ is $n$, then $G$ has a polycyclic\ngenerating set $\\{a_1, \\ldots, a_n\\}$ which is self-similar under the action of\n$f: a_1 \\rightarrow a_2 \\rightarrow \\ldots \\rightarrow a_n$, and then $G$ is\neither a finite $p$-group or is torsion-free. Surprisingly, the arithmetic of\n$n$ modulo $3$ has a strong impact on the structure of $G$. This fact allows us\nto prove that $G$ is nilpotent metabelian whose center is free $p$-abelian ($p$\nprime or infinite) of rank at least $n\/3$.\n  We classify those groups $G$ where $H$ has nilpotency class at most $2$.\nFurthermore, when $p=2$, we prove that $G$ is a finite $2$-group of nilpotency\nclass at most $2$, and classify all such groups."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-497",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20342",
    "b_title":[
      "Reservoir Computing and Photoelectrochemical Sensors: A Marriage of\n  Convenience"
    ],
    "b_abstract":[
      "Sensing technology is an important aspect of information processing. Current\ndevelopment in artificial intelligence systems (especially those aimed at\nmedical and environmental applications) requires a lot of data on the chemical\ncomposition of biological fluids or environmental samples. These complex\nmatrices require advanced sensing devices, and photoelectrochemical ones seem\nto have potential to overcome at least some of the obstacles. Furthermore, the\ndevelopment of artificial intelligence (AI) technology for autonomous robotics\nrequires technology mimicking human senses, also those operating at the\nmolecular level, such as gustation and olfaction. Again, photoelectrochemical\nsensing can provide some suitable solutions. In this review, we introduce the\nidea of integration of photoelectrochemical sensors with some unconventional\ncomputing paradigm - reservoir computing. This approach should not only boost\nthe performance of the sensors itself, but also open new pathways through\nscience. Integration of sensing devices with computing systems will also\ncontribute to a better understanding (or at least mimicking) of the human\nsenses and neuromorphic sensory information processing. Although reservoir\nsystems can be considered magic \"black boxes\" and their operation is at the\nsame time simple and hard to comprehend, this combination is expected to open a\nnew era of effective information harvesting and processing systems."
    ],
    "b_categories":[
      [
        "cs.ET",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14729",
    "c_title":[
      "HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene\n  Understanding and Generation"
    ],
    "c_abstract":[
      "Driving World Models (DWMs) have become essential for autonomous driving by\nenabling future scene prediction. However, existing DWMs are limited to scene\ngeneration and fail to incorporate scene understanding, which involves\ninterpreting and reasoning about the driving environment. In this paper, we\npresent a unified Driving World Model named HERMES. We seamlessly integrate 3D\nscene understanding and future scene evolution (generation) through a unified\nframework in driving scenarios. Specifically, HERMES leverages a Bird's-Eye\nView (BEV) representation to consolidate multi-view spatial information while\npreserving geometric relationships and interactions. We also introduce world\nqueries, which incorporate world knowledge into BEV features via causal\nattention in the Large Language Model, enabling contextual enrichment for\nunderstanding and generation tasks. We conduct comprehensive studies on\nnuScenes and OmniDrive-nuScenes datasets to validate the effectiveness of our\nmethod. HERMES achieves state-of-the-art performance, reducing generation error\nby 32.4% and improving understanding metrics such as CIDEr by 8.0%. The model\nand code will be publicly released at https:\/\/github.com\/LMD0311\/HERMES."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-498",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08661",
    "b_title":[
      "Task-Oriented Co-Design of Communication, Computing, and Control for\n  Edge-Enabled Industrial Cyber-Physical Systems"
    ],
    "b_abstract":[
      "This paper proposes a task-oriented co-design framework that integrates\ncommunication, computing, and control to address the key challenges of\nbandwidth limitations, noise interference, and latency in mission-critical\nindustrial Cyber-Physical Systems (CPS). To improve communication efficiency\nand robustness, we design a task-oriented Joint Source-Channel Coding (JSCC)\nusing Information Bottleneck (IB) to enhance data transmission efficiency by\nprioritizing task-specific information. To mitigate the perceived End-to-End\n(E2E) delays, we develop a Delay-Aware Trajectory-Guided Control Prediction\n(DTCP) strategy that integrates trajectory planning with control prediction,\npredicting commands based on E2E delay. Moreover, the DTCP is co-designed with\ntask-oriented JSCC, focusing on transmitting task-specific information for\ntimely and reliable autonomous driving. Experimental results in the CARLA\nsimulator demonstrate that, under an E2E delay of 1 second (20 time slots), the\nproposed framework achieves a driving score of 48.12, which is 31.59 points\nhigher than using Better Portable Graphics (BPG) while reducing bandwidth usage\nby 99.19%."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.IT",
        "eess.IV",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17692",
    "c_title":[
      "Fidelity-Enhanced Variational Quantum Optimal Control"
    ],
    "c_abstract":[
      "Creating robust quantum operations is a major challenge in the current noisy\nintermediate-scale quantum computing era. Recently, the importance of\nnoise-resilient control methods has become more pronounced in the field.\nOrdinarily, noisy quantum systems are described by the Lindblad equation.\nHowever, minimizing noise susceptibility using this equation has proven\nchallenging because of its irreversibility. In this study, we propose a new\nmethod for creating robust pulses based on the stochastic Schr\\\"{o}dinger\nequation. This equation describes individual noise realizations under any\ncolored noise process, contrary to the Lindblad equation, which describes mean\nsystem behavior under white noise. Using stochastic optimal control techniques,\nour method, Fidelity-Enhanced Variational Quantum Optimal Control (F-VQOC), is\nable to construct higher fidelity paths than its non-stochastic counterpart\n(VQOC). By accounting for both environmental noise sources as well as noise\nsources inherent to the control system, highly significant increases in\nfidelity are noted for both single and multiqubit state preparations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-499",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04946",
    "b_title":[
      "Non-asymptotic analysis of the performance of the penalized least\n  trimmed squares in sparse models"
    ],
    "b_abstract":[
      "The least trimmed squares (LTS) estimator is a renowned robust alternative to\nthe classic least squares estimator and is popular in location, regression,\nmachine learning, and AI literature. Many studies exist on LTS, including its\nrobustness, computation algorithms, extension to non-linear cases, asymptotics,\netc. The LTS has been applied in the penalized regression in a high-dimensional\nreal-data sparse-model setting where dimension $p$ (in thousands) is much\nlarger than sample size $n$ (in tens, or hundreds). In such a practical\nsetting, the sample size $n$ often is the count of sub-population that has a\nspecial attribute (e.g. the count of patients of Alzheimer's, Parkinson's,\nLeukemia, or ALS, etc.) among a population with a finite fixed size N.\nAsymptotic analysis assuming that $n$ tends to infinity is not practically\nconvincing and legitimate in such a scenario. A non-asymptotic or finite sample\nanalysis will be more desirable and feasible.\n  This article establishes some finite sample (non-asymptotic) error bounds for\nestimating and predicting based on LTS with high probability for the first\ntime."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12213",
    "c_title":[
      "Black holes surrounded by dark matter spike: spacetime metrics and\n  gravitational wave ringdown waveforms"
    ],
    "c_abstract":[
      "The black holes at the centers of galaxies may be surrounded by dark matter\nspike, which could leave detectable imprints on the gravitational wave signals\nthey emit. In this work, combining the mass model of M87 and the black hole\nsolutions derived from the TOV equations, we focus on the gravitational wave\nringdown waveforms of the black holes under the axial gravitational\nperturbation using the continued fraction method, that is quasinormal modes,\nand compare them with the Schwarzschild black hole. Furthermore, the impact of\nthe different dark matter parameters on the quasinormal frequencies of the\nblack holes was also investigated. In particular, we found that the impact of\ndark matter spike on the quasinormal modes of the black holes can reach up to\nthe order of $10^{-4}$. These results may provide some help in further\nexploring the impact of dark matter spike on the black holes and their related\ngravitational wave phenomena."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-500",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16947",
    "b_title":[
      "Exceptional field theories"
    ],
    "b_abstract":[
      "We review exceptional field theories as the duality-covariant reformulation\nof maximal supergravity theories in ten and eleven dimensions, that make the\nunderlying exceptional symmetries explicit. Beyond their structural role in\nunifying the various maximal supergravities, we illustrate how they also\nprovide access to very efficient techniques for tackling concrete computational\nproblems in supergravity."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17855",
    "c_title":[
      "A novel gradient-based method for decision trees optimizing arbitrary\n  differential loss functions"
    ],
    "c_abstract":[
      "There are many approaches for training decision trees. This work introduces a\nnovel gradient-based method for constructing decision trees that optimize\narbitrary differentiable loss functions, overcoming the limitations of\nheuristic splitting rules. Unlike traditional approaches that rely on heuristic\nsplitting rules, the proposed method refines predictions using the first and\nsecond derivatives of the loss function, enabling the optimization of complex\ntasks such as classification, regression, and survival analysis. We demonstrate\nthe method's applicability to classification, regression, and survival analysis\ntasks, including those with censored data. Numerical experiments on both real\nand synthetic datasets compare the proposed method with traditional decision\ntree algorithms, such as CART, Extremely Randomized Trees, and SurvTree. The\nimplementation of the method is publicly available, providing a practical tool\nfor researchers and practitioners. This work advances the field of decision\ntree-based modeling, offering a more flexible and accurate approach for\nhandling structured data and complex tasks. By leveraging gradient-based\noptimization, the proposed method bridges the gap between traditional decision\ntrees and modern machine learning techniques, paving the way for further\ninnovations in interpretable and high-performing models."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-501",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15454",
    "b_title":[
      "On the Discrimination and Consistency for Exemplar-Free Class\n  Incremental Learning"
    ],
    "b_abstract":[
      "Exemplar-free class incremental learning (EF-CIL) is a nontrivial task that\nrequires continuously enriching model capability with new classes while\nmaintaining previously learned knowledge without storing and replaying any old\nclass exemplars. An emerging theory-guided framework for CIL trains\ntask-specific models for a shared network, shifting the pressure of forgetting\nto task-id prediction. In EF-CIL, task-id prediction is more challenging due to\nthe lack of inter-task interaction (e.g., replays of exemplars). To address\nthis issue, we conduct a theoretical analysis of the importance and feasibility\nof preserving a discriminative and consistent feature space, upon which we\npropose a novel method termed DCNet. Concretely, it progressively maps class\nrepresentations into a hyperspherical space, in which different classes are\northogonally distributed to achieve ample inter-class separation. Meanwhile, it\nalso introduces compensatory training to adaptively adjust supervision\nintensity, thereby aligning the degree of intra-class aggregation. Extensive\nexperiments and theoretical analysis verified the superiority of the proposed\nDCNet."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10051",
    "c_title":[
      "A Family of Controllable Momentum Coefficients for Forward-Backward\n  Accelerated Algorithms"
    ],
    "c_abstract":[
      "Nesterov's accelerated gradient method (NAG) marks a pivotal advancement in\ngradient-based optimization, achieving faster convergence compared to the\nvanilla gradient descent method for convex functions. However, its algorithmic\ncomplexity when applied to strongly convex functions remains unknown, as noted\nin the comprehensive review by Chambolle and Pock [2016]. This issue, aside\nfrom the critical step size, was addressed by Li et al. [2024b], with the\nmonotonic case further explored by Fu and Shi [2024]. In this paper, we\nintroduce a family of controllable momentum coefficients for forward-backward\naccelerated methods, focusing on the critical step size $s=1\/L$. Unlike\ntraditional linear forms, the proposed momentum coefficients follow an\n$\\alpha$-th power structure, where the parameter $r$ is adaptively tuned to\n$\\alpha$. Using a Lyapunov function specifically designed for $\\alpha$, we\nestablish a controllable $O\\left(1\/k^{2\\alpha} \\right)$ convergence rate for\nthe NAG-$\\alpha$ method, provided that $r > 2\\alpha$. At the critical step\nsize, NAG-$\\alpha$ achieves an inverse polynomial convergence rate of arbitrary\ndegree by adjusting $r$ according to $\\alpha > 0$. We further simplify the\nLyapunov function by expressing it in terms of the iterative sequences $x_k$\nand $y_k$, eliminating the need for phase-space representations. This\nsimplification enables us to extend the controllable $O \\left(1\/k^{2\\alpha}\n\\right)$ rate to the monotonic variant, M-NAG-$\\alpha$, thereby enhancing\noptimization efficiency. Finally, by leveraging the fundamental inequality for\ncomposite functions, we extended the controllable $O\\left(1\/k^{2\\alpha}\n\\right)$ rate to proximal algorithms, including the fast iterative\nshrinkage-thresholding algorithm (FISTA-$\\alpha$) and its monotonic counterpart\n(M-FISTA-$\\alpha$)."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-502",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09236",
    "b_title":[
      "Early Validation of High-level Requirements on Cyber-Physical Systems"
    ],
    "b_abstract":[
      "The overarching, broad topic of my research are advancements in the area of\nsafety-critical, cyber-physical systems (CPS) development with emphasis on\nvalidation and verification. The particular focus of my research is the early\nvalidation of high-level requirements on CPS. My current approach for tackling\nthis problem is transforming the requirements into Event Calculus and\nsubsequently reasoning about them using ASP solvers such as the grounding-free\ns(CASP). Below, I discuss my research, its current state, and the open issues\nthat are still left to tackle. The first results of my work will be presented\nin a paper that was accepted for ICLP'24, which is my first paper in this area."
    ],
    "b_categories":[
      [
        "cs.LO",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14424",
    "c_title":[
      "Identifying Materials-Level Sources of Performance Variation in\n  Superconducting Transmon Qubits"
    ],
    "c_abstract":[
      "The Superconducting Materials and Systems (SQMS) Center, a DOE National\nQuantum Information Science Research Center, has conducted a comprehensive and\ncoordinated study using superconducting transmon qubit chips with known\nperformance metrics to identify the underlying materials-level sources of\ndevice-to-device performance variation. Following qubit coherence measurements,\nthese qubits of varying base superconducting metals and substrates have been\nexamined with various nondestructive and invasive material characterization\ntechniques at Northwestern University, Ames National Laboratory, and Fermilab\nas part of a blind study. We find trends in variations of the depth of the\netched substrate trench, the thickness of the surface oxide, and the geometry\nof the sidewall, which when combined, lead to correlations with the T$_1$\nlifetime across different devices. In addition, we provide a list of features\nthat varied from device to device, for which the impact on performance requires\nfurther studies. Finally, we identify two low-temperature characterization\ntechniques that may potentially serve as proxy tools for qubit measurements.\nThese insights provide materials-oriented solutions to not only reduce\nperformance variations across neighboring devices, but also to engineer and\nfabricate devices with optimal geometries to achieve performance metrics beyond\nthe state-of-the-art values."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-503",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03004",
    "b_title":[
      "Large $N$ Vertex Algebras via Deligne Category"
    ],
    "b_abstract":[
      "In this paper, we propose a new construction of vertex algebras using the\nDeligne category. This approach provides a rigorous framework for defining the\nso-called large $N$ vertex algebra, which has appeared in recent physics\nliteratures. We first define the notion of a vertex algebra in a symmetric\nmonoidal category and extend familiar constructions in ordinary vertex algebras\nto this broader categorical context. As an application, we consider a\n$\\beta\\gamma$ vertex algebra in the Deligne category and construct the large N\nvertex algebra from it. We study some simple properties of this vertex algebra\nand analyze a certain vertex Poisson algebra limit."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.11985",
    "c_title":[
      "No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in\n  Large Language models"
    ],
    "c_abstract":[
      "Advancements in Large Language Models (LLMs) have increased the performance\nof different natural language understanding as well as generation tasks.\nAlthough LLMs have breached the state-of-the-art performance in various tasks,\nthey often reflect different forms of bias present in the training data. In the\nlight of this perceived limitation, we provide a unified evaluation of\nbenchmarks using a set of representative LLMs that cover different forms of\nbiases starting from physical characteristics to socio-economic categories.\nMoreover, we propose five prompting approaches to carry out the bias detection\ntask across different aspects of bias. Further, we formulate three research\nquestions to gain valuable insight in detecting biases in LLMs using different\napproaches and evaluation metrics across benchmarks. The results indicate that\neach of the selected LLMs suffer from one or the other form of bias with the\nLLaMA3.1-8B model being the least biased. Finally, we conclude the paper with\nthe identification of key challenges and possible future directions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-504",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18610",
    "b_title":[
      "Exploring the Onset of Collectivity Approaching N=40 through Manganese\n  Masses"
    ],
    "b_abstract":[
      "Isotopes in the region of the nuclear chart below $^{68}\\mathrm{Ni}$ have\nbeen the subject of intense experimental and theoretical effort due to the\npotential onset of a new ``island of inversion'' when crossing the harmonic\noscillator subshell closure at $N = 40$. We have measured the masses of\n$^{64-68}\\textrm{Mn}$ using TITAN's multiple-reflection time-of-flight mass\nspectrometer, resulting in the first precision mass measurements of\n$^{67}\\mathrm{Mn}$ and $^{68}\\mathrm{Mn}$. These results are compared to\n\\textit{ab initio} calculations and modern shell model calculations and show an\nincrease in collectivity approaching $N=40$."
    ],
    "b_categories":[
      [
        "nucl-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06939",
    "c_title":[
      "Quantization of nonlinear non-Hamiltonian systems"
    ],
    "c_abstract":[
      "Several important dynamical systems are in $\\mathbb{R}^2$, defined by\n$(x',y')=(f(x,y),g(x,y))$. A question of fundamental importance is how such\nsystems might behave quantum mechanically. In developing quantum theory, Dirac\nand others realized that classical Hamiltonian systems can be mapped to their\nquantum counterparts via canonical quantization. The resulting quantum dynamics\nis always physical, characterized by completely-positive and trace-preserving\nevolutions in the Schr\\\"odinger picture. However, whether non-Hamiltonian\nsystems can be quantized systematically while respecting the same physical\nrequirements has remained a long-standing problem. Here we resolve this\nquestion when $f(x,y)$ and $g(x,y)$ are arbitrary polynomials. By leveraging\nopen-systems theory, we prove constructively that every polynomial system\nadmits a physical generator of time evolution in the form of a Lindbladian. We\nrefer to our method as cascade quantization, and demonstrate its power by\nanalyzing several paradigmatic examples of nonlinear dynamics such as\nbifurcations, noise-activated spiking, and Li\\'{e}nard systems. In effect, any\nclassical system whose $f(x,y)$ and $g(x,y)$ are analytic functions can be\nquantized with arbitrary precision. Crucially, our method is exact. Being free\nfrom any approximations, cascade quantization dispenses with simplifying\nassumptions such as the weakly-nonlinear limit, or semiclassical dynamics in\nthe quantized system -- both of which have been critical in facilitating\nquantization in the literature. We also highlight the advantages of cascade\nquantization over the existing proposals, by weighing it against examples from\nthe variational paradigm using Lagrangians, as well as non-variational\napproaches."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "nlin.AO",
        "nlin.CD",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-505",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01058",
    "b_title":[
      "Giant emitter magnetometer"
    ],
    "b_abstract":[
      "Leveraging the sensitive dependence of a giant atom's radiation rate on its\nfrequency [A. F. Kockum, $et~al$., Phys. Rev. A 90, 013837 (2014)], we propose\nan effective magnetometer model based on single giant emitter. In this model,\nthe emitter's frequency is proportional to the applied bias magnetic field. The\nself-interference effect causes the slope of the dissipation spectrum to vary\nlinearly with the number of emitter-coupling points. The giant emitter\nmagnetometer achieves a sensitivity as high as $10^{-8}-10^{-9}\\,{\\rm\nT\/\\sqrt{Hz}}$, demonstrating the significant advantages of the\nself-interference effect compared to small emitters. We hope our proposal will\nexpand the applications of giant emitters in precision measurement and\nmagnetometry."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.05899",
    "c_title":[
      "Towards Understanding the Use of MLLM-Enabled Applications for Visual\n  Interpretation by Blind and Low Vision People"
    ],
    "c_abstract":[
      "Blind and Low Vision (BLV) people have adopted AI-powered visual\ninterpretation applications to address their daily needs. While these\napplications have been helpful, prior work has found that users remain\nunsatisfied by their frequent errors. Recently, multimodal large language\nmodels (MLLMs) have been integrated into visual interpretation applications,\nand they show promise for more descriptive visual interpretations. However, it\nis still unknown how this advancement has changed people's use of these\napplications. To address this gap, we conducted a two-week diary study in which\n20 BLV people used an MLLM-enabled visual interpretation application we\ndeveloped, and we collected 553 entries. In this paper, we report a preliminary\nanalysis of 60 diary entries from 6 participants. We found that participants\nconsidered the application's visual interpretations trustworthy (mean 3.75 out\nof 5) and satisfying (mean 4.15 out of 5). Moreover, participants trusted our\napplication in high-stakes scenarios, such as receiving medical dosage advice.\nWe discuss our plan to complete our analysis to inform the design of future\nMLLM-enabled visual interpretation systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-506",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10174",
    "b_title":[
      "Sensitivity-Based Distributed Programming for Non-Convex Optimization"
    ],
    "b_abstract":[
      "This paper presents a novel sensitivity-based distributed programming (SBDP)\napproach for non-convex, large-scale nonlinear programs (NLP). The algorithm\nrelies on first-order sensitivities to cooperatively solve the central NLP in a\ndistributed manner with only neighbor-to-neighbor communication and\nparallelizable local computations. The scheme is based on primal decomposition\nand offers minimal algorithmic complexity. We derive sufficient local\nconvergence conditions for non-convex problems. Furthermore, we consider the\nSBDP method in a distributed optimal control context and derive favorable\nconvergence properties in this setting. We illustrate these theoretical\nfindings and the performance of the proposed algorithm with simulations of\nvarious distributed optimization and control problems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08621",
    "c_title":[
      "ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and\n  Vietnamese-Lao language pair"
    ],
    "c_abstract":[
      "This paper presents an results of the VLSP 2022-2023 Machine Translation\nShared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine\ntranslation. The tasks were organized as part of the 9th, 10th annual workshop\non Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The\nobjective of the shared task was to build machine translation systems,\nspecifically targeting Vietnamese-Chinese and Vietnamese-Lao translation\n(corresponding to 4 translation directions). The submission were evaluated on\n1,000 pairs for testing (news and general domains) using established metrics\nlike BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were\nevaluated with human judgment provided by experts in Chinese and Lao languages.\nThese human assessments played a crucial role in ranking the performance of the\nmachine translation models, ensuring a more comprehensive evaluation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-507",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03605",
    "b_title":[
      "Accelerating OTA Circuit Design: Transistor Sizing Based on a\n  Transformer Model and Precomputed Lookup Tables"
    ],
    "b_abstract":[
      "Device sizing is crucial for meeting performance specifications in\noperational transconductance amplifiers (OTAs), and this work proposes an\nautomated sizing framework based on a transformer model. The approach first\nleverages the driving-point signal flow graph (DP-SFG) to map an OTA circuit\nand its specifications into transformer-friendly sequential data. A specialized\ntokenization approach is applied to the sequential data to expedite the\ntraining of the transformer on a diverse range of OTA topologies, under\nmultiple specifications. Under specific performance constraints, the trained\ntransformer model is used to accurately predict DP-SFG parameters in the\ninference phase. The predicted DP-SFG parameters are then translated to\ntransistor sizes using a precomputed look-up table-based approach inspired by\nthe gm\/Id methodology. In contrast to previous conventional or\nmachine-learning-based methods, the proposed framework achieves significant\nimprovements in both speed and computational efficiency by reducing the need\nfor expensive SPICE simulations within the optimization loop; instead, almost\nall SPICE simulations are confined to the one-time training phase. The method\nis validated on a variety of unseen specifications, and the sizing solution\ndemonstrates over 90% success in meeting specifications with just one SPICE\nsimulation for validation, and 100% success with 3-5 additional SPICE\nsimulations."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10511",
    "c_title":[
      "Irradiated Pulsar Planets and Companions as 511 keV Positron\n  Annihilation Line Sources"
    ],
    "c_abstract":[
      "Millisecond pulsars (MSPs) are prolific GeV {\\gamma}-ray emitters, and nearly\n80% of Fermi-LAT MSPs reside in compact binaries. We demonstrate that the\ncompanions in these compact MSPs binaries are also 511 keV annihilation line\nemitters using MEGAlib simulations (a high energy radiation transport software\nbuilt with Geant4) to compute the particle showers and resulting backsplash\nemission from the pulsar irradiation. The 511 keV signal exhibits strong flux\nmodulation and red\/blueshifts associated with a binary orbit, enabling powerful\ncoherent searches. Measuring the 511 keV emission would enable direct\n{\\gamma}-ray characterization of unusual pulsar exoplanets and companions, and\nallow one to identify the unambiguous presence of active pulsars whose beams do\nnot intercept Earth. Intriguingly, the 511 keV flux is brightest for\nultra-compact systems against which pulsar surveys are systematically biased.\nThese ultra-compact systems are also possibly prime LISA galactic sources. This\nnecessitates future joint LISA-MeV {\\gamma}-ray techniques to characterize MSP\nbinaries. These MSP binaries may also contribute to the puzzling source of the\nexcess 511 keV photons near the galactic bulge and center."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-508",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09337",
    "b_title":[
      "Some aspects of descent theory and applications"
    ],
    "b_abstract":[
      "This thesis is an exposition of the author's contribution on effective\ndescent morphisms in various categories of generalized categorical structures.\nIt consists of: Chapter 1, where an elementary description of descent theory\nand the content of each remaining chapter is provided, supplemented with\nreferences; Chapter 2, consisting of various descent theoretical definitions\nand results employed in the remainder of this work; four chapters, each\ncorresponding to an article written by the author during the period of his PhD\nstudies."
    ],
    "b_categories":[
      [
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16298",
    "c_title":[
      "Uncoded Download in Lagrange-Coded Elastic Computing with Straggler\n  Tolerance"
    ],
    "c_abstract":[
      "Coded elastic computing, introduced by Yang et al. in 2018, is a technique\ndesigned to mitigate the impact of elasticity in cloud computing systems, where\nmachines can be preempted or be added during computing rounds. This approach\nutilizes maximum distance separable (MDS) coding for both storage and download\nin matrix-matrix multiplications. The proposed scheme is unable to tolerate\nstragglers and has high encoding complexity and upload cost. In 2023, we\naddressed these limitations by employing uncoded storage and Lagrange-coded\ndownload. However, it results in a large storage size. To address the\nchallenges of storage size and upload cost, in this paper, we focus on\nLagrange-coded elastic computing based on uncoded download. We propose a new\nclass of elastic computing schemes, using Lagrange-coded storage with uncoded\ndownload (LCSUD). Our proposed schemes address both elasticity and straggler\nchallenges while achieving lower storage size, reduced encoding complexity, and\nupload cost compared to existing methods."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-509",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11876",
    "b_title":[
      "FNIN: A Fourier Neural Operator-based Numerical Integration Network for\n  Surface-form-gradients"
    ],
    "b_abstract":[
      "Surface-from-gradients (SfG) aims to recover a three-dimensional (3D) surface\nfrom its gradients. Traditional methods encounter significant challenges in\nachieving high accuracy and handling high-resolution inputs, particularly\nfacing the complex nature of discontinuities and the inefficiencies associated\nwith large-scale linear solvers. Although recent advances in deep learning,\nsuch as photometric stereo, have enhanced normal estimation accuracy, they do\nnot fully address the intricacies of gradient-based surface reconstruction. To\novercome these limitations, we propose a Fourier neural operator-based\nNumerical Integration Network (FNIN) within a two-stage optimization framework.\nIn the first stage, our approach employs an iterative architecture for\nnumerical integration, harnessing an advanced Fourier neural operator to\napproximate the solution operator in Fourier space. Additionally, a\nself-learning attention mechanism is incorporated to effectively detect and\nhandle discontinuities. In the second stage, we refine the surface\nreconstruction by formulating a weighted least squares problem, addressing the\nidentified discontinuities rationally. Extensive experiments demonstrate that\nour method achieves significant improvements in both accuracy and efficiency\ncompared to current state-of-the-art solvers. This is particularly evident in\nhandling high-resolution images with complex data, achieving errors of fewer\nthan 0.1 mm on tested objects."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06947",
    "c_title":[
      "Quantum Spacetime Leaps: Higher Dimensional Energetic Causal Sets"
    ],
    "c_abstract":[
      "We propose a 2+1d simulation of Energetic Causal Sets (ECS). These are a\nclass of Causal Sets where the agency of time and its irreversibility are taken\nas fundamental. Events are endowed with energy-momentum conservation laws being\napplied at events dictating the dynamics of the Set. Unlike Causal Sets, ECS\nhave three orders, a birth total order, a partial dynamical order which\nprescribes the flow of energy-momentum between events and a partial causal\norder that arises from the embedding of these events in Minkowski spacetime.\nThese orders aren't necessarily in agreement with each other, something we call\ndiscausality or disordered causality. We therefore explain our first attempts\nat expanding to two spatial dimensions the simulations of the Energetic Causal\nSet model to see if we can still obtain reversible dynamics from fundamental\ntime-irreversible laws like in the 1d case."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-510",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04028",
    "b_title":[
      "Stress-stress correlations in two-dimensional amorphous and crystalline\n  solids"
    ],
    "b_abstract":[
      "Stress-stress correlations in crystalline solids with long-range order can be\nstraightforwardly derived using elasticity theory. In contrast, the `emergent\nelasticity' of amorphous solids, rigid materials characterized by an underlying\ndisordered structure, defies direct explanation within traditional theoretical\nframeworks. To address this challenge, tensor gauge theories have been recently\nproposed as a promising approach to describe the emergent elasticity of\ndisordered solids and predict their stress-stress correlations. In this work,\nwe revisit this problem in two-dimensional amorphous and crystalline solids by\nemploying a canonical elasticity theory approach, supported by experimental and\nsimulation data. We demonstrate that, with respect to static stress-stress\ncorrelations, the response of a 2D disordered solid is indistinguishable from\nthat of a 2D isotropic crystalline solid and it is well predicted by vanilla\nelasticity theory. Moreover, we show that the presence of pinch-point\nsingularities in the stress response is not an exclusive feature of amorphous\nsolids. Our results confirm previous observations about the universal character\nof static stress-stress correlations in crystalline and amorphous packings."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07764",
    "c_title":[
      "Deep Learning for Disease Outbreak Prediction: A Robust Early Warning\n  Signal for Transcritical Bifurcations"
    ],
    "c_abstract":[
      "Early Warning Signals (EWSs) are vital for implementing preventive measures\nbefore a disease turns into a pandemic. While new diseases exhibit unique\nbehaviors, they often share fundamental characteristics from a dynamical\nsystems perspective. Moreover, measurements during disease outbreaks are often\ncorrupted by different noise sources, posing challenges for Time Series\nClassification (TSC) tasks. In this study, we address the problem of having a\nrobust EWS for disease outbreak prediction using a best-performing deep\nlearning model in the domain of TSC. We employed two simulated datasets to\ntrain the model: one representing generated dynamical systems with randomly\nselected polynomial terms to model new disease behaviors, and another\nsimulating noise-induced disease dynamics to account for noisy measurements.\nThe model's performance was analyzed using both simulated data from different\ndisease models and real-world data, including influenza and COVID-19. Results\ndemonstrate that the proposed model outperforms previous models, effectively\nproviding EWSs of impending outbreaks across various scenarios. This study\nbridges advancements in deep learning with the ability to provide robust early\nwarning signals in noisy environments, making it highly applicable to\nreal-world crises involving emerging disease outbreaks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-511",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17464",
    "b_title":[
      "Modelling a storage system of a wind farm with a ramp-rate limitation: a\n  semi-Markov modulated Brownian bridge approach"
    ],
    "b_abstract":[
      "We propose a new methodology to simulate the discounted penalty applied to a\nwind-farm operator by violating ramp-rate limitation policies. It is assumed\nthat the operator manages a wind turbine plugged into a battery, which either\nprovides or stores energy on demand to avoid ramp-up and ramp-down events. The\nbattery stages, namely charging, discharging, or neutral, are modeled as a\nsemi-Markov process. During each charging\/discharging period, the energy\nstored\/supplied is assumed to follow a modified Brownian bridge that depends on\nthree parameters. We prove the validity of our methodology by testing the model\non 10 years of real wind-power data and comparing real versus simulated\nresults."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11579",
    "c_title":[
      "Flipping qudits: Extending the Bit-Flip Channel to higher-dimensional\n  systems"
    ],
    "c_abstract":[
      "We present three possible extensions of the bit-flip channel to qutrit\nsystems based on the diverse interpretations of the channel. Also, we extended\nthem to higher-dimensional qudit systems, formulating different versions of dit\nflip channels. Finally, we studied their impact on the Negativity, as an\nentanglement measure, of qubit-qutrit and 2-qutrit Werner states. In doing so,\nwe showed the inequivalence of these versions as they affect in very distinct\nways the states entanglement."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-512",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13529",
    "b_title":[
      "The impact of artificial intelligence technology on cross-border trade\n  in Southeast Asia: A meta-analytic approach"
    ],
    "b_abstract":[
      "This study investigates the impact of artificial intelligence (AI) technology\non cross-border trade using a qualitative content analysis approach. By\nsynthesizing existing empirical studies, we aim to quantify the overall effect\nof AI on trade flows and identify the key moderating and mediating variables.\nBesides, our results show that AI adoption significantly increases trade\nvolumes in Southeast Asia. Likewise, these effects are stronger in regions with\nadvanced technological infrastructure and favorable regulatory frameworks. In\naddition, Trade firm size partially mediates the relationship between AI\ntechnology and trade performance. Furthermore, this study draws on several key\ntheoretical frameworks that provide a comprehensive understanding of the\nmechanisms through which AI technology is affecting cross-border trade in\nSoutheast Asia. The primary theories used in this research include the\ntechnology, organization, and environment (TOE) framework, the diffuse\ninnovation (DOI) theory, Dynamic Capabilities Theory, Comparative Advantage\nTheory, Network theory, Transaction Cost Economics (TCE), the resource-based\nview, and the institution theory. Consequently, this study contributes to the\nexisting literature by providing a comprehensive analysis of the role of AI in\ninternational trade and highlighting the importance of contextual factors in\nmaximizing the benefits of AI. Thus, our findings underscore the need for\nfavorable policies and robust infrastructure to facilitate AI-driven trade\ngrowth. A discussion of limitations and future research directions will also be\npart of the report in Southeast Asia Trade."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.18984",
    "c_title":[
      "Cycles and collusion in congestion games under Q-learning"
    ],
    "c_abstract":[
      "We investigate the dynamics of Q-learning in a class of generalized Braess\nparadox games. These games represent an important class of network routing\ngames where the associated stage-game Nash equilibria do not constitute social\noptima. We provide a full convergence analysis of Q-learning with varying\nparameters and learning rates. A wide range of phenomena emerges, broadly\neither settling into Nash or cycling continuously in ways reminiscent of\n\"Edgeworth cycles\" (i.e. jumping suddenly from Nash toward social optimum and\nthen deteriorating gradually back to Nash). Our results reveal an important\nincentive incompatibility when thinking in terms of a meta-game being played by\nthe designers of the individual Q-learners who set their agents' parameters.\nIndeed, Nash equilibria of the meta-game are characterized by heterogeneous\nparameters, and resulting outcomes achieve little to no cooperation beyond\nNash. In conclusion, we suggest a novel perspective for thinking about\nregulation and collusion, and discuss the implications of our results for\nBertrand oligopoly pricing games."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.MA",
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-513",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02987",
    "b_title":[
      "On the numerical evaluation of wall shear stress using the finite\n  element method"
    ],
    "b_abstract":[
      "Wall shear stress (WSS) is a crucial hemodynamic quantity extensively studied\nin cardiovascular research, yet its numerical computation is not\nstraightforward. This work aims to compare WSS results obtained from two\ndifferent finite element discretizations, quantify the differences between\ncontinuous and discontinuous stresses, and introduce a novel method for WSS\nevaluation through the formulation of a boundary-flux problem. Two benchmark\nproblems are considered - a 2D Stokes flow on a unit square and a 3D Poiseuille\nflow through a cylindrical pipe. These are followed by investigations of\nsteady-state Navier-Stokes flow in two patient-specific aneurysms. The study\nfocuses on P1\/P1 stabilized and Taylor-Hood P2\/P1 mixed finite elements for\nvelocity and pressure. WSS is computed using either the proposed boundary-flux\nmethod or as a projection of tangential traction onto First order Lagrange\n(P1), Discontinuous Galerkin first order (DG-1), or Discontinuous Galerkin zero\norder (DG-0) space. For the P1\/P1 stabilized element, the boundary-flux and P1\nprojection methods yielded equivalent results. With the P2\/P1 element, the\nboundary-flux evaluation demonstrated faster convergence in the Poiseuille flow\nexample but showed increased sensitivity to pressure field inaccuracies in\npatient-specific geometries compared to the projection method. In\npatient-specific cases, the P2\/P1 element exhibited superior robustness to mesh\nsize when evaluating average WSS and low shear area (LSA), outperforming the\nP1\/P1 stabilized element. Projecting discontinuous finite element results into\ncontinuous spaces can introduce artifacts, such as the Gibbs phenomenon.\nConsequently, it becomes crucial to carefully select the finite element space\nfor boundary stress calculations - not only in applications involving WSS\ncomputations for aneurysms."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17142",
    "c_title":[
      "The feasibility of multi-graph alignment: a Bayesian approach"
    ],
    "c_abstract":[
      "We establish thresholds for the feasibility of random multi-graph alignment\nin two models. In the Gaussian model, we demonstrate an \"all-or-nothing\"\nphenomenon: above a critical threshold, exact alignment is achievable with high\nprobability, while below it, even partial alignment is statistically\nimpossible. In the sparse Erd\\H{o}s-R\\'enyi model, we rigorously identify a\nthreshold below which no meaningful partial alignment is possible and\nconjecture that above this threshold, partial alignment can be achieved. To\nprove these results, we develop a general Bayesian estimation framework over\nmetric spaces, which provides insight into a broader class of high-dimensional\nstatistical problems."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-514",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14366",
    "b_title":[
      "QuGStep: Refining Step Size Selection in Gradient Estimation for\n  Variational Quantum Algorithms"
    ],
    "b_abstract":[
      "Variational quantum algorithms (VQAs) offer a promising approach to solving\ncomputationally demanding problems by combining parameterized quantum circuits\nwith classical optimization. Estimating probabilistic outcomes on quantum\nhardware requires repeated measurements (shots). However, in practice, the\nlimited shot budget introduces significant noise in the evaluation of the\nobjective function. Gradient estimation in VQAs often relies on the\nfinite-difference, which evaluates the noisy objective function at perturbed\ncircuit parameter values. The accuracy of this estimation is highly dependent\non the choice of step size for these perturbations. An inappropriate step size\ncan exacerbate the impact of noise, causing inaccurate gradient estimates and\nhindering the classical optimization in VQAs. This paper proposes QuGStep, an\nalgorithm that addresses the challenge of determining the appropriate step size\nfor finite-difference gradient estimation under a shot budget. QuGStep is\ngrounded in a theorem that proves the optimal step size, which accounts for the\nshot budget, minimizes the error bound in gradient estimation using finite\ndifferences. Numerical experiments approximating the ground state energy of\nseveral molecules demonstrate that QuGStep can identify the appropriate step\nsize for the given shot budget to obtain effective gradient estimation.\nNotably, the step size identified by QuGStep achieved convergence to the ground\nstate energy with over 96% fewer shots compared to using a default step size.\nThese findings highlight the potential of QuGStep to improve the practical\ndeployment and scalability of quantum computing technologies."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2502.11435",
    "c_title":[
      "SMART: Self-Aware Agent for Tool Overuse Mitigation"
    ],
    "c_abstract":[
      "Current Large Language Model (LLM) agents demonstrate strong reasoning and\ntool use capabilities, but often lack self-awareness, failing to balance these\napproaches effectively. This imbalance leads to Tool Overuse, where models\nunnecessarily rely on external tools for tasks solvable with parametric\nknowledge, increasing computational overhead. Inspired by human metacognition,\nwe introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm\nthat enhances an agent's self-awareness to optimize task handling and reduce\ntool overuse. To support this paradigm, we introduce SMART-ER, a dataset\nspanning three domains, where reasoning alternates between parametric knowledge\nand tool-dependent steps, with each step enriched by rationales explaining when\ntools are necessary. Through supervised training, we develop SMARTAgent, a\nfamily of models that dynamically balance parametric knowledge and tool use.\nEvaluations show that SMARTAgent reduces tool use by 24% while improving\nperformance by over 37%, enabling 7B-scale models to match its 70B counterpart\nand GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test\ndata like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool\ncalls. These highlight the potential of strategic tool use to enhance\nreasoning, mitigate overuse, and bridge the gap between model size and\nperformance, advancing intelligent and resource-efficient agent designs."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-515",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19152",
    "b_title":[
      "Oddities in the Entanglement Scaling of the Quantum Six-Vertex Model"
    ],
    "b_abstract":[
      "We investigate the entanglement properties of the Quantum Six-Vertex Model on\na cylinder, focusing on the Shannon-Renyi entropy in the limit of Renyi order\n$n = \\infty$. This entropy, calculated from the ground state amplitudes of the\nequivalent XXZ spin-1\/2 chain, allows us to determine the Renyi entanglement\nentropy of the corresponding Rokhsar-Kivelson wavefunctions, which describe the\nground states of certain conformal quantum critical points. Our analysis\nreveals a novel logarithmic correction to the expected entanglement scaling\nwhen the system size is odd. This anomaly arises from the geometric frustration\nof spin configurations imposed by periodic boundary conditions on odd-sized\nchains. We demonstrate that the scaling prefactor of this logarithmic term is\ndirectly related to the compactification radius of the low-energy bosonic field\ntheory description, or equivalently, the Luttinger parameter. Thus, this\ncorrection provides a direct probe of the underlying Conformal Field Theory\n(CFT) describing the critical point. Our findings highlight the crucial role of\nsystem size parity in determining the entanglement properties of this model and\noffer insights into the interplay between geometry, frustration, and\ncriticality."
    ],
    "b_categories":[
      [
        "cond-mat.str-el",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00372",
    "c_title":[
      "Nucleolus Credit Assignment for Effective Coalitions in Multi-agent\n  Reinforcement Learning"
    ],
    "c_abstract":[
      "In cooperative multi-agent reinforcement learning (MARL), agents typically\nform a single grand coalition based on credit assignment to tackle a composite\ntask, often resulting in suboptimal performance. This paper proposed a\nnucleolus-based credit assignment grounded in cooperative game theory, enabling\nthe autonomous partitioning of agents into multiple small coalitions that can\neffectively identify and complete subtasks within a larger composite task.\nSpecifically, our designed nucleolus Q-learning could assign fair credits to\neach agent, and the nucleolus Q-operator provides theoretical guarantees with\ninterpretability for both learning convergence and the stability of the formed\nsmall coalitions. Through experiments on Predator-Prey and StarCraft scenarios\nacross varying difficulty levels, our approach demonstrated the emergence of\nmultiple effective coalitions during MARL training, leading to faster learning\nand superior performance in terms of win rate and cumulative rewards especially\nin hard and super-hard environments, compared to four baseline methods. Our\nnucleolus-based credit assignment showed the promise for complex composite\ntasks requiring effective subteams of agents."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-516",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14100",
    "b_title":[
      "JWST 1.5 {\\mu}m and 4.8 {\\mu}m Photometry of Y Dwarfs"
    ],
    "b_abstract":[
      "Brown dwarfs lack nuclear fusion and cool with time; the coldest known have\nan effective temperature below 500 K, and are known as Y dwarfs. We present a\nJames Webb Space Telescope (JWST) photometric dataset of Y dwarfs: twenty-three\nwere imaged in wide-field mode, 20 using NIRCam with the F150W and F480M\nfilters, and 3 using NIRISS with the F480M filter. We present an F480M vs.\nF150W $-$ F480M color-magnitude diagram for our sample, and other brown dwarfs\nwith F150W and F480M colors synthesized from JWST spectra by Beiler et al.\n(2024). For one target, WISEA J083011.95$+$283716.0, its detection in the\nnear-infrared confirms it as one of the reddest Y dwarfs known, with F150W $-$\nF480M $= 9.62$ mag. We provide its updated parallax and proper motion. One of\nthe Beiler et al. Y dwarfs, CWISEP J104756.81+545741.6, is unusually blue,\nconsistent with strong CO absorption seen in its spectrum which the F480M\nfilter is particularly sensitive to. The strong CO and the kinematics of the\nobject suggest it may be very low-mass and young. We update the resolved\nphotometry for the close binary system WISE J033605.05$-$014350.4 AB, and find\nthat the secondary is almost as cold as WISE 085510.83$-$071442.5, with $T_{\\rm\neff} \\lesssim 300$ K, however the F150W $-$ F480M color is significantly bluer,\npossibly suggesting the presence of water clouds. Astrometry is measured at the\nJWST epoch for the sample which is consistent with parallax and proper motion\nvalues reported by Kirkpatrick et al. (2021) and Marocco et al. (in prep)."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20568",
    "c_title":[
      "A Tutorial on Multi-time Scale Optimization Models and Algorithms"
    ],
    "c_abstract":[
      "Systems across different industries consist of interrelated processes and\ndecisions in different time scales including long-time decisions and short-term\ndecisions. To optimize such systems, the most effective approach is to\nformulate and solve multi-time scale optimization models that integrate various\ndecision layers. In this tutorial, we provide an overview of multi-time scale\noptimization models and review the algorithms used to solve them. We also\ndiscuss the metric Value of the Multi-scale Model (VMM) introduced to quantify\nthe benefits of using multi-time scale optimization models as opposed to\nsequentially solving optimization models from high-level to low-level. Finally,\nwe present an illustrative example of a multi-time scale capacity expansion\nplanning model and showcase how it can be solved using some of the algorithms\n(https:\/\/github.com\/li-group\/MultiScaleOpt-Tutorial.git). This tutorial serves\nas both an introductory guide for beginners with no prior experience and a\nhigh-level overview of current algorithms for solving multi-time scale\noptimization models, catering to experts in process systems engineering."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-517",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09402",
    "b_title":[
      "VLog: Video-Language Models by Generative Retrieval of Narration\n  Vocabulary"
    ],
    "b_abstract":[
      "Human daily activities can be concisely narrated as sequences of routine\nevents (e.g., turning off an alarm) in video streams, forming an event\nvocabulary. Motivated by this, we introduce VLog, a novel video understanding\nframework that define video narrations as vocabulary, going beyond the typical\nsubword vocabularies in existing generative video-language models. Built on the\nlightweight language model GPT-2, VLog feature three key innovations: (i) A\ngenerative retrieval model, marrying language model's complex reasoning\ncapabilities with contrastive retrieval's efficient similarity search. (ii) A\nhierarchical vocabulary derived from large-scale video narrations using our\nnarration pair encoding algorithm, enabling efficient indexing of specific\nevents (e.g., cutting a tomato) by identifying broader scenarios (e.g.,\nkitchen) with expressive postfixes (e.g., by the left hand). (iii) A vocabulary\nupdate strategy leveraging generative models to extend the vocabulary for novel\nevents encountered during inference. To validate our approach, we introduce\nVidCap-Eval, a development set requiring concise narrations with reasoning\nrelationships (e.g., before and after). Experiments on EgoSchema, COIN, and\nHiREST further demonstrate the effectiveness of VLog, highlighting its ability\nto generate concise, contextually accurate, and efficient narrations, offering\na novel perspective on video understanding. Codes are released at\nhttps:\/\/github.com\/showlab\/VLog."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01173",
    "c_title":[
      "Improving knowledge of the acoustic factors involved in railway noise\n  annoyance: first results of a pilot field survey of sixty-two local residents"
    ],
    "c_abstract":[
      "Railway transportation contributes to the objectives of decarbonization but\nalso generates negative externalities, including noise. Energy noise indicators\nused to characterize population exposure do not adequately reflect the\nrepetitive nature of railway noise peaks. The GENIFER pilot study aims to test\na protocol designed to characterize railway noise events according to the\ninstantaneous perceived annoyance when the train is passing, in order to\nimprove understanding of the influence of acoustic factors on annoyance. The\nfirst phase of the survey was carried out in 2023 among 62 residents of a pilot\nsite. An electronic device was used to collect around 5,000 ratings, ranging\nfrom 1 to 10, assessing the instantaneous annoyance induced by railway noise at\npassing trains. The site instrumentation included sixteen sound level meters\nand two video recording systems, enabling annoyance ratings to be associated\nwith the acoustic characteristics of railway noise events. A questionnaire\naimed at identifying co-determinants of long-term annoyance was also\nadministered to participants. Feedback on the field implementation of this\nsurvey and initial results concerning acoustic measurements, instantaneous\nannoyance ratings and questionnaire responses will be presented."
    ],
    "c_categories":[
      [
        "physics.class-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-518",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10182",
    "b_title":[
      "Secure Semantic Communication With Homomorphic Encryption"
    ],
    "b_abstract":[
      "In recent years, Semantic Communication (SemCom), which aims to achieve\nefficient and reliable transmission of meaning between agents, has garnered\nsignificant attention from both academia and industry. To ensure the security\nof communication systems, encryption techniques are employed to safeguard\nconfidentiality and integrity. However, traditional cryptography-based\nencryption algorithms encounter obstacles when applied to SemCom. Motivated by\nthis, this paper explores the feasibility of applying homomorphic encryption to\nSemCom. Initially, we review the encryption algorithms utilized in mobile\ncommunication systems and analyze the challenges associated with their\napplication to SemCom. Subsequently, we employ scale-invariant feature\ntransform to demonstrate that semantic features can be preserved in homomorphic\nencrypted ciphertext. Based on this finding, we propose a task-oriented SemCom\nscheme secured through homomorphic encryption. We design the privacy preserved\ndeep joint source-channel coding (JSCC) encoder and decoder, and the frequency\nof key updates can be adjusted according to service requirements without\ncompromising transmission performance. Simulation results validate that, when\ncompared to plaintext images, the proposed scheme can achieve almost the same\nclassification accuracy performance when dealing with homomorphic ciphertext\nimages. Furthermore, we provide potential future research directions for\nhomomorphic encrypted SemCom."
    ],
    "b_categories":[
      [
        "cs.CR",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03421",
    "c_title":[
      "Linear stability of charged warm holes"
    ],
    "c_abstract":[
      "Charged black holes are known to suffer from an interior instability\nassociated with the presence of the Cauchy horizon. Recently, a hairy charged\nblack hole was proposed that avoids the formation of a Cauchy horizon. It is\nnatural to question whether this instability might manifest in the exterior\nsolution. In this paper, we have analyzed the stability of this black hole. Our\nresults show that vector perturbations are stable, along with the scalar sector\nfor $l=0$. We have also computed the corresponding quasinormal modes (QNMs) and\nquasibound states (QBSs). Among the six degrees of freedom identified, one\nexhibits a ghost-like behavior. However, this mode decouples from the other\nperturbations, rendering the associated instability irrelevant in the linear\nregime. Nonetheless, this feature could indicate a more significant issue in\nthe nonlinear regime."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-519",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19475",
    "b_title":[
      "Impulsive mixing of stellar populations in dwarf spheroidal galaxies"
    ],
    "b_abstract":[
      "We study the response of mono-energetic stellar populations with initially\nisotropic kinematics to impulsive and adiabatic changes to an underlying dark\nmatter potential. Half-light radii expand and velocity dispersions decrease as\nenclosed dark matter is removed. The details of this expansion and cooling\ndepend on the time scale on which the underlying potential changes. In the\nadiabatic regime, the product of half-light radius and average velocity\ndispersion is conserved. We show that the stellar populations maintain\ncentrally isotropic kinematics throughout their adiabatic evolution, and their\ndensities can be approximated by a family of analytical radial profiles.\nMetallicity gradients within the galaxy flatten as dark matter is slowly\nremoved. In the case of strong impulsive perturbations, stellar populations\ndevelop power-law-like density tails with radially biased kinematics. We show\nthat the distribution of stellar binding energies within the dark matter halo\nsubstantially widens after an impulsive perturbation, no matter the sign of the\nperturbation. This allows initially energetically separated stellar populations\nto mix, to the extent that previously chemo-dynamically distinct populations\nmay masquerade as a single population with large metallicity and energy spread.\nFinally, we show that in response to an impulsive perturbation, stellar\npopulations that are deeply embedded in cored dark matter halos undergo a\nseries of damped oscillations before reaching a virialised equilibrium state,\ndriven by inefficient phase mixing in the harmonic potentials of cored halos.\nThis slow return to equilibrium adds substantial systematic uncertainty to\ndynamical masses estimated from Jeans modeling or the virial theorem."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14245",
    "c_title":[
      "Parameterized bipartite entanglement measures and entanglement\n  constraints"
    ],
    "c_abstract":[
      "In this paper, we propose a novel class of parameterized entanglement\nmeasures which are named as $G_\\omega$-concurrence ($G_\\omega$C)\n($0<\\omega\\leq1$), and demonstrate comprehensively that they satisfy all the\nnecessary axiomatic conditions required for an entanglement measure.\nFurthermore, we derive an analytical formula relating $G_\\omega$C to\nconcurrence for the range of $0.85798\\leq\\omega\\leq1$ within two-qubit systems.\nAdditionally, we prove a new polygamy relation of multiqubit quantum\nentanglement in terms of $G_\\omega$-concurrence of assistance ($G_\\omega$CoA).\nHowever, it fails to obey the monogamy relation, but we have demonstrated that\nthe squared $G_\\omega$-concurrence (S$G_\\omega$C) does obeys a general monogamy\nrelation in an arbitrary $N$-qubit mixed state. Based on the monogamy\nproperties of S$G_\\omega$C, we can construct the corresponding multipartite\nentanglement indicators, which can detect all genuine multiqubit entangled\nstates even in the case of $N$-tangle vanishes. In addition, for multipartite\nhigher-dimensional systems, it is illustrated that S$G_\\omega$C still has the\napplicability of the monogamy relation."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-520",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00284",
    "b_title":[
      "Bounded-Confidence Models of Multi-Dimensional Opinions with\n  Topic-Weighted Discordance"
    ],
    "b_abstract":[
      "People's opinions on a wide range of topics often evolve over time through\ntheir interactions with others. Models of opinion dynamics primarily focus on\none-dimensional opinions which represent opinions on one topic. However,\nopinions on various topics are rarely isolated; instead, they can be\ninterdependent and exhibit correlations. In a bounded-confidence model (BCM) of\nopinion dynamics, agents influence each other's opinions only if their opinions\nare sufficiently similar. We extend classical agent-based BCMs -- namely, the\nHegeselmann--Krause BCM, which has synchronous interactions, and the\nDeffuant--Weisbuch BCM, which has asynchronous interactions -- to a\nmultidimensional setting, in which the opinions are multidimensional vectors\nrepresenting opinions of different topics and opinions on different topics are\ninterdependent. To measure opinion differences between agents, we introduce\ntopic-weighted discordance functions that account for opinion differences in\nall topics. We use the regions of receptiveness to characterize the\nsteady-state opinion clusters and provide an analytical approach to compute\nthese regions. In addition, we numerically simulate our models on various\nnetworks with initial opinions drawn from a variety of distributions. When\ninitial opinions are correlated across different topics, our topic-weighted\nBCMs yield significantly different results in both transient and steady states\ncompared to baseline models, where the dynamics of each opinion topic are\nindependent."
    ],
    "b_categories":[
      [
        "cs.SI",
        "math.DS",
        "physics.soc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12656",
    "c_title":[
      "PPO-Based Vehicle Control for Ramp Merging Scheme Assisted by Enhanced\n  C-V2X"
    ],
    "c_abstract":[
      "On-ramp merging presents a critical challenge in autonomous driving, as\nvehicles from merging lanes need to dynamically adjust their positions and\nspeeds while monitoring traffic on the main road to prevent collisions. To\naddress this challenge, we propose a novel merging control scheme based on\nreinforcement learning, which integrates lateral control mechanisms. This\napproach ensures the smooth integration of vehicles from the merging lane onto\nthe main road, optimizing both fuel efficiency and passenger comfort.\nFurthermore, we recognize the impact of vehicle-to-vehicle (V2V) communication\non control strategies and introduce an enhanced protocol leveraging Cellular\nVehicle-to-Everything (C-V2X) Mode 4. This protocol aims to reduce the Age of\nInformation (AoI) and improve communication reliability. In our simulations, we\nemploy two AoI-based metrics to rigorously assess the protocol's effectiveness\nin autonomous driving scenarios. By combining the NS3 network simulator with\nPython, we simulate V2V communication and vehicle control simultaneously. The\nresults demonstrate that the enhanced C-V2X Mode 4 outperforms the standard\nversion, while the proposed control scheme ensures safe and reliable vehicle\noperation during on-ramp merging."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-521",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09972",
    "b_title":[
      "A bijection for descent sets of permutations with only even and only odd\n  cycles"
    ],
    "b_abstract":[
      "It is known that, when $n$ is even, the number of permutations of\n$\\{1,2,\\dots,n\\}$ all of whose cycles have odd length equals the number of\nthose all of whose cycles have even length. Adin, Heged\\H{u}s and Roichman\nrecently found a surprising refinement of this identity. They showed that, for\nany fixed set $J$, the equality still holds when restricting to permutations\nwith descent set $J$ on one side, and permutations with ascent set $J$ on the\nother. Their proof uses generating functions for higher Lie characters. They\nalso deduce a version for odd $n$.\n  Here we give a bijective proof of their result. We first use known bijections\nto restate the identity in terms of multisets of necklaces, and then describe a\nnew weight-preserving bijection between words all of whose Lyndon factors have\nodd length and are distinct, and words all of whose Lyndon factors have even\nlength. We also show that the corresponding equality about Lyndon\nfactorizations has a short proof using generating functions."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12099",
    "c_title":[
      "Automatic Characterization of Fluxonium Superconducting Qubits\n  Parameters with Deep Transfer Learning"
    ],
    "c_abstract":[
      "Accurate determination of qubit parameters is critical for the successful\nimplementation of quantum information and computation applications. In solid\nstate systems, the parameters of individual qubits vary across the entire\nsystem, requiring time consuming measurements and manual fitting processes for\ncharacterization. Recent developed superconducting qubits, such as fluxonium or\n0-pi qubits, offer improved fidelity operations but exhibit a more complex\nphysical and spectral structure, complicating parameter extraction. In this\nwork, we propose a machine learning (ML)based methodology for the automatic and\naccurate characterization of fluxonium qubit parameters. Our approach utilized\nthe energy spectrum calculated by a model Hamiltonian with various magnetic\nfields, as training data for the ML model. The output consists of the essential\nfluxonium qubit energy parameters, EJ, EC, and EL in Hamiltonian. The ML model\nachieves remarkable accuracy (with an average accuracy 95.6%) as an initial\nguess, enabling the development of an automatic fitting procedure for direct\napplication to realistic experimental data. Moreover, we demonstrate that\nsimilar accuracy can be retrieved even when the input experimental spectrum is\nnoisy or incomplete, highlighting the model robustness. These results suggest\nthat our automated characterization method, based on a transfer learning\napproach, provides a reliable framework for future extensions to other\nsuperconducting qubits or different solid-state systems. Ultimately, we believe\nthis methodology paves the way for the construction of large-scale quantum\nprocessors."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-522",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12422",
    "b_title":[
      "CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer\n  and Metric Learning"
    ],
    "b_abstract":[
      "Multimodal Fake News Detection has received increasing attention recently.\nExisting methods rely on independently encoded unimodal data and overlook the\nadvantages of capturing intra-modality relationships and integrating\ninter-modal similarities using advanced techniques. To address these issues,\nCross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News\nDetection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image\nPre-training with Frozen Image Encoders and Large Language Models (BLIP2) as\nencoders to capture detailed text, image and combined image-text\nrepresentations. The metric learning module employs a proxy anchor method to\ncapture intra-modality relationships while the feature fusion module uses a\nCross-Modal and Tri-Transformer for effective integration. The final fake news\ndetector processes the fused features through a classifier to predict the\nauthenticity of the content. Experiments on datasets show that CroMe excels in\nmultimodal fake news detection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11113",
    "c_title":[
      "Exact Stark analytical function for H{\\alpha} line based on the FFM\n  Model related with plasma parameters"
    ],
    "c_abstract":[
      "Optical Emission Spectroscopy is a widely used technique for plasma\ndiagnosis, with particular interest in hydrogen atomic emission due to its\nprevalence in plasmas. However, accurately determining plasma parameters like\nelectron density, electron temperature, and gas temperature starting from the\nexperimental profiles remains a challenge. This paper introduces a\ncomprehensive model for Stark broadening of the H{\\alpha} line in a wide range\nof plasma conditions, addressing the limitations of existing analytical\nexpressions for line shapes. The proposed model encompasses the full splitting\nof the transition into fifteen Lorentzian profiles and electric micro-field\nfluctuations surrounding the emitting atoms due to collisions with charged\nparticles. Starting from accurate spectral data obtained from realistic\ncomputer simulations, fitting parameters of the model, have been obtained by\nusing an optimization method based on a genetic algorithm. The set of\nparameters of the model are reported for a wide range of plasma conditions. The\nbehavior of these parameters is analyzed to understand their dependence in\nterms of the electron density and temperature and gas density of the plasma.\nThe model parameters here obtained constitute a useful tool in plasma diagnosis\nto obtaining the values of the physical parameters of the plasma starting from\nthe experimental profiles."
    ],
    "c_categories":[
      [
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-523",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16719",
    "b_title":[
      "Practical Acoustic Eavesdropping On Typed Passphrases"
    ],
    "b_abstract":[
      "Cloud services have become an essential infrastructure for enterprises and\nindividuals. Access to these cloud services is typically governed by Identity\nand Access Management systems, where user authentication often relies on\npasswords. While best practices dictate the implementation of multi-factor\nauthentication, it's a reality that many such users remain solely protected by\npasswords. This reliance on passwords creates a significant vulnerability, as\nthese credentials can be compromised through various means, including\nside-channel attacks. This paper exploits keyboard acoustic emanations to infer\ntyped natural language passphrases via unsupervised learning, necessitating no\nprevious training data. Whilst this work focuses on short passphrases, it is\nalso applicable to longer messages, such as confidential emails, where the\nmargin for error is much greater, than with passphrases, making the attack even\nmore effective in such a setting. Unlike traditional attacks that require\nphysical access to the target device, acoustic side-channel attacks can be\nexecuted within the vicinity, without the user's knowledge, offering a\nworthwhile avenue for malicious actors. Our findings replicate and extend\nprevious work, confirming that cross-correlation audio preprocessing\noutperforms methods like mel-frequency-cepstral coefficients and fast-fourier\ntransforms in keystroke clustering. Moreover, we show that partial passphrase\nrecovery through clustering and a dictionary attack can enable faster than\nbrute-force attacks, further emphasizing the risks posed by this attack vector."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10487",
    "c_title":[
      "Sediment Concentration Estimation via Multiscale Inverse Problem and\n  Stochastic Homogenization"
    ],
    "c_abstract":[
      "In this work, we contribute to the broader understanding of inverse problems\nby introducing a versatile multiscale modeling framework tailored to the\nchallenges of sediment concentration estimation. Specifically, we propose a\nnovel approach for sediment concentration measurement in water flow, modeled as\na multiscale inverse medium problem. To address the multiscale nature of the\nsediment distribution, we treat it as an inhomogeneous random field and use the\nhomogenization theory in deriving the effective medium model. The inverse\nproblem is formulated as the reconstruction of the effective medium model,\nspecifically, the sediment concentration, from partial boundary measurements.\nAdditionally, we develop numerical algorithms to improve the efficiency and\naccuracy of solving this inverse problem. Our numerical experiments demonstrate\nthe effectiveness of the proposed model and methods in producing accurate\nsediment concentration estimates, offering new insights into sediment\nconcentration measurement in complex environments."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-524",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04801",
    "b_title":[
      "Entanglement and Bell Nonlocality in $\\tau^+ \\tau^-$ at the BEPC"
    ],
    "b_abstract":[
      "Quantum entanglement and Bell nonlocality are two phenomena that occur only\nin quantum systems. In both cases, these are correlations between two\nsubsystems that are classically absent. Traditionally, these phenomena have\nbeen measured in low-energy photon and electron experiments, but more recently\nthey have also been measured in high-energy particle collider environments. In\nthis work, we propose measuring the entanglement and Bell nonlocality in the\n$\\tau^+\\tau^-$ state near and above its kinematic threshold at the Beijing\nElectron Positron Collider (BEPC). We find that in the existing dataset,\nentanglement is observable if systematic uncertainties are kept to 1%. In the\nupcoming run between 4.0 and 5.6 GeV, the entanglement is predicted to be\nmeasurable with a precision better than 4% and Bell nonlocality can be\nestablished at $5\\sigma$ as long as systematic uncertainty can be controlled at\nlevel of 0.5% - 2.0%, depending on the center-of-mass energy."
    ],
    "b_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10741",
    "c_title":[
      "Development of Application-Specific Large Language Models to Facilitate\n  Research Ethics Review"
    ],
    "c_abstract":[
      "Institutional review boards (IRBs) play a crucial role in ensuring the\nethical conduct of human subjects research, but face challenges including\ninconsistency, delays, and inefficiencies. We propose the development and\nimplementation of application-specific large language models (LLMs) to\nfacilitate IRB review processes. These IRB-specific LLMs would be fine-tuned on\nIRB-specific literature and institutional datasets, and equipped with retrieval\ncapabilities to access up-to-date, context-relevant information. We outline\npotential applications, including pre-review screening, preliminary analysis,\nconsistency checking, and decision support. While addressing concerns about\naccuracy, context sensitivity, and human oversight, we acknowledge remaining\nchallenges such as over-reliance on AI and the need for transparency. By\nenhancing the efficiency and quality of ethical review while maintaining human\njudgment in critical decisions, IRB-specific LLMs offer a promising tool to\nimprove research oversight. We call for pilot studies to evaluate the\nfeasibility and impact of this approach."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-525",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15712",
    "b_title":[
      "SeqSeg: Learning Local Segments for Automatic Vascular Model\n  Construction"
    ],
    "b_abstract":[
      "Computational modeling of cardiovascular function has become a critical part\nof diagnosing, treating and understanding cardiovascular disease. Most\nstrategies involve constructing anatomically accurate computer models of\ncardiovascular structures, which is a multistep, time-consuming process. To\nimprove the model generation process, we herein present SeqSeg (sequential\nsegmentation): a novel deep learning based automatic tracing and segmentation\nalgorithm for constructing image-based vascular models. SeqSeg leverages local\nU-Net-based inference to sequentially segment vascular structures from medical\nimage volumes. We tested SeqSeg on CT and MR images of aortic and aortofemoral\nmodels and compared the predictions to those of benchmark 2D and 3D global\nnnU-Net models, which have previously shown excellent accuracy for medical\nimage segmentation. We demonstrate that SeqSeg is able to segment more complete\nvasculature and is able to generalize to vascular structures not annotated in\nthe training data."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV",
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14087",
    "c_title":[
      "On the scalar sector of 2HDM: ring of basis invariants, syzygies, and\n  six-loop renormalization-group equations"
    ],
    "c_abstract":[
      "We consider a generating set of reparametrization invariants that can be\nconstructed from the couplings and masses entering the scalar potential of the\ngeneral Two-Higgs-Doublet Model (2HDM). Being independent of higgs-basis\nrotations, they generate a polynomial ring of basis invariants that represent\nthe physical content of the model. Ignoring for the moment gauge and Yukawa\ninteractions, we derive six-loop renormalization group equations (RGE) for all\nthe invariants entering the set. We do not compute a single Feynman diagram but\nrely heavily on the general RGE results for scalar theories. We use linear\nalgebra together with techniques from Invariant Theory. The latter not only\nallow one to compute the number of linearly independent invariants entering\nbeta functions at a certain loop order (via Hilbert series) but also provide a\nconvenient tool for dealing with polynomial relations (so-called syzygies)\nbetween invariants from the generating set."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-526",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09674",
    "b_title":[
      "The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Safety\n  Analysis"
    ],
    "b_abstract":[
      "Large Language Models' safety-aligned behaviors, such as refusing harmful\nqueries, can be represented by linear directions in activation space. Previous\nresearch modeled safety behavior with a single direction, limiting mechanistic\nunderstanding to an isolated safety feature. In this work, we discover that\nsafety-aligned behavior is jointly controlled by multi-dimensional directions.\nNamely, we study the vector space of representation shifts during safety\nfine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal\ndirections in the space, we first find that a dominant direction governs the\nmodel's refusal behavior, while multiple smaller directions represent distinct\nand interpretable features like hypothetical narrative and role-playing. We\nthen measure how different directions promote or suppress the dominant\ndirection, showing the important role of secondary directions in shaping the\nmodel's refusal representation. Finally, we demonstrate that removing certain\ntrigger tokens in harmful queries can mitigate these directions to bypass the\nlearned safety capability, providing new insights on understanding safety\nalignment vulnerability from a multi-dimensional perspective. Code and\nartifacts are available at https:\/\/github.com\/BMPixel\/safety-residual-space."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03744",
    "c_title":[
      "Hydrogen Network Expansion Planning considering the Chicken-and-egg\n  Dilemma and Market Uncertainty"
    ],
    "c_abstract":[
      "Green hydrogen is thought to be a game changer for reaching sustainability\ntargets. However, the transition to a green hydrogen economy faces a critical\nchallenge known as the `chicken-and-egg dilemma', wherein establishing a\nhydrogen supply network relies on demand, while demand only grows with reliable\nsupply. In addition, as the hydrogen market is in the early stage, predicting\ndemand distributions is challenging due to lack of data availability. This\npaper addresses these complex issues through a risk-averse framework with the\nintroduction of a distributionally robust hydrogen network expansion planning\nproblem under decision-dependent demand ambiguity. The problem optimizes\nlocation and production capacity decisions of the suppliers considering the\nmoments of the stochastic hydrogen demand as a function of these investment\ndecisions. To obtain tractable representations of this problem, we derive two\ndifferent reformulations that consider continuous and discrete hydrogen demand\nsupport sets under different forms of decision dependencies. To efficiently\nsolve the reformulations, we develop a tailored algorithm based on the\ncolumn-and-constraint generation approach, and enhance the computational\nperformance through solving the master problems to a relative optimality gap,\ndecomposing the subproblems, and integrating pre-generated columns and\nconstraints. To validate the effectiveness of our approach, we investigate a\nreal case study leveraging data from the \"Hydrogen Energy Applications in\nValley Environments for Northern Netherlands (HEAVENN)\" project. The results\nreveal that considering the chicken-and-egg dilemma under uncertain hydrogen\nmarket conditions leads to earlier and more diverse investments, providing\ncritical insights for policymakers based on the degree of decision dependency."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-527",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18515",
    "b_title":[
      "Recovering a (1+1)-dimensional wave equation from a single white noise\n  boundary measurement"
    ],
    "b_abstract":[
      "We consider the following inverse problem: Suppose a $(1+1)$-dimensional wave\nequation on $\\mathbb R_+$ with zero initial conditions is excited with a\nNeumann boundary data modelled as a white noise process. Given also the\nDirichlet data at the same point, determine the unknown first order coefficient\nfunction of the system.\n  We first establish that direct problem is well-posed. The inverse problem is\nthen solved by showing that correlations of the boundary data determine the\nNeumann-to-Dirichlet operator in the sense of distributions, which is known to\nuniquely identify the coefficient. This approach has applications in acoustic\nmeasurements of internal cross-sections of fluid pipes such as pressurised\nwater supply pipes and vocal tract shape determination."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02530",
    "c_title":[
      "UDMC: Unified Decision-Making and Control Framework for Urban Autonomous\n  Driving with Motion Prediction of Traffic Participants"
    ],
    "c_abstract":[
      "Current autonomous driving systems often struggle to balance decision-making\nand motion control while ensuring safety and traffic rule compliance,\nespecially in complex urban environments. Existing methods may fall short due\nto separate handling of these functionalities, leading to inefficiencies and\nsafety compromises. To address these challenges, we introduce UDMC, an\ninterpretable and unified Level 4 autonomous driving framework. UDMC integrates\ndecision-making and motion control into a single optimal control problem (OCP),\nconsidering the dynamic interactions with surrounding vehicles, pedestrians,\nroad lanes, and traffic signals. By employing innovative potential functions to\nmodel traffic participants and regulations, and incorporating a specialized\nmotion prediction module, our framework enhances on-road safety and rule\nadherence. The integrated design allows for real-time execution of flexible\nmaneuvers suited to diverse driving scenarios. High-fidelity simulations\nconducted in CARLA exemplify the framework's computational efficiency,\nrobustness, and safety, resulting in superior driving performance when compared\nagainst various baseline models. Our open-source project is available at\nhttps:\/\/github.com\/henryhcliu\/udmc_carla.git."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-528",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04928",
    "b_title":[
      "AUTOFRAME -- A Software-driven Integration Framework for Automotive\n  Systems"
    ],
    "b_abstract":[
      "The evolution of automotive technologies towards more integrated and\nsophisticated systems requires a shift from traditional distributed\narchitectures to centralized vehicle architectures. This work presents a novel\nframework that addresses the increasing complexity of Software Defined Vehicles\n(SDV) through a centralized approach that optimizes software and hardware\nintegration. Our approach introduces a scalable, modular, and secure automotive\ndeployment framework that leverages a hardware abstraction layer and dynamic\nsoftware deployment capabilities to meet the growing demands of the industry.\nThe framework supports centralized computing of vehicle functions, making\nsoftware development more dynamic and easier to update and upgrade. We\ndemonstrate the capabilities of our framework by implementing it in a simulated\nenvironment where it effectively handles several automotive operations such as\nlane detection, motion planning, and vehicle control. Our results highlight the\nframework's potential to facilitate the development and maintenance of future\nvehicles, emphasizing its adaptability to different hardware configurations and\nits readiness for real-world applications. This work lays the foundation for\nfurther exploration of robust, scalable, and secure SDV systems, setting a new\nstandard for future automotive architectures."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09710",
    "c_title":[
      "Trotter error mitigation by error profiling with shallow quantum circuit"
    ],
    "c_abstract":[
      "Understanding the dynamics of quantum systems is crucial in many areas of\nphysics, but simulating many-body systems presents significant challenges due\nto the large Hilbert space to navigate and the exponential growth of\ncomputational overhead. Quantum computers offer a promising platform to\novercome these challenges, particularly for simulating the time evolution with\nHamiltonians. Trotterization is a widely used approach among available\nalgorithms in this regard, and well suited for near-term quantum devices.\nHowever, it introduces algorithmic Trotter errors due to the non-commutativity\nof Hamiltonian components. Several techniques such as multi-product formulas\nhave been developed to mitigate Trotter errors, but often require deep quantum\ncircuits, which can introduce additional physical errors. In this work, we\npropose a resource-efficient scheme to reduce the algorithmic Trotter error\nwith relatively shallow circuit depth. We develop a profiling method by\nintroducing an auxiliary parameter to estimate the error effects in expectation\nvalues, enabling significant error suppression with a fixed number of Trotter\nsteps. Our approach offers an efficient way of quantum simulation on near-term\nquantum processors with shallow circuits."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-529",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00670",
    "b_title":[
      "Transformer Based Self-Context Aware Prediction for Few-Shot Anomaly\n  Detection in Videos"
    ],
    "b_abstract":[
      "Anomaly detection in videos is a challenging task as anomalies in different\nvideos are of different kinds. Therefore, a promising way to approach video\nanomaly detection is by learning the non-anomalous nature of the video at hand.\nTo this end, we propose a one-class few-shot learning driven transformer based\napproach for anomaly detection in videos that is self-context aware. Features\nfrom the first few consecutive non-anomalous frames in a video are used to\ntrain the transformer in predicting the non-anomalous feature of the subsequent\nframe. This takes place under the attention of a self-context learned from the\ninput features themselves. After the learning, given a few previous frames, the\nvideo-specific transformer is used to infer if a frame is anomalous or not by\ncomparing the feature predicted by it with the actual. The effectiveness of the\nproposed method with respect to the state-of-the-art is demonstrated through\nqualitative and quantitative results on different standard datasets. We also\nstudy the positive effect of the self-context used in our approach."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16941",
    "c_title":[
      "Actions of nilpotent groups on nilpotent groups"
    ],
    "c_abstract":[
      "For finite nilpotent groups $J$ and $N$, suppose $J$ acts on $N$ via\nautomorphisms. We exhibit a decomposition of the first cohomology set in terms\nof the first cohomologies of the Sylow $p$-subgroups of $J$ that mirrors the\nprimary decomposition of $H^1(J,N)$ for abelian $N$. We then show that if $N\n\\rtimes J$ acts on some non-empty set $\\Omega$, where the action of $N$ is\ntransitive and for each prime $p$ a Sylow $p$-subgroup of $J$ fixes an element\nof $\\Omega$, then $J$ fixes an element of $\\Omega$."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-530",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02963",
    "b_title":[
      "A data-driven merit order: Learning a fundamental electricity price\n  model"
    ],
    "b_abstract":[
      "Power prices can be forecasted using data-driven models or fundamental\nmodels. Data-driven models learn from historical patterns, while fundamental\nmodels simulate electricity markets. Traditionally, fundamental models have\nbeen too computationally demanding to allow for intrinsic parameter estimation\nor frequent updates, which are essential for short-term forecasting. In this\npaper, we propose a novel data-driven fundamental model that combines the\nstrengths of both approaches. We estimate the parameters of a fully fundamental\nmerit order model using historical data, similar to how data-driven models\nwork. This removes the need for fixed technical parameters or expert\nassumptions, allowing most parameters to be calibrated directly to\nobservations. The model is efficient enough for quick parameter estimation and\nforecast generation. We apply it to forecast German day-ahead electricity\nprices and demonstrate that it outperforms both classical fundamental and\npurely data-driven models. The hybrid model effectively captures price\nvolatility and sequential price clusters, which are becoming increasingly\nimportant with the expansion of renewable energy sources. It also provides\nvaluable insights, such as fuel switches, marginal power plant contributions,\nestimated parameters, dispatched plants, and power generation."
    ],
    "b_categories":[
      [
        "econ.EM",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.13877",
    "c_title":[
      "Near-Optimal List-Recovery of Linear Code Families"
    ],
    "c_abstract":[
      "We prove several results on linear codes achieving list-recovery capacity. We\nshow that random linear codes achieve list-recovery capacity with constant\noutput list size (independent of the alphabet size and length). That is, over\nalphabets of size at least $\\ell^{\\Omega(1\/\\varepsilon)}$, random linear codes\nof rate $R$ are $(1-R-\\varepsilon, \\ell,\n(\\ell\/\\varepsilon)^{O(\\ell\/\\varepsilon)})$-list-recoverable for all $R\\in(0,1)$\nand $\\ell$. Together with a result of Levi, Mosheiff, and Shagrithaya, this\nimplies that randomly punctured Reed-Solomon codes also achieve list-recovery\ncapacity. We also prove that our output list size is near-optimal among all\nlinear codes: all $(1-R-\\varepsilon, \\ell, L)$-list-recoverable linear codes\nmust have $L\\ge \\ell^{\\Omega(R\/\\varepsilon)}$.\n  Our simple upper bound combines the Zyablov-Pinsker argument with recent\nbounds from Kopparty, Ron-Zewi, Saraf, Wootters, and Tamo on the maximum\nintersection of a \"list-recovery ball\" and a low-dimensional subspace with\nlarge distance. Our lower bound is inspired by a recent lower bound of Chen and\nZhang."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.CO",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-531",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02520",
    "b_title":[
      "Privacy by Design for Self-Sovereign Identity Systems: An in-depth\n  Component Analysis completed by a Design Assistance Dashboard"
    ],
    "b_abstract":[
      "The use of Self-Sovereign Identity (SSI) systems for digital identity\nmanagement is gaining traction and interest. Countries such as Bhutan have\nalready implemented an SSI infrastructure to manage the identity of their\ncitizens. The EU, thanks to the revised eIDAS regulation, is opening the door\nfor SSI vendors to develop SSI systems for the planned EU digital identity\nwallet. These developments, which fall within the sovereign domain, raise\nquestions about individual privacy.\n  The purpose of this article is to help SSI solution designers make informed\nchoices to ensure that the designed solution is privacy-friendly. The\nobservation is that the range of possible solutions is very broad, from DID and\nDID resolution methods to verifiable credential types, publicly available\ninformation (e.g. in a blockchain), type of infrastructure, etc. As a result,\nthe article proposes (1) to group the elementary building blocks of a SSI\nsystem into 5 structuring layers, (2) to analyze for each layer the privacy\nimplications of using the chosen building block, and (3) to provide a design\nassistance dashboard that gives the complete picture of the SSI, and shows the\ninterdependencies between architectural choices and technical building blocks,\nallowing designers to make informed choices and graphically achieve a SSI\nsolution that meets their need for privacy."
    ],
    "b_categories":[
      [
        "cs.CY",
        "cs.ET",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03463",
    "c_title":[
      "Cosmic Calipers: Precise and Accurate Neutron Star Radius Measurements\n  with Next-Generation Gravitational Wave Detectors"
    ],
    "c_abstract":[
      "Gravitational waves from merging binary neutron stars carry characteristic\ninformation about their astrophysical properties, including masses and tidal\ndeformabilities, that are needed to infer their radii. In this study, we use\nBayesian inference to quantify the precision with which radius can inferred\nwith upgrades in the current gravitational wave detectors and next-generation\nobservatories such as the Einstein Telescope and Cosmic Explorer. We assign\nevidences for a set of plausible equations of state, which are then used as\nweights to obtain radius posteriors. We find that prior choices and the\nloudness of observed signals limit the precision and accuracy of inferred radii\nby current detectors. In contrast, next-generation observatories can resolve\nthe radius precisely and accurately, across most of the mass range to within\n$\\lesssim 5\\%$ for both soft and stiff equations of state. We also explore how\nthe choice of the neutron star mass prior can influence the inferred masses and\npotentially affect radii measurements, finding that choosing an astrophysically\nmotivated prior does not notably impact an individual neutron star's radius\nmeasurements."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-532",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17842",
    "b_title":[
      "Task-Driven Semantic Quantization and Imitation Learning for\n  Goal-Oriented Communications"
    ],
    "b_abstract":[
      "Semantic communication marks a new paradigm shift from bit-wise data\ntransmission to semantic information delivery for the purpose of bandwidth\nreduction. To more effectively carry out specialized downstream tasks at the\nreceiver end, it is crucial to define the most critical semantic message in the\ndata based on the task or goal-oriented features. In this work, we propose a\nnovel goal-oriented communication (GO-COM) framework, namely Goal-Oriented\nSemantic Variational Autoencoder (GOS-VAE), by focusing on the extraction of\nthe semantics vital to the downstream tasks. Specifically, we adopt a Vector\nQuantized Variational Autoencoder (VQ-VAE) to compress media data at the\ntransmitter side. Instead of targeting the pixel-wise image data\nreconstruction, we measure the quality-of-service at the receiver end based on\na pre-defined task-incentivized model. Moreover, to capture the relevant\nsemantic features in the data reconstruction, imitation learning is adopted to\nmeasure the data regeneration quality in terms of goal-oriented semantics. Our\nexperimental results demonstrate the power of imitation learning in\ncharacterizing goal-oriented semantics and bandwidth efficiency of our proposed\nGOS-VAE."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00967",
    "c_title":[
      "On the Implementation of a Bayesian Optimization Framework for\n  Interconnected Systems"
    ],
    "c_abstract":[
      "Bayesian optimization (BO) is an effective paradigm for the optimization of\nexpensive-to-sample systems. Standard BO learns the performance of a system\n$f(x)$ by using a Gaussian Process (GP) model; this treats the system as a\nblack-box and limits its ability to exploit available structural knowledge\n(e.g., physics and sparse interconnections in a complex system). Grey-box\nmodeling, wherein the performance function is treated as a composition of known\nand unknown intermediate functions $f(x, y(x))$ (where $y(x)$ is a GP model)\noffers a solution to this limitation; however, generating an analytical\nprobability density for $f$ from the Gaussian density of $y(x)$ is often an\nintractable problem (e.g., when $f$ is nonlinear). Previous work has handled\nthis issue by using sampling techniques or by solving an auxiliary problem over\nan augmented space where the values of $y(x)$ are constrained by confidence\nintervals derived from the GP models; such solutions are computationally\nintensive. In this work, we provide a detailed implementation of a recently\nproposed grey-box BO paradigm, BOIS, that uses adaptive linearizations of $f$\nto obtain analytical expressions for the statistical moments of the composite\nfunction. We show that the BOIS approach enables the exploitation of structural\nknowledge, such as that arising in interconnected systems as well as systems\nthat embed multiple GP models and combinations of physics and GP models. We\nbenchmark the effectiveness of BOIS against standard BO and existing grey-box\nBO algorithms using a pair of case studies focused on chemical process\noptimization and design. Our results indicate that BOIS performs as well as or\nbetter than existing grey-box methods, while also being less computationally\nintensive."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-533",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14394",
    "b_title":[
      "Enhancing Portuguese Variety Identification with Cross-Domain Approaches"
    ],
    "b_abstract":[
      "Recent advances in natural language processing have raised expectations for\ngenerative models to produce coherent text across diverse language varieties.\nIn the particular case of the Portuguese language, the predominance of\nBrazilian Portuguese corpora online introduces linguistic biases in these\nmodels, limiting their applicability outside of Brazil. To address this gap and\npromote the creation of European Portuguese resources, we developed a\ncross-domain language variety identifier (LVI) to discriminate between European\nand Brazilian Portuguese. Motivated by the findings of our literature review,\nwe compiled the PtBrVarId corpus, a cross-domain LVI dataset, and study the\neffectiveness of transformer-based LVI classifiers for cross-domain scenarios.\nAlthough this research focuses on two Portuguese varieties, our contribution\ncan be extended to other varieties and languages. We open source the code,\ncorpus, and models to foster further research in this task."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00393",
    "c_title":[
      "The multi-index Monte Carlo method for semilinear stochastic partial\n  differential equations"
    ],
    "c_abstract":[
      "Stochastic partial differential equations (SPDEs) are often difficult to\nsolve numerically due to their low regularity and high dimensionality. These\nchallenges limit the practical use of computer-aided studies and pose\nsignificant barriers to statistical analysis of SPDEs. In this work, we\nintroduce a highly efficient multi-index Monte Carlo method (MIMC) designed to\napproximate statistics of mild solutions to semilinear parabolic SPDEs. Key to\nour approach is the proof of a multiplicative convergence property for coupled\nsolutions generated by an exponential integrator numerical solver, which we\nincorporate with MIMC. We further describe theoretically how the asymptotic\ncomputational cost of MIMC can be bounded in terms of the input accuracy\ntolerance, as the tolerance goes to zero. Notably, our methodology illustrates\nthat for an SPDE with low regularity, MIMC offers substantial performance\nimprovements over other viable methods. Numerical experiments comparing the\nperformance of MIMC with the multilevel Monte Carlo method on relevant test\nproblems validate our theoretical findings. These results also demonstrate that\nMIMC significantly outperforms state-of-the-art multilevel Monte Carlo, thereby\nunderscoring its potential as a robust and tractable tool for solving\nsemilinear parabolic SPDEs."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-534",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11495",
    "b_title":[
      "V-STaR: Benchmarking Video-LLMs on Video Spatio-Temporal Reasoning"
    ],
    "b_abstract":[
      "Human processes video reasoning in a sequential spatio-temporal reasoning\nlogic, we first identify the relevant frames (\"when\") and then analyse the\nspatial relationships (\"where\") between key objects, and finally leverage these\nrelationships to draw inferences (\"what\"). However, can Video Large Language\nModels (Video-LLMs) also \"reason through a sequential spatio-temporal logic\" in\nvideos? Existing Video-LLM benchmarks primarily focus on assessing object\npresence, neglecting relational reasoning. Consequently, it is difficult to\nmeasure whether a model truly comprehends object interactions (actions\/events)\nin videos or merely relies on pre-trained \"memory\" of co-occurrences as biases\nin generating answers. In this work, we introduce a Video Spatio-Temporal\nReasoning (V-STaR) benchmark to address these shortcomings. The key idea is to\ndecompose video understanding into a Reverse Spatio-Temporal Reasoning (RSTR)\ntask that simultaneously evaluates what objects are present, when events occur,\nand where they are located while capturing the underlying Chain-of-thought\n(CoT) logic. To support this evaluation, we construct a dataset to elicit the\nspatial-temporal reasoning process of Video-LLMs. It contains coarse-to-fine\nCoT questions generated by a semi-automated GPT-4-powered pipeline, embedding\nexplicit reasoning chains to mimic human cognition. Experiments from 14\nVideo-LLMs on our V-STaR reveal significant gaps between current Video-LLMs and\nthe needs for robust and consistent spatio-temporal reasoning."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16620",
    "c_title":[
      "Multiplicatively irreducibility of small perturbations of shifted $k$-th\n  powers"
    ],
    "c_abstract":[
      "Motivated by a conjecture of Erd\\H{o}s on the additively irreducibility of\nsmall perturbations of the set of squares, recently Hajdu and S\\'{a}rk\\\"{o}zy\nstudied a multiplicative analogue of the conjecture for shifted $k$-th powers.\nThey conjectured that for each $k\\geq 2$, if one changes $o(X^{1\/k})$ elements\nof $M_k'=\\{x^k+1: x \\in \\mathbb{N}\\}$ up to $X$, then the resulting set cannot\nbe written as a product set $AB$ nontrivially. In this paper, we confirm a more\ngeneral version of their conjecture for $k\\geq 3$."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-535",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16282",
    "b_title":[
      "Brain-Adapter: Enhancing Neurological Disorder Analysis with\n  Adapter-Tuning Multimodal Large Language Models"
    ],
    "b_abstract":[
      "Understanding brain disorders is crucial for accurate clinical diagnosis and\ntreatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a\npromising approach to interpreting medical images with the support of text\ndescriptions. However, previous research has primarily focused on 2D medical\nimages, leaving richer spatial information of 3D images under-explored, and\nsingle-modality-based methods are limited by overlooking the critical clinical\ninformation contained in other modalities. To address this issue, this paper\nproposes Brain-Adapter, a novel approach that incorporates an extra bottleneck\nlayer to learn new knowledge and instill it into the original pre-trained\nknowledge. The major idea is to incorporate a lightweight bottleneck layer to\ntrain fewer parameters while capturing essential information and utilize a\nContrastive Language-Image Pre-training (CLIP) strategy to align multimodal\ndata within a unified representation space. Extensive experiments demonstrated\nthe effectiveness of our approach in integrating multimodal data to\nsignificantly improve the diagnosis accuracy without high computational costs,\nhighlighting the potential to enhance real-world diagnostic workflows."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05871",
    "c_title":[
      "Symmetric Tensor Coupling in Holographic Mean-Field Theory: Deformed\n  Dirac Cones"
    ],
    "c_abstract":[
      "We extend the holographic mean-field theory to rank-two symmetric tensor\norder parameter field coupled with fermion. We classify the roles of symmetric\ntensor order according to the effect on the spectral density: cone-angle\nchange, squashing, and tilting of the spectral light cones. In case of the\nover-tilted light cone, an analytic continuation of the Green's function is\nnecessary to preserve the continuity of the spectrum inside the lightcone. Our\nresults provide agreements between the holographic spectra with those observed\nin real materials, such as type-II Dirac cones and strained graphene."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-536",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16959",
    "b_title":[
      "Observe Gamma-Rays and Neutrinos Associated with Ultra-High Energy\n  Cosmic Rays"
    ],
    "b_abstract":[
      "IceCube measures a diffuse neutrino flux comparable to the Waxman-Bahcall\nbound, which suggests the possibility that the ultra-high energy cosmic rays\n(UHECRs) have a common origin with diffuse high energy neutrinos. We propose\nhigh energy gamma-ray and\/or neutrino observations toward the arrival\ndirections of UHECRs to search for the sources and test this possibility. We\ncalculate the detection probability of gamma-ray\/neutrino sources, and find\nthat the average probability per UHECR of >10 EeV is $\\sim$10% if the\nsensitivity of the gamma-ray or neutrino telescope is $\\sim$10$^{-12}$ erg\ncm$^{-2}$s$^{-1}$ and the source number density is $\\sim$10$^{-5}$ Mpc$^{-3}$.\nFuture gamma-ray and neutrino observations toward UHECRs, e.g., by LHAASO-WCDA,\nCTA, IceCube\/Gen2, are encouraged to constrain the density of UHECR sources or\neven identify the sources of UHECRs."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10152",
    "c_title":[
      "Characterization of Logarithmic Fekete Critical Configurations of at\n  Most Six Points in All Dimensions"
    ],
    "c_abstract":[
      "We consider the logarithmic Fekete problem, which consists of placing a fixed\nnumber of points on the unit sphere in $\\mathbb{R}^d$, in such a way that the\nproduct of all pairs of mutual Euclidean distances is maximized or,\nequivalently, so that their logarithmic energy is minimized. Using tools from\nComputational Algebraic Geometry, we find and classify all critical\nconfigurations for this problem when considering at most six points in every\ndimension $d$. Our results discover some previously unknown optimal\nconfigurations and give the first reported case of a spurious local minimum for\nthe Fekete problem."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.AC",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-537",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14118",
    "b_title":[
      "Selecting Critical Scenarios of DER Adoption in Distribution Grids Using\n  Bayesian Optimization"
    ],
    "b_abstract":[
      "We develop a new methodology to select scenarios of DER adoption most\ncritical for distribution grids. Anticipating risks of future voltage and line\nflow violations due to additional PV adopters is central for utility investment\nplanning but continues to rely on deterministic or ad hoc scenario selection.\nWe propose a highly efficient search framework based on multi-objective\nBayesian Optimization. We treat underlying grid stress metrics as\ncomputationally expensive black-box functions, approximated via Gaussian\nProcess surrogates and design an acquisition function based on probability of\nscenarios being Pareto-critical across a collection of line- and bus-based\nviolation objectives. Our approach provides a statistical guarantee and offers\nan order of magnitude speed-up relative to a conservative exhaustive search.\nCase studies on realistic feeders with 200-400 buses demonstrate the\neffectiveness and accuracy of our approach."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11796",
    "c_title":[
      "Finite-time blowup of a Brownian particle in a repulsive potential"
    ],
    "c_abstract":[
      "We consider a Brownian particle performing an overdamped motion in a\npower-law repulsive potential. If the potential grows with the distance faster\nthan quadratically, the particle escapes to infinity in a finite time. We\ndetermine the average blowup time and study the probability distribution of the\nblowup time. In particular, we show that the long-time tail of this probability\ndistribution decays purely exponentially, while the short-time tail exhibits an\nessential singularity. These qualitative features turn out to be quite\nuniversal, as they occur for all rapidly growing power-law potentials in\narbitrary spatial dimensions. The quartic potential is especially tractable,\nand we analyze it in more detail."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "math-ph",
        "math.MP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-538",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02817",
    "b_title":[
      "A Stable Measure for Conditional Periodicity of Time Series using\n  Persistent Homology"
    ],
    "b_abstract":[
      "Given a pair of time series, we study how the periodicity of one influences\nthe periodicity of the other. There are several known methods to measure the\nsimilarity between a pair of time series, such as cross-correlation, coherence,\ncross-recurrence, and dynamic time warping. But we have yet to find any\nmeasures with theoretical stability results.\n  Persistence homology has been utilized to construct a scoring function with\ntheoretical guarantees of stability that quantifies the periodicity of a single\nunivariate time series f1, denoted score(f1). Building on this concept, we\npropose a conditional periodicity score that quantifies the periodicity of one\nunivariate time series f1 given another f2, denoted score(f1|f2), and derive\ntheoretical stability results for the same. With the use of dimension reduction\nin mind, we prove a new stability result for score(f1|f2) under principal\ncomponent analysis (PCA) when we use the projections of the time series\nembeddings onto their respective first K principal components. We show that the\nchange in our score is bounded by a function of the eigenvalues corresponding\nto the remaining (unused) N-K principal components and hence is small when the\nfirst K principal components capture most of the variation in the time series\nembeddings. Finally we derive a lower bound on the minimum embedding dimension\nto use in our pipeline which guarantees that any two such embeddings give\nscores that are within a given epsilon of each other.\n  We present a procedure for computing conditional periodicity scores and\nimplement it on several pairs of synthetic signals. We experimentally compare\nour similarity measure to the most-similar statistical measure of\ncross-recurrence, and show the increased accuracy and stability of our score\nwhen predicting and measuring whether or not the periodicities of two time\nseries are similar."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01881",
    "c_title":[
      "Mapping representations in Reinforcement Learning via Semantic Alignment\n  for Zero-Shot Stitching"
    ],
    "c_abstract":[
      "Deep Reinforcement Learning (RL) models often fail to generalize when even\nsmall changes occur in the environment's observations or task requirements.\nAddressing these shifts typically requires costly retraining, limiting the\nreusability of learned policies. In this paper, we build on recent work in\nsemantic alignment to propose a zero-shot method for mapping between latent\nspaces across different agents trained on different visual and task variations.\nSpecifically, we learn a transformation that maps embeddings from one agent's\nencoder to another agent's encoder without further fine-tuning. Our approach\nrelies on a small set of \"anchor\" observations that are semantically aligned,\nwhich we use to estimate an affine or orthogonal transform. Once the\ntransformation is found, an existing controller trained for one domain can\ninterpret embeddings from a different (existing) encoder in a zero-shot\nfashion, skipping additional trainings. We empirically demonstrate that our\nframework preserves high performance under visual and task domain shifts. We\nempirically demonstrate zero-shot stitching performance on the CarRacing\nenvironment with changing background and task. By allowing modular re-assembly\nof existing policies, it paves the way for more robust, compositional RL in\ndynamically changing environments."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-539",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02307",
    "b_title":[
      "UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training"
    ],
    "b_abstract":[
      "Despite decades of research on data collection and model architectures,\ncurrent gaze estimation models encounter significant challenges in generalizing\nacross diverse data domains. Recent advances in self-supervised pre-training\nhave shown remarkable performances in generalization across various vision\ntasks. However, their effectiveness in gaze estimation remains unexplored. We\npropose UniGaze, for the first time, leveraging large-scale in-the-wild facial\ndatasets for gaze estimation through self-supervised pre-training. Through\nsystematic investigation, we clarify critical factors that are essential for\neffective pretraining in gaze estimation. Our experiments reveal that\nself-supervised approaches designed for semantic tasks fail when applied to\ngaze estimation, while our carefully designed pre-training pipeline\nconsistently improves cross-domain performance. Through comprehensive\nexperiments of challenging cross-dataset evaluation and novel protocols\nincluding leave-one-dataset-out and joint-dataset settings, we demonstrate that\nUniGaze significantly improves generalization across multiple data domains\nwhile minimizing reliance on costly labeled data. source code and model are\navailable at https:\/\/github.com\/ut-vision\/UniGaze."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14789",
    "c_title":[
      "Analyses of anomalous lensing events detected from the UKIRT\n  microlensing survey"
    ],
    "c_abstract":[
      "The United Kingdom Infrared Telescope (UKIRT) microlensing survey was\nconducted over four years, from 2016 to 2019, with the goal of serving as a\nprecursor to future near-infrared microlensing surveys (Shvartzvald et al.\n2017). Focusing on stars in the Galactic center and utilizing near-infrared\npassbands, the survey identified approximately one thousand microlensing\nevents, 27 of which displayed anomalies in their light curves (Wen et al.\n2023). This paper presents an analysis of these anomalous events, aiming to\nuncover the underlying causes of the observed anomalies. The events were\nanalyzed under various configurations, considering the potential binarity of\nboth the lens and the source. For 11 events that were additionally observed by\nother optical microlensing surveys, including those conducted by the OGLE,\nKMTNet, and MOA collaborations, we incorporated their data into our analysis.\nAmong the reported anomalous events, we revealed the nature of 24 events except\nfor three events, in which one was likely to be a transient variable, and two\nwere were difficult to accurately characterize their nature due to the\nlimitations of the available data. We confirmed the binary lens nature of the\nanomalies in 22 events. Among these, we verified the earlier discovery that the\ncompanion in the binary lens system UKIRT11L is a planetary object. Accurately\ndescribing the anomaly in UKIRT21 required a model that accounted for the\nbinarity of both the lens and the source. For two events UKIRT01 and UKIRT17,\nthe anomalies could be interpreted using either a binary-source or a\nbinary-lens model."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-540",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17020",
    "b_title":[
      "Benign Overfitting with Quantum Kernels"
    ],
    "b_abstract":[
      "Quantum kernels quantify similarity between data points by measuring the\ninner product between quantum states, computed through quantum circuit\nmeasurements. By embedding data into quantum systems, quantum kernel feature\nmaps, that may be classically intractable to compute, could efficiently exploit\nhigh-dimensional Hilbert spaces to capture complex patterns. However, designing\neffective quantum feature maps remains a major challenge. Many quantum kernels,\nsuch as the fidelity kernel, suffer from exponential concentration, leading to\nnear-identity kernel matrices that fail to capture meaningful data correlations\nand lead to overfitting and poor generalization. In this paper, we propose a\nnovel strategy for constructing quantum kernels that achieve good\ngeneralization performance, drawing inspiration from benign overfitting in\nclassical machine learning. Our approach introduces the concept of local-global\nquantum kernels, which combine two complementary components: a local quantum\nkernel based on measurements of small subsystems and a global quantum kernel\nderived from full-system measurements. Through numerical experiments, we\ndemonstrate that local-global quantum kernels exhibit benign overfitting,\nsupporting the effectiveness of our approach in enhancing quantum kernel\nmethods."
    ],
    "b_categories":[
      [
        "cs.LG",
        "quant-ph",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16633",
    "c_title":[
      "Functional limit theorems for Gaussian-fed queueing network in light and\n  heavy traffic"
    ],
    "c_abstract":[
      "We consider a queueing network operating under a strictly upper-triangular\nrouting matrix with per column at most one non-negative entry. The root node is\nfed by a Gaussian process with stationary increments. Our aim is to\ncharacterize the distribution of the multivariate stationary workload process\nunder a specific scaling of the queue's service rates. In the main results of\nthis paper we identify, under mild conditions on the standard deviation\nfunction of the driving Gaussian process, in both light and heavy traffic\nparameterization, the limiting law of an appropriately scaled version (in both\ntime and space) of the joint stationary workload process. In particular, we\ndevelop conditions under which specific queueing processes of the network\neffectively decouple, i.e., become independent in the limiting regime."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-541",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02128",
    "b_title":[
      "Emission processes in a self-consistent field"
    ],
    "b_abstract":[
      "We present a microscopic description of cluster emission processes within the\nCluster--Hartree--Fock (CHF) self--consistent field (SCF) theory. The starting\npoint is a Woods--Saxon (WS) mean field (MF) with spin--orbit and Coulomb\nterms. Pairing is treated through standard Bardeen--Cooper--Schrieffer (BCS)\nquasiparticles. The residual two--body interaction is given by a\ndensity--dependent Wigner force having a Gaussian shape with a center of mass\n(com) correction located in a region of low nuclear density slightly beyond the\ngeometrical contact radius of a system comprised from a nucleus and a surface\ncluster. We show that such a description adequately reproduces the ground state\n(gs) shape of a spherical nucleus while the surface correction enhances the\nradial tail of single particle orbitals, thus allowing for an adequate\ndescription of the $\\alpha$-decay width for unstable systems."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.15849",
    "c_title":[
      "Gaussian Process-Based Prediction and Control of Hammerstein-Wiener\n  Systems"
    ],
    "c_abstract":[
      "This work investigates data-driven prediction and control of\nHammerstein-Wiener systems using physics-informed Gaussian process models.\nData-driven prediction algorithms have been developed for structured nonlinear\nsystems based on Willems' fundamental lemma. However, existing frameworks\ncannot treat output nonlinearities and require a dictionary of basis functions\nfor Hammerstein systems. In this work, an implicit predictor structure is\nconsidered, leveraging the multi-step-ahead ARX structure for the linear part\nof the model. This implicit function is learned by Gaussian process regression\nwith kernel functions designed from Gaussian process priors for the\nnonlinearities. The linear model parameters are estimated as hyperparameters by\nassuming a stable spline hyperprior. The implicit Gaussian process model\nprovides explicit output prediction by optimizing selected optimality criteria.\nThe model is also applied to receding horizon control with the expected control\ncost and chance constraint satisfaction guarantee. Numerical results\ndemonstrate that the proposed prediction and control algorithms are superior to\nblack-box Gaussian process models."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-542",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06664",
    "b_title":[
      "Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets"
    ],
    "b_abstract":[
      "High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19283",
    "c_title":[
      "Quasi-reversible parametric instability in presence of noise"
    ],
    "c_abstract":[
      "We present an experimental and theoretical study of the effect of\nspatio-temporal fluctuations in quasi-reversible systems displaying a spatial\nquintic supercritical bifurcation. The saturation mechanism is drastically\nchanged by the inclusion of fluctuations. Experimentally, we observe the\nmodification of the bifurcation diagram of parametrically amplified surface\nwaves as spatiotemporal fluctuations stemming from an underlying vortex flow\nare included. Theoretically, we characterize the noise-dependent effective\ndynamics in a model system, the parametrically driven nonlinear Schr\\\"odinger\nequation, subjected to noise which allows us to rationalize the effect of the\nunderlying vortex flow on the surface waves"
    ],
    "c_categories":[
      [
        "nlin.PS"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-543",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03171",
    "b_title":[
      "Hybrid Near-Field and Far-Field Localization with Multiple Holographic\n  MIMO Surfaces"
    ],
    "b_abstract":[
      "Localization methods based on holographic multiple input multiple output\n(HMIMO) have gained much attention for its potential to achieve high accuracy.\nBy deploying multiple HMIMOs, we can improve the link quality and system\ncoverage. As the scale of HMIMO increases to improve beam control capability,\nthe near-field (NF) region of each HMIMO expands. However, existing multiple\nHMIMO-enabled methods mainly focus on the far-field (FF) of each HMIMO, which\nleads to low localization accuracy when applied in the NF. In this paper, a\nhybrid NF and FF localization method aided by multiple RISs, a low cost\nimplementation of HMIMO, is proposed. In such a scenario, it is difficult to\nachieve user localization and RIS optimization since the equivalent NF of all\nRISs expands, which results in high complexity, and we need to handle the\ninterference caused by multiple RISs. To tackle this challenge, we propose a\ntwo-phase RIS-enabled localization method that first estimate the relative\nlocations of the user to each RIS and fuse the results to obtain the global\nestimation. In this way, the algorithm complexity is reduced. We formulate the\nRIS optimization problem to keep the RIS sidelobe as low as possible to\nminimize the interference. The effectiveness of the proposed method is verified\nthrough simulations."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07525",
    "c_title":[
      "Anomaly Equation of the Large U(1) Chiral Symmetry"
    ],
    "c_abstract":[
      "In this study, we first heuristically constitute the charges for the chiral\ntransformation associated with the large U(1) gauge symmetry. We name those as\nthe large chiral charges, and the chiral transformation those generate as the\nlarge chiral transformations. Then, showing that those can be obtained based on\nNoether's theorem, we once obtain the anomaly equation associated with those\nlarge chiral transformations. Then, for the one-loop diagrams of the fermionic\nfield coupling to the multiple classical gauge fields (those constitute the\neffective action of the model in this study with regard to the gauge field), we\nperform an axailization. Then, defining the BRS transformations for the large\nU(1) gauge symmetry (we name those as the large BRS transformation), we perform\nthose large BRS transformations to those axialized one-loop diagrams. Then,\nevaluating those, we show that the anomaly equations mentioned above can be\nderived. It is also shown that those anomaly equations can be derived in\nFujikawa method. The result in this study would be important as a development\nof the large U(1) gauge symmetry."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-544",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05859",
    "b_title":[
      "Large Model Empowered Streaming Speech Semantic Communications"
    ],
    "b_abstract":[
      "In this paper, we introduce a large model-empowered streaming semantic\ncommunication system for speech transmission across various languages, named\nLSSC-ST. Specifically, we devise an edge-device collaborative semantic\ncommunication architecture by offloading the intricate semantic extraction and\nchannel coding modules to edge servers, thereby reducing the computational\nburden on local devices. To support multilingual speech transmission,\npre-trained large speech models are utilized to learn unified semantic features\nfrom speech in different languages, breaking the constraint of a single input\nlanguage and enhancing the practicality of the LSSC-ST. Moreover, the input\nspeech is sequentially streamed into the developed system as short speech\nsegments, which enables low transmission latency without degrading the quality\nof the produced speech. A novel dynamic speech segmentation algorithm is\nproposed to further reduce the transmission latency by adaptively adjusting the\nduration of speech segments. According to simulation results, the LSSC-ST\nprovides more accurate speech transmission and achieves a streaming manner with\nlower latency compared to the existing non-streaming semantic communication\nsystems."
    ],
    "b_categories":[
      [
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15623",
    "c_title":[
      "Josephson effect in strongly disordered metallic wires"
    ],
    "c_abstract":[
      "We study localization effects in Josephson junctions with two superconductors\nconnected by a strongly disordered metallic wire of length $L$. The\nconventional description of the Josephson effect in such systems, based on the\nquasiclassical Usadel equation, neglects electron interference and is only\napplicable when $L$ is shorter than the localization length $\\xi$ in the wire.\nWe develop a more general theory for the Josephson effect using the non-linear\nsigma model that fully accounts for electron interference, and hence\nlocalization. We show that for $L \\gg \\xi$, three qualitatively different\nregimes of the Josephson current arise depending on the ratio of the\nsuperconducting order parameter $\\Delta$ and the mean level spacing in the\nlocalization volume $\\Delta_\\xi$. We derive the average supercurrent as a\nfunction of the phase difference for all three regimes. Quite unexpectedly, we\nobserve that the Ambegaokar-Baratoff relation between the average critical\ncurrent and the normal-state conductance still holds in the strongly localized\nstate when $\\Delta_\\xi \\gg \\Delta$ and $\\xi \\ll L \\ll (\\xi\/\\pi^2)\n\\ln^2(\\Delta_\\xi\/\\Delta)$."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "cond-mat.mes-hall",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-545",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04329",
    "b_title":[
      "An Efficient Adaptive Compression Method for Human Perception and\n  Machine Vision Tasks"
    ],
    "b_abstract":[
      "While most existing neural image compression (NIC) and neural video\ncompression (NVC) methodologies have achieved remarkable success, their\noptimization is primarily focused on human visual perception. However, with the\nrapid development of artificial intelligence, many images and videos will be\nused for various machine vision tasks. Consequently, such existing compression\nmethodologies cannot achieve competitive performance in machine vision. In this\nwork, we introduce an efficient adaptive compression (EAC) method tailored for\nboth human perception and multiple machine vision tasks. Our method involves\ntwo key modules: 1), an adaptive compression mechanism, that adaptively selects\nseveral subsets from latent features to balance the optimizations for multiple\nmachine vision tasks (e.g., segmentation, and detection) and human vision. 2),\na task-specific adapter, that uses the parameter-efficient delta-tuning\nstrategy to stimulate the comprehensive downstream analytical networks for\nspecific machine vision tasks. By using the above two modules, we can optimize\nthe bit-rate costs and improve machine vision performance. In general, our\nproposed EAC can seamlessly integrate with existing NIC (i.e., Ball\\'e2018, and\nCheng2020) and NVC (i.e., DVC, and FVC) methods. Extensive evaluation on\nvarious benchmark datasets (i.e., VOC2007, ILSVRC2012, VOC2012, COCO, UCF101,\nand DAVIS) shows that our method enhances performance for multiple machine\nvision tasks while maintaining the quality of human vision."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10719",
    "c_title":[
      "On approximate preservation of orthogonality and its application to\n  isometries"
    ],
    "c_abstract":[
      "Motivated by the famous Blanco-Koldobsky-Turn\\v{s}ek characterization of\nisometries, we study the \\textit{approximate preservation of Birkhoff-James\northogonality by a linear operator between Banach spaces}. In particular, we\ninvestigate various geometric and analytic properties related to such\npreservation on finite-dimensional polyhedral Banach spaces. As an application\nof the results obtained here, we present refinements of the\nBlanco-Koldobsky-Turn\\v{s}ek characterization of isometries on certain Banach\nspaces."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-546",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12166",
    "b_title":[
      "Beyond Window-Based Detection: A Graph-Centric Framework for Discrete\n  Log Anomaly Detection"
    ],
    "b_abstract":[
      "Detecting anomalies in discrete event logs is critical for ensuring system\nreliability, security, and efficiency. Traditional window-based methods for log\nanomaly detection often suffer from context bias and fuzzy localization, which\nhinder their ability to precisely and efficiently identify anomalies. To\naddress these challenges, we propose a graph-centric framework, TempoLog, which\nleverages multi-scale temporal graph networks for discrete log anomaly\ndetection. Unlike conventional methods, TempoLog constructs continuous-time\ndynamic graphs directly from event logs, eliminating the need for fixed-size\nwindow grouping. By representing log templates as nodes and their temporal\nrelationships as edges, the framework dynamically captures both local and\nglobal dependencies across multiple temporal scales. Additionally, a\nsemantic-aware model enhances detection by incorporating rich contextual\ninformation. Extensive experiments on public datasets demonstrate that our\nmethod achieves state-of-the-art performance in event-level anomaly detection,\nsignificantly outperforming existing approaches in both accuracy and\nefficiency."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17418",
    "c_title":[
      "Exhibition of piecewise syndetic and broken IP sets near idempotent"
    ],
    "c_abstract":[
      "Characterizations of ultrafilters belong to the smallest ideal of\nStone-\\v{C}ech compactification of a discrete semigroup are exhibited using\nsyndetic sets, strongly central sets and very strongly central sets\nrespectively. These lead to represent piecewise syndetic sets of a semigroup in\nterms of the sets that contain a broken $\\mathcal{A}$ set, where\n$\\mathcal{A}\\in\\{$ syndetic, quasi-central, central, strongly central, very\nstrongly central$\\}$. Also, a characterization of broken IP$^{n}$ sets using\nultrafilters, and the equivalence between the sets that contain a broken IP set\nand sets that contain a broken IP$^{n}$ are established, $n\\in \\mathbb{N}$.\nWithout assuming the countability of a semigroup, it is shown that piecewise\nsyndetic sets i.e., sets that contain a broken syndetic set (broken IP set)\nforce uniform recurrence (recurrence respectively) and vice versa. In addition,\nall the said results are established near idempotent of a semitopological\nsemigroup."
    ],
    "c_categories":[
      [
        "math.GN"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-547",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14385",
    "b_title":[
      "Study $\\Xi_c^+ \\to \\Lambda {\\bar{K}}^0 \\pi^+$ and search for the\n  low-lying baryons $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$"
    ],
    "b_abstract":[
      "Since searches for the low-lying excited baryons $\\Xi(1\/2^-)$ and\n$\\Sigma(1\/2^-)$ are crucial to deepening our understanding of the light baryon\nspectrum, we have investigated the Cabibbo-favored process $\\Xi_c^+ \\to \\Lambda\n{\\bar{K}}^0 \\pi^+$ by taking into account the $S$-wave pseudoscalar meson-octet\nbaryon interactions within the chiral unitary approach, which could dynamically\ngenerate the resonances $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$. The contributions\nfrom the excited kaons are double Cabibbo-suppressed, and the contribution from\nthe $\\Sigma(1385)$ is also suppressed due to Korner-Pati-Woo theory, thus those\nstates are expected to play negligible contributions in this process. We have\npredicted the $\\bar{K}^0 \\Lambda$ and $\\pi^+\\Lambda$ invariant mass\ndistributions, which have the clear signals of the $\\Xi(1\/2^-)$ and\n$\\Sigma(1\/2^-)$. Thus, the $\\Xi_c^+ \\to \\Lambda {\\bar{K}}^0 \\pi^+$ is an ideal\nprocess to search for the low-lying baryons $\\Xi(1\/2^-)$ and $\\Sigma(1\/2^-)$,\nand we make a call for a precise measurements of this process in experiments,\nsuch as Belle II, LHCb, and the proposed Super Tau-Charm Facility (STCF)."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08248",
    "c_title":[
      "Eliciting In-context Retrieval and Reasoning for Long-context Large\n  Language Models"
    ],
    "c_abstract":[
      "Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-548",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08686",
    "b_title":[
      "EEG Artifact Detection and Correction with Deep Autoencoders"
    ],
    "b_abstract":[
      "EEG signals convey important information about brain activity both in healthy\nand pathological conditions. However, they are inherently noisy, which poses\nsignificant challenges for accurate analysis and interpretation. Traditional\nEEG artifact removal methods, while effective, often require extensive expert\nintervention. This study presents LSTEEG, a novel LSTM-based autoencoder\ndesigned for the detection and correction of artifacts in EEG signals.\nLeveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear\ndependencies in sequential EEG data. LSTEEG demonstrates superior performance\nin both artifact detection and correction tasks compared to other\nstate-of-the-art convolutional autoencoders. Our methodology enhances the\ninterpretability and utility of the autoencoder's latent space, enabling\ndata-driven automated artefact removal in EEG its application in downstream\ntasks. This research advances the field of efficient and accurate multi-channel\nEEG preprocessing, and promotes the implementation and usage of automated EEG\nanalysis pipelines for brain health applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12623",
    "c_title":[
      "Betti number bounds for varieties and exponential sums"
    ],
    "c_abstract":[
      "Using basic properties of perverse sheaves, we give new upper bounds for\ncompactly supported Betti numbers for arbitrary affine varieties in\n$\\mathbb{A}^n$ defined by $r$ polynomial equations of degrees at most $d$. As\narithmetic applications, new total degree bounds are obtained for zeta\nfunctions of varieties and L-functions of exponential sums over finite fields,\nimproving the classical results of Bombieri, Katz, and Adolphson--Sperber. In\nthe complete intersection case, our total Betti number bound is asymptotically\noptimal as a function in $d$. In general, it remains an open problem to find an\nasymptotically optimal bound as a function in $d$."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-549",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00395",
    "b_title":[
      "Pressure Tuning of Layer-hybridized Excitons in Trilayer WSe2"
    ],
    "b_abstract":[
      "We demonstrate dynamic pressure tuning (0-6.6 GPa) of layer-hybridized\nexcitons in AB-stacked trilayer WSe$_2$ via diamond-anvil-cell-integrated\nreflectance spectroscopy. Pressure-controlled interlayer coupling manifests in\nenhanced energy-level anti-crossings and oscillator strength redistribution,\nwith Stark shift analysis revealing a characteristic dipole moment reduction of\n11%. Notably, the hybridization strength between the intra- and interlayer\nexcitons triples from $\\sim$10 meV to above $\\sim$30 meV, exhibiting a\nnear-linear scaling of 3.5$\\pm$0.2 meV\/GPa. Spectral density simulations\nresolve four distinct components, i.e., intralayer ground\/excited and\ninterlayer ground\/excited excitons, with their relative weights transitioning\nfrom one component dominant to strongly hybridized at higher pressures. Our\nfindings highlight the potential for controlling excitonic properties and\nengineering novel optoelectronic devices through interlayer compression."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10020",
    "c_title":[
      "Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions"
    ],
    "c_abstract":[
      "The 2D cartoon style is a prominent art form in digital character creation,\nparticularly popular among younger audiences. While advancements in digital\nhuman technology have spurred extensive research into photorealistic digital\nhumans and 3D characters, interactive 2D cartoon characters have received\ncomparatively less attention. Unlike 3D counterparts, which require\nsophisticated construction and resource-intensive rendering, Live2D, a\nwidely-used format for 2D cartoon characters, offers a more efficient\nalternative, which allows to animate 2D characters in a manner that simulates\n3D movement without the necessity of building a complete 3D model. Furthermore,\nLive2D employs lightweight HTML5 (H5) rendering, improving both accessibility\nand efficiency. In this technical report, we introduce Textoon, an innovative\nmethod for generating diverse 2D cartoon characters in the Live2D format based\non text descriptions. The Textoon leverages cutting-edge language and vision\nmodels to comprehend textual intentions and generate 2D appearance, capable of\ncreating a wide variety of stunning and interactive 2D characters within one\nminute. The project homepage is https:\/\/human3daigc.github.io\/Textoon_webpage\/."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-550",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05583",
    "b_title":[
      "Efficient Sampling Allocation Strategies for General Graph-Filter-Based\n  Signal Recovery"
    ],
    "b_abstract":[
      "Sensor placement plays a crucial role in graph signal recovery in\nunderdetermined systems. In this paper, we present the graph-filtered\nregularized maximum likelihood (GFR-ML) estimator of graph signals, which\nintegrates general graph filtering with regularization to enhance signal\nrecovery performance under a limited number of sensors. Then, we investigate\ntask-based sampling allocation aimed at minimizing the mean squared error (MSE)\nof the GFR-ML estimator by wisely choosing sensor placement. Since this MSE\ndepends on the unknown graph signals to be estimated, we propose four cost\nfunctions for the optimization of the sampling allocation: the biased\nCram$\\acute{\\text{e}}$r-Rao bound (bCRB), the worst-case MSE (WC-MSE), the\nBayesian MSE (BMSE), and the worst-case BMSE (WC-BMSE), where the last two\nassume a Gaussian prior. We investigate the properties of these cost functions\nand develop two algorithms for their practical implementation: 1) the\nstraightforward greedy algorithm; and 2) the alternating projection gradient\ndescent (PGD) algorithm that reduces the computational complexity. Simulation\nresults on synthetic and real-world datasets of the IEEE 118-bus power system\nand the Minnesota road network demonstrate that the proposed sampling\nallocation methods reduce the MSE by up to $50\\%$ compared to the common\nsampling methods A-design, E-design, and LR-design in the tested scenarios.\nThus, the proposed methods improve the estimation performance and reduce the\nrequired number of measurements in graph signal processing (GSP)-based signal\nrecovery in the case of underdetermined systems."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11672",
    "c_title":[
      "Exact Upper and Lower Bounds for the Output Distribution of Neural\n  Networks with Random Inputs"
    ],
    "c_abstract":[
      "We derive exact upper and lower bounds for the cumulative distribution\nfunction (cdf) of the output of a neural network over its entire support\nsubject to noisy (stochastic) inputs. The upper and lower bounds converge to\nthe true cdf over its domain as the resolution increases. Our method applies to\nany feedforward NN using continuous monotonic piecewise differentiable\nactivation functions (e.g., ReLU, tanh and softmax) and convolutional NNs,\nwhich were beyond the scope of competing approaches. The novelty and an\ninstrumental tool of our approach is to bound general NNs with ReLU NNs. The\nReLU NN based bounds are then used to derive upper and lower bounds of the cdf\nof the NN output. Experiments demonstrate that our method delivers guaranteed\nbounds of the predictive output distribution over its support, thus providing\nexact error guarantees, in contrast to competing approaches."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-551",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13388",
    "b_title":[
      "A mathematical model for a universal digital quantum computer with an\n  application to the Grover-Rudolph algorithm"
    ],
    "b_abstract":[
      "In this work, we develop a novel mathematical framework for universal digital\nquantum computation using algebraic probability theory. We rigorously define\nquantum circuits as finite sequences of elementary quantum gates and establish\ntheir role in implementing unitary transformations. A key result demonstrates\nthat every unitary matrix in \\(\\mathrm{U}(N)\\) can be expressed as a product of\nelementary quantum gates, leading to the concept of a universal dictionary for\nquantum computation. We apply this framework to the construction of quantum\ncircuits that encode probability distributions, focusing on the Grover-Rudolph\nalgorithm. By leveraging controlled quantum gates and rotation matrices, we\ndesign a quantum circuit that approximates a given probability density\nfunction. Numerical simulations, conducted using Qiskit, confirm the\ntheoretical predictions and validate the effectiveness of our approach. These\nresults provide a rigorous foundation for quantum circuit synthesis within an\nalgebraic probability framework and offer new insights into the encoding of\nprobability distributions in quantum algorithms. Potential applications include\nquantum machine learning, circuit optimization, and experimental\nimplementations on real quantum hardware."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15247",
    "c_title":[
      "Classification of Electron and Muon Neutrino Events for the ESS$\\nu$SB\n  Near Water Cherenkov Detector using Graph Neural Networks"
    ],
    "c_abstract":[
      "In the effort to obtain a precise measurement of leptonic CP-violation with\nthe ESS$\\nu$SB experiment, accurate and fast reconstruction of detector events\nplays a pivotal role. In this work, we examine the possibility of replacing the\ncurrently proposed likelihood-based reconstruction method with an approach\nbased on Graph Neural Networks (GNNs). As the likelihood-based reconstruction\nmethod is reasonably accurate but computationally expensive, one of the\nbenefits of a Machine Learning (ML) based method is enabling fast event\nreconstruction in the detector development phase, allowing for easier\ninvestigation of the effects of changes to the detector design. Focusing on\nclassification of flavour and interaction type in muon and electron events and\nmuon- and electron neutrino interaction events, we demonstrate that the GNN\nreconstructs events with greater accuracy than the likelihood method for events\nwith greater complexity, and with increased speed for all events. Additionally,\nwe investigate the key factors impacting reconstruction performance, and\ndemonstrate how separation of events by pion production using another GNN\nclassifier can benefit flavour classification."
    ],
    "c_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-552",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09455",
    "b_title":[
      "Recoil nuclear size corrections in hydrogenic systems"
    ],
    "b_abstract":[
      "Formulas for the combined nuclear-recoil and finite-nuclear-size effects of\norder $(Z\\,\\alpha)^5$ and $(Z\\,\\alpha)^6$ are derived without any expansion in\nthe nuclear charge radius $r_C$, making them applicable to both electronic and\nmuonic atoms. The obtained results are particularly relevant for high-precision\ndeterminations of root-mean-square charge radii from muonic atom spectroscopy.\nWe demonstrate that calculations of the atomic isotope shift based on the\nwidely used Breit approximation give rise to an unphysical nuclear-size\ncontribution that is linear in the nuclear charge radius $r_C$ at order\n$(Z\\,\\alpha)^5$. This spurious term vanishes in a full QED treatment, leaving\nthe correct contribution quadratic in $r_C$. For electronic atoms, this\nquadratic term is significantly smaller than the spurious linear contribution."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06725",
    "c_title":[
      "Pull-Based Query Scheduling for Goal-Oriented Semantic Communication"
    ],
    "c_abstract":[
      "This paper addresses query scheduling for goal-oriented semantic\ncommunication in pull-based status update systems. We consider a system where\nmultiple sensing agents (SAs) observe a source characterized by various\nattributes and provide updates to multiple actuation agents (AAs), which act\nupon the received information to fulfill their heterogeneous goals at the\nendpoint. A hub serves as an intermediary, querying the SAs for updates on\nobserved attributes and maintaining a knowledge base, which is then broadcast\nto the AAs. The AAs leverage the knowledge to perform their actions\neffectively. To quantify the semantic value of updates, we introduce a grade of\neffectiveness (GoE) metric. Furthermore, we integrate cumulative perspective\ntheory (CPT) into the long-term effectiveness analysis to account for risk\nawareness and loss aversion in the system. Leveraging this framework, we\ncompute effect-aware scheduling policies aimed at maximizing the expected\ndiscounted sum of CPT-based total GoE provided by the transmitted updates while\ncomplying with a given query cost constraint. To achieve this, we propose a\nmodel-based solution based on dynamic programming and model-free solutions\nemploying state-of-the-art deep reinforcement learning (DRL) algorithms. Our\nfindings demonstrate that effect-aware scheduling significantly enhances the\neffectiveness of communicated updates compared to benchmark scheduling methods,\nparticularly in settings with stringent cost constraints where optimal query\nscheduling is vital for system performance and overall effectiveness."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.IT",
        "cs.NI",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-553",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04060",
    "b_title":[
      "SFADNet: Spatio-temporal Fused Graph based on Attention Decoupling\n  Network for Traffic Prediction"
    ],
    "b_abstract":[
      "In recent years, traffic flow prediction has played a crucial role in the\nmanagement of intelligent transportation systems. However, traditional\nprediction methods are often limited by static spatial modeling, making it\ndifficult to accurately capture the dynamic and complex relationships between\ntime and space, thereby affecting prediction accuracy. This paper proposes an\ninnovative traffic flow prediction network, SFADNet, which categorizes traffic\nflow into multiple traffic patterns based on temporal and spatial feature\nmatrices. For each pattern, we construct an independent adaptive\nspatio-temporal fusion graph based on a cross-attention mechanism, employing\nresidual graph convolution modules and time series modules to better capture\ndynamic spatio-temporal relationships under different fine-grained traffic\npatterns. Extensive experimental results demonstrate that SFADNet outperforms\ncurrent state-of-the-art baselines across four large-scale datasets."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07375",
    "c_title":[
      "Ultrafast dynamics of moments in bulk ferromagnets"
    ],
    "c_abstract":[
      "A robust and efficient model for investigating the ultrafast dynamics of\nmagnetic materials excited by laser pulses has been created, integrating\ndynamic Landau-Lifshitz-Bloch equations with a quantum thermostat and a\ntwo-temperature model. The model has been successfully applied to three\narchetypal materials in the literature: nickel, cobalt, and iron. Additionally,\nanalysis of the ultrafast dynamic susceptibility tensor indicates that\noff-diagonal components display specific features depending on whether a\ncontinuous external magnetic field is present."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-554",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13214",
    "b_title":[
      "A General Adaptive Dual-level Weighting Mechanism for Remote Sensing\n  Pansharpening"
    ],
    "b_abstract":[
      "Currently, deep learning-based methods for remote sensing pansharpening have\nadvanced rapidly. However, many existing methods struggle to fully leverage\nfeature heterogeneity and redundancy, thereby limiting their effectiveness. We\nuse the covariance matrix to model the feature heterogeneity and redundancy and\npropose Correlation-Aware Covariance Weighting (CACW) to adjust them. CACW\ncaptures these correlations through the covariance matrix, which is then\nprocessed by a nonlinear function to generate weights for adjustment. Building\nupon CACW, we introduce a general adaptive dual-level weighting mechanism\n(ADWM) to address these challenges from two key perspectives, enhancing a wide\nrange of existing deep-learning methods. First, Intra-Feature Weighting (IFW)\nevaluates correlations among channels within each feature to reduce redundancy\nand enhance unique information. Second, Cross-Feature Weighting (CFW) adjusts\ncontributions across layers based on inter-layer correlations, refining the\nfinal output. Extensive experiments demonstrate the superior performance of\nADWM compared to recent state-of-the-art (SOTA) methods. Furthermore, we\nvalidate the effectiveness of our approach through generality experiments,\nredundancy visualization, comparison experiments, key variables and complexity\nanalysis, and ablation studies. Our code is available at\nhttps:\/\/github.com\/Jie-1203\/ADWM."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14843",
    "c_title":[
      "Slave-spin approach to the Anderson-Josephson quantum dot"
    ],
    "c_abstract":[
      "We study a strongly interacting quantum dot connected to two superconducting\nleads using a slave-spin representation of the dot. At the mean-field level the\nproblem maps into a resonant level model with superconducting leads, coupled to\nan auxiliary spin-1\/2 variable accounting for the parity of the dot. We obtain\nthe mean-field phase diagram, showing a transition between a Kondo (singlet)\nand a local moment (doublet) regime, corresponding to the $0-\\pi$ transition of\nthe junction. The mean-field theory qualitatively captures the Kondo singlet\nphase and its competition with superconductivity for weak values of the BCS\ngap, including the non-trivial dependence of the Andreev bound states on the\ninteraction, but fails in the doublet regime where it predicts a dot decoupled\nfrom the bath. Using diagrammatic techniques and a random phase approximation,\nwe include fluctuations on top of the mean-field theory to describe\nfinite-frequency dynamics of the effective spin variable. This leads to the\nformation of high-energy Hubbard bands in the spectral function and a coherent\nKondo peak with a BCS gap at low energies. Finally, we compute the Josephson\ncurrent and the induced superconducting correlations on the dot."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-555",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00069",
    "b_title":[
      "Societal Alignment Frameworks Can Improve LLM Alignment"
    ],
    "b_abstract":[
      "Recent progress in large language models (LLMs) has focused on producing\nresponses that meet human expectations and align with shared values - a process\ncoined alignment. However, aligning LLMs remains challenging due to the\ninherent disconnect between the complexity of human values and the narrow\nnature of the technological approaches designed to address them. Current\nalignment methods often lead to misspecified objectives, reflecting the broader\nissue of incomplete contracts, the impracticality of specifying a contract\nbetween a model developer, and the model that accounts for every scenario in\nLLM alignment. In this paper, we argue that improving LLM alignment requires\nincorporating insights from societal alignment frameworks, including social,\neconomic, and contractual alignment, and discuss potential solutions drawn from\nthese domains. Given the role of uncertainty within societal alignment\nframeworks, we then investigate how it manifests in LLM alignment. We end our\ndiscussion by offering an alternative view on LLM alignment, framing the\nunderspecified nature of its objectives as an opportunity rather than perfect\ntheir specification. Beyond technical improvements in LLM alignment, we discuss\nthe need for participatory alignment interface designs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13265",
    "c_title":[
      "Continuity of the Distribution Function of the argmax of a Gaussian\n  Process"
    ],
    "c_abstract":[
      "An increasingly important class of estimators has members whose asymptotic\ndistribution is non-Gaussian, yet characterizable as the argmax of a Gaussian\nprocess. This paper presents high-level sufficient conditions under which such\nasymptotic distributions admit a continuous distribution function. The\nplausibility of the sufficient conditions is demonstrated by verifying them in\nthree prominent examples, namely maximum score estimation, empirical risk\nminimization, and threshold regression estimation. In turn, the continuity\nresult buttresses several recently proposed inference procedures whose validity\nseems to require a result of the kind established herein. A notable feature of\nthe high-level assumptions is that one of them is designed to enable us to\nemploy the celebrated Cameron-Martin theorem. In a leading special case, the\nassumption in question is demonstrably weak and appears to be close to minimal."
    ],
    "c_categories":[
      [
        "econ.EM",
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-556",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08654",
    "b_title":[
      "Statistical tests based on Renyi entropy estimation"
    ],
    "b_abstract":[
      "Entropy and its various generalizations are important in many fields,\nincluding mathematical statistics, communication theory, physics and computer\nscience, for characterizing the amount of information associated with a\nprobability distribution. In this paper we propose goodness-of-fit statistics\nfor the multivariate Student and multivariate Pearson type II distributions,\nbased on the maximum entropy principle and a class of estimators for Renyi\nentropy based on nearest neighbour distances. We prove the L2-consistency of\nthese statistics using results on the subadditivity of Euclidean functionals on\nnearest neighbour graphs, and investigate their rate of convergence and\nasymptotic distribution using Monte Carlo methods."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15738",
    "c_title":[
      "Towards Interoperable Data Spaces: Comparative Analysis of Data Space\n  Implementations between Japan and Europe"
    ],
    "c_abstract":[
      "The rapid evolution of data spaces is transforming the landscape of secure\nand interoperable data sharing across industries and geographies. In Europe,\nthe concept of data spaces, supported by initiatives such as the European Data\nStrategy, emphasises the importance of trust, sovereignty, and\ninteroperability. Meanwhile, Japan has been developing its approach to data\nsharing, in line with global trends but also to address unique domestic\nchallenges. Despite these parallel advances, achieving interoperability between\nEuropean and Japanese data spaces remains a critical challenge due to\ndifferences in governance, technology standards, and authentication frameworks.\nThis paper undertakes a comparative analysis of DATA-EX and Catena-X to explore\nthe challenges and opportunities for achieving interoperability between\nJapanese and European data spaces. By examining common data exchange processes,\nkey objects such as participants, datasets, and data catalogs, and specific\nevaluation criteria, the study identifies gaps and proposes actionable\nsolutions. Through this analysis, the paper aims to contribute to the ongoing\ndiscourse on global data interoperability. It proposes an interoperable\narchitecture that bridges regional differences while addressing common\nchallenges. It also identifies challenges that should be addressed to achieve\ninteroperability."
    ],
    "c_categories":[
      [
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-557",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06011",
    "b_title":[
      "Uncertainty Quantification and Causal Considerations for Off-Policy\n  Decision Making"
    ],
    "b_abstract":[
      "Off-policy evaluation (OPE) is a critical challenge in robust decision-making\nthat seeks to assess the performance of a new policy using data collected under\na different policy. However, the existing OPE methodologies suffer from several\nlimitations arising from statistical uncertainty as well as causal\nconsiderations. In this thesis, we address these limitations by presenting\nthree different works. Firstly, we consider the problem of high variance in the\nimportance-sampling-based OPE estimators. We introduce the Marginal Ratio (MR)\nestimator, a novel OPE method that reduces variance by focusing on the marginal\ndistribution of outcomes rather than direct policy shifts, improving robustness\nin contextual bandits. Next, we propose Conformal Off-Policy Prediction (COPP),\na principled approach for uncertainty quantification in OPE that provides\nfinite-sample predictive intervals, ensuring robust decision-making in\nrisk-sensitive applications. Finally, we address causal unidentifiability in\noff-policy decision-making by developing novel bounds for sequential decision\nsettings, which remain valid under arbitrary unmeasured confounding. We apply\nthese bounds to assess the reliability of digital twin models, introducing a\nfalsification framework to identify scenarios where model predictions diverge\nfrom real-world behaviour. Our contributions provide new insights into robust\ndecision-making under uncertainty and establish principled methods for\nevaluating policies in both static and dynamic settings."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.14528",
    "c_title":[
      "Longitudinal Impact of Tobacco Use and Social Determinants on\n  Respiratory Health Disparities Among Louisiana Medicaid Enrollees"
    ],
    "c_abstract":[
      "Tobacco use remains a leading preventable contributor to serious health\nconditions in the United States, notably chronic obstructive pulmonary disease\n(COPD) and severe COVID-19 complications. Within Louisiana's Medicaid\npopulation, tobacco use prevalence is particularly high compared to privately\ninsured groups, yet its full impact on long-term outcomes is not fully\nunderstood. This study aimed to investigate how tobacco use, in conjunction\nwith demographic and clinical risk factors, influences the incidence of COPD\nand COVID-19 among Medicaid enrollees over time. We analyzed Louisiana\nDepartment of Health data from January 2020 to February 2023. Chi-square tests\nwere conducted to provide descriptive statistics, and multivariate logistic\nregression models were applied across three discrete waves to assess both\ncross-sectional and longitudinal associations between risk factors and disease\noutcomes. Enrollees without baseline diagnoses of COPD or COVID-19 were\nfollowed to determine new-onset cases in subsequent waves. Adjusted odds ratios\n(AOR) were calculated after controlling for socio-demographic variables,\ncomorbidities, and healthcare utilization patterns. Tobacco use emerged as a\nsignificant independent predictor of both COPD (Adjusted Odd Ratio= 1.12) and\nCOVID-19 (Adjusted Odd Ratio = 1.66). Additional risk factors -- such as older\nage, gender, region, and pre-existing health conditions -- also showed\nsignificant associations with higher incidence rates of COPD and COVID-19. By\nlinking tobacco use, demographic disparities, and comorbidities to an increased\nrisk of COPD and COVID-19, this study underscores the urgent need for targeted\ntobacco cessation efforts and prevention strategies within this underserved\npopulation."
    ],
    "c_categories":[
      [
        "q-bio.QM",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-558",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09671",
    "b_title":[
      "Undulatory underwater swimming: Linking vortex dynamics, thrust, and\n  wake structure with a biorobotic fish"
    ],
    "b_abstract":[
      "Flapping-based propulsive systems rely on fluid-structure interactions to\nproduce thrust. At intermediate and high Reynolds numbers, vortex formation and\norganization in the wake of such systems are crucial for the generation of a\npropulsive force. In this work, we experimentally investigate the wake produced\nby a tethered robotic fish immersed in a water tunnel. By systematically\nvarying the amplitude and frequency of the fish tail as well as the free-stream\nspeed, we are able to observe and characterize different vortex streets as a\nfunction of the Strouhal number. The produced wakes are three-dimensional and\nexhibit a classical V-shape, mainly with two oblique trains of vortex rings\nconvecting outward. Using two-dimensional Particle Image Velocimetry (PIV) in\nthe mid-span plane behind the fish and through extensive data processing of the\nvelocity and vorticity fields, we demonstrate the strong couplings at place\nbetween vortex dynamics, thrust production and wake structure. We first measure\nthe evolution of the vortex velocity with the Strouhal number, and model it\nusing a momentum balance equation directly related to thrust production. We\nthen focus on the wake structure, such as wake angle as well as vortex ring\norientation, diameter and vorticity. The wake structure is modelled in a simple\ngeometrical framework where the vortex ring velocity is composed of the\nfree-stream speed and the ring self-advecting speed. This framework is tested\nand validated by our experimental measurements as well as literature data\ncollapsing on master curves, highlighting a universal behavior dominated by the\nStrouhal number. This allows us to establish a comprehensive understanding of\nhow the wake structure varies with this number and, thus, thrust production."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11704",
    "c_title":[
      "Motivic counting of rational curves with tangency conditions via\n  universal torsors"
    ],
    "c_abstract":[
      "Using the formalism of Cox rings and universal torsors, we prove a\ndecomposition of the Grothendieck motive of the moduli space of morphisms from\nan arbitrary smooth projective curve to a Mori Dream Space (MDS).\n  For the simplest cases of MDS, that of toric varieties, we use this\ndecomposition to prove an instance of the motivic Batyrev--Manin--Peyre\nprinciple for curves satisfying tangency conditions with respect to the\nboundary divisors, often called Campana curves."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-559",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10778",
    "b_title":[
      "Supervised Large Neighbourhood Search for MIPs"
    ],
    "b_abstract":[
      "Large Neighbourhood Search (LNS) is a powerful heuristic framework for\nsolving Mixed-Integer Programming (MIP) problems. However, designing effective\nvariable selection strategies in LNS remains challenging, especially for\ndiverse sets of problems. In this paper, we propose an approach that integrates\nMachine Learning (ML) within the destroy operator of LNS for MIPs with a focus\non minimal offline training. We implement a modular LNS matheuristic as a test\nbench to compare different LNS heuristics, including our ML-enhanced LNS.\nExperimental results on the MIPLIB 2017 dataset demonstrate that the\nmatheuristic can significantly improve the performance of state-of-the-art\nsolvers like Gurobi and SCIP. We conduct analyses on noisy oracles to explore\nthe impact of prediction accuracy on solution quality. Additionally, we develop\ntechniques to enhance the ML model through loss adjustments and sampling\nroutines. Our findings suggest that while random LNS remains competitive, our\nSupervised LNS (SLNS) outperforms other baselines and helps set the foundation\nfor future research on ML for LNS methods that are both efficient and general."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18028",
    "c_title":[
      "KNN and K-means in Gini Prametric Spaces"
    ],
    "c_abstract":[
      "This paper introduces innovative enhancements to the K-means and K-nearest\nneighbors (KNN) algorithms based on the concept of Gini prametric spaces.\nUnlike traditional distance metrics, Gini-based measures incorporate both\nvalue-based and rank-based information, improving robustness to noise and\noutliers. The main contributions of this work include: proposing a Gini-based\nmeasure that captures both rank information and value distances; presenting a\nGini K-means algorithm that is proven to converge and demonstrates resilience\nto noisy data; and introducing a Gini KNN method that performs competitively\nwith state-of-the-art approaches such as Hassanat's distance in noisy\nenvironments. Experimental evaluations on 14 datasets from the UCI repository\ndemonstrate the superior performance and efficiency of Gini-based algorithms in\nclustering and classification tasks. This work opens new avenues for leveraging\nrank-based measures in machine learning and statistical analysis."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-560",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02487",
    "b_title":[
      "ACE++: Instruction-Based Image Creation and Editing via Context-Aware\n  Content Filling"
    ],
    "b_abstract":[
      "We report ACE++, an instruction-based diffusion framework that tackles\nvarious image generation and editing tasks. Inspired by the input format for\nthe inpainting task proposed by FLUX.1-Fill-dev, we improve the Long-context\nCondition Unit (LCU) introduced in ACE and extend this input paradigm to any\nediting and generation tasks. To take full advantage of image generative\npriors, we develop a two-stage training scheme to minimize the efforts of\nfinetuning powerful text-to-image diffusion models like FLUX.1-dev. In the\nfirst stage, we pre-train the model using task data with the 0-ref tasks from\nthe text-to-image model. There are many models in the community based on the\npost-training of text-to-image foundational models that meet this training\nparadigm of the first stage. For example, FLUX.1-Fill-dev deals primarily with\npainting tasks and can be used as an initialization to accelerate the training\nprocess. In the second stage, we finetune the above model to support the\ngeneral instructions using all tasks defined in ACE. To promote the widespread\napplication of ACE++ in different scenarios, we provide a comprehensive set of\nmodels that cover both full finetuning and lightweight finetuning, while\nconsidering general applicability and applicability in vertical scenarios. The\nqualitative analysis showcases the superiority of ACE++ in terms of generating\nimage quality and prompt following ability. Code and models will be available\non the project page: https:\/\/ali-vilab. github.io\/ACE_plus_page\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16008",
    "c_title":[
      "Gaussian credible intervals in Bayesian nonparametric estimation of the\n  unseen"
    ],
    "c_abstract":[
      "The unseen-species problem assumes $n\\geq1$ samples from a population of\nindividuals belonging to different species, possibly infinite, and calls for\nestimating the number $K_{n,m}$ of hitherto unseen species that would be\nobserved if $m\\geq1$ new samples were collected from the same population. This\nis a long-standing problem in statistics, which has gained renewed relevance in\nbiological and physical sciences, particularly in settings with large values of\n$n$ and $m$. In this paper, we adopt a Bayesian nonparametric approach to the\nunseen-species problem under the Pitman-Yor prior, and propose a novel\nmethodology to derive large $m$ asymptotic credible intervals for $K_{n,m}$,\nfor any $n\\geq1$. By leveraging a Gaussian central limit theorem for the\nposterior distribution of $K_{n,m}$, our method improves upon competitors in\ntwo key aspects: firstly, it enables the full parameterization of the\nPitman-Yor prior, including the Dirichlet prior; secondly, it avoids the need\nof Monte Carlo sampling, enhancing computational efficiency. We validate the\nproposed method on synthetic and real data, demonstrating that it improves the\nempirical performance of competitors by significantly narrowing the gap between\nasymptotic and exact credible intervals for any $m\\geq1$."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ME",
        "stat.ML",
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-561",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04086",
    "b_title":[
      "On gcd-graphs over finite rings"
    ],
    "b_abstract":[
      "Gcd-graphs represent an interesting and historically important class of\nintegral graphs. Since the pioneering work of Klotz and Sander, numerous\nincarnations of these graphs have been explored in the literature. In this\narticle, we define and establish some foundational properties of gcd-graphs\ndefined over a general finite commutative ring. In particular, we investigate\nthe connectivity and diameter of these graphs. Additionally, when the ring is a\nfinite symmetric $\\mathbb{Z}\/n$-algebra, we give an explicit description of\ntheir spectrum using the theory of Ramanujan sums that gives a unified\ntreatment of various results in the literature."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.12911",
    "c_title":[
      "Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL\n  Generation"
    ],
    "c_abstract":[
      "Generating SQLs from user queries is a long-standing challenge, where the\naccuracy of initial schema linking significantly impacts subsequent SQL\ngeneration performance. However, current schema linking models still struggle\nwith missing relevant schema elements or an excess of redundant ones. A crucial\nreason for this is that commonly used metrics, recall and precision, fail to\ncapture relevant element missing and thus cannot reflect actual schema linking\nperformance. Motivated by this, we propose an enhanced schema linking metric by\nintroducing a restricted missing indicator. Accordingly, we introduce Knapsack\noptimization-based Schema Linking Agent (KaSLA), a plug-in schema linking agent\ndesigned to prevent the missing of relevant schema elements while minimizing\nthe inclusion of redundant ones. KaSLA employs a hierarchical linking strategy\nthat first identifies the optimal table linking and subsequently links columns\nwithin the selected table to reduce linking candidate space. In each linking\nprocess, it utilize a knapsack optimization approach to link potentially\nrelevant elements while accounting for a limited tolerance of potential\nredundant ones.With this optimization, KaSLA-1.6B achieves superior schema\nlinking results compared to large-scale LLMs, including deepseek-v3 with\nstate-of-the-art (SOTA) schema linking method. Extensive experiments on Spider\nand BIRD benchmarks verify that KaSLA can significantly improve the SQL\ngeneration performance of SOTA text-to-SQL models by substituting their schema\nlinking processes."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-562",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15192",
    "b_title":[
      "A polynomial-time algorithm for the automatic Baire property"
    ],
    "b_abstract":[
      "A subset of a topological space possesses the Baire property if it can be\n  covered by an open set up to a meagre set. For the Cantor space of infinite\n  words Finkel introduced the automatic Baire category where both sets, the\n  open and the meagre, can be chosen to be definable by finite automata. Here\n  we show that, given a Muller automaton defining the original set, resulting\n  open and meagre sets can be constructed in polynomial time.\n  Since the constructed sets are of simple topological structure, it is\n  possible to construct not only Muller automata defining them but also the\n  simpler B\\\"uchi automata. To this end we give, for a restricted class of\n  Muller automata, a conversion to equivalent B\\\"uchi automata of at most\n  quadratic size."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15767",
    "c_title":[
      "Formal Verification of Markov Processes with Learned Parameters"
    ],
    "c_abstract":[
      "We introduce the problem of formally verifying properties of Markov processes\nwhere the parameters are the output of machine learning models. Our formulation\nis general and solves a wide range of problems, including verifying properties\nof probabilistic programs that use machine learning, and subgroup analysis in\nhealthcare modeling. We show that for a broad class of machine learning models,\nincluding linear models, tree-based models, and neural networks, verifying\nproperties of Markov chains like reachability, hitting time, and total reward\ncan be formulated as a bilinear program. We develop a decomposition and bound\npropagation scheme for solving the bilinear program and show through\ncomputational experiments that our method solves the problem to global\noptimality up to 100x faster than state-of-the-art solvers. We also release\n$\\texttt{markovml}$, an open-source tool for building Markov processes,\nintegrating pretrained machine learning models, and verifying their properties,\navailable at https:\/\/github.com\/mmaaz-git\/markovml."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-563",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16101",
    "b_title":[
      "Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the\n  Robustness of RAG Against Misleading Retrievals"
    ],
    "b_abstract":[
      "Retrieval-augmented generation (RAG) has shown impressive capabilities in\nmitigating hallucinations in large language models (LLMs). However, LLMs\nstruggle to handle misleading retrievals and often fail to maintain their own\nreasoning when exposed to conflicting or selectively-framed evidence, making\nthem vulnerable to real-world misinformation. In such real-world retrieval\nscenarios, misleading and conflicting information is rampant, particularly in\nthe political domain, where evidence is often selectively framed, incomplete,\nor polarized. However, existing RAG benchmarks largely assume a clean retrieval\nsetting, where models succeed by accurately retrieving and generating answers\nfrom gold-standard documents. This assumption fails to align with real-world\nconditions, leading to an overestimation of RAG system performance. To bridge\nthis gap, we introduce RAGuard, a fact-checking dataset designed to evaluate\nthe robustness of RAG systems against misleading retrievals. Unlike prior\nbenchmarks that rely on synthetic noise, our dataset constructs its retrieval\ncorpus from Reddit discussions, capturing naturally occurring misinformation.\nIt categorizes retrieved evidence into three types: supporting, misleading, and\nirrelevant, providing a realistic and challenging testbed for assessing how\nwell RAG systems navigate different retrieval information. Our benchmark\nexperiments reveal that when exposed to misleading retrievals, all tested\nLLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no\nretrieval at all), highlighting their susceptibility to noisy environments. To\nthe best of our knowledge, RAGuard is the first benchmark to systematically\nassess RAG robustness against misleading evidence. We expect this benchmark\nwill drive future research toward improving RAG systems beyond idealized\ndatasets, making them more reliable for real-world applications."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00771",
    "c_title":[
      "Role of long-range interaction in critical quantum metrology"
    ],
    "c_abstract":[
      "Long-range interacting quantum systems are useful for improving the\nperformance of various applications of quantum technologies. In this work, we\ncarry out a detailed analysis of how the long-range interaction affects the\nmeasurement precision in critical quantum metrology. By employing the\nparadigmatic model of a Kiteav chain with power-law decaying interaction, we\nfocus on the impacts of long-range interaction on the critical sensing for the\nscenarios with and without uncertainty in system parameters.We show that the\nlong-range interaction can be used as a valuable resource for enhancing the\nsensitivity of critical parameter estimation in both scenarios. Our findings\nnot only provide more insights into the features of the long-range interacting\nsystems, but also verify the usefulness of long-range interacting systems in\nquantum metrology."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-564",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13688",
    "b_title":[
      "Non-Linear Function Computation Broadcast"
    ],
    "b_abstract":[
      "This work addresses the $K$-user computation broadcast problem consisting of\na master node, that holds all datasets and users for a general class of\nfunction demands, including linear and non-linear functions, over finite\nfields. The master node sends a broadcast message to enable each of $K$\ndistributed users to compute its demanded function in an asymptotically\nlossless manner with user's side information. We derive bounds on the optimal\n$K$-user computation broadcast rate that allows the users to compute their\ndemanded functions by capturing the structures of the computations and\navailable side information. Our achievability scheme involves the design of a\nnovel graph-based coding model to build a broadcast message to meet each user's\ndemand, by leveraging the structural dependencies among the datasets, the user\ndemands, and the side information of each user, drawing on K{\\\"o}rner's\ncharacteristic graph framework. The converse uses the structures of the demands\nand the side information available at $K$ users to yield a tight lower bound on\nthe broadcast rate. With the help of examples, we demonstrate our scheme\nachieves a better communication rate than the existing state of the art."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01878",
    "c_title":[
      "District Vitality Index Using Machine Learning Methods for Urban\n  Planners"
    ],
    "c_abstract":[
      "City leaders face critical decisions regarding budget allocation and\ninvestment priorities. How can they identify which city districts require\nrevitalization? To address this challenge, a Current Vitality Index and a\nLong-Term Vitality Index are proposed. These indexes are based on a carefully\ncurated set of indicators. Missing data is handled using K-Nearest Neighbors\nimputation, while Random Forest is employed to identify the most reliable and\nsignificant features. Additionally, k-means clustering is utilized to generate\nmeaningful data groupings for enhanced monitoring of Long-Term Vitality.\nCurrent vitality is visualized through an interactive map, while Long-Term\nVitality is tracked over 15 years with predictions made using Multilayer\nPerceptron or Linear Regression. The results, approved by urban planners, are\nalready promising and helpful, with the potential for further improvement as\nmore data becomes available. This paper proposes leveraging machine learning\nmethods to optimize urban planning and enhance citizens' quality of life."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-565",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04565",
    "b_title":[
      "Private Federated Learning In Real World Application -- A Case Study"
    ],
    "b_abstract":[
      "This paper presents an implementation of machine learning model training\nusing private federated learning (PFL) on edge devices. We introduce a novel\nframework that uses PFL to address the challenge of training a model using\nusers' private data. The framework ensures that user data remain on individual\ndevices, with only essential model updates transmitted to a central server for\naggregation with privacy guarantees. We detail the architecture of our app\nselection model, which incorporates a neural network with attention mechanisms\nand ambiguity handling through uncertainty management. Experiments conducted\nthrough off-line simulations and on device training demonstrate the feasibility\nof our approach in real-world scenarios. Our results show the potential of PFL\nto improve the accuracy of an app selection model by adapting to changes in\nuser behavior over time, while adhering to privacy standards. The insights\ngained from this study are important for industries looking to implement PFL,\noffering a robust strategy for training a predictive model directly on edge\ndevices while ensuring user data privacy."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14419",
    "c_title":[
      "Non-Invertible $SO(2)$ Symmetry of 4d Maxwell from Continuous Gaugings"
    ],
    "c_abstract":[
      "We describe the self-duality symmetries for 4d Maxwell theory at any value of\nthe coupling $\\tau$ via topological manipulations that include gauging\ncontinuous symmetries with flat connections. Moreover, we demonstrate that the\n$SL(2,\\mathbb{Z})$ duality of Maxwell can be realized by trivial gauging\noperations. Using a non-compact symmetry topological field theory (symTFT) to\nencode continuous global symmetries of the boundary theory, we reproduce the\nsymTFT for Maxwell and find within this framework condensation defects that\nimplement the non-invertible $SO(2)$ self-duality symmetry. These defects are\nsystematically constructed by higher gauging subsets of the bulk\n$\\mathbb{R}\\times \\mathbb{R}$ symmetry with appropriate discrete torsion."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-566",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10699",
    "b_title":[
      "Exploring Synaptic Resonance in Large Language Models: A Novel Approach\n  to Contextual Memory Integration"
    ],
    "b_abstract":[
      "Contextual memory integration remains a high challenge in the development of\nlanguage models, particularly in tasks that require maintaining coherence over\nextended sequences. Traditional approaches, such as self-attention mechanisms\nand memory-augmented architectures, often prioritize short-term dependencies,\nleading to fragmentation and inconsistency in long-range contextual\nunderstanding. Inspired by principles of synaptic plasticity observed in\nbiological neural systems, a novel mechanism, Synaptic Resonance, is introduced\nto dynamically reinforce relevant memory pathways during training and\ninference. Unlike static memory representations, this mechanism continuously\nadjusts synaptic weight matrices based on contextual relevance, allowing for\nimproved information retention without excessive computational overhead.\nEvaluations conducted on an open-source language model demonstrate reductions\nin perplexity, enhancements in contextual coherence, and increased robustness\nagainst input noise, highlighting the effectiveness of reinforcement-driven\nmemory modulation. Comparative analysis against baseline models further reveals\nthat the proposed approach achieves higher memory retention efficiency while\nmaintaining computational feasibility. The architectural modifications\nintegrate seamlessly into existing transformer-based frameworks, ensuring\nstable convergence and efficient inference without sacrificing scalability.\nApplications benefiting from improved long-term contextual consistency, such as\ndialogue systems and document summarization, stand to gain from this approach.\nEmpirical findings suggest that dynamically reinforced memory pathways offer a\npromising alternative to conventional memory mechanisms, addressing\nlongstanding limitations in extended sequence modeling."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03099",
    "c_title":[
      "Twisting in h-BN bilayers and their angle-dependent properties"
    ],
    "c_abstract":[
      "In this paper, we systematically investigate the structural and electronic\nproperties of twisted h-BN bilayers to understand the role of the twisting\nangle. Using first-principles methods with relaxation taken into account, we\nsimulate h-BN bilayers with commensurate supercells with the smallest angle\nbeing $2.88^{\\circ}$ until $60^{\\circ}$. We find that the interlayer separation\nis not constant throughout each bilayer because of the various stacking\npatterns of AA, AA', AB, AB', and A'B throughout the layers, which also play a\nsignificant role in their unique charge redistribution. The calculations for\nthe 110 generated structures show the existence of flat bands in several\ntwisted h-BN bilayers, as well as the emergence of different trends in their\nproperties as a function of the twist angle. These results are useful for\nestablishing a systematic base line of registry-dependent relations for the\ndevelopment of more advanced computational methods to access incommensurate\nh-BN bilayers."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-567",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01003",
    "b_title":[
      "EasySplat: View-Adaptive Learning makes 3D Gaussian Splatting Easy"
    ],
    "b_abstract":[
      "3D Gaussian Splatting (3DGS) techniques have achieved satisfactory 3D scene\nrepresentation. Despite their impressive performance, they confront challenges\ndue to the limitation of structure-from-motion (SfM) methods on acquiring\naccurate scene initialization, or the inefficiency of densification strategy.\nIn this paper, we introduce a novel framework EasySplat to achieve high-quality\n3DGS modeling. Instead of using SfM for scene initialization, we employ a novel\nmethod to release the power of large-scale pointmap approaches. Specifically,\nwe propose an efficient grouping strategy based on view similarity, and use\nrobust pointmap priors to obtain high-quality point clouds and camera poses for\n3D scene initialization. After obtaining a reliable scene structure, we propose\na novel densification approach that adaptively splits Gaussian primitives based\non the average shape of neighboring Gaussian ellipsoids, utilizing KNN scheme.\nIn this way, the proposed method tackles the limitation on initialization and\noptimization, leading to an efficient and accurate 3DGS modeling. Extensive\nexperiments demonstrate that EasySplat outperforms the current state-of-the-art\n(SOTA) in handling novel view synthesis."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05956",
    "c_title":[
      "Self-consistent full MHD coupling of JOREK and STARWALL for advanced\n  plasma free boundary simulation"
    ],
    "c_abstract":[
      "An adequate modelling of the electromagnetic interaction of the plasma with\nthe surrounding conductors is paramount for the correct reproduction of 3D\nplasma dynamics. Simulations of the latter provide in turn useful predictions\nregarding the plasma evolution, the related MHD modes leading to disruptions\nand the electromagnetic forces acting on the vacuum vessel's components when\nsaid disruptions occur. The latest modelling efforts with the 3D FEM non-linear\nJOREK code have been directed towards the eddy current coupling of a reduced\nmagnetohydrodynamic (MHD) plasma model with thin and volumetric wall codes\n(STARWALL and CARIDDI). In this contribution, we present an eddy current\ncoupling between the full MHD model of JOREK and the STARWALL code; this new\ncoupling scheme describes the full three-dimensional interactions of the plasma\nwith the vacuum region and external conductors, modeled by natural boundary\nconditions linking the magnetic vector potential $\\mathbf{A}$ to the magnetic\nfield $\\mathbf{B}$. The consistency of the new coupling scheme is validated via\nbenchmarks for axisymmetric Vertical Displacement Events and multi-harmonics\nsimulations of MHD modes."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-568",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08481",
    "b_title":[
      "Operational solutions for the generalized Fokker-Planck and generalized\n  diffusion-wave equations"
    ],
    "b_abstract":[
      "The evolution operator method is used to solve the generalized Fokker-Planck\nequations and the generalized diffusion-wave equations in the (1+1) dimensional\nspace in which $x\\in\\mathbb{R}$ and $t\\in\\mathbb{R}_+$. These equations contain\neither the first- or the second-time derivatives smeared by memory functions,\neach of which forms an integral kernel (denoted by $f(\\xi, t)$,\n$\\xi\\in\\mathbb{R}_+$) of suitable evolution operators. If memory functions in\nthe Laplace space are Stieltjes functions, then $f(\\xi, t)$ satisfy\nnormalization, non-negativity, and infinite divisibility to be considered a\nprobability density function. The evolution operators also contain\nexponential-like operators whose action on initial condition $p_0(x) > 0$ leads\nto the parent process distribution functions. This makes the results fully\nanalogous to those obtained within the standard subordination approach. The\nabove conclusion is satisfied by the solution of the generalized Fokker-Planck\nequation. In the case of the generalized diffusion-wave equation, to get this\nproperty, we should employ a special class, namely \"diffusion-like\" initial\nconditions. The key models of the operator method involve power-law memory\nfunctions. It leads to the characterization of $f(\\xi, t)$ by applying\none-sided stable L\\'{e}vy distributions. The article also examines the\nproperties of evolution operators in terms of evolution and self-reproduction."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16338",
    "c_title":[
      "Unboundedness of shapes of unit lattices in totally real cubic fields"
    ],
    "c_abstract":[
      "The question of the distribution of shapes of unit lattices in number fields,\npioneered by Margulis and Gromov, has lately attracted considerable interest,\nnot least because of the lack of available results. Here we prove that the set\nof shapes of orders of totally real cubic fields is unbounded in the modular\nsurface."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-569",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19317",
    "b_title":[
      "LLM-based Affective Text Generation Quality Based on Different\n  Quantization Values"
    ],
    "b_abstract":[
      "Large language models exhibit a remarkable capacity in language generation\nand comprehension. These advances enable AI systems to produce more human-like\nand emotionally engaging text. However, these models rely on a large number of\nparameters, requiring significant computational resources for training and\ninference. In some scenarios, accessing these resources can be challenging\n(e.g., budget or hardware limitations). Techniques like reducing precision bits\ncan make models more memory-efficient, reducing the computational resources\nneeded, at the cost of reduced accuracy. This paper addresses the trade-off\nbetween different quantization values, GPU RAM utilization, and text quality in\naffective text generation (e.g., \"I really enjoy running in the snow-covered\nforest\"). To evaluate, we use an emotion classifier and ten seed prompts to\ngenerate affective text. We test three setups of precision bits (8, 16, and 32)\nacross five open-weight language models from two different families. Our\nfindings demonstrate that bit reductions lead to memory savings, achieving a\nreduction of 76%. However, this optimization comes with a trade-off, leading to\na decrease of up to 10 pp in F1 score for larger models and an increase of 10\npp for smaller models, along with roughly double the inference time. In terms\nof text quality, larger models at lower quantization levels generally\noutperform smaller, higher-precision models -- while requiring similar memory."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10947",
    "c_title":[
      "The Relationship between No-Regret Learning and Online Conformal\n  Prediction"
    ],
    "c_abstract":[
      "Existing algorithms for online conformal prediction -- guaranteeing marginal\ncoverage in adversarial settings -- are variants of online gradient descent\n(OGD), but their analyses of worst-case coverage do not follow from the regret\nguarantee of OGD. What is the relationship between no-regret learning and\nonline conformal prediction? We observe that although standard regret\nguarantees imply marginal coverage in i.i.d. settings, this connection fails as\nsoon as we either move to adversarial environments or ask for group conditional\ncoverage. On the other hand, we show a tight connection between threshold\ncalibrated coverage and swap-regret in adversarial settings, which extends to\ngroup-conditional (multi-valid) coverage. We also show that algorithms in the\nfollow the perturbed leader family of no regret learning algorithms (which\nincludes online gradient descent) can be used to give group-conditional\ncoverage guarantees in adversarial settings for arbitrary grouping functions.\nVia this connection we analyze and conduct experiments using a multi-group\ngeneralization of the ACI algorithm of Gibbs & Candes [2021]\n(arXiv:2106.00170)."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-570",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15795",
    "b_title":[
      "Can Multimodal Large Language Models be Guided to Improve Industrial\n  Anomaly Detection?"
    ],
    "b_abstract":[
      "In industrial settings, the accurate detection of anomalies is essential for\nmaintaining product quality and ensuring operational safety. Traditional\nindustrial anomaly detection (IAD) models often struggle with flexibility and\nadaptability, especially in dynamic production environments where new defect\ntypes and operational changes frequently arise. Recent advancements in\nMultimodal Large Language Models (MLLMs) hold promise for overcoming these\nlimitations by combining visual and textual information processing\ncapabilities. MLLMs excel in general visual understanding due to their training\non large, diverse datasets, but they lack domain-specific knowledge, such as\nindustry-specific defect tolerance levels, which limits their effectiveness in\nIAD tasks. To address these challenges, we propose Echo, a novel multi-expert\nframework designed to enhance MLLM performance for IAD. Echo integrates four\nexpert modules: Reference Extractor which provides a contextual baseline by\nretrieving similar normal images, Knowledge Guide which supplies\ndomain-specific insights, Reasoning Expert which enables structured, stepwise\nreasoning for complex queries, and Decision Maker which synthesizes information\nfrom all modules to deliver precise, context-aware responses. Evaluated on the\nMMAD benchmark, Echo demonstrates significant improvements in adaptability,\nprecision, and robustness, moving closer to meeting the demands of real-world\nindustrial anomaly detection."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15603",
    "c_title":[
      "Quantum entropy as a harbinger of factorizability"
    ],
    "c_abstract":[
      "Deeply inelastic scattering (DIS) is a powerful probe for investigating the\nQCD structure of hadronic matter and testing the standard model (SM). DIS can\nbe described through QCD factorization theorems which separate contributions to\nthe scattering interaction arising from disparate scales - e.g., with\nnonperturbative matrix elements associated with long distances and a\nperturbative hard scattering kernel applying to short-distance parton-level\ninteractions. The fundamental underpinnings of factorization may be recast in\nthe quantum-theoretic terms of entanglement, (de)coherence, and system\nlocalization in a fashion which sheds complementary light on the dynamics at\nwork in DIS from QCD bound states. In this Letter, we propose and\nquantitatively test such a quantum-information theoretic approach for\ndissecting factorization in DIS and its domain of validity; we employ metrics\nassociated with quantum entanglement such as a differential quantum entropy and\nassociated KL divergences in numerical tests. We deploy these methods on an\narchetypal quark-spectator model of the proton, for which we monitor quantum\ndecoherence in DIS as underlying model parameters are varied. On this basis, we\ndemonstrate quantitatively how factorization-breaking effects may be imprinted\non quantum entropies in a kinematic regime where leading-twist factorization\nincreasingly receives large corrections from finite-$Q^2$ effects; our findings\nsuggest potential applications of quantum simulation to QCD systems and their\ninteractions."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-571",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07779",
    "b_title":[
      "The route to turbulence in magnetohydrodynamic square duct flow"
    ],
    "b_abstract":[
      "The transition route from laminar to turbulent flow in a magnetohydrodynamic\n(MHD) duct with a square cross-section is investigated in the limit of low\nmagnetic Reynolds number. In the presence of a transverse magnetic field,\nHartmann and Shercliff layers are present on the walls orthogonal and parallel\nto the field direction, respectively. We assume reflection symmetries in both\ntransverse directions, and investigate the competition between transition\nmechanisms specific to each boundary layer using direct numerical simulations.\nIndependently of which wall turbulence eventually occupies, transition relies\nexclusively on a tripping of the Shercliff layer by perturbations, while the\nHartmann layer plays a passive role. This is explained, using a dynamical\nsystems interpretation, by the spatial localization of the edge states in the\nShercliff layer at the expense of the Hartmann layer. The link between these\nnon-linear coherent structures and the linear optimal modes known from\nnon-modal stability and energy stability theory is pointed out."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00953",
    "c_title":[
      "Nonadiabatic braiding of Majorana modes"
    ],
    "c_abstract":[
      "The realization and manipulation of Majorana zero modes have drawn\nsignificant attention for their crucial role in enabling topological quantum\ncomputation. Conventional approaches to the braiding of Majorana zero modes\nrely on adiabatic processes. In this work, using a composite 2-Kitaev-chain\nsystem accommodating Majorana zero modes as a working example, we propose a\nnonadiabatic and non-Abelian geometry phase-based protocol to execute\noperations on these Majorana zero modes. This is possible by locally coupling\nthe edge sites of both quantum chains with an embedded lattice defect,\nsuccessfully simulating the braiding operation of two Majorana modes in a\nhighly nonadiabatic fashion. To further enhance the robustness against control\nimperfections, we apply a multiple-pulse composite strategy to our quantum\nchain setting for second-order protection of the braiding operations. Our\nproposal can also support the fast and robust realization of the {\\pi}\/8 gate,\nan essential ingredient for universal quantum computation. This work hence\noffers a potential pathway towards the nonadiabatic and fault-tolerant control\nof Majorana zero modes."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-572",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12502",
    "b_title":[
      "Enhanced Approximation Algorithms for the Capacitated Location Routing\n  Problem"
    ],
    "b_abstract":[
      "The Capacitated Location Routing Problem is an important planning and routing\nproblem in logistics, which generalizes the capacitated vehicle routing problem\nand the uncapacitated facility location problem. In this problem, we are given\na set of depots and a set of customers where each depot has an opening cost and\neach customer has a demand. The goal is to open some depots and route\ncapacitated vehicles from the opened depots to satisfy all customers' demand,\nwhile minimizing the total cost. In this paper, we propose a\n$4.169$-approximation algorithm for this problem, improving the best-known\n$4.38$-approximation ratio. Moreover, if the demand of each customer is allowed\nto be delivered by multiple tours, we propose a more refined\n$4.091$-approximation algorithm. Experimental study on benchmark instances\nshows that the quality of our computed solutions is better than that of the\nprevious algorithm and is also much closer to optimality than the provable\napproximation factor."
    ],
    "b_categories":[
      [
        "cs.DS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12109",
    "c_title":[
      "Lower bounds for levels of complexes by resolution dimensions"
    ],
    "c_abstract":[
      "Let $\\mathcal{A}$ be an abelian category. Denote by\n$\\mathrm{D}^{b}(\\mathcal{A})$ the bounded derived category of $\\mathcal{A}$. In\nthis paper, we investigate the lower bounds for the levels of objects in\n$\\mathrm{D}^{b}(\\mathcal{A})$ with respect to a (co)resolving subcategory\nsatisfying a certain condition. As an application, we not only recover the\nresults of Altmann--Grifo--Monta\\~{n}o--Sanders--Vu, and Awadalla--Marley but\nalso extend them to establish lower bounds for levels with respect to some\nother subcategories in an abelian category."
    ],
    "c_categories":[
      [
        "math.AC",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-573",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06130",
    "b_title":[
      "Self-Correcting Decoding with Generative Feedback for Mitigating\n  Hallucinations in Large Vision-Language Models"
    ],
    "b_abstract":[
      "While recent Large Vision-Language Models (LVLMs) have shown remarkable\nperformance in multi-modal tasks, they are prone to generating hallucinatory\ntext responses that do not align with the given visual input, which restricts\ntheir practical applicability in real-world scenarios. In this work, inspired\nby the observation that the text-to-image generation process is the inverse of\nimage-conditioned response generation in LVLMs, we explore the potential of\nleveraging text-to-image generative models to assist in mitigating\nhallucinations in LVLMs. We discover that generative models can offer valuable\nself-feedback for mitigating hallucinations at both the response and token\nlevels. Building on this insight, we introduce self-correcting Decoding with\nGenerative Feedback (DeGF), a novel training-free algorithm that incorporates\nfeedback from text-to-image generative models into the decoding process to\neffectively mitigate hallucinations in LVLMs. Specifically, DeGF generates an\nimage from the initial response produced by LVLMs, which acts as an auxiliary\nvisual reference and provides self-feedback to verify and correct the initial\nresponse through complementary or contrastive decoding. Extensive experimental\nresults validate the effectiveness of our approach in mitigating diverse types\nof hallucinations, consistently surpassing state-of-the-art methods across six\nbenchmarks. Code is available at https:\/\/github.com\/zhangce01\/DeGF."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15359",
    "c_title":[
      "Neural quantum embedding via deterministic quantum computation with one\n  qubit"
    ],
    "c_abstract":[
      "Quantum computing is expected to provide exponential speedup in machine\nlearning. However, optimizing the data loading process, commonly referred to as\nquantum data embedding, to maximize classification performance remains a\ncritical challenge. In this work, we propose a neural quantum embedding (NQE)\ntechnique based on deterministic quantum computation with one qubit (DQC1).\nUnlike the traditional embedding approach, NQE trains a neural network to\nmaximize the trace distance between quantum states corresponding to different\ncategories of classical data. Furthermore, training is efficiently achieved\nusing DQC1, which is specifically designed for ensemble quantum systems, such\nas nuclear magnetic resonance (NMR). We validate the NQE-DQC1 protocol by\nencoding handwritten images into NMR quantum processors, demonstrating a\nsignificant improvement in distinguishability compared to traditional methods.\nAdditionally, after training the NQE, we implement a parameterized quantum\ncircuit for classification tasks, achieving 98\\% classification accuracy, in\ncontrast to the 54\\% accuracy obtained using traditional embedding. Moreover,\nwe show that the NQE-DQC1 protocol is extendable, enabling the use of the NMR\nsystem for NQE training due to its high compatibility with DQC1, while\nsubsequent machine learning tasks can be performed on other physical platforms,\nsuch as superconducting circuits. Our work opens new avenues for utilizing\nensemble quantum systems for efficient classical data embedding into quantum\nregisters."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-574",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03531",
    "b_title":[
      "Traversable AdS Wormhole via Non-local Double Trace or Janus Deformation"
    ],
    "b_abstract":[
      "We study (i) Janus deformations and (ii) non-local double trace deformations\nof a pair of CFTs, as two different ways to construct CFT duals of traversable\nAdS wormholes. First, we construct a simple model of traversable wormholes by\ngluing two Poincar\\'e AdS geometries and BTZ black holes and compute\nholographic two point functions and (pseudo) entanglement entropy. We point out\nthat a Janus gravity solution describes a traversable wormhole when the\ndeformation parameter takes imaginary values. On the other hand, we show that\ndouble trace deformations between two decoupled CFTs can reproduce two point\nfunctions of traversable AdS wormholes. By considering the case where the\ndouble trace deformation is given by a non-local $T\\overline{T}$ deformation,\nwe analyze the dual gravity which implies emergence of wormholes. We present\ntoy model of these deformed CFTs by using free scalars and obtain qualitative\nbehaviors expected for them. We argue that the crucial difference between the\ntwo constructions is that a global time slice of wormhole is described by a\npure state for Janus deformations, while it is a mixed state for the double\ntrace deformations."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13707",
    "c_title":[
      "Human-Like Robot Impedance Regulation Skill Learning from Human-Human\n  Demonstrations"
    ],
    "c_abstract":[
      "Humans are experts in collaborating with others physically by regulating\ncompliance behaviors based on the perception of their partner states and the\ntask requirements. Enabling robots to develop proficiency in human\ncollaboration skills can facilitate more efficient human-robot collaboration\n(HRC). This paper introduces an innovative impedance regulation skill learning\nframework for achieving HRC in multiple physical collaborative tasks. The\nframework is designed to adjust the robot compliance to the human partner\nstates while adhering to reference trajectories provided by human-human\ndemonstrations. Specifically, electromyography (EMG) signals from human muscles\nare collected and analyzed to extract limb impedance, representing compliance\nbehaviors during demonstrations. Human endpoint motions are captured and\nrepresented using a probabilistic learning method to create reference\ntrajectories and corresponding impedance profiles. Meanwhile, an LSTMbased\nmodule is implemented to develop task-oriented impedance regulation policies by\nmapping the muscle synergistic contributions between two demonstrators.\nFinally, we propose a wholebody impedance controller for a human-like robot,\ncoordinating joint outputs to achieve the desired impedance and reference\ntrajectory during task execution. Experimental validation was conducted through\na collaborative transportation task and two interactive Tai Chi pushing hands\ntasks, demonstrating superior performance from the perspective of interactive\nforces compared to a constant impedance control method."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-575",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02310",
    "b_title":[
      "Improving the stability and efficiency of high-order operator-splitting\n  methods"
    ],
    "b_abstract":[
      "Operator-splitting methods are widely used to solve differential equations,\nespecially those that arise from multi-scale or multi-physics models, because a\nmonolithic (single-method) approach may be inefficient or even infeasible. The\nmost common operator-splitting methods are the first-order Lie--Trotter (or\nGodunov) and the second-order Strang (Strang--Marchuk) splitting methods.\nHigh-order splitting methods with real coefficients require backward-in-time\nintegration in each operator and hence may be adversely impacted by instability\nfor certain operators such as diffusion. However, besides the method\ncoefficients, there are many other ancillary aspects to an overall\noperator-splitting method that are important but often overlooked. For example,\nthe operator ordering and the choice of sub-integration methods can\nsignificantly affect the stability and efficiency of an operator-splitting\nmethod. In this paper, we investigate some design principles for the\nconstruction of operator-splitting methods, including minimization of local\nerror measure, choice of sub-integration method, maximization of linear\nstability, and minimization of overall computational cost. We propose a new\nfour-stage, third-order, 2-split operator-splitting method with seven\nsub-integrations per step and optimized linear stability for a benchmark\nproblem from cardiac electrophysiology. We then propose a general principle to\nfurther improve stability and efficiency of such operator-splitting methods by\nusing low-order, explicit sub-integrators for unstable sub-integrations. We\ndemonstrate an almost 30\\% improvement in the performance of methods derived\nfrom these design principles compared to the best-known third-order methods."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03835",
    "c_title":[
      "Neutrino quantum kinetics in three flavors"
    ],
    "c_abstract":[
      "The impact of neutrino flavor conversion on the supernova mechanism is yet to\nbe fully understood. We present multi-energy and multi-angle solutions of the\nneutrino quantum kinetic equations in three flavors, taking into account\nneutrino advection and non-forward collisions with the background medium.\nFlavor evolution is explored within a spherically symmetric shell surrounding\nthe region of neutrino decoupling in the interior of a core-collapse supernova,\nrelying on the outputs of a spherically symmetric core-collapse supernova model\nwith a mass of $18.6 M_\\odot$. We select two representative post-bounce times:\n$t_{\\rm pb} = 0.25$ s (no angular crossings are present and flavor conversion\nis triggered by slow collective effects) and $t_{\\rm pb} = 1$ s (angular\ncrossings trigger fast flavor instabilities). We find that flavor equipartition\nis achieved in the antineutrino sector between $\\bar\\nu_e$ and $\\bar\\nu_x =\n(\\bar\\nu_\\mu + \\bar\\nu_\\tau)\/2$ for both post-bounce times. In the neutrino\nsector, flavor equipartition between $\\nu_e$ and $\\nu_x$ seems more likely at\nlater post-bounce times, where the neutrino emission properties among different\nflavors tend to approach each other, but it is not a generic feature. The\nexponential growth of the $\\nu_\\mu$--$\\nu_\\tau$ asymmetry due to three-flavor\neffects is responsible for differences between the quasi-steady configurations\nobtained in the three-flavor solution and in the two-flavor approximation. This\nhas consequences on the neutrino heating rate, which is generally larger when\nall three flavors are taken into account and can increase up to $30\\%$ with\nrespect to the case where flavor conversion is neglected."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-576",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11528",
    "b_title":[
      "A Survey of Personalized Large Language Models: Progress and Future\n  Directions"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) excel in handling general knowledge tasks, yet\nthey struggle with user-specific personalization, such as understanding\nindividual emotions, writing styles, and preferences. Personalized Large\nLanguage Models (PLLMs) tackle these challenges by leveraging individual user\ndata, such as user profiles, historical dialogues, content, and interactions,\nto deliver responses that are contextually relevant and tailored to each user's\nspecific needs. This is a highly valuable research topic, as PLLMs can\nsignificantly enhance user satisfaction and have broad applications in\nconversational agents, recommendation systems, emotion recognition, medical\nassistants, and more. This survey reviews recent advancements in PLLMs from\nthree technical perspectives: prompting for personalized context (input level),\nfinetuning for personalized adapters (model level), and alignment for\npersonalized preferences (objective level). To provide deeper insights, we also\ndiscuss current limitations and outline several promising directions for future\nresearch. Updated information about this survey can be found at the\nhttps:\/\/github.com\/JiahongLiu21\/Awesome-Personalized-Large-Language-Models."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03861",
    "c_title":[
      "Homological stability for Hurwitz spaces and applications"
    ],
    "c_abstract":[
      "We show the homology of the Hurwitz space associated to an arbitrary finite\nrack stabilizes integrally in a suitable sense. We also compute the dominant\npart of its stable homology after inverting finitely many primes. This proves a\nconjecture of Ellenberg--Venkatesh--Westerland and improves upon our previous\nresults for non-splitting racks. We obtain applications to Malle's conjecture,\nthe Picard rank conjecture, and the Cohen--Lenstra--Martinet heuristics."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.AT",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-577",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00563",
    "b_title":[
      "Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for\n  Semantic Segmentation"
    ],
    "b_abstract":[
      "Recent advancements in deep neural networks have significantly enhanced the\nperformance of semantic segmentation. However, class imbalance and instance\nimbalance remain persistent challenges, where smaller instances and thin\nboundaries are often overshadowed by larger structures. To address the\nmultiscale nature of segmented objects, various models have incorporated\nmechanisms such as spatial attention and feature pyramid networks. Despite\nthese advancements, most loss functions are still primarily pixel-wise, while\nregional and boundary-focused loss functions often incur high computational\ncosts or are restricted to small-scale regions. To address this limitation, we\npropose complex wavelet mutual information (CWMI) loss, a novel loss function\nthat leverages mutual information from subband images decomposed by a complex\nsteerable pyramid. The complex steerable pyramid captures features across\nmultiple orientations and preserves structural similarity across scales.\nMeanwhile, mutual information is well-suited for capturing high-dimensional\ndirectional features and exhibits greater noise robustness. Extensive\nexperiments on diverse segmentation datasets demonstrate that CWMI loss\nachieves significant improvements in both pixel-wise accuracy and topological\nmetrics compared to state-of-the-art methods, while introducing minimal\ncomputational overhead. The code is available at\nhttps:\/\/anonymous.4open.science\/r\/CWMI-83B7\/"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09199",
    "c_title":[
      "On mean curvature flow solitons in the sphere"
    ],
    "c_abstract":[
      "In this paper, we consider soliton solutions of the mean curvature flow in\nthe unit sphere $S^{2n+1}$ moving along the integral curves of the Hopf unit\nvector field. While such solitons must necessarily be minimal if compact, we\nproduce a non-minimal, complete example with topology $S^{2n-1} \\times R$. The\nexample wraps around a Clifford torus $S^{2n-1} \\times S^1$ along each end, it\nhas reflection and rotational symmetry and its mean curvature changes sign on\neach end. Indeed, we prove that a complete 2-dimensional soliton with\nnon-negative mean curvature outside a compact set must be a covering of a\nClifford torus. Concluding, we obtain a pinching theorem under suitable\nconditions on the second fundamental form."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-578",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01731",
    "b_title":[
      "Dark Photons can Prevent Core-Collapse Supernova Explosions"
    ],
    "b_abstract":[
      "During the accretion phase of a core-collapse supernova (SN), dark-photon\n(DP) cooling can be largest in the gain layer below the stalled shock wave. In\nthis way, it could counter-act the usual shock rejuvenation by neutrino energy\ndeposition and thus prevent the explosion. This peculiar energy-loss profile\nderives from the resonant nature of DP production. The largest cooling and thus\nstrongest constraints obtain for DP masses of 0.1-0.4 MeV, a range\ncorresponding to the photon plasma mass in the gain region. Electron-capture\nSNe, once observationally unambiguously identified, could provide strong bounds\neven down to nearly 0.01 MeV. For a coupling strength so small that\nneutrino-driven explosions are expected to survive, the DP cooling of the core\nis too small to modify the neutrino signal, i.e., our new argument supersedes\nthe traditional SN1987A cooling bound."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08556",
    "c_title":[
      "Lyapunov stability and uniqueness problems for Hamilton-Jacobi equations\n  without monotonicity"
    ],
    "c_abstract":[
      "We consider the evolutionary Hamilton-Jacobi equation\n  \\begin{align*}\n  w_t(x,t)+H(x,Dw(x,t),w(x,t))=0, \\quad(x,t)\\in M\\times [0,+\\infty),\n  \\end{align*}\n  where $M$ is a compact manifold, $H:T^*M\\times R\\to R$, $H=H(x,p,u)$\nsatisfies Tonelli conditions in $p$ and the Lipschitz condition in $u$.\n  This work mainly concerns with the Lyapunov stability (including asymptotic\nstability, and instability) and uniqueness of stationary viscosity solutions of\nthe equation. A criterion for stability and a criterion for instability are\ngiven. We do not utilize auxiliary functions and thus our method is different\nfrom the classical Lyapunov's direct method.\n  We also prove several uniqueness results for stationary viscosity solutions.\nThe Hamiltonian $H$ has no concrete form and it may be non-monotonic in the\nargument $u$, where the situation is more complicated than the monotonic case.\nSeveral simple but nontrivial examples are provided, including the following\nequation on the unit circle\n  \\[\n  w_t(x,t)+\\frac{1}{2}w^2_x(x,t)-a\\cdot w_x(x,t)+(\\sin x+b)\\cdot w(x,t)=0,\\quad\nx\\in \\mathbf{S},\n  \\]\n  where $a$, $b\\in R$ are parameters. We analyze the stability, and instability\nof the stationary solution $w=0$ when parameters vary, and show that $w=0$ is\nthe unique stationary solution when $a=0$, $b>1$ and $a\\neq0$, $b\\geqslant 1$.\n  The sign of the integral of $\\frac{\\partial H}{\\partial u}$ with respect to\nthe Mather measure of the contact Hamiltonian system generated by $H$ plays an\nessential role in the proofs of aforementioned results. For this reason, we\nfirst develop the Mather and weak KAM theories for contact Hamiltonian systems\nin this non-monotonic setting. A decomposition theorem of the Ma\\~n\\'e set is\nthe main result of this part."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-579",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08827",
    "b_title":[
      "CHEmical-shift selective Adiabatic Pulse (CHEAP): Fast and High\n  Resolution Downfield 3D 1H-MRSI at 7T"
    ],
    "b_abstract":[
      "The key molecules such as triphosphate (ATP), glutathione (GSH), and\nhomocarnosine (hCs) - central to metabolic processes in the human brain remain\nelusive or challenging to detect with upfield 1H-MRSI. Traditional 3D 1H-MRSI\nin vivo faces challenges, including a low signal-to-noise ratio and\nmagnetization transfer effects with water, leading to prolonged measurement\ntimes and reduced resolution. To address these limitations, we propose a\ndownfield 3D-MRSI method aimed at measuring downfield metabolites with enhanced\nspatial resolution, and speed acceptable for clinical practice at 7T. The\nCHEmical-shift selective Adiabatic Pulse (CHEAP) technique was integrated into\necho-planar spectroscopic imaging (EPSI) readout sequence for downfield\nmetabolite and water reference 3D-MRSI. Five healthy subjects and two glioma\npatients were scanned to test the feasibility. In this work, CHEAP-EPSI\ntechnique is shown to significantly enhance spatial the resolution to 0.37 ml\nwhile simultaneously reducing the scan time to 10.5 minutes. Its distinct\nadvantages include low specific absorption rate, effective suppression of water\nand lipid signals, and minimal baseline distortions, making it a valuable tool\nfor research or potentially diagnostic purposes. CHEAP-EPSI improves the\ndetection sensitivity of downfield metabolites like N-acetyl-aspartate (NAA+)\nand DF8.18 (ATP&GSH+), and offers new possibilities for the study of metabolism\nin healthy and diseased brain."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09744",
    "c_title":[
      "KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity\n  Recognition and Normalization for Dysmorphology Physical Examination Reports"
    ],
    "c_abstract":[
      "The objective of BioCreative8 Track 3 is to extract phenotypic key medical\nfindings embedded within EHR texts and subsequently normalize these findings to\ntheir Human Phenotype Ontology (HPO) terms. However, the presence of diverse\nsurface forms in phenotypic findings makes it challenging to accurately\nnormalize them to the correct HPO terms. To address this challenge, we explored\nvarious models for named entity recognition and implemented data augmentation\ntechniques such as synonym marginalization to enhance the normalization step.\nOur pipeline resulted in an exact extraction and normalization F1 score 2.6\\%\nhigher than the mean score of all submissions received in response to the\nchallenge. Furthermore, in terms of the normalization F1 score, our approach\nsurpassed the average performance by 1.9\\%. These findings contribute to the\nadvancement of automated medical data extraction and normalization techniques,\nshowcasing potential pathways for future research and application in the\nbiomedical domain."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-580",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12602",
    "b_title":[
      "Learning-based Dynamic Robot-to-Human Handover"
    ],
    "b_abstract":[
      "This paper presents a novel learning-based approach to dynamic robot-to-human\nhandover, addressing the challenges of delivering objects to a moving receiver.\nWe hypothesize that dynamic handover, where the robot adjusts to the receiver's\nmovements, results in more efficient and comfortable interaction compared to\nstatic handover, where the receiver is assumed to be stationary. To validate\nthis, we developed a nonparametric method for generating continuous handover\nmotion, conditioned on the receiver's movements, and trained the model using a\ndataset of 1,000 human-to-human handover demonstrations. We integrated\npreference learning for improved handover effectiveness and applied impedance\ncontrol to ensure user safety and adaptiveness. The approach was evaluated in\nboth simulation and real-world settings, with user studies demonstrating that\ndynamic handover significantly reduces handover time and improves user comfort\ncompared to static methods. Videos and demonstrations of our approach are\navailable at https:\/\/zerotohero7886.github.io\/dyn-r2h-handover ."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10826",
    "c_title":[
      "Equidistribution Conditions for Gaps of Geometric Numerical Semigroups"
    ],
    "c_abstract":[
      "In 2008, Wang \\& Wang showed that the set of gaps of a numerical semigroup\ngenerated by two coprime positive integers $a$ and $b$ is equidistributed\nmodulo 2 precisely when $a$ and $b$ are both odd. Shor generalized this in\n2022, showing that the set of gaps of such a numerical semigroup is\nequidistributed modulo $m$ when $a$ and $b$ are coprime to $m$ and at least one\nof them is 1 modulo $m$. In this paper, we further generalize these results by\nconsidering numerical semigroups generalized by geometric sequences of the form\n$a^k, a^{k-1}b, \\dots, b^k$, aiming to determine when the corresponding set of\ngaps is equidistributed modulo $m$. With elementary methods, we are able to\nobtain a result for $k=2$ and all $m$. We then work with cyclotomic rings,\nusing results about multiplicative independence of cyclotomic units to obtain\nresults for all $k$ and infinitely many $m$. Finally, we take an approach with\ncyclotomic units and Dirichlet L-functions to obtain results for all $k$ and\nall $m$."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-581",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10512",
    "b_title":[
      "Conformal Prediction Sets for Deep Generative Models via Reduction to\n  Conformal Regression"
    ],
    "b_abstract":[
      "We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16626",
    "c_title":[
      "Hyper-active repeating fast radio bursts from rotation modulated\n  starquakes on magnetars"
    ],
    "c_abstract":[
      "The non-detection of periodicity related to rotation challenges the magnetar\nmodel for fast radio bursts (FRBs). Moreover, a bimodal distribution of the\nburst waiting times is widely observed in hyper-active FRBs, a significant\ndeviation from the exponential distribution expected from stationary Poisson\nprocesses. By combining the epidemic-type aftershock sequence (ETAS) earthquake\nmodel and the rotating vector model (RVM) involving the rotation of the\nmagnetar and orientations of the spin and magnetic axes, we find that starquake\nevents modulated by the rotation of FRB-emitting magnetar can explain the\nbimodal distribution of FRB waiting times, as well as the non-detection of\nperiodicity in active repeating FRBs. We analyze data from multiple FRB\nsources, demonstrating that differences in waiting time distributions and\nobserved energies can be explained by varying parameters related to magnetar\nproperties and starquake dynamics. Our results suggest that rotation-modulated\nstarquakes on magnetars can possibly be a unified source for FRBs. Notably, we\nfind that active repeaters tend to have small magnetic inclination angles in\norder to hide their periodicity. We also show that our model can reproduce the\nwaiting time distribution of a pulsar phase of the galactic magnetar SGR\nJ1935+2154 with a larger inclination angle than the active repeaters, which\ncould explain the detection of spin period and the relatively low observed\nenergy for FRBs from the magnetar. The spin periods of active repeaters are not\nwell constrained, but most likely fall in the valley region between the two\npeaks of the waiting time distributions."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-582",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01756",
    "b_title":[
      "Stueckelberg field and Cosmology"
    ],
    "b_abstract":[
      "Stueckelberg introduced an axion like scalar field to provide mass to the\ngauge electromagnetic field without breaking gauge invariance. This can be\nconsidered as a precursor to the spontaneously broken abelian Higgs model. We\nwill consider its role in cosmology to provide a novel candidate to the dark\nmatter question. In addition its implications to deeper issues will be pointed\nout."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14433",
    "c_title":[
      "Daily Land Surface Temperature Reconstruction in Landsat Cross-Track\n  Areas Using Deep Ensemble Learning With Uncertainty Quantification"
    ],
    "c_abstract":[
      "Many real-world applications rely on land surface temperature (LST) data at\nhigh spatiotemporal resolution. In complex urban areas, LST exhibits\nsignificant variations, fluctuating dramatically within and across city blocks.\nLandsat provides high spatial resolution data at 100 meters but is limited by\nlong revisit time, with cloud cover further disrupting data collection. Here,\nwe propose DELAG, a deep ensemble learning method that integrates annual\ntemperature cycles and Gaussian processes, to reconstruct Landsat LST in\ncomplex urban areas. Leveraging the cross-track characteristics and\ndual-satellite operation of Landsat since 2021, we further enhance data\navailability to 4 scenes every 16 days. We select New York City, London and\nHong Kong from three different continents as study areas. Experiments show that\nDELAG successfully reconstructed LST in the three cities under clear-sky (RMSE\n= 0.73-0.96 K) and heavily-cloudy (RMSE = 0.84-1.62 K) situations, superior to\nexisting methods. Additionally, DELAG can quantify uncertainty that enhances\nLST reconstruction reliability. We further tested the reconstructed LST to\nestimate near-surface air temperature, achieving results (RMSE = 1.48-2.11 K)\ncomparable to those derived from clear-sky LST (RMSE = 1.63-2.02 K). The\nresults demonstrate the successful reconstruction through DELAG and highlight\nthe broader applications of LST reconstruction for estimating accurate air\ntemperature. Our study thus provides a novel and practical method for Landsat\nLST reconstruction, particularly suited for complex urban areas within Landsat\ncross-track areas, taking one step toward addressing complex climate events at\nhigh spatiotemporal resolution."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-583",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08747",
    "b_title":[
      "Every group is the automorphism group of a graph with arbitrarily large\n  genus"
    ],
    "b_abstract":[
      "We prove that, to every abstract group $G$, we can associate a sequence of\ngraphs $\\Gamma_n$ such that the automorphism group of $\\Gamma_n$ is isomorphic\nto $G$ and the genus of $\\Gamma_n$ is an unbounded function of $n$."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03517",
    "c_title":[
      "Atomistically informed phase field study of austenite grain growth"
    ],
    "c_abstract":[
      "Atomistically-informed phase field simulations have been performed to\ninvestigate the effect of five common alloying elements (Nb, Ti, Mo, V, Mn) on\naustenite grain growth. The anisotropic simulations based on the segregation\nenergy profiles of the solutes to four different grain boundary (GB) types from\ndensity functional theory calculations suggest a secondary role of solute drag\nanisotropy on grain growth. Hence, the solute trends are determined to be the\nsame for all investigated GBs, and as a result, the $\\Sigma 5(310)[001]$ GB can\nbe considered as a representative GB for solute trend predictions. The decrease\nin grain growth rates due to solute additions is quantitatively described using\na solute trend parameter. The following hierarchy of the solute's effectiveness\nto retard austenite grain growth has been determined based on the results of\nthe presented model calculations in agreement with the experimental\nobservations: Nb$>$Ti$>$Mo$>$V$\\approx$Mn. The limitations and the strengths of\nthe proposed approach are discussed in detail, and a potential application of\nthis approach to steel design is proposed."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-584",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09028",
    "b_title":[
      "Second-order derivations of functions spaces -- a characterization of\n  second-order differential operators"
    ],
    "b_abstract":[
      "Let $\\Omega \\subset \\mathbb{R}$ be a nonempty and open set, then for all $f,\ng, h\\in \\mathscr{C}^{2}(\\Omega)$ we have \\begin{multline*}\n\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot g\\cdot h) -\nf\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(g\\cdot\nh)-g\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot\nh)-h\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}(f\\cdot g) + f\\cdot\ng\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}} h+f\\cdot\nh\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}} g+g\\cdot h\n\\frac{\\mathrm{d}^{2}}{\\mathrm{d} x^{2}}f=0 \\end{multline*} The aim of this\npaper is to consider the corresponding operator equation \\[D(f\\cdot g \\cdot h)\n- fD(g\\cdot h) - gD(f\\cdot h) - hD(f \\cdot g) + f\\cdot g D(h) + f\\cdot h D(g)\n+g\\cdot h D(f) = 0\\] for operators $D\\colon \\mathscr{C}^{k}(\\Omega)\\to\n\\mathscr{C}(\\Omega)$, where $k$ is a given nonnegative integer and the above\nidentity is supposed to hold for all $f, g, h \\in \\mathscr{C}^{k}(\\Omega)$. We\nshow that besides the operators of first and second derivative, there are more\nsolutions to this equation. Some special cases characterizing differential\noperators are also studied."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04990",
    "c_title":[
      "DP-GTR: Differentially Private Prompt Protection via Group Text\n  Rewriting"
    ],
    "c_abstract":[
      "Prompt privacy is crucial, especially when using online large language models\n(LLMs), due to the sensitive information often contained within prompts. While\nLLMs can enhance prompt privacy through text rewriting, existing methods\nprimarily focus on document-level rewriting, neglecting the rich,\nmulti-granular representations of text. This limitation restricts LLM\nutilization to specific tasks, overlooking their generalization and in-context\nlearning capabilities, thus hindering practical application. To address this\ngap, we introduce DP-GTR, a novel three-stage framework that leverages local\ndifferential privacy (DP) and the composition theorem via group text rewriting.\nDP-GTR is the first framework to integrate both document-level and word-level\ninformation while exploiting in-context learning to simultaneously improve\nprivacy and utility, effectively bridging local and global DP mechanisms at the\nindividual data point level. Experiments on CommonSense QA and DocVQA\ndemonstrate that DP-GTR outperforms existing approaches, achieving a superior\nprivacy-utility trade-off. Furthermore, our framework is compatible with\nexisting rewriting techniques, serving as a plug-in to enhance privacy\nprotection. Our code is publicly available at\nhttps:\/\/github.com\/FatShion-FTD\/DP-GTR for reproducibility."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-585",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15223",
    "b_title":[
      "Efficient and Interpretable Neural Networks Using Complex Lehmer\n  Transform"
    ],
    "b_abstract":[
      "We propose an efficient and interpretable neural network with a novel\nactivation function called the weighted Lehmer transform. This new activation\nfunction enables adaptive feature selection and extends to the complex domain,\ncapturing phase-sensitive and hierarchical relationships within data. Notably,\nit provides greater interpretability and transparency compared to existing\nmachine learning models, facilitating a deeper understanding of its\nfunctionality and decision-making processes. We analyze the mathematical\nproperties of both real-valued and complex-valued Lehmer activation units and\ndemonstrate their applications in modeling nonlinear interactions. Empirical\nevaluations demonstrate that our proposed neural network achieves competitive\naccuracy on benchmark datasets with significantly improved computational\nefficiency. A single layer of real-valued or complex-valued Lehmer activation\nunits is shown to deliver state-of-the-art performance, balancing efficiency\nwith interpretability."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08490",
    "c_title":[
      "Classification of primitive immmersions of constant curvature into flag\n  manifolds"
    ],
    "c_abstract":[
      "We classify primitive minimal immersions of constant curvature from the\ntwo-sphere $S^2$ into the low-dimensional flag manifolds $F_{2,1,1}$ and\n$F_{2,2,1}$."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-586",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03644",
    "b_title":[
      "Finite length for unramified $\\mathrm{GL}_2$"
    ],
    "b_abstract":[
      "Let $p$ be a prime number and $K$ a finite unramified extension of\n$\\mathbb{Q}_p$. If $p$ is large enough with respect to $[K:\\mathbb{Q}_p]$ and\nunder mild genericity assumptions, we prove that the admissible smooth\nrepresentations of $\\mathrm{GL}_2(K)$ that occur in Hecke eigenspaces of the\nmod $p$ cohomology are of finite length. We also prove many new structural\nresults about these representations of $\\mathrm{GL}_2(K)$ and their\nsubquotients."
    ],
    "b_categories":[
      [
        "math.NT",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08126",
    "c_title":[
      "Trilinos: Enabling Scientific Computing Across Diverse Hardware\n  Architectures at Scale"
    ],
    "c_abstract":[
      "Trilinos is a community-developed, open-source software framework that\nfacilitates building large-scale, complex, multiscale, multiphysics simulation\ncode bases for scientific and engineering problems. Since the Trilinos\nframework has undergone substantial changes to support new applications and new\nhardware architectures, this document is an update to ``An Overview of the\nTrilinos project'' by Heroux et al. (ACM Transactions on Mathematical Software,\n31(3):397-423, 2005). It describes the design of Trilinos, introduces its new\norganization in product areas, and highlights established and new features\navailable in Trilinos. Particular focus is put on the modernized software stack\nbased on the Kokkos ecosystem to deliver performance portability across\nheterogeneous hardware architectures. This paper also outlines the organization\nof the Trilinos community and the contribution model to help onboard interested\nusers and contributors."
    ],
    "c_categories":[
      [
        "cs.MS",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-587",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18904",
    "b_title":[
      "An Empirical Study on Commit Message Generation using LLMs via\n  In-Context Learning"
    ],
    "b_abstract":[
      "Commit messages concisely describe code changes in natural language and are\nimportant for software maintenance. Several approaches have been proposed to\nautomatically generate commit messages, but they still suffer from critical\nlimitations, such as time-consuming training and poor generalization ability.\nTo tackle these limitations, we propose to borrow the weapon of large language\nmodels (LLMs) and in-context learning (ICL). Our intuition is based on the fact\nthat the training corpora of LLMs contain extensive code changes and their\npairwise commit messages, which makes LLMs capture the knowledge about commits,\nwhile ICL can exploit the knowledge hidden in the LLMs and enable them to\nperform downstream tasks without model tuning. However, it remains unclear how\nwell LLMs perform on commit message generation via ICL. In this paper, we\nconduct an empirical study to investigate the capability of LLMs to generate\ncommit messages via ICL. Specifically, we first explore the impact of different\nsettings on the performance of ICL-based commit message generation. We then\ncompare ICL-based commit message generation with state-of-the-art approaches on\na popular multilingual dataset and a new dataset we created to mitigate\npotential data leakage. The results show that ICL-based commit message\ngeneration significantly outperforms state-of-the-art approaches on subjective\nevaluation and achieves better generalization ability. We further analyze the\nroot causes for LLM's underperformance and propose several implications, which\nshed light on future research directions for using LLMs to generate commit\nmessages."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05269",
    "c_title":[
      "On representations of the crystallization of the quantized function\n  algebra C(SUq(n + 1))"
    ],
    "c_abstract":[
      "The crystallization C(SU0(n + 1)) of the q-family of C*-algebras C(SUq(n +\n1)) was defined by Giri & Pal for all n \\geq 2 and they observed that any\nirreducible representation at the q = 0 level is the norm limit of irreducible\nrepresentations of C(SUq(n + 1)) as q\\to 0+. In this article, we will\ngeneralize this to any non-degenerate representation (respectively faithful) of\nC(SU0(n+1)). As a consequence, one can alternatively realize C(SU0(n+1)) as the\nC*-algebra generated by the limit operators of faithful representations of\nC(SUq(n+1))."
    ],
    "c_categories":[
      [
        "math.OA",
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-588",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16805",
    "b_title":[
      "Martians Among Us: Observing Private or Reserved IPs on the Public\n  Internet"
    ],
    "b_abstract":[
      "Spoofed traffic has been identified as one of the main issues of concern for\nnetwork hygiene nowadays, as it facilitates Distributed Denial-of-Service\n(DDoS) attacks by hiding their origin and complicating forensic investigations.\nSome indicators of poor network hygiene are packets with Bogon or Martian\nsource addresses representing either misconfigurations or spoofed packets.\nDespite the development of Source Address Validation (SAV) techniques and\nguidelines such as BCP 38 and BCP 84, Bogons are often overlooked in the\nfiltering practices of network operators. This study uses traceroute\nmeasurements from the CAIDA Ark dataset, enriched with historical BGP routing\ninformation from RIPE RIS and RouteViews, to investigate the prevalence of\nBogon addresses over seven years (2017-2023). Our analysis reveals widespread\nnon-compliance with best practices, with Bogon traffic detected across\nthousands of ASes. Notably, 82.69%-97.83% of CAIDA Ark vantage points observe\npaths containing Bogon IPs, primarily RFC1918 addresses. Additionally, 19.70%\nof all analyzed traceroutes include RFC1918 addresses, while smaller\nproportions involve RFC6598 (1.50%) and RFC3927 (0.10%) addresses. We identify\nmore than 13,000 unique ASes transiting Bogon traffic, with only 11.64%\nappearing in more than half of the measurements. Cross-referencing with the\nSpoofer project and MANRS initiatives shows a concerning gap: 62.67% of ASes\nthat do not filter packets with Bogon sources are marked as non-spoofable,\nsuggesting incomplete SAV implementation. Our contributions include an\nassessment of network hygiene using the transiting of Bogon packets as a\nmetric, an analysis of the main types of Bogon addresses found in traceroutes,\nand several proposed recommendations to address the observed gaps, enforcing\nthe need for stronger compliance with best practices to improve global network\nsecurity."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03802",
    "c_title":[
      "Quasi-optimal cyclic orbit codes"
    ],
    "c_abstract":[
      "We focus on two aspects of cyclic orbit codes: invariants under equivalence\nand quasi-optimality. Regarding the first aspect, we establish a connection\nbetween the codewords of a cyclic orbit code and a certain linear set on the\nprojective line. This allows us to derive new bounds on the parameters of the\ncode. In the second part, we study a particular family of (quasi-)optimal\ncyclic orbit codes and derive a general existence theorem for quasi-optimal\ncodes in even-dimensional vector spaces over finite fields of any\ncharacteristic. Finally, for our particular code family we describe the\nautomorphism groups under the general linear group and a suitable Galois group."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.CO",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-589",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12453",
    "b_title":[
      "Shape Bias and Robustness Evaluation via Cue Decomposition for Image\n  Classification and Segmentation"
    ],
    "b_abstract":[
      "Previous works studied how deep neural networks (DNNs) perceive image content\nin terms of their biases towards different image cues, such as texture and\nshape. Previous methods to measure shape and texture biases are typically\nstyle-transfer-based and limited to DNNs for image classification. In this\nwork, we provide a new evaluation procedure consisting of 1) a\ncue-decomposition method that comprises two AI-free data pre-processing methods\nextracting shape and texture cues, respectively, and 2) a novel\ncue-decomposition shape bias evaluation metric that leverages the\ncue-decomposition data. For application purposes we introduce a corresponding\ncue-decomposition robustness metric that allows for the estimation of the\nrobustness of a DNN w.r.t. image corruptions. In our numerical experiments, our\nfindings for biases in image classification DNNs align with those of previous\nevaluation metrics. However, our cue-decomposition robustness metric shows\nsuperior results in terms of estimating the robustness of DNNs. Furthermore,\nour results for DNNs on the semantic segmentation datasets Cityscapes and\nADE20k for the first time shed light into the biases of semantic segmentation\nDNNs."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08535",
    "c_title":[
      "Astrophysical properties of star clusters projected toward tidally\n  perturbed SMC regions"
    ],
    "c_abstract":[
      "We report on the astrophysical properties of a sample of star clusters in the\nSmall Magellanic Cloud (SMC). They have been selected with the aim of looking\nfor the connection between their ages, heliocentric distances and metallicities\nwith the existence of tidally perturbed\/induced outermost SMC regions. We\nderived the star cluster fundamental parameters from relatively deep Survey of\nthe Magellanic Stellar History (SMASH) DR2 color magnitude diagrams, cleaned\nfrom field star contamination, and compared to thousand synthetic CMDs covering\na wide range of heliocentric distances, ages and metal content. Heliocentric\ndistances for 15 star clusters are derived for the first time, which represents\nan increase of 50 per cent of SMC clusters with estimated heliocentric\ndistances. The analysis of the age-metallicity relationships (AMRs) of cluster\nlocated in outermost regions distributed around the SMC and in the SMC Main\nBody reveals that they have followed the overall galaxy chemical enrichment\nhistory. However, since half of the studied clusters are placed in front of or\nbehind the SMC Main Body, we concluded that they formed in the SMC and have\ntraveled outward because of the tidal effects from the interaction with the\nLarge Magellanic Cloud (LMC). Furthermore, metal rich clusters formed recently\nin some of these outermost regions from gas that was also dragged by tidal\neffects from the inner SMC. This outcome leads to consider the SMC as a galaxy\nscarred by the LMC tidal interaction with distance-perturbed and newly induced\noutermost stellar substructures."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-590",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06957",
    "b_title":[
      "A Spectral Theory of Scalar Volterra Equations"
    ],
    "b_abstract":[
      "Volterra integral and integro-differential equations have been extensively\nstudied in both pure mathematics and applied science. In one direction,\ndevelopments in analysis have yielded far-ranging existence, uniqueness, and\nregularity results. In the other, applications in science have inspired a\nsubstantial library of practical techniques to deal with such equations.\n  The present work connects these research areas by examining five large\nclasses of linear Volterra equations: integral and integro-differential\nequations with completely monotone (CM) kernels, corresponding to linear\nviscoelastic models; those with positive definite (PD) kernels, corresponding\nto partially-observed quantum systems; difference equations with PD kernels; a\nclass of generalized delay differential equations; and a class of generalized\nfractional differential equations. We develop a system of correspondences\nbetween these problems, showing that all five can be understood within the\nsame, spectral theory. We leverage this theory to recover practical,\nclosed-form solutions of all five classes, and we show that interconversion\nyields a natural, continuous involution within each class. Our work unifies\nseveral results from science: the interconversion formula of Gross, recent\nresults in viscoelasticity and operator theory for integral equations of the\nsecond type, classical formulas for Prony series and fractional differential\nequations, and the convergence of Prony series to CM kernels. Finally, our\ntheory yields a novel, geometric construction of the regularized Hilbert\ntransform, extends it to a wide class of infinite measures, and reveals a\nnatural connection to delay and fractional differential equations.\n  We leverage our theory to develop a powerful, spectral method to handle\nscalar Volterra equations numerically, and illustrate it with a number of\npractical examples."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.DS",
        "math.SP",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03510",
    "c_title":[
      "Salient Region Matching for Fully Automated MR-TRUS Registration"
    ],
    "c_abstract":[
      "Prostate cancer is a leading cause of cancer-related mortality in men. The\nregistration of magnetic resonance (MR) and transrectal ultrasound (TRUS) can\nprovide guidance for the targeted biopsy of prostate cancer. In this study, we\npropose a salient region matching framework for fully automated MR-TRUS\nregistration. The framework consists of prostate segmentation, rigid alignment\nand deformable registration. Prostate segmentation is performed using two\nsegmentation networks on MR and TRUS respectively, and the predicted salient\nregions are used for the rigid alignment. The rigidly-aligned MR and TRUS\nimages serve as initialization for the deformable registration. The deformable\nregistration network has a dual-stream encoder with cross-modal spatial\nattention modules to facilitate multi-modality feature learning, and a salient\nregion matching loss to consider both structure and intensity similarity within\nthe prostate region. Experiments on a public MR-TRUS dataset demonstrate that\nour method achieves satisfactory registration results, outperforming several\ncutting-edge methods. The code is publicly available at\nhttps:\/\/github.com\/mock1ngbrd\/salient-region-matching."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-591",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04968",
    "b_title":[
      "Gravitational waves from r-mode oscillations of stochastically accreting\n  neutron stars"
    ],
    "b_abstract":[
      "$r$-mode oscillations in rotating neutron stars are a source of continuous\ngravitational radiation. We investigate the excitation of $r$-modes by the\nmechanical impact on the neutron star surface of stochastically accreted clumps\nof matter, assuming that the Chandrasekhar-Friedman-Schutz instability is not\ntriggered. The star is idealised as a slowly-rotating, unmagnetised,\none-component fluid with a barotropic equation of state in Newtonian gravity.\nIt is found that the $r$-mode amplitude depends weakly on the equation of state\nbut sensitively on the rotation frequency $\\nu_{\\rm s}$. The gravitational wave\nstrain implicitly depends on the equation of state through the damping\ntimescale. The root-mean-square strain is $h_{\\rm rms} \\approx 10^{-35}\n(\\nu_{\\rm s}\/ 10 {\\rm Hz})^{2} (R_*\/10 {\\rm km})^2 (\\Delta t_{\\rm acc}\/1 {\\rm\nyr})^{1\/2} (f_{\\rm acc}\/1 {\\rm kHz})^{-1\/2} (\\dot{M}\/10^{-8} \\text{M}_{\\odot}\n\\text{yr}^{-1}) (v\/0.4c) (d\/1 {\\rm kpc})^{-1}$, which is comparable to the\nstrain from $g$-, $p$- and $f$-modes excited by stochastic accretion, where\n$R_*$ is the radius of the star, $\\Delta t_{\\rm acc}$ is the uninterrupted\nduration of an accretion episode, $f_{\\rm acc}$ is the mean clump impact\nfrequency, $\\dot{M}$ is the accretion rate, $v$ is the impact speed, and $d$ is\nthe distance of the star from the Earth. An observational test is proposed,\nbased on the temporal autocorrelation function of the gravitational wave\nsignal, to discern whether the Chandrasekhar-Friedman-Schutz instability\nswitches on and coexists with impact-excited $r$-modes before or during a\ngravitational wave observation."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.08402",
    "c_title":[
      "The complex structure of the Teichm\\\"uller space of circle\n  diffeomorphisms in the Zygmund smooth class II"
    ],
    "c_abstract":[
      "In our previous paper with the same title, we established the complex Banach\nmanifold structure for the Teichm\\\"uller space of circle diffeomorphisms whose\nderivatives belong to the Zygmund class. This was achieved by demonstrating\nthat the Schwarzian derivative map is a holomorphic split submersion. We also\nobtained analogous results for the pre-Schwarzian derivative map.\n  In this second part of the study, we investigate the structure of the image\nof the pre-Schwarzian derivative map, viewing it as a fiber space over the Bers\nembedding of the Teichm\\\"uller space, and prove that it forms a real-analytic\ndisk-bundle. Furthermore, we consider the little Zygmund class and establish\ncorresponding results for the closed Teichm\\\"uller subspace consisting of\nmappings in this class.\n  Finally, we construct the quotient space of this subspace in analogy with the\nasymptotic Teichm\\\"uller space and prove that the quotient Bers embedding and\npre-Bers embedding are well-defined and injective, thereby endowing it with a\ncomplex structure modeled on a quotient Banach space."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-592",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00319",
    "b_title":[
      "Current-driven collective control of helical spin texture in van der\n  Waals antiferromagnet"
    ],
    "b_abstract":[
      "Electrical control of quantum magnetic states is essential in spintronic\nscience. Initial studies on the ferromagnetic state control were extended to\ncollinear antiferromagnets and, more recently, noncollinear antiferromagnets.\nHowever, electrical control mechanisms of such exotic magnetic states remain\npoorly understood. Here, we report the first experimental and theoretical\nexample of the current control of helical antiferromagnets, arising from the\ncompetition between collinear antiferromagnetic exchange and interlayer\nDzyaloshinskii-Moriya interaction in new van-der-Waals (vdW) material\nNi1\/3NbS2. Due to the intrinsic broken inversion symmetry, an in-plane current\ngenerates spin-orbit torque that, in turn, interacts directly with the helical\nantiferromagnetic order. Our theoretical analyses indicate that a weak\nferromagnetic order coexists due to the Dzyaloshinskii-Moriya interaction,\nmediating the spin-orbit torque to collectively rotate the helical\nantiferromagnetic order. Our Ni1\/3NbS2 nanodevice experiments produce\ncurrent-dependent resistance change consistent with the theoretical prediction.\nThis work widens our understanding of the electrical control of helical\nantiferromagnets and promotes vdW quantum magnets as interesting material\nplatforms for electrical control."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.other",
        "physics.app-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14195",
    "c_title":[
      "Bridging Text and Vision: A Multi-View Text-Vision Registration Approach\n  for Cross-Modal Place Recognition"
    ],
    "c_abstract":[
      "Mobile robots necessitate advanced natural language understanding\ncapabilities to accurately identify locations and perform tasks such as package\ndelivery. However, traditional visual place recognition (VPR) methods rely\nsolely on single-view visual information and cannot interpret human language\ndescriptions. To overcome this challenge, we bridge text and vision by\nproposing a multiview (360{\\deg} views of the surroundings) text-vision\nregistration approach called Text4VPR for place recognition task, which is the\nfirst method that exclusively utilizes textual descriptions to match a database\nof images. Text4VPR employs the frozen T5 language model to extract global\ntextual embeddings. Additionally, it utilizes the Sinkhorn algorithm with\ntemperature coefficient to assign local tokens to their respective clusters,\nthereby aggregating visual descriptors from images. During the training stage,\nText4VPR emphasizes the alignment between individual text-image pairs for\nprecise textual description. In the inference stage, Text4VPR uses the Cascaded\nCross-Attention Cosine Alignment (CCCA) to address the internal mismatch\nbetween text and image groups. Subsequently, Text4VPR performs precisely place\nmatch based on the descriptions of text-image groups. On Street360Loc, the\nfirst text to image VPR dataset we created, Text4VPR builds a robust baseline,\nachieving a leading top-1 accuracy of 57% and a leading top-10 accuracy of 92%\nwithin a 5-meter radius on the test set, which indicates that localization from\ntextual descriptions to images is not only feasible but also holds significant\npotential for further advancement, as shown in Figure 1."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-593",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04637",
    "b_title":[
      "Effective action for relativistic hydrodynamics from Crooks fluctuation\n  theorem"
    ],
    "b_abstract":[
      "A new effective theory framework for fluctuating hydrodynamics in the\nrelativistic regime is derived using standard thermodynamical principles and\ngeneral properties of non-equilibrium stochastic dynamics. For the first time,\nwe establish clear and concise conditions for ensuring that the resulting\neffective theories are causal, stable, and well-posed within general\nrelativity. These properties are independent of spacetime foliation and are\nvalid in the full nonlinear regime. Out-of-equilibrium fluctuations are\nconstrained by a relativistically covariant version of Crooks fluctuation\ntheorem, which determines how the entropy production is distributed even when\nthe system is driven by an external force. This leads to an emerging\n$\\mathbb{Z}_2$ symmetry responsible for imposing fluctuation-dissipation\nrelations for n-point correlation functions, which matches the standard\nconstraints for the Schwinger-Keldysh effective action."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18857",
    "c_title":[
      "DAPPER: A Performance-Attack-Resilient Tracker for RowHammer Defense"
    ],
    "c_abstract":[
      "RowHammer vulnerabilities pose a significant threat to modern DRAM-based\nsystems, where rapid activation of DRAM rows can induce bit-flips in\nneighboring rows. To mitigate this, state-of-the-art host-side RowHammer\nmitigations typically rely on shared counters or tracking structures. While\nthese optimizations benefit benign applications, they are vulnerable to\nPerformance Attacks (Perf-Attacks), where adversaries exploit shared structures\nto reduce DRAM bandwidth for co-running benign applications by increasing DRAM\naccesses for RowHammer counters or triggering repetitive refreshes required for\nthe early reset of structures, significantly degrading performance.\n  In this paper, we propose secure hashing mechanisms to thwart adversarial\nattempts to capture the mapping of shared structures. We propose DAPPER, a\nnovel low-cost tracker resilient to Perf-Attacks even at ultra-low RowHammer\nthresholds. We first present a secure hashing template in the form of DAPPER-S.\nWe then develop DAPPER-H, an enhanced version of DAPPER-S, incorporating\ndouble-hashing, novel reset strategies, and mitigative refresh techniques. Our\nsecurity analysis demonstrates the effectiveness of DAPPER-H against both\nRowHammer and Perf-Attacks. Experiments with 57 workloads from SPEC2006,\nSPEC2017, TPC, Hadoop, MediaBench, and YCSB show that, even at an ultra-low\nRowHammer threshold of 500, DAPPER-H incurs only a 0.9% slowdown in the\npresence of Perf-Attacks while using only 96KB of SRAM per 32GB of DRAM memory."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-594",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11724",
    "b_title":[
      "Proportion of Nilpotent Subgroups in Finite Groups and Their Properties"
    ],
    "b_abstract":[
      "This work introduces and investigates the function $J(G) =\n\\frac{\\text{Nil}(G)}{L(G)}$, where $\\text{Nil}(G)$ denotes the number of\nnilpotent subgroups and $L(G)$ the total number of subgroups of a finite group\n$G$. The function $J(G)$, defined over the interval $(0,1]$, serves as a tool\nto analyze structural patterns in finite groups, particularly within\nnon-nilpotent families such as supersolvable and dihedral groups. Analytical\nresults demonstrate the product density of $J(G)$ values in $(0,1]$,\nhighlighting its distribution across products of dihedral groups. Additionally,\na probabilistic analysis was conducted, and based on extensive computational\nsimulations, it was conjectured that the sample mean of $J(G)$ values converges\nin distribution to the standard normal distribution, in accordance with the\nCentral Limit Theorem, as the sample size increases. These findings expand the\nunderstanding of multiplicative functions in group theory, offering novel\ninsights into the structural and probabilistic behavior of finite groups."
    ],
    "b_categories":[
      [
        "math.GR",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15233",
    "c_title":[
      "Cosmic distance duality after DESI 2024 data release and dark energy\n  evolution"
    ],
    "c_abstract":[
      "The cosmic distance duality relates the angular-diameter and luminosity\ndistances and its possible violation may puzzle the standard cosmological\nmodel. This appears particularly interesting in view of the recent results\nfound by the DESI Collaboration, suggesting that a dynamical dark energy\nscenario seems to be favored than a genuine cosmological constant. Accordingly,\nwe take into account possible violations by considering four different\nparameterizations, namely: a Taylor expansion around $z\\simeq 0$, a\nslightly-departing logarithmic correction, a (1;2) Pad\\'e rational series to\nheal the convergence problem and a Chebyshev polynomial expansion, reducing\n\\emph{de facto} the systematic errors associated with the analysis. We test\neach of them in a model-independent (-dependent) way, by working out\nMonte-Carlo Markov chain analyses, employing the B\\'ezier interpolation of the\nHubble rate $H(z)$ for the model-independent approach while assuming the flat\n(non-flat) $\\Lambda$CDM and $\\omega_0\\omega_1$CDM models, motivating the latter\nparadigm in view of the DESI findings. Subsequently, we explore two analyses,\nemploying observational Hubble data, galaxy clusters from the Sunyaev-Zeldovich\neffect and type Ia supernovae, investigating the impact of the DESI data\ncatalog, first including then excluding the entire data set. Afterwards, we\nadopt statistical model selection criteria to assess the statistically favored\ncosmological model. Our results suggest \\emph{no violation} of the cosmic\ndistance duality. While a slight spatial curvature cannot be entirely excluded,\nthe preferred cosmological model remains the flat $\\Lambda$CDM background, even\nwhen incorporating DESI data. Finally, concerning the Hubble tension, our\nfindings match the Riess estimates, as BAO data points are excluded."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-595",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17990",
    "b_title":[
      "SUNAR: Semantic Uncertainty based Neighborhood Aware Retrieval for\n  Complex QA"
    ],
    "b_abstract":[
      "Complex question-answering (QA) systems face significant challenges in\nretrieving and reasoning over information that addresses multi-faceted queries.\nWhile large language models (LLMs) have advanced the reasoning capabilities of\nthese systems, the bounded-recall problem persists, where procuring all\nrelevant documents in first-stage retrieval remains a challenge. Missing\npertinent documents at this stage leads to performance degradation that cannot\nbe remedied in later stages, especially given the limited context windows of\nLLMs which necessitate high recall at smaller retrieval depths. In this paper,\nwe introduce SUNAR, a novel approach that leverages LLMs to guide a\nNeighborhood Aware Retrieval process. SUNAR iteratively explores a neighborhood\ngraph of documents, dynamically promoting or penalizing documents based on\nuncertainty estimates from interim LLM-generated answer candidates. We validate\nour approach through extensive experiments on two complex QA datasets. Our\nresults show that SUNAR significantly outperforms existing retrieve-and-reason\nbaselines, achieving up to a 31.84% improvement in performance over existing\nstate-of-the-art methods for complex QA."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09922",
    "c_title":[
      "Quasi-projective manifolds uniformized by Carath\\'eodory hyperbolic\n  manifolds and hyperbolicity of their subvarieties"
    ],
    "c_abstract":[
      "Let $M$ be a Carath\\'eodory hyperbolic complex manifold. We show that $M$\nsupports a real-analytic bounded strictly plurisubharmonic function. If $M$ is\nalso complete K\\\"ahler, we show that $M$ admits the Bergman metric. When $M$ is\nstrongly Carath\\'eodory hyperbolic and is the universal covering of a\nquasi-projective manifold $X$, the Bergman metric can be estimated in terms of\na Poincar\\'e type metric on $X$. It is also proved that any quasi-projective\n(resp. projective) subvariety of $X$ is of log-general type (resp. general\ntype), a result consistent with a conjecture of Lang."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-596",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09950",
    "b_title":[
      "Mixing rate exponent of planar Fortuin-Kasteleyn percolation"
    ],
    "b_abstract":[
      "Duminil-Copin and Manolescu (2022) recently proved the scaling relations for\nplanar Fortuin-Kasteleyn (FK) percolation. In particular, they showed that the\none-arm exponent and the mixing rate exponent are sufficient to derive the\nother near-critical exponents. The scaling limit of critical FK percolation is\nconjectured to be a conformally invariant random collection of loops called the\nconformal loop ensemble (CLE). In this paper, we define the CLE analog of the\nmixing rate exponent. Assuming the convergence of FK percolation to CLE, we\nshow that the mixing rate exponent for FK percolation agrees with that of CLE.\nWe prove that the CLE$_\\kappa$ mixing rate exponent equals $\\frac{3\n\\kappa}{8}-1$, thereby answering Question 3 of Duminil-Copin and Manolescu\n(2022). The derivation of the CLE exponent is based on an exact formula for the\nRadon-Nikodym derivative between the marginal laws of the odd-level and\neven-level CLE loops, which is obtained from the coupling between Liouville\nquantum gravity and CLE."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04394",
    "c_title":[
      "Energy barriers for small electron polaron hopping in bismuth ferrite\n  from first principles"
    ],
    "c_abstract":[
      "Evidence from first-principles calculations indicates that excess electrons\nin BiFeO3 form small polarons with energy levels deep inside the electronic\nband gap. Hence, n-type electronic transport could occur by hopping of small\nelectron polarons rather than by band-like transport. Here, by means of\nfirst-principles calculations, small electron polaron hopping in BiFeO3 is\ninvestigated. Both bulk BiFeO3 and a typical ferroelectric domain wall, the\nneutral 71{\\deg} domain wall, are considered. The latter is included to account\nfor experimental observations of electrical conductivity at domain walls in\notherwise insulating ferroelectrics. The object of this study is to shed light\non the intrinsic electron conduction in rhombohedral BiFeO3 and the effect of\npristine neutral ferroelectric domain walls. The computed energy barriers for\nsmall electron polaron hopping are of the order of the thermal energy at room\ntemperature, both in bulk and within the neutral 71{\\deg} domain wall. The\ndomain wall is found to act as a two-dimensional trap for small electron\npolarons with a trap depth of about two to three times the thermal energy at\nroom temperature. Based on these findings, the intrinsic n-type mobility and\ndiffusion constant in BiFeO3 at room temperature are estimated, and\nexperimental conductivity data for BiFeO3 are discussed."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-597",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13506",
    "b_title":[
      "Reproducing NevIR: Negation in Neural Information Retrieval"
    ],
    "b_abstract":[
      "Negation is a fundamental aspect of human communication, yet it remains a\nchallenge for Language Models (LMs) in Information Retrieval (IR). Despite the\nheavy reliance of modern neural IR systems on LMs, little attention has been\ngiven to their handling of negation. In this study, we reproduce and extend the\nfindings of NevIR, a benchmark study that revealed most IR models perform at or\nbelow the level of random ranking when dealing with negation. We replicate\nNevIR's original experiments and evaluate newly developed state-of-the-art IR\nmodels. Our findings show that a recently emerging category - listwise Large\nLanguage Model (LLM) rerankers - outperforms other models but still\nunderperforms human performance. Additionally, we leverage ExcluIR, a benchmark\ndataset designed for exclusionary queries with extensive negation, to assess\nthe generalizability of negation understanding. Our findings suggest that\nfine-tuning on one dataset does not reliably improve performance on the other,\nindicating notable differences in their data distributions. Furthermore, we\nobserve that only cross-encoders and listwise LLM rerankers achieve reasonable\nperformance across both negation tasks."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12005",
    "c_title":[
      "A note on the relations between mixture models, maximum-likelihood and\n  entropic optimal transport"
    ],
    "c_abstract":[
      "This note aims to demonstrate that performing maximum-likelihood estimation\nfor a mixture model is equivalent to minimizing over the parameters an optimal\ntransport problem with entropic regularization. The objective is pedagogical:\nwe seek to present this already known result in a concise and hopefully simple\nmanner. We give an illustration with Gaussian mixture models by showing that\nthe standard EM algorithm is a specific block-coordinate descent on an optimal\ntransport loss."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-598",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15299",
    "b_title":[
      "Sensitive bioassay with an ultra-large dynamic range via microlaser\n  ensemble quenching"
    ],
    "b_abstract":[
      "We present a bioassay platform that leverages the lasing threshold\ndistribution in a microlaser ensemble (ME), consisting of hundreds of\nindividual microlasers, to measure analyte concentrations in solution. An ME is\nformed by placing dye-doped microbeads in a micro Fabry-Perot cavity.\nMicrobeads are surface modified with biorecognition molecules to capture\nanalytes, while the quenchers resulting from the presence of the analytes on\nthe microbeads' surfaces increase the lasing thresholds of microlasers. Since\nthe number of analytes varies from one microbead (or microlaser) to another due\nto the randomness in binding processes, a distribution of the analytes (and\nhence the quenchers) in the ME is created, which in turn leads to a lasing\nthreshold distribution in the ME. Experimentally, multiple pumping energy\ndensities are used to probe the lasing threshold distribution. A theoretical\nmodel is developed to map the lasing threshold distribution to analyte\ndistribution in the ME, and then to recover the analyte concentration in\nsolution. Using streptavidin and interleukin-6 as a model system, our platform\nachieves a detection limit of 0.1 pg\/mL and a dynamic range exceeding five\norders of magnitude, showing that the ME quenching method can provide a high\nsensitivity with a superior dynamic range."
    ],
    "b_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02345",
    "c_title":[
      "Optimal Subspace Inference for the Laplace Approximation of Bayesian\n  Neural Networks"
    ],
    "c_abstract":[
      "Subspace inference for neural networks assumes that a subspace of their\nparameter space suffices to produce a reliable uncertainty quantification. In\nthis work, we mathematically derive the optimal subspace model to a Bayesian\ninference scenario based on the Laplace approximation. We demonstrate\nempirically that, in the optimal case, often a fraction of parameters less than\n1% is sufficient to obtain a reliable estimate of the full Laplace\napproximation. Since the optimal solution is derived, we can evaluate all other\nsubspace models against a baseline. In addition, we give an approximation of\nour method that is applicable to larger problem settings, in which the optimal\nsolution is not computable, and compare it to existing subspace models from the\nliterature. In general, our approximation scheme outperforms previous work.\nFurthermore, we present a metric to qualitatively compare different subspace\nmodels even if the exact Laplace approximation is unknown."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-599",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12769",
    "b_title":[
      "How Much Do LLMs Hallucinate across Languages? On Multilingual\n  Estimation of LLM Hallucination in the Wild"
    ],
    "b_abstract":[
      "In the age of misinformation, hallucination -- the tendency of Large Language\nModels (LLMs) to generate non-factual or unfaithful responses -- represents the\nmain risk for their global utility. Despite LLMs becoming increasingly\nmultilingual, the vast majority of research on detecting and quantifying LLM\nhallucination are (a) English-centric and (b) focus on machine translation (MT)\nand summarization, tasks that are less common ``in the wild'' than open\ninformation seeking. In contrast, we aim to quantify the extent of LLM\nhallucination across languages in knowledge-intensive long-form question\nanswering. To this end, we train a multilingual hallucination detection model\nand conduct a large-scale study across 30 languages and 6 open-source LLM\nfamilies. We start from an English hallucination detection dataset and rely on\nMT to generate (noisy) training data in other languages. We also manually\nannotate gold data for five high-resource languages; we then demonstrate, for\nthese languages, that the estimates of hallucination rates are similar between\nsilver (LLM-generated) and gold test sets, validating the use of silver data\nfor estimating hallucination rates for other languages. For the final rates\nestimation, we build a knowledge-intensive QA dataset for 30 languages with\nLLM-generated prompts and Wikipedia articles as references. We find that, while\nLLMs generate longer responses with more hallucinated tokens for\nhigher-resource languages, there is no correlation between length-normalized\nhallucination rates of languages and their digital representation. Further, we\nfind that smaller LLMs exhibit larger hallucination rates than larger models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11275",
    "c_title":[
      "Higher Order Approximation Rates for ReLU CNNs in Korobov Spaces"
    ],
    "c_abstract":[
      "This paper investigates the $L_p$ approximation error for higher order\nKorobov functions using deep convolutional neural networks (CNNs) with ReLU\nactivation. For target functions having a mixed derivative of order m+1 in each\ndirection, we improve classical approximation rate of second order to (m+1)-th\norder (modulo a logarithmic factor) in terms of the depth of CNNs. The key\ningredient in our analysis is approximate representation of high-order sparse\ngrid basis functions by CNNs. The results suggest that higher order\nexpressivity of CNNs does not severely suffer from the curse of dimensionality."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-600",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15216",
    "b_title":[
      "Nanoscale resolved mapping of the dipole emission of hBN color centers\n  with a scattering-type scanning near-field optical microscope"
    ],
    "b_abstract":[
      "Color centers in hexagonal boron nitride (hBN) are promising candidates as\nquantum light sources for future technologies. In this work, we utilize a\nscattering-type near-field optical microscope (s-SNOM) to study the\nphotoluminescence (PL) emission characteristics of such quantum emitters in\nmetalorganic vapor phase epitaxy grown hBN. On the one hand, we demonstrate\ndirect near-field optical excitation and emission through interaction with the\nnanofocus of the tip resulting in a sub-diffraction limited tip-enhanced PL\nhotspot. On the other hand, we show that indirect excitation and emission via\nscattering from the tip significantly increases the recorded PL intensity. This\ndemonstrates that the tip-assisted PL (TAPL) process efficiently guides the\ngenerated light to the detector. We apply the TAPL method to map the in-plane\ndipole orientations of the hBN color centers on the nanoscale. This work\npromotes the widely available s-SNOM approach to applications in the quantum\ndomain including characterization and optical control."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17909",
    "c_title":[
      "FactFlow: Automatic Fact Sheet Generation and Customization from Tabular\n  Dataset via AI Chain Design & Implementation"
    ],
    "c_abstract":[
      "With the proliferation of data across various domains, there is a critical\ndemand for tools that enable non-experts to derive meaningful insights without\ndeep data analysis skills. To address this need, existing automatic fact sheet\ngeneration tools offer heuristic-based solutions to extract facts and generate\nstories. However, they inadequately grasp the semantics of data and struggle to\ngenerate narratives that fully capture the semantics of the dataset or align\nthe fact sheet with specific user needs. Addressing these shortcomings, this\npaper introduces \\tool, a novel tool designed for the automatic generation and\ncustomisation of fact sheets. \\tool applies the concept of collaborative AI\nworkers to transform raw tabular dataset into comprehensive, visually\ncompelling fact sheets. We define effective taxonomy to profile AI worker for\nspecialised tasks. Furthermore, \\tool empowers users to refine these fact\nsheets through intuitive natural language commands, ensuring the final outputs\nalign closely with individual preferences and requirements. Our user evaluation\nwith 18 participants confirms that \\tool not only surpasses state-of-the-art\nbaselines in automated fact sheet production but also provides a positive user\nexperience during customization tasks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-601",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09731",
    "b_title":[
      "Results from an Einstein@Home search for continuous gravitational waves\n  from Cassiopeia A and Vela Jr. using LIGO O2 data"
    ],
    "b_abstract":[
      "We conduct two searches for continuous, nearly monochromatic gravitational\nwaves originating from the central compact objects in the supernova remnants\nCassiopeia A and Vela Jr. using public LIGO data. The search for Cassiopeia A\ntargets signal frequencies between 20 Hz and 400 Hz; the Vela Jr. search\nbetween 400 Hz and 1700 Hz, and both investigate the broadest set of waveforms\never considered with highly sensitive deterministic search methods. Above 1500\nHz the Vela Jr. search is the most sensitive carried out thus far, improving on\nprevious results by over 300\\%. Above 976 Hz these results improve on existing\nones by 50\\%. In all we investigate over $10^{18}$ waveforms, leveraging the\ncomputational power donated by thousands of Einstein@Home volunteers. We\nperform a 4-stage follow-up on more than 6 million waveforms. None of the\nconsidered waveforms survives the follow-up scrutiny, indicating no significate\ndetection candidate. Our null results constrain the maximum amplitude of\ncontinuous signals as a function of signal frequency from the targets. The most\nstringent 90\\% confidence upper limit for Cas A is $h_0^{90 \\%}\\approx\n7.3\\times10^{-26}$ near 200 Hz, and for Vela Jr. it is $h_0^{90 \\%}\\approx\n8.9\\times10^{-26}$ near 400 Hz. Translated into upper limits on the ellipticity\nand r-mode amplitude, our results probe physically interesting regions: for\nexample the ellipticity of Vela Jr. is constrained to be smaller than $10^{-7}$\nacross the frequency band, with a tighter constraint of less than\n$2\\times10^{-8}$ at the highest frequencies."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12377",
    "c_title":[
      "Alignment and Adversarial Robustness: Are More Human-Like Models More\n  Secure?"
    ],
    "c_abstract":[
      "Representational alignment refers to the extent to which a model's internal\nrepresentations mirror biological vision, offering insights into both neural\nsimilarity and functional correspondence. Recently, some more aligned models\nhave demonstrated higher resiliency to adversarial examples, raising the\nquestion of whether more human-aligned models are inherently more secure. In\nthis work, we conduct a large-scale empirical analysis to systematically\ninvestigate the relationship between representational alignment and adversarial\nrobustness. We evaluate 118 models spanning diverse architectures and training\nparadigms, measuring their neural and behavioral alignment and engineering task\nperformance across 106 benchmarks as well as their adversarial robustness via\nAutoAttack. Our findings reveal that while average alignment and robustness\nexhibit a weak overall correlation, specific alignment benchmarks serve as\nstrong predictors of adversarial robustness, particularly those that measure\nselectivity towards texture or shape. These results suggest that different\nforms of alignment play distinct roles in model robustness, motivating further\ninvestigation into how alignment-driven approaches can be leveraged to build\nmore secure and perceptually-grounded vision models."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-602",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04098",
    "b_title":[
      "A Detection of Circumgalactic Dust at Megaparsec Scales with Maximum\n  Likelihood Estimation"
    ],
    "b_abstract":[
      "One of the more surprising astrophysical discoveries of the last decade has\nbeen the presence of enormous quantities of dust at megaparsec distances from\ngalaxies, which has important implications for galaxy evolution, the\ncircumgalactic and intergalactic medium, and observational cosmology. In this\nwork, we present a novel method for studying these vast halos of circumgalactic\ndust: a maximum-likelihood estimator for dust-induced extinction of background\ngalaxies. This estimator can accommodate a broad range of archival photometric\ndata and can incorporate different dust reddening prescriptions, making it\napplicable to diverse galaxy types and redshifts. We apply the estimator to the\nredMaGiC catalog of luminous red galaxies, selected for their tight dispersion\nin color and well-constrained photometric redshifts, and measure the resulting\nextinction as a function of projected distance from WISExSuperCOSMOS and\nredMaGiC foreground galaxies. We detect significant dust-induced extinction\nprofiles extending to at least 1 megaparsec from galactic disks, with\nnoticeable differences between star-forming and quiescent galaxies:\nstar-forming galaxies exhibit a pronounced rise in extinction within the inner\n50 kiloparsecs and a steep decline beyond 1 megaparsec, while the quiescent\ngalaxies host little dust in the inner halo but have detectable extinction out\nto 30 megaparsecs. We test the robustness of our results using star catalogs\nand inverted foreground and background samples and find no evidence for\nsignificant systematic error. Our approach provides a powerful tool for\nstudying the interplay between circumgalactic dust, galaxy evolution, and\nlarge-scale structure, with potential applications in a number of astrophysical\nsubfields."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09662",
    "c_title":[
      "Generalizable Cervical Cancer Screening via Large-scale Pretraining and\n  Test-Time Adaptation"
    ],
    "c_abstract":[
      "Cervical cancer is a leading malignancy in female reproductive system. While\nAI-assisted cytology offers a cost-effective and non-invasive screening\nsolution, current systems struggle with generalizability in complex clinical\nscenarios. To address this issue, we introduced Smart-CCS, a generalizable\nCervical Cancer Screening paradigm based on pretraining and adaptation to\ncreate robust and generalizable screening systems. To develop and validate\nSmart-CCS, we first curated a large-scale, multi-center dataset named CCS-127K,\nwhich comprises a total of 127,471 cervical cytology whole-slide images\ncollected from 48 medical centers. By leveraging large-scale self-supervised\npretraining, our CCS models are equipped with strong generalization capability,\npotentially generalizing across diverse scenarios. Then, we incorporated\ntest-time adaptation to specifically optimize the trained CCS model for complex\nclinical settings, which adapts and refines predictions, improving real-world\napplicability. We conducted large-scale system evaluation among various\ncohorts. In retrospective cohorts, Smart-CCS achieved an overall area under the\ncurve (AUC) value of 0.965 and sensitivity of 0.913 for cancer screening on 11\ninternal test datasets. In external testing, system performance maintained high\nat 0.950 AUC across 6 independent test datasets. In prospective cohorts, our\nSmart-CCS achieved AUCs of 0.947, 0.924, and 0.986 in three prospective\ncenters, respectively. Moreover, the system demonstrated superior sensitivity\nin diagnosing cervical cancer, confirming the accuracy of our cancer screening\nresults by using histology findings for validation. Interpretability analysis\nwith cell and slide predictions further indicated that the system's\ndecision-making aligns with clinical practice. Smart-CCS represents a\nsignificant advancement in cancer screening across diverse clinical contexts."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV",
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-603",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17363",
    "b_title":[
      "Assessment various control methods a digital copy of enterprise by\n  integral indicator"
    ],
    "b_abstract":[
      "The difficulty of assessing the state lies in a little predictable change in\nthe dimension of a dynamic system under the influence of internal changes and\nenvironmental parameters. In the work, the state of such a system is estimated\nby the method of integral indicators. The application of the method of integral\nindicators allowed us to evaluate the activity of an enterprise. In the present\nwork, the method of integrated indicators is used to assess the control of a\ndigital copy (enterprise)."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07663",
    "c_title":[
      "Enhancing Talent Employment Insights Through Feature Extraction with LLM\n  Finetuning"
    ],
    "c_abstract":[
      "This paper explores the application of large language models (LLMs) to\nextract nuanced and complex job features from unstructured job postings. Using\na dataset of 1.2 million job postings provided by AdeptID, we developed a\nrobust pipeline to identify and classify variables such as remote work\navailability, remuneration structures, educational requirements, and work\nexperience preferences. Our methodology combines semantic chunking,\nretrieval-augmented generation (RAG), and fine-tuning DistilBERT models to\novercome the limitations of traditional parsing tools. By leveraging these\ntechniques, we achieved significant improvements in identifying variables often\nmislabeled or overlooked, such as non-salary-based compensation and inferred\nremote work categories. We present a comprehensive evaluation of our fine-tuned\nmodels and analyze their strengths, limitations, and potential for scaling.\nThis work highlights the promise of LLMs in labor market analytics, providing a\nfoundation for more accurate and actionable insights into job data."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-604",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19893",
    "b_title":[
      "A Multiple Transferable Neural Network Method with Domain Decomposition\n  for Elliptic Interface Problems"
    ],
    "b_abstract":[
      "The transferable neural network (TransNet) is a two-layer shallow neural\nnetwork with pre-determined and uniformly distributed neurons in the hidden\nlayer, and the least-squares solvers can be particularly used to compute the\nparameters of its output layer when applied to the solution of partial\ndifferential equations. In this paper, we integrate the TransNet technique with\nthe nonoverlapping domain decomposition and the interface conditions to develop\na novel multiple transferable neural network (Multi-TransNet) method for\nsolving elliptic interface problems, which typically contain discontinuities in\nboth solutions and their derivatives across interfaces. We first propose an\nempirical formula for the TransNet to characterize the relationship between the\nradius of the domain-covering ball, the number of hidden-layer neurons, and the\noptimal neuron shape. In the Multi-TransNet method, we assign each subdomain\none distinct TransNet with an adaptively determined number of hidden-layer\nneurons to maintain the globally uniform neuron distribution across the entire\ncomputational domain, and then unite all the subdomain TransNets together by\nincorporating the interface condition terms into the loss function. The\nempirical formula is also extended to the Multi-TransNet and further employed\nto estimate appropriate neuron shapes for the subdomain TransNets, greatly\nreducing the parameter tuning cost. Additionally, we propose a normalization\napproach to adaptively select the weighting parameters for the terms in the\nloss function. Ablation studies and extensive experiments with comparison tests\non different types of elliptic interface problems with low to high contrast\ndiffusion coefficients in two and three dimensions are carried out to\nnumerically demonstrate the superior accuracy, efficiency, and robustness of\nthe proposed Multi-TransNet method."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16124",
    "c_title":[
      "Effects of tau-neutrino detection on non-standard interactions at DUNE\n  with a short discussion on the nature of neutrino mixing"
    ],
    "c_abstract":[
      "In this paper, we investigate the effects of $\\nu_\\tau$ and $\\bar{\\nu}_\\tau$\ndetection at the DUNE far detector on the experiment's sensitivity to\nNon-Standard Interactions (NSI) in neutrino propagation. We show that the\nstrongest observable NSI effect in the $\\nu_\\tau$ and $\\bar{\\nu}_\\tau$\nappearance probabilities arises from $\\epsilon_{\\mu\\tau}$. We have studied the\nhierarchy sensitivity, CP violation sensitivity and octant sensitivity of DUNE\nfrom $\\nu_\\tau$ and $\\bar{\\nu}_\\tau$ appearance channels in presence of NSI. We\nhave also studied the detection sensitivity of NSI phases and the future\nconstaints on NSI parameters from the tau neutrino appearance channels in DUNE.\nAdditionally, we examine the role of $\\nu_\\tau$ detection in constraining the\nunitary nature of the PMNS matrix. These studies emphasize the importance of\nincorporating $\\nu_\\tau$ detection in long-baseline neutrino experiments such\nas DUNE."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-605",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18262",
    "b_title":[
      "Enhanced State Estimation for turbulent flows combining Ensemble Data\n  Assimilation and Machine Learning"
    ],
    "b_abstract":[
      "A novel strategy is proposed to improve the accuracy of state estimation and\nreconstruction from low-fidelity models and sparse data from sensors. This\nstrategy combines ensemble Data Assimilation (DA) and Machine Learning (ML)\ntools, exploiting their complementary features. ML techniques rely on the data\nproduced by DA methods during analysis phases to train physics-informed\ncorrective algorithms, which are then coupled with the low-fidelity models when\ndata from sensors is unavailable. The methodology is validated via the analysis\nof the turbulent plane channel flow test case for $Re_\\tau \\approx 550$. Here,\nthe low-fidelity model consists of coarse-grained simulations coupled with the\nImmersed Boundary Method (IBM), while observation is sampled by a highly\nrefined body-fitted calculation. The analysis demonstrates the capabilities of\nthe algorithm based on DA and ML to accurately predict the flow features with\nsignificantly reduced computational costs. This approach exhibits potential for\nfuture synergistic applications of DA and ML, leveraging the robustness and\nefficiency of ML models alongside the physical interpretability ensured by DA\nalgorithms."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06152",
    "c_title":[
      "The Value of Information in Human-AI Decision-making"
    ],
    "c_abstract":[
      "Humans and AIs are often paired on decision tasks with the expectation of\nachieving complementary performance, where the combination of human and AI\noutperforms either one alone. However, how to improve performance of a human-AI\nteam is often not clear without knowing more about what particular information\nand strategies each agent employs. We provide a decision-theoretic framework\nfor characterizing the value of information -- and consequently, opportunities\nfor agents to better exploit available information -- in AI-assisted decision\nworkflow. We demonstrate the use of the framework for model selection,\nempirical evaluation of human-AI performance, and explanation design. We\npropose a novel information-based instance-level explanation technique that\nadapts a conventional saliency-based explanation to explain information value\nin decision making."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-606",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03616",
    "b_title":[
      "Noncooperative Equilibrium Selection via a Trading-based Auction"
    ],
    "b_abstract":[
      "Noncooperative multi-agent systems often face coordination challenges due to\nconflicting preferences among agents. In particular, agents acting in their own\nself-interest can settle on different equilibria, leading to suboptimal\noutcomes or even safety concerns. We propose an algorithm named trading auction\nfor consensus (TACo), a decentralized approach that enables noncooperative\nagents to reach consensus without communicating directly or disclosing private\nvaluations. TACo facilitates coordination through a structured trading-based\nauction, where agents iteratively select choices of interest and provably reach\nan agreement within an a priori bounded number of steps. A series of numerical\nexperiments validate that the termination guarantees of TACo hold in practice,\nand show that TACo achieves a median performance that minimizes the total cost\nacross all agents, while allocating resources significantly more fairly than\nbaseline approaches."
    ],
    "b_categories":[
      [
        "cs.GT",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04732",
    "c_title":[
      "Coherent spin dynamics in ensembles of randomly oriented singly charged\n  colloidal nanoplatelets and nanocrystals"
    ],
    "c_abstract":[
      "We present a theoretical study of the pump-probe Faraday rotation and\nellipticity signals in ensembles of uniaxially anisotropic CdSe nanoplatelets\nand nanocrystals. We use the Faraday rotation mechanism based on the excitation\nof negative heavy hole trions for a magnetic field applied in the Voigt\ngeometry. Three types of ensembles with typical spatial distributions of the\norientation of the anisotropy axis with respect to the direction of light\npropagation are considered. Faraday rotation and ellipticity signals are\nmodeled for excitation by single and repeated pump pulses, taking into account\nthe anisotropy of the electron g-factor. We show that spin dephasing caused by\nthe electron g-factor anisotropy and the arbitrary orientation of nanoplatelets\nor nanocrystals result only in partial damping of oscillation amplitude in\ncontrast to the dephasing caused by the dispersion of the electron g-factor in\nthe ensemble. We demonstrate that regardless of the g-factor anisotropy degree\nthe oscillation frequency of the Faraday rotation and ellipticity signals for a\nrandomly oriented ensemble is determined by the transverse electron g-factor\ncomponent."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-607",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06663",
    "b_title":[
      "Energy-Adaptive Checkpoint-Free Intermittent Inference for Low Power\n  Energy Harvesting Systems"
    ],
    "b_abstract":[
      "Deep neural network (DNN) inference in energy harvesting (EH) devices poses\nsignificant challenges due to resource constraints and frequent power\ninterruptions. These power losses not only increase end-to-end latency, but\nalso compromise inference consistency and accuracy, as existing checkpointing\nand restore mechanisms are prone to errors. Consequently, the quality of\nservice (QoS) for DNN inference on EH devices is severely impacted. In this\npaper, we propose an energy-adaptive DNN inference mechanism capable of\ndynamically transitioning the model into a low-power mode by reducing\ncomputational complexity when harvested energy is limited. This approach\nensures that end-to-end latency requirements are met. Additionally, to address\nthe limitations of error-prone checkpoint-and-restore mechanisms, we introduce\na checkpoint-free intermittent inference framework that ensures consistent,\nprogress-preserving DNN inference during power failures in energy-harvesting\nsystems."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10449",
    "c_title":[
      "Measure transport via pseudo-cones"
    ],
    "c_abstract":[
      "For the solution of the Gauss image problem for pseudo-cones, which can be\nconsidered as a measure transport problem for certain measures on the sphere,\nwe give a new proof, using a special case of Kantorovich duality."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-608",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01902",
    "b_title":[
      "H$\\alpha$-X-ray Surface Brightness Correlation for Filaments in Cooling\n  Flow Clusters"
    ],
    "b_abstract":[
      "Massive galaxies in cooling flow clusters display clear evidence of feedback\nfrom Active Galactic Nuclei (AGN). Joint X-ray and radio observations have\nshown that AGN radio jets push aside the surrounding hot gas and form cavities\nin the hot intracluster medium (ICM). These systems host complex,\nkiloparsec-scale, multiphase filamentary structures, from warm ionized (10,000\nK) to cold molecular ($<$100 K). These striking clumpy filaments are believed\nto be a natural outcome of thermally unstable cooling from the hot ICM, likely\ntriggered by feedback processes while contributing to feeding the AGN via\nChaotic Cold Accretion (CCA). However, the detailed constraints on the\nformation mechanism of the filaments are still uncertain, and the connection\nbetween the different gas phases has to be fully unveiled. By leveraging a\nsample of seven X-ray bright cooling-flow clusters, we have discovered a tight\npositive correlation between the X-ray surface brightness and the H$\\alpha$\nsurface brightness of the filaments over two orders of magnitude, as also found\nin stripped tails."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03153",
    "c_title":[
      "Segment Anything Model for Zero-shot Single Particle Tracking in Liquid\n  Phase Transmission Electron Microscopy"
    ],
    "c_abstract":[
      "Liquid phase transmission electron microscopy (LPTEM) offers an unparalleled\ncombination of spatial and temporal resolution, making it a promising tool for\nsingle particle tracking at the nanoscale. However, the absence of a\nstandardized framework for identifying and tracking nanoparticles in noisy\nLPTEM videos has impeded progress in the field to develop this technique as a\nsingle particle tracking tool. To address this, we leveraged Segment Anything\nModel 2 (SAM 2), released by Meta, which is a foundation model developed for\nsegmenting videos and images. Here, we demonstrate that SAM 2 can successfully\nsegment LPTEM videos in a zero-shot manner and without requiring fine-tuning.\nBuilding on this capability, we introduce SAM4EM, a comprehensive framework\nthat integrates promptable video segmentation with particle tracking and\nstatistical analysis, providing an end-to-end LPTEM analysis framework for\nsingle particle tracking. SAM4EM achieves nearly 50-fold higher accuracy in\nsegmenting and analyzing LPTEM videos compared to state-of-the-art methods,\npaving the way for broader applications of LPTEM in nanoscale imaging."
    ],
    "c_categories":[
      [
        "cs.CV",
        "physics.data-an"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-609",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13892",
    "b_title":[
      "Formation and evolution of new primordial open cluster groups:\n  Feedback-driven star formation"
    ],
    "b_abstract":[
      "The formation mechanisms of open cluster (OCs) groups remain unclear due to\nlimited sample sizes and data precision. Recent advancements in Gaia\nastrometric data provide an unprecedented opportunity to study OC groups in\ngreater detail. This study aims to extend the sample of OC groups and\ninvestigate their formation and evolution mechanisms, with a focus on the role\nof stellar feedback in triggering star formation. We identify four new OC\ngroups based on Gaia data, whose member OCs are spatially proximate and\nkinematically coherent. Their age spreads are consistent with the timescale of\ncontinuous star formation, suggesting that their member OCs formed sequentially\nfrom the same molecular cloud. N-body simulation results further reveal that\nthese groups will gradually disperse, evolving into independent OCs. By\nanalyzing the correlation between OC ages and their separation from potential\nSN explosion sites, we predict SN explosion regions around the birthplaces of\nOC groups. The strong correlation between OC ages and predicted SN explosion\nsites supports a supernova-triggered star formation scenario. Additionally, we\ntrace pulsar (PSR) orbits to examine their association with these regions. We\ndetected three PSRs near Group 1 and 26 PSRs near Group 2, whose birthplaces\nalign with the predicted SN explosions regions. The presence of PSRs associated\nwith OC groups provides additional observational evidence for SN explosions in\nthis region, further supporting a supernova-triggered star formation scenario\nfor G1 and G2. We propose that multiple SN explosions in a short period\ntriggered the formation of Group 1 and Group 2, reinforcing the hierarchical\nstar formation model. These results highlight the multi-scale interactions\ndriving star and OC formation and provide new insights into the role of stellar\nfeedback in shaping OC groups."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12118",
    "c_title":[
      "Regularized dynamical parametric approximation of stiff evolution\n  problems"
    ],
    "c_abstract":[
      "Evolutionary deep neural networks have emerged as a rapidly growing field of\nresearch. This paper studies numerical integrators for such and other classes\nof nonlinear parametrizations $ u(t) = \\Phi(\\theta(t)) $, where the evolving\nparameters $\\theta(t)$ are to be computed. The primary focus is on tackling the\nchallenges posed by the combination of stiff evolution problems and irregular\nparametrizations, which typically arise with neural networks, tensor networks,\nflocks of evolving Gaussians, and in further cases of overparametrization. We\npropose and analyse regularized parametric versions of the implicit Euler\nmethod and higher-order implicit Runge--Kutta methods for the time integration\nof the parameters in nonlinear approximations to evolutionary partial\ndifferential equations and large systems of stiff ordinary differential\nequations. At each time step, an ill-conditioned nonlinear optimization problem\nis solved approximately with a few regularized Gauss--Newton iterations. Error\nbounds for the resulting parametric integrator are derived by relating the\ncomputationally accessible Gauss--Newton iteration for the parameters to the\ncomputationally inaccessible Newton iteration for the underlying non-parametric\ntime integration scheme. The theoretical findings are supported by numerical\nexperiments that are designed to show key properties of the proposed parametric\nintegrators."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-610",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11137",
    "b_title":[
      "Clustering indications before the Mw7.0 2020 Samos, Greece, main shock\n  as revealed in an equivalent dimensions space"
    ],
    "b_abstract":[
      "The transformation to equivalent dimensions that offers a novel approach for\ninvestigating earthquake clustering was engaged to analyze the preparatory\nphase of the 2020 Samos, Greece, Mw7.0 main shock. The analysis considered\nearthquakes that occurred between 2006 and October 2020, covering an area\nextended three times the length of the main rupture. Each earthquake was\nparameterized by its magnitude, the interevent time (interval since the\nprevious earthquake), and the interevent spatial distance (distance between the\nepicenters of consecutive earthquakes). Transforming these parameters into\nequivalent dimensions allowed them to be directly compared. The degree of\nclustering was quantified using the average distance between earthquakes in\nthis transformed parameter space, calculated within consecutive 100 events data\nwindows. Results revealed a distinct pattern, the average distance was\nincreasing steadily during the twelve year period before the main shock. These\ntemporal changes in the average distance were driven by a systematic evolution\nof earthquake clustering in the used parameter space. Beginning from a\ntwo-cluster system, when the distance was minimal, the clustering development\ncontinued along two branches and ended before the main shock with the formation\nof five earthquake clusters of different characteristics."
    ],
    "b_categories":[
      [
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06533",
    "c_title":[
      "Hierarchical Multi-Objective Optimization for Precise Performance Design\n  of Closed-Chain Legged Mechanisms"
    ],
    "c_abstract":[
      "Over the past decades, the performance design of closed-chain legged\nmechanisms (CLMs) has not been adequately addressed. Most existing design\nmethodologies have predominantly relied on trajectory synthesis, which\ninadvertently prioritizes less critical performance aspects. This study\nproposes a hierarchical multi-objective optimization strategy to address this\nlimitation. First, the numerical performance-trajectory mapping is derived\nbased on a foot-ground contact model, aiming to decouple the performance\ncharacteristics. Subsequently, a hierarchical optimization strategy is employed\nfor two CLM design scenarios: In trajectory shape-constrained scenarios, a\ncoarse-to-fine optimization process, integrating Fourier descriptors, refines\nthe design from overall shape to local features. In scenarios without\ntrajectory shape constraints, a stepwise optimization process is proposed for\nreconfigurable CLMs to transition from primary motion to auxiliary motion. The\nrobustness of the proposed design strategy is validated across three\nconfigurations and seven algorithms. The effectiveness of the proposed design\nstrategy is verified by comparison with other existing CLM design methods. The\napplicability of the proposed strategy is confirmed through simulation and\nprototype experiments. The results demonstrate that the hierarchical strategy\neffectively addresses the challenges of precise performance design in CLMs. Our\nwork provides a general framework for the CLM design and offers insights for\nthe optimization design of other closed-chain linkages."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-611",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03996",
    "b_title":[
      "Power-over-fiber and distributed acoustic sensing hybridization in\n  single fiber channel"
    ],
    "b_abstract":[
      "The efficient and independent operation of power-over-fiber (PoF) and\ndistributed acoustic sensing (DAS) has been demonstrated using standard\nsingle-mode fiber (SSMF). A transmission optical power efficiency (OPTE) of\n6.67% was achieved over an 11.8 km fiber link, supporting both power delivery\nand distributed optical fiber sensing (DOFS). To minimize cross-talk, the\nsystem separates the power and sensing channels by a 40 THz bandwidth. In the\nexperiment, the power and sensing light wavelengths are 1064 nm (continuous)\nand 1550 nm (pulsed), respectively. As the transmitted optical power increased\nfrom 0 W to 2.13 W, the DAS system successfully localized vibration sources and\nreconstructed phase information, confirming its ability to operate under high\noptical power. The reported scheme verifies the possibility of constructing the\nsensing-energy hybrid network based on conventional optical fiber with the\nadvantages of flexibility and low cost."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07767",
    "c_title":[
      "Killing and homothetic initial data for general hypersurfaces"
    ],
    "c_abstract":[
      "In this paper we present a collection of general identities relating the\ndeformation tensor $\\mathcal{K}=\\mathcal{L}_{\\eta}g$ of an arbitrary vector\nfield $\\eta$ with the tensor $\\Sigma=\\mathcal{L}_{\\eta}\\nabla$ on an abstract\nhypersurface $\\mathcal{H}$ of any causal character. As an application we\nestablish necessary conditions on $\\mathcal{H}$ for the existence of a\nhomothetic Killing vector on the spacetime where $\\mathcal{H}$ is embedded. The\nsufficiency of these conditions is then analysed in three specific settings.\nFor spacelike hypersurfaces, we recover the well-known homothetic KID equations\n[10, 13] in the language of hypersurface data. For two intersecting null\nhypersurfaces, we generalize a previous result [7], valid for Killings, to the\nhomothetic case and, moreover, demonstrate that the equations can be formulated\nsolely in terms of the initial data for the characteristic Cauchy problem,\ni.e., without involving a priori spacetime quantities. This puts the\ncharacteristic KID problem on equal footing with the spacelike KID problem.\nFurthermore, we highlight the versatility of the formalism by addressing the\nhomothetic KID problem for smooth spacelike-characteristic initial data. Other\ninitial value problems, such as the spacelike-characteristic with corners, can\nbe approached similarly."
    ],
    "c_categories":[
      [
        "gr-qc",
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-612",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17933",
    "b_title":[
      "Experience Retrieval-Augmentation with Electronic Health Records Enables\n  Accurate Discharge QA"
    ],
    "b_abstract":[
      "To improve the reliability of Large Language Models (LLMs) in clinical\napplications, retrieval-augmented generation (RAG) is extensively applied to\nprovide factual medical knowledge. However, beyond general medical knowledge\nfrom open-ended datasets, clinical case-based knowledge is also critical for\neffective medical reasoning, as it provides context grounded in real-world\npatient experiences. Motivated by this, we propose Experience Retrieval\nAugmentation - ExpRAG framework based on Electronic Health Record (EHR), aiming\nto offer the relevant context from other patients' discharge reports. ExpRAG\nperforms retrieval through a coarse-to-fine process, utilizing an EHR-based\nreport ranker to efficiently identify similar patients, followed by an\nexperience retriever to extract task-relevant content for enhanced medical\nreasoning. To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset\nwith 1,280 discharge-related questions across diagnosis, medication, and\ninstruction tasks. Each problem is generated using EHR data to ensure realistic\nand challenging scenarios. Experimental results demonstrate that ExpRAG\nconsistently outperforms a text-based ranker, achieving an average relative\nimprovement of 5.2%, highlighting the importance of case-based knowledge for\nmedical reasoning."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02546",
    "c_title":[
      "Electric Penrose process and collisions of particles near\n  five-dimensional weakly charged Schwarzschild black hole"
    ],
    "c_abstract":[
      "The particle dynamics and the electric Penrose process for the\nfive-dimensional weakly charged Schwarzschild black hole are studied. Firstly,\nthe horizon structure and the effective potential for the test particle are\nexplored. The radial profile of the effective potential is plotted for\ndifferent values of the BH charge. Then, we studied energy efficiency using the\nconservation laws for energy, angular momentum, and charge of particles. The\nappropriate plots were obtained and compared with the results for the\nfour-dimensional Schwarzschild BH. Moreover, we obtained the constraints on\nmass and charge of black hole to accelerate protons of different energies\n($1$-$10^{9}$ GeV). Finally, collisions of electrically charged particles near\nthe horizon of the five-dimensional Schwarzschild BH are studied. We\ndemonstrated the radial dependence of the center of mass energy for different\nvalues of the angular momentum and charge of the particles together with the BH\ncharge."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-613",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12663",
    "b_title":[
      "Trajectories of light beams in a Kerr metric: the influence of the\n  rotation of an observer on the shadow of a black hole"
    ],
    "b_abstract":[
      "This paper investigates the trajectories of light beams in a Kerr metric,\nwhich describes the gravitational field in the neighborhood of a rotating black\nhole. After reduction by cyclic coordinates, this problem reduces to analysis\nof a Hamiltonian system with two degrees of freedom. A bifurcation diagram is\nconstructed and a classification is made of the types of trajectories of the\nsystem according to the values of first integrals. Relations describing the\nboundary of the shadow of the black hole are obtained for a stationary observer\nwho rotates with an arbitrary angular velocity about the axis of rotation of\nthe black hole."
    ],
    "b_categories":[
      [
        "gr-qc",
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02639",
    "c_title":[
      "Xavier: Toward Better Coding Assistance in Authoring Tabular Data\n  Wrangling Scripts"
    ],
    "c_abstract":[
      "Data analysts frequently employ code completion tools in writing custom\nscripts to tackle complex tabular data wrangling tasks. However, existing tools\ndo not sufficiently link the data contexts such as schemas and values with the\ncode being edited. This not only leads to poor code suggestions, but also\nfrequent interruptions in coding processes as users need additional code to\nlocate and understand relevant data. We introduce Xavier, a tool designed to\nenhance data wrangling script authoring in computational notebooks. Xavier\nmaintains users' awareness of data contexts while providing data-aware code\nsuggestions. It automatically highlights the most relevant data based on the\nuser's code, integrates both code and data contexts for more accurate\nsuggestions, and instantly previews data transformation results for easy\nverification. To evaluate the effectiveness and usability of Xavier, we\nconducted a user study with 16 data analysts, showing its potential to\nstreamline data wrangling scripts authoring."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-614",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13681",
    "b_title":[
      "A projection method for particle resampling"
    ],
    "b_abstract":[
      "Particle discretizations of partial differential equations are advantageous\nfor high-dimensional kinetic models in phase space due to their better\nscalability than continuum approaches with respect to dimension. Complex\nprocesses collectively referred to as \\textit{particle noise} hamper long-time\nsimulations with particle methods. One approach to address this problem is\nparticle mesh adaptivity or remapping, known as \\textit{particle resampling}.\nThis paper introduces a resampling method that projects particles to and from a\n(finite element) function space. The method is simple; using standard sparse\nlinear algebra and finite element techniques, it can adapt to almost any set of\nnew particle locations and preserves all moments up to the order of polynomial\nrepresented exactly by the continuum function space.\n  This work is motivated by the Vlasov-Maxwell-Landau model of magnetized\nplasmas with up to six dimensions, $3X$ in physical space and $3V$ in velocity\nspace, and is developed in the context of a $1X$ + $1V$ Vlasov-Poisson model of\nLandau damping with logically regular particle and continuum phase space grids.\nThe evaluation codes are publicly available, along with the data and\nreproducibility artifacts, and developed in the PETSc numerical library\n(petsc.org)."
    ],
    "b_categories":[
      [
        "physics.comp-ph",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02079",
    "c_title":[
      "Online Clustering of Dueling Bandits"
    ],
    "c_abstract":[
      "The contextual multi-armed bandit (MAB) is a widely used framework for\nproblems requiring sequential decision-making under uncertainty, such as\nrecommendation systems. In applications involving a large number of users, the\nperformance of contextual MAB can be significantly improved by facilitating\ncollaboration among multiple users. This has been achieved by the clustering of\nbandits (CB) methods, which adaptively group the users into different clusters\nand achieve collaboration by allowing the users in the same cluster to share\ndata. However, classical CB algorithms typically rely on numerical reward\nfeedback, which may not be practical in certain real-world applications. For\ninstance, in recommendation systems, it is more realistic and reliable to\nsolicit preference feedback between pairs of recommended items rather than\nabsolute rewards. To address this limitation, we introduce the first\n\"clustering of dueling bandit algorithms\" to enable collaborative\ndecision-making based on preference feedback. We propose two novel algorithms:\n(1) Clustering of Linear Dueling Bandits (COLDB) which models the user reward\nfunctions as linear functions of the context vectors, and (2) Clustering of\nNeural Dueling Bandits (CONDB) which uses a neural network to model complex,\nnon-linear user reward functions. Both algorithms are supported by rigorous\ntheoretical analyses, demonstrating that user collaboration leads to improved\nregret bounds. Extensive empirical evaluations on synthetic and real-world\ndatasets further validate the effectiveness of our methods, establishing their\npotential in real-world applications involving multiple users with\npreference-based feedback."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-615",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04572",
    "b_title":[
      "Social Imitation Dynamics of Vaccination Driven by Vaccine Effectiveness\n  and Beliefs"
    ],
    "b_abstract":[
      "Declines in vaccination coverage for vaccine-preventable diseases, such as\nmeasles and chickenpox, have enabled their surprising comebacks and pose\nsignificant public health challenges in the wake of growing vaccine hesitancy.\nVaccine opt-outs and refusals are often fueled by beliefs concerning\nperceptions of vaccine effectiveness and exaggerated risks. Here, we quantify\nthe impact of competing beliefs -- vaccine-averse versus vaccine-neutral -- on\nsocial imitation dynamics of vaccination, alongside the epidemiological\ndynamics of disease transmission. These beliefs may be pre-existing and fixed,\nor coevolving attitudes. This interplay among beliefs, behaviors, and disease\ndynamics demonstrates that individuals are not perfectly rational; rather, they\nbase their vaccine uptake decisions on beliefs, personal experiences, and\nsocial influences. We find that the presence of a small proportion of fixed\nvaccine-averse beliefs can significantly exacerbate the vaccination dilemma,\nmaking the tipping point in the hysteresis loop more sensitive to changes in\nindividuals' perceived costs of vaccination and vaccine effectiveness. However,\nin scenarios where competing beliefs spread concurrently with vaccination\nbehavior, their double-edged impact can lead to self-correction and alignment\nbetween vaccine beliefs and behaviors. The results show that coevolution of\nvaccine beliefs and behaviors makes populations more sensitive to abrupt\nchanges in perceptions of vaccine cost and effectiveness compared to scenarios\nwithout beliefs. Our work provides valuable insights into harnessing the social\ncontagion of even vaccine-neutral attitudes to overcome vaccine hesitancy."
    ],
    "b_categories":[
      [
        "physics.soc-ph",
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Physics"
      ]
    ],
    "c_id":"2501.15499",
    "c_title":[
      "One Model to Forecast Them All and in Entity Distributions Bind Them"
    ],
    "c_abstract":[
      "Probabilistic forecasting in power systems often involves multi-entity\ndatasets like households, feeders, and wind turbines, where generating reliable\nentity-specific forecasts presents significant challenges. Traditional\napproaches require training individual models for each entity, making them\ninefficient and hard to scale. This study addresses this problem using\nGUIDE-VAE, a conditional variational autoencoder that allows entity-specific\nprobabilistic forecasting using a single model. GUIDE-VAE provides flexible\noutputs, ranging from interpretable point estimates to full probability\ndistributions, thanks to its advanced covariance composition structure. These\ndistributions capture uncertainty and temporal dependencies, offering richer\ninsights than traditional methods. To evaluate our GUIDE-VAE-based forecaster,\nwe use household electricity consumption data as a case study due to its\nmulti-entity and highly stochastic nature. Experimental results demonstrate\nthat GUIDE-VAE outperforms conventional quantile regression techniques across\nkey metrics while ensuring scalability and versatility. These features make\nGUIDE-VAE a powerful and generalizable tool for probabilistic forecasting\ntasks, with potential applications beyond household electricity consumption."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-616",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09954",
    "b_title":[
      "AIRCHITECT v2: Learning the Hardware Accelerator Design Space through\n  Unified Representations"
    ],
    "b_abstract":[
      "Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02691",
    "c_title":[
      "Temperature-dependent radiative lifetime measurement of the\n  $6^1\\Sigma_g^+(v=9,J=31)$ state of sodium molecules"
    ],
    "c_abstract":[
      "We report the measurement of radiative lifetimes of the\n$6^1\\Sigma_g^+(v=9,J=31)$ state of gas-phase molecular sodium using a\nhigh-resolution double-resonance spectroscopy. Measurements were done using a\ntime-correlated photon counting technique at various pressures and\ntemperatures. Lifetimes were extracted from extrapolations to the zero buffer\ngas pressure, called Stern-Volmer plot, and the temperature-dependence of the\nradiative lifetimes were measured over a temperature range from 593 K to 653 K.\nOur result agrees well within the error limits with the theoretical\ncalculations."
    ],
    "c_categories":[
      [
        "physics.atm-clus",
        "physics.atom-ph",
        "physics.chem-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-617",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09016",
    "b_title":[
      "Soliton resuscitations: asymmetric revivals of the breathing mode of an\n  atomic bright soliton in a harmonic trap"
    ],
    "b_abstract":[
      "We study the collective modes of an atomic bright soliton realised in a\nquasi-one-dimensional Bose-Einstein condensate, using Bogoliubov-de Gennes\ntheory. In particular we focus on the breathing mode of the soliton, which is\nnot a single linearized normal mode but a common component of many modes, and\ntherefore decays within a $t^{-1\/2}$ envelope due to dispersion. If the soliton\nis held in the center of a harmonic trap, we show that the breathing amplitude\nrevives periodically, as atoms shed from the vibrating soliton oscillate in the\ntrap, and return. After each revival the breathing amplitude again decays, and\nthis cycle repeats every trap half-period. The amplitude envelope of these\nbreathing revivals shows a curious asymmetry, however, with a gradual increase\nin breathing followed by sudden drop in breathing amplitude that becomes more\nand more pronounced in later revivals. We explain this asymmetrical revival\npattern by deriving a close analytical approximation to the Bogoliubov-de\nGennes frequency spectrum, and offer this coherent Bogoliubov-de Gennes\nphenomenon as a background against which to compare possible quantum many-body\neffects, including decoherence over trap-period time scales."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10081",
    "c_title":[
      "AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial\n  Attention Disruption"
    ],
    "c_abstract":[
      "The outstanding capability of diffusion models in generating high-quality\nimages poses significant threats when misused by adversaries. In particular, we\nassume malicious adversaries exploiting diffusion models for inpainting tasks,\nsuch as replacing a specific region with a celebrity. While existing methods\nfor protecting images from manipulation in diffusion-based generative models\nhave primarily focused on image-to-image and text-to-image tasks, the challenge\nof preventing unauthorized inpainting has been rarely addressed, often\nresulting in suboptimal protection performance. To mitigate inpainting abuses,\nwe propose ADVPAINT, a novel defensive framework that generates adversarial\nperturbations that effectively disrupt the adversary's inpainting tasks.\nADVPAINT targets the self- and cross-attention blocks in a target diffusion\ninpainting model to distract semantic understanding and prompt interactions\nduring image generation. ADVPAINT also employs a two-stage perturbation\nstrategy, dividing the perturbation region based on an enlarged bounding box\naround the object, enhancing robustness across diverse masks of varying shapes\nand sizes. Our experimental results demonstrate that ADVPAINT's perturbations\nare highly effective in disrupting the adversary's inpainting tasks,\noutperforming existing methods; ADVPAINT attains over a 100-point increase in\nFID and substantial decreases in precision."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-618",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14669",
    "b_title":[
      "Reinforcement Learning-Based Neuroadaptive Control of Robotic\n  Manipulators under Deferred Constraints"
    ],
    "b_abstract":[
      "This paper presents a reinforcement learning-based neuroadaptive control\nframework for robotic manipulators operating under deferred constraints. The\nproposed approach improves traditional barrier Lyapunov functions by\nintroducing a smooth constraint enforcement mechanism that offers two key\nadvantages: (i) it minimizes control effort in unconstrained regions and\nprogressively increases it near constraints, improving energy efficiency, and\n(ii) it enables gradual constraint activation through a prescribed-time\nshifting function, allowing safe operation even when initial conditions violate\nconstraints. To address system uncertainties and improve adaptability, an\nactor-critic reinforcement learning framework is employed. The critic network\nestimates the value function, while the actor network learns an optimal control\npolicy in real time, enabling adaptive constraint handling without requiring\nexplicit system modeling. Lyapunov-based stability analysis guarantees the\nboundedness of all closed-loop signals. The effectiveness of the proposed\nmethod is validated through numerical simulations."
    ],
    "b_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05489",
    "c_title":[
      "Singularity of mean curvature flow with bounded mean curvature and Morse\n  index"
    ],
    "c_abstract":[
      "We study the multiplicity of the singularity of mean curvature flow with\nbounded mean curvature and Morse index. For $3\\leq n\\leq 6$, we show that\neither the mean curvature or the Morse index blows up at the first singular\ntime for a closed smooth embedded mean curvature flow in $\\mathbb{R}^{n+1}$."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-619",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18627",
    "b_title":[
      "A Radiance Field Loss for Fast and Simple Emissive Surface\n  Reconstruction"
    ],
    "b_abstract":[
      "We present a fast and simple technique to convert images into an emissive\nsurface-based scene representation. Building on existing emissive volume\nreconstruction algorithms, we introduce a subtle yet impactful modification of\nthe loss function requiring changes to only a few lines of code: instead of\nintegrating the radiance field along rays and supervising the resulting images,\nwe project the training images into the scene to directly supervise the\nspatio-directional radiance field.\n  The primary outcome of this change is the complete removal of alpha blending\nand ray marching from the image formation model, instead moving these steps\ninto the loss computation. In addition to promoting convergence to surfaces,\nthis formulation assigns explicit semantic meaning to 2D subsets of the\nradiance field, turning them into well-defined emissive surfaces. We finally\nextract a level set from this representation, which results in a high-quality\nemissive surface model.\n  Our method retains much of the speed and quality of the baseline algorithm.\nFor instance, a suitably modified variant of Instant~NGP maintains comparable\ncomputational efficiency, while achieving an average PSNR that is only 0.1 dB\nlower. Most importantly, our method generates explicit surfaces in place of an\nexponential volume, doing so with a level of simplicity not seen in prior work."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20751",
    "c_title":[
      "Terminating Hybrid Tableaus for Ordered Models"
    ],
    "c_abstract":[
      "Hybrid logic extends modal logic with special propositions called nominals,\neach of which is true at only one state in a model. This enables us to describe\nsome properties of binary relations, such as irreflexivity and anti-symmetry,\nwhich are essential to treat partial orders. We present terminating tableau\ncalculi complete with respect to models whose accessibility relations are\nstrictly partially ordered, unbounded strictly partially ordered, and partially\nordered."
    ],
    "c_categories":[
      [
        "cs.LO",
        "math.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-620",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05908",
    "b_title":[
      "Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo"
    ],
    "b_abstract":[
      "In image processing, solving inverse problems is the task of finding\nplausible reconstructions of an image that was corrupted by some (usually\nknown) degradation model. Commonly, this process is done using a generative\nimage model that can guide the reconstruction towards solutions that appear\nnatural. The success of diffusion models over the last few years has made them\na leading candidate for this task. However, the sequential nature of diffusion\nmodels makes this conditional sampling process challenging. Furthermore, since\ndiffusion models are often defined in the latent space of an autoencoder, the\nencoder-decoder transformations introduce additional difficulties. Here, we\nsuggest a novel sampling method based on sequential Monte Carlo (SMC) in the\nlatent space of diffusion models. We use the forward process of the diffusion\nmodel to add additional auxiliary observations and then perform an SMC sampling\nas part of the backward process. Empirical evaluations on ImageNet and FFHQ\nshow the benefits of our approach over competing methods on various inverse\nproblem tasks."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17818",
    "c_title":[
      "Gleaning gravitational amplitudes -- a double copy for canceling\n  dilatons"
    ],
    "c_abstract":[
      "Scattering amplitudes in general relativity can be conveniently computed\nusing the double copy, which relates them to Yang-Mills amplitudes. However,\nunwanted dilatons are sourced by massive scalar matter, which must be removed\nfrom the double copy in order to match the long range gravitational\ninteractions. In this paper, we study how to automatically cancel out the\ndilatons by finding a suitable double-copy prescription in terms of\ngauge-theory fields, effectively treating the new contributions as ghosts that\nsubtract out the unwanted states. At tree level, we find that an asymmetric\ndouble copy can reproduce the dilaton graphs in general dimension, which we\nexplicitly verify up to six external massive scalars. Considering a one-loop\nfour-point example, the same asymmetric double copy needs to be supplemented by\nthe subtraction of bubble graphs that originate both from the axion and a\nresidual dilaton term."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-621",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13199",
    "b_title":[
      "The Role of GitHub Copilot on Software Development: A Perspec-tive on\n  Productivity, Security, Best Practices and Future Directions"
    ],
    "b_abstract":[
      "GitHub Copilot is transforming software development by automating tasks and\nboosting productivity through AI-driven code generation. In this paper, we\ncon-duct a literature survey to synthesize insights on Copilot's impact on\nproductivity and security. We review academic journal databases, industry\nreports, and official docu-mentation to highlight key findings and challenges.\nWhile Copilot accelerates coding and prototyping, concerns over security\nvulnerabilities and intellectual property risks persist. Drawing from the\nliterature, we provide a perspective on best practices and future directions\nfor responsible AI adoption in software engineering, offering action-able\ninsights for developers and organizations to integrate Copilot effectively\nwhile maintaining high standards of quality and security."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06936",
    "c_title":[
      "Full C- and L-band tunable erbium-doped integrated lasers via scalable\n  manufacturing"
    ],
    "c_abstract":[
      "Erbium (Er) ions are the gain medium of choice for fiber-based amplifiers and\nlasers, offering a long excited-state lifetime, slow gain relaxation, low\namplification nonlinearity and noise, and temperature stability compared to\nsemiconductor-based platforms. Recent advances in ultra-low-loss silicon\nnitride (Si$_3$N$_4$) photonic integrated circuits, combined with ion\nimplantation, have enabled the realization of high-power on-chip Er amplifiers\nand lasers with performance comparable to fiber-based counterparts, supporting\ncompact photonic systems. Yet, these results are limited by the high (2 MeV)\nimplantation beam energy required for tightly confined Si$_3$N$_4$ waveguides\n(700 nm height), preventing volume manufacturing of Er-doped photonic\nintegrated circuits. Here, we overcome these limitations and demonstrate the\nfirst fully wafer-scale, foundry-compatible Er-doped photonic integrated\ncircuit-based tunable lasers. Using 200 nm-thick Si$_3$N$_4$ waveguides, we\nreduce the ion beam energy requirement to below 500 keV, enabling efficient\nwafer-scale implantation with an industrial 300 mm ion implanter. We\ndemonstrate a laser wavelength tuning range of 91 nm, covering nearly the\nentire optical C- and L-bands, with fiber-coupled output power reaching 36 mW\nand an intrinsic linewidth of 95 Hz. The temperature-insensitive properties of\nerbium ions allowed stable laser operation up to 125$^{\\circ}$C and lasing with\nless than 15 MHz drift for over 6 hours at room temperature using a remote\nfiber pump. The fully scalable, low-cost fabrication of Er-doped waveguide\nlasers opens the door for widespread adoption in coherent communications,\nLiDAR, microwave photonics, optical frequency synthesis, and free-space\ncommunications."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-622",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17813",
    "b_title":[
      "Connectedness: a dimension of security bug severity assessment for\n  measuring uncertainty"
    ],
    "b_abstract":[
      "Current frameworks for evaluating security bug severity, such as the Common\nVulnerability Scoring System (CVSS), prioritize the ratio of exploitability to\nimpact. This paper suggests that the above approach measures the \"known knowns\"\nbut inadequately addresses the \"known unknowns\" especially when there exist\nmultiple possible exploit paths and side effects, which introduce significant\nuncertainty. This paper introduces the concept of connectedness, which measures\nhow strongly a security bug is connected with different entities, thereby\nreflecting the uncertainty of impact and the exploit potential. This work\nhighlights the critical but underappreciated role connectedness plays in\nseverity assessments."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14364",
    "c_title":[
      "Localization and entanglement entropy in the Discrete Non-Linear\n  Schr\\\"odinger Equation"
    ],
    "c_abstract":[
      "In this work we perform an accurate numerical study of the very peculiar\nthermodynamic properties of the localized high-energy phase of the Discrete\nNon-Linear Schr\\\"odinger Equation (DNLSE). A numerical sampling of the\nmicrocanonical ensemble done by means of Hamiltonian dynamics reveals a new and\nsubtle relation between the presence of the localized phase and a non-trivial\nbehaviour of entanglement entropy. Our finding that the entanglement entropy\ngrows as $S_{\\text{ent}}(N) \\sim \\log(N)$ beautifully encodes the lack of\nadditivity in the DNLSE non-thermal localized phase and reveals how a property\nso far believed peculiar of purely quantum systems may characterize even\ncertain classical frameworks."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-623",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03116",
    "b_title":[
      "Poincar\\'{e}-Birkhoff-Witt Theorems in Higher Algebra"
    ],
    "b_abstract":[
      "We extend the classical Poincar\\'e-Birkhoff-Witt theorem to higher algebra by\nestablishing a version that applies to spectral Lie algebras. We deduce this\nstatement from a basic relation between operads in spectra: the commutative\noperad is the quotient of the associative operad by a right action of the\nspectral Lie operad. This statement, in turn, is a consequence of a fundamental\nrelation between different $\\mathbb{E}_n$-operads, which we articulate and\nprove. We deduce a variant of the Poincar\\'{e}--Birkhoff--Witt theorem for\nrelative enveloping algebras of $\\mathbb{E}_n$-algebras. Our methods also give\na simple construction and description of the higher enveloping\n$\\mathbb{E}_n$-algebras of a spectral Lie algebra."
    ],
    "b_categories":[
      [
        "math.AT",
        "math.CT",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00173",
    "c_title":[
      "Lifting by Gaussians: A Simple, Fast and Flexible Method for 3D Instance\n  Segmentation"
    ],
    "c_abstract":[
      "We introduce Lifting By Gaussians (LBG), a novel approach for open-world\ninstance segmentation of 3D Gaussian Splatted Radiance Fields (3DGS). Recently,\n3DGS Fields have emerged as a highly efficient and explicit alternative to\nNeural Field-based methods for high-quality Novel View Synthesis. Our 3D\ninstance segmentation method directly lifts 2D segmentation masks from SAM\n(alternately FastSAM, etc.), together with features from CLIP and DINOv2,\ndirectly fusing them onto 3DGS (or similar Gaussian radiance fields such as\n2DGS). Unlike previous approaches, LBG requires no per-scene training, allowing\nit to operate seamlessly on any existing 3DGS reconstruction. Our approach is\nnot only an order of magnitude faster and simpler than existing approaches; it\nis also highly modular, enabling 3D semantic segmentation of existing 3DGS\nfields without requiring a specific parametrization of the 3D Gaussians.\nFurthermore, our technique achieves superior semantic segmentation for 2D\nsemantic novel view synthesis and 3D asset extraction results while maintaining\nflexibility and efficiency. We further introduce a novel approach to evaluate\nindividually segmented 3D assets from 3D radiance field segmentation methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-624",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15196",
    "b_title":[
      "Detectability of oxygen fugacity regimes in the magma ocean world 55\n  Cancri e at high spectral resolution"
    ],
    "b_abstract":[
      "Ultra-short Period exoplanets (USPs) like 55 Cnc e, hosting dayside magma\noceans, present unique opportunities to study surface-atmosphere interactions.\nThe composition of a vaporised mineral atmosphere enveloping the dayside is\ndictated by that of the surface magma ocean, which in turn is sensitive to its\noxygen fugacity ($f$O$_2$). Observability estimations and characterisation of\nthe atmospheric emission of 55 Cnc e have mostly remained limited to low\nspectral resolution space-based studies. Here, we aim to examine ground-based\nhigh-resolution observabilities of a diverse set of mineral atmospheres\nproduced across a grid of mantle $f$O$_2$s varying over 12 orders of magnitude.\nWe assume a Bulk Silicate Earth mantle composition and a substellar dayside\ntemperature of T = 2500K in the near infrared wavelength (NIR) region. This\nspectral range is often featureless for this class of atmospheres at\nlow-resolution. Coupling our newly developed simulator for synthesising\nrealistic observations from high-resolution ground-based spectrographs (Ratri)\nto a pre-developed high-resolution cross-correlation spectroscopy (HRCCS)\nanalysis pipeline (Upamana), we find that this array of mineral atmospheres\nwould all be detectable with 11 hours of observing time of the dayside of 55\nCnc e with CARMENES and each individual scenario can be correctly\ndifferentiated within 1$\\sigma$. Our analysis is readily able to distinguish\nbetween a planet with an Earth-like redox state (with $f$O$_2$ $\\sim$3.5\nlog$_{10}$ units above the iron-w\\\"ustite, IW buffer) from a Mercury-like\nplanet ($f$O$_2$ $\\sim$5 log$_{10}$ units below IW). We thus conclude that the\nHRCCS technique holds promise for cataloguing the diversity of redox states\namong the rocky exoplanetary population."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07532",
    "c_title":[
      "Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with\n  Diffusion"
    ],
    "c_abstract":[
      "Machine learning methods have been shown to be effective for weather\nforecasting, based on the speed and accuracy compared to traditional numerical\nmodels. While early efforts primarily concentrated on deterministic\npredictions, the field has increasingly shifted toward probabilistic\nforecasting to better capture the forecast uncertainty. Most machine\nlearning-based models have been designed for global-scale predictions, with\nonly limited work targeting regional or limited area forecasting, which allows\nmore specialized and flexible modeling for specific locations. This work\nintroduces Diffusion-LAM, a probabilistic limited area weather model leveraging\nconditional diffusion. By conditioning on boundary data from surrounding\nregions, our approach generates forecasts within a defined area. Experimental\nresults on the MEPS limited area dataset demonstrate the potential of\nDiffusion-LAM to deliver accurate probabilistic forecasts, highlighting its\npromise for limited-area weather prediction."
    ],
    "c_categories":[
      [
        "cs.LG",
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-625",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05388",
    "b_title":[
      "Modular programming of interaction and geometric specificity enables\n  assembly of complex DNA origami nanostructures"
    ],
    "b_abstract":[
      "We present a modular DNA origami design approach to address the challenges of\nassembling geometrically complex nanoscale structures, including those with\nnonuniform Gaussian curvature. This approach features a core structure that\ncompletely conserves the scaffold routing across different designs and\npreserves more than 70% of the DNA staples between designs, dramatically\nreducing both cost and effort, while enabling precise and independent\nprogramming of subunit interactions and binding angles through adjustable\noverhang lengths and sequences. Using cryogenic electron microscopy, gel\nelectrophoresis, and coarse-grained molecular dynamics simulations, we validate\na set of robust design rules. We demonstrate the method's utility by assembling\na variety of self-limiting structures, including anisotropic shells with\ncontrolled inter-subunit interactions and curvature, and a toroid with globally\nvarying curvature. Our strategy is both cost-effective and versatile, providing\na promising and efficient solution for the synthetic fabrication of complex\nnanostructures."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14796",
    "c_title":[
      "A New Benchmark for Online Learning with Budget-Balancing Constraints"
    ],
    "c_abstract":[
      "The adversarial Bandit with Knapsack problem is a multi-armed bandits problem\nwith budget constraints and adversarial rewards and costs. In each round, a\nlearner selects an action to take and observes the reward and cost of the\nselected action. The goal is to maximize the sum of rewards while satisfying\nthe budget constraint. The classical benchmark to compare against is the best\nfixed distribution over actions that satisfies the budget constraint in\nexpectation. Unlike its stochastic counterpart, where rewards and costs are\ndrawn from some fixed distribution (Badanidiyuru et al., 2018), the adversarial\nBwK problem does not admit a no-regret algorithm for every problem instance due\nto the \"spend-or-save\" dilemma (Immorlica et al., 2022).\n  A key problem left open by existing works is whether there exists a weaker\nbut still meaningful benchmark to compare against such that no-regret learning\nis still possible. In this work, we present a new benchmark to compare against,\nmotivated both by real-world applications such as autobidding and by its\nunderlying mathematical structure. The benchmark is based on the Earth Mover's\nDistance (EMD), and we show that sublinear regret is attainable against any\nstrategy whose spending pattern is within EMD $o(T^2)$ of any sub-pacing\nspending pattern.\n  As a special case, we obtain results against the \"pacing over windows\"\nbenchmark, where we partition time into disjoint windows of size $w$ and allow\nthe benchmark strategies to choose a different distribution over actions for\neach window while satisfying a pacing budget constraint. Against this\nbenchmark, our algorithm obtains a regret bound of\n$\\tilde{O}(T\/\\sqrt{w}+\\sqrt{wT})$. We also show a matching lower bound, proving\nthe optimality of our algorithm in this important special case. In addition, we\nprovide further evidence of the necessity of the EMD condition for obtaining a\nsublinear regret."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-626",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03077",
    "b_title":[
      "MochiSwarm: A testbed for robotic blimps in realistic environments"
    ],
    "b_abstract":[
      "Testing aerial robots in tasks such as pickup-and-delivery and surveillance\nsignificantly benefits from high energy efficiency and scalability of the\ndeployed robotic system. This paper presents MochiSwarm, an open-source testbed\nof light-weight robotic blimps, ready for multi-robot operation without\nexternal localization. We introduce the system design in hardware, software,\nand perception, which capitalizes on modularity, low cost, and light weight.\nThe hardware allows for rapid modification, which enables the integration of\nadditional sensors to enhance autonomy for different scenarios. The software\nframework supports different actuation models and communication between the\nbase station and multiple blimps. The detachable perception module allows\nindependent blimps to perform tasks that involve detection and autonomous\nactuation. We showcase a differential-drive module as an example, of which the\nautonomy is enabled by visual servoing using the perception module. A case\nstudy of pickup-and-delivery tasks with up to 12 blimps highlights the autonomy\nof the MochiSwarm without external infrastructures."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03327",
    "c_title":[
      "Is In-Context Universality Enough? MLPs are Also Universal In-Context"
    ],
    "c_abstract":[
      "The success of transformers is often linked to their ability to perform\nin-context learning. Recent work shows that transformers are universal in\ncontext, capable of approximating any real-valued continuous function of a\ncontext (a probability measure over $\\mathcal{X}\\subseteq \\mathbb{R}^d$) and a\nquery $x\\in \\mathcal{X}$. This raises the question: Does in-context\nuniversality explain their advantage over classical models? We answer this in\nthe negative by proving that MLPs with trainable activation functions are also\nuniversal in-context. This suggests the transformer's success is likely due to\nother factors like inductive bias or training stability."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "cs.NE",
        "math.NA",
        "math.PR",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-627",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13676",
    "b_title":[
      "Certified Robustness Under Bounded Levenshtein Distance"
    ],
    "b_abstract":[
      "Text classifiers suffer from small perturbations, that if chosen\nadversarially, can dramatically change the output of the model. Verification\nmethods can provide robustness certificates against such adversarial\nperturbations, by computing a sound lower bound on the robust accuracy.\nNevertheless, existing verification methods incur in prohibitive costs and\ncannot practically handle Levenshtein distance constraints. We propose the\nfirst method for computing the Lipschitz constant of convolutional classifiers\nwith respect to the Levenshtein distance. We use these Lipschitz constant\nestimates for training 1-Lipschitz classifiers. This enables computing the\ncertified radius of a classifier in a single forward pass. Our method, LipsLev,\nis able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and\n$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude\nfaster than existing approaches. We believe our work can open the door to more\nefficient verification in the text domain."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16772",
    "c_title":[
      "Two-Photon Resonance Fluorescence in a Three-Level Ladder-Type Atom"
    ],
    "c_abstract":[
      "In this work, we consider a three-level ladder-type atom driven by a coherent\nfield, inspired by the experimental work of Gasparinetti et al. [Phys. Rev. A\n100, 033802 (2019)]. When driven on two-photon resonance, the atom is excited\ninto its highest energy state $| f \\rangle$ by absorbing two photons\nsimultaneously. The atom then de-excites via a cascaded decay $| f \\rangle\n\\rightarrow | e \\rangle \\rightarrow | g \\rangle$. Here we present a theoretical\nstudy of the atomic fluorescence spectrum where, upon strong coherent driving,\nthe spectrum exhibits seven distinct frequencies corresponding to transitions\namongst the atomic dressed states. We characterize the quantum statistics of\nthe emitted photons by investigating the second-order correlation functions of\nthe emitted field. We do so by considering the total field emitted by the atom\nand focusing on each of the dressed-state components, taking in particular a\nsecular-approximation and deriving straightforward, transparent analytic\nexpressions for the second-order auto- and cross-correlations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-628",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15171",
    "b_title":[
      "Charging dynamics of electric double layer capacitors including\n  beyond-mean-field electrostatic correlations"
    ],
    "b_abstract":[
      "Electric double layer (EDL) formation underlies the functioning of\nsupercapacitors and several other electrochemical technologies. Here, we study\nhow the EDL formation near two flat blocking electrodes separated by $2L$ is\naffected by beyond-mean-field Coulombic interactions, which can be substantial\nfor electrolytes of high salt concentration or with multivalent ions. Our model\ncombines the Nernst-Planck and Bazant-Storey-Kornyshev (BSK) equations; the\nlatter is a modified Poisson equation with a correlation length $\\ell_c$. In\nresponse to a voltage step, the system charges exponentially with a\ncharacteristic timescale $\\tau$ that depends nonmonotonically on $\\ell_c$. For\nsmall $\\ell_c$, $\\tau$ is given by the BSK capacitance times a dilute\nelectrolyte's resistance, in line with [Zhao, Phys. Rev. E 84, 051504 (2011)];\nhere, $\\tau$ decreases with increasing $\\ell_c$. Increasing the correlation\nlength beyond $\\ell_c\\approx L^{2\/3}\\lambda_D^{1\/3}$, with $\\lambda_D$ the\nDebye length, $\\tau$ reaches a minimum, rises as $\\tau\\propto\n\\lambda_D\\ell_c\/D$, and plateaus at $\\tau=4L^2\/(\\pi^2 D)$. Our results imply\nthat strongly correlated, strongly confined electrolytes - ionic liquids in the\nsurface force balance apparatus, say - move slower than predicted so far."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02419",
    "c_title":[
      "On a function of Ramanujan twisted by a logarithm"
    ],
    "c_abstract":[
      "A two-term functional equation for an infinite series involving the digamma\nfunction and a logarithmic factor is derived. A modular relation on page 220 of\nRamanujan's Lost Notebook as well as a corresponding recent result for the\nderivative of Deninger's function are two main ingredients in its derivation.\nAn interesting integral $\\mathscr{H}(x)$, which is of independent interest,\nplays a prominent role in our functional equation. Several alternative\nrepresentations for $\\mathscr{H}(x)$ are obtained."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-629",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14039",
    "b_title":[
      "AtomProNet: Data flow to and from machine learning interatomic\n  potentials in materials science"
    ],
    "b_abstract":[
      "As the atomistic simulations of materials science move from traditional\npotentials to machine learning interatomic potential (MLIP), the field is\nentering the second phase focused on discovering and explaining new material\nphenomena. While MLIP development relies on curated data and flexible datasets\nfrom ab-initio simulations, transitioning seamlessly between ab-initio\nworkflows and MLIP frameworks remains challenging. A global survey was\nconducted to understand the current standing (progress and bottleneck) of the\nmachine learning-guided materials science research. The survey responses have\nbeen implemented to design an open-source software to reduce the access\nbarriers of MLIP models for the global scientific community. Here, we present\nAtomProNet, an open-source Python package that automates obtaining atomic\nstructures, prepares and submits ab-initio jobs, and efficiently collects\nbatch-processed data for streamlined neural network (NN) training. Finally, we\ncompared empirical and start-of-the-art machine learning potential, showing the\npracticality of using MLIPs based on computational time and resources."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10306",
    "c_title":[
      "Micro-Macro Decomposition of Particle Swarm Optimization Methods"
    ],
    "c_abstract":[
      "Solving non-convex minimization problems using multi-particle metaheuristic\nderivative-free optimization methods is still active area of research. Popular\nmethods are Particle Swarm Optimization (PSO) methods, that iteratively update\na population of particles according to dynamics inspired by social interactions\nbetween individuals. We present a modification to include constrained\nminimization problems using exact penalization. Additionally, we utilize the\nhierarchical structure of PSO to introduce a micro-macro decomposition of the\nalgorithm. The probability density of particles is written as a convex\ncombination of microscopic and macroscopic contributions, and both parts are\npropagated separately. The decomposition is dynamically updated based on\nheuristic considerations. Numerical examples compare the results obtained using\nthe algorithm in the microscopic scale, in the macroscopic scale, and, using\nthe new micro-macro decomposition."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-630",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01474",
    "b_title":[
      "Interactive Navigation for Legged Manipulators with Learned Arm-Pushing\n  Controller"
    ],
    "b_abstract":[
      "Interactive navigation is crucial in scenarios where proactively interacting\nwith objects can yield shorter paths, thus significantly improving traversal\nefficiency. Existing methods primarily focus on using the robot body to\nrelocate large obstacles (which could be comparable to the size of a robot).\nHowever, they prove ineffective in narrow or constrained spaces where the\nrobot's dimensions restrict its manipulation capabilities. This paper\nintroduces a novel interactive navigation framework for legged manipulators,\nfeaturing an active arm-pushing mechanism that enables the robot to reposition\nmovable obstacles in space-constrained environments. To this end, we develop a\nreinforcement learning-based arm-pushing controller with a two-stage reward\nstrategy for large-object manipulation. Specifically, this strategy first\ndirects the manipulator to a designated pushing zone to achieve a kinematically\nfeasible contact configuration. Then, the end effector is guided to maintain\nits position at appropriate contact points for stable object displacement while\npreventing toppling. The simulations validate the robustness of the arm-pushing\ncontroller, showing that the two-stage reward strategy improves policy\nconvergence and long-term performance. Real-world experiments further\ndemonstrate the effectiveness of the proposed navigation framework, which\nachieves shorter paths and reduced traversal time. The open-source project can\nbe found at\nhttps:\/\/github.com\/Zhihaibi\/Interactive-Navigation-for-legged-manipulator.git."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14179",
    "c_title":[
      "Analysis of symmetries in the Causal Loop-Tree Duality representations"
    ],
    "c_abstract":[
      "Unveiling hidden symmetries within Feynman diagrams is crucial for achieving\nmore efficient computations in high-energy physics. In this paper, we study the\nsymmetries underlying the causal Loop-Tree Duality (LTD) representations\nthrough a geometric analysis. Focusing on the integrand-level representations\nof $N$-point functions at one loop, we examine their degenerations and discover\nthat different causal representations are interconnected through specific\ntransformations arising from the symmetries of cut diagrams. Furthermore, the\ndegeneration is linked to algebraic constraints among the different causal\nthresholds. Our findings shed new light on the deeper structures of Feynman\nintegrals and pave the way for significantly accelerating their calculation by\ninterrelating different approaches."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-631",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19921",
    "b_title":[
      "Shifting the Paradigm: A Diffeomorphism Between Time Series Data\n  Manifolds for Achieving Shift-Invariancy in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning models lack shift invariance, making them sensitive to input\nshifts that cause changes in output. While recent techniques seek to address\nthis for images, our findings show that these approaches fail to provide\nshift-invariance in time series, where the data generation mechanism is more\nchallenging due to the interaction of low and high frequencies. Worse, they\nalso decrease performance across several tasks. In this paper, we propose a\nnovel differentiable bijective function that maps samples from their\nhigh-dimensional data manifold to another manifold of the same dimension,\nwithout any dimensional reduction. Our approach guarantees that samples -- when\nsubjected to random shifts -- are mapped to a unique point in the manifold\nwhile preserving all task-relevant information without loss. We theoretically\nand empirically demonstrate that the proposed transformation guarantees\nshift-invariance in deep learning models without imposing any limits to the\nshift. Our experiments on six time series tasks with state-of-the-art methods\nshow that our approach consistently improves the performance while enabling\nmodels to achieve complete shift-invariance without modifying or imposing\nrestrictions on the model's topology. The source code is available on\n\\href{https:\/\/github.com\/eth-siplab\/Shifting-the-Paradigm}{GitHub}."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04673",
    "c_title":[
      "The Method of ${\\cal M}_{n}$-Extension: The KdV Equation"
    ],
    "c_abstract":[
      "In this work we generalize ${\\cal M}_{2}$-extension that has been introduced\nrecently. For illustration we use the KdV equation. We present five different\n${\\cal M}_{3}$-extensions of the KdV equation and their recursion operators. We\ngive a compact form of ${\\cal M}_{n}$-extension of the KdV equation and\nrecursion operator of the coupled KdV system. The method of ${\\cal\nM}_{n}$-extension can be applied to any integrable scalar equation to obtain\nintegrable multi-field system of equations. We also present unshifted and\nshifted nonlocal reductions of an example of ${\\cal M}_{3}$-extension of KdV."
    ],
    "c_categories":[
      [
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-632",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12178",
    "b_title":[
      "Public Sector Efficiency in Delivering Social Services and Its Impact on\n  Human Development: A Comparative Study of Healthcare and Education Spending\n  in India, Pakistan, and Bangladesh"
    ],
    "b_abstract":[
      "The research investigates the effects of public spending on health and\neducation in shaping the human development in south Asian three countries:\nIndia, Pakistan and Bangladesh. The study uses the VAR (Vector Auto regression)\nmodel to estimate the effects on government spending on these sectors to\nevaluate the human development. The findings state that there are different\ndegrees of impact in these three countries. In Bangladesh and India, health\nspending increases the human development in short term. On the other hand\neducation spending shows the significance on the HDI.Moreover, the study also\nhighlights that there are different levels of effectiveness of government\nspending across these three countries. In order to maximize the human\ndevelopment an optimum country specific strategies should be adopted."
    ],
    "b_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.08643",
    "c_title":[
      "Rethinking Diffusion Model in High Dimension"
    ],
    "c_abstract":[
      "Curse of Dimensionality is an unavoidable challenge in statistical\nprobability models, yet diffusion models seem to overcome this limitation,\nachieving impressive results in high-dimensional data generation. Diffusion\nmodels assume that they can learn the statistical properties of the underlying\nprobability distribution, enabling sampling from this distribution to generate\nrealistic samples. But is this really how they work? To address this question,\nthis paper conducts a detailed analysis of the objective function and inference\nmethods of diffusion models, leading to several important conclusions that help\nanswer the above question: 1) In high-dimensional sparse scenarios, the target\nof the objective function fitting degrades from a weighted sum of multiple\nsamples to a single sample. 2) The mainstream inference methods can all be\nrepresented within a simple unified framework, without requiring statistical\nconcepts such as Markov chains and SDEs. 3) Guided by this simple framework,\nmore efficient inference methods can be discovered."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-633",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14344",
    "b_title":[
      "Towards Accurate Binary Spiking Neural Networks: Learning with Adaptive\n  Gradient Modulation Mechanism"
    ],
    "b_abstract":[
      "Binary Spiking Neural Networks (BSNNs) inherit the eventdriven paradigm of\nSNNs, while also adopting the reduced storage burden of binarization\ntechniques. These distinct advantages grant BSNNs lightweight and\nenergy-efficient characteristics, rendering them ideal for deployment on\nresource-constrained edge devices. However, due to the binary synaptic weights\nand non-differentiable spike function, effectively training BSNNs remains an\nopen question. In this paper, we conduct an in-depth analysis of the challenge\nfor BSNN learning, namely the frequent weight sign flipping problem. To\nmitigate this issue, we propose an Adaptive Gradient Modulation Mechanism\n(AGMM), which is designed to reduce the frequency of weight sign flipping by\nadaptively adjusting the gradients during the learning process. The proposed\nAGMM can enable BSNNs to achieve faster convergence speed and higher accuracy,\neffectively narrowing the gap between BSNNs and their full-precision\nequivalents. We validate AGMM on both static and neuromorphic datasets, and\nresults indicate that it achieves state-of-the-art results among BSNNs. This\nwork substantially reduces storage demands and enhances SNNs' inherent energy\nefficiency, making them highly feasible for resource-constrained environments."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02378",
    "c_title":[
      "Investigation of Plasma Mixing Processes in the Context of Indirect\n  Drive Inertial Confinement Fusion"
    ],
    "c_abstract":[
      "In inertial confinement fusion (ICF), the dynamics of plasma mixing in\nhohlraums critically influence laser-plasma instabilities (LPI) and implosion\nperformance. This study investigates the mixing of hohlraum ablated Au plasmas\nand filling C$_5$H$_{12}$ plasmas using one-dimensional particle-in-cell (PIC)\nsimulations. We find that ion-ion collisions slow the diffusion of ions,\nrendering Au ions sub-diffusive, while C and H ions remain super-diffusive. Due\nto their lower collisionality, H ions diffuse faster into Au regions than C\nions, leading to a distinct separation between C and H ions at the interface.\nAlthough an electrostatic shock is still generated at the plasma interface in\nthe presence of collisions, its electric field strength and propagation speed\nare notably reduced. To systematically explore plasma mixing in hohlraum\nenvironments, we evaluate the individual effects of incident laser irradiation,\nplasma flow, and inhomogeneous density profiles on ion mixing. We find that\nlaser irradiation and plasma flow have a minor impact on ion mixing compared to\ndiffusion-driven processes, while the inhomogeneous density profile restricts\ndiffusion from low-density to high-density regions. By incorporating realistic\nhohlraum plasma conditions derived from radiation hydrodynamic models into the\nPIC simulations, we demonstrate that the diffusion of C and H ions continues to\ndominate ion mixing. Simple phenomenological fits are derived to describe the\nevolution of the mixing width in a hohlraum condition. Further theoretical\ncalculations indicate that the penetration of H and C into Au plasmas\nsuppresses stimulated Brillouin scattering (SBS) within the mixing layer. This\nfinding underscores the importance of integrating ion mixing effects into LPI\ncodes for more accurate modeling of ICF hohlraum dynamics."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-634",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11071",
    "b_title":[
      "Generalization of the Gibbs algorithm with high probability at low\n  temperatures"
    ],
    "b_abstract":[
      "The paper gives a bound on the generalization error of the Gibbs algorithm,\nwhich recovers known data-independent bounds for the high temperature range and\nextends to the low-temperature range, where generalization depends critically\non the data-dependent loss-landscape. It is shown, that with high probability\nthe generalization error of a single hypothesis drawn from the Gibbs posterior\ndecreases with the total prior volume of all hypotheses with similar or smaller\nempirical error. This gives theoretical support to the belief in the benefit of\nflat minima. The zero temperature limit is discussed and the bound is extended\nto a class of similar stochastic algorithms."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05422",
    "c_title":[
      "Angular bispectrum of matter number counts in cosmic structures"
    ],
    "c_abstract":[
      "The bispectrum of galaxy number counts is a key probe of large-scale\nstructure (LSS), offering insights into the initial conditions of the Universe,\nthe nature of gravity, and cosmological parameters. In this work, we derive the\ntheoretical angular bispectrum of number counts for the first time without\nrelying on the Limber approximation, while incorporating redshift binning.\nNotably, our analysis includes all Newtonian effects, leading relativistic\nprojection effects, and general relativistic contributions, including radiation\ndynamics, up to second order in perturbation theory. For simplicity, however,\nwe neglect any biasing effects. We have implemented these expressions in an\nopen access code to evaluate the bispectrum for two redshift bins, $z=2 \\pm\n0.25$ and $z=0.6 \\pm 0.05$, and compare our analytical results with\nsimulations. For the contributions that already appear in a Newtonian treatment\nwe find an interesting cancellation between the quadratic terms. At $z=2$, the\nprojection effects and the dynamical effects have similar amplitude on large\nscales as we approach $k \\sim \\mathcal{H}$. In the squeezed limit, radiation\neffects are found to be the leading relativistic effects, by one order of\nmagnitude. At $z=0.6$, we find the correct weak-field hierarchy between the\nterms, controlled by the ratio $\\mathcal{H}\/k$, but we still find that\ndynamical effects (from nonlinear evolution) are only a factor $2-3$ smaller\nthan the projection effects. We compare our results with simulation\nmeasurements and find good agreement for the total bispectrum."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-635",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12408",
    "b_title":[
      "On the Robust Approximation of ASR Metrics"
    ],
    "b_abstract":[
      "Recent advances in speech foundation models are largely driven by scaling\nboth model size and data, enabling them to perform a wide range of tasks,\nincluding speech recognition. Traditionally, ASR models are evaluated using\nmetrics like Word Error Rate (WER) and Character Error Rate (CER), which depend\non ground truth labels. As a result of limited labeled data from diverse\ndomains and testing conditions, the true generalization capabilities of these\nmodels beyond standard benchmarks remain unclear. Moreover, labeling data is\nboth costly and time-consuming. To address this, we propose a novel label-free\napproach for approximating ASR performance metrics, eliminating the need for\nground truth labels. Our method utilizes multimodal embeddings in a unified\nspace for speech and transcription representations, combined with a\nhigh-quality proxy model to compute proxy metrics. These features are used to\ntrain a regression model to predict key ASR metrics like Word Error Rate (WER)\nand Character Error Rate (CER). We experiment with over 40 models across 14\ndatasets representing both standard and in-the-wild testing conditions. Our\nresults show that we approximate the metrics within a single-digit absolute\ndifference across all experimental configurations, outperforming the most\nrecent baseline by more than 50\\%."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18667",
    "c_title":[
      "Exploring the accuracy of the equation-of-motion coupled-cluster band\n  gap of solids"
    ],
    "c_abstract":[
      "While the periodic equation-of-motion coupled-cluster (EOM-CC) method\npromises systematic improvement of electronic band gap calculations in solids,\nits practical application at the singles and doubles level (EOM-CCSD) is\nhindered by severe finite-size errors in feasible simulation cells. We present\na hybrid approach combining EOM-CCSD with the computationally efficient $GW$\napproximation to estimate thermodynamic limit band gaps for several insulators\nand semiconductors. Our method substantially reduces required cell sizes while\nmaintaining accuracy. Comparisons with experimental gaps and self-consistent\n$GW$ calculations reveal that deviations in EOM-CCSD predictions correlate with\nreduced single excitation character of the excited many-electron states. Our\nwork not only provides a computationally tractable approach to EOM-CC\ncalculations in solids but also reveals fundamental insights into the role of\nsingle excitations in electronic-structure theory."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-636",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09594",
    "b_title":[
      "SimLingo: Vision-Only Closed-Loop Autonomous Driving with\n  Language-Action Alignment"
    ],
    "b_abstract":[
      "Integrating large language models (LLMs) into autonomous driving has\nattracted significant attention with the hope of improving generalization and\nexplainability. However, existing methods often focus on either driving or\nvision-language understanding but achieving both high driving performance and\nextensive language understanding remains challenging. In addition, the dominant\napproach to tackle vision-language understanding is using visual question\nanswering. However, for autonomous driving, this is only useful if it is\naligned with the action space. Otherwise, the model's answers could be\ninconsistent with its behavior. Therefore, we propose a model that can handle\nthree different tasks: (1) closed-loop driving, (2) vision-language\nunderstanding, and (3) language-action alignment. Our model SimLingo is based\non a vision language model (VLM) and works using only camera, excluding\nexpensive sensors like LiDAR. SimLingo obtains state-of-the-art performance on\nthe widely used CARLA simulator on the Bench2Drive benchmark and is the winning\nentry at the CARLA challenge 2024. Additionally, we achieve strong results in a\nwide variety of language-related tasks while maintaining high driving\nperformance."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11322",
    "c_title":[
      "Multiply iterated Poisson processes and their applications in ruin\n  theory"
    ],
    "c_abstract":[
      "This paper studies the properties of the Multiply Iterated Poisson Process\n(MIPP), a stochastic process constructed by repeatedly time-changing a Poisson\nprocess, and its applications in ruin theory. Like standard Poisson processes,\nMIPPs have exponentially distributed sojourn times (waiting times between\njumps). We explicitly derive the probabilities of all possible jump sizes at\nthe first jump and obtain the Laplace transform of the joint distribution of\nthe first jump time and its corresponding jump size. In ruin theory, the\nclassical Cram\\'er-Lundberg model assumes claims arrive independently according\nto a Poisson process. In contrast, our model employs MIPP to allow for\nclustered arrivals, reflecting real-world scenarios, such as catastrophic\nevents. Under this new framework, we derive the corresponding scale function in\nclosed form, facilitating accurate ruin probability calculations in the\npresence of clustered claims. These results improve the modeling of extreme\nrisks and have practical implications for insurance solvency assessments,\nreinsurance pricing, and capital reserve estimation."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-637",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12485",
    "b_title":[
      "Safe at the Margins: A General Approach to Safety Alignment in\n  Low-Resource English Languages -- A Singlish Case Study"
    ],
    "b_abstract":[
      "To ensure safe usage, Large Language Models (LLMs) typically undergo\nalignment with human-defined values. However, this alignment often relies on\nprimarily English data and is biased towards Western-centric values, limiting\nits effectiveness in low-resource language settings. In this paper, we describe\nour approach for aligning SEA-Lion-v2.1-Instruct (a Llama3-8B variant) to\nminimize toxicity in Singlish, an English creole specific to Singapore. We find\nthat supervised fine-tuning and Kahneman-Tversky Optimization (KTO) on paired\nand unpaired preferences is more sample efficient and yields significantly\nbetter results than Direct Preference Optimization (DPO). Our analysis reveals\nthat DPO implicitly enforces a weaker safety objective than KTO, and that SFT\ncomplements KTO by improving training stability. Finally, we introduce a simple\nbut novel modification to KTO, KTO-S, which improves training stability through\nbetter gradient exploitation. Overall, we present a general approach for safety\nalignment conducive to low-resource English languages, successfully reducing\ntoxicity by 99\\% on our Singlish benchmark, with gains generalizing to the\nbroader TOXIGEN dataset while maintaining strong performance across standard\nLLM benchmarks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11456",
    "c_title":[
      "On the Converse of Pr\\'{e}kopa's Theorem and Berndtsson's Theorem"
    ],
    "c_abstract":[
      "Given a continuous function $\\phi$ defined on a domain\n$\\Omega\\subset\\mathbb{R}^m\\times\\mathbb{R}^n$, we show that if a Pr\\'ekopa-type\nresult holds for $\\phi+\\psi$ for any non-negative convex function $\\psi$ on\n$\\Omega$, then $\\phi$ must be a convex function. Additionally, if the\nprojection of $\\Omega$ onto $\\mathbb{R}^m$ is convex, then $\\overline{\\Omega}$\nis also convex. This provides a converse of Pr\\'ekopa's theorem from convex\nanalysis. We also establish analogous results for Berndtsson's theorem on the\nplurisubharmonic variation of Bergman kernels, showing that the\nplurisubharmonicity of weight functions and the pseudoconvexity of domains are\nnecessary conditions in some sense."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-638",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20034",
    "b_title":[
      "Vision-Encoders (Already) Know What They See: Mitigating Object\n  Hallucination via Simple Fine-Grained CLIPScore"
    ],
    "b_abstract":[
      "Recently, Large Vision-Language Models (LVLMs) show remarkable performance\nacross various domains. However, these models suffer from object hallucination.\nThis study revisits the previous claim that the primary cause of such\nhallucination lies in the limited representational capacity of the vision\nencoder. Our analysis reveals that the capacity of the vision encoder itself is\nalready enough for detecting object hallucination. Based on this insight, we\npropose a Fine-grained CLIPScore (F-CLIPScore), a simple yet effective\nevaluation metric that enhances object-level granularity by incorporating text\nembeddings at the noun phrase level. Evaluations on the OHD-Caps benchmark show\nthat F-CLIPScore significantly outperforms conventional CLIPScore in accuracy\nby a large margin of 39.6% without additional training. We further validate\nF-CLIPScore by showing that LVLM trained with the data filtered using\nF-CLIPScore exhibits reduced hallucination."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13312",
    "c_title":[
      "High Power Fast Frequency Modulation"
    ],
    "c_abstract":[
      "A fast and highly efficient frequency modulation at a high power level is\ndescribed. The system incorporates ferroelectric phase shifters and a magic-T\nor a circulator. A magnetron may be considered as a potential application. The\nmagnetron output may be converted to a selected reference frequency with\nnegligible insertion loss. The method also allows simultaneous amplitude and\nphase control."
    ],
    "c_categories":[
      [
        "physics.acc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-639",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07369",
    "b_title":[
      "Uniform Kernel Prober"
    ],
    "b_abstract":[
      "The ability to identify useful features or representations of the input data\nbased on training data that achieves low prediction error on test data across\nmultiple prediction tasks is considered the key to multitask learning success.\nIn practice, however, one faces the issue of the choice of prediction tasks and\nthe availability of test data from the chosen tasks while comparing the\nrelative performance of different features. In this work, we develop a class of\npseudometrics called Uniform Kernel Prober (UKP) for comparing features or\nrepresentations learned by different statistical models such as neural networks\nwhen the downstream prediction tasks involve kernel ridge regression. The\nproposed pseudometric, UKP, between any two representations, provides a uniform\nmeasure of prediction error on test data corresponding to a general class of\nkernel ridge regression tasks for a given choice of a kernel without access to\ntest data. Additionally, desired invariances in representations can be\nsuccessfully captured by UKP only through the choice of the kernel function and\nthe pseudometric can be efficiently estimated from $n$ input data samples with\n$O(\\frac{1}{\\sqrt{n}})$ estimation error. We also experimentally demonstrate\nthe ability of UKP to discriminate between different types of features or\nrepresentations based on their generalization performance on downstream kernel\nridge regression tasks."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03538",
    "c_title":[
      "Efficient and Accurate Tuberculosis Diagnosis: Attention Residual U-Net\n  and Vision Transformer Based Detection Framework"
    ],
    "c_abstract":[
      "Tuberculosis (TB), an infectious disease caused by Mycobacterium\ntuberculosis, continues to be a major global health threat despite being\npreventable and curable. This burden is particularly high in low and middle\nincome countries. Microscopy remains essential for diagnosing TB by enabling\ndirect visualization of Mycobacterium tuberculosis in sputum smear samples,\noffering a cost effective approach for early detection and effective treatment.\nGiven the labour-intensive nature of microscopy, automating the detection of\nbacilli in microscopic images is crucial to improve both the expediency and\nreliability of TB diagnosis. The current methodologies for detecting\ntuberculosis bacilli in bright field microscopic sputum smear images are\nhindered by limited automation capabilities, inconsistent segmentation quality,\nand constrained classification precision. This paper proposes a twostage deep\nlearning methodology for tuberculosis bacilli detection, comprising bacilli\nsegmentation followed by classification. In the initial phase, an advanced\nU-Net model employing attention blocks and residual connections is proposed to\nsegment microscopic sputum smear images, enabling the extraction of Regions of\nInterest (ROIs). The extracted ROIs are then classified using a Vision\nTransformer, which we specifically customized as TBViT to enhance the precise\ndetection of bacilli within the images. For the experiments, a newly developed\ndataset of microscopic sputum smear images derived from Ziehl-Neelsen-stained\nslides is used in conjunction with existing public datasets. The qualitative\nand quantitative evaluation of the experiments using various metrics\ndemonstrates that the proposed model achieves significantly improved\nsegmentation performance, higher classification accuracy, and a greater level\nof automation, surpassing existing methods."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-640",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17727",
    "b_title":[
      "Can Score-Based Generative Modeling Effectively Handle Medical Image\n  Classification?"
    ],
    "b_abstract":[
      "The remarkable success of deep learning in recent years has prompted\napplications in medical image classification and diagnosis tasks. While\nclassification models have demonstrated robustness in classifying simpler\ndatasets like MNIST or natural images such as ImageNet, this resilience is not\nconsistently observed in complex medical image datasets where data is more\nscarce and lacks diversity. Moreover, previous findings on natural image\ndatasets have indicated a potential trade-off between data likelihood and\nclassification accuracy. In this study, we explore the use of score-based\ngenerative models as classifiers for medical images, specifically mammographic\nimages. Our findings suggest that our proposed generative classifier model not\nonly achieves superior classification results on CBIS-DDSM, INbreast and Vin-Dr\nMammo datasets, but also introduces a novel approach to image classification in\na broader context. Our code is publicly available at\nhttps:\/\/github.com\/sushmitasarker\/sgc_for_medical_image_classification"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03588",
    "c_title":[
      "Zero Field Antiferromagnetically Coupled Skyrmions and their\n  Field-Driven Uncoupling in Composite Chiral Multilayers"
    ],
    "c_abstract":[
      "Antiferromagnetic (AF) skyrmions are topological spin structures with fully\ncompensated, net-zero magnetization. Compared to their ferromagnetic (FM)\nskyrmion counterparts, their reduced stray field and enhanced electrical\nresponse can enable linear, high-throughput current-driven motion. However,\ntheir bubble-like character in conventional bilayer AFs limits their stability\nto fluctuations, leading to deformation and annihilation. Here we present the\nengineering of a composite AF chiral multilayer, wherein the interplay of AF\nand FM interlayer couplings generates compensated skyrmions with compact\nstructures. High-resolution magnetic imaging and micromagnetic simulations show\nthat the internal exchange field stabilizes AF skyrmions at zero external field\nwith characteristics comparable to FM counterparts at 100 mT. Quantitative\nanalyses establish their decoupling above the exchange field, yielding\nindependent, spatially segregated textures in constituent chiral layers. This\nwork provides a foundation to develop AF spin-textures with enhanced immunity,\ncompatible with efficient readout and manipulation, with relevance to\nunconventional computing."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-641",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15287",
    "b_title":[
      "Distributed Generalized Linear Models: A Privacy-Preserving Approach"
    ],
    "b_abstract":[
      "This paper presents a novel approach to classical linear regression, enabling\nmodel computation from data streams or in a distributed setting while\npreserving data privacy in federated environments. We extend this framework to\ngeneralized linear models (GLMs), ensuring scalability and adaptability to\ndiverse data distributions while maintaining privacy-preserving properties. To\nassess the effectiveness of our approach, we conduct numerical studies on both\nsimulated and real datasets, comparing our method with conventional maximum\nlikelihood estimation for GLMs using iteratively reweighted least squares. Our\nresults demonstrate the advantages of the proposed method in distributed and\nfederated settings."
    ],
    "b_categories":[
      [
        "cs.DC",
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11705",
    "c_title":[
      "LLM Agents Making Agent Tools"
    ],
    "c_abstract":[
      "Tool use has turned large language models (LLMs) into powerful agents that\ncan perform complex multi-step tasks by dynamically utilising external software\ncomponents. However, these tools must be implemented in advance by human\ndevelopers, hindering the applicability of LLM agents in domains which demand\nlarge numbers of highly specialised tools, like in life sciences and medicine.\nMotivated by the growing trend of scientific studies accompanied by public code\nrepositories, we propose ToolMaker, a novel agentic framework that autonomously\ntransforms papers with code into LLM-compatible tools. Given a short task\ndescription and a repository URL, ToolMaker autonomously installs required\ndependencies and generates code to perform the task, using a closed-loop\nself-correction mechanism to iteratively diagnose and rectify errors. To\nevaluate our approach, we introduce a benchmark comprising 15 diverse and\ncomplex computational tasks spanning both medical and non-medical domains with\nover 100 unit tests to objectively assess tool correctness and robustness.\nToolMaker correctly implements 80% of the tasks, substantially outperforming\ncurrent state-of-the-art software engineering agents. ToolMaker therefore is a\nstep towards fully autonomous agent-based scientific workflows."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-642",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11092",
    "b_title":[
      "Storing quantum coherence in a quantum dot nuclear spin ensemble for\n  over 100 milliseconds"
    ],
    "b_abstract":[
      "States with long coherence are a crucial requirement for qubits and quantum\nmemories. Nuclear spins in epitaxial quantum dots are a great candidate,\noffering excellent isolation from external environments and on-demand coupling\nto optical flying qubits. However, coherence times are limited to $\\lesssim1$\nms by the dipole-dipole interactions between the nuclei and their quadrupolar\ncoupling to inhomogeneous crystal strain. Here, we combine strain engineering\nof the nuclear spin ensemble and tailored dynamical decoupling sequences to\nachieve nuclear spin coherence times exceeding 100 ms. Recently, a reversible\ntransfer of quantum information into nuclear spin ensembles has been\ndemonstrated in quantum dots. Our results provide a path to develop this\nconcept into a functioning solid-state quantum memory suitable for quantum\nrepeaters in optical quantum communication networks."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16841",
    "c_title":[
      "Preferential Multi-Objective Bayesian Optimization for Drug Discovery"
    ],
    "c_abstract":[
      "Despite decades of advancements in automated ligand screening, large-scale\ndrug discovery remains resource-intensive and requires post-processing hit\nselection, a step where chemists manually select a few promising molecules\nbased on their chemical intuition. This creates a major bottleneck in the\nvirtual screening process for drug discovery, demanding experts to repeatedly\nbalance complex trade-offs among drug properties across a vast pool of\ncandidates. To improve the efficiency and reliability of this process, we\npropose a novel human-centered framework named CheapVS that allows chemists to\nguide the ligand selection process by providing preferences regarding the\ntrade-offs between drug properties via pairwise comparison. Our framework\ncombines preferential multi-objective Bayesian optimization with a docking\nmodel for measuring binding affinity to capture human chemical intuition for\nimproving hit identification. Specifically, on a library of 100K chemical\ncandidates targeting EGFR and DRD2, CheapVS outperforms state-of-the-art\nscreening methods in identifying drugs within a limited computational budget.\nNotably, our method can recover up to 16\/37 EGFR and 37\/58 DRD2 known drugs\nwhile screening only 6% of the library, showcasing its potential to\nsignificantly advance drug discovery."
    ],
    "c_categories":[
      [
        "cs.HC",
        "cs.LG",
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-643",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04908",
    "b_title":[
      "HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned\n  with HDL Engineers"
    ],
    "b_abstract":[
      "Recently, the use of large language models (LLMs) for Verilog code generation\nhas attracted great research interest to enable hardware design automation.\nHowever, previous works have shown a gap between the ability of LLMs and the\npractical demands of hardware description language (HDL) engineering. This gap\nincludes differences in how engineers phrase questions and hallucinations in\nthe code generated. To address these challenges, we introduce HaVen, a novel\nLLM framework designed to mitigate hallucinations and align Verilog code\ngeneration with the practices of HDL engineers. HaVen tackles hallucination\nissues by proposing a comprehensive taxonomy and employing a chain-of-thought\n(CoT) mechanism to translate symbolic modalities (e.g. truth tables, state\ndiagrams, etc.) into accurate natural language descriptions. Furthermore, HaVen\nbridges this gap by using a data augmentation strategy. It synthesizes\nhigh-quality instruction-code pairs that match real HDL engineering practices.\nOur experiments demonstrate that HaVen significantly improves the correctness\nof Verilog code generation, outperforming state-of-the-art LLM-based Verilog\ngeneration methods on VerilogEval and RTLLM benchmark. HaVen is publicly\navailable at https:\/\/github.com\/Intelligent-Computing-Research-Group\/HaVen."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03585",
    "c_title":[
      "Combinatorics in (2,1)-categories"
    ],
    "c_abstract":[
      "Groupoid cardinality is an invariant of locally finite groupoids which has\nmany of the properties of the cardinality of finite sets, but which takes\nvalues in all non-negative real numbers, and accounts for the morphisms of a\ngroupoid. Several results on groupoid cardinality are proved, analogous to the\nrelationship between cardinality of finite sets and i.e. injective or\nsurjective functions. We also generalize to a broad class of (2,1)-categories a\nfamous theorem of Lov\\'asz which characterizes the isomorphism type of\nrelational structures by counting the number of homomorphisms into them."
    ],
    "c_categories":[
      [
        "math.CO",
        "math.CT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-644",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08892",
    "b_title":[
      "Fast, Accurate Numerical Evaluation of Incomplete Planck Integrals"
    ],
    "b_abstract":[
      "Methods for computing the integral of the Planck blackbody function over a\nfinite spectral range, the so-called incomplete Planck integral, are necessary\nto perform multigroup radiative transfer calculations. We present a comparison,\nin terms of speed and accuracy, of a wide array of approaches to numerically\nevaluating these integrals. Our results indicate that a direct rational\npolynomial approximation to these integrals has the best combination of\naccuracy and efficiency. We also present for the first time a derivation of the\npolylogarithm form of these integrals and show that modern approaches to\npolylogarithm evaluation are suitable for numerically evaluating incomplete\nPlanck integrals. This article is dedicated to Prof. B.D. Ganapol, the\nTransport Cowboy, on the occasion of his retirement."
    ],
    "b_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01348",
    "c_title":[
      "Sharp conditions for preserving uniformity, doubling measure and\n  Poincar\\'e inequality under sphericalization"
    ],
    "c_abstract":[
      "We study sphericalization, which is a mapping that conformally deforms the\nmetric and the measure of an unbounded metric measure space so that the\ndeformed space is bounded. The goal of this paper is to study sharp conditions\non the deforming density function under which the sphericalization preserves\nuniformity of the space, the doubling property of the measure and the support\nof a Poincar\\'e inequality. We also provide examples that demonstrate the\nsharpness of our conditions."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-645",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02582",
    "b_title":[
      "Carleman-lattice-Boltzmann quantum circuit with matrix access oracles"
    ],
    "b_abstract":[
      "We apply Carleman linearization of the Lattice Boltzmann (CLB) representation\nof fluid flows to quantum emulate the dynamics of a 2D Kolmogorov-like flow. We\nassess the accuracy of the result and find a relative error of the order of\n$10^{-3}$ with just two Carleman iterates, for a range of the Reynolds number\nup to a few hundreds. We first define a gate-based quantum circuit for the\nimplementation of the CLB method and then exploit the sparse nature of the CLB\nmatrix to build a quantum circuit based on block-encoding techniques which\nmakes use of matrix oracles. It is shown that the gate complexity of the\nalgorithm is thereby dramatically reduced, from exponential to quadratic.\nHowever, due to the need of employing up to seven ancilla qubits, the\nprobability of success of the corresponding circuit for a single time step is\ntoo low to enable multi-step time evolution. Several possible directions to\ncircumvent this problem are briefly outlined."
    ],
    "b_categories":[
      [
        "physics.comp-ph",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07345",
    "c_title":[
      "On the Gross-Pitaevskii evolution linearized around the degree-one\n  vortex"
    ],
    "c_abstract":[
      "We study the evolution of the Gross-Pitaevskii equation linearized around the\nGinzburg-Landau vortex of degree one under equivariant symmetry. Among the main\nresults of this work, we determine the spectrum of the linearized operator,\nuncover a remarkable $L^2$-norm growth phenomenon related to a zero-energy\nresonance, and provide a complete construction of the distorted Fourier\ntransform at small energies. The latter hinges upon a meticulous analysis of\nthe behavior of the resolvent in the upper and lower half-planes in a small\ndisk around zero-energy."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-646",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18056",
    "b_title":[
      "RL-based Query Rewriting with Distilled LLM for online E-Commerce\n  Systems"
    ],
    "b_abstract":[
      "Query rewriting (QR) is a critical technique in e-commerce search, addressing\nthe lexical gap between user queries and product descriptions to enhance search\nperformance. Existing QR approaches typically fall into two categories:\ndiscriminative models and generative methods leveraging large language models\n(LLMs). Discriminative models often struggle with natural language\nunderstanding and offer limited flexibility in rewriting, while generative\nLLMs, despite producing high-quality rewrites, face high inference latency and\ncost in online settings. These limitations force offline deployment, making\nthem vulnerable to issues like information staleness and semantic drift. To\novercome these challenges, we propose a novel hybrid pipeline for QR that\nbalances efficiency and effectiveness. Our approach combines offline knowledge\ndistillation to create a lightweight but efficient student model with online\nreinforcement learning (RL) to refine query rewriting dynamically using\nreal-time feedback. A key innovation is the use of LLMs as simulated human\nfeedback, enabling scalable reward signals and cost-effective evaluation\nwithout manual annotations. Experimental results on Amazon ESCI dataset\ndemonstrate significant improvements in query relevance, diversity, and\nadaptability, as well as positive feedback from the LLM simulation. This work\ncontributes to advancing LLM capabilities for domain-specific applications,\noffering a robust solution for dynamic and complex e-commerce search\nenvironments."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08688",
    "c_title":[
      "FAST: A Future Aircraft Sizing Tool for Advanced Aircraft and Propulsion\n  System Design"
    ],
    "c_abstract":[
      "Without radical technological advancements, the global aviation industry will\ncontinue to be a major carbon emitter. To reduce aviation's carbon emissions,\ninnovative aircraft technology, including electrified aircraft propulsion, is\nunder development. However, current aircraft sizing tools require detailed\ndesign information that may not be available early in the development process,\nparticularly for novel technologies. This can yield suboptimal designs and\ninhibits innovation. A computational tool is needed to easily and rapidly size\nan aircraft configuration while allowing the designer to explore the design\nspace, examine tradeoffs, and evaluate alternative designs. The Future Aircraft\nSizing Tool (FAST), developed in Matlab, addresses this challenge by rapidly\nsizing aircraft with any propulsion architecture, including conventional,\nelectric, and hybrid electric systems, even with limited initial data. FAST\nenables engineers to explore various aircraft configurations, evaluate design\nalternatives, assess performance across a flight envelope, and visualize\nconcepts during the sizing process. By supporting early stage design, FAST\naddresses a gap in currently available computational tools for developing\nsustainable aviation technologies to help reduce the industry's carbon\nfootprint."
    ],
    "c_categories":[
      [
        "cs.CE",
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-647",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00275",
    "b_title":[
      "Simultaneous Estimation of Manipulation Skill and Hand Grasp Force from\n  Forearm Ultrasound Images"
    ],
    "b_abstract":[
      "Accurate estimation of human hand configuration and the forces they exert is\ncritical for effective teleoperation and skill transfer in robotic\nmanipulation. A deeper understanding of human interactions with objects can\nfurther enhance teleoperation performance. To address this need, researchers\nhave explored methods to capture and translate human manipulation skills and\napplied forces to robotic systems. Among these, biosignal-based approaches,\nparticularly those using forearm ultrasound data, have shown significant\npotential for estimating hand movements and finger forces. In this study, we\npresent a method for simultaneously estimating manipulation skills and applied\nhand force using forearm ultrasound data. Data collected from seven\nparticipants were used to train deep learning models for classifying\nmanipulation skills and estimating grasp force. Our models achieved an average\nclassification accuracy of 94.87 percent plus or minus 10.16 percent for\nmanipulation skills and an average root mean square error (RMSE) of 0.51 plus\nor minus 0.19 Newtons for force estimation, as evaluated using five-fold\ncross-validation. These results highlight the effectiveness of forearm\nultrasound in advancing human-machine interfacing and robotic teleoperation for\ncomplex manipulation tasks. This work enables new and effective possibilities\nfor human-robot skill transfer and tele-manipulation, bridging the gap between\nhuman dexterity and robotic control."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.ET",
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00832",
    "c_title":[
      "On oriented alternating inverse monoids"
    ],
    "c_abstract":[
      "In this paper, we consider the inverse submonoids $AOR_n$ of oriented\ntransformations and $AOP_n$ of orientation-preserving transformations of the\nalternating inverse monoid $AI_n$ on a chain with $n$ elements. We compute the\ncardinalities, describe the Green's structures and the congruences, and\ncalculate the ranks of $AOR_n$ and $AOP_n$."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-648",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02323",
    "b_title":[
      "Hybrid Resolver Model Generalization for Fault Condition Modeling: A\n  Promising Tool for Reliability Study"
    ],
    "b_abstract":[
      "Resolvers, like all electromagnetic devices, are constantly under\ninvestigation, both operationally and structurally. In this regard, proposing a\nmodeling methodology that can save significant time without compromising\naccuracy is a big honor. In this study, a generalized hybrid model is suggested\nthat, in addition to the above benefits, has sufficient capability to ease\nreliability study in the field of resolvers, where a large number of faulty\nconditions must be investigated under different operating conditions, including\nchanges in angular velocity, voltage, and frequency of excitation; all of which\nare highlighted in the context of fault coverage. This model also serves as a\npromising tool for generating large datasets, which is advantageous for fault\ndiagnosis. A resolver with a non-uniform air gap is chosen as a case study to\nchallenge the suggested model, particularly in relation to eccentricity faults.\nWe generalize the suggested model to account for the most common faulty\nconditions of resolvers: in-turn short circuits in signal and excitation\nwindings, as well as static and dynamic eccentricity faults. The close\nagreement between the results of the suggested model and those from\nTime-Stepping Finite Element Analysis (TS-FEA), along with significant time\nsavings in both healthy and faulty conditions, highlights the generality and\nproficiency of the suggested model. Finally, the case study is prototyped, and\nwe verify the accuracy of the suggested model experimentally."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09883",
    "c_title":[
      "The nonfactorizable QED correction to the $\\overline{B}_{s}$ ${\\to}$\n  $D_{s}^{(\\ast)} {\\ell} \\bar{\\nu}_{\\ell}$ decays"
    ],
    "c_abstract":[
      "Considering the nonfactorizable QED corrections, the branching ratios and\nratios of branching ratios $R(D_{s}^{({\\ast})})$ for the semileptonic\n$\\overline{B}_{s}$ ${\\to}$ $D_{s}^{(\\ast)} {\\ell} \\bar{\\nu}_{\\ell}$ decays are\nreevaluated. It is found that (a) the QED contributions can enhance the\nbranching ratios and reduce the ratios $R(D_{s}^{({\\ast})})$. (b) The $SU(3)$\nflavor symmetry holds basically well in the ratios $R(D)$-$R(D^{\\ast})$ for the\nsemileptonic charmed $\\overline{B}_{u,d,s}$ decays. (c) The current theoretical\nuncertainties of branching ratios ${\\cal B}(\\overline{B}_{s} {\\to} D_{s}^{\\ast}\n{\\ell} \\bar{\\nu}_{\\ell})$ from the form factors are very large."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-649",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10662",
    "b_title":[
      "Analyzing the Higgs-confinement transition with non-local operators on\n  the lattice"
    ],
    "b_abstract":[
      "We study non-local operators for analyzing the Higgs-confinement phase\ntransition in lattice gauge theory. Since the nature of the Higgs-confinement\nphase transition is topological, its order parameter is the expectation value\nof non-local operators, such as loop and surface operators. There exist several\ncandidates for the non-local operators. Adopting the charge-2 Abelian Higgs\nmodel, we test numerical simulation of conventional ones, the Polyakov loop and\nthe 't Hooft loop, and an unconventional one, the Aharonov-Bohm phase defined\nby the Wilson loop wrapping around a vortex line."
    ],
    "b_categories":[
      [
        "hep-lat",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19318",
    "c_title":[
      "Does 3D Gaussian Splatting Need Accurate Volumetric Rendering?"
    ],
    "c_abstract":[
      "Since its introduction, 3D Gaussian Splatting (3DGS) has become an important\nreference method for learning 3D representations of a captured scene, allowing\nreal-time novel-view synthesis with high visual quality and fast training\ntimes. Neural Radiance Fields (NeRFs), which preceded 3DGS, are based on a\nprincipled ray-marching approach for volumetric rendering. In contrast, while\nsharing a similar image formation model with NeRF, 3DGS uses a hybrid rendering\nsolution that builds on the strengths of volume rendering and primitive\nrasterization. A crucial benefit of 3DGS is its performance, achieved through a\nset of approximations, in many cases with respect to volumetric rendering\ntheory. A naturally arising question is whether replacing these approximations\nwith more principled volumetric rendering solutions can improve the quality of\n3DGS. In this paper, we present an in-depth analysis of the various\napproximations and assumptions used by the original 3DGS solution. We\ndemonstrate that, while more accurate volumetric rendering can help for low\nnumbers of primitives, the power of efficient optimization and the large number\nof Gaussians allows 3DGS to outperform volumetric rendering despite its\napproximations."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-650",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08884",
    "b_title":[
      "Improved Compression Bounds for Scenario Decision Making"
    ],
    "b_abstract":[
      "Scenario decision making offers a flexible way of making decision in an\nuncertain environment while obtaining probabilistic guarantees on the risk of\nfailure of the decision. The idea of this approach is to draw samples of the\nuncertainty and make a decision based on the samples, called \"scenarios\". The\nprobabilistic guarantees take the form of a bound on the probability of\nsampling a set of scenarios that will lead to a decision whose risk of failure\nis above a given maximum tolerance. This bound can be expressed as a function\nof the number of sampled scenarios, the maximum tolerated risk, and some\nintrinsic property of the problem called the \"compression size\". Several such\nbounds have been proposed in the literature under various assumptions on the\nproblem. We propose new bounds that improve upon the existing ones without\nrequiring stronger assumptions on the problem."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02650",
    "c_title":[
      "Comparative study on radiation resistance of WTaCrV high-entropy alloy\n  and tungsten in helium-containing conditions"
    ],
    "c_abstract":[
      "W and W-based high-entropy alloys (HEAs) are promising candidates for\nplasma-facing materials in fusion reactors. While irradiation studies on W have\nrevealed a tendency for helium (He) bubble formation and radiation-induced\ndefects, investigations of WTaCrV HEA have demonstrated superior radiation\nresistance, whether under He+ irradiation or heavy ion irradiation. To assess\nmaterial performance under conditions relevant to fusion reactors -\ncharacterized by fast neutrons and gas production from transmutation reactions\n- complex irradiation environments need to be modeled. Using molecular dynamics\nsimulations, we examined defect evolution in W and equimolar WTaCrV HEA with\nand without preexisting He atoms under cascade overlap conditions up to 0.2 dpa\nat 300 K. In W, dislocation loops and large interstitial clusters formed\nreadily, with increasing He content leading to higher dislocation densities and\nthe formation of polygonal interstitial networks. In contrast, the WTaCrV alloy\nexhibited strong resistance to the formation of dislocation loops and large\ninterstitial clusters but was more susceptible to the formation of bubbles at\nhigher He concentrations. Bubble growth was driven by helium trapping at\nvacancy sites and the coalescence of smaller bubbles. Larger bubbles remained\nstable against cascade overlap, limiting further growth by coalescence."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-651",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03121",
    "b_title":[
      "The Littlewood decomposition via colored Frobenius partitions"
    ],
    "b_abstract":[
      "The Littlewood decomposition for partitions is a well-known bijection between\npartitions and pairs of $t$-core and $t$-quotient partitions. This\ndecomposition can be described in several ways, such as the $t$-abacus method\nof James or the biinfinite word method of Garvan, Kim, and Stanton. In a recent\nstudy, Frobenius partitions have proven to be a highly useful tool in dealing\nwith partition statistics related to $t$-core partitions. Motivated by this\nstudy, in this paper, we present an alternative description of the Littlewood\ndecomposition using Frobenius partitions. We also apply our approach to\nself-conjugate partitions and doubled distinct partitions, and give new\ncharacterizations of their $t$-cores and $t$-quotients."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.02026",
    "c_title":[
      "ContinuouSP: Generative Model for Crystal Structure Prediction with\n  Invariance and Continuity"
    ],
    "c_abstract":[
      "The discovery of new materials using crystal structure prediction (CSP) based\non generative machine learning models has become a significant research topic\nin recent years. In this paper, we study invariance and continuity in the\ngenerative machine learning for CSP. We propose a new model, called\nContinuouSP, which effectively handles symmetry and periodicity in crystals. We\nclearly formulate the invariance and the continuity, and construct a model\nbased on the energy-based model. Our preliminary evaluation demonstrates the\neffectiveness of this model with the CSP task."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-652",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13997",
    "b_title":[
      "Characterizing Beam Profiles in Accelerator Neutrino Experiments through\n  Off-Axis Neutrino Interactions"
    ],
    "b_abstract":[
      "We introduce a novel approach that utilizes neutrino events from the off-axis\nnear detector to investigate the beam profile in long-baseline neutrino\nexperiments. Understanding the dynamics of the neutrino beam is crucial for\nimproving the precision of neutrino oscillation measurements. We demonstrate\nthat certain observables related to the azimuthal angle of the neutrino\ndirection are useful for determining the average neutrino production point from\nexperimental data, providing a valuable cross-check against Monte Carlo\nsimulations. Additionally, these observables can help identify potential\nalignment issues between the detector and the decay volume. In future neutrino\nexperiments with significantly higher statistics, these observables will become\nessential to ensure the accuracy and stability of the beam profile."
    ],
    "b_categories":[
      [
        "hep-ex",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05241",
    "c_title":[
      "Contrast-Free Myocardial Scar Segmentation in Cine MRI using Motion and\n  Texture Fusion"
    ],
    "c_abstract":[
      "Late gadolinium enhancement MRI (LGE MRI) is the gold standard for the\ndetection of myocardial scars for post myocardial infarction (MI). LGE MRI\nrequires the injection of a contrast agent, which carries potential side\neffects and increases scanning time and patient discomfort. To address these\nissues, we propose a novel framework that combines cardiac motion observed in\ncine MRI with image texture information to segment the myocardium and scar\ntissue in the left ventricle. Cardiac motion tracking can be formulated as a\nfull cardiac image cycle registration problem, which can be solved via deep\nneural networks. Experimental results prove that the proposed method can\nachieve scar segmentation based on non-contrasted cine images with comparable\naccuracy to LGE MRI. This demonstrates its potential as an alternative to\ncontrast-enhanced techniques for scar detection."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-653",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03432",
    "b_title":[
      "A formalization of Borel determinacy in Lean"
    ],
    "b_abstract":[
      "We present a formalization of Borel determinacy in the Lean 4 theorem prover.\nThe formalization includes a definition of Gale-Stewart games and a proof of\nMartin's theorem stating that Borel games are determined. The proof closely\nfollows Martin's \"A purely inductive proof of Borel determinacy\"."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06411",
    "c_title":[
      "The reliable quantum master equation of the Unruh-DeWitt detector"
    ],
    "c_abstract":[
      "In this paper, we present a method for estimating the validity range of the\nquantum Markovian master equation as applied to the Unruh-DeWitt (UDW) detector\nwithin a broader context, particularly without necessitating an exact solution\nfor the detector's evolution. We propose a relaxed van Hove limit (i.e.,\nlate-time limit) and offer a perturbative estimate of the error order resulting\nfrom the standard derivation procedure of open quantum dynamics. Our primary\nfindings include reliability criteria for the Markov approximation and\nconditions for the applicability of the rotating wave approximation (RWA).\nNevertheless, the specific forms of these validity conditions rely on the\ndetails of the detector-field system, such as the spacetime background, the\ntrajectory of the detector, and the type of quantum field being analyzed.\nFinally, we illustrate our results by re-examining the open dynamics of an\naccelerating UDW detector undergoing the Unruh effect, where the validity\nconditions narrow the parameter space to ensure the solution's reliability\nregarding the quantum Markovian master equation."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-654",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06018",
    "b_title":[
      "Evolution of the pseudogap band structure in a system of\n  electron-correlated lattice polarons"
    ],
    "b_abstract":[
      "The evolution of the role of lattice vibrations in the formation of the\npseudogap state in strongly correlated electron systems has been investigated\nconcerning changes in the electron-phonon coupling parameters and the\nconcentration of doped charge carriers. We apply the polaronic version of the\ngeneralized tight-binding method to analyze the band structure of a realistic\nmultiband two-dimensional model that incorporates the electron-lattice\ncontributions of both Holstein and Peierls types. It has been demonstrated that\nthe emergence of polaronic effects begins with the modulation of spectral\nfunction intensity. However, within a specific region of the phase diagram, a\nsignificant transformation of the electron band structure and pseudogap state\noccurs. It results from coherent polaron excitations that create a partially\nflat band near the Fermi level. This process leads to a change in the topology\nof the Fermi surface and the emergence of corresponding features in the density\nof states."
    ],
    "b_categories":[
      [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09818",
    "c_title":[
      "Positive singular solutions of a certain elliptic PDE"
    ],
    "c_abstract":[
      "In this paper, we investigate the existence of positive singular solutions\nfor a system of partial differential equations on a bounded domain. Our\napproach is based on analyzing the solution of the equation \\begin{equation}\n\\label{base equation} \\left\\{ \\begin{array}{lr} -\\Delta w = | \\nabla w |^p &\n\\text{in}~~ B_1 \\backslash \\{0\\},\\\\ w = 0 & \\text{on}~~ \\partial B_1,\n\\end{array} \\right. \\end{equation} and using its properties to study positive\nsingular solutions of its perturbations on $ B_1 $, the unit ball centered at\nthe origin in $\\mathbb{R}^N$, under the assumptions $N \\geq 3$ and\n$\\frac{N}{N-1} < p < 2$ . Specifically, we consider the system \\begin{equation}\n\\label{main equation of the thesis} \\left\\{ \\begin{array}{lr} -\\Delta u =\n(1+\\kappa_1(x)) | \\nabla v |^p & \\text{in}~~ B_1 \\backslash \\{0\\},\\\\ -\\Delta v\n= (1+\\kappa_2(x)) | \\nabla u |^p & \\text{in}~~ B_1 \\backslash \\{0\\},\\\\ u = v =\n0 & \\text{on}~~ \\partial B_1. \\end{array} \\right. \\end{equation} Here,\n$\\kappa_1$ and $\\kappa_2$ are non-negative, continuous functions satisfying\n$\\kappa_1(0) = \\kappa_2(0) = 0$ . The goal of this work is to establish the\nexistence of positive singular solutions for this equation within the given\ndomain."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-655",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06121",
    "b_title":[
      "Automorphism group schemes of lattice vertex operator algebras"
    ],
    "b_abstract":[
      "Given a positive definite even lattice and a commutative ring, there is a\nstandard construction of a lattice vertex algebra over the commutative ring,\nand this is promoted to a vertex operator algebra when the determinant of the\nlattice is invertible. We describe the groups of automorphisms of these vertex\nalgebras and vertex operator algebras as affine group schemes, showing in\nparticular that each is an extension of an explicitly described split reductive\ngroup of ADE type by the outer automorphism group of the lattice."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.GR",
        "math.QA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06235",
    "c_title":[
      "StreamGS: Online Generalizable Gaussian Splatting Reconstruction for\n  Unposed Image Streams"
    ],
    "c_abstract":[
      "The advent of 3D Gaussian Splatting (3DGS) has advanced 3D scene\nreconstruction and novel view synthesis. With the growing interest of\ninteractive applications that need immediate feedback, online 3DGS\nreconstruction in real-time is in high demand. However, none of existing\nmethods yet meet the demand due to three main challenges: the absence of\npredetermined camera parameters, the need for generalizable 3DGS optimization,\nand the necessity of reducing redundancy. We propose StreamGS, an online\ngeneralizable 3DGS reconstruction method for unposed image streams, which\nprogressively transform image streams to 3D Gaussian streams by predicting and\naggregating per-frame Gaussians. Our method overcomes the limitation of the\ninitial point reconstruction \\cite{dust3r} in tackling out-of-domain (OOD)\nissues by introducing a content adaptive refinement. The refinement enhances\ncross-frame consistency by establishing reliable pixel correspondences between\nadjacent frames. Such correspondences further aid in merging redundant\nGaussians through cross-frame feature aggregation. The density of Gaussians is\nthereby reduced, empowering online reconstruction by significantly lowering\ncomputational and memory costs. Extensive experiments on diverse datasets have\ndemonstrated that StreamGS achieves quality on par with optimization-based\napproaches but does so 150 times faster, and exhibits superior generalizability\nin handling OOD scenes."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-656",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07166",
    "b_title":[
      "Natural Language-Assisted Multi-modal Medication Recommendation"
    ],
    "b_abstract":[
      "Combinatorial medication recommendation(CMR) is a fundamental task of\nhealthcare, which offers opportunities for clinical physicians to provide more\nprecise prescriptions for patients with intricate health conditions,\nparticularly in the scenarios of long-term medical care. Previous research\nefforts have sought to extract meaningful information from electronic health\nrecords (EHRs) to facilitate combinatorial medication recommendations. Existing\nlearning-based approaches further consider the chemical structures of\nmedications, but ignore the textual medication descriptions in which the\nfunctionalities are clearly described. Furthermore, the textual knowledge\nderived from the EHRs of patients remains largely underutilized. To address\nthese issues, we introduce the Natural Language-Assisted Multi-modal Medication\nRecommendation(NLA-MMR), a multi-modal alignment framework designed to learn\nknowledge from the patient view and medication view jointly. Specifically,\nNLA-MMR formulates CMR as an alignment problem from patient and medication\nmodalities. In this vein, we employ pretrained language models(PLMs) to extract\nin-domain knowledge regarding patients and medications, serving as the\nfoundational representation for both modalities. In the medication modality, we\nexploit both chemical structures and textual descriptions to create medication\nrepresentations. In the patient modality, we generate the patient\nrepresentations based on textual descriptions of diagnosis, procedure, and\nsymptom. Extensive experiments conducted on three publicly accessible datasets\ndemonstrate that NLA-MMR achieves new state-of-the-art performance, with a\nnotable average improvement of 4.72% in Jaccard score. Our source code is\npublicly available on https:\/\/github.com\/jtan1102\/NLA-MMR_CIKM_2024."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03400",
    "c_title":[
      "Dependence of Krylov complexity on the initial operator and state"
    ],
    "c_abstract":[
      "Krylov complexity, a quantum complexity measure which uniquely characterizes\nthe spread of a quantum state or an operator, has recently been studied in the\ncontext of quantum chaos. However, the definitiveness of this measure as a\nchaos quantifier is in question in light of its strong dependence on the\ninitial condition. This article clarifies the connection between the Krylov\ncomplexity dynamics and the initial operator or state. We find that the Krylov\ncomplexity depends monotonically on the inverse participation ratio (IPR) of\nthe initial condition in the eigenbasis of the Hamiltonian. We explain the\nreversal of the complexity saturation levels observed in\n\\href{https:\/\/doi.org\/10.1103\/PhysRevE.107.024217}{ Phys.Rev.E.107,024217,\n2023} using the initial spread of the operator in the Hamiltonian eigenbasis.\nIPR dependence is present even in the fully chaotic regime, where popular\nquantifiers of chaos, such as out-of-time-ordered correlators and entanglement\ngeneration, show similar behavior regardless of the initial condition. Krylov\ncomplexity averaged over many initial conditions still does not characterize\nchaos."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-657",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14077",
    "b_title":[
      "The effect of a band gap gradient on the radiative losses in the open\n  circuit voltage of solar cells"
    ],
    "b_abstract":[
      "The radiative open circuit voltage loss in a solar cell occurs because the\nabsorptance spectrum near the band gap shows gradual increase rather than sharp\nstep function like transition. This broadening effect has been attributed to\nband gap fluctuations and or to Urbach tails. In this report, we use modelling\nbased on Planck s generalized law to distinguish between these two effects. Our\nresults demonstrate that Urbach tails have only a minimal effect on the\nabsorptance edge broadening and clarify that even an ideal direct semiconductor\nwith no band gap fluctuations shows broadening at the absorptance onset.\nFurthermore, state of the art inorganic thin film solar cells often incorporate\na band gap gradient across their thickness, which can further contribute to\nabsorptance broadening. Using Cu(In,Ga)Se2 (CIGSe) absorbers as a case study,\nwe perform a comprehensive analysis of voltage losses through absolute\nphotoluminescence and electroluminescence spectroscopy, combined with\nphotospectrometry and high-spatial-resolution cathodoluminescence measurements.\nWe find that the loss analysis based on the combination of radiative,\ngeneration and non-radiative losses is complete. Samples with a graded band gap\nprofile show more pronounced broadening of the absorptance onset and up to 16\nmV higher radiative losses compared to the samples with uniform band gap. There\nis indication, that band gap-graded samples also have larger lateral band gap\ninhomogeneity."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07835",
    "c_title":[
      "Bridging LLM-Generated Code and Requirements: Reverse Generation\n  technique and SBC Metric for Developer Insights"
    ],
    "c_abstract":[
      "The rise of Large Language Models (LLMs) in software engineering,\nparticularly in code generation, has garnered significant attention. However,\nassessing the quality of AI-generated code remains a challenge due to the\ninherent complexity of programming tasks and the lack of robust evaluation\nmetrics that align well with human judgment. Traditional token-based metrics\nsuch as BLEU and ROUGE, while commonly used in natural language processing,\nexhibit weak correlations with human assessments in code intelligence and\nverification tasks. Furthermore, these metrics are primarily research focused\nand are not designed for seamless integration into the software development\nlifecycle, limiting their practical utility for developers seeking to improve\ncode quality and security.\n  AI-assisted coding has been shown to be more beneficial for senior\ndevelopers, as they possess the expertise to critically evaluate the generated\ncode for correctness, completeness, and compliance. In contrast, junior\ndevelopers may struggle to identify hallucinations, missing functionality, or\nincorrect logic in AI-generated code. To bridge this gap, This paper introduces\na novel scoring mechanism called the SBC score, which is based on a reverse\ngeneration technique that leverages the natural language generation\ncapabilities of LLMs. Unlike direct code analysis, our approach reconstructs\nsystem requirements from AI-generated code and compares them with the original\nspecifications to quantify accuracy. The SBC score combines semantic\nsimilarity, BLEU, and completeness analysis, providing actionable insights to\ndevelopers by highlighting missing features and hallucinations. Our code and\ndatasets are available on GitHub"
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-658",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12637",
    "b_title":[
      "DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet\n  Transform"
    ],
    "b_abstract":[
      "Neural Radiance Fields (NeRF) has achieved superior performance in novel view\nsynthesis and 3D scene representation, but its practical applications are\nhindered by slow convergence and reliance on dense training views. To this end,\nwe present DWTNeRF, a unified framework based on Instant-NGP's fast-training\nhash encoding. It is coupled with regularization terms designed for few-shot\nNeRF, which operates on sparse training views. Our DWTNeRF additionally\nincludes a novel Discrete Wavelet loss that allows explicit prioritization of\nlow frequencies directly in the training objective, reducing few-shot NeRF's\noverfitting on high frequencies in earlier training stages. We also introduce a\nmodel-based approach, based on multi-head attention, that is compatible with\nINGP, which are sensitive to architectural changes. On the 3-shot LLFF\nbenchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM\nand 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot\napproaches for fast-converging implicit representations like INGP or 3DGS."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14041",
    "c_title":[
      "Looking for new strategies to probe low mass axion-like particles in\n  ultraperipheral heavy-ion collisions at the LHC"
    ],
    "c_abstract":[
      "The possibility of searching for long-lived axion-like particles (ALPs)\ndecaying into photons is investigated in ultraperipheral $PbPb$ collisions at\nthe Large Hadron Collider (LHC). We propose a search strategy for low mass ALPs\nusing the LHCb and ALICE experiments. The ALP identification is performed by\nrequiring the decay vertex be reconstructed outside the region where a primary\nvertex is expected, which strongly suppress the contribution associated with\nthe decay of light mesons. We also use the fact that a fraction of the photons\nconvert into electron-positron pairs, allowing the reconstruction of the\nparticle decay position. We present the predictions for the pseudo - rapidity\nand transverse momentum distributions of the ALPs and photons. Moreover,\npredictions for the fiducial cross-sections, derived considering the\ncharacteristics of the ALICE and LHCb detectors, are presented for different\nvalues of the ALP mass and the ALP - photon coupling."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-659",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03420",
    "b_title":[
      "Hydrodynamic memory and Quincke rotation"
    ],
    "b_abstract":[
      "The spontaneous (so-called Quincke) rotation of an uncharged, solid,\ndielectric, spherical particle under a steady electric field is analyzed,\naccounting for the inertia of the particle and the transient fluid inertia, or\n``hydrodynamic memory,'' due to the unsteady Stokes flow around the particle.\nThe dynamics of the particle are encapsulated in three coupled nonlinear\nintegro-differential equations for the evolution of the angular velocity of the\nparticle, and the components of the induced dipole of the particle that are\nparallel and transverse to the applied field. These equations represent a\ngeneralization of the celebrated Lorenz system. A numerical solution of these\n`modified Lorenz equations' (MLE) shows that hydrodynamic memory leads to an\nincrease in the threshold field strength for chaotic particle rotation, which\nis in qualitative agreement with experimental observations. Furthermore,\nhydrodynamic memory leads to an increase in the range of field strengths where\nmulti-stability between steady and chaotic rotation occurs. At large field\nstrengths, chaos ceases and the particle is predicted to execute periodic\nrotational motion."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13722",
    "c_title":[
      "Symmetric 2-(35,17,8) designs with an automorphism of order 2"
    ],
    "c_abstract":[
      "The largest prime p that can be the order of an automorphism of a 2-(35,17,8)\ndesign is p=17, and all 2-(35,17,8) designs with an automorphism of order 17\nwere classified by Tonchev. The symmetric 2-(35,17,8) designs with\nautomorphisms of odd prime order $p<17$ were also classified. In this paper we\ngive the classification of all symmetric 2-(35,17,8) designs that admit an\nautomorphism of order $p=2$. It is shown that there are exactly $11,642,495$\nnonisomorphic such designs. Furthermore, it is shown that the number of\nnonisomorphic 3-(36,18,8) designs which have at least one derived 2-$(35,17,8)$\ndesign with an automorphism of order 2, is $1,015,225$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-660",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04313",
    "b_title":[
      "Episodes from the history of infinitesimals"
    ],
    "b_abstract":[
      "Infinitesimals have seen ups and downs in their tumultuous history. In the\n18th century, d'Alembert set the tone by describing infinitesimals as chimeras.\nSome adversaries of infinitesimals, including Moigno and Connes, picked up on\nthe term. We highlight the work of Cauchy, No\\\"el, Poisson and Riemann. We also\nchronicle reactions by Moigno, Lamarle and Cantor, and signal the start of a\nrevival with Peano."
    ],
    "b_categories":[
      [
        "math.HO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.14229",
    "c_title":[
      "On the multi-$\\mathbf{q}$ characteristics of magnetic ground states of\n  honeycomb cobalt oxides"
    ],
    "c_abstract":[
      "The Kitaev honeycomb model has received significant attention for its exactly\nsolvable quantum spin liquid ground states and fractionalized excitations. For\nrealizing the model, layered cobalt oxides have been considered a promising\nplatform. Yet, in contrast to the conventional wisdom about single-$\\mathbf{q}$\nzigzag magnetic order inferred from previous studies of the Na$_2$IrO$_3$ and\n$\\alpha$-RuCl$_3$ candidate materials, recent experiments on two of the\nrepresentative honeycomb cobalt oxides, hexagonal Na$_2$Co$_2$TeO$_6$ and\nmonoclinic Na$_3$Co$_2$SbO$_6$, have uncovered evidence for more complex\nmulti-$\\mathbf{q}$ variants of the zigzag order. This review surveys on\nexperimental strategies to distinguish between single- and multi-$\\mathbf{q}$\norders, along with the crystallographic symmetries of the cobalt oxides in\ncomparison to the previously studied systems. General formation mechanism of\nmulti-$\\mathbf{q}$ order is also briefly discussed. The goal is to provide some\nrationales for examining the relevance of multi-$\\mathbf{q}$ order in the\nhoneycomb cobalt oxides, along with its implications on the microscopic model\nof these intriguing quantum magnets."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-661",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04279",
    "b_title":[
      "OpenIN: Open-Vocabulary Instance-Oriented Navigation in Dynamic Domestic\n  Environments"
    ],
    "b_abstract":[
      "In daily domestic settings, frequently used objects like cups often have\nunfixed positions and multiple instances within the same category, and their\ncarriers frequently change as well. As a result, it becomes challenging for a\nrobot to efficiently navigate to a specific instance. To tackle this challenge,\nthe robot must capture and update scene changes and plans continuously.\nHowever, current object navigation approaches primarily focus on the semantic\nlevel and lack the ability to dynamically update scene representation. In\ncontrast, this paper captures the relationships between frequently used objects\nand their static carriers. It constructs an open-vocabulary\nCarrier-Relationship Scene Graph (CRSG) and updates the carrying status during\nrobot navigation to reflect the dynamic changes of the scene. Based on the\nCRSG, we further propose an instance navigation strategy that models the\nnavigation process as a Markov Decision Process. At each step, decisions are\ninformed by the Large Language Model's commonsense knowledge and\nvisual-language feature similarity. We designed a series of long-sequence\nnavigation tasks for frequently used everyday items in the Habitat simulator.\nThe results demonstrate that by updating the CRSG, the robot can efficiently\nnavigate to moved targets. Additionally, we deployed our algorithm on a real\nrobot and validated its practical effectiveness. The project page can be found\nhere: https:\/\/OpenIN-nav.github.io."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13615",
    "c_title":[
      "A new study of the interactions of the axion with mesons and photons\n  using a chiral effective Lagrangian model"
    ],
    "c_abstract":[
      "In this paper, we extend the results obtained in a previous work and\ninvestigate the most interesting decay processes involving axions, photons and\nthe lightest pseudoscalar mesons in the more general case in which the quarks\n(and, therefore, the mesons) may be charged under the $U(1)$ Peccei-Quinn\nsymmetry, making use of a chiral effective Lagrangian model with $N_f=3$ light\nquark flavors, which also includes the flavor-singlet pseudoscalar meson and\nimplements the $U(1)$ axial anomaly of the fundamental theory. In particular,\nwe compute the axion mass, the electromagnetic coupling of the axion to\nphotons, and the amplitudes and widths of the decay processes\n$\\eta\/\\eta'\\rightarrow \\pi\\pi a$."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-662",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02292",
    "b_title":[
      "Optimal Control for Remote Patient Monitoring with Multidimensional\n  Health States"
    ],
    "b_abstract":[
      "Selecting the right monitoring level in Remote Patient Monitoring (RPM)\nsystems for e-healthcare is crucial for balancing patient outcomes, various\nresources, and patient's quality of life. A prior work has used one-dimensional\nhealth representations, but patient health is inherently multidimensional and\ntypically consists of many measurable physiological factors. In this paper, we\nintroduce a multidimensional health state model within the RPM framework and\nuse dynamic programming to study optimal monitoring strategies. Our analysis\nreveals that the optimal control is characterized by switching curves (for\ntwo-dimensional health states) or switching hyper-surfaces (in general):\npatients switch to intensive monitoring when health measurements cross a\nspecific multidimensional surface. We further study how the optimal switching\ncurve varies for different medical conditions and model parameters. This\nfinding of the optimal control structure provides actionable insights for\nclinicians and aids in resource planning. The tunable modeling framework\nenhances the applicability and effectiveness of RPM services across various\nmedical conditions."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07272",
    "c_title":[
      "A Large-Scale Reconfigurable Multiplexed Quantum Photonic Network"
    ],
    "c_abstract":[
      "Entanglement distribution in quantum networks will enable next-generation\ntechnologies for quantum-secured communications, distributed quantum computing\nand sensing. Future quantum networks will require dense connectivity, allowing\nmultiple users to share entanglement in a reconfigurable and multiplexed\nmanner, while long-distance connections are established through the\nteleportation of entanglement, or entanglement swapping. While several recent\nworks have demonstrated fully connected, local multi-user networks based on\nmultiplexing, extending this to a global network architecture of interconnected\nlocal networks remains an outstanding challenge. Here we demonstrate the next\nstage in the evolution of multiplexed quantum networks: a prototype global\nreconfigurable network where entanglement is routed and teleported in a\nflexible and multiplexed manner between two local multi-user networks composed\nof four users each. At the heart of our network is a programmable\n8x8-dimensional multi-port circuit that harnesses the natural mode-mixing\nprocess inside a multi-mode fibre to implement on-demand high-dimensional\noperations on two independent photons carrying eight transverse-spatial modes.\nOur circuit design allows us to break away from the limited planar geometry and\nbypass the control and fabrication challenges of conventional integrated\nphotonic platforms. Our demonstration showcases the potential of this\narchitecture for enabling large-scale, global quantum networks that offer\nversatile connectivity while being fully compatible with an existing\ncommunications infrastructure."
    ],
    "c_categories":[
      [
        "physics.optics",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-663",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06367",
    "b_title":[
      "Observing the exponential growth of the eigenmodes in the absence of\n  coalescence for a non-Hermitian circuit with an unavoidable inductor\n  dissipation"
    ],
    "b_abstract":[
      "We investigate, both experimentally and theoretically, the eigenmodes of an\nelectronic circuit in which gain and loss $RLC$ resonators are coupled through\na capacitor. Due to the unavoidable magnetic loss in the inductors, we find\nthat the eigenmode coalescence no longer emerges in contrast to the\nconventional non-Hermitian systems with the spontaneous $\\cal{PT}$-symmetry\nbreaking. In particular, we find a transition from the exponential decay to\nexponential growth in the amplitude of the periodic voltage oscillations of the\nresonators. The transition occurs near the exceptional points of the\nnon-Hermitian circuit without considering the dissipations in inductors. We\nintroduce a small resistor of three orders of magnitude smaller than that of\nthe $RLC$ resonators to mimic the energy dissipation in inductors and\nnumerically solve the equivalent non-Hermitian Schr{\\\" o}dinger equation. The\nnumerical results can well reproduce experimental observations. Our above\nfindings unambiguously indicate that the exponential growth behavior beyond the\nexceptional points is robust against some unavoidable dissipative\nperturbations."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2501.09644",
    "c_title":[
      "Planetary Rhythms: Synchronous Circulation on Variably Irradiated\n  Asynchronous Planets"
    ],
    "c_abstract":[
      "Tidal locking of planets to their host stars results in an atmospheric\ncirculation with a hotspot fixed to the frame of reference of the planet. On\nthe other hand, asynchronously rotating planets feature moving hotspots either\nlagging or leading the corresponding substellar point as it translates along\nthe surface. We show that a planet falling in the latter category could mimic\nthe circulation of tidally synchronous planets under the influence of\ntime-varying instellation, possibly provided by pulsating or multiple star\nsystems. This happens when the planets diurnal period is in resonance with the\nperiod of instellation variation, leading to a planet-frame-fixed hotspot.\nSlight differences in the above periods lead to East-West or West-East creeping\nhotspots with a period significantly longer than both. The rate of hotspot\nmotion is given by the difference between the diurnal and instellation\nvariation rates, similar to the lower envelope frequency of beat patterns\nformed by two superposed waves in linear wave theory. We call this phenomenon\nbeating. A combination of the radiative, rotational, wave propagation, and drag\ntimescales establishes dynamical constraints on beating. Based on this we\nclassify a set of Kepler and TESS circumbinary planets with two candidates\nexhibiting climatic departures from the no-variation scenario. In general,\nhotter and faster-spinning planets are more susceptible to climatic departures.\nBeating, if it occurs, may additionally create optimistic extensions of\nhabitable zones for corresponding systems."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-664",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07432",
    "b_title":[
      "Quadratic quasinormal modes at null infinity on a Schwarzschild\n  spacetime"
    ],
    "b_abstract":[
      "The ringdown of perturbed black holes has been studied since the 1970s, but\nuntil recently, studies have focused on linear perturbations. There is now\nburgeoning interest in nonlinear perturbative effects during ringdown. Here,\nusing a hyperboloidal framework, we provide a complete treatment of linear and\nquadratic quasinormal modes (QNMs and QQNMs) in second-order perturbation\ntheory, in Schwarzschild spacetime. We include novel methods for extracting\nQNMs and QQNMs amplitudes using a Laplace transform treatment, allowing for the\ninclusion of arbitrary initial data. We produce both time- and frequency-domain\ncodes. From these codes, we present new results further exploring the\nunforeseen dependence of QQNMs amplitudes on the parity of the progenitor\nsystem, as demonstrated in our letter [Phys. Rev. Lett. 134, 061401 (2025)].\nOur numerical results are restricted to perturbations of a Schwarzschild black\nhole, but our methods extend straightforwardly to the astrophysically realistic\ncase of a Kerr black hole."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13769",
    "c_title":[
      "A consensus set for the aggregation of partial rankings: the case of the\n  Optimal Set of Bucket Orders Problem"
    ],
    "c_abstract":[
      "In rank aggregation problems (RAP), the solution is usually a consensus\nranking that generalizes a set of input orderings. There are different variants\nthat differ not only in terms of the type of rankings that are used as input\nand output, but also in terms of the objective function employed to evaluate\nthe quality of the desired output ranking. In contrast, in some machine\nlearning tasks (e.g. subgroup discovery) or multimodal optimization tasks,\nattention is devoted to obtaining several models\/results to account for the\ndiversity in the input data or across the search landscape. Thus, in this paper\nwe propose to provide, as the solution to an RAP, a set of rankings to better\nexplain the preferences expressed in the input orderings. We exemplify our\nproposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists\nin finding a single consensus ranking (with ties) that generalizes a set of\ninput rankings codified as a precedence matrix. To address this, we introduce\nthe Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP\nthat aims to produce not a single ranking as output but a set of consensus\nrankings. Experimental results are presented to illustrate this proposal,\nshowing how, by providing a set of consensus rankings, the fitness of the\nsolution significantly improves with respect to the one of the original OBOP,\nwithout losing comprehensibility."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-665",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10346",
    "b_title":[
      "Normal forms and geometric structures on Hopf manifolds"
    ],
    "b_abstract":[
      "We prove that Hopf manifolds admit holomorphic $(G,X)$-structures, extending\nto any dimension a result of McKay and Pokrovskiy. For this, we revisit\nGuysinsky-Katok's group of invertible sub-resonant polynomials, and\nBertheloot's approach of Poincar\\'e-Dulac normal form theory."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08619",
    "c_title":[
      "A lattice QCD calculation of the Compton amplitude subtraction function"
    ],
    "c_abstract":[
      "The Compton amplitude subtraction function is an essential component in work\nconcerning both the proton radius puzzle and the proton-neutron mass\ndifference. However, owing to the difficulty in determining the subtraction\nfunction, it remains a key source of uncertainty in these two contexts. Here,\nwe use the Feynman-Hellmann method to determine this subtraction function\ndirectly from lattice QCD. Furthermore, we demonstrate how to control dominant\ndiscretisation artefacts for this calculation, eliminating a major source of\nsystematic error. This calculation is performed for a range of hard momentum\nscales, and three different sets of gauge configurations for pion masses about\n400 MeV. Our results show good agreement with continuum OPE expectations. As\nsuch, this work paves the way for model-independent and precise determinations\nof the subtraction function over a wide range of kinematics."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-666",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06429",
    "b_title":[
      "Reliable Imputed-Sample Assisted Vertical Federated Learning"
    ],
    "b_abstract":[
      "Vertical Federated Learning (VFL) is a well-known FL variant that enables\nmultiple parties to collaboratively train a model without sharing their raw\ndata. Existing VFL approaches focus on overlapping samples among different\nparties, while their performance is constrained by the limited number of these\nsamples, leaving numerous non-overlapping samples unexplored. Some previous\nwork has explored techniques for imputing missing values in samples, but often\nwithout adequate attention to the quality of the imputed samples. To address\nthis issue, we propose a Reliable Imputed-Sample Assisted (RISA) VFL framework\nto effectively exploit non-overlapping samples by selecting reliable imputed\nsamples for training VFL models. Specifically, after imputing non-overlapping\nsamples, we introduce evidence theory to estimate the uncertainty of imputed\nsamples, and only samples with low uncertainty are selected. In this way,\nhigh-quality non-overlapping samples are utilized to improve VFL model.\nExperiments on two widely used datasets demonstrate the significant performance\ngains achieved by the RISA, especially with the limited overlapping samples,\ne.g., a 48% accuracy gain on CIFAR-10 with only 1% overlapping samples."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16735",
    "c_title":[
      "Stochastic Population Update Provably Needs An Archive in Evolutionary\n  Multi-objective Optimization"
    ],
    "c_abstract":[
      "Evolutionary algorithms (EAs) have been widely applied to multi-objective\noptimization, due to their nature of population-based search. Population\nupdate, a key component in multi-objective EAs (MOEAs), is usually performed in\na greedy, deterministic manner. However, recent studies have questioned this\npractice and shown that stochastic population update (SPU), which allows\ninferior solutions have a chance to be preserved, can help MOEAs jump out of\nlocal optima more easily. While introducing randomness in the population update\nprocess boosts the exploration of MOEAs, there is a drawback that the\npopulation may not always preserve the very best solutions found, thus\nentailing a large population. Intuitively, a possible solution to this issue is\nto introduce an archive that stores the best solutions ever found. In this\npaper, we theoretically show that using an archive can allow a small population\nand accelerate the search of SPU-based MOEAs substantially. Specifically, we\nanalyze the expected running time of two well-established MOEAs, SMS-EMOA and\nNSGA-II, with SPU for solving a commonly studied bi-objective problem\nOneJumpZeroJump, and prove that using an archive can bring (even exponential)\nspeedups. The comparison between SMS-EMOA and NSGA-II also suggests that the\n$(\\mu+\\mu)$ update mode may be more suitable for SPU than the $(\\mu+1)$ update\nmode. Furthermore, our derived running time bounds for using SPU alone are\nsignificantly tighter than previously known ones. Our theoretical findings are\nalso empirically validated on a well-known practical problem, the\nmulti-objective traveling salesperson problem. We hope this work may provide\ntheoretical support to explore different ideas of designing algorithms in\nevolutionary multi-objective optimization."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-667",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11981",
    "b_title":[
      "DecompDreamer: Advancing Structured 3D Asset Generation with\n  Multi-Object Decomposition and Gaussian Splatting"
    ],
    "b_abstract":[
      "Text-to-3D generation saw dramatic advances in recent years by leveraging\nText-to-Image models. However, most existing techniques struggle with\ncompositional prompts, which describe multiple objects and their spatial\nrelationships. They often fail to capture fine-grained inter-object\ninteractions. We introduce DecompDreamer, a Gaussian splatting-based training\nroutine designed to generate high-quality 3D compositions from such complex\nprompts. DecompDreamer leverages Vision-Language Models (VLMs) to decompose\nscenes into structured components and their relationships. We propose a\nprogressive optimization strategy that first prioritizes joint relationship\nmodeling before gradually shifting toward targeted object refinement. Our\nqualitative and quantitative evaluations against state-of-the-art text-to-3D\nmodels demonstrate that DecompDreamer effectively generates intricate 3D\ncompositions with superior object disentanglement, offering enhanced control\nand flexibility in 3D generation. Project page :\nhttps:\/\/decompdreamer3d.github.io"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15254",
    "c_title":[
      "Highly Variable Quasar Candidates Selected from 4XMM-DR13 with Machine\n  Learning"
    ],
    "c_abstract":[
      "We present a sample of 12 quasar candidates with highly variable soft X-ray\nemission from the 4th XMM-newton Serendipitous Source Catalog (4XMM-DR13) using\nrandom forest. We obtained optical to mid-IR photometric data for the 4XMM-DR13\nsources by correlating the sample with the SDSS DR18 photometric database and\nthe AllWISE database. By cross-matching this sample with known spectral\ncatalogs from the SDSS and LAMOST surveys, we obtained a training data set\ncontaining stars, galaxies, and quasars. The random forest algorithm was\ntrained to classify the XMM-WISE-SDSS sample. We further filtered the\nclassified quasar candidates with $\\it{Gaia}$ proper motion to remove stellar\ncontaminants. Finally, 53,992 quasar candidates have been classified, with\n10,210 known quasars matched in SIMBAD. The quasar candidates have\nsystematically lower X-ray fluxes than quasars in the training set, which\nindicates the classifier is helpful to single out fainter quasars. We\nconstructed a sample of 12 sources from these quasars candidates which changed\ntheir soft X-ray fluxes by a factor of 10 over $\\sim$ 20 years in the\n4XMM-newton survey. Our selected highly variable quasar candidates extend the\nquasar sample, characterized by extreme soft X-ray variability, to the\noptically faint end with magnitudes around $r \\sim 22$. None of the 12 sources\nwere detected in ROSAT observations. Given the flux limit of ROSAT, the result\nsuggests that quasars exhibiting variations of more than two orders of\nmagnitudes are extremely rare."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-668",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08308",
    "b_title":[
      "prunAdag: an adaptive pruning-aware gradient method"
    ],
    "b_abstract":[
      "A pruning-aware adaptive gradient method is proposed which classifies the\nvariables in two sets before updating them using different strategies. This\ntechnique extends the ``relevant\/irrelevant\" approach of Ding (2019) and Zimmer\net al. (2022) and allows a posteriori sparsification of the solution of model\nparameter fitting problems. The new method is proved to be convergent with a\nglobal rate of decrease of the averaged gradient's norm of the form\n$\\calO(\\log(k)\/\\sqrt{k+1})$. Numerical experiments on several applications show\nthat it is competitive."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08576",
    "c_title":[
      "Intelligent Reflecting Surfaces for Wireless Networks: Deployment\n  Architectures, Key Solutions, and Field Trials"
    ],
    "c_abstract":[
      "Intelligent reflecting surfaces (IRSs) have emerged as a transformative\ntechnology for wireless networks by improving coverage, capacity, and energy\nefficiency through intelligent manipulation of wireless propagation\nenvironments. This paper provides a comprehensive study on the deployment and\ncoordination of IRSs for wireless networks. By addressing both single- and\nmulti-reflection IRS architectures, we examine their deployment strategies\nacross diverse scenarios, including point-to-point, point-to-multipoint, and\npoint-to-area setups. For the single-reflection case, we highlight the\ntrade-offs between passive and active IRS architectures in terms of beamforming\ngain, coverage extension, and spatial multiplexing. For the multi-reflection\ncase, we discuss practical strategies to optimize IRS deployment and element\nallocation, balancing cooperative beamforming gains and path loss. The paper\nfurther discusses practical challenges in IRS implementation, including\nenvironmental conditions, system compatibility, and hardware limitations.\nNumerical results and field tests validate the effectiveness of IRS-aided\nwireless networks and demonstrate their capacity and coverage improvements.\nLastly, promising research directions, including movable IRSs, near-field\ndeployments, and network-level optimization, are outlined to guide future\ninvestigations."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-669",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04988",
    "b_title":[
      "CMamba: Learned Image Compression with State Space Models"
    ],
    "b_abstract":[
      "Learned Image Compression (LIC) has explored various architectures, such as\nConvolutional Neural Networks (CNNs) and transformers, in modeling image\ncontent distributions in order to achieve compression effectiveness. However,\nachieving high rate-distortion performance while maintaining low computational\ncomplexity (\\ie, parameters, FLOPs, and latency) remains challenging. In this\npaper, we propose a hybrid Convolution and State Space Models (SSMs) based\nimage compression framework, termed \\textit{CMamba}, to achieve superior\nrate-distortion performance with low computational complexity. Specifically,\nCMamba introduces two key components: a Content-Adaptive SSM (CA-SSM) module\nand a Context-Aware Entropy (CAE) module. First, we observed that SSMs excel in\nmodeling overall content but tend to lose high-frequency details. In contrast,\nCNNs are proficient at capturing local details. Motivated by this, we propose\nthe CA-SSM module that can dynamically fuse global content extracted by SSM\nblocks and local details captured by CNN blocks in both encoding and decoding\nstages. As a result, important image content is well preserved during\ncompression. Second, our proposed CAE module is designed to reduce spatial and\nchannel redundancies in latent representations after encoding. Specifically,\nour CAE leverages SSMs to parameterize the spatial content in latent\nrepresentations. Benefiting from SSMs, CAE significantly improves spatial\ncompression efficiency while reducing spatial content redundancies. Moreover,\nalong the channel dimension, CAE reduces inter-channel redundancies of latent\nrepresentations via an autoregressive manner, which can fully exploit prior\nknowledge from previous channels without sacrificing efficiency. Experimental\nresults demonstrate that CMamba achieves superior rate-distortion performance."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11125",
    "c_title":[
      "Asymptotic Growth of Trivial Summands in Tensor Powers"
    ],
    "c_abstract":[
      "Given a finite-dimensional representation $V$ over an algebraically closed\nfield of an abstract group $G$, we consider the number of the trivial summand\ncounted with multiplicity in the direct sum decomposition of $V^{\\otimes n}$.\nWe give necessary and sufficient conditions when the field is of characteristic\n$0$ and when the field is of characteristic $p$ so that $(V^{\\otimes n})_n$ has\na subsequence $(V^{\\otimes n_k})_k$ such that $V^{\\otimes n_k}$ contains enough\ntrivial summands when $k$ is sufficiently large."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-670",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01149",
    "b_title":[
      "A3: Android Agent Arena for Mobile GUI Agents"
    ],
    "b_abstract":[
      "AI agents have become increasingly prevalent in recent years, driven by\nsignificant advancements in the field of large language models (LLMs). Mobile\nGUI agents, a subset of AI agents, are designed to autonomously perform tasks\non mobile devices. While numerous studies have introduced agents, datasets, and\nbenchmarks to advance mobile GUI agent research, many existing datasets focus\non static frame evaluations and fail to provide a comprehensive platform for\nassessing performance on real-world, in-the-wild tasks. To address this gap, we\npresent Android Agent Arena (A3), a novel evaluation platform. Unlike existing\nin-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as\nreal-time online information retrieval and operational instructions; (2) a\nlarger, more flexible action space, enabling compatibility with agents trained\non any dataset; and (3) automated business-level LLM-based evaluation process.\nA3 includes 21 widely used general third-party apps and 201 tasks\nrepresentative of common user scenarios, providing a robust foundation for\nevaluating mobile GUI agents in real-world situations and a new autonomous\nevaluation process for less human labor and coding expertise. The project is\navailable at https:\/\/yuxiangchai.github.io\/Android-Agent-Arena\/."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09904",
    "c_title":[
      "Improved bound on the number of cycle sets"
    ],
    "c_abstract":[
      "The cycle set of a graph $G$ is the set consisting of all sizes of cycles in\n$G$. Answering a conjecture of Erd\\H{o}s and Faudree, Verstra\\\"{e}te showed\nthat there are at most $2^{n - n^{1\/10}}$ different cycle sets of graphs with\n$n$ vertices. We improve this bound to $2^{n - n^{1\/2 - o(1)}}$. Our proof\nfollows the general strategy of Verstra\\\"{e}te of reducing the problem to\ncounting cycle sets of Hamiltonian graphs with many chords or a large maximum\ndegree. The key new ingredients are near-optimal container lemmata for cycle\nsets of such graphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-671",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11801",
    "b_title":[
      "Diffuse-CLoC: Guided Diffusion for Physics-based Character Look-ahead\n  Control"
    ],
    "b_abstract":[
      "We present Diffuse-CLoC, a guided diffusion framework for physics-based\nlook-ahead control that enables intuitive, steerable, and physically realistic\nmotion generation. While existing kinematics motion generation with diffusion\nmodels offer intuitive steering capabilities with inference-time conditioning,\nthey often fail to produce physically viable motions. In contrast, recent\ndiffusion-based control policies have shown promise in generating physically\nrealizable motion sequences, but the lack of kinematics prediction limits their\nsteerability. Diffuse-CLoC addresses these challenges through a key insight:\nmodeling the joint distribution of states and actions within a single diffusion\nmodel makes action generation steerable by conditioning it on the predicted\nstates. This approach allows us to leverage established conditioning techniques\nfrom kinematic motion generation while producing physically realistic motions.\nAs a result, we achieve planning capabilities without the need for a high-level\nplanner. Our method handles a diverse set of unseen long-horizon downstream\ntasks through a single pre-trained model, including static and dynamic obstacle\navoidance, motion in-betweening, and task-space control. Experimental results\nshow that our method significantly outperforms the traditional hierarchical\nframework of high-level motion diffusion and low-level tracking."
    ],
    "b_categories":[
      [
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01742",
    "c_title":[
      "Multifluid tensorial equations for the flow of semi-dilute monodisperse\n  suspensions"
    ],
    "c_abstract":[
      "Using the volume averaging technique of Jackson (1997), we derive a set of\ntwo-fluid equations that describe the dynamics of a mono-disperse non-Brownian\ncolloidal suspension in the semi-dilute regime. The equations are tensorial and\ncan be applied in arbitrary geometries. Closure models are developed that\nrepresent the stress surrounding each particle as a sum of stresses due to\nfluid movement through a fixed bed of particles, and those due to interactions\nbetween particles. Emphasising pragmatism, the developed closure models are\nconsistent with current knowledge of particle interactions in these systems but\nemploy parameters that can be tuned to represent the microstructure of specific\nparticle suspensions. Within the interaction model, a model for the particle\ndistribution around each particle is used that depends on the strain rate\nfield, allowing anisotropy of the microstructure (and hence normal suspension\nstresses) to develop within the suspension in response to arbitrary strain\nfields. Force moments acting on particles during particle interactions are\ncalculating by summing hydrodynamic contributions between particle pairs, but\nadjusted to recognise that multi-particle interactions can increase the\neffective stress generated during each interaction. Finally, an order of\nmagnitude analysis is performed on the derived momentum equations to determine\nwhat terms are significant, leaving only terms in the final equations that are\nrequired to predict behaviour during laminar flow within the targeted\nsemi-dilute regime. In a companion paper (referred to as paper II, Noori et.\nal., 2024) we chose sets of microstructure parameters that predict\nexperimentally measured bulk suspension behaviour, creating a link between\nparticle properties (i.e. roughness), suspension microstructure and\nshear-induced particle migration in arbitrary flow fields."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-672",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02301",
    "b_title":[
      "Towards Large Language Model Guided Kernel Direct Fuzzing"
    ],
    "b_abstract":[
      "Direct kernel fuzzing is a targeted approach that focuses on specific areas\nof the kernel, effectively addressing the challenges of frequent updates and\nthe inherent complexity of operating systems, which are critical\ninfrastructure. This paper introduces SyzAgent, a framework that integrates\nLLMs with the state-of-the-art kernel fuzzer Syzkaller, where the LLMs are used\nto guide the mutation and generation of test cases in real-time. We present\npreliminary results demonstrating that this method is effective on around 67\\%\ncases in our benchmark during the experiment."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04385",
    "c_title":[
      "\"Exact\" solutions for circularly polarized Kerr solitons"
    ],
    "c_abstract":[
      "For the nonlinear vector curl-curl equation describing a monochromatic light\nwave in a Kerr medium, an exact reduction is suggested which results in a\nsystem of four ordinary differential equations, of the first order each, for\nfunctions of the transverse radial coordinate. Numerical solutions of this\nsystem, with appropriate boundary conditions, give full information about\ninternal structure of a strongly nonlinear, stationary optical beam consisting\nmainly of a definite circular polarization, but with a small portion of the\nopposite polarization containing a double vortex, as well as with the parallel\ncomponent of the electric field containing an ordinary vortex."
    ],
    "c_categories":[
      [
        "nlin.PS",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-673",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11260",
    "b_title":[
      "To Assess the Impact of Smart Cities on Urbanization Patterns in the\n  United States"
    ],
    "b_abstract":[
      "This paper investigates the relationship between smart city initiatives and\nevolving urbanization trends in the United States. The research addresses the\ncritical issue of rapid urban growth in the U.S. and explores how innovations\nwithin the smart city paradigm influence urban development. Utilizing\nprinciples from Urban Complexity Theory, this study identifies four key\nvariables relevant to smart cities and their impact on urbanization: smart city\ntechnology, government policy, environmental sustainability, and socioeconomic\nfactors. A mixed-method approach, combining quantitative and qualitative\nmethodologies, was employed. A web-based survey (n=50) utilizing a five-point\nLikert scale was conducted among residents of Manhattan, New York, and Capitol\nHill, Seattle. Results indicate that the implementation of smart city\ntechnologies is significantly associated with shifts in population density,\nland use diversification, and enhanced infrastructure dynamics. Additionally,\nresidents demonstrated preferences for smart cities based on efficient urban\nmobility, environmental sustainability, and personal socioeconomic\nimprovements. The findings highlight essential considerations for urban\nplanners, policymakers, and employers. This study concludes that incorporating\nthe identified influential factors into strategic urban planning optimizes city\ndevelopment to better accommodate growing urban populations."
    ],
    "b_categories":[
      [
        "cs.CY",
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17590",
    "c_title":[
      "Dual Block Gradient Ascent for Entropically Regularised Quantum Optimal\n  Transport"
    ],
    "c_abstract":[
      "We present a block gradient ascent method for solving the quantum optimal\ntransport problem with entropic regularisation similar to the algorithm\nproposed in [D. Feliciangeli, A. Gerolin, L. Portinale: J. Funct. Anal. 285\n(2023), no. 4, 109963] and [E. Caputo, A. Gerolin, N. Monina, L. Portinale:\narXiv:2409.03698]. We prove a linear convergence rate based on strong concavity\nof the dual functional and present some results of numerical experiments of an\nimplementation."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math-ph",
        "math.MP",
        "math.NA",
        "math.OC",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-674",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11343",
    "b_title":[
      "SPLD polynomial optimization and bounded degree SOS hierarchies"
    ],
    "b_abstract":[
      "In this paper, a new class of structured polynomials, which we dub the {\\it\nseparable plus lower degree {\\rm (SPLD in short)} polynomials}, is introduced.\nThe formal definition of an SPLD polynomial, which extends the concept of the\nSPQ polynomial (Ahmadi et al. in Math Oper Res 48:1316--1343, 2023), is\ndefined. A type of bounded degree SOS hierarchy (BSOS-SPLD) is proposed to\nefficiently solve the optimization problems with SPLD polynomials, and several\nnumerical examples are performed much better than the bounded degree SOS\nhierarchy (Lasserre et al. in EURO J Comput Optim 5:87--117, 2017). An exact\nSOS relaxation for a class of convex SPLD polynomial optimization problems is\nproposed. Finally, an application of SPLD polynomials to polynomial regression\nproblems in statistics is presented."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06120",
    "c_title":[
      "Exact solvability of the Gross-Pitaevskii equation for bound states\n  subjected to general potentials"
    ],
    "c_abstract":[
      "In this paper we present the analytic solution to the problem of bound states\nof the Gross-Pitaevskii (GP) equation in 1D and its properties, in the presence\nof external potentials in the form of finite square wells or attractive Dirac\ndeltas, as well as stable solitons for repulsive defects. We show that the GP\nequation can be mapped to a first-order non-autonomous dynamical system, whose\nsolutions can sometimes be written in terms of known functions. The formal\nsolutions of this non-conservative system can be written with the help of\nGlauber-Trotter formulas or a series of ordered exponentials in the coordinate\n$x$. With this we illustrate how to solve any nonlinear problem based on a\nconstruction due to Mello and Kumar for the linear case (layered potentials).\nFor the benefit of the reader, we comment on the difference between the\nintegrability of a quantum system and the solvability of the wave equation."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-675",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17201",
    "b_title":[
      "Towards Carbon Footprint-Aware Recommender Systems for Greener Item\n  Recommendation"
    ],
    "b_abstract":[
      "The commodity and widespread use of online shopping are having an\nunprecedented impact on climate, with emission figures from key actors that are\neasily comparable to those of a large-scale metropolis. Despite online shopping\nbeing fueled by recommender systems (RecSys) algorithms, the role and potential\nof the latter in promoting more sustainable choices is little studied. One of\nthe main reasons for this could be attributed to the lack of a dataset\ncontaining carbon footprint emissions for the items. While building such a\ndataset is a rather challenging task, its presence is pivotal for opening the\ndoors to novel perspectives, evaluations, and methods for RecSys research. In\nthis paper, we target this bottleneck and study the environmental role of\nRecSys algorithms. First, we mine a dataset that includes carbon footprint\nemissions for its items. Then, we benchmark conventional RecSys algorithms in\nterms of accuracy and sustainability as two faces of the same coin. We find\nthat RecSys algorithms optimized for accuracy overlook greenness and that\nlonger recommendation lists are greener but less accurate. Then, we show that a\nsimple reranking approach that accounts for the item's carbon footprint can\nestablish a better trade-off between accuracy and greenness. This reranking\napproach is modular, ready to use, and can be applied to any RecSys algorithm\nwithout the need to alter the underlying mechanisms or retrain models. Our\nresults show that a small sacrifice of accuracy can lead to significant\nimprovements of recommendation greenness across all algorithms and list\nlengths. Arguably, this accuracy-greenness trade-off could even be seen as an\nenhancement of user satisfaction, particularly for purpose-driven users who\nprioritize the environmental impact of their choices. We anticipate this work\nwill serve as the starting point for studying RecSys for more sustainable\nrecommendations."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13479",
    "c_title":[
      "Coherence analysis of phase-controlled HOM effects"
    ],
    "c_abstract":[
      "The second-order intensity correlation of entangled photons has been\nintensively studied for decades, particularly for the Hong-Ou-Mandel (HOM)\neffect and nonlocal correlation -- key quantum phenomena that have no classical\ncounterparts. Recently, a path-entangled two-photon state has been\nexperimentally demonstrated for both bosonic (symmetric) and fermionic\n(anti-symmetric) HOM effects by manipulating the photon phase at one input\nport. Entanglement represents a quantum superposition of path- or\nenergy-correlated two-photon states with a relative phase. According to the\nconventional quantum mechanics, this phase is not an individual property but\ncollective attribute of interacting photons. Here, the wave nature of photons\nis employed to coherently analyze the phase-controlled HOM effects recently\nobserved in npj Quantum Info. 5, 43 (2019). A pure coherence approach is\napplied to derive a general solution for these phase-controlled HOM effects.\nConsequently, the quantum mystery of HOM effects, traditionally interpreted\nthrough the particle nature of quantum mechanics, is revealed as a coherent\nphenomenon between entangled photons via a selective choice of correlated\nphotons."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-676",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04085",
    "b_title":[
      "The Cosmic Evolution Early Release Science Survey (CEERS)"
    ],
    "b_abstract":[
      "We present the Cosmic Evolution Early Release Science (CEERS) Survey, a 77.2\nhour Director's Discretionary Early Release Science Program. CEERS\ndemonstrates, tests, and validates efficient extragalactic surveys using\ncoordinated, overlapping parallel observations with the JWST instrument suite,\nincluding NIRCam and MIRI imaging, NIRSpec low (R~100) and medium (R~1000)\nresolution spectroscopy, and NIRCam slitless grism (R~1500) spectroscopy. CEERS\ntargets the Hubble Space Telescope-observed region of the Extended Groth Strip\n(EGS) field, supported by a rich set of multiwavelength data. CEERS facilitated\nimmediate community science in both of the extragalactic core JWST science\ndrivers ``First Light\" and ``Galaxy Assembly,\" including: 1) The discovery and\ncharacterization of large samples of galaxies at z >~ 10 from ~90 arcmin^2 of\nNIRCam imaging, constraining their abundance and physical nature; 2) Deep\nspectra of >1000 galaxies, including dozens of galaxies at 6<z<10, enabling\nredshift measurements and constraints on the physical conditions of\nstar-formation and black hole growth via line diagnostics; 3) Quantifying the\nfirst bulge, bar and disk structures at z>3; and 4) Characterizing galaxy\nmid-IR emission with MIRI to study dust-obscured star-formation and\nsupermassive black hole growth at z~1-3. As a legacy product for the community,\nthe CEERS team has provided several data releases, accompanied by detailed\nnotes on the data reduction procedures and notebooks to aid in reproducibility.\nIn addition to an overview of the survey and quality of the data, we provide\nscience highlights from the first two years with CEERS data."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06173",
    "c_title":[
      "VideoAuteur: Towards Long Narrative Video Generation"
    ],
    "c_abstract":[
      "Recent video generation models have shown promising results in producing\nhigh-quality video clips lasting several seconds. However, these models face\nchallenges in generating long sequences that convey clear and informative\nevents, limiting their ability to support coherent narrations. In this paper,\nwe present a large-scale cooking video dataset designed to advance long-form\nnarrative generation in the cooking domain. We validate the quality of our\nproposed dataset in terms of visual fidelity and textual caption accuracy using\nstate-of-the-art Vision-Language Models (VLMs) and video generation models,\nrespectively. We further introduce a Long Narrative Video Director to enhance\nboth visual and semantic coherence in generated videos and emphasize the role\nof aligning visual embeddings to achieve improved overall video quality. Our\nmethod demonstrates substantial improvements in generating visually detailed\nand semantically aligned keyframes, supported by finetuning techniques that\nintegrate text and image embeddings within the video generation process.\nProject page: https:\/\/videoauteur.github.io\/"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-677",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13260",
    "b_title":[
      "Field induced density wave in a kagome superconductor"
    ],
    "b_abstract":[
      "On the kagome lattice, electrons benefit from the simultaneous presence of\nband topology, flat electronic bands, and van Hove singularities, forming\ncompeting or cooperating orders. Understanding the interrelation between these\ndistinct order parameters remains a significant challenge, leaving much of the\nassociated physics unexplored. In the kagome superconductor KV3Sb5, which\nexhibits a charge density wave (CDW) state below T = 78 K, we uncover an\nunpredicted field-induced phase transition below 6 K. The observed transition\nis marked by a hysteretic anomaly in the resistivity, nonlinear electrical\ntransport, and a change in the symmetry of the electronic response as probed\nvia the angular dependence of the magnetoresistivity. These observations\nsurprisingly suggest the emergence of an unanticipated broken symmetry state\ncoexisting with the original CDW. To understand this experimental observation,\nwe developed a theoretical minimal model for the normal state inside the\nhigh-temperature parent CDW phase where an incommensurate CDW order emerges as\nan instability sub-leading to superconductivity. The incommensurate CDW emerges\nwhen superconducting fluctuations become fully suppressed by large magnetic\nfields. Our results suggest that, in kagome superconductors, quantum states can\neither coexist or are nearly degenerate in energy, indicating that these are\nrich platforms to expose new correlated phenomena."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06954",
    "c_title":[
      "A Hessian-informed hyperparameter optimization for differential learning\n  rate"
    ],
    "c_abstract":[
      "Differential learning rate (DLR), a technique that applies different learning\nrates to different model parameters, has been widely used in deep learning and\nachieved empirical success via its various forms. For example,\nparameter-efficient fine-tuning (PEFT) applies zero learning rates to most\nparameters so as to significantly save the computational cost.\n  At the core, DLR leverages the observation that different parameters can have\ndifferent loss curvature, which is hard to characterize in general. We propose\nthe Hessian-informed differential learning rate (Hi-DLR), an efficient approach\nthat solves the hyperparameter optimization (HPO) of learning rates and\ncaptures the loss curvature for any model and optimizer adaptively. Given a\nproper grouping of parameters, we empirically demonstrate that Hi-DLR can\nimprove the convergence by dynamically determining the learning rates during\nthe training. Furthermore, we can quantify the influence of different\nparameters and freeze the less-contributing parameters, which leads to a new\nPEFT that automatically adapts to various tasks and models. Additionally,\nHi-DLR also exhibits comparable performance on various full model training\ntasks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-678",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16779",
    "b_title":[
      "Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of\n  Frozen Language Models"
    ],
    "b_abstract":[
      "Tool learning can further broaden the usage scenarios of large language\nmodels (LLMs). However most of the existing methods either need to finetune\nthat the model can only use tools seen in the training data, or add tool\ndemonstrations into the prompt with lower efficiency. In this paper, we present\na new Tool Learning method Chain-of-Tools. It makes full use of the powerful\nsemantic representation capability of frozen LLMs to finish tool calling in CoT\nreasoning with a huge and flexible tool pool which may contain unseen tools.\nEspecially, to validate the effectiveness of our approach in the massive unseen\ntool scenario, we construct a new dataset SimpleToolQuestions. We conduct\nexperiments on two numerical reasoning benchmarks (GSM8K-XL and FuncQA) and two\nknowledge-based question answering benchmarks (KAMEL and SimpleToolQuestions).\nExperimental results show that our approach performs better than the baseline.\nWe also identify dimensions of the model output that are critical in tool\nselection, enhancing the model interpretability. Our code and data are\navailable at: https:\/\/github.com\/fairyshine\/Chain-of-Tools ."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04933",
    "c_title":[
      "Arbitrary control of the flow of light using pseudomagnetic fields in\n  photonic crystals at telecommunication wavelengths"
    ],
    "c_abstract":[
      "In photonics, the idea of controlling light in a similar way that magnetic\nfields control electrons has always been attractive. It can be realized by\nsynthesizing pseudomagnetic fields (PMFs) in photonic crystals (PhCs). Previous\nworks mainly focus on the Landau levels and the robust transport of the chiral\nstates. More versatile control over light using complex nonuniform PMFs such as\nthe flexible splitting and routing of light has been elusive, which hinders\ntheir application in practical photonic integrated circuits. Here we propose an\nuniversal and systematic methodology to design nonuniform PMFs and arbitrarily\ncontrol the flow of light in silicon PhCs at telecommunication wavelengths. As\nproofs of concept, a low-loss S-bend and a highly efficient 50:50 power\nsplitter based on PMFs are experimentally demonstrated. A high-speed data\ntransmission experiment is performed on these devices to prove their\napplicability in real communication systems. The proposed method offers a new\nparadigm for the exploration of fundamental physics and the development of\nnovel nanophotonic devices."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-679",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00322",
    "b_title":[
      "MODS: Moderating a Mixture of Document Speakers to Summarize Debatable\n  Queries in Document Collections"
    ],
    "b_abstract":[
      "Query-focused summarization (QFS) gives a summary of documents to answer a\nquery. Past QFS work assumes queries have one answer, ignoring debatable ones\n(Is law school worth it?). We introduce Debatable QFS (DQFS), a task to create\nsummaries that answer debatable queries via documents with opposing\nperspectives; summaries must comprehensively cover all sources and balance\nperspectives, favoring no side. These goals elude LLM QFS systems, which: 1)\nlack structured content plans, failing to guide LLMs to write balanced\nsummaries, and 2) use the same query to retrieve contexts across documents,\nfailing to cover all perspectives specific to each document's content. To\novercome this, we design MODS, a multi-LLM framework mirroring human panel\ndiscussions. MODS treats documents as individual Speaker LLMs and has a\nModerator LLM that picks speakers to respond to tailored queries for planned\ntopics. Speakers use tailored queries to retrieve relevant contexts from their\ndocuments and supply perspectives, which are tracked in a rich outline,\nyielding a content plan to guide the final summary. Experiments on\nConflictingQA with controversial web queries and DebateQFS, our new dataset of\ndebate queries from Debatepedia, show MODS beats SOTA by 38-59% in topic\nparagraph coverage and balance, based on new citation metrics. Users also find\nMODS's summaries to be readable and more balanced."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05257",
    "c_title":[
      "Is there an analogue of the Radcliffe wave between the\n  Carina-Sagittarius and Scutum arms?"
    ],
    "c_abstract":[
      "The most complete sample of galactic maser sources and radio stars with\ntrigonometric parallaxes, proper motions and radial velocities measured by the\nVLBI method has been compiled based on literature data. These sources are\nassociated with young stars located in high mass star forming regions. The\nrotation parameters of the Galaxy have been determined based on 156 masers with\nrelative parallax errors less than 10\\%, located further than 3 kpc from the\ngalactic center. The linear rotation velocity of the Galaxy at the solar\ndistance $R_0$ is $V_0=243.9\\pm3.9$ km s$^{-1}$. A very narrow chain of masers\n3-4 kpc long, elongated in the $\\sim40^\\circ$ direction, passing from a segment\nof the Carina-Sagittarius spiral arm to the Scutum arm, has been studied. A\nnumber of authors have hypothesized that this is a possible analogue of the\nRadcliffe wave. In the present work, no noticeable periodic perturbations of\nvertical coordinates and velocities were found in this structure. On the other\nhand, on the diagram ``$\\ln(R\/R_0)-\\theta$'' this chain of masers has the form\nof a segment of a logarithmic spiral with a pitch angle of $-48^\\circ$. Perhaps\nthis chain of masers belongs to a jet extending from the end of the bar,\nrotating rigidly with the angular velocity of the bar."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-680",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11567",
    "b_title":[
      "Microfacet projected area-based correction for unified model of Geant4\n  for rough surfaces"
    ],
    "b_abstract":[
      "A modification of the optical model for rough surfaces, implemented in Geant4\nas a part of the unified model, is suggested. The modified model takes into\naccount the variation of the interaction probability of the photon with the\nmicrofacet based on the relative orientation of the photon and the sampled\nmicrofacet's normal. The implementation is using a rejection algorithm and\nassumes the interaction probability to be proportional to the projection of the\nmicrofacet area on the plane perpendicular to the photon direction. A\ncomparison of the results obtained with the original and the modified models,\nas well as obtained in direct Monte Carlo simulations are presented for several\ntest surfaces constructed using a pattern of elementary geometrical shapes."
    ],
    "b_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10422",
    "c_title":[
      "DA-LIF: Dual Adaptive Leaky Integrate-and-Fire Model for Deep Spiking\n  Neural Networks"
    ],
    "c_abstract":[
      "Spiking Neural Networks (SNNs) are valued for their ability to process\nspatio-temporal information efficiently, offering biological plausibility, low\nenergy consumption, and compatibility with neuromorphic hardware. However, the\ncommonly used Leaky Integrate-and-Fire (LIF) model overlooks neuron\nheterogeneity and independently processes spatial and temporal information,\nlimiting the expressive power of SNNs. In this paper, we propose the Dual\nAdaptive Leaky Integrate-and-Fire (DA-LIF) model, which introduces spatial and\ntemporal tuning with independently learnable decays. Evaluations on both static\n(CIFAR10\/100, ImageNet) and neuromorphic datasets (CIFAR10-DVS, DVS128 Gesture)\ndemonstrate superior accuracy with fewer timesteps compared to state-of-the-art\nmethods. Importantly, DA-LIF achieves these improvements with minimal\nadditional parameters, maintaining low energy consumption. Extensive ablation\nstudies further highlight the robustness and effectiveness of the DA-LIF model."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-681",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13616",
    "b_title":[
      "Fragile Unconventional Magnetism in RuO$_2$ by Proximity to\n  Landau-Pomeranchuk Instability"
    ],
    "b_abstract":[
      "Altermagnetism has attracted considerable attention for its remarkable\ncombination of spin-polarized band structures and zero net magnetization,\nmaking it a promising candidate for spintronics applications. We demonstrate\nthat this magnetic phase represents a case of ``unconventional magnetism,\"\nfirst proposed nearly two decades ago by one of the present authors as part of\na broader framework for understanding Landau-Pomeranchuk instabilities in the\nspin channel, driven by many-body interactions. By systematically analyzing the\naltermagnetism in RuO$_2$ with first-principles calculations, we reconcile\nconflicting experimental and theoretical reports by attributing it to RuO$_2$'s\nproximity to a quantum phase transition. We emphasize the critical role of\ntuning parameters, such as the Hubbard $U$, hole doping, and epitaxial strain,\nin modulating quasiparticle interactions near the Fermi surface. This work\nprovides fresh insights into the origin and tunability of altermagnetism in\nRuO$_2$, highlighting its potential as a platform for investigating quantum\nphase transitions and the broader realm of unconventional magnetism."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07639",
    "c_title":[
      "SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization\n  with Large Language Models"
    ],
    "c_abstract":[
      "Efficiently solving Optimal Power Flow (OPF) problems in power systems is\ncrucial for operational planning and grid management. There is a growing need\nfor scalable algorithms capable of handling the increasing variability,\nconstraints, and uncertainties in modern power networks while providing\naccurate and fast solutions. To address this, machine learning techniques,\nparticularly Graph Neural Networks (GNNs) have emerged as promising approaches.\nThis letter introduces SafePowerGraph-LLM, the first framework explicitly\ndesigned for solving OPF problems using Large Language Models (LLM)s. The\nproposed approach combines graph and tabular representations of power grids to\neffectively query LLMs, capturing the complex relationships and constraints in\npower systems. A new implementation of in-context learning and fine-tuning\nprotocols for LLMs is introduced, tailored specifically for the OPF problem.\nSafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.\nOur study reveals the impact of LLM architecture, size, and fine-tuning and\ndemonstrates our framework's ability to handle realistic grid components and\nconstraints."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-682",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18182",
    "b_title":[
      "Exploring Topic Trends in COVID-19 Research Literature using\n  Non-Negative Matrix Factorization"
    ],
    "b_abstract":[
      "In this work, we apply topic modeling using Non-Negative Matrix Factorization\n(NMF) on the COVID-19 Open Research Dataset (CORD-19) to uncover the underlying\nthematic structure and its evolution within the extensive body of COVID-19\nresearch literature. NMF factorizes the document-term matrix into two\nnon-negative matrices, effectively representing the topics and their\ndistribution across the documents. This helps us see how strongly documents\nrelate to topics and how topics relate to words. We describe the complete\nmethodology which involves a series of rigorous pre-processing steps to\nstandardize the available text data while preserving the context of phrases,\nand subsequently feature extraction using the term frequency-inverse document\nfrequency (tf-idf), which assigns weights to words based on their frequency and\nrarity in the dataset. To ensure the robustness of our topic model, we conduct\na stability analysis. This process assesses the stability scores of the NMF\ntopic model for different numbers of topics, enabling us to select the optimal\nnumber of topics for our analysis. Through our analysis, we track the evolution\nof topics over time within the CORD-19 dataset. Our findings contribute to the\nunderstanding of the knowledge structure of the COVID-19 research landscape,\nproviding a valuable resource for future research in this field."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13677",
    "c_title":[
      "Value-Oriented Forecast Combinations for Unit Commitment"
    ],
    "c_abstract":[
      "Value-oriented forecasts for two-stage power system operational problems have\nbeen demonstrated to reduce cost, but prove to be computationally challenging\nfor large-scale systems because the underlying optimization problem must be\ninternalized into the forecast model training. Therefore, existing approaches\ntypically scale poorly in the usable training data or require relaxations of\nthe underlying optimization. This paper presents a method for value-oriented\nforecast combinations using progressive hedging, which unlocks high-fidelity,\nat-scale models and large-scale datasets in training. We also derive a direct\none-shot training model for reference and study how different modifications of\nthe training model impact the solution quality. Our method reduces operation\ncost by 1.8% on average and trains forecast combinations for a 2736-bus test\nsystem with one year of data within 20 hours."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-683",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13535",
    "b_title":[
      "Unlocking Learning Potentials: The Transformative Effect of Generative\n  AI in Education Across Grade Levels"
    ],
    "b_abstract":[
      "The advent of generative artificial intelligence (GAI) has brought about a\nnotable surge in the field of education. The use of GAI to support learning is\nbecoming increasingly prevalent among students. However, the manner and extent\nof its utilisation vary considerably from one individual to another. And\nresearches about student's utilisation and perceptions of GAI remains\nrelatively scarce. To gain insight into the issue, this paper proposed a\nhybrid-survey method to examine the impact of GAI on students across four\ndifferent grades in six key areas (LIPSAL): learning interest, independent\nlearning, problem solving, self-confidence, appropriate use, and learning\nenjoyment. Firstly, through questionnaire, we found that among LIPSAL, GAI has\nthe greatest impact on the concept of appropriate use, the lowest level of\nlearning interest and self-confidence. Secondly, a comparison of four grades\nrevealed that the high and low factors of LIPSAL exhibited grade-related\nvariation, and college students exhibited a higher level than high school\nstudents across LIPSAL. Thirdly, through interview, the students demonstrated a\ncomprehensive understanding of the application of GAI. We found that students\nhave a positive attitude towards GAI and are very willing to use it, which is\nwhy GAI has grown so rapidly in popularity. They also told us prospects and\nchallenges in using GAI. In the future, as GAI matures technologically, it will\nhave an greater impact on students. These findings may help better understand\nusage by different students and inform future research in digital education."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09973",
    "c_title":[
      "Stability of quark matter affected by the surface tension in a strong\n  magnetic field"
    ],
    "c_abstract":[
      "The surface tension of quark matter in a strong magnetic field is\ninvestigated using a geometric approach. The interface between the hadronic\nphase and quark phase is determined by the Maxwell construction of the\nfirst-order transition. When surface tension is included, the free energy per\nbaryon is no longer a monotonic function of the chemical potential.\nSpecifically, for smaller droplets, a larger chemical potential is required to\nachieve a stable phase. Moreover, we find that the surface tension does not\nincrease monotonically with the magnetic field. Finally, it is shown that\nstable quark matter, both with and without surface tension, can exist at a\nspecific magnetic field strength, which would provide favorable conditions for\nthe experimental production of quark matter."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-684",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18601",
    "b_title":[
      "Tighten The Lasso: A Convex Hull Volume-based Anomaly Detection Method"
    ],
    "b_abstract":[
      "The rapid advancements in data-driven methodologies have underscored the\ncritical importance of ensuring data quality. Consequently, detecting\nout-of-distribution (OOD) data has emerged as an essential task to maintain the\nreliability and robustness of data-driven models, in general, and machine and\ndeep learning models, in particular. In this study, we leveraged the convex\nhull property of a dataset and the fact that anomalies highly contribute to the\nincrease of the CH's volume to propose a novel anomaly detection algorithm. Our\nalgorithm computes the CH's volume as an increasing number of data points are\nremoved from the dataset to define a decision line between OOD and\nin-distribution data points. We compared the proposed algorithm to seven widely\nused anomaly detection algorithms over ten datasets, showing comparable results\nfor state-of-the-art (SOTA) algorithms. Moreover, we show that with a\ncomputationally cheap and simple check, one can detect datasets that are\nwell-suited for the proposed algorithm which outperforms the SOTA anomaly\ndetection algorithms."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10001",
    "c_title":[
      "Structure stability of steady supersonic shear flow with inflow boundary\n  conditions"
    ],
    "c_abstract":[
      "We study the existence and zero viscous limit of smooth solutions to steady\ncompressible Navier-Stokes equations near plane shear flow between two moving\nparallel walls. Under the assumption $0<L\\ll1$, we prove that for any plane\nsupersonic shear flow $\\mathbf{U}^0=(\\mu(x_2),0)$, there exist smooth solutions\nnear $\\mathbf{U}^0$ to steady compressible Navier-Stokes equations in a\n2-dimension domain $\\Omega=(0,L)\\times (0,2)$. Moreover, based on the\nuniform-in-$\\varepsilon$ estimates, we establish the zero viscosity limit of\nthe solutions obtained above to the solutions of the steady Euler equations."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-685",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16120",
    "b_title":[
      "A Fenchel-Young Loss Approach to Data-Driven Inverse Optimization"
    ],
    "b_abstract":[
      "Data-driven inverse optimization seeks to estimate unknown parameters in an\noptimization model from observations of optimization solutions. Many existing\nmethods are ineffective in handling noisy and suboptimal solution observations\nand also suffer from computational challenges. In this paper, we build a\nconnection between inverse optimization and the Fenchel-Young (FY) loss\noriginally designed for structured prediction, proposing a FY loss approach to\ndata-driven inverse optimization. This new approach is amenable to efficient\ngradient-based optimization, hence much more efficient than existing methods.\nWe provide theoretical guarantees for the proposed method and use extensive\nsimulation and real-data experiments to demonstrate its significant advantage\nin parameter estimation accuracy, decision error and computational speed."
    ],
    "b_categories":[
      [
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07956",
    "c_title":[
      "Bridging HCI and AI Research for the Evaluation of Conversational SE\n  Assistants"
    ],
    "c_abstract":[
      "As Large Language Models (LLMs) are increasingly adopted in software\nengineering, recently in the form of conversational assistants, ensuring these\ntechnologies align with developers' needs is essential. The limitations of\ntraditional human-centered methods for evaluating LLM-based tools at scale\nraise the need for automatic evaluation. In this paper, we advocate combining\ninsights from human-computer interaction (HCI) and artificial intelligence (AI)\nresearch to enable human-centered automatic evaluation of LLM-based\nconversational SE assistants. We identify requirements for such evaluation and\nchallenges down the road, working towards a framework that ensures these\nassistants are designed and deployed in line with user needs."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-686",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14331",
    "b_title":[
      "Cosmic ray transport and acceleration in an evolving shock landscape"
    ],
    "b_abstract":[
      "The sources of cosmic rays between the knee and the ankle are still debated.\nThe Galactic wind and its termination shock have been proposed to contribute to\nthis transition between Galactic and extragalactic origin, but another\npossibility is large-scale shock structures from local sources in the Milky\nWay. In this paper, we investigate CR transport in a time-dependent landscape\nof shocks in the Galactic halo. These shocks could result from local outbursts,\ne.g. starforming regions and superbubbles. CRs re-accelerated at such shocks\ncan reach energies above the knee. Since the shocks are closer to the Galaxy\nthan a termination shock and CRs escape downstream, they can propagate back\nmore easily. With such outbursts happening frequently, shocks will interact.\nThis interaction could adjust the CR spectrum, particularly for the particles\nthat are able to be accelerated at two shocks simultaneously. The transport and\nacceleration of CRs at the shock is modeled by Stochastic Differential\nEquations (SDEs) within the public CR propagation framework CRPropa. We\ndeveloped extensions for time-dependent wind profiles and for the first time\nconnected the code to hydrodynamic simulations, which were run with the public\nAthena++ code. We find that, depending on the concrete realization of the\ndiffusion tensor, a significant fraction of CRs can make it back to the Galaxy.\nThese could contribute to the observed spectrum around and above the CR knee\n($E \\gtrsim 10\\,\\mathrm{PeV}$). In contrast to simplified models, a simple\npower-law does not describe the energy spectra well. Instead, for single\nshocks, we find a flat spectrum ($E^{-2}$) at low energies, which steepens\ngradually until it reaches an exponential decline. When shocks collide, the\nenergy spectra transiently become harder than $E^{-2}$ at high energies."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18749",
    "c_title":[
      "Simulating Safe Bite Transfer in Robot-Assisted Feeding with a Soft Head\n  and Articulated Jaw"
    ],
    "c_abstract":[
      "Ensuring safe and comfortable bite transfer during robot-assisted feeding is\nchallenging due to the close physical human-robot interaction required. This\npaper presents a novel approach to modeling physical human-robot interaction in\na physics-based simulator (MuJoCo) using soft-body dynamics. We integrate a\nflexible head model with a rigid skeleton while accounting for internal\ndynamics, enabling the flexible model to be actuated by the skeleton.\nIncorporating realistic soft-skin contact dynamics in simulation allows for\nsystematically evaluating bite transfer parameters, such as insertion depth and\nentry angle, and their impact on user safety and comfort. Our findings suggest\nthat a straight-in-straight-out strategy minimizes forces and enhances user\ncomfort in robot-assisted feeding, assuming a static head. This\nsimulation-based approach offers a safer and more controlled alternative to\nreal-world experimentation. Supplementary videos can be found at:\nhttps:\/\/tinyurl.com\/224yh2kx."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-687",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02762",
    "b_title":[
      "The hot corino-like chemistry of four FUor-like protostars"
    ],
    "b_abstract":[
      "Context: Compared to Class 0 protostars, the higher densities and lower\ntemperatures of the disk midplanes of Class I young stellar objects (YSOs)\nlimit the detectability of complex organic molecules (COMs). The elevated\nluminosities of eruptive YSOs increase disk temperatures sublimating frozen\nmolecules and easing their detection.\n  Aims: Our aim is to investigate the chemical composition of four FUor-like\nClass I YSOs: L1551 IRS 5, Haro 5a IRS, V346 Nor, and OO Ser, and to compare\ntheir abundances of COMs with other YSOs in the literature.\n  Methods: We search for COMs line emission in ALMA Band 6 observations. We use\nthe CASSIS software to determine their column densities (N) and excitation\ntemperatures (T_ex) assuming local thermodynamical equilibrium.\n  Results: We detect 249 transitions from 12 COMs. In L1551 IRS 5 we identified\nCH3OH, 13CH3OH, CH318OH, CH2DOH, CH3CHO, CH3OCH3, CH3OCHO, CH3COCH3, C2H5OH,\nC2H5CN, 13CH3CN, and CH3C15)N. Haro 5a IRS and OO Ser have emission from CH3OH,\nCH3CHO, CH3OCH3, and CH3OCHO. CH3COCH3 is also detected in OO Ser. In V346 Nor\nwe found CH3OH, CH2DOH, CH3CHO, CH3OCH3, CH3OCHO, and C2H5CN. The emission of\nCOMs is compact in all targets. The analysis indicates their temperatures are\nabove 100K. The abundance ratios of COMs derived for these eruptive YSOs, as\nwell as for other protostars in the literature, span several orders of\nmagnitude without any clear differentiation between the eruptive and quiescent\nYSOs. The column density of the main isotopologue of CH3OH should not be used\nas a reference, as most of the lines are optically thick.\n  Conclusions: The hot and compact emission of COMs indicates that the four\nFUor-like targets are hot corino-like. Spectral studies of such objects can be\nuseful to investigate the complex organic chemistry at later evolutionary\nstages than the usual Class 0 stage."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11639",
    "c_title":[
      "Neural Interpretable Reasoning"
    ],
    "c_abstract":[
      "We formalize a novel modeling framework for achieving interpretability in\ndeep learning, anchored in the principle of inference equivariance. While the\ndirect verification of interpretability scales exponentially with the number of\nvariables of the system, we show that this complexity can be mitigated by\ntreating interpretability as a Markovian property and employing neural\nre-parametrization techniques. Building on these insights, we propose a new\nmodeling paradigm -- neural generation and interpretable execution -- that\nenables scalable verification of equivariance. This paradigm provides a general\napproach for designing Neural Interpretable Reasoners that are not only\nexpressive but also transparent."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-688",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11846",
    "b_title":[
      "Neural Network Reconstruction of Non-Gaussian Initial Conditions from\n  Dark Matter Halos"
    ],
    "b_abstract":[
      "We develop a machine learning approach to reconstructing the cosmological\ninitial conditions from late-time dark matter halo number density fields in\nredshift space, with the goal of improving sensitivity to cosmological\nparameters, and in particular primordial non-Gaussianity. Using an U-Net\narchitecture, our model achieves a cross-correlation accuracy of 44% for scales\nout to $k = 0.4 \\text{ h}\/\\text{Mpc}$ between reconstructed and true initial\nconditions of Quijote 1 Gpc$^3$ simulation boxes with an average halo number\ndensity of $\\bar{n} = 4\\times 10^{-4}$ (h\/Mpc)$^{3}$ in the tracer field at\n$z=0$ . We demonstrate that our reconstruction is likely to be optimal for this\nsetup and that it is highly effective at reducing redshift-space distortions.\nUsing a Fisher analysis, we show that reconstruction improves cosmological\nparameter constraints derived from the power spectrum and bispectrum. By\ncombining the power spectrum monopole, quadrupole, and bispectrum monopole up\nto $k_{\\rm{max}} = 0.52 \\text{ h}\/\\text{Mpc}$, our joint analysis of pre- and\npost-reconstructed fields from the Quijote simulation suite finds improved\nmarginalized errors on all cosmological parameters. In particular,\nreconstruction improves constraints on $f_{\\rm{NL}}$ by factors of 1.33, 1.88,\nand 1.57 for local, equilateral, and orthogonal shapes. Our findings\ndemonstrate the effectiveness of reconstruction in decoupling modes, mitigating\nredshift-space distortions and maximizing information on cosmology. The results\nprovide important insights into the amount of cosmological information that can\nbe extracted from small scales, and can potentially be used to complement\nstandard analysis of observational data, upon further development."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08726",
    "c_title":[
      "SIMAC: A Semantic-Driven Integrated Multimodal Sensing And Communication\n  Framework"
    ],
    "c_abstract":[
      "Traditional single-modality sensing faces limitations in accuracy and\ncapability, and its decoupled implementation with communication systems\nincreases latency in bandwidth-constrained environments. Additionally,\nsingle-task-oriented sensing systems fail to address users' diverse demands. To\novercome these challenges, we propose a semantic-driven integrated multimodal\nsensing and communication (SIMAC) framework. This framework leverages a joint\nsource-channel coding architecture to achieve simultaneous sensing decoding and\ntransmission of sensing results. Specifically, SIMAC first introduces a\nmultimodal semantic fusion (MSF) network, which employs two extractors to\nextract semantic information from radar signals and images, respectively. MSF\nthen applies cross-attention mechanisms to fuse these unimodal features and\ngenerate multimodal semantic representations. Secondly, we present a large\nlanguage model (LLM)-based semantic encoder (LSE), where relevant communication\nparameters and multimodal semantics are mapped into a unified latent space and\ninput to the LLM, enabling channel-adaptive semantic encoding. Thirdly, a\ntask-oriented sensing semantic decoder (SSD) is proposed, in which different\ndecoded heads are designed according to the specific needs of tasks.\nSimultaneously, a multi-task learning strategy is introduced to train the SIMAC\nframework, achieving diverse sensing services. Finally, experimental\nsimulations demonstrate that the proposed framework achieves diverse sensing\nservices and higher accuracy."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-689",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07102",
    "b_title":[
      "Coordinated Energy-Trajectory Economic Model Predictive Control for\n  Autonomous Surface Vehicles under Disturbances"
    ],
    "b_abstract":[
      "The paper proposes a novel Economic Model Predictive Control (EMPC) scheme\nfor Autonomous Surface Vehicles (ASVs) to simultaneously address path following\naccuracy and energy constraints under environmental disturbances. By\nformulating lateral deviations as energy-equivalent penalties in the cost\nfunction, our method enables explicit trade-offs between tracking precision and\nenergy consumption. Furthermore, a motion-dependent decomposition technique is\nproposed to estimate terminal energy costs based on vehicle dynamics. Compared\nwith the existing EMPC method, simulations with real-world ocean disturbance\ndata demonstrate the controller's energy consumption with a 0.06 energy\nincrease while reducing cross-track errors by up to 18.61. Field experiments\nconducted on an ASV equipped with an Intel N100 CPU in natural lake\nenvironments validate practical feasibility, achieving 0.22 m average\ncross-track error at nearly 1 m\/s and 10 Hz control frequency. The proposed\nscheme provides a computationally tractable solution for ASVs operating under\nresource constraints."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05184",
    "c_title":[
      "Towards Optimizing the Expected Performance of Sampling-Based\n  Quantum-Inspired Algorithms"
    ],
    "c_abstract":[
      "Quantum-inspired classical algorithms has received much attention due to its\nexponential speedup compared to existing algorithms, under certain data storage\nassumptions. The improvements are noticeable in fundamental linear algebra\ntasks. In this work, we analyze two major subroutines in sampling-based\nquantum-inspired algorithms, specifically, inner product estimation and\nsampling from a linear combination of vectors, and discuss their possible\nimprovements by generalizing the data structure. The idea is to consider the\naverage behavior of the subroutines under certain assumptions regarding the\ndata elements. This allows us to determine the optimal data structure, and the\nhigh-dimensional nature of data makes our assumptions reasonable. Experimental\nresults from recommendation systems also highlight a consistent preference for\nour proposed data structure. Motivated by this observation, we tighten the\nupper bound on the number of required measurements for direct fidelity\nestimation. We expect our findings to suggest optimal implementations for\nvarious quantum and quantum-inspired machine learning algorithms that involve\nextremely high-dimensional operations, which has potential for many\napplications."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-690",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12379",
    "b_title":[
      "Constant Weight Polar Codes through Periodic Markov Processes"
    ],
    "b_abstract":[
      "Constant weight codes can arise from an input process sampled from a periodic\nMarkov chain. A previous result showed that, in general, polarization does not\noccur for input-output processes with an underlying periodic Markov chain. In\nthis work, we show that if we fix the initial state of an underlying periodic\nMarkov chain, polarization does occur. Fixing the initial state is aligned with\nensuring a constant weight code."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11187",
    "c_title":[
      "TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking"
    ],
    "c_abstract":[
      "In this paper, we present TituLLMs, the first large pretrained Bangla LLMs,\navailable in 1b and 3b parameter sizes. Due to computational constraints during\nboth training and inference, we focused on smaller models. To train TituLLMs,\nwe collected a pretraining dataset of approximately ~37 billion tokens. We\nextended the Llama-3.2 tokenizer to incorporate language- and culture-specific\nknowledge, which also enables faster training and inference. There was a lack\nof benchmarking datasets to benchmark LLMs for Bangla. To address this gap, we\ndeveloped five benchmarking datasets. We benchmarked various LLMs, including\nTituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual\nversions. However, this is not always the case, highlighting the complexities\nof language adaptation. Our work lays the groundwork for adapting existing\nmultilingual open models to other low-resource languages. To facilitate broader\nadoption and further research, we have made the TituLLMs models and\nbenchmarking datasets publicly available\n(https:\/\/huggingface.co\/collections\/hishab\/titulm-llama-family-6718d31fc1b83529276f490a)."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-691",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16039",
    "b_title":[
      "Complexity of Minimal Faithful Permutation Degree for Fitting-free\n  Groups"
    ],
    "b_abstract":[
      "In this paper, we investigate the complexity of computing the minimal\nfaithful permutation degree for groups without abelian normal subgroups. When\nour groups are given as quotients of permutation groups, we establish that this\nproblem is in $\\textsf{P}$. Furthermore, in the setting of permutation groups,\nwe obtain an upper bound of $\\textsf{NC}$ for this problem. This improves upon\nthe work of Das and Thakkar (STOC 2024), who established a Las Vegas\npolynomial-time algorithm for this class in the setting of permutation groups."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.DS",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06966",
    "c_title":[
      "GEMS JWST: Transmission spectroscopy of TOI-5205b reveals significant\n  stellar contamination and a metal-poor atmosphere"
    ],
    "c_abstract":[
      "Recent discoveries of transiting giant exoplanets around M dwarfs (GEMS)\npresent an opportunity to investigate their atmospheric compositions and\nexplore how such massive planets can form around low-mass stars contrary to\ncanonical formation models. Here, we present the first transmission spectra of\nTOI-5205b, a short-period ($P=1.63~\\mathrm{days}$) Jupiter-like planet\n($M_p=1.08~\\mathrm{M_J}$ and $R_p=0.94~\\mathrm{R_J}$) orbiting an M4 dwarf. We\nobtained three transits using the PRISM mode of the JWST Near Infrared\nSpectrograph (NIRSpec) spanning $0.6-5.3$ um. Our data reveal significant\nstellar contamination that is evident in the light curves as spot-crossing\nevents and in the transmission spectra as a larger transit depth at bluer\nwavelengths. Atmospheric retrievals demonstrate that stellar contamination from\nunocculted star spots is the dominant component of the transmission spectrum at\nwavelengths $\\lambda\\lesssim3.0$ um, which reduced the sensitivity to the\npresence of clouds or hazes in our models. The degree of stellar contamination\nalso prevented the definitive detection of any $\\mathrm{H_2O}$, which has\nprimary absorption features at these shorter wavelengths. The broad wavelength\ncoverage of NIRSpec PRISM enabled a robust detection of $\\mathrm{CH_4}$ and\n$\\mathrm{H_2S}$, which have detectable molecular features between $3.0-5.0$ um.\nOur gridded and Bayesian retrievals consistently favored an atmosphere with\nboth sub-solar metallicity ($\\log\\mathrm{[M\/H]}\\sim-2$ for a clear atmosphere)\nand super-solar C\/O ratio ($\\log\\mathrm{[C\/O]}\\sim3$ for a clear or cloudy\natmosphere). This contrasts with estimates from planetary interior models that\npredict a bulk metallicity of 10--20%, which is $\\sim100\\times$ the atmospheric\nmetallicity, and suggests that the planetary interior for TOI-5205b is\ndecoupled from its atmosphere and not well mixed."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-692",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02096",
    "b_title":[
      "Effects of Galaxy Cluster Structure on Lensed Transients"
    ],
    "b_abstract":[
      "Strong gravitational lenses come in many forms, but are typically divided\ninto two populations: galaxies, and groups and clusters of galaxies. When\ncalculating the properties of the images we expect to see from these lenses, it\nis typically assumed that each lens is roughly a singular isothermal sphere. In\nreality, the largest objects in the Universe (i.e. galaxy clusters) are highly\nirregular and composed of many components due to a history of (or active)\nhierarchical mergers. In this work, we analyze the discrepancies in the\nobservables of strongly lensed transients in both scenarios, namely relative\nmagnifications, time delays, and image multiplicities. Focusing on\ngravitational waves, we compare the detection rates between the single\nspherical dark matter halo models found in the literature, and publicly\navailable state-of-the-art cluster lens models. We find there to be\napproximately an order of magnitude fewer detection of strongly lensed\ntransients in the realistic model case, likely caused by their loss of overall\nstrong lensing optical depth. We also report detection rates in the weak\nlensing or single-image regime. Additionally, we find a systemic shift towards\nlower time delays between the brightest image pairs in the cases of the\nrealistic models, as well as higher fractions of positive versus negative\nparity images, as seen elsewhere in the literature. This significant deviation\nin the joint relative magnification factor-time delay distribution will hinder\nthe feasibility of the reconstruction of lenses through time domain transients\nalone, but can still provide a lower limit on the lens mass."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16885",
    "c_title":[
      "\"My Whereabouts, my Location, it's Directly Linked to my Physical\n  Security\": An Exploratory Qualitative Study of Location-Dependent Security\n  and Privacy Perceptions among Activist Tech Users"
    ],
    "c_abstract":[
      "Digital-safety research with at-risk users is particularly urgent. At-risk\nusers are more likely to be digitally attacked or targeted by surveillance and\ncould be disproportionately harmed by attacks that facilitate physical\nassaults. One group of such at-risk users are activists and politically active\nindividuals. For them, as for other at-risk users, the rise of smart\nenvironments harbors new risks. Since digitization and datafication are no\nlonger limited to a series of personal devices that can be switched on and off,\nbut increasingly and continuously surround users, granular geolocation poses\nnew safety challenges. Drawing on eight exploratory qualitative interviews of\nan ongoing research project, this contribution highlights what activists with\npowerful adversaries think about evermore data traces, including location data,\nand how they intend to deal with emerging risks. Responses of activists include\nattempts to control one's immediate technological surroundings and to more\ncarefully manage device-related location data. For some activists, threat\nmodeling has also shaped provider choices based on geopolitical considerations.\nSince many activists have not enough digital-safety knowledge for effective\nprotection, feelings of insecurity and paranoia are widespread. Channeling the\nconcerns and fears of our interlocutors, we call for more research on how\nactivists can protect themselves against evermore fine-grained location data\ntracking."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-693",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15009",
    "b_title":[
      "Contextualizing Search Queries In-Context Learning for Conversational\n  Rewriting with LLMs"
    ],
    "b_abstract":[
      "Conversational query rewriting is crucial for effective conversational\nsearch, yet traditional supervised methods require substantial labeled data,\nwhich is scarce in low-resource settings. This paper introduces Prompt-Guided\nIn-Context Learning, a novel approach that leverages the in-context learning\ncapabilities of Large Language Models (LLMs) for few-shot conversational query\nrewriting. Our method employs carefully designed prompts, incorporating task\ndescriptions, input\/output format specifications, and a small set of\nillustrative examples, to guide pre-trained LLMs to generate\ncontext-independent queries without explicit fine-tuning. Extensive experiments\non benchmark datasets, TREC and Taskmaster-1, demonstrate that our approach\nsignificantly outperforms strong baselines, including supervised models and\ncontrastive co-training methods, across various evaluation metrics such as\nBLEU, ROUGE-L, Success Rate, and MRR. Ablation studies confirm the importance\nof in-context examples, and human evaluations further validate the superior\nfluency, relevance, and context utilization of our generated rewrites. The\nresults highlight the potential of prompt-guided in-context learning as an\nefficient and effective paradigm for low-resource conversational query\nrewriting, reducing the reliance on extensive labeled data and complex training\nprocedures."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10217",
    "c_title":[
      "State transfer of Grover walks on unitary and quadratic unitary Cayley\n  graphs over finite commutative rings"
    ],
    "c_abstract":[
      "This paper focuses on periodicity and perfect state transfer of Grover walks\non two well-known families of Cayley graphs, namely, the unitary Cayley graphs\nand the quadratic unitary Cayley graphs. Let $R$ be a finite commutative ring.\nThe unitary Cayley graph $G_R$ has vertex set $R$, where two vertices $u$ and\n$v$ are adjacent if $u-v$ is a unit in $R$. We provide a necessary and\nsufficient condition for the periodicity of the Cayley graph $G_R$. We also\ncompletely determine the rings $R$ for which $G_R$ exhibits perfect state\ntransfer. The quadratic unitary Cayley graph $\\mathcal{G}_R$ has vertex set\n$R$, where two vertices $u$ and $v$ are adjacent if $u-v$ or $v-u$ is a square\nof some units in $R$. It is well known that any finite commutative ring $R$ can\nbe expressed as $R_1\\times\\cdots\\times R_s$, where each $R_i$ is a local ring\nwith maximal ideal $M_i$ for $i\\in\\{1,...,s\\}$. We characterize periodicity and\nperfect state transfer on $\\mathcal{G}_R$ under the condition that\n$|R_i|\/|M_i|\\equiv 1 \\pmod 4$ for $i\\in\\{1,...,s\\}$. Also, we characterize\nperiodicity and perfect state transfer on $\\mathcal{G}_R$, where $R$ can be\nexpressed as $R_0\\times\\cdots\\times R_s$ such that $|R_0|\/|M_0|\\equiv3\\pmod 4$,\nand $|R_i|\/|M_i|\\equiv1\\pmod4$ for $i\\in\\{1,..., s\\}$, where $R_i$ is a local\nring with maximal ideal $M_i$ for $i\\in\\{0,...,s\\}$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-694",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08064",
    "b_title":[
      "Continual Learning for Multiple Modalities"
    ],
    "b_abstract":[
      "Continual learning aims to learn knowledge of tasks observed in sequential\ntime steps while mitigating the forgetting of previously learned knowledge.\nExisting methods were proposed under the assumption of learning a single\nmodality (e.g., image) over time, which limits their applicability in scenarios\ninvolving multiple modalities. In this work, we propose a novel continual\nlearning framework that accommodates multiple modalities (image, video, audio,\ndepth, and text). We train a model to align various modalities with text,\nleveraging its rich semantic information. However, this increases the risk of\nforgetting previously learned knowledge, exacerbated by the differing input\ntraits of each task. To alleviate the overwriting of the previous knowledge of\nmodalities, we propose a method for aggregating knowledge within and across\nmodalities. The aggregated knowledge is obtained by assimilating new\ninformation through self-regularization within each modality and associating\nknowledge between modalities by prioritizing contributions from relevant\nmodalities. Furthermore, we propose a strategy that re-aligns the embeddings of\nmodalities to resolve biased alignment between modalities. We evaluate the\nproposed method in a wide range of continual learning scenarios using multiple\ndatasets with different modalities. Extensive experiments demonstrate that ours\noutperforms existing methods in the scenarios, regardless of whether the\nidentity of the modality is given."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06102",
    "c_title":[
      "Gigahertz directional light modulation with electro-optic metasurfaces"
    ],
    "c_abstract":[
      "Active metasurfaces promise spatiotemporal control over optical wavefronts,\nbut achieving high-speed modulation with pixel-level control has remained an\nunmet challenge. While local phase control can be achieved with nanoscale\noptical confinement, such as in plasmonic nanoparticles, the resulting\nelectrode spacings lead to large capacitance, limiting speed. Here, we\ndemonstrate the operation of a gigahertz-tunable metasurface for beam steering\nthrough local control of metasurface elements in a plasmonic-organic hybrid\narchitecture. Our device comprises a corrugated metallic slot array engineered\nto support plasmonic quasi-bound states in the continuum (quasi-BICs). These\nplasmonic quasi-BICs provide ideal optical confinement and electrical\ncharacteristics for integrating organic electro-optic (OEO) materials like JRD1\nand have not been previously utilized in optical metasurfaces. We obtain a\nquasi-static resonance tunability of 0.4 nm\/V, which we leverage to steer light\nbetween three diffraction orders and achieve an electro-optic bandwidth of ~4\nGHz, with the potential for further speed improvements through scaling rules.\nThis work showcases on-chip spatiotemporal control of light at the\nsub-micrometer and gigahertz level, opening new possibilities for applications\nin 3D sensing and high-speed spatial light modulation."
    ],
    "c_categories":[
      [
        "physics.app-ph",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-695",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19538",
    "b_title":[
      "Multi-Language Probabilistic Programming"
    ],
    "b_abstract":[
      "There are many different probabilistic programming languages that are\nspecialized to specific kinds of probabilistic programs. From a usability and\nscalability perspective, this is undesirable: today, probabilistic programmers\nare forced up-front to decide which language they want to use and cannot\nmix-and-match different languages for handling heterogeneous programs. To\nrectify this, we seek a foundation for sound interoperability for probabilistic\nprogramming languages: just as today's Python programmers can resort to\nlow-level C programming for performance, we argue that probabilistic\nprogrammers should be able to freely mix different languages for meeting the\ndemands of heterogeneous probabilistic programming environments. As a first\nstep towards this goal, we introduce \\textsc{MultiPPL}, a probabilistic\nmulti-language that enables programmers to interoperate between two different\nprobabilistic programming languages: one that leverages a high-performance\nexact discrete inference strategy, and one that uses approximate importance\nsampling. We give a syntax and semantics for \\textsc{MultiPPL}, prove soundness\nof its inference algorithm, and provide empirical evidence that it enables\nprogrammers to perform inference on complex heterogeneous probabilistic\nprograms and flexibly exploits the strengths and weaknesses of two languages\nsimultaneously.%"
    ],
    "b_categories":[
      [
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04216",
    "c_title":[
      "Interference in OFDM Systems and Networks"
    ],
    "c_abstract":[
      "In this paper we present an overview of various kinds of interference, that\narise in the Orthogonal Frequency-Domain Multiplexing (OFDM)-based digital\ncommunications systems at the physical layer. Inter-symbol, inter-block,\ninter-carrier interference types are described in detail, valid for any OFDM\ntransmission, along with Inter-cell interference specific to cellular networks.\nA survey of various communication disruptions techniques is presented -\nprimarily focusing on intentional interference - jamming. Furthermore, we\npresent a survey of modulation techniques that expand on the OFDM and may be\nconsidered viable candidates for modulation in the future 6G cellular networks."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-696",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05246",
    "b_title":[
      "Domain-Incremental Semantic Segmentation for Autonomous Driving under\n  Adverse Driving Conditions"
    ],
    "b_abstract":[
      "Semantic segmentation for autonomous driving is an even more challenging task\nwhen faced with adverse driving conditions. Standard models trained on data\nrecorded under ideal conditions show a deteriorated performance in unfavorable\nweather or illumination conditions. Fine-tuning on the new task or condition\nwould lead to overwriting the previously learned information resulting in\ncatastrophic forgetting. Adapting to the new conditions through traditional\ndomain adaption methods improves the performance on the target domain at the\nexpense of the source domain. Addressing these issues, we propose an\narchitecture-based domain-incremental learning approach called Progressive\nSemantic Segmentation (PSS). PSS is a task-agnostic, dynamically growing\ncollection of domain-specific segmentation models. The task of inferring the\ndomain and subsequently selecting the appropriate module for segmentation is\ncarried out using a collection of convolutional autoencoders. We extensively\nevaluate our proposed approach using several datasets at varying levels of\ngranularity in the categorization of adverse driving conditions. Furthermore,\nwe demonstrate the generalization of the proposed approach to similar and\nunseen domains."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05606",
    "c_title":[
      "Control analysis and synthesis for general control-affine systems"
    ],
    "c_abstract":[
      "This paper provides controllability analysis and control synthesis for\ngeneral control-affine systems, potentially subject to a bounded perturbation.\nWe establish sufficient controllability conditions based on a proper\ngeneralization of the controllability Gramian for linear systems. Under these\nsufficient conditions, control syntheses are developed. We provide two control\ninput constructions for a given system, either of which can steer the system\nfrom a given initial state to any desired target state within a finite time\nhorizon. As in our analysis, in the case of linearity, these syntheses are\nreduced to common control inputs based on the controllability of Gramian.\nAdditionally, we derive a sharp upper bound on the $L^2$-norm of these control\nfunctions, allowing us to derive insights into the energy required to enact\ncontrol. The work advances the theory of nonlinear controllability and provides\nan analytical framework that facilitates numerical verification and practical\nimplementation."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.DS",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-697",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04041",
    "b_title":[
      "A stabilized finite element method for steady Darcy-Brinkman-Forchheimer\n  flow model with different viscous and inertial resistances in porous media"
    ],
    "b_abstract":[
      "We implement a stabilized finite element method for steady\nDarcy-Brinkman-Forchheimer model within the continuous Galerkin framework. The\nnonlinear fluid model is first linearized using a standard \\textit{Newton's\nmethod. The sequence of linear problems is then discretized utilizing a stable\n\\textit{inf-sup} type continuous finite elements based on the\n\\textit{Taylor-Hood} pair to approximate the primary variables: velocity and\npressure}. Such a pair is known to be optimal for the approximation of the\nisotropic Navier-Stokes equation. To overcome the well-known numerical\ninstability in the convection-dominated problems, the Grad-Div stabilization is\nemployed with an efficient \\textit{augmented Lagrangian-type} penalty method.\nWe use the penalty term to develop the \\textit{block Schur complement}\npreconditioner, which is later coupled with a Krylov-space-based iterative\nlinear solver. In addition, the Kelly error estimator for the adaptive mesh\nrefinement is employed to achieve better numerical results with less\ncomputational cost. Performance of the proposed algorithm is verified for a\nclassical benchmark problem. Particularly for the Forchheimer parameter, we\npresent some interesting flow patterns with the velocity components and their\nstreamlines along the mid-lines in the computational domain. The role of the\nForchheimer term is highlighted for different porous medium scenarios. This\nstudy can offer an attractive setting for discretizing many multi-physics\nproblems along with the fluid flow having inertial effects in porous media."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00386",
    "c_title":[
      "Efficient Adaptive Label Refinement for Label Noise Learning"
    ],
    "c_abstract":[
      "Deep neural networks are highly susceptible to overfitting noisy labels,\nwhich leads to degraded performance. Existing methods address this issue by\nemploying manually defined criteria, aiming to achieve optimal partitioning in\neach iteration to avoid fitting noisy labels while thoroughly learning clean\nsamples. However, this often results in overly complex and difficult-to-train\nmodels. To address this issue, we decouple the tasks of avoiding fitting\nincorrect labels and thoroughly learning clean samples and propose a simple yet\nhighly applicable method called Adaptive Label Refinement (ALR). First,\ninspired by label refurbishment techniques, we update the original hard labels\nto soft labels using the model's predictions to reduce the risk of fitting\nincorrect labels. Then, by introducing the entropy loss, we gradually `harden'\nthe high-confidence soft labels, guiding the model to better learn from clean\nsamples. This approach is simple and efficient, requiring no prior knowledge of\nnoise or auxiliary datasets, making it more accessible compared to existing\nmethods. We validate ALR's effectiveness through experiments on benchmark\ndatasets with artificial label noise (CIFAR-10\/100) and real-world datasets\nwith inherent noise (ANIMAL-10N, Clothing1M, WebVision). The results show that\nALR outperforms state-of-the-art methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-698",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16500",
    "b_title":[
      "The Impact of VR and 2D Interfaces on Human Feedback in Preference-Based\n  Robot Learning"
    ],
    "b_abstract":[
      "Aligning robot navigation with human preferences is essential for ensuring\ncomfortable and predictable robot movement in shared spaces, facilitating\nseamless human-robot coexistence. While preference-based learning methods, such\nas reinforcement learning from human feedback (RLHF), enable this alignment,\nthe choice of the preference collection interface may influence the process.\nTraditional 2D interfaces provide structured views but lack spatial depth,\nwhereas immersive VR offers richer perception, potentially affecting preference\narticulation. This study systematically examines how the interface modality\nimpacts human preference collection and navigation policy alignment. We\nintroduce a novel dataset of 2,325 human preference queries collected through\nboth VR and 2D interfaces, revealing significant differences in user\nexperience, preference consistency, and policy outcomes. Our findings highlight\nthe trade-offs between immersion, perception, and preference reliability,\nemphasizing the importance of interface selection in preference-based robot\nlearning. The dataset will be publicly released to support future research."
    ],
    "b_categories":[
      [
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04812",
    "c_title":[
      "The effect of finite mass in cavity QED calculations"
    ],
    "c_abstract":[
      "The effect of finite nuclear mass is investigated in coupled light matter\nsystems in cavity quantum electrodynamics (cavity QED) using the Pauli-Fierz\nHamiltonian. Three different systems, the He atom, the H$^-$ ion and the\nH$_2^+$ ion is investigated. There are small, but significant differences in\nthe behavior of the binding energies as the function of the coupling strength.\nThe probability of coupling to light is found to be very small but even this\nsmall coupling has a very strong effect on the energies of the systems."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-699",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13846",
    "b_title":[
      "Identifying and Mitigating Machine Learning Biases for the\n  Gravitational-wave Detection Problem"
    ],
    "b_abstract":[
      "Matched-filtering is a long-standing technique for the optimal detection of\nknown signals in stationary Gaussian noise. However, it has known departures\nfrom optimality when operating on unknown signals in real noise and suffers\nfrom computational inefficiencies in its pursuit to near-optimality. A\ncompelling alternative that has emerged in recent years to address this problem\nis deep learning. Although it has shown significant promise when applied to the\nsearch for gravitational-waves in detector noise, we demonstrate the existence\nof a multitude of learning biases that hinder generalisation and detection\nperformance. Our work identifies the sources of a set of 11 interconnected\nbiases present in the supervised learning of the gravitational-wave detection\nproblem, and contributes mitigation tactics and training strategies to\nconcurrently address them. We introduce, Sage, a machine-learning based binary\nblack hole search pipeline. We evaluate our pipeline on the injection study\npresented in the Machine Learning Gravitational-Wave Search Challenge and show\nthat Sage detects ~11.2% more signals than the benchmark PyCBC analysis at a\nfalse alarm rate of one per month in O3a noise. Moreover, we also show that it\ncan detect ~48.29% more signals than the previous best performing\nmachine-learning pipeline on the same dataset. We empirically prove that our\npipeline has the capability to effectively handle out-of-distribution noise\npower spectral densities and reject non-Gaussian transient noise artefacts. By\nstudying machine-learning biases and conducting empirical investigations to\nunderstand the reasons for performance improvement\/degradation, we aim to\naddress the need for interpretability of machine-learning methods for\ngravitational-wave detection. All code and implementations are available at\nhttps:\/\/github.com\/nnarenraju\/sage."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11366",
    "c_title":[
      "Moment Monotonicity of Weibull, Gamma and Log-normal Distributions"
    ],
    "c_abstract":[
      "This paper investigates the moment monotonicity property of Weibull, Gamma,\nand Log-normal distributions. We provide the first complete mathematical proofs\nfor the monotonicity of the function $E(X^n)^{\\frac{1}{n}}$ specific to these\ndistributions. Through the derivations, we identify a key property: in many\ncases, one of the two parameters defining each distribution can be effectively\ncanceled out. This finding opens up opportunities for improved parameter\nestimation of these random variables. Our results contribute to a deeper\nunderstanding of the behavior of these widely used distributions and offer\nvaluable insights for applications in fields such as reliability engineering,\neconometrics, and machine learning."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-700",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19303",
    "b_title":[
      "Operando XPS in Reactive Plasmas: The Importance of The Wall Reactions"
    ],
    "b_abstract":[
      "Advancements in differential pumping and electron optics over the past few\ndecades have enabled x-ray photoelectron spectroscopy (XPS) measurements at\n(near-)ambient pressures, bridging the pressure gap for characterizing\nrealistic sample chemistries. Recently, we demonstrated the capabilities of an\nambient pressure XPS (APXPS) setup for in-situ plasma environment measurements,\nallowing plasma-surface interactions to be studied in operando rather than\nusing the traditional before-and-after analysis approach. This new plasma-XPS\ntechnique facilitates the identification of reaction intermediates critical for\nunderstanding plasma-assisted surface processes relevant to semiconductor\nnanomanufacturing, such as physical vapor deposition, etching, atomic layer\ndeposition, etc. In this report, we apply the plasma-XPS approach to monitor\nreal-time surface chemical changes on a model Ag(111) single crystal exposed to\noxidizing and reducing plasmas. We correlate surface-sensitive data with\nconcurrent gas-phase XPS measurements and residual gas mass-spectra analysis of\nspecies generated during plasma exposure, highlighting the significant role of\nplasma-induced chamber wall reactions. Ultimately, we demonstrate that\nplasma-XPS provides comprehensive insights into both surface and gas-phase\nchemistry, establishing it as a versatile and dynamic characterization tool\nwith broad applications in microelectronics research."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03375",
    "c_title":[
      "Interactive Visualization Recommendation with Hier-SUCB"
    ],
    "c_abstract":[
      "Visualization recommendation aims to enable rapid visual analysis of massive\ndatasets. In real-world scenarios, it is essential to quickly gather and\ncomprehend user preferences to cover users from diverse backgrounds, including\nvarying skill levels and analytical tasks. Previous approaches to personalized\nvisualization recommendations are non-interactive and rely on initial user data\nfor new users. As a result, these models cannot effectively explore options or\nadapt to real-time feedback. To address this limitation, we propose an\ninteractive personalized visualization recommendation (PVisRec) system that\nlearns on user feedback from previous interactions. For more interactive and\naccurate recommendations, we propose Hier-SUCB, a contextual combinatorial\nsemi-bandit in the PVisRec setting. Theoretically, we show an improved overall\nregret bound with the same rank of time but an improved rank of action space.\nWe further demonstrate the effectiveness of Hier-SUCB through extensive\nexperiments where it is comparable to offline methods and outperforms other\nbandit algorithms in the setting of visualization recommendation."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-701",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11036",
    "b_title":[
      "Bimeron Crystals by a Linearly Polarized AC Electric Field in Frustrated\n  Magnets"
    ],
    "b_abstract":[
      "We theoretically propose a method to generate topological spin textures by\nirradiating a classical spin system with a linearly polarized AC electric\nfield. To this end, we investigate non-equilibrium steady states in a classical\nHeisenberg model with frustrated exchange interactions on a two-dimensional\ntriangular lattice by numerically solving the Landau-Lifshitz-Gilbert equation\nat zero temperature. Our results reveal that the linearly polarized AC\nelectric-field irradiation induces a topological phase transition from a\nsingle-Q spiral state to a bimeron crystal with the skyrmion number of one in\nthe low-frequency regime. Furthermore, we show that the obtained bimeron\ncrystal remains relatively stable against both easy-axis and easy-plane\nsingle-ion anisotropies."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05306",
    "c_title":[
      "Dagger-Drazin Inverses"
    ],
    "c_abstract":[
      "Drazin inverses are a special kind of generalized inverses that can be\ndefined for endomorphisms in any category. A natural question to ask is whether\none can somehow extend the notion of Drazin inverse to arbitrary maps -- not\nsimply endomorphisms. It turns out that this is possible and, indeed, natural\nto do so for dagger categories. This paper, thus, introduces the notion of a\ndagger-Drazin inverse, which is a new kind of generalized inverse appropriate\nfor arbitrary maps in a dagger category. This inverse is closely related to the\nDrazin inverse, for having dagger-Drazin inverses is equivalent to asking that\npositive maps have Drazin inverses. Moreover, dagger-Drazin inverses are also\nclosely related to Moore-Penrose inverses as we observe that a map has a\nMoore-Penrose inverse if and only if it is a Drazin-inverse. Furthermore, we\nexplain how Drazin inverses of opposing pairs correspond precisely to\ndagger-Drazin inverses in cofree dagger categories. We also give examples of\ndagger-Drazin inverses for matrices over (involutive) fields, bounded linear\noperators, and partial injections."
    ],
    "c_categories":[
      [
        "math.CT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-702",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00133",
    "b_title":[
      "Exploring Transfer Learning for Deep Learning Polyp Detection in\n  Colonoscopy Images Using YOLOv8"
    ],
    "b_abstract":[
      "Deep learning methods have demonstrated strong performance in objection\ntasks; however, their ability to learn domain-specific applications with\nlimited training data remains a significant challenge. Transfer learning\ntechniques address this issue by leveraging knowledge from pre-training on\nrelated datasets, enabling faster and more efficient learning for new tasks.\nFinding the right dataset for pre-training can play a critical role in\ndetermining the success of transfer learning and overall model performance. In\nthis paper, we investigate the impact of pre-training a YOLOv8n model on seven\ndistinct datasets, evaluating their effectiveness when transferred to the task\nof polyp detection. We compare whether large, general-purpose datasets with\ndiverse objects outperform niche datasets with characteristics similar to\npolyps. In addition, we assess the influence of the size of the dataset on the\nefficacy of transfer learning. Experiments on the polyp datasets show that\nmodels pre-trained on relevant datasets consistently outperform those trained\nfrom scratch, highlighting the benefit of pre-training on datasets with shared\ndomain-specific features."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17012",
    "c_title":[
      "A Deterministic and Linear Model of Dynamic Optimization"
    ],
    "c_abstract":[
      "We introduce a model of infinite horizon linear dynamic optimization and\nobtain results concerning existence of solution and satisfaction of the\ncompetitive condition and transversality condition being unconditionally\nsufficient for optimality of a trajectory. We also show that under some mild\nrestrictions the optimal trajectory satisfies the Euler condition and a related\ntransversality condition. We show that the optimal value function is concave\nand continuous and the optimal trajectory satisfies the functional equation of\ndynamic programming. Linearity bites when it comes to the definition of optimal\ndecision rules which can no longer be guaranteed to be single-valued. We show\nthat the optimal decision rule is an upper semi-continuous correspondence. For\nlinear cake-eating problems, we obtain monotonicity results for the optimal\nvalue function and a conditional monotonicity result for optimal decision\nrules. We also introduce the concept of a two-phase linear cake eating problem\nand obtain a necessary condition that must be satisfied by all solutions of\nsuch problems. We show that for a class of linear dynamic optimization\nproblems, known as interlinked linear dynamic optimization problems, a slightly\nmodified version of the functional equation of dynamic programming is\nsatisfied."
    ],
    "c_categories":[
      [
        "econ.TH",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-703",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04472",
    "b_title":[
      "Challenges and Opportunities for time-delay cosmography with\n  multi-messenger gravitational lensing"
    ],
    "b_abstract":[
      "Strong gravitational lensing of variable sources, such as quasars or\nsupernovae, can be used to constrain cosmological parameters through a\ntechnique known as \"time-delay cosmography''. Competitive constraints on the\nHubble constant have been achieved with electromagnetic observations of lensed\nquasars and lensed supernovae. Gravitational wave (GW) astronomy may open up a\nnew channel for time-delay cosmography with GW signal replacing the\nelectromagnetic (EM) one. We highlight the similarities of using GW signals to\nbe applied to time-delay cosmography compared to EM signal. We then discuss key\ndifferences between GW and EM signals and their resulting advantages and\ninconveniences from the angle of the current state-of-the-art using quasars and\nlensed supernovae for time-delay cosmography. We identify the astrometric\nprecision requirement of the images as a key challenge to overcome and\nhighlight the potentially significant impact that near-perfect time-delay\nmeasurements of lensed GWs can bring to the table."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16289",
    "c_title":[
      "Multi-view Structural Convolution Network for Domain-Invariant Point\n  Cloud Recognition of Autonomous Vehicles"
    ],
    "c_abstract":[
      "Point cloud representation has recently become a research hotspot in the\nfield of computer vision and has been utilized for autonomous vehicles.\nHowever, adapting deep learning networks for point cloud data recognition is\nchallenging due to the variability in datasets and sensor technologies. This\nvariability underscores the necessity for adaptive techniques to maintain\naccuracy under different conditions. In this paper, we present the Multi-View\nStructural Convolution Network (MSCN) designed for domain-invariant point cloud\nrecognition. MSCN comprises Structural Convolution Layers (SCL) that extract\nlocal context geometric features from point clouds and Structural Aggregation\nLayers (SAL) that extract and aggregate both local and overall context features\nfrom point clouds. Additionally, our MSCN enhances feature representation\nrobustness by training with unseen domain point clouds derived from source\ndomain point clouds. This method acquires domain-invariant features and\nexhibits robust, consistent performance across various point cloud datasets,\nensuring compatibility with diverse sensor configurations without the need for\nparameter adjustments. This highlights MSCN's potential to significantly\nimprove the reliability and domain invariant features in different\nenvironments. Our code is available at https:\/\/github.com\/MLMLab\/MSCN."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-704",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04390",
    "b_title":[
      "In Praise of Stubbornness: The Case for Cognitive-Dissonance-Aware\n  Knowledge Updates in LLMs"
    ],
    "b_abstract":[
      "Despite remarkable capabilities, large language models (LLMs) struggle to\ncontinually update their knowledge without catastrophic forgetting. In\ncontrast, humans effortlessly integrate new information, detect conflicts with\nexisting beliefs, and selectively update their mental models. This paper\nintroduces a cognitive-inspired investigation paradigm to study continual\nknowledge updating in LLMs. We implement two key components inspired by human\ncognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior\nto classify information as novel, familiar, or dissonant; and (2) Targeted\nNetwork Updates, which track neural activity to identify frequently used\n(stubborn) and rarely used (plastic) neurons. Through carefully designed\nexperiments in controlled settings, we uncover a number of empirical findings\ndemonstrating the potential of this approach. First, dissonance detection is\nfeasible using simple activation and gradient features, suggesting potential\nfor cognitive-inspired training. Second, we find that non-dissonant updates\nlargely preserve prior knowledge regardless of targeting strategy, revealing\ninherent robustness in LLM knowledge integration. Most critically, we discover\nthat dissonant updates prove catastrophically destructive to the model's\nknowledge base, indiscriminately affecting even information unrelated to the\ncurrent updates. This suggests fundamental limitations in how neural networks\nhandle contradictions and motivates the need for new approaches to knowledge\nupdating that better mirror human cognitive mechanisms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06377",
    "c_title":[
      "Sets of equiangular lines in dimension $18$ constructed from $A_9 \\oplus\n  A_9 \\oplus A_1$"
    ],
    "c_abstract":[
      "In 2023, Greaves et~al.\\ constructed several sets of 57 equiangular lines in\ndimension 18. Using the concept of switching root introduced by Cao et~al.\\ in\n2021, these sets of equiangular lines are embedded in a lattice of rank 19\nspanned by norm 3 vectors together with a switching root. We characterize this\nlattice as an overlattice of the root lattice $A_9\\oplus A_9\\oplus A_1$, and\nshow that there are at least $246896$ sets of 57 equiangular lines in dimension\n$18$ arising in this way, up to isometry. Additionally, we prove that all of\nthese sets of equiangular lines are strongly maximal. Here, a set of\nequiangular lines is said to be strongly maximal if there is no set of\nequiangular lines properly containing it even if the dimension of the\nunderlying space is increased. Among these sets, there are ones with only six\ndistinct Seidel eigenvalues."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-705",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01815",
    "b_title":[
      "Tautological characteristic classes III: the Witt class for PSL(2)"
    ],
    "b_abstract":[
      "We explain the relation between the Witt class and the universal\nequicommutative class for PSL(2,K). We discuss an analogue of the Milnor-Wood\ninequality."
    ],
    "b_categories":[
      [
        "math.GR",
        "math.KT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08145",
    "c_title":[
      "Refusal Behavior in Large Language Models: A Nonlinear Perspective"
    ],
    "c_abstract":[
      "Refusal behavior in large language models (LLMs) enables them to decline\nresponding to harmful, unethical, or inappropriate prompts, ensuring alignment\nwith ethical standards. This paper investigates refusal behavior across six\nLLMs from three architectural families. We challenge the assumption of refusal\nas a linear phenomenon by employing dimensionality reduction techniques,\nincluding PCA, t-SNE, and UMAP. Our results reveal that refusal mechanisms\nexhibit nonlinear, multidimensional characteristics that vary by model\narchitecture and layer. These findings highlight the need for nonlinear\ninterpretability to improve alignment research and inform safer AI deployment\nstrategies."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-706",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03500",
    "b_title":[
      "Efficient Image Restoration via Latent Consistency Flow Matching"
    ],
    "b_abstract":[
      "Recent advances in generative image restoration (IR) have demonstrated\nimpressive results. However, these methods are hindered by their substantial\nsize and computational demands, rendering them unsuitable for deployment on\nedge devices. This work introduces ELIR, an Efficient Latent Image Restoration\nmethod. ELIR operates in latent space by first predicting the latent\nrepresentation of the minimum mean square error (MMSE) estimator and then\ntransporting this estimate to high-quality images using a latent consistency\nflow-based model. Consequently, ELIR is more than 4x faster compared to the\nstate-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also\nmore than 4x smaller, making it well-suited for deployment on\nresource-constrained edge devices. Comprehensive evaluations of various image\nrestoration tasks show that ELIR achieves competitive results, effectively\nbalancing distortion and perceptual quality metrics while offering improved\nefficiency in terms of memory and computation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "eess.IV",
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01500",
    "c_title":[
      "Gamma\/hadron separation in the TAIGA experiment with neural network\n  methods"
    ],
    "c_abstract":[
      "In this work, the ability of rare VHE gamma ray selection with neural network\nmethods is investigated in the case when cosmic radiation flux strongly\nprevails (ratio up to {10^4} over the gamma radiation flux from a point\nsource). This ratio is valid for the Crab Nebula in the TeV energy range, since\nthe Crab is a well-studied source for calibration and test of various methods\nand installations in gamma astronomy. The part of TAIGA experiment which\nincludes three Imaging Atmospheric Cherenkov Telescopes observes this\ngamma-source too. Cherenkov telescopes obtain images of Extensive Air Showers.\nHillas parameters can be used to analyse images in standard processing method,\nor images can be processed with convolutional neural networks. In this work we\nwould like to describe the main steps and results obtained in the gamma\/hadron\nseparation task from the Crab Nebula with neural network methods. The results\nobtained are compared with standard processing method applied in the TAIGA\ncollaboration and using Hillas parameter cuts. It is demonstrated that a signal\nwas received at the level of higher than 5.5{\\sigma} in 21 hours of Crab Nebula\nobservations after processing the experimental data with the neural network\nmethod."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "astro-ph.IM",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-707",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07037",
    "b_title":[
      "Liquid crystalline structures formed by sphere-rod amphiphilic molecules\n  in solvents"
    ],
    "b_abstract":[
      "Self-assembly of amphiphilic molecules is an important phenomenon attracting\na broad range of research. In this work, we study the self-assembly of KTOF4\nsphere-rod amphiphilic molecules in mixed water-dioxane solvents. The molecules\nare of a T-shaped geometry, comprised of a hydrophilic spherical Keggin-type\ncluster attached by a flexible bridge to the center of a hydrophobic rod-like\noligodialkylfluorene (OF), which consists of four OF units. Transmission\nelectron microscopy (TEM) uncovers self-assembled spherical structures of KTOF4\nin dilute solutions. These spheres are filled with smectic-like layers of KTOF4\nseparated by layers of the solution. There are two types of layer packings: (i)\nconcentric spheres and (ii) flat layers. The concentric spheres form when the\ndioxane volume fraction in the solution is 35-50 vol%. The flat layers are\nformed when the dioxane volume fraction is either below (20 and 30 vol%.) or\nabove (55 and 60 vol%.) the indicated range. The layered structures show no\nin-plane orientational order and thus resemble thermotropic smectic A liquid\ncrystals and their lyotropic analogs. The layered packings reveal edge and\nscrew dislocations. Evaporation of the solvent produces a bulk birefringent\nliquid crystal phase with textures resembling the ones of uniaxial nematic\nliquid crystals. These findings demonstrate that sphere-rod molecules produce a\nvariety of self-assembled structures that are controlled by the solvent\nproperties."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01409",
    "c_title":[
      "On Unifying Video Generation and Camera Pose Estimation"
    ],
    "c_abstract":[
      "Inspired by the emergent 3D capabilities in image generators, we explore\nwhether video generators similarly exhibit 3D awareness. Using\nstructure-from-motion (SfM) as a benchmark for 3D tasks, we investigate if\nintermediate features from OpenSora, a video generation model, can support\ncamera pose estimation. We first examine native 3D awareness in video\ngeneration features by routing raw intermediate outputs to SfM-prediction\nmodules like DUSt3R. Then, we explore the impact of fine-tuning on camera pose\nestimation to enhance 3D awareness. Results indicate that while video generator\nfeatures have limited inherent 3D awareness, task-specific supervision\nsignificantly boosts their accuracy for camera pose estimation, resulting in\ncompetitive performance. The proposed unified model, named JOG3R, produces\ncamera pose estimates with competitive quality without degrading video\ngeneration quality."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-708",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14693",
    "b_title":[
      "I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree\n  Search"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have shown remarkable\npotential in automating machine learning tasks. However, existing LLM-based\nagents often struggle with low-diversity and suboptimal code generation. While\nrecent work has introduced Monte Carlo Tree Search (MCTS) to address these\nissues, limitations persist in the quality and diversity of thoughts generated,\nas well as in the scalar value feedback mechanisms used for node selection. In\nthis study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a\nnovel approach that iteratively expands tree nodes through an introspective\nprocess that meticulously analyzes solutions and results from parent and\nsibling nodes. This facilitates a continuous refinement of the node in the\nsearch tree, thereby enhancing the overall decision-making process.\nFurthermore, we integrate a Large Language Model (LLM)-based value model to\nfacilitate direct evaluation of each node's solution prior to conducting\ncomprehensive computational rollouts. A hybrid rewarding mechanism is\nimplemented to seamlessly transition the Q-value from LLM-estimated scores to\nactual performance scores. This allows higher-quality nodes to be traversed\nearlier. Applied to the various ML tasks, our approach demonstrates a 6%\nabsolute improvement in performance compared to the strong open-source AutoML\nagents, showcasing its effectiveness in enhancing agentic AutoML systems.\nResource available at https:\/\/github.com\/jokieleung\/I-MCTS"
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13757",
    "c_title":[
      "Identifying metric structures of deep latent variable models"
    ],
    "c_abstract":[
      "Deep latent variable models learn condensed representations of data that,\nhopefully, reflect the inner workings of the studied phenomena. Unfortunately,\nthese latent representations are not statistically identifiable, meaning they\ncannot be uniquely determined. Domain experts, therefore, need to tread\ncarefully when interpreting these. Current solutions limit the lack of\nidentifiability through additional constraints on the latent variable model,\ne.g. by requiring labeled training data, or by restricting the expressivity of\nthe model. We change the goal: instead of identifying the latent variables, we\nidentify relationships between them such as meaningful distances, angles, and\nvolumes. We prove this is feasible under very mild model conditions and without\nadditional labeled data. We empirically demonstrate that our theory results in\nmore reliable latent distances, offering a principled path forward in\nextracting trustworthy conclusions from deep latent variable models."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-709",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09425",
    "b_title":[
      "Quasianalytic algebras with weakly smooth germs generate o-minimal\n  structures"
    ],
    "b_abstract":[
      "In arXiv:1303.3724, the authors provide an axiomatic way of constructing new\npolynomially bounded o-minimal structures. However, all of the structures\nsatisfying these axioms must also have smooth cell-decomposition. In this\npaper, we generalize their approach by allowing weakly smooth germs into the\nconstruction. In particular, we showed in arXiv:2501.17583 that the o-minimal\nstructure constructed in [O. Le Gal, J.-P. Rolin. \"An o-minimal structure which\ndoes not admit $C^\\infty$ cellular decomposition\" Ann. Inst. Fourier 59 (2009),\npp 543-562] satisfies the assumptions of our theorem."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17104",
    "c_title":[
      "Observations of complex organic molecules in the gas phase of the\n  interstellar medium"
    ],
    "c_abstract":[
      "Thanks to the advent of sensitive and broad bandwidth instrumentation,\ncomplex organic molecules (COMs) have been found in a wide variety of\ninterstellar environments, not only in our Galaxy but also in external galaxies\nup to a redshift of 0.89. The detection of COMs in cold environments such as\nstarless or prestellar cores has challenged our understanding of COM formation\nand new ideas are being implemented in chemical models and explored in\nlaboratory experiments. At the protostellar stage, the advent of new\ninterferometers such as the Atacama Large Millimeter\/submillimeter Array (ALMA)\nhas allowed the mapping of the weak emission of COMs in the protostellar\nenvelopes and protoplanetary disks around both low-mass and high-mass\nprotostars, pinpointing their location and revealing differentiation between\nthe different families of molecules. In this way, thermal and non-thermal\ndesorption mechanisms can be probed, constraining the efficiency of formation\nof COMs in the gas phase versus on grain surfaces. Some degree of continuity in\nthe COM composition is found from the early to late stages of star formation,\nsuggesting that a significant fraction of COMs are formed at the initial\nconditions of star formation. For extreme environments such as the Galactic\nCenter, cosmic rays and low-velocity shocks seem to influence the COM\ncomposition of low and high-density gas components. The spectral confusion\nlimit will be a major challenge for the detection of new COMs in future\nspectroscopic surveys. However, low-frequency interferometers targeting sources\nwith low-excitation temperatures may help to overcome this limit."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-710",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10682",
    "b_title":[
      "Hybrid Deepfake Image Detection: A Comprehensive Dataset-Driven Approach\n  Integrating Convolutional and Attention Mechanisms with Frequency Domain\n  Features"
    ],
    "b_abstract":[
      "Effective deepfake detection tools are becoming increasingly essential over\nthe last few years due to the growing usage of deepfakes in unethical\npractices. There exists a diverse range of deepfake generation techniques,\nwhich makes it challenging to develop an accurate universal detection\nmechanism. The 2025 Signal Processing Cup (DFWild-Cup competition) provided a\ndiverse dataset of deepfake images, which are generated from multiple deepfake\nimage generators, for training machine learning model(s) to emphasize the\ngeneralization of deepfake detection. To this end, we proposed an\nensemble-based approach that employs three different neural network\narchitectures: a ResNet-34-based architecture, a data-efficient image\ntransformer (DeiT), and an XceptionNet with Wavelet Transform to capture both\nlocal and global features of deepfakes. We visualize the specific regions that\nthese models focus for classification using Grad-CAM, and empirically\ndemonstrate the effectiveness of these models in grouping real and fake images\ninto cohesive clusters using t-SNE plots. Individually, the ResNet-34\narchitecture has achieved 88.9% accuracy, whereas the Xception network and the\nDeiT architecture have achieved 87.76% and 89.32% accuracy, respectively. With\nthese networks, our weighted ensemble model achieves an excellent accuracy of\n93.23% on the validation dataset of the SP Cup 2025 competition. Finally, the\nconfusion matrix and an Area Under the ROC curve of 97.44% further confirm the\nstability of our proposed method."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07285",
    "c_title":[
      "On the complexity of solving equations over the symmetric group $S_4$"
    ],
    "c_abstract":[
      "The complexity of solving equations over finite groups has been an active\narea of research over the last two decades, starting with Goldmann and Russell,\n\\emph{The complexity of solving equations over finite groups} from 1999. One\nimportant case of a group with unknown complexity is the symmetric group $S_4.$\nIn 2023, Idziak, Kawa{\\l}ek, and Krzaczkowski published $\\exp(\\Omega(\\log^2\nn))$ lower bounds for the satisfiability and equivalence problems over $S_4$\nunder the Exponential Time Hypothesis. In the present note, we prove that the\nsatisfiability problem $\\textsc{PolSat}(S_4)$ can be reduced to the equivalence\nproblem $\\textsc{PolEqv}(S_4)$ and thus, the two problems have the same\ncomplexity. We provide several equivalent formulations of the problem. In\nparticular, we prove that $\\textsc{PolEqv}(S_4)$ is equivalent to the circuit\nequivalence problem for $\\operatorname{CC}[2,3,2]$-circuits, which were\nintroduced by Idziak, Kawe{\\l}ek and Krzaczkowski. Under their strong\nexponential size hypothesis, such circuits cannot compute\n$\\operatorname{AND}_n$ in size $\\exp(o(\\sqrt{n})).$ Our results provide an\nupper bound on the complexity of $\\textsc{PolEqv}(S_4)$ that is based on the\nminimal size of $\\operatorname{AND}_n$ over\n$\\operatorname{CC}[2,3,2]$-circuits."
    ],
    "c_categories":[
      [
        "cs.CC",
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-711",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14187",
    "b_title":[
      "Non-convergence of the Navier-Stokes equations toward the Euler\n  equations in weak Besov spaces"
    ],
    "b_abstract":[
      "In this paper, we consider the inviscid limit problem to the higher\ndimensional incompressible Navier-Stokes equations in the whole space. It was\nproved in \\cite[J. Funct. Anal., 276 (2019)]{GZ} that given initial data\n$u_0\\in B^{s}_{p,r}$ with $1\\leq r<\\infty$, the solutions of the Navier-Stokes\nequations converge strongly in $B^{s}_{p,r}$ to the Euler equations as the\nviscosity parameter tends to zero. In the case when $r=\\infty$, we prove the\nfailure of the $B^{s}_{p,\\infty}$-convergence of the Navier-Stokes equations\ntoward the Euler equations in the inviscid limit."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08436",
    "c_title":[
      "Effect of thickness on the maximum potential drop of current collectors"
    ],
    "c_abstract":[
      "The basic principle for achieving high-power capability on an electrochemical\nenergy storage cell is minimizing the overall resistance. The resistance due to\ncurrent collecting systems has not received sufficient attention in the past,\npresumably because it was not considered of significance for low-power\nbatteries and supercapacitors. However, the necessity of high-power cells has\nreduced other sources of the inner resistance, and the current collector\npotential drop has become more important. Moreover, the miniaturization of\nenergy storage devices could increase the ohmic loses in current collectors. In\nthis work, we have developed an electrical model to assess the effect of the\ncurrent collector thickness on the maximum potential drop. We have found that\nthe thickness of current collectors is a critical parameter that can increase\nthe maximum potential drop drastically. Indeed, the maximum potential drop of\ncurrent collectors remains almost constant for thicknesses greater than 500 lm,\nbut below this value, there is an inverse relationship between the maximum\npotential drop and the thickness. We have also analyzed the effect of the\nmaterial and tab position in the maximum potential drop."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-712",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14266",
    "b_title":[
      "Divisibility Relations Between Ring Homomorphisms and Surjective Group\n  Homomorphisms in Finite Cyclic Structures"
    ],
    "b_abstract":[
      "In this article, we delve into the intricate relationship between the number\nof ring homomorphisms and surjective group homomorphisms between two finite\ncyclic structures, specifically $\\mathbb{Z}_m$ and $\\mathbb{Z}_n$. We\ndemonstrate that the number of ring homomorphisms from $\\mathbb{Z}_m$ to\n$\\mathbb{Z}_n$ is a divisor of the number of surjective group homomorphisms\nfrom $\\mathbb{Z}_m$ to $\\mathbb{Z}_n$, provided that $n$ is not of the form $2\n\\cdot \\alpha$, where each prime factor $p$ of $\\alpha$ satisfies $p \\equiv 3\n\\pmod{4}$."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15700",
    "c_title":[
      "Adapting Biomedical Abstracts into Plain language using Large Language\n  Models"
    ],
    "c_abstract":[
      "A vast amount of medical knowledge is available for public use through online\nhealth forums, and question-answering platforms on social media. The majority\nof the population in the United States doesn't have the right amount of health\nliteracy to make the best use of that information. Health literacy means the\nability to obtain and comprehend the basic health information to make\nappropriate health decisions. To build the bridge between this gap,\norganizations advocate adapting this medical knowledge into plain language.\nBuilding robust systems to automate the adaptations helps both medical and\nnon-medical professionals best leverage the available information online. The\ngoal of the Plain Language Adaptation of Biomedical Abstracts (PLABA) track is\nto adapt the biomedical abstracts in English language extracted from PubMed\nbased on the questions asked in MedlinePlus for the general public using plain\nlanguage at the sentence level. As part of this track, we leveraged the best\nopen-source Large Language Models suitable and fine-tuned for dialog use cases.\nWe compare and present the results for all of our systems and our ranking among\nthe other participants' submissions. Our top performing GPT-4 based model\nranked first in the avg. simplicity measure and 3rd on the avg. accuracy\nmeasure."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-713",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18157",
    "b_title":[
      "Monitoring snow avalanches from SAR data with deep learning"
    ],
    "b_abstract":[
      "Snow avalanches present significant risks to human life and infrastructure,\nparticularly in mountainous regions, making effective monitoring crucial.\nTraditional monitoring methods, such as field observations, are limited by\naccessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture\nRadar (SAR) data has become an important tool for large-scale avalanche\ndetection, as it can capture data in all weather conditions and across remote\nareas. However, traditional processing methods struggle with the complexity and\nvariability of avalanches. This chapter reviews the application of deep\nlearning for detecting and segmenting snow avalanches from SAR data. Early\nefforts focused on the binary classification of SAR images, while recent\nadvances have enabled pixel-level segmentation, providing greater accuracy and\nspatial resolution. A case study using Sentinel-1 SAR data demonstrates the\neffectiveness of deep learning models for avalanche segmentation, achieving\nsuperior results over traditional methods. We also present an extension of this\nwork, testing recent state-of-the-art segmentation architectures on an expanded\ndataset of over 4,500 annotated SAR images. The best-performing model among\nthose tested was applied for large-scale avalanche detection across the whole\nof Norway, revealing important spatial and temporal patterns over several\nwinter seasons."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16116",
    "c_title":[
      "Uniform Poincar\\'{e} inequalities for the discrete de Rham complex of\n  differential forms"
    ],
    "c_abstract":[
      "In this paper we prove discrete Poincar\\'e inequalities that are uniform in\nthe mesh size for the discrete de Rham complex of differential forms developed\nin [Bonaldi, Di Pietro, Droniou, and Hu, An exterior calculus framework for\npolytopal methods, J. Eur. Math. Soc., to appear, arXiv preprint 2303.11093].\nWe unify the underlying ideas behind the Poincar\\'e inequalities for all\ndifferential operators in the sequence, extending the known inequalities for\nthe gradient, curl, and divergence in three-dimensions to polytopal domains of\narbitrary dimension and general topology. A key step in the proof involves\nderiving specific Poincar\\'e inequalities for the cochain complex supported on\nthe polytopal mesh. These inequalities are of independent interest, as they are\nuseful, for instance, in establishing the existence and stability, on domains\nof generic topology, of solutions of schemes based on Mimetic Finite\nDifferences, Compatible Discrete Operators or Discrete Geometric Approach."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-714",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09495",
    "b_title":[
      "Calibration of Solid State Nuclear Track Detectors for Rare Event\n  Searches"
    ],
    "b_abstract":[
      "The calibration of the CR39 and Makrofol Nuclear Track Detectors of the\nMoEDAL experiment at the CERN-LHC was performed by exposing stacks of detector\nfoils to heavy ion beams with energies ranging from 340 MeV\/nucleon to 150\nGeV\/nucleon. After chemical etching, the base areas and lengths of etch-pit\ncones were measured using automatic and manual optical microscopes. The\nresponse of the detectors, as measured by the ratio of the track-etching rate\nover the bulk-etching rate, was determined over a range extending from their\nthreshold at Z\/$\\beta\\sim7$ and $\\sim50$ for CR39 and Makrofol, respectively,\nup to Z\/$\\beta\\sim92$"
    ],
    "b_categories":[
      [
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00369",
    "c_title":[
      "Exploring Radial Symmetry on Phased Arrays Using Particle Swarm\n  Optimization"
    ],
    "c_abstract":[
      "Phased antenna arrays enable dynamic beam shaping, which is essential for\nNon-Geostationary (NGSO) satellite communications where efficient beam\ndistribution is important. This study focuses on thinning phased antenna arrays\nwith circular apertures made up of eight replicated sectors. Circular apertures\nreduce the number of active elements, lowering system costs and improving\nradiation performance by evenly distributing energy, which helps to reduce Side\nLobe Levels (SLL). Particle Swarm Optimization was used to approach the\nthinning problem, addressing the challenge of selecting which elements should\nbe activated. The resulting design achieves an SLL of (-25.67 dB),\noutperforming previous designs with SLL reductions of (-22.53 dB). Achieved\nresults underscore the potential of circular aperture phased arrays to improve\nbeam quality, minimize interference, and deliver cost-effective solutions for\nNGSO satellites."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-715",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05880",
    "b_title":[
      "TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV\n  systems in Emergency Response Scenarios"
    ],
    "b_abstract":[
      "Designing efficient neural networks for embedded devices is a critical\nchallenge, particularly in applications requiring real-time performance, such\nas aerial imaging with drones and UAVs for emergency responses. In this work,\nwe introduce TakuNet, a novel light-weight architecture which employs\ntechniques such as depth-wise convolutions and an early downsampling stem to\nreduce computational complexity while maintaining high accuracy. It leverages\ndense connections for fast convergence during training and uses 16-bit\nfloating-point precision for optimization on embedded hardware accelerators.\nExperimental evaluation on two public datasets shows that TakuNet achieves\nnear-state-of-the-art accuracy in classifying aerial images of emergency\nsituations, despite its minimal parameter count. Real-world tests on embedded\ndevices, namely Jetson Orin Nano and Raspberry Pi, confirm TakuNet's\nefficiency, achieving more than 650 fps on the 15W Jetson board, making it\nsuitable for real-time AI processing on resource-constrained platforms and\nadvancing the applicability of drones in emergency scenarios. The code and\nimplementation details are publicly released."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.PF"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19875",
    "c_title":[
      "Reduced Basis Model for Compressible Flow"
    ],
    "c_abstract":[
      "Numerical simulations are a valuable research and layout tool for fluid flow\nproblems, yet repeated evaluations of parametrized problems, necessary to solve\noptimization problems, can be very costly. One option to speed up this process\nis to replace the costly CFD model with a cheaper one. These surrogate models\ncan be either data-driven or they can also rely on reduced basis (RB) methods\nto speed up the calculations. In contrast to data-driven surrogate models, the\nlatter are not based on regression techniques but are still aimed at explicitly\nsolving the conservation equations. Their speed-up comes from a strong\nreduction of the solution space, which results in much smaller algebraic\nsystems that need to be solved. Within this work, an RB model, suited for\nslightly compressible flow, is presented and tested on different flow\nconfigurations. The model is stabilized using a Petrov-Galerkin method with\ntrial and test function spaces of different dimensionality to generate stable\nresults for a wide range of Reynolds numbers. The presented model applies to\ngeometrically and physically parametrized flow problems. Finally, a data-driven\napproach was used to extend it to turbulent flows."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-716",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15420",
    "b_title":[
      "Visual Generation Without Guidance"
    ],
    "b_abstract":[
      "Classifier-Free Guidance (CFG) has been a default technique in various visual\ngenerative models, yet it requires inference from both conditional and\nunconditional models during sampling. We propose to build visual models that\nare free from guided sampling. The resulting algorithm, Guidance-Free Training\n(GFT), matches the performance of CFG while reducing sampling to a single\nmodel, halving the computational cost. Unlike previous distillation-based\napproaches that rely on pretrained CFG networks, GFT enables training directly\nfrom scratch. GFT is simple to implement. It retains the same maximum\nlikelihood objective as CFG and differs mainly in the parameterization of\nconditional models. Implementing GFT requires only minimal modifications to\nexisting codebases, as most design choices and hyperparameters are directly\ninherited from CFG. Our extensive experiments across five distinct visual\nmodels demonstrate the effectiveness and versatility of GFT. Across domains of\ndiffusion, autoregressive, and masked-prediction modeling, GFT consistently\nachieves comparable or even lower FID scores, with similar diversity-fidelity\ntrade-offs compared with CFG baselines, all while being guidance-free. Code\nwill be available at https:\/\/github.com\/thu-ml\/GFT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11480",
    "c_title":[
      "Matching Lagrangian and Hamiltonian Simulations in (2+1)-dimensional\n  U(1) Gauge Theory"
    ],
    "c_abstract":[
      "At finite lattice spacing, Lagrangian and Hamiltonian predictions differ due\nto discretization effects. In the Hamiltonian limit, i.e. at vanishing temporal\nlattice spacing $a_t$, the path integral approach in the Lagrangian formalism\nreproduces the results of the Hamiltonian theory. In this work, we numerically\ncalculate the Hamiltonian limit of a U$(1)$ gauge theory in $(2+1)$ dimensions.\nThis is achieved by Monte Carlo simulations in the Lagrangian formalism with\nlattices that are anisotropic in the time direction. For each ensemble, we\ndetermine the ratio between the temporal and spatial scale with the static\nquark potential and extrapolate to $a_t \\to 0$. Our results are compared with\nthe data from Hamiltonian simulations at small volumes, showing agreement\nwithin $<2\\sigma$. These results can be used to match the two formalisms."
    ],
    "c_categories":[
      [
        "hep-lat",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-717",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05812",
    "b_title":[
      "Intolerable Risk Threshold Recommendations for Artificial Intelligence"
    ],
    "b_abstract":[
      "Frontier AI models -- highly capable foundation models at the cutting edge of\nAI development -- may pose severe risks to public safety, human rights,\neconomic stability, and societal value in the coming years. These risks could\narise from deliberate adversarial misuse, system failures, unintended cascading\neffects, or simultaneous failures across multiple models.\n  In response to such risks, at the AI Seoul Summit in May 2024, 16 global AI\nindustry organizations signed the Frontier AI Safety Commitments, and 27\nnations and the EU issued a declaration on their intent to define these\nthresholds. To fulfill these commitments, organizations must determine and\ndisclose ``thresholds at which severe risks posed by a model or system, unless\nadequately mitigated, would be deemed intolerable.''\n  To assist in setting and operationalizing intolerable risk thresholds, we\noutline key principles and considerations; for example, to aim for ``good, not\nperfect'' thresholds in the face of limited data on rapidly advancing AI\ncapabilities and consequently evolving risks. We also propose specific\nthreshold recommendations, including some detailed case studies, for a subset\nof risks across eight risk categories: (1) Chemical, Biological, Radiological,\nand Nuclear (CBRN) Weapons, (2) Cyber Attacks, (3) Model Autonomy, (4)\nPersuasion and Manipulation, (5) Deception, (6) Toxicity, (7) Discrimination,\nand (8) Socioeconomic Disruption. Our goal is to serve as a starting point or\nsupplementary resource for policymakers and industry leaders, encouraging\nproactive risk management that prioritizes preventing intolerable risks (ex\nante) rather than merely mitigating them after they occur (ex post)."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18919",
    "c_title":[
      "Disparities in Magnetic Cloud Observations Between Two Spacecraft Having\n  Small Radial and Angular Separations Near 1 AU"
    ],
    "c_abstract":[
      "Studies for inferring the global characteristics of coronal mass ejections\n(CMEs) from its multipoint local in situ observations have been undertaken\nearlier, but there are limited studies utilizing measurements from multiple\nspacecraft with sufficiently small radial and angular separations. In the\npresent study, we investigate a magnetic cloud (MC) region of a CME observed in\nsitu during 2023 September 24-26, at STEREO-A and Wind spacecraft near 1 AU,\nwhich had radial and angular separations of 0.03 AU and 3.4 degrees,\nrespectively. We examine the disparities in the estimates of the arrival times\nof CME substructures, the MC axis, and its orientation between the two\nspacecraft. We also propose an approach for identifying the MC axis's arrival\nand have compared it with the arrival of the size\/time center to understand the\nnon-isotropic compression of the MC along its angular extent. Using minimum\nvariance analysis (MVA), we note that the orientation of the MC is slightly\nout-of-ecliptic at Wind but not at STEREO-A. We also compare the magnetic field\nparameters over the start to end of the MC at both spacecraft and note a\nsignificant non-coherency in the MC towards its trailing portion. Our analysis\nconfirms that MC has a stronger rear side compression at STEREO-A than at Wind,\nwith its trailing edge arriving later at Wind. Our study highlights substantial\ndifferences in CME characteristics even at mesoscales across the angular\nextent, and therefore, one needs to analyze several such cases to better\nunderstand the flux rope structure."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR",
        "physics.space-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-718",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18993",
    "b_title":[
      "Visual Autoregressive Modeling for Image Super-Resolution"
    ],
    "b_abstract":[
      "Image Super-Resolution (ISR) has seen significant progress with the\nintroduction of remarkable generative models. However, challenges such as the\ntrade-off issues between fidelity and realism, as well as computational\ncomplexity, have also posed limitations on their application. Building upon the\ntremendous success of autoregressive models in the language domain, we propose\n\\textbf{VARSR}, a novel visual autoregressive modeling for ISR framework with\nthe form of next-scale prediction. To effectively integrate and preserve\nsemantic information in low-resolution images, we propose using prefix tokens\nto incorporate the condition. Scale-aligned Rotary Positional Encodings are\nintroduced to capture spatial structures and the diffusion refiner is utilized\nfor modeling quantization residual loss to achieve pixel-level fidelity.\nImage-based Classifier-free Guidance is proposed to guide the generation of\nmore realistic images. Furthermore, we collect large-scale data and design a\ntraining process to obtain robust generative priors. Quantitative and\nqualitative results show that VARSR is capable of generating high-fidelity and\nhigh-realism images with more efficiency than diffusion-based methods. Our\ncodes will be released at https:\/\/github.com\/qyp2000\/VARSR."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10746",
    "c_title":[
      "NPA Hierarchy and Extremal Criterion in the Simplest Bell Scenario"
    ],
    "c_abstract":[
      "It is difficult to establish an analytical criterion to identify the\nboundaries of quantum correlations, even for the simplest Bell scenario. Here,\nwe briefly reviewed the plausible analytical criterion, and we found a way to\nconfirm the extremal conditions from another direction. For that purpose, we\nanalyzed the Navascu\\'es-Pironio-Ac\\'{\\i}n (NPA) hierarchy to study the\nalgebraic structure and found that the problem could not be simplified using\n$1\\!+\\!AB$ level. However, considering the plausible criterion, the $1\\!+\\!AB$\nand second levels for correlations were equal, and the extremal condition in\nthe simplest Bell scenario was replaced by that in the $1\\!+\\!AB$ level. Thus,\nthe correctness of the plausible criterion was verified, and the results\ndemonstrated that the plausible criterion held, thereby explaining its\nsimplicity. It seemed plausible, but now it becomes more certain."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-719",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05793",
    "b_title":[
      "MedSimAI: Simulation and Formative Feedback Generation to Enhance\n  Deliberate Practice in Medical Education"
    ],
    "b_abstract":[
      "Medical education faces challenges in scalability, accessibility, and\nconsistency, particularly in clinical skills training for physician-patient\ncommunication. Traditional simulation-based learning, while effective, is\nresource-intensive, difficult to schedule, and often highly variable in\nfeedback quality. Through a collaboration between AI, learning science, and\nmedical education experts, we co-developed MedSimAI, an AI-powered simulation\nplatform that enables deliberate practice, self-regulated learning (SRL), and\nautomated assessment through interactive patient encounters. Leveraging large\nlanguage models (LLMs), MedSimAI generates realistic clinical interactions and\nprovides immediate, structured feedback using established medical evaluation\nframeworks such as the Master Interview Rating Scale (MIRS). In a pilot study\nwith 104 first-year medical students, we examined engagement, conversation\npatterns, and user perceptions. Students found MedSimAI beneficial for\nrepeated, realistic patient-history practice. Conversation analysis revealed\nthat certain higher-order skills were often overlooked, though students\ngenerally performed systematic histories and empathic listening. By integrating\nunlimited practice opportunities, real-time AI assessment, and SRL principles,\nMedSimAI addresses key limitations of traditional simulation-based training,\nmaking high-quality clinical education more accessible and scalable."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15244",
    "c_title":[
      "Mode-locking in a semiconductor photonic bandgap laser"
    ],
    "c_abstract":[
      "Multimode lasers have a very complex dynamics, as expected when oscillators\nare nonlinearly coupled. Order emerges when the modes lock together; in this\ncase the coherent superposition of the modes results into a periodic train of\npulses or a nearly constant power output with a linearly chirped frequency, for\ninstance. The first is promoted by a saturable absorber, or an equivalent\nphysical mechanism, while the latter is connected to more subtle conditions,\nsuch as the fast dynamics of the gain. Here we consider the case of a multimode\nsemiconductor laser with gain provided by quantum wells but without any\nsaturable absorber. The cavity is designed to have a photonic bandgap and very\nlow dispersion. We show, first in theory, that modes can lock together and\ngenerate a variety of waveforms which are not trains of pulses nor chirped\ncontinuous power waves. Mode locking is observed in experiments on a\nIII-V\/Silicon hybrid laser with the cavity made of a suitably tapered grating.\nMoreover, we find that the mode-locking beatnote is strongly dependent on the\ninjected current: we reach more than 1 GHz modulation amplitude of the beatnote\nat a modulation frequency of 50 kHz. The behaviour of the laser is critically\ndetermined by the dispersion, which can be controlled by the photonic crystal\nstructure. By scaling up the number of interacting modes, this laser source may\noffer an effective and extremely flexible way of generating waveforms \\`a la\ncarte."
    ],
    "c_categories":[
      [
        "nlin.PS",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-720",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14087",
    "b_title":[
      "On the scalar sector of 2HDM: ring of basis invariants, syzygies, and\n  six-loop renormalization-group equations"
    ],
    "b_abstract":[
      "We consider a generating set of reparametrization invariants that can be\nconstructed from the couplings and masses entering the scalar potential of the\ngeneral Two-Higgs-Doublet Model (2HDM). Being independent of higgs-basis\nrotations, they generate a polynomial ring of basis invariants that represent\nthe physical content of the model. Ignoring for the moment gauge and Yukawa\ninteractions, we derive six-loop renormalization group equations (RGE) for all\nthe invariants entering the set. We do not compute a single Feynman diagram but\nrely heavily on the general RGE results for scalar theories. We use linear\nalgebra together with techniques from Invariant Theory. The latter not only\nallow one to compute the number of linearly independent invariants entering\nbeta functions at a certain loop order (via Hilbert series) but also provide a\nconvenient tool for dealing with polynomial relations (so-called syzygies)\nbetween invariants from the generating set."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05940",
    "c_title":[
      "Proto-exact and parabelian categories"
    ],
    "c_abstract":[
      "Proto-exact and parabelian categories serve as non-additive analogues of\nexact and quasi-abelian categories, respectively. They give rise to algebraic\nK-theory and Hall algebras similarly to the additive setting. We show that\nevery parabelian category admits a canonical proto-exact structure and we study\nseveral classes of parabelian categories, including categories of normed and\nEuclidean vector spaces, pointed closure spaces and pointed matroids, Hermitian\nvector bundles over rings of integers. We also examine finitary algebraic\ncategories arising in Arakelov geometry and provide a criterion for determining\nwhen such a category is parabelian. In particular, we prove that the categories\nof pointed convex spaces and absolutely convex spaces are parabelian."
    ],
    "c_categories":[
      [
        "math.CT",
        "math.NT",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-721",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14965",
    "b_title":[
      "Lost in Translation: How Does Bilingualism Shape Reader Preferences for\n  Annotated Charts?"
    ],
    "b_abstract":[
      "Visualizations are powerful tools for conveying information but often rely on\naccompanying text for essential context and guidance. This study investigates\nthe impact of annotation patterns on reader preferences and comprehension\naccuracy among multilingual populations, addressing a gap in visualization\nresearch. We conducted experiments with two groups fluent in English and either\nTamil (n = 557) or Arabic (n = 539) across six visualization types, each\nvarying in annotation volume and semantic content. Full-text annotations\nyielded the highest comprehension accuracy across all languages, while\npreferences diverged: English readers favored highly annotated charts, whereas\nTamil\/Arabic readers preferred full-text or minimally annotated versions.\nSemantic variations in annotations (L1-L4) did not significantly affect\ncomprehension, demonstrating the robustness of text comprehension across\nlanguages. English annotations were generally preferred, with a tendency to\nthink technically in English linked to greater aversion to non-English\nannotations, though this diminished among participants who regularly switched\nlanguages internally. Non-English annotations incorporating visual or external\nknowledge were less favored, particularly in titles. Our findings highlight\ncultural and educational factors influencing perceptions of visual information,\nunderscoring the need for inclusive annotation practices for diverse linguistic\naudiences. All data and materials are available at: https:\/\/osf.io\/ckdb4\/."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08386",
    "c_title":[
      "On the positivity of light-ray operators"
    ],
    "c_abstract":[
      "We consider light-ray operators $\\mathcal{L}_{2n} = \\int\\mathrm{d} x^+\n(x^+)^{2n}T_{++}$, where $x^+$ is a null coordinate and $n$ a positive integer,\nin QFT in Minkowski spacetime in arbitrary dimensions. These operators are\ngeneralizations of the average null energy operator, which is positive. We give\na proof that the light-ray operators are positive in a non-minimally coupled\nbut otherwise free scalar field theory, and we present various arguments that\nshow that $\\mathcal{L}_2$ is positive semi-definite in two-dimensional\nconformal field theories. However, we are also able to construct reasonable\nstates which contradict these results by exploiting an infrared loophole in our\nproof. To resolve the resulting tension, we conjecture that the light-ray\noperators are positive in a more restrictive set of states. These states\nsatisfy stronger conditions than the Hadamard condition, and have the\ninterpretation of states that can be physically prepared. Our proposal is\nnontrivial even in two-dimensional CFT."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-722",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17882",
    "b_title":[
      "Think Before Refusal : Triggering Safety Reflection in LLMs to Mitigate\n  False Refusal Behavior"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have demonstrated that\nfine-tuning and human alignment can render LLMs harmless. In practice, such\n\"harmlessness\" behavior is mainly achieved by training models to reject harmful\nrequests, such as \"Explain how to burn down my neighbor's house\", where the\nmodel appropriately declines to respond. However, this approach can\ninadvertently result in false refusal, where models reject benign queries as\nwell, such as \"Tell me how to kill a Python process\". In this work, we\ndemonstrate that prompting safety reflection before generating a response can\nmitigate false refusal behavior. Building on this finding, we introduce the\nThink-Before-Refusal (TBR) schema and conduct safety-aware instruction\nfine-tuning incorporating safety reflection. In an ablation study across 15\npre-trained models, we show that models fine-tuned with safety reflection\nsignificantly reduce false refusal behavior while maintaining safety and\noverall performance compared to those fine-tuned without safety reflection."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01910",
    "c_title":[
      "dyAb: Flow Matching for Flexible Antibody Design with AlphaFold-driven\n  Pre-binding Antigen"
    ],
    "c_abstract":[
      "The development of therapeutic antibodies heavily relies on accurate\npredictions of how antigens will interact with antibodies. Existing\ncomputational methods in antibody design often overlook crucial conformational\nchanges that antigens undergo during the binding process, significantly\nimpacting the reliability of the resulting antibodies. To bridge this gap, we\nintroduce dyAb, a flexible framework that incorporates AlphaFold2-driven\npredictions to model pre-binding antigen structures and specifically addresses\nthe dynamic nature of antigen conformation changes. Our dyAb model leverages a\nunique combination of coarse-grained interface alignment and fine-grained flow\nmatching techniques to simulate the interaction dynamics and structural\nevolution of the antigen-antibody complex, providing a realistic representation\nof the binding process. Extensive experiments show that dyAb significantly\noutperforms existing models in antibody design involving changing antigen\nconformations. These results highlight dyAb's potential to streamline the\ndesign process for therapeutic antibodies, promising more efficient development\ncycles and improved outcomes in clinical applications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-723",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12674",
    "b_title":[
      "Boundary Conditions for the Entanglement Cut in 2D Conformal Field\n  Theories"
    ],
    "b_abstract":[
      "The entanglement spectra for a subsystem in a spin chain fine-tuned to a\nquantum-critical point contains signatures of the underlying quantum field\ntheory that governs its low-energy properties. For an open chain with given\nboundary conditions described by a 2D conformal field theory~(CFT), the\nentanglement spectrum of the left\/right half of the system coincides with a\nboundary CFT spectrum, where one of the boundary conditions arise due to the\n`entanglement cut'. The latter has been argued to be conformal and has been\nnumerically found to be the `free' boundary condition for Ising, Potts and free\nboson theories. For these models, the `free' boundary condition for the lattice\ndegree of freedom has a counterpart in the continuum theory. However, this is\nnot true in general. Here, this question is analyzed for the unitary minimal\nmodels of 2D CFTs using the density matrix renormalization group technique. The\nentanglement spectra are computed for blocks of spins in open chains of A-type\nrestricted solid-on-solid models with identical boundary conditions at the\nends. The imposed boundary conditions are realized exactly for these lattice\nmodels due to their integrable nature. The obtained entanglement spectra are in\ngood agreement with certain boundary CFT spectra. The boundary condition for\nthe entanglement cut is found to be conformal and to coincide with the one with\nthe highest boundary entropy. This identification enables determination of the\nexponents governing the unusual corrections to the entanglement entropy from\nthe CFT partition functions. These are compared with numerical results."
    ],
    "b_categories":[
      [
        "hep-th",
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01705",
    "c_title":[
      "Progressive Binarization with Semi-Structured Pruning for LLMs"
    ],
    "c_abstract":[
      "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing tasks, but their high computational and memory demands pose\nchallenges for deployment on resource-constrained devices. Binarization, as an\nefficient compression method that reduces model weights to just 1 bit,\nsignificantly lowers both computational and memory requirements. Despite this,\nthe binarized LLM still contains redundancy, which can be further compressed.\nSemi-structured pruning provides a promising approach to achieve this, which\noffers a better trade-off between model performance and hardware efficiency.\nHowever, simply combining binarization with semi-structured pruning can lead to\na significant performance drop. To address this issue, we propose a Progressive\nBinarization with Semi-Structured Pruning (PBS$^2$P) method for LLM\ncompression. We first propose a Stepwise semi-structured Pruning with\nBinarization Optimization (SPBO). Our optimization strategy significantly\nreduces the total error caused by pruning and binarization, even below that of\nthe no-pruning scenario. Furthermore, we design a Coarse-to-Fine Search (CFS)\nmethod to select pruning elements more effectively. Extensive experiments\ndemonstrate that PBS$^2$P achieves superior accuracy across various LLM\nfamilies and evaluation metrics, noticeably outperforming state-of-the-art\n(SOTA) binary PTQ methods. The code and models will be available at\nhttps:\/\/github.com\/XIANGLONGYAN\/PBS2P."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-724",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05100",
    "b_title":[
      "Hands vs. Controllers: Comparing User Interactions in Virtual Reality\n  Shopping Environments"
    ],
    "b_abstract":[
      "Virtual reality enables users to experience real-life situations in immersive\nenvironments. Interaction methods significantly shape user experience,\nparticularly in high fidelity simulations mimicking real world tasks. This\nstudy evaluates two primary VR interaction techniques, hand based and\ncontroller based, through virtual shopping tasks in a simulated supermarket\nwith 40 participants. Hand-based interaction was preferred for its natural,\nimmersive qualities and alignment with real-world gestures but faced usability\nchallenges, including limited haptic feedback and grasping inefficiencies. In\ncontrast, controller-based interaction offered greater precision and\nreliability, making it more suitable for tasks requiring fine motor skills."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14086",
    "c_title":[
      "Grassmann Tensor Renormalization Group for two-flavor massive Schwinger\n  model with a theta term"
    ],
    "c_abstract":[
      "We investigate the $N_f=2$ Schwinger model with the massive staggered\nfermions in the presence of a $2\\pi$ periodic $\\theta$ term, using the\nGrassmann tensor renormalization group. Thanks to the Grassmann tensor network\nformulation, there is no difficulty in dealing with the massive staggered\nfermions. We study the $\\theta$ dependence of the free energy in the\nthermodynamic limit. Our calculation provides consistent results with the\nanalytical solution in the large mass limit. The results also suggest that the\n$N_f=2$ Schwinger model on a lattice has a different phase structure from that\ndescribed by the continuum theory."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-725",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11089",
    "b_title":[
      "Advancing Atom Probe Tomography of SrTiO$_3$: Measurement Methodology\n  and Impurity Detection Limits"
    ],
    "b_abstract":[
      "Strontium titanate (STO) possesses promising properties for applications in\nthermoelectricity, catalysis, fuel cells, and more, but its performance is\nhighly dependent on stoichiometry and impurity levels. While atom probe\ntomography (APT) can provide detailed three-dimensional atomic-scale chemical\ninformation, STO specimens have been challenging to analyze due to premature\nspecimen fracture. In this study, we show that by applying a thin metal coating\nto atom probe tips, STO specimens can be analyzed with nearly 100% success.\nUsing this approach, we investigate both undoped STO and 1 at% Nb-doped STO,\nachieving sufficient sensitivity to detect Nb concentrations as low as 0.7 at%.\nThis work establishes a reliable APT method for high-resolution chemical\nanalysis of STO at the nanoscale."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06473",
    "c_title":[
      "Enhancing Layer Attention Efficiency through Pruning Redundant\n  Retrievals"
    ],
    "c_abstract":[
      "Growing evidence suggests that layer attention mechanisms, which enhance\ninteraction among layers in deep neural networks, have significantly advanced\nnetwork architectures. However, existing layer attention methods suffer from\nredundancy, as attention weights learned by adjacent layers often become highly\nsimilar. This redundancy causes multiple layers to extract nearly identical\nfeatures, reducing the model's representational capacity and increasing\ntraining time. To address this issue, we propose a novel approach to quantify\nredundancy by leveraging the Kullback-Leibler (KL) divergence between adjacent\nlayers. Additionally, we introduce an Enhanced Beta Quantile Mapping (EBQM)\nmethod that accurately identifies and skips redundant layers, thereby\nmaintaining model stability. Our proposed Efficient Layer Attention (ELA)\narchitecture, improves both training efficiency and overall performance,\nachieving a 30\\% reduction in training time while enhancing performance in\ntasks such as image classification and object detection."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-726",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12075",
    "b_title":[
      "The large mass limit of $G_2$ and Calabi-Yau monopoles"
    ],
    "b_abstract":[
      "We develop a structure theory for the limit of $SU(2)$ $G_2$-monopoles (resp.\nCalabi-Yau monopoles) on a principal $SU(2)$-bundle over an asymptotically\nconical $G_2$-manifolds (resp. Calabi-Yau 3-folds) as the mass parameter tends\nto infinity, while the topologial data for the bundle stays fixed. We show how\nto extract a singular abelian $G_2$-monopole (resp. Calabi-Yau monopole) with\nDirac singularity along a calibrated cycle in the large mass limit, and we\nprove an energy identity for monopole bubbles."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01876",
    "c_title":[
      "Accuracy Can Lie: On the Impact of Surrogate Model in Configuration\n  Tuning"
    ],
    "c_abstract":[
      "To ease the expensive measurements during configuration tuning, it is natural\nto build a surrogate model as the replacement of the system, and thereby the\nconfiguration performance can be cheaply evaluated. Yet, a stereotype therein\nis that the higher the model accuracy, the better the tuning result would be.\nThis \"accuracy is all\" belief drives our research community to build more and\nmore accurate models and criticize a tuner for the inaccuracy of the model\nused. However, this practice raises some previously unaddressed questions,\ne.g., Do those somewhat small accuracy improvements reported in existing work\nreally matter much to the tuners? What role does model accuracy play in the\nimpact of tuning quality? To answer those related questions, we conduct one of\nthe largest-scale empirical studies to date-running over the period of 13\nmonths 24*7-that covers 10 models, 17 tuners, and 29 systems from the existing\nworks while under four different commonly used metrics, leading to 13,612 cases\nof investigation. Surprisingly, our key findings reveal that the accuracy can\nlie: there are a considerable number of cases where higher accuracy actually\nleads to no improvement in the tuning outcomes (up to 58% cases under certain\nsetting), or even worse, it can degrade the tuning quality (up to 24% cases\nunder certain setting). We also discover that the chosen models in most\nproposed tuners are sub-optimal and that the required % of accuracy change to\nsignificantly improve tuning quality varies according to the range of model\naccuracy. Deriving from the fitness landscape analysis, we provide in-depth\ndiscussions of the rationale behind, offering several lessons learned as well\nas insights for future opportunities. Most importantly, this work poses a clear\nmessage to the community: we should take one step back from the natural\n\"accuracy is all\" belief for model-based configuration tuning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-727",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08298",
    "b_title":[
      "Improving Existing Optimization Algorithms with LLMs"
    ],
    "b_abstract":[
      "The integration of Large Language Models (LLMs) into optimization has created\na powerful synergy, opening exciting research opportunities. This paper\ninvestigates how LLMs can enhance existing optimization algorithms. Using their\npre-trained knowledge, we demonstrate their ability to propose innovative\nheuristic variations and implementation strategies. To evaluate this, we\napplied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt\n(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that\nincorporates a heuristic in the solution construction phase. Our results show\nthat an alternative heuristic proposed by GPT-4o outperforms the\nexpert-designed heuristic of CMSA, with the performance gap widening on larger\nand denser graphs. Project URL: https:\/\/imp-opt-algo-llms.surge.sh\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12113",
    "c_title":[
      "Dual NUP Representations and Min-Maximization in Factor Graphs"
    ],
    "c_abstract":[
      "Normals with unknown parameters (NUP) can be used to convert nontrivial\nmodel-based estimation problems into iterations of linear least-squares or\nGaussian estimation problems. In this paper, we extend this approach by\naugmenting factor graphs with convex-dual variables and pertinent NUP\nrepresentations. In particular, in a state space setting, we propose a new\niterative forward-backward algorithm that is dual to a recently proposed\nbackward-forward algorithm."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SY",
        "eess.SP",
        "eess.SY",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-728",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14137",
    "b_title":[
      "A variational formulation of the governing equations of ideal quantum\n  fluids"
    ],
    "b_abstract":[
      "Applying the least action principle to the motion of an ideal gas, we find\nBernoulli's equation where the local velocity is expressed as the gradient of a\nvelocity potential, while the internal energy depends on the interaction among\nthe particles of the gas. Then, assuming that the internal energy is\nproportional non-locally to the logarithm of the mass density and truncating\nthe resulting sum of density gradients after the second term, we find an\nadditional Bohm's quantum potential term in the internal energy. Therefore, the\nBernoulli equation reduces to the Madelung equation, revealing a novel\nclassical description of quantum fluids that does not require to postulate\nquantum mechanics. Finally, non-locality can be removed by introducing a\nretarded potential, thus leading to a covariant formulation of the quantum\npotential and of the equation of motion of an ideal quantum fluid."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.14164",
    "c_title":[
      "Large deviation principles for periodic points of the Dyck shift"
    ],
    "c_abstract":[
      "We investigate periodic points of the Dyck shift from the viewpoint of large\ndeviations. We establish the level-2 Large Deviation Principle with the rate\nfunction given in terms of Kolmogorov-Sinai entropies of shift-invariant Borel\nprobability measures. Unlike topologically mixing Markov shifts, the level-2\nrate function is non-convex and level-1 rate functions are superpositions of\ntwo convex continuous functions. Using the thermodynamic formalism, we show the\nanalyticity of level-1 rate functions in some relevant cases. We display a\nnon-convex level-1 rate function with a non-differentiable point in the\ninterior of its effective domain."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-729",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03276",
    "b_title":[
      "High-precision numerical evaluation of Lauricella functions"
    ],
    "b_abstract":[
      "We present a method for high-precision numerical evaluations of Lauricella\nfunctions, whose indices are linearly dependent on some parameter\n$\\varepsilon$, in terms of their Laurent series expansions at zero. This method\nis based on finding analytic continuations of these functions in terms of\nFrobenius generalized power series. Being one-dimensional, these series are\nmuch more suited for high-precision numerical evaluations than\nmulti-dimensional sums arising in approaches to analytic continuations based on\nre-expansions of hypergeometric series or Mellin--Barnes integral\nrepresentations. To accelerate the calculation procedure further, the\n$\\varepsilon$ dependence of the result is reconstructed from the evaluations of\ngiven Lauricella functions at specific numerical values of $\\varepsilon$,\nwhich, in addition, allows for efficient parallel implementation. The method\nhas been implemented in the $\\texttt{PrecisionLauricella}$ package, written in\nWolfram Mathematica language."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12448",
    "c_title":[
      "Introduction to inverse problems for non-linear partial differential\n  equations"
    ],
    "c_abstract":[
      "We consider inverse problems for non-linear hyperbolic and elliptic equations\nand give an introduction to the method based on the multiple linearization, or\non the construction of artificial sources, to solve these problems. The method\nis based on self-interaction of linearized waves or other solutions in the\npresence of non-linearities. Multiple linearization has successfully been used\nto solve inverse problems for non-linear equation which are still unsolved for\nthe corresponding linear equations."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-730",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07744",
    "b_title":[
      "Hydrodynamic stresses in a multi-species suspension of active Janus\n  colloids"
    ],
    "b_abstract":[
      "A realistic description of active particles should include interactions with\nthe medium, commonly a momentum-conserving simple fluid, in which they are\nsuspended. In this work, we consider a multi-species suspension of\nself-diffusiophoretic Janus colloids interacting via chemical and hydrodynamic\nfields. Through a systematic coarse-graining of the microscopic dynamics, we\ncalculate the multi-component contribution to the hydrodynamic stress tensor of\nthe incompressible Stokesian fluid in which the particles are immersed. For a\nsingle species, we find that the strength of the stress produced by the\ngradients of the number density field is determined by the particles'\nself-propulsion and chemotactic alignment, and can be tuned to be either\ncontractile or extensile. For a multi-species system, we unveil how different\nforms of activity modify the stress tensor, and how non-reciprocity in\nhydrodynamic interactions emerges in an active binary mixture."
    ],
    "b_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09969",
    "c_title":[
      "Data Valuation using Neural Networks for Efficient Instruction\n  Fine-Tuning"
    ],
    "c_abstract":[
      "Influence functions provide crucial insights into model training, but\nexisting methods suffer from large computational costs and limited\ngeneralization. Particularly, recent works have proposed various metrics and\nalgorithms to calculate the influence of data using language models, which do\nnot scale well with large models and datasets. This is because of the expensive\nforward and backward passes required for computation, substantial memory\nrequirements to store large models, and poor generalization of influence\nestimates to new data. In this paper, we explore the use of small neural\nnetworks -- which we refer to as the InfluenceNetwork -- to estimate influence\nvalues, achieving up to 99% cost reduction. Our evaluation demonstrates that\ninfluence values can be estimated with models just 0.0027% the size of full\nlanguage models (we use 7B and 8B versions). We apply our algorithm of\nestimating influence values (called NN-CIFT: Neural Networks for effiCient\nInstruction Fine-Tuning) to the downstream task of subset selection for general\ninstruction fine-tuning. In our study, we include four state-of-the-art\ninfluence functions and show no compromise in performance, despite large\nspeedups, between NN-CIFT and the original influence functions. We provide an\nin-depth hyperparameter analyses of NN-CIFT. The code for our method can be\nfound here: https:\/\/github.com\/agarwalishika\/NN-CIFT."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-731",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05159",
    "b_title":[
      "A Lightweight Method to Disrupt Memorized Sequences in LLM"
    ],
    "b_abstract":[
      "Large language models (LLMs) demonstrate impressive capabilities across many\ntasks yet risk reproducing copyrighted content verbatim, raising legal and\nethical concerns. Although methods like differential privacy or neuron editing\ncan reduce memorization, they typically require costly retraining or direct\naccess to model weights and may degrade performance. To address these\nchallenges, we propose TokenSwap, a lightweight, post-hoc approach that\nreplaces the probabilities of grammar-related tokens with those from a small\nauxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercial\ngrade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our method\neffectively reduces well-known cases of memorized generation by upto 10x with\nlittle to no impact on downstream tasks. Our approach offers a uniquely\naccessible and effective solution to users of real-world systems."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14063",
    "c_title":[
      "Empirical estimation of host galaxy dispersion measure towards well\n  localized fast radio bursts"
    ],
    "c_abstract":[
      "Fast radio bursts (FRBs) are very energetic pulses of unknown physical\norigin. These can be used to study the intergalactic medium (IGM) thanks to\ntheir dispersion measure (DM). The DM has several contributions that can be\nmeasured (or estimated), including the contribution from the host galaxy\nitself, DM_host. In this work, we empirically estimate DM_host for a sample of\n12 galaxy hosts, using a direct method based solely on the properties of the\nhost galaxies themselves (DM_host_dir). We use VLT\/MUSE observations of the FRB\nhosts for estimating DM_host_dir. The method relies on estimating the DM\ncontribution of both the FRB host galaxy's interstellar medium and its halo\nseparately. For comparison purposes, we also provide an alternative indirect\nmethod to estimate DM_host based on the Macquart relation (DM_host_mq). We find\nan average <DM_host> = 80+\/-11 pc\/cc with a standard deviation of 38 pc\/cc (in\nthe rest-frame) based on our direct method, with a systematic uncertainty of\n30%. We report positive correlations between DM_host and both the stellar\nmasses and the star-formation rates of their host galaxies. In contrast, we do\nnot find any strong correlation between DM_host and neither redshift nor the\nprojected distances to the FRB hosts centers. Finally, we do not find any\nstrong correlation between DM_host_dir and DM_host_mq, although their average\nvalues are consistent. Our reported correlations could be used to improve the\npriors used in establishing DM_host for individual FRBs. Similarly, such\ncorrelations and the lack of a strong redshift evolution can be used to\nconstrain models for the progenitor of FRBs. However, the lack of a DM_host_dir\nand DM_host_mq correlation indicates that there may still be contributions to\nthe DM of FRBs not included in our modeling, e.g. large DMs from the FRB\nprogenitor and\/or intervening large-scale structures not accounted for in\nDM_host_mq."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-732",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07366",
    "b_title":[
      "RITHMS : An advanced stochastic framework for the simulation of\n  transgenerational hologenomic data"
    ],
    "b_abstract":[
      "A holobiont is made up of a host organism together with its microbiota. In\nthe context of animal breeding, as the holobiont can be viewed as the single\nunit upon which selection operates, integrating microbiota data into genomic\nprediction models may be a promising approach to improve predictions of\nphenotypic and genetic values. Nevertheless, there is a paucity of hologenomic\ntransgenerational data to address this hypothesis, and thus to fill this gap,\nwe propose a new simulation framework. Our approach, an R Implementation of a\nTransgenerational Hologenomic Model-based Simulator (RITHMS) is an open-source\npackage, builds upon the MoBPS package and incorporates distinctive\ncharacteristics of the microbiota, notably vertical and horizontal transmission\nas well as modulation due to the environment and host genetics. In addition,\nRITHMS can account for a variety of selection strategies and is adaptable to\ndifferent genetic architectures. We simulated transgenerational hologenomic\ndata using RITHMS under a wide variety of scenarios, varying heritability,\nmicrobiability, and microbiota heritability. We found that simulated data\naccurately reflected expected characteristics, notably based on microbial\ndiversity metrics, correlation between taxa, modulation of vertical and\nhorizontal transmission, response to environmental effects and the evolution of\nphenotypic values depending on selection strategy. Our results support the\nrelevance of our simulation framework and illustrate its possible use for\nbuilding a selection index balancing genetic gain and microbial diversity.\nRITHMS is an advanced, flexible tool for generating transgenerational\nhologenomic data that incorporate the complex interplay between genetics,\nmicrobiota and environment."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11278",
    "c_title":[
      "Reducing Computational Complexity of Rigidity-Based UAV Trajectory\n  Optimization for Real-Time Cooperative Target Localization"
    ],
    "c_abstract":[
      "Accurate and swift localization of the target is crucial in emergencies.\nHowever, accurate position data of a target mobile device, typically obtained\nfrom global navigation satellite systems (GNSS), cellular networks, or WiFi,\nmay not always be accessible to first responders. For instance, 1) accuracy and\navailability can be limited in challenging signal reception environments, and\n2) in regions where emergency location services are not mandatory, certain\nmobile devices may not transmit their location during emergencies. As an\nalternative localization method, a network of unmanned aerial vehicles (UAVs)\ncan be employed to passively locate targets by collecting radio frequency (RF)\nsignal measurements, such as received signal strength (RSS). In these\nsituations, UAV trajectories play a critical role in localization performance,\ninfluencing both accuracy and search time. Previous studies optimized UAV\ntrajectories using the determinant of the Fisher information matrix (FIM), but\nits performance declines under unfavorable geometric conditions, such as when\nUAVs start from a single base, leading to position ambiguity. To address this,\nour prior work introduced a rigidity-based approach, which improved the search\ntime compared to FIM-based methods in our simulation case. However, the high\ncomputational cost of rigidity-based optimization, primarily due to singular\nvalue decomposition (SVD), limits its practicality. In this paper, we applied\ntechniques to reduce computational complexity, including randomized SVD, smooth\nSVD, and vertex pruning."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-733",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07087",
    "b_title":[
      "iManip: Skill-Incremental Learning for Robotic Manipulation"
    ],
    "b_abstract":[
      "The development of a generalist agent with adaptive multiple manipulation\nskills has been a long-standing goal in the robotics community. In this paper,\nwe explore a crucial task, skill-incremental learning, in robotic manipulation,\nwhich is to endow the robots with the ability to learn new manipulation skills\nbased on the previous learned knowledge without re-training. First, we build a\nskill-incremental environment based on the RLBench benchmark, and explore how\ntraditional incremental methods perform in this setting. We find that they\nsuffer from severe catastrophic forgetting due to the previous methods on\nclassification overlooking the characteristics of temporality and action\ncomplexity in robotic manipulation tasks. Towards this end, we propose an\nincremental Manip}ulation framework, termed iManip, to mitigate the above\nissues. We firstly design a temporal replay strategy to maintain the integrity\nof old skills when learning new skill. Moreover, we propose the extendable\nPerceiverIO, consisting of an action prompt with extendable weight to adapt to\nnew action primitives in new skill. Extensive experiments show that our\nframework performs well in Skill-Incremental Learning. Codes of the\nskill-incremental environment with our framework will be open-source."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16470",
    "c_title":[
      "Optical Nuclear Electric Resonance in LiNa: Selective Addressing of\n  Nuclear Spins Through Pulsed Lasers"
    ],
    "c_abstract":[
      "Optical nuclear electric resonance (ONER), a recently proposed protocol for\nnuclear spin manipulation in atomic systems via short laser pulses with MHz\nrepetition rate, exploits the coupling between the nuclear quadrupole moment of\na suitable atom and the periodic modulations of the electric field gradient\ngenerated by an optically stimulated electronic excitation. In this theory\npaper, we extend the scope of ONER from atomic to molecular systems and show\nthat molecular vibrations do not interfere with our protocol. Exploring the\ndiatomic molecule LiNa as a first benchmark system, our investigation showcases\nthe robustness with respect to molecular vibration, and the ability to address\nand manipulate each of the two nuclear spins independently, simply by adjusting\nthe repetition rate of a pulsed laser. Our findings suggest that it might be\npossible to shift complicated spin manipulation tasks required for quantum\ncomputing into the time domain by pulse-duration encoded laser signals."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-734",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09329",
    "b_title":[
      "Energy Optimized Piecewise Polynomial Approximation Utilizing Modern\n  Machine Learning Optimizers"
    ],
    "b_abstract":[
      "This work explores an extension of ML-optimized piecewise polynomial\napproximation by incorporating energy optimization as an additional objective.\nTraditional closed-form solutions enable continuity and approximation targets\nbut lack flexibility in accommodating complex optimization goals. By leveraging\nmodern gradient descent optimizers within TensorFlow, we introduce a framework\nthat minimizes total curvature in cam profiles, leading to smoother motion and\nreduced energy consumption for input data that is unfavorable for sole\napproximation and continuity optimization. Experimental results confirm the\neffectiveness of this approach, demonstrating its potential to improve\nefficiency in scenarios where input data is noisy or suboptimal for\nconventional methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15642",
    "c_title":[
      "The classical limit of quantum mechanics through coarse-grained\n  measurements"
    ],
    "c_abstract":[
      "We address the classical limit of quantum mechanics, focusing on its\nemergence through coarse-grained measurements when multiple outcomes are\nconflated into slots. We rigorously derive effective classical kinematics under\nsuch measurements, demonstrating that when the volume of the coarse-grained\nslot in phase space significantly exceeds Planck's constant, quantum states can\nbe effectively described by classical probability distributions. Furthermore,\nwe show that the dynamics, derived under coarse-grained observations and the\nlinear approximation of the quantum Hamiltonian around its classical values\nwithin the slots, is effectively described by a classical Hamiltonian following\nLiouville dynamics. The classical Hamiltonian obtained through this process is\nequivalent to the one from which the underlying quantum Hamiltonian is derived\nvia the (Dirac) quantization procedure, completing the quantization-classical\nlimit loop. The Ehrenfest time, marking the duration within which classical\nbehavior remains valid, is analyzed for various physical systems. The\nimplications of these findings are discussed in the context of both macroscopic\nand microscopic systems, revealing the mechanisms behind their observed\nclassicality. This work provides a comprehensive framework for understanding\nthe quantum-to-classical transition and addresses foundational questions about\nthe consistency of the quantization-classical limit cycle."
    ],
    "c_categories":[
      [
        "physics.class-ph",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-735",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10074",
    "b_title":[
      "SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and\n  Chain-of-Thought for Embodied Task Planning"
    ],
    "b_abstract":[
      "Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19299",
    "c_title":[
      "General diffusions on the star graph as time-changed Walsh Brownian\n  motion"
    ],
    "c_abstract":[
      "We establish a representation of general regular diffusions on star-shaped\ngraphs as time-changed Walsh Brownian motions. These are Markov processes with\ncontinuous sample paths whose law on each edge is described locally by\ngeneralized second-order operators, a gluing condition at the junction vertex,\nand boundary conditions. The representation is built upon two key results: (i)\na time-change representation for the distance-to-origin process, and (ii) a\nprobabilistic interpretation of the gluing condition. This result is leveraged\nto derive an occupation times formula for these processes.\n  Additionally, we prove two results of independent interest. First, we provide\nconditions under which a diffusion on the star graph is Feller and\nFeller--Dynkin, extending classical results for one-dimensional diffusions.\nSecond, we establish the existence and uniqueness of solutions to the Dirichlet\nproblem on the unit disk of the star graph, along with an explicit expression\nfor the corresponding Green function."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-736",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07969",
    "b_title":[
      "7ABAW-Compound Expression Recognition via Curriculum Learning"
    ],
    "b_abstract":[
      "With the advent of deep learning, expression recognition has made significant\nadvancements. However, due to the limited availability of annotated compound\nexpression datasets and the subtle variations of compound expressions, Compound\nEmotion Recognition (CE) still holds considerable potential for exploration. To\nadvance this task, the 7th Affective Behavior Analysis in-the-wild (ABAW)\ncompetition introduces the Compound Expression Challenge based on C-EXPR-DB, a\nlimited dataset without labels. In this paper, we present a curriculum\nlearning-based framework that initially trains the model on single-expression\ntasks and subsequently incorporates multi-expression data. This design ensures\nthat our model first masters the fundamental features of basic expressions\nbefore being exposed to the complexities of compound emotions. Specifically,\nour designs can be summarized as follows: 1) Single-Expression Pre-training:\nThe model is first trained on datasets containing single expressions to learn\nthe foundational facial features associated with basic emotions. 2) Dynamic\nCompound Expression Generation: Given the scarcity of annotated compound\nexpression datasets, we employ CutMix and Mixup techniques on the original\nsingle-expression images to create hybrid images exhibiting characteristics of\nmultiple basic emotions. 3) Incremental Multi-Expression Integration: After\nperforming well on single-expression tasks, the model is progressively exposed\nto multi-expression data, allowing the model to adapt to the complexity and\nvariability of compound expressions. The official results indicate that our\nmethod achieves the \\textbf{best} performance in this competition track with an\nF-score of 0.6063. Our code is released at https:\/\/github.com\/YenanLiu\/ABAW7th."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17727",
    "c_title":[
      "The Large Hadron electron Collider as a bridge project for CERN"
    ],
    "c_abstract":[
      "The LHeC is the project for delivering electron-nucleon collisions at CERN\nusing the HL-LHC beams. An Energy Recovery Linac in racetrack configuration\nwill provide 50 GeV electrons to achieve centre-of-mass energies around 1\nTeV\/nucleon and instantaneous luminosities around $10^{34}$ cm$^{-2}$s$^{-1}$.\nThe LHeC program elaborated in the CDR of 2021 included a phase with concurrent\noperation of electron-hadron and hadron-hadron collisions, followed by a\nstandalone phase of electron-hadron collisions only. In view of the current\nHL-LHC schedule, in this paper we have examined the possibilities of a program\nafter the regular HL-LHC program with only electron-proton operation. In this\noperation mode, the LHeC would serve as an impactful bridge project between\nmajor colliders at CERN. The standalone physics program comprises electroweak,\nHiggs, top-quark, BSM and strong-interaction physics. In addition, it empowers\nthe physics analyses at the HL-LHC by retrofitting measurements and searches\nwith significantly more precise knowledge of the proton structure and\n$\\alpha_s$. The accelerator technology deployed in the Energy Recovery Linac\nfor the LHeC is a major stepping-stone for the performance, cost reduction and\ntraining for future colliders. The capital investments in the LHeC electron\naccelerator can be reused in a cost-efficient way as the injector for the\nFCC-ee. Finally, data from the LHeC are essential to enable the physics\npotential of any new high-energy hadron collider. The operational plan of 6\nyears easily fits in the period between two major colliders at CERN. Similar to\nthe LHeC empowering the HL-LHC physics program, the FCC-eh would be an\nimpactful addition to the FCC physics program."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-737",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12119",
    "b_title":[
      "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free\n  Multimodal Data Selection"
    ],
    "b_abstract":[
      "Visual instruction tuning refines pre-trained Multimodal Large Language\nModels (MLLMs) to enhance their real-world task performance. However, the rapid\nexpansion of visual instruction datasets introduces significant data\nredundancy, leading to excessive computational costs. Existing data selection\nmethods predominantly rely on proxy models or loss-based metrics, both of which\nimpose substantial computational overheads due to the necessity of model\ninference and backpropagation. To address this challenge, we propose PRISM, a\nnovel training-free approach for efficient multimodal data selection. Unlike\nexisting methods, PRISM eliminates the reliance on proxy models, warm-up\npretraining, and gradient-based optimization. Instead, it leverages Pearson\ncorrelation analysis to quantify the intrinsic visual encoding properties of\nMLLMs, computing a task-specific correlation score to identify high-value\ninstances. This not only enbles data-efficient selection,but maintains the\noriginal performance. Empirical evaluations across multiple MLLMs demonstrate\nthat PRISM reduces the overall time required for visual instruction tuning and\ndata selection to just 30% of conventional methods, while surpassing fully\nfine-tuned models across eight multimodal and three language understanding\nbenchmarks, achieving a 101.7% relative improvement in final performance."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02119",
    "c_title":[
      "Effect of SOI substrate on silicon nitride resistance switching using\n  MIS structure"
    ],
    "c_abstract":[
      "Several resistive memory technologies (RRAMs) are prominent, but few are\nfulfilling the requirements for CMOS integration and meet the commercialization\nstandards. In this work, the fabrication and electrical characterization of a\nfully compatible CMOS process on SOI substrate of 1R silicon SiN-based\nresistance switching (RS) MIS devices is presented. The RS characteristics are\ncompared with the same devices previously fabricated on bulk silicon."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-738",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03282",
    "b_title":[
      "Two-loop helicity amplitudes for diphoton production with massive quark\n  loop"
    ],
    "b_abstract":[
      "We compute two-loop helicity amplitudes in QCD for diphoton production\nthrough quark- and gluon-initiated channels, accounting for a massive internal\nquark loop by keeping its full mass dependence. Using physical projectors, we\ndirectly decompose the amplitude into its helicity components. By renormalising\nthe heavy quark mass in on-shell, and other quantities in $\\overline{\\rm MS}$\nschemes, we obtain finite remainders. This work paves the way for calculating\nthe cross-section for diphoton production at higher orders in QCD with a\nmassive quark loop, employing different subtraction schemes. The effect of a\nheavy quark is expected to play a crucial role in high-luminosity LHC."
    ],
    "b_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13012",
    "c_title":[
      "Towards a Design Guideline for RPA Evaluation: A Survey of Large\n  Language Model-Based Role-Playing Agents"
    ],
    "c_abstract":[
      "Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that\nsimulates human-like behaviors in a variety of tasks. However, evaluating RPAs\nis challenging due to diverse task requirements and agent designs. This paper\nproposes an evidence-based, actionable, and generalizable evaluation design\nguideline for LLM-based RPA by systematically reviewing 1,676 papers published\nbetween Jan. 2021 and Dec. 2024. Our analysis identifies six agent attributes,\nseven task attributes, and seven evaluation metrics from existing literature.\nBased on these findings, we present an RPA evaluation design guideline to help\nresearchers develop more systematic and consistent evaluation methods."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-739",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04706",
    "b_title":[
      "Enhancing Impression Change Prediction in Speed Dating Simulations Based\n  on Speakers' Personalities"
    ],
    "b_abstract":[
      "This paper focuses on simulating text dialogues in which impressions between\nspeakers improve during speed dating. This simulation involves selecting an\nutterance from multiple candidates generated by a text generation model that\nreplicates a specific speaker's utterances, aiming to improve the impression of\nthe speaker. Accurately selecting an utterance that improves the impression is\ncrucial for the simulation. We believe that whether an utterance improves a\ndialogue partner's impression of the speaker may depend on the personalities of\nboth parties. However, recent methods for utterance selection do not consider\nthe impression per utterance or the personalities. To address this, we propose\na method that predicts whether an utterance improves a partner's impression of\nthe speaker, considering the personalities. The evaluation results showed that\npersonalities are useful in predicting impression changes per utterance.\nFurthermore, we conducted a human evaluation of simulated dialogues using our\nmethod. The results showed that it could simulate dialogues more favorably\nreceived than those selected without considering personalities."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16541",
    "c_title":[
      "Experimental demonstration of a scalable room-temperature quantum\n  battery"
    ],
    "c_abstract":[
      "Harnessing quantum phenomena in energy storage systems offers an opportunity\nto introduce a new generation of batteries with quantum-enhanced performance.\nUntil now, the quantum battery has largely remained a theoretical concept, with\nlittle progress towards experimental realisation, due to the challenges in\nquantum coherent control. Here, we experimentally demonstrate a scalable\nroom-temperature quantum battery with a multi-layered organic-microcavity\ndesign. We show that it exhibits superextensive charging, metastabilisation of\nstored energy, and generates superextensive electrical power, the latter an\nunpredicted phenomenon. The combination of these properties in a single device\nis the first demonstration of the full cycle of a quantum battery, laying the\nframework for future designs."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-740",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00693",
    "b_title":[
      "DPBloomfilter: Securing Bloom Filters with Differential Privacy"
    ],
    "b_abstract":[
      "The Bloom filter is a simple yet space-efficient probabilistic data structure\nthat supports membership queries for dramatically large datasets. It is widely\nutilized and implemented across various industrial scenarios, often handling\nmassive datasets that include sensitive user information necessitating privacy\npreservation. To address the challenge of maintaining privacy within the Bloom\nfilter, we have developed the DPBloomfilter. This innovation integrates the\nclassical differential privacy mechanism, specifically the Random Response\ntechnique, into the Bloom filter, offering robust privacy guarantees under the\nsame running complexity as the standard Bloom filter. Through rigorous\nsimulation experiments, we have demonstrated that our DPBloomfilter algorithm\nmaintains high utility while ensuring privacy protections. To the best of our\nknowledge, this is the first work to provide differential privacy guarantees\nfor the Bloom filter for membership query problems."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08158",
    "c_title":[
      "Secondary impact debris in the Didymos system: what could be observed by\n  Hera?"
    ],
    "c_abstract":[
      "We investigate the effects of low--velocity impacts of rocks and boulders,\noriginally released after the DART impact, on the surface of Didymos and the\ndynamics of dust particles released by those impacts. We determine if any of\nthose effects can be observed by the Hera mission. The iSALE-2D shock physics\ncode was used to simulate the re-impacts of boulders on the surface of the\nasteroid. To model the dynamics of the boulders, we used a numerical model that\nincludes the gravity of non-spherical Didymos and Dimorphos, the solar gravity,\nand the radiation pressure. The sesquinary impacts can result in small, shallow\ncraters on the surface of Didymos. For the given low impact speeds, the ejected\nmass depends mostly on the boulder mass. Ejection speeds range from 10 \\% to 80\n\\% of the impact speed. The majority of the ejected dust falls back covering a\nlarge area of the surface, mostly at low\/medium latitudes. Less than 20 \\% of\nthe ejected dust is escaping the system after a few days. The space surrounding\nthe asteroids becomes free from dust after 15-30 days following each sesquinary\nimpact. Results. The sesquinary impacts can result in small, shallow craters on\nthe surface of Didymos. For the given low impact speeds, the ejected mass\ndepends mostly on the boulder mass. Ejection speeds range from 10 \\% to 80 \\%\nof the impact speed. The majority of the ejected dust falls back covering a\nlarge area of the surface, mostly at low and medium latitudes. Less than 20 \\%\nof the ejected dust is escaping the system after a few days. The space\nsurrounding the asteroids becomes free from dust after 15-30 days following\neach sesquinary impact."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-741",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04365",
    "b_title":[
      "AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case\n  Study on Detecting Time of Birth"
    ],
    "b_abstract":[
      "Approximately 10% of newborns need some assistance to start breathing and 5\\%\nproper ventilation. It is crucial that interventions are initiated as soon as\npossible after birth. Accurate documentation of Time of Birth (ToB) is thereby\nessential for documenting and improving newborn resuscitation performance.\nHowever, current clinical practices rely on manual recording of ToB, typically\nwith minute precision. In this study, we present an AI-driven, video-based\nsystem for automated ToB detection using thermal imaging, designed to preserve\nthe privacy of healthcare providers and mothers by avoiding the use of\nidentifiable visual data. Our approach achieves 91.4% precision and 97.4%\nrecall in detecting ToB within thermal video clips during performance\nevaluation. Additionally, our system successfully identifies ToB in 96% of test\ncases with an absolute median deviation of 1 second compared to manual\nannotations. This method offers a reliable solution for improving ToB\ndocumentation and enhancing newborn resuscitation outcomes."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17509",
    "c_title":[
      "The current cratering rate on the regular satellites of Jupiter, Saturn,\n  and Uranus"
    ],
    "c_abstract":[
      "We aim to compute the impact rates for objects with a diameter of 1 km onto\nthe regular satellites of Jupiter, Saturn and Uranus using our latest dynamical\nsimulations of the evolution of outer solar system coupled with the best\nestimates of the current population of objects beyond Neptune and their\nsize-frequency distribution. We use the outcome of the last 3.5~Gyr of\nevolution of the outer solar system from our database of simulations and\ncombine this with observational constraints of the population beyond Neptune to\ncompute the flux of objects entering the Centaur region, with uncertainties.\nThe initial conditions resemble the current population rather than a\nnear-circular, near-planar disc usually assumed just before the onset of giant\nplanet migration. We obtain a better estimate of the impact probability of a\nCentaur with the satellites from enacting simulations of planetesimals flying\npast the satellites on hyperbolic orbits, which agree with literature\nprecedents. We find that our impact rate of objects greater than 1 km in\ndiameter with Jupiter is 0.0012\/yr, which is a factor of 3--6 lower than\nprevious estimates of 0.0044\/yr from Nesvorny et al. (2023) and 0.0075\/yr from\nZahnle et al. (2003). On the other hand our impact probabilities with the\nsatellites scaled to the giant planets are consistent with these earlier\nliterature estimates, as is the leakage rate of objects from beyond Neptune\ninto the Centaur region. However, our absolute impact probabilities with the\ngiant planets are lower. We attribute this to our choice of initial conditions."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-742",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03529",
    "b_title":[
      "Stellar population synthesis models with a physically varying IMF"
    ],
    "b_abstract":[
      "Interpreting galactic luminosity requires assumptions about the galaxy-wide\ninitial mass function (gwIMF), often assumed invariant in most stellar\npopulation synthesis (SPS) models. If stars form in clusters with metallicity-\nand density-dependent \\textit{stellar IMFs}, the integrated galaxy-wide IMF\n(IGIMF) can be calculated, with its shape depending on the star formation rate\n(SFR) and metallicity. The shape of the IGIMF thus depends on the star\nformation rate (SFR) and metallicity. We develop the \\texttt{SPS-VarIMF} code\nwhich enables us for the first time to compute the spectra, luminosities, and\nremnant populations of galaxies in the context of the varying gwIMF with time,\nSFR, and an assumed metallicity. Using the \\texttt{SPS-VarIMF} code one can\ncalculate how the interpretation from the integrated galactic light may change\nif the underlying galaxy-wide IMF is assumed to be environmentally dependent\ninstead of being invariant. In particular, we compare the time evolution of the\ngalaxy color and the stellar mass-to-light ratio in different bands for the\nIGIMF and invariant canonical gwIMF assuming constant and delayed-$\\tau$ star\nformation histories. We show that the underlying gwIMF can be determined by\nexamining the colors and luminosities of late-type galaxies in UV and optical\nbands. On the other hand, for early-type galaxies, it is difficult to\ndistinguish which gwIMF is valid since adopting the different gwIMFs yields\nalmost identical colors. However, their gwIMF-dependent $M\/L$ ratios differ by\nup to an order of magnitude. Massive present-day elliptical galaxies would have\nbeen $10^4$ times as bright as at present when they were forming."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17605",
    "c_title":[
      "Towards Reliable Systems: A Scalable Approach to AXI4 Transaction\n  Monitoring"
    ],
    "c_abstract":[
      "In safety-critical SoC applications such as automotive and aerospace,\nreliable transaction monitoring is crucial for maintaining system integrity.\nThis paper introduces a drop-in Transaction Monitoring Unit (TMU) for AXI4\nsubordinate endpoints that detects transaction failures including protocol\nviolations or timeouts and triggers recovery by resetting the affected\nsubordinates. Two TMU variants address different constraints: a Tiny-Counter\nsolution for tightly area-constrained systems and a Full-Counter solution for\ncritical subordinates in mixed-criticality SoCs. The Tiny-Counter employs a\nsingle counter per outstanding transaction, while the Full-Counter uses\nmultiple counters to track distinct transaction stages, offering finer-grained\nmonitoring and reducing detection latencies by up to hundreds of cycles at\nroughly 2.5x the area cost. The Full-Counter also provides detailed error logs\nfor performance and bottleneck analysis. Evaluations at both IP and system\nlevels confirm the TMU's effectiveness and low overhead. In GF12 technology,\nmonitoring 16-32 outstanding transactions occupies 1330-2616 um2 for the\nTiny-Counter and 3452-6787 um2 for the Full-Counter; moderate prescaler steps\nreduce these figures by 18-39% and 19-32%, respectively, with no loss of\nfunctionality. Results from a full-system integration demonstrate the TMU's\nrobust and precise monitoring capabilities in safety-critical SoC environments."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-743",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08623",
    "b_title":[
      "Dimensional Reduction and K\\\"ahler Metric for Metric Moduli in Imaginary\n  Self-Dual Flux"
    ],
    "b_abstract":[
      "Understanding which effective field theories are consistent with an\nultraviolet completion in quantum gravity is an important theoretical question.\nTherefore, it is important to know the structure of the 4D effective theory\nassociated with a given compactification of string theory. We present a\nfirst-principles derivation of the low-energy 4D effective theory of geometric\nmoduli in a warped Calabi-Yau compactification of type IIB string theory with\nimaginary self-dual 3-form flux. This completes the derivation of the metric on\nK\\\"ahler moduli space from the 10D equations of motion. We also give the first\nderivation of an effective action for flat directions in the complex structure\nmoduli space of the Calabi-Yau (which generically mix with the axiodilaton)."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18366",
    "c_title":[
      "A Subconvex Metaplectic Prime Geodesic Theorem and the Shimura\n  Correspondence"
    ],
    "c_abstract":[
      "We investigate the prime geodesic theorem with an error term dependent on the\nvarying weight and its higher metaplectic coverings in the arithmetic setting,\neach admitting subconvex refinements despite the softness of our input. The\nformer breaks the $\\frac{3}{4}$-barrier due to Hejhal (1983) when the\nmultiplier system is nontrivial, while the latter represents the first\ntheoretical evidence supporting the prevailing consensus on the optimal\nexponent $1+\\varepsilon$ when the multiplier system specialises to the Kubota\ncharacter. Our argument relies on the elegant phenomenon that the main term in\nthe prime geodesic theorem is governed by the size of the largest residual\nLaplace eigenvalue, thereby yielding a simultaneous polynomial power-saving in\nthe error term relative to its Shimura correspondent where the multiplier\nsystem is trivial."
    ],
    "c_categories":[
      [
        "math.NT",
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-744",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07790",
    "b_title":[
      "Sampling from Density power divergence-based Generalized posterior\n  distribution via Stochastic optimization"
    ],
    "b_abstract":[
      "Robust Bayesian inference using density power divergence (DPD) has emerged as\na promising approach for handling outliers in statistical estimation. While the\nDPD-based posterior offers theoretical guarantees for robustness, its practical\nimplementation faces significant computational challenges, particularly for\ngeneral parametric models with intractable integral terms. These challenges\nbecome especially pronounced in high-dimensional settings where traditional\nnumerical integration methods prove inadequate and computationally expensive.\nWe propose a novel sampling methodology that addresses these limitations by\nintegrating the loss-likelihood bootstrap with a stochastic gradient descent\nalgorithm specifically designed for DPD-based estimation. Our approach enables\nefficient and scalable sampling from DPD-based posteriors for a broad class of\nparametric models, including those with intractable integrals, and we further\nextend it to accommodate generalized linear models. Through comprehensive\nsimulation studies, we demonstrate that our method efficiently samples from\nDPD-based posteriors, offering superior computational scalability compared to\nconventional methods, particularly in high-dimensional settings. The results\nalso highlight its ability to handle complex parametric models with intractable\nintegral terms."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03114",
    "c_title":[
      "PromAssistant: Leveraging Large Language Models for Text-to-PromQL"
    ],
    "c_abstract":[
      "With the increasing complexity of modern online service systems,\nunderstanding the state and behavior of the systems is essential for ensuring\ntheir reliability and stability. Therefore, metric monitoring systems are\nwidely used and become an important infrastructure in online service systems.\nEngineers usually interact with metrics data by manually writing\ndomain-specific language (DSL) queries to achieve various analysis objectives.\nHowever, writing these queries can be challenging and time-consuming, as it\nrequires engineers to have high programming skills and understand the context\nof the system. In this paper, we focus on PromQL, which is the metric query DSL\nprovided by the widely used metric monitoring system Prometheus. We aim to\nsimplify metrics querying by enabling engineers to interact with metrics data\nin Prometheus through natural language, and we call this task text-to-PromQL.\nBuilding upon the insight, this paper proposes PromAssistant, a Large Language\nModel-based text-to-PromQL framework. PromAssistant first uses a knowledge\ngraph to describe the complex context of an online service system. Then,\nthrough the synergistic reasoning of LLMs and the knowledge graph,\nPromAssistant transforms engineers' natural language questions into PromQL\nqueries. To evaluate PromAssistant, we manually construct the first\ntext-to-PromQL benchmark dataset which contains 280 metric query questions. The\nexperiment results show that PromAssistant is effective in text-to-PromQL and\noutperforms baseline approaches. To the best of our knowledge, this paper is\nthe first study of text-to-PromQL, and PromAssistant pioneered the DSL\ngeneration framework for metric querying and analysis."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-745",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12705",
    "b_title":[
      "2D Layered Heterojunctions for Photoelectrocatalysis"
    ],
    "b_abstract":[
      "Two-dimensional (2D) layered nanomaterials heterostructures, arising from the\ncombination of 2D materials with other low-dimensional species, feature large\nsurface area to volume ratio, which provides a high density of active sites for\ncatalytic ap-plications and in particular for (photo)electrocatalysis (PEC).\nMeanwhile, their unique electronic band structure and high electrical\nconductivity enable efficient charge transfer (CT) between the active material\nand the substrate, which is essential for catalytic activity. In recent years,\nresearchers have demonstrated the potential of a range of 2D material\ninterfaces, such as graphene, graphitic carbon nitride (g-C3N4), metal\nchalcogenides (MCs), and MXenes, for (photo)electrocatalytic applica-tions. For\ninstance, MCs such as MoS2 and WS2 have shown excellent catalytic activity for\nhydrogen evolution, while gra-phene and MXenes have been used for the reduction\nof carbon dioxide to higher value chemicals. However, despite their great\npotential, there are still major challenges that need to be addressed in order\nto fully realize the potential of 2D materials for PEC. For example, their\nstability under harsh reaction conditions, as well as their scalability for\nlarge-scale production are important factors to be considered. Generating\nheterojunctions (HJs) by combining 2D layered structures with other\nna-nomaterials is a promising method to improve the photoelectrocatalytic\nproperties of the former. In this review, we inspect thoroughly the recent\nliterature, to demonstrate the significant potential that arises from utilizing\n2D layered heterostructures in PEC processes across a broad spectrum of\napplications, from energy conversion and storage to environmental remediation.\nWith the ongoing research and development, it is likely that the potential of\nthese materials will be fully expressed in the near future."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02773",
    "c_title":[
      "Prime Convolutional Model: Breaking the Ground for Theoretical\n  Explainability"
    ],
    "c_abstract":[
      "In this paper, we propose a new theoretical approach to Explainable AI.\nFollowing the Scientific Method, this approach consists in formulating on the\nbasis of empirical evidence, a mathematical model to explain and predict the\nbehaviors of Neural Networks. We apply the method to a case study created in a\ncontrolled environment, which we call Prime Convolutional Model (p-Conv for\nshort). p-Conv operates on a dataset consisting of the first one million\nnatural numbers and is trained to identify the congruence classes modulo a\ngiven integer $m$. Its architecture uses a convolutional-type neural network\nthat contextually processes a sequence of $B$ consecutive numbers to each\ninput. We take an empirical approach and exploit p-Conv to identify the\ncongruence classes of numbers in a validation set using different values for\n$m$ and $B$. The results show that the different behaviors of p-Conv (i.e.,\nwhether it can perform the task or not) can be modeled mathematically in terms\nof $m$ and $B$. The inferred mathematical model reveals interesting patterns\nable to explain when and why p-Conv succeeds in performing task and, if not,\nwhich error pattern it follows."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-746",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14005",
    "b_title":[
      "Device-aware Optical Adversarial Attack for a Portable Projector-camera\n  System"
    ],
    "b_abstract":[
      "Deep-learning-based face recognition (FR) systems are susceptible to\nadversarial examples in both digital and physical domains. Physical attacks\npresent a greater threat to deployed systems as adversaries can easily access\nthe input channel, allowing them to provide malicious inputs to impersonate a\nvictim. This paper addresses the limitations of existing projector-camera-based\nadversarial light attacks in practical FR setups. By incorporating device-aware\nadaptations into the digital attack algorithm, such as resolution-aware and\ncolor-aware adjustments, we mitigate the degradation from digital to physical\ndomains. Experimental validation showcases the efficacy of our proposed\nalgorithm against real and spoof adversaries, achieving high physical\nsimilarity scores in FR models and state-of-the-art commercial systems. On\naverage, there is only a 14% reduction in scores from digital to physical\nattacks, with high attack success rate in both white- and black-box scenarios."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18131",
    "c_title":[
      "An approximate solution of a case of perturbed Fokker-Planck equation"
    ],
    "c_abstract":[
      "This paper focuses on finding an approximate solution of a kind of\nFokker-Planck equation with time-dependent perturbations. A formulation of the\napproximate solution of the equation is constructed, and then the existence of\nthe formulation is proved. The related Hamiltonian dynamical system explains\nthe estimations. Our work provides a more comprehensive understanding of the\nbehaviour of systems described by this Fokker-Planck equation and the\ncorresponding stochastic differential equation."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-747",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06222",
    "b_title":[
      "Vision-based 3D Semantic Scene Completion via Capture Dynamic\n  Representations"
    ],
    "b_abstract":[
      "The vision-based semantic scene completion task aims to predict dense\ngeometric and semantic 3D scene representations from 2D images. However, the\npresence of dynamic objects in the scene seriously affects the accuracy of the\nmodel inferring 3D structures from 2D images. Existing methods simply stack\nmultiple frames of image input to increase dense scene semantic information,\nbut ignore the fact that dynamic objects and non-texture areas violate\nmulti-view consistency and matching reliability. To address these issues, we\npropose a novel method, CDScene: Vision-based Robust Semantic Scene Completion\nvia Capturing Dynamic Representations. First, we leverage a multimodal\nlarge-scale model to extract 2D explicit semantics and align them into 3D\nspace. Second, we exploit the characteristics of monocular and stereo depth to\ndecouple scene information into dynamic and static features. The dynamic\nfeatures contain structural relationships around dynamic objects, and the\nstatic features contain dense contextual spatial information. Finally, we\ndesign a dynamic-static adaptive fusion module to effectively extract and\naggregate complementary features, achieving robust and accurate semantic scene\ncompletion in autonomous driving scenarios. Extensive experimental results on\nthe SemanticKITTI, SSCBench-KITTI360, and SemanticKITTI-C datasets demonstrate\nthe superiority and robustness of CDScene over existing state-of-the-art\nmethods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13066",
    "c_title":[
      "A robust score test in g-computation for covariate adjustment in\n  randomized clinical trials leveraging different variance estimators via\n  influence functions"
    ],
    "c_abstract":[
      "G-computation has become a widely used robust method for estimating\nunconditional (marginal) treatment effects with covariate adjustment in the\nanalysis of randomized clinical trials. Statistical inference in this context\ntypically relies on the Wald test or Wald interval, which can be easily\nimplemented using a consistent variance estimator. However, existing literature\nsuggests that when sample sizes are small or when parameters of interest are\nnear boundary values, Wald-based methods may be less reliable due to type I\nerror rate inflation and insufficient interval coverage. In this article, we\npropose a robust score test for g-computation estimators in the context of\ntwo-sample treatment comparisons. The proposed test is asymptotically valid\nunder simple and stratified (biased-coin) randomization schemes, even when\nregression models are misspecified. These test statistics can be conveniently\ncomputed using existing variance estimators, and the corresponding confidence\nintervals have closed-form expressions, making them convenient to implement.\nThrough extensive simulations, we demonstrate the superior finite-sample\nperformance of the proposed method. Finally, we apply the proposed method to\nreanalyze a completed randomized clinical trial. The new analysis using our\nproposed score test achieves statistical significance, whilst reducing the\nissue of type I error inflation."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-748",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13068",
    "b_title":[
      "Beyond the Lungs: Extending the Field of View in Chest CT with Latent\n  Diffusion Models"
    ],
    "b_abstract":[
      "The interconnection between the human lungs and other organs, such as the\nliver and kidneys, is crucial for understanding the underlying risks and\neffects of lung diseases and improving patient care. However, most research\nchest CT imaging is focused solely on the lungs due to considerations of cost\nand radiation dose. This restricted field of view (FOV) in the acquired images\nposes challenges to comprehensive analysis and hinders the ability to gain\ninsights into the impact of lung diseases on other organs. To address this, we\npropose SCOPE (Spatial Coverage Optimization with Prior Encoding), a novel\napproach to capture the inter-organ relationships from CT images and extend the\nFOV of chest CT images. Our approach first trains a variational autoencoder\n(VAE) to encode 2D axial CT slices individually, then stacks the latent\nrepresentations of the VAE to form a 3D context for training a latent diffusion\nmodel. Once trained, our approach extends the FOV of CT images in the\nz-direction by generating new axial slices in a zero-shot manner. We evaluated\nour approach on the National Lung Screening Trial (NLST) dataset, and results\nsuggest that it effectively extends the FOV to include the liver and kidneys,\nwhich are not completely covered in the original NLST data acquisition.\nQuantitative results on a held-out whole-body dataset demonstrate that the\ngenerated slices exhibit high fidelity with acquired data, achieving an SSIM of\n0.81."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12056",
    "c_title":[
      "Time-resolved spectral diffusion of a multimode mechanical memory"
    ],
    "c_abstract":[
      "High-frequency phonons hold great promise as carriers of quantum information\non-chip and as quantum memories. Due to their coherent interaction with several\nsystems, their compact mode volume and slow group velocity, multiple\nexperiments have recently demonstrated coherent transport of information\non-chip using phonon modes, interconnecting distinct quantum devices. Strongly\nconfined phonons in waveguide-like geometries are particularly interesting\nbecause of their long lifetime. However, spectral diffusion has been observed\nto substantially limit their coherence times. Coupling to two-level systems is\nsuspected to be a major contributor to the diffusion, however, to date, the\norigin and underlying mechanisms are however still not fully understood. Here,\nwe perform a time-domain study on two adjacent mechanical modes (separated by\naround 5 MHz) and show that the frequency positions of the two modes are not\ncorrelated in time, in agreement with our theoretical model and Monte-Carlo\nsimulations. This result is an important step in fully understanding the\nmicroscopic mechanisms of dephasing in mechanical quantum buses and memories."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-749",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11967",
    "b_title":[
      "Floquet topological state induced by light-driven band inversion in SnTe"
    ],
    "b_abstract":[
      "High intensity coherent light can dress matter, realizing new hybrid phases\nthat are not accessible in equilibrium. This effect results from the coherent\ninteraction between Bloch states inside the solid and the periodic field of\nimpinging photons which produces hybrid light-matter states called\nFloquet-Bloch states that can alter properties of the solid. Optically inducing\na topological state in a semiconductor using so-called Floquet engineering is\nan exciting prospect. However, it has not been realized, despite its\ntheoretical prediction more than 10 years ago. Here we show that an\nultrashort-lived topological state that is absent at equilibrium in the ground\nstate of SnTe can be created with femtosecond light pulses. This occurs when\nthe photoexcitation is similar in energy with the band gap of this polar\nsemiconductor. We observe a concomitant renormalization of the band dispersions\nthat reveals the generation of Floquet states connecting to the topological\nstate. We therefore provide the first direct experimental observation of a\nFloquet topological state and propose that it is driven by a light-induced band\ninversion in SnTe. Our discovery opens the way for controlling optically\non-demand the topological properties of semiconductors."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01177",
    "c_title":[
      "Insights from Network Science can advance Deep Graph Learning"
    ],
    "c_abstract":[
      "Deep graph learning and network science both analyze graphs but approach\nsimilar problems from different perspectives. Whereas network science focuses\non models and measures that reveal the organizational principles of complex\nsystems with explicit assumptions, deep graph learning focuses on flexible and\ngeneralizable models that learn patterns in graph data in an automated fashion.\nDespite these differences, both fields share the same goal: to better model and\nunderstand patterns in graph-structured data. Early efforts to integrate\nmethods, models, and measures from network science and deep graph learning\nindicate significant untapped potential. In this position, we explore\nopportunities at their intersection. We discuss open challenges in deep graph\nlearning, including data augmentation, improved evaluation practices,\nhigher-order models, and pooling methods. Likewise, we highlight challenges in\nnetwork science, including scaling to massive graphs, integrating continuous\ngradient-based optimization, and developing standardized benchmarks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-750",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06782",
    "b_title":[
      "The Rainbow Saturation Number of Cycles"
    ],
    "b_abstract":[
      "An edge-coloring of a graph $H$ is a function $\\mathcal{C}: E(H) \\rightarrow\n\\mathbb{N}$. We say that $H$ is rainbow if all edges of $H$ have different\ncolors. Given a graph $F$, an edge-colored graph $G$ is $F$-rainbow saturated\nif $G$ does not contain a rainbow copy of $F$, but the addition of any nonedge\nwith any color on it would create a rainbow copy of $F$. The rainbow saturation\nnumber $rsat(n,F)$ is the minimum number of edges in an $F$-rainbow saturated\ngraph with order $n$. In this paper we proved several results on cycle rainbow\nsaturation. For $n \\geq 5$, we determined the exact value of $rsat(n,C_4)$. For\n$ n \\geq 15$, we proved that $\\frac{3}{2}n-\\frac{5}{2} \\leq rsat(n,C_{5}) \\leq\n2n-6$. For $r \\geq 6$ and $n \\geq r+3$, we showed that $ \\frac{6}{5}n \\leq\nrsat(n,C_r) \\leq 2n+O(r^2)$. Moreover, we establish better lower bound on\n$C_r$-rainbow saturated graph $G$ while $G$ is rainbow."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.03822",
    "c_title":[
      "Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible\n  Training"
    ],
    "c_abstract":[
      "Diffusion policies trained via offline behavioral cloning have recently\ngained traction in robotic motion generation. While effective, these policies\ntypically require a large number of trainable parameters. This model size\naffords powerful representations but also incurs high computational cost during\ntraining. Ideally, it would be beneficial to dynamically adjust the trainable\nportion as needed, balancing representational power with computational\nefficiency. For example, while overparameterization enables diffusion policies\nto capture complex robotic behaviors via offline behavioral cloning, the\nincreased computational demand makes online interactive imitation learning\nimpractical due to longer training time. To address this challenge, we present\na framework, called DRIFT, that uses the Singular Value Decomposition to enable\ndynamic rank adjustment during diffusion policy training. We implement and\ndemonstrate the benefits of this framework in DRIFT-DAgger, an imitation\nlearning algorithm that can seamlessly slide between an offline bootstrapping\nphase and an online interactive phase. We perform extensive experiments to\nbetter understand the proposed framework, and demonstrate that DRIFT-DAgger\nachieves improved sample efficiency and faster training with minimal impact on\nmodel performance."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-751",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15687",
    "b_title":[
      "Joint Cell Selection and Resource Allocation Games with Backhaul\n  Constraints"
    ],
    "b_abstract":[
      "In this work we study the problem of user association and resource allocation\nto maximize the proportional fairness of a wireless network with limited\nbackhaul capacity. The optimal solution of this problem requires solving a\nmixed integer non-linear programming problem which generally cannot be solved\nin real time. We propose instead to model the problem as a potential game,\nwhich decreases dramatically the computational complexity and obtains a user\nassociation and resource allocation close to the optimal solution.\nAdditionally, the use of a game-theoretic approach allows an efficient\ndistribution of the computational burden among the computational resources of\nthe network."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01267",
    "c_title":[
      "Di-$\\pi^0$ Production and Generalized Distribution Amplitudes at Future\n  Electron-Ion Colliders"
    ],
    "c_abstract":[
      "Generalized distribution amplitudes (GDAs) offer valuable insights into the\nthree-dimensional structure of hadrons, delineating the amplitudes associated\nwith the transition from a quark-antiquark pair to a hadron pair. Currently,\nhadron GDAs can be probed in electron-positron collisions, with experimental\nfeasibility demonstrated at facilities such as Belle and BESIII. In this study,\nwe put forth the proposition that hadron GDAs can also be investigated in\nelectron-hadron collisions at forthcoming Electron-Ion Colliders (EICs),\nspecifically through the subprocess $\\gamma^*\\gamma \\to h_1 h_2$. In this\nframework, a quasi-real photon, emitted by the ion, exhibits a photon flux\nproportional to the square of the ion's electric charge. Consequently, we\nanticipate that the cross sections in EICs will be substantially larger than\nthose in electron-positron collisions. We present numerical calculations\npertaining to di-$\\pi^0$ production employing the equivalent photon\napproximation (EPA). Our findings suggest that, within the same kinematic\nregion, electron-proton ($e$-$p$) collisions at the EIC could yield an event\nrate comparable to that of Belle II, while electron-gold ($e$-Au) collisions\nare expected to generate an even greater number of events. This enhanced event\nrate facilitates a high-precision examination of di-$\\pi^0$ GDAs at the EIC."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-752",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09630",
    "b_title":[
      "Chern-Simons gravitational term coupled to an isocurvature field"
    ],
    "b_abstract":[
      "The Chern-Simons gravitational term during inflation is usually coupled to\nthe inflaton field. The resulting theory suffers from ghost-field formation in\nthe tensor sector, which limits the observational effects of P-violation on\ncosmological correlators. In this work, we consider the Chern-Simons term\ncoupled to an isocurvature component in a multi-field model of inflation. Since\nthe resulting theory does not affect the quadratic action of tensor\nperturbations, ghost fields do not appear. This operator provides (P-violating)\ninteractions between the isocurvature perturbation and the curvature and tensor\nperturbations. We show that combining these couplings with interactions between\nthe curvature and isocurvature components coming from a turning trajectory, the\nresulting $\\langle sst \\rangle_{PV}$ non-Gaussianities can reach $f^{sst,\nPV}_{\\rm NL}=B_{PV}^{\\zeta\\zeta h}(k,k,k)\/P^2_{\\zeta}(k)\\sim \\mathcal O(1)$\nwithin the parameter space of the theory. Our result motivates the systematic\nstudy of the Chern-Simons gravitational term coupled to isocurvature fields in\nmulti-field models of inflation with couplings between the curvature and\nisocurvature fields or other mechanisms that transfer effects on the\nisocurvature field into the curvature field."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04735",
    "c_title":[
      "How Personality Traits Shape LLM Risk-Taking Behaviour"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) are increasingly deployed as autonomous agents,\nnecessitating a deeper understanding of their decision-making behaviour under\nrisk. This study investigates the relationship between LLMs' personality traits\nand risk propensity, employing cumulative prospect theory (CPT) and the Big\nFive personality framework. We focus on GPT-4o, comparing its behaviour to\nhuman baselines and earlier models. Our findings reveal that GPT-4o exhibits\nhigher Conscientiousness and Agreeableness traits compared to human averages,\nwhile functioning as a risk-neutral rational agent in prospect selection.\nInterventions on GPT-4o's Big Five traits, particularly Openness, significantly\ninfluence its risk propensity, mirroring patterns observed in human studies.\nNotably, Openness emerges as the most influential factor in GPT-4o's risk\npropensity, aligning with human findings. In contrast, legacy models like\nGPT-4-Turbo demonstrate inconsistent generalization of the personality-risk\nrelationship. This research advances our understanding of LLM behaviour under\nrisk and elucidates the potential and limitations of personality-based\ninterventions in shaping LLM decision-making. Our findings have implications\nfor the development of more robust and predictable AI systems such as financial\nmodelling."
    ],
    "c_categories":[
      [
        "cs.CY",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-753",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18719",
    "b_title":[
      "Enhancing Subject-Independent Accuracy in fNIRS-based Brain-Computer\n  Interfaces with Optimized Channel Selection"
    ],
    "b_abstract":[
      "Achieving high subject-independent accuracy in functional near-infrared\nspectroscopy (fNIRS)-based brain-computer interfaces (BCIs) remains a\nchallenge, particularly when minimizing the number of channels. This study\nproposes a novel feature extraction scheme and a Pearson correlation-based\nchannel selection algorithm to enhance classification accuracy while reducing\nhardware complexity. Using an open-access fNIRS dataset, our method improved\naverage accuracy by 28.09% compared to existing approaches, achieving a peak\nsubject-independent accuracy of 95.98% with only two channels. These results\ndemonstrate the potential of our optimized feature extraction and channel\nselection methods for developing efficient, subject-independent fNIRS-based BCI\nsystems."
    ],
    "b_categories":[
      [
        "cs.HC",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09555",
    "c_title":[
      "Incorporating Backreaction in One-Loop Corrections in Ultra-Slow-Roll\n  Inflation"
    ],
    "c_abstract":[
      "We investigate the one-loop quantum correction to the power spectrum of\nprimordial curvature perturbations in the ultra-slow-roll (USR) inflationary\nscenario, incorporating the backreaction effect from curvature perturbations.\nIn the spatially-flat gauge, we expand the background inflaton field up to\nsecond order and identify the one-loop level backreaction term in the action.\nUtilizing a gauge transformation, we derive the comoving curvature interaction\nHamiltonian in the presence of the backreaction term and calculate the one-loop\ncorrection using the in-in formalism. Our results reveal that the one-loop\nsuper-horizon corrections previously reported in the literature are canceled by\nthe backreaction contributions. This finding underscores the importance of\naccounting for the backreaction effects in the analysis of quantum corrections\nduring USR inflation."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-754",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09580",
    "b_title":[
      "An Intermediate-mass Black Hole Lurking in A Galactic Halo Caught Alive\n  during Outburst"
    ],
    "b_abstract":[
      "Stellar-mass and supermassive black holes abound in the Universe, whereas\nintermediate-mass black holes (IMBHs) of ~10^2-10^5 solar masses in between are\nlargely missing observationally, with few cases found only. Here we report the\nreal-time discovery of a long-duration X-ray transient, EP240222a, accompanied\nby an optical flare with prominent H and He emission lines revealed by prompt\nfollow-up observations. Its observed properties evidence an IMBH located\nunambiguously in the halo of a nearby galaxy and flaring by tidally disrupting\na star -- the only confirmed off-nucleus IMBH-tidal disruption event so far.\nThis work demonstrates the potential of sensitive time-domain X-ray surveys,\ncomplemented by timely multi-wavelength follow-ups, in probing IMBHs, their\nenvironments, demographics, origins and connections to stellar-mass and\nsupermassive black holes."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07564",
    "c_title":[
      "An Elliptic Curve Based Solution to the Perspective-Three-Point Problem"
    ],
    "c_abstract":[
      "The Perspective-Three-Point Problem (P3P) is solved by first focusing on\ndetermining the directions of the lines through pairs of control points,\nrelative to the camera, rather than the distances from the camera to the\ncontrol points. The analysis of this produces an efficient, accurate and\nreasonably simple P3P solver, which is compared with a state-of-the-art P3P\nsolver, \"Lambda Twist.\" Both methods depend on the accurate computation of a\nsingle root of a cubic polynomial. They have been implemented and tested for a\nwide range of control-point triangles, and under certain reasonable\nrestrictions, the new method is noticably more accurate than Lambda Twist,\nthough it is slower. However, the principal value of the present work is not in\nintroducing yet another P3P solver, but lies rather in the discovery of an\nintimate connection between the P3P problem and a special family of elliptic\ncurves that includes curves utilized in cryptography. This holds the potential\nfor further advances in a number of directions. To make this connection, an\ninteresting spherical analogue of an ancient \"sliding\" problem is stated and\nsolved."
    ],
    "c_categories":[
      [
        "cs.CV",
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-755",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03661",
    "b_title":[
      "A k-Hessian equation with a power nonlinearity source and\n  self-similarity"
    ],
    "b_abstract":[
      "We study existence and uniqueness of spherically symmetric solutions of\nS_k(D^2v)+beta xi\\cdot\\nabla v+\\alpha v+\\abs{v}^{q-1}v=0 in R^n, where\n\\alpha,\\beta are real parameters, n>2,\\, q>k\\geq 1 and S_k(D^2v) stands for the\nk-Hessian operator of v. Our results are based mainly on the analysis of an\nassociated dynamical system and energy methods. We derive some properties of\nthe solutions of the above equation for different ranges of the parameters\n\\alpha and \\beta. In particular, we describe with precision its asymptotic\nbehavior at infinity. Further, according to the position of q with respect to\nthe first critical exponent \\frac{(n+2)k}{n} and the Tso critical exponent\n\\frac{(n+2)k}{n-2k} we study the existence of three classes of solutions:\ncrossing, slow decay or fast decay solutions. In particular, if k>1 all the\nfast decay solutions have a compact support in R^n. The results also apply to\nconstruct self-similar solutions of type I to a related nonlinear evolution\nequation. These are self-similar functions of the form\nu(t,x)=t^{-\\alpha}v(xt^{-\\beta}) with suitable \\alpha and \\beta."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.11442",
    "c_title":[
      "Controllable Antiferromagnetic-Ferromagnetic phase transition in\n  monolayer MnPSe3 via atomic adsorption of Li, O, and F"
    ],
    "c_abstract":[
      "The engineering of magnetic order and electronic states in two-dimensional\n(2D) materials is pivotal for advanced spintronic technologies. Despite their\npotential, the scarcity of intrinsic 2D ferromagnets remains a critical\nchallenge. Here, we employ density functional theory with Hubbard-U corrections\nto systematically investigate adsorbate-driven magnetic transitions in\nmonolayer MnPSe3. While pristine MnPSe3 exhibits antiferromagnetic (AFM)\nordering with a semiconducting gap, Li, O, and F adatom adsorption induces an\nAFM-to-ferromagnetic (AFM-FM) phase transition across large coverage ranges.\nOur calculations reveal enhanced thermodynamic stability at elevated coverages,\nwith full-coverage configurations (Li0.5MnPSe3, MnPSe3O0.5, MnPSe3F0.5) favored\nenergetically. Hybrid functional (HSE06) calculations show that F adsorption\ndrives a semiconductor-to-half-metal transition, whereas Li and O adsorption\npreserves semiconductivity. Moreover, Li adsorption induces a valley splitting\nof 20.3 meV at the K1 and K2 points in the band structure of the monolayer\nMnPSe3. Magnetic anisotropy analysis reveals adsorbate-dependent easy-axis\nreorientation: Li (electron doping) switches the easy-axis from in-plane to\nout-of-plane, while O\/F (hole doping) stabilizes in-plane easy-axis, consistent\nwith carrier-density-modulation simulations. Crucially, carrier doping results\nindicate that once the electron doping concentration reaches critical\nconcentration, the magnetic easy axis of monolayer MnPSe3 transitions from\nin-plane to out-of-plane. This work establishes atomic adsorption as a robust\nstrategy for tailoring 2D magnetism, resolving discrepancies through rigorous\ntreatment of exchange-correlation effects and configurational diversity."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-756",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18244",
    "b_title":[
      "CustomKD: Customizing Large Vision Foundation for Edge Model Improvement\n  via Knowledge Distillation"
    ],
    "b_abstract":[
      "We propose a novel knowledge distillation approach, CustomKD, that\neffectively leverages large vision foundation models (LVFMs) to enhance the\nperformance of edge models (e.g., MobileNetV3). Despite recent advancements in\nLVFMs, such as DINOv2 and CLIP, their potential in knowledge distillation for\nenhancing edge models remains underexplored. While knowledge distillation is a\npromising approach for improving the performance of edge models, the\ndiscrepancy in model capacities and heterogeneous architectures between LVFMs\nand edge models poses a significant challenge. Our observation indicates that\nalthough utilizing larger backbones (e.g., ViT-S to ViT-L) in teacher models\nimproves their downstream task performances, the knowledge distillation from\nthe large teacher models fails to bring as much performance gain for student\nmodels as for teacher models due to the large model discrepancy. Our simple yet\neffective CustomKD customizes the well-generalized features inherent in LVFMs\nto a given student model in order to reduce model discrepancies. Specifically,\nbeyond providing well-generalized original knowledge from teachers, CustomKD\naligns the features of teachers to those of students, making it easy for\nstudents to understand and overcome the large model discrepancy overall.\nCustomKD significantly improves the performances of edge models in scenarios\nwith unlabeled data such as unsupervised domain adaptation (e.g., OfficeHome\nand DomainNet) and semi-supervised learning (e.g., CIFAR-100 with 400 labeled\nsamples and ImageNet with 1% labeled samples), achieving the new\nstate-of-the-art performances."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13024",
    "c_title":[
      "Euclidean AdS wormholes and gravitational instantons in the\n  Einstein-Skyrme theory"
    ],
    "c_abstract":[
      "Euclidean AdS wormholes provide a natural setup for studying the AdS\/CFT\ncorrespondence with multiple boundaries. However, from a bottom-up perspective,\nthey cannot be embedded in the four-dimensional Einstein-AdS-Maxwell theory if\nthese boundaries have positive curvature. Nevertheless, Maldacena and Maoz\nshowed that this obstruction could be circumvented by introducing merons in the\nfour-dimensional Einstein-AdS-Yang-Mills theory. In this work, we show that\nEuclidean-AdS wormholes also exist in the four-dimensional Einstein-AdS-Skyrme\ntheory, whose matter sector possesses a nontrivial baryonic charge. We compute\nits free energy and show that it does not depend on the integration constants\nwhatsoever, resembling topological solitons. Additionally, we obtain its\nholographic stress tensor and show that it vanishes, allowing us to interpret\nthis configuration as a holographic Bogomol'nyi-Prasad-Sommerfield (BPS) state.\nOther topologically nontrivial ground states in Einstein-Skyrme theory are\nfound, such as gravitational instantons, representing the homotopically\ninequivalent vacua of the theory. We find that they develop Hawking-Page phase\ntransitions above a critical temperature. Some of these solutions are periodic\nin Euclidean time, representing the gravitational analog of calorons in\nYang-Mills theory."
    ],
    "c_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-757",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01425",
    "b_title":[
      "The Batch Complexity of Bandit Pure Exploration"
    ],
    "b_abstract":[
      "In a fixed-confidence pure exploration problem in stochastic multi-armed\nbandits, an algorithm iteratively samples arms and should stop as early as\npossible and return the correct answer to a query about the arms distributions.\nWe are interested in batched methods, which change their sampling behaviour\nonly a few times, between batches of observations. We give an\ninstance-dependent lower bound on the number of batches used by any sample\nefficient algorithm for any pure exploration task. We then give a general\nbatched algorithm and prove upper bounds on its expected sample complexity and\nbatch complexity. We illustrate both lower and upper bounds on best-arm\nidentification and thresholding bandits."
    ],
    "b_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03813",
    "c_title":[
      "EDGE: The emergence of dwarf galaxy scaling relations from cosmological\n  radiation-hydrodynamics simulations"
    ],
    "c_abstract":[
      "We present a new suite of EDGE (`Engineering Dwarfs at Galaxy formation's\nEdge') cosmological zoom simulations. The suite includes 15\nradiation-hydrodynamical dwarf galaxies covering the ultra-faint to the dwarf\nirregular regime ($10^4 \\leq M_{\\star}(z=0) \\leq 10^8 \\, M_{\\odot}$) to enable\ncomparisons with observed scaling relations. Each object in the suite is\nevolved at high resolution ($\\approx 3 \\, \\text{pc}$) and includes stellar\nradiation, winds and supernova feedback channels. We compare with previous EDGE\nsimulations without radiation, finding that radiative feedback results in\nsignificantly weaker galactic outflows. This generalises our previous findings\nto a wide mass range, and reveals that the effect is most significant at low\n$M_{\\star}$. Despite this difference, stellar masses stay within a factor of\ntwo of each other, and key scaling relations of dwarf galaxies (size-mass,\nneutral gas-stellar mass, gas-phase mass-metallicity) emerge correctly in both\nsimulation suites. Only the stellar mass -- stellar metallicity relation is\nstrongly sensitive to the change in feedback. This highlights how obtaining\nstatistical samples of dwarf galaxy stellar abundances with next-generation\nspectrographs will be key to probing and constraining the baryon cycle of dwarf\ngalaxies."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-758",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04459",
    "b_title":[
      "Rapid Automated Mapping of Clouds on Titan With Instance Segmentation"
    ],
    "b_abstract":[
      "Despite widespread adoption of deep learning models to address a variety of\ncomputer vision tasks, planetary science has yet to see extensive utilization\nof such tools to address its unique problems. On Titan, the largest moon of\nSaturn, tracking seasonal trends and weather patterns of clouds provides\ncrucial insights into one of the most complex climates in the Solar System, yet\nmuch of the available image data are still analyzed in a conventional way. In\nthis work, we apply a Mask R-CNN trained via transfer learning to perform\ninstance segmentation of clouds in Titan images acquired by the Cassini\nspacecraft - a previously unexplored approach to a big data problem in\nplanetary science. We demonstrate that an automated technique can provide\nquantitative measures for clouds, such as areas and centroids, that may\notherwise be prohibitively time-intensive to produce by human mapping.\nFurthermore, despite Titan specific challenges, our approach yields accuracy\ncomparable to contemporary cloud identification studies on Earth and other\nworlds. We compare the efficiencies of human-driven versus algorithmic\napproaches, showing that transfer learning provides speed-ups that may open new\nhorizons for data investigation for Titan. Moreover, we suggest that such\napproaches have broad potential for application to similar problems in\nplanetary science where they are currently under-utilized. Future planned\nmissions to the planets and remote sensing initiatives for the Earth promise to\nprovide a deluge of image data in the coming years that will benefit strongly\nfrom leveraging machine learning approaches to perform the analysis."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13583",
    "c_title":[
      "Effect Size-Driven Pathway Meta-Analysis for Gene Expression Data"
    ],
    "c_abstract":[
      "The proliferation of omics datasets in public repositories has created\nunprecedented opportunities for biomedical research but has also posed\nsignificant challenges for their integration, particularly due to missing genes\nand platform-specific discrepancies. Traditional gene expression metaanalysis\noften focuses on individual genes, leading to data loss and limited biological\ninsights when there are missing genes across different studies. To address\nthese limitations, we propose GSEMA (Gene Set Enrichment Meta-Analysis), a\nnovel methodology that leverages singlesample enrichment scoring to aggregate\ngene expression data into pathway-level matrices. By applying meta-analysis\ntechniques to enrichment scores, GSEMA preserves the magnitude and\ndirectionality of effects, enabling the definition of pathway activity across\ndatasets. Using simulated data and case studies on Systemic Lupus Erythematosus\n(SLE) and Parkinson's Disease (PD), we demonstrate that GSEMA outperforms other\nmethods in controlling false positive rates while providing meaningful\nbiological interpretations. GSEMA methodology is implemented as an R package\navailable on CRAN repository"
    ],
    "c_categories":[
      [
        "q-bio.GN",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-759",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17085",
    "b_title":[
      "Deterministic AI Agent Personality Expression through Standard\n  Psychological Diagnostics"
    ],
    "b_abstract":[
      "Artificial intelligence (AI) systems powered by large language models have\nbecome increasingly prevalent in modern society, enabling a wide range of\napplications through natural language interaction. As AI agents proliferate in\nour daily lives, their generic and uniform expressiveness presents a\nsignificant limitation to their appeal and adoption. Personality expression\nrepresents a key prerequisite for creating more human-like and distinctive AI\nsystems. We show that AI models can express deterministic and consistent\npersonalities when instructed using established psychological frameworks, with\nvarying degrees of accuracy depending on model capabilities. We find that more\nadvanced models like GPT-4o and o1 demonstrate the highest accuracy in\nexpressing specified personalities across both Big Five and Myers-Briggs\nassessments, and further analysis suggests that personality expression emerges\nfrom a combination of intelligence and reasoning capabilities. Our results\nreveal that personality expression operates through holistic reasoning rather\nthan question-by-question optimization, with response-scale metrics showing\nhigher variance than test-scale metrics. Furthermore, we find that model\nfine-tuning affects communication style independently of personality expression\naccuracy. These findings establish a foundation for creating AI agents with\ndiverse and consistent personalities, which could significantly enhance\nhuman-AI interaction across applications from education to healthcare, while\nadditionally enabling a broader range of more unique AI agents. The ability to\nquantitatively assess and implement personality expression in AI systems opens\nnew avenues for research into more relatable, trustworthy, and ethically\ndesigned AI."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09854",
    "c_title":[
      "Chasing the Light: Shadowing, Collimation, and the Super-Eddington\n  Growth of Infant Black Holes in JWST-Discovered AGNs"
    ],
    "c_abstract":[
      "Observations with the James Webb Space Telescope (JWST) have uncovered a\nsubstantial population of high-redshift broad-line active galactic nuclei\n(AGNs) characterized by moderate luminosities, weak X-ray emissions, and faint\nhigh-ionization lines, challenging conventional models of black hole growth and\nAGN activity. In this study, we propose that these sources are accreting at\nsuper-Eddington rates and use geometrically thick, non-advective disk models to\ninvestigate the critical roles of photon scattering, reflections, and shadowing\nwithin funnel-like structures along the disk's rotation axis. Our models\npredict highly collimated radiation fields, with isotropic-equivalent\nluminosities vastly exceeding the Eddington limit in polar directions, and\nsignificant suppression of emission at higher inclination angles due to\nshadowing. These effects result in altered spectral energy distributions and\npronounced anisotropies in observable properties. Key features include\nultra-blue UV continuum slopes (alpha=+0.5 to +0.8), bolometric correction\nfactors varying by over an order of magnitude with orientation, and suppressed\ncoronal X-ray emissions. The anisotropy and shadowing effects may also explain\nthe observed faintness of broad high-ionization emission lines, as the viewing\nangle strongly modulates both continuum brightness and the illumination of the\nbroad-line region. These findings indicate that super-Eddington accretion\nflows, shaped by thick disk geometries and anisotropic radiation fields, can\nnaturally account for many puzzling features of JWST-discovered AGNs and\nprovide new insights into black hole growth in the early universe."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-760",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01550",
    "b_title":[
      "Dynamic realization of emergent high-dimensional optical vortices"
    ],
    "b_abstract":[
      "The dimensionality of vortical structures has recently been extended beyond\ntwo dimensions, providing higher-order topological characteristics and\nrobustness for high-capacity information processing and turbulence control. The\ngeneration of high-dimensional vortical structures has mostly been demonstrated\nin classical systems through the complex interference of fluidic, acoustic, or\nelectromagnetic waves. However, natural materials rarely support three- or\nhigher-dimensional vortical structures and their physical interactions. Here,\nwe present a high-dimensional gradient thickness optical cavity (GTOC) in which\nthe optical coupling of planar metal-dielectric multilayers implements\ntopological interactions across multiple dimensions. Topological interactions\nin high-dimensional GTOC construct non-trivial topological phases, which induce\nhigh-dimensional vortical structures in generalized parameter space in three,\nfour dimensions, and beyond. These emergent high-dimensional vortical\nstructures are observed under electro-optic tomography as optical vortex\ndynamics in two-dimensional real-space, employing the optical thicknesses of\nthe dielectric layers as synthetic dimensions. We experimentally demonstrate\nemergent vortical structures, optical vortex lines and vortex rings, in a\nthree-dimensional generalized parameter space and their topological\ntransitions. Furthermore, we explore four-dimensional vortical structures,\ntermed optical vortex sheets, which provide the programmability of real-space\noptical vortex dynamics. Our findings hold significant promise for emulating\nhigh-dimensional physics and developing active topological photonic devices."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14368",
    "c_title":[
      "Langevin model for soliton molecules in ultrafast fiber ring laser\n  cavity: investigating experimentally the interplay between noise and inertia"
    ],
    "c_abstract":[
      "The dynamics of soliton molecules in ultrafast fiber ring laser cavity is\nstrongly influenced by noise. We show how a parsimonious Langevin model can be\nconstructed from experimental data, resulting in a mathematical description\nthat encompasses both the deterministic and stochastic properties of the\nevolution of the soliton molecules. In particular, we were able to probe the\nresponse dynamics of the soliton molecule to an external kick in a sub-critical\napproach, namely without the need to actually disturb the systems under\ninvestigation. Moreover, the noise experienced by the dissipative solitonic\nsystem, including its distribution and correlation, can now be also analyzed in\ndetails. Our strategy can be applied to any systems where the individual motion\nof its constitutive particles can be traced; the case of optical\nsolitonic-system laser presented here serving as a proof-of-principle\ndemonstration."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-761",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12040",
    "b_title":[
      "On the distribution of $t$-hooks of doubled distinct partitions"
    ],
    "b_abstract":[
      "Recently, Griffin, Ono, and Tsai examined the distribution of the number of\n$t$-hooks in partitions of $n$, which was later followed by the work of Craig,\nOno, and Singh on the distribution of the number of $t$-hooks in self-conjugate\npartitions of $n$. Motivated by these studies, in this paper, we further\ninvestigate the number of $t$-hooks in some subsets of partitions. More\nspecifically, we obtain the generating functions for the number of $t$-hooks in\ndoubled distinct partitions and the number of $t$-shifted hooks in strict\npartitions. Based on these generating functions, we prove that the number of\n$t$-hooks in doubled distinct partitions and the number of $t$-shifted hooks in\nstrict partitions are both asymptotically normally distributed."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01673",
    "c_title":[
      "Nonuniform superconducting states caused by odd-frequency Cooper pairs"
    ],
    "c_abstract":[
      "We discuss the origin of a nonuniform superconducting state in which Cooper\npairs have a finite center of mass momentum. The instability to such a\nnonuniform superconducting state is analyzed by a pole of the pair fluctuation\npropagator for weak coupling superconductors. The results show that\nodd(even)-frequency Cooper pairs stabilize a nonuniform (uniform)\nsuperconducting phase below the transition temperature. We provide a\ntheoretical framework that explains the reasons for appearing the nonuniform\nsuperconducting states."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-762",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12987",
    "b_title":[
      "Solving unbounded optimal control problems with the moment-SOS hierarchy\n  *"
    ],
    "b_abstract":[
      "The behaviour of the moment-sums-of-squares (moment-SOS) hierarchy for\npolynomial optimal control problems on compact sets has been explored to a\nlarge extent. Our contribution focuses on the case of non-compact control sets.\nWe describe a new approach to optimal control problems with unbounded controls,\nusing compactification by partial homogenization, leading to an equivalent\ninfinite dimensional linear program with compactly supported measures. Our\nresults are closely related to the results of a previous approach using\nDiPerna-Majda measures. However, our work provides a sound proof of the absence\nof relaxation gap, which was conjectured in the previous work, and thereby\nenables the design of a moment-sum-of-squares relaxation with guaranteed\nconvergence."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11730",
    "c_title":[
      "Transformer Vibration Forecasting for Advancing Rail Safety and\n  Maintenance 4.0"
    ],
    "c_abstract":[
      "Maintaining railway axles is critical to preventing severe accidents and\nfinancial losses. The railway industry is increasingly interested in advanced\ncondition monitoring techniques to enhance safety and efficiency, moving beyond\ntraditional periodic inspections toward Maintenance 4.0.\n  This study introduces a robust Deep Autoregressive solution that integrates\nseamlessly with existing systems to avert mechanical failures. Our approach\nsimulates and predicts vibration signals under various conditions and fault\nscenarios, improving dataset robustness for more effective detection systems.\nThese systems can alert maintenance needs, preventing accidents preemptively.\nWe use experimental vibration signals from accelerometers on train axles.\n  Our primary contributions include a transformer model, ShaftFormer, designed\nfor processing time series data, and an alternative model incorporating\nspectral methods and enhanced observation models. Simulating vibration signals\nunder diverse conditions mitigates the high cost of obtaining experimental\nsignals for all scenarios. Given the non-stationary nature of railway vibration\nsignals, influenced by speed and load changes, our models address these\ncomplexities, offering a powerful tool for predictive maintenance in the rail\nindustry."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-763",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13481",
    "b_title":[
      "LLM4Tag: Automatic Tagging System for Information Retrieval via Large\n  Language Models"
    ],
    "b_abstract":[
      "Tagging systems play an essential role in various information retrieval\napplications such as search engines and recommender systems. Recently, Large\nLanguage Models (LLMs) have been applied in tagging systems due to their\nextensive world knowledge, semantic understanding, and reasoning capabilities.\nDespite achieving remarkable performance, existing methods still have\nlimitations, including difficulties in retrieving relevant candidate tags\ncomprehensively, challenges in adapting to emerging domain-specific knowledge,\nand the lack of reliable tag confidence quantification. To address these three\nlimitations above, we propose an automatic tagging system LLM4Tag. First, a\ngraph-based tag recall module is designed to effectively and comprehensively\nconstruct a small-scale highly relevant candidate tag set. Subsequently, a\nknowledge-enhanced tag generation module is employed to generate accurate tags\nwith long-term and short-term knowledge injection. Finally, a tag confidence\ncalibration module is introduced to generate reliable tag confidence scores.\nExtensive experiments over three large-scale industrial datasets show that\nLLM4Tag significantly outperforms the state-of-the-art baselines and LLM4Tag\nhas been deployed online for content tagging to serve hundreds of millions of\nusers."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07043",
    "c_title":[
      "From trees to traits: A review of advances in PhyloG2P methods and\n  future directions"
    ],
    "c_abstract":[
      "Mapping genotypes to phenotypes (G2P) is a fundamental goal in biology. So\ncalled PhyloG2P methods are a relatively new set of tools that leverage\nreplicated evolution in phylogenetically independent lineages to identify\ngenomic regions associated with traits of interest. Here, we review recent\ndevelopments in PhyloG2P methods, focusing on three key areas: methods based on\nreplicated amino acid substitutions, methods detecting changes in evolutionary\nrates, and methods analysing gene duplication and loss. We discuss how the\ndefinition and measurement of traits impacts the utility of these methods,\narguing that focusing on simple rather than compound traits will lead to more\nmeaningful genotype-phenotype associations. We advocate for the use of methods\nthat work with continuous traits directly rather than collapsing them to binary\nrepresentations. We examine the strengths and limitations of different\napproaches to modeling genetic replication, highlighting the importance of\nexplicit modeling of evolutionary processes. Finally, we outline promising\nfuture directions, including the integration of population-level variation, as\nwell as epigenetic and environmental information. No one method is likely to\nidentify all genomic regions of interest, so we encourage users to apply\nmultiple methods that are capable of detecting a wide range of associations.\nThe overall aim of this review is to provide practitioners a roadmap for\nunderstanding and applying PhyloG2P methods."
    ],
    "c_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-764",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21288",
    "b_title":[
      "The Grothendieck construction for delta lenses"
    ],
    "b_abstract":[
      "Delta lenses are functors equipped with a functorial choice of lifts,\ngeneralising the notion of split opfibration. In this paper, we introduce a\nGrothendieck construction (or category of elements) for delta lenses, thus\ndemonstrating a correspondence between delta lenses and certain lax double\nfunctors into the double category of sets, functions, and split multivalued\nfunctions. We show that the double category of split multivalued functions\nadmits a universal property as a certain kind of limit, and inherits many nice\nproperties from the double category of spans. Applications of this construction\nto the theory of delta lenses are explored in detail."
    ],
    "b_categories":[
      [
        "math.CT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.09865",
    "c_title":[
      "Identification and Classification of Human Performance related\n  Challenges during Remote Driving"
    ],
    "c_abstract":[
      "Remote driving of vehicles is gaining in importance in the transportation\nsector, especially when Automated Driving Systems (ADSs) reach the limits of\ntheir system boundaries. This study investigates the challenges faced by human\nRemote Drivers (RDs) during remote driving, particularly focusing on the\nidentification and classification of human performance-related challenges\nthrough a comprehensive analysis of real-world remote driving data Las Vegas.\nFor this purpose, a total of 183 RD performance-related Safety Driver (SD)\ninterventions were analyzed and classified using an introduced severity\nclassification. As it is essential to prevent the need for SD interventions,\nthis study identified and analyzed harsh driving events to detect an increased\nlikelihood of interventions by the SD. In addition, the results of the\nsubjective RD questionnaire are used to evaluate whether the objective metrics\nfrom SD interventions and harsh driving events can also be confirmed by the RDs\nand whether additional challenges can be uncovered. The analysis reveals\nlearning curves, showing a significant decrease in SD interventions as RD\nexperience increases. Early phases of remote driving experience, especially\nbelow 200 km of experience, showed the highest frequency of safety-related\nevents, including braking late for traffic signs and responding impatiently to\nother traffic participants. Over time, RDs follow defined rules for improving\ntheir control, with experience leading to less harsh braking, acceleration, and\nsteering maneuvers. The study contributes to understanding the requirements of\nRDS, emphasizing the importance of targeted training to address human\nperformance limitations. It further highlights the need for system improvements\nto address challenges like latency and the limited haptic feedback replaced by\nvisual feedback, which affect the RDs' perception and vehicle control."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-765",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08671",
    "b_title":[
      "Color Universal Design Neural Network for the Color Vision Deficiencies"
    ],
    "b_abstract":[
      "Information regarding images should be visually understood by anyone,\nincluding those with color deficiency. However, such information is not\nrecognizable if the color that seems to be distorted to the color deficiencies\nmeets an adjacent object. The aim of this paper is to propose a color universal\ndesign network, called CUD-Net, that generates images that are visually\nunderstandable by individuals with color deficiency. CUD-Net is a convolutional\ndeep neural network that can preserve color and distinguish colors for input\nimages by regressing the node point of a piecewise linear function and using a\nspecific filter for each image. To generate CUD images for color deficiencies,\nwe follow a four-step process. First, we refine the CUD dataset based on\nspecific criteria by color experts. Second, we expand the input image\ninformation through pre-processing that is specialized for color deficiency\nvision. Third, we employ a multi-modality fusion architecture to combine\nfeatures and process the expanded images. Finally, we propose a conjugate loss\nfunction based on the composition of the predicted image through the model to\naddress one-to-many problems that arise from the dataset. Our approach is able\nto produce high-quality CUD images that maintain color and contrast stability.\nThe code for CUD-Net is available on the GitHub repository"
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14069",
    "c_title":[
      "Finite sample bounds for barycenter estimation in geodesic spaces"
    ],
    "c_abstract":[
      "We study the problem of estimating the barycenter of a distribution given\ni.i.d. data in a geodesic space. Assuming an upper curvature bound in\nAlexandrov's sense and a support condition ensuring the strong geodesic\nconvexity of the barycenter problem, we establish finite-sample error bounds in\nexpectation and with high probability. Our results generalize Hoeffding- and\nBernstein-type concentration inequalities from Euclidean to geodesic spaces.\nBuilding on these concentration inequalities, we derive statistical guarantees\nfor two efficient algorithms for the computation of barycenters."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-766",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08234",
    "b_title":[
      "Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement\n  Learning"
    ],
    "b_abstract":[
      "This paper addresses a critical challenge in the high-speed passenger railway\nindustry: designing effective dynamic pricing strategies in the context of\ncompeting and cooperating operators. To address this, a multi-agent\nreinforcement learning (MARL) framework based on a non-zero-sum Markov game is\nproposed, incorporating random utility models to capture passenger decision\nmaking. Unlike prior studies in areas such as energy, airlines, and mobile\nnetworks, dynamic pricing for railway systems using deep reinforcement learning\nhas received limited attention. A key contribution of this paper is a\nparametrisable and versatile reinforcement learning simulator designed to model\na variety of railway network configurations and demand patterns while enabling\nrealistic, microscopic modelling of user behaviour, called RailPricing-RL. This\nenvironment supports the proposed MARL framework, which models heterogeneous\nagents competing to maximise individual profits while fostering cooperative\nbehaviour to synchronise connecting services. Experimental results validate the\nframework, demonstrating how user preferences affect MARL performance and how\npricing policies influence passenger choices, utility, and overall system\ndynamics. This study provides a foundation for advancing dynamic pricing\nstrategies in railway systems, aligning profitability with system-wide\nefficiency, and supporting future research on optimising pricing policies."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13754",
    "c_title":[
      "Large Deviations in Switching Diffusion: from Free Cumulants to\n  Dynamical Transitions"
    ],
    "c_abstract":[
      "We study the diffusion of a particle with a time-dependent diffusion constant\n$D(t)$ that switches between random values drawn from a distribution $W(D)$ at\na fixed rate $r$. Using a renewal approach, we compute exactly the moments of\nthe position of the particle $\\langle x^{2n}(t) \\rangle$ at any finite time\n$t$, and for any $W(D)$ with finite moments $\\langle D^n \\rangle$. For $t \\gg\n1$, we demonstrate that the cumulants $\\langle x^{2n}(t) \\rangle_c$ grow\nlinearly with $t$ and are proportional to the free cumulants of a random\nvariable distributed according to $W(D)$. For specific forms of $W(D)$, we\ncompute the large deviations of the position of the particle, uncovering rich\nbehaviors and dynamical transitions of the rate function $I(y=x\/t)$. Our\nanalytical predictions are validated numerically with high precision, achieving\naccuracy up to $10^{-2000}$."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "math-ph",
        "math.MP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-767",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07856",
    "b_title":[
      "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE\n  Solvers"
    ],
    "b_abstract":[
      "In applications of diffusion models, controllable generation is of practical\nsignificance, but is also challenging. Current methods for controllable\ngeneration primarily focus on modifying the score function of diffusion models,\nwhile Mean Reverting (MR) Diffusion directly modifies the structure of the\nstochastic differential equation (SDE), making the incorporation of image\nconditions simpler and more natural. However, current training-free fast\nsamplers are not directly applicable to MR Diffusion. And thus MR Diffusion\nrequires hundreds of NFEs (number of function evaluations) to obtain\nhigh-quality samples. In this paper, we propose a new algorithm named MaRS (MR\nSampler) to reduce the sampling NFEs of MR Diffusion. We solve the reverse-time\nSDE and the probability flow ordinary differential equation (PF-ODE) associated\nwith MR Diffusion, and derive semi-analytical solutions. The solutions consist\nof an analytical function and an integral parameterized by a neural network.\nBased on this solution, we can generate high-quality samples in fewer steps.\nOur approach does not require training and supports all mainstream\nparameterizations, including noise prediction, data prediction and velocity\nprediction. Extensive experiments demonstrate that MR Sampler maintains high\nsampling quality with a speedup of 10 to 20 times across ten different image\nrestoration tasks. Our algorithm accelerates the sampling procedure of MR\nDiffusion, making it more practical in controllable generation."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17303",
    "c_title":[
      "Asymptotically geodesic surfaces"
    ],
    "c_abstract":[
      "A sequence of distinct closed surfaces in a hyperbolic 3-manifold M is\nasymptotically geodesic if their principal curvatures tend uniformly to zero.\nWhen M has finite volume, we show such sequences are always asymptotically\ndense in the 2-plane Grassmann bundle of M. When M has infinite volume and is\ngeometrically finite, we show such sequences do not exist. As an application of\nthe former, we obtain partial answers to the question of whether a negatively\ncurved Riemannian 3-manifold that contains a sequence of asymptotically totally\ngeodesic or totally umbilic surfaces must be hyperbolic. Finally, we give\nexamples to show that if the dimension of M is greater than 3, the possible\nlimiting behavior of asymptotically geodesic surfaces is less constrained than\nfor totally geodesic surfaces."
    ],
    "c_categories":[
      [
        "math.DG",
        "math.DS",
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-768",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02414",
    "b_title":[
      "InfoGNN: End-to-end deep learning on mesh via graph neural networks"
    ],
    "b_abstract":[
      "3D models are widely used in various industries, and mesh data has become an\nindispensable part of 3D modeling because of its unique advantages. Mesh data\ncan provide an intuitive and practical expression of rich 3D information.\nHowever, its disordered, irregular data structure and complex surface\ninformation make it challenging to apply with deep learning models directly.\nTraditional mesh data processing methods often rely on mesh models with many\nlimitations, such as manifold, which restrict their application scopes in\nreality and do not fully utilize the advantages of mesh models. This paper\nproposes a novel end-to-end framework for addressing the challenges associated\nwith deep learning in mesh models centered around graph neural networks (GNN)\nand is titled InfoGNN. InfoGNN treats the mesh model as a graph, which enables\nit to handle irregular mesh data efficiently. Moreover, we propose InfoConv and\nInfoMP modules, which utilize the position information of the points and fully\nuse the static information such as face normals, dihedral angles, and dynamic\nglobal feature information to fully use all kinds of data. In addition, InfoGNN\nis an end-to-end framework, and we simplify the network design to make it more\nefficient, paving the way for efficient deep learning of complex 3D models. We\nconducted experiments on several publicly available datasets, and the results\nshow that InfoGNN achieves excellent performance in mesh classification and\nsegmentation tasks."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09761",
    "c_title":[
      "Making mathematical claims"
    ],
    "c_abstract":[
      "Good problems grab us. They invite us to find patterns, make conjectures, and\nprove-or perhaps disprove-a conjecture. When I first taught, I saw my work as\ntantalizing students with structures just beyond their reach, so that I could\nelicit conjectures from promising half-phrases. With a community conjecture\ncrystallized on the board, \"we\" proved the statement. \"We\" anointed the\nconjecture a community theorem, and \"we\" moved on. I hoped that, through\nrepeated exposure to this routine, students would absorb a mathematical process\nfrom discovery to proof. But I've since wondered: What does this routine teach\nstudents? I've concluded that if this is the only instructional routine that\nstudents experience, they may leave with an impoverished image of the beauty\nand joy that doing math can offer."
    ],
    "c_categories":[
      [
        "math.HO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-769",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06830",
    "b_title":[
      "OrderFusion: Encoding Orderbook for Probabilistic Intraday Price\n  Prediction"
    ],
    "b_abstract":[
      "Efficient and reliable probabilistic prediction of intraday electricity\nprices is essential to manage market uncertainties and support robust trading\nstrategies. However, current methods often suffer from parameter\ninefficiencies, as they fail to fully exploit the potential of modeling\ninterdependencies between bids and offers in the orderbook, requiring a large\nnumber of parameters for representation learning. Furthermore, these methods\nface the quantile crossing issue, where upper quantiles fall below the lower\nquantiles, resulting in unreliable probabilistic predictions. To address these\ntwo challenges, we propose an encoding method called OrderFusion and design a\nhierarchical multi-quantile head. The OrderFusion encodes the orderbook into a\n2.5D representation, which is processed by a tailored jump cross-attention\nbackbone to capture the interdependencies of bids and offers, enabling\nparameter-efficient learning. The head sets the median quantile as an anchor\nand predicts multiple quantiles hierarchically, ensuring reliability by\nenforcing monotonicity between quantiles through non-negative functions.\nExtensive experiments and ablation studies are conducted on four price indices:\n60-min ID3, 60-min ID1, 15-min ID3, and 15-min ID1 using the German orderbook\nover three years to ensure a fair evaluation. The results confirm that our\ndesign choices improve overall performance, offering a parameter-efficient and\nreliable solution for probabilistic intraday price prediction."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.06059",
    "c_title":[
      "Position: We Need An Adaptive Interpretation of Helpful, Honest, and\n  Harmless Principles"
    ],
    "c_abstract":[
      "The Helpful, Honest, and Harmless (HHH) principle is a foundational framework\nfor aligning AI systems with human values. However, existing interpretations of\nthe HHH principle often overlook contextual variability and conflicting\nrequirements across applications. In this paper, we argue for an adaptive\ninterpretation of the HHH principle and propose a reference framework for its\nadaptation to diverse scenarios. We first examine the principle's foundational\nsignificance and identify ambiguities and conflicts through case studies of its\ndimensions. To address these challenges, we introduce the concept of priority\norder, which provides a structured approach for balancing trade-offs among\nhelpfulness, honesty, and harmlessness. Further, we explore the\ninterrelationships between these dimensions, demonstrating how harmlessness and\nhelpfulness can be jointly enhanced and analyzing their interdependencies in\nhigh-risk evaluations. Building on these insights, we propose a reference\nframework that integrates context definition, value prioritization, risk\nassessment, and benchmarking standards to guide the adaptive application of the\nHHH principle. This work offers practical insights for improving AI alignment,\nensuring that HHH principles remain both ethically grounded and operationally\neffective in real-world AI deployment."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-770",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11864",
    "b_title":[
      "LLM-Agents Driven Automated Simulation Testing and Analysis of small\n  Uncrewed Aerial Systems"
    ],
    "b_abstract":[
      "Thorough simulation testing is crucial for validating the correct behavior of\nsmall Uncrewed Aerial Systems (sUAS) across multiple scenarios, including\nadverse weather conditions (such as wind, and fog), diverse settings (hilly\nterrain, or urban areas), and varying mission profiles (surveillance,\ntracking). While various sUAS simulation tools exist to support developers, the\nentire process of creating, executing, and analyzing simulation tests remains a\nlargely manual and cumbersome task. Developers must identify test scenarios,\nset up the simulation environment, integrate the System under Test (SuT) with\nsimulation tools, formulate mission plans, and collect and analyze results.\nThese labor-intensive tasks limit the ability of developers to conduct\nexhaustive testing across a wide range of scenarios. To alleviate this problem,\nin this paper, we propose AutoSimTest, a Large Language Model (LLM)-driven\nframework, where multiple LLM agents collaborate to support the sUAS simulation\ntesting process. This includes: (1) creating test scenarios that subject the\nSuT to unique environmental contexts; (2) preparing the simulation environment\nas per the test scenario; (3) generating diverse sUAS missions for the SuT to\nexecute; and (4) analyzing simulation results and providing an interactive\nanalytics interface. Further, the design of the framework is flexible for\ncreating and testing scenarios for a variety of sUAS use cases, simulation\ntools, and SuT input requirements. We evaluated our approach by (a) conducting\nsimulation testing of PX4 and ArduPilot flight-controller-based SuTs, (b)\nanalyzing the performance of each agent, and (c) gathering feedback from sUAS\ndevelopers. Our findings indicate that AutoSimTest significantly improves the\nefficiency and scope of the sUAS testing process, allowing for more\ncomprehensive and varied scenario evaluations while reducing the manual effort."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05513",
    "c_title":[
      "Discovery of a likely Type II SN at $z$=3.6 with JWST"
    ],
    "c_abstract":[
      "Transient astronomy in the early, high-redshift (z > 3) Universe is an\nunexplored regime that offers the possibility of probing the first stars and\nthe Epoch of Reionization. During Cycles 1 and 2 of the James Webb Space\nTelescope (JWST), the JWST Advanced Deep Extragalactic Survey (JADES) program\nenabled one of the first searches for transients in deep images (~30 AB mag)\nover a relatively wide area (25 arcmin^2). One transient, AT 2023adsv, was\ndiscovered with an F200W magnitude of 28.04 AB mag, and subsequent JWST\nobservations revealed that the transient is a likely supernova (SN) in a host\nwith z_spec = 3.613 +\/- 0.001 and an inferred metallicity at the position of\nthe SN of Z_* = 0.3 +\/- 0.1 Z_{\\odot}. At this redshift, the first detections\nin F115W and F150W show that AT 2023adsv had bright rest-frame ultraviolet flux\nat the time of discovery. The multi-band light curve of AT 2023adsv is best\nmatched by a template of an SN IIP with a peak absolute magnitude of M_B ~\n-18.3 AB mag. We find a good match to a 20 M_{\\odot} red supergiant progenitor\nstar with an explosion energy of 2.0x10^51 ergs, likely higher than normally\nobserved in the local Universe, but consistent with SNe IIP drawn from local,\nlower metallicity environments. AT 2023adsv is the most distant photometrically\nclassified SN IIP yet discovered with a spectroscopic redshift measurement, and\nmay represent a global shift in SNe IIP properties as a function of redshift."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-771",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18422",
    "b_title":[
      "Quantum States from Minimal Surfaces"
    ],
    "b_abstract":[
      "Apart from relating interesting quantum mechanical systems to equations\ndescribing a parabolic discrete minimal surface, the quantization of a cubic\nminimal surface in $\\mathbb{R}^4$ is considered."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19905",
    "c_title":[
      "Moments of quadratic Dirichlet character sums"
    ],
    "c_abstract":[
      "We consider moments of higher powers of quadratic Dirichlet character sums.\nIn a restricted region, we give their asymptotic behavior by using de la\nBret\\`{e}che's multivariable Tauberian theorem. We also give the lower bound of\nthe exponent of $\\log$ factor in the conjecture of Jutila. As an application,\nwe give a lower bound of a weighted average of shifted moments of quadratic\nDirichlet $L$-functions."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-772",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08007",
    "b_title":[
      "MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped\n  Vision-Language-Action Models"
    ],
    "b_abstract":[
      "Developing versatile quadruped robots that can smoothly perform various\nactions and tasks in real-world environments remains a significant challenge.\nThis paper introduces a novel vision-language-action (VLA) model, mixture of\nrobotic experts (MoRE), for quadruped robots that aim to introduce\nreinforcement learning (RL) for fine-tuning large-scale VLA models with a large\namount of mixed-quality data. MoRE integrates multiple low-rank adaptation\nmodules as distinct experts within a dense multi-modal large language model\n(MLLM), forming a sparse-activated mixture-of-experts model. This design\nenables the model to effectively adapt to a wide array of downstream tasks.\nMoreover, we employ a reinforcement learning-based training objective to train\nour model as a Q-function after deeply exploring the structural properties of\nour tasks. Effective learning from automatically collected mixed-quality data\nenhances data efficiency and model performance. Extensive experiments\ndemonstrate that MoRE outperforms all baselines across six different skills and\nexhibits superior generalization capabilities in out-of-distribution scenarios.\nWe further validate our method in real-world scenarios, confirming the\npracticality of our approach and laying a solid foundation for future research\non multi-task learning in quadruped robots."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12184",
    "c_title":[
      "Limit theorems for squared increment sums of the maximum of two\n  isotropic fractional Brownian fields over a fixed-domain"
    ],
    "c_abstract":[
      "The pointwise maximum of two independent and identically distributed\nisotropic fractional Brownian fields (with Hurst parameter $H<1\/2$) is observed\nin a family of points in the unit square $\\mathbf{C}=(-1\/2,1\/2]^{2}$. We assume\nthat these points come from the realization of a homogeneous Poisson point\nprocess with intensity $N$. We consider normalized increments (resp. pairs of\nincrements) along the edges of the Delaunay triangulation generated by the\nPoisson point process (resp. pairs of edges within triangles). We investigate\nthe asymptotic behaviors of the squared increment sums as $N\\rightarrow \\infty\n$. We show that the normalizations differ from the case of a unique isotropic\nfractional Brownian field as obtained in \\cite{Chenavier&Robert25a} and that\nthe sums converge to the local time of the difference of the two isotropic\nfractional Brownian fields up to constant factors."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-773",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10722",
    "b_title":[
      "PMU-Data: Data Traces Could be Distinguished"
    ],
    "b_abstract":[
      "Modern processors widely equip the Performance Monitoring Unit (PMU) to\ncollect various architecture and microarchitecture events. Software developers\noften utilize the PMU to enhance program's performance, but the potential side\neffects that arise from its activation are often disregarded. In this paper, we\nfind that the PMU can be employed to retrieve instruction operands. Based on\nthis discovery, we introduce PMU-Data, a novel category of side-channel attacks\naimed at leaking secret by identifying instruction operands with PMU.\n  To achieve the PMU-Data attack, we develop five gadgets to encode the\nconfidential data into distinct data-related traces while maintaining the\ncontrol-flow unchanged. We then measure all documented PMU events on three\nphysical machines with different processors while those gadgets are performing.\nWe successfully identify two types of vulnerable gadgets caused by DIV and MOV\ninstructions. Additionally, we discover 40 vulnerable PMU events that can be\nused to carry out the PMU-Data attack. We through real experiments to\ndemonstrate the perniciousness of the PMU-Data attack by implementing three\nattack goals: (1) leaking the kernel data illegally combined with the transient\nexecution vulnerabilities including Meltdown, Spectre, and Zombieload; (2)\nbuilding a covert-channel to secretly transfer data; (3) extracting the secret\ndata protected by the Trusted Execution Environment (TEE) combined with the\nZombieload vulnerability."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13897",
    "c_title":[
      "Connections between coupling and Ishii-Lions methods for tug-of-war with\n  noise stochastic games"
    ],
    "c_abstract":[
      "We present a streamlined account of two different regularity methods as well\nas their connections. We consider the coupling method in the context of\ntug-of-war with noise stochastic games, and consider viscosity solutions of the\n$p$-Laplace equation in the context of the Ishii-Lions method."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-774",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13664",
    "b_title":[
      "Dynamics of defects and interfaces for interacting quantum hard disks"
    ],
    "b_abstract":[
      "Defects and interfaces are essential to understand the properties of matter.\nHowever, studying their dynamics in the quantum regime remains a challenge in\nparticular concerning the regime of two spatial dimensions. Recently, it has\nbeen shown that a quantum counterpart of the hard-disk problem on a lattice\nyields defects and interfaces, which are stable just due to quantum effects\nwhile they delocalize and dissolve classically. Here, we study in more detail\nthe properties of defects and interfaces in this quantum hard-disk problem with\na particular emphasis on the stability of these quantum effects upon including\nperturbations. Specifically, we introduce short-range soft-core interactions\nbetween the hard disks. From both analytical arguments and numerical\nsimulations we find that large classes of defects and interfaces remain stable\neven under such perturbations suggesting that the quantum nature of the\ndynamics exhibits a large range of robustness. Our findings demonstrate the\nstability and non-classical behavior of quantum interface dynamics, offering\ninsights into the dynamics of two-dimensional quantum matter and establishing\nthe quantum hard-disk model as a platform for studying unconventional\nconstrained quantum dynamics."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08995",
    "c_title":[
      "A Combination Theorem for Geodesic Coarsely Convex Group Pairs"
    ],
    "c_abstract":[
      "The first author and Oguni introduced a class of groups of non-positive\ncurvature, called coarsely convex group. The recent success of the theory of\ngroups which are hyperbolic relative to a collection of subgroups has motivated\nthe study of other properties of groups from the relative perspective. In this\narticle, we propose definitions for the notions of weakly semihyperbolic,\nsemihyperbolic, and coarsely convex group pairs extending the corresponding\nnotions in the non-relative case. The main result of this article is the\nfollowing combination theorem. Let $\\mathcal{A}_{wsh}$, $\\mathcal{A}_{sh}$, and\n$\\mathcal{A}_{gcc}$ denote the classes of group pairs that are weakly\nsemihyperbolic, semihyperbolic, and geodesic coarsely convex respectively. Let\n$\\mathcal A$ be one of the classes $\\mathcal{A}_{wsh}$, $\\mathcal{A}_{sh}$, and\n$\\mathcal{A}_{gcc}$. Let $G$ be a group that splits as a finite graph of groups\nsuch that each vertex group $G_v$ is assigned a finite collection of subgroups\n$\\mathcal{H}_v$, and each edge group $G_e$ is conjugate to a subgroup of some\n$H\\in \\mathcal{H}_v$ if $e$ is adjacent to $v$. Then there is a non-trivial\nfinite collection of subgroups $\\mathcal{H}$ of $G$ satisfying the following\nproperties. If each $(G_v, \\mathcal{H}_v)$ is in $\\mathcal{A} $, then\n$(G,\\mathcal{H})$ is in $\\mathcal{A}$. The main results of the article are\ncombination theorems generalizing results of Alonso and Bridson; and Fukaya and\nMatsuka."
    ],
    "c_categories":[
      [
        "math.GR",
        "math.GT",
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-775",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04742",
    "b_title":[
      "Meta-learning-based percussion transcription and $t\\bar{a}la$\n  identification from low-resource audio"
    ],
    "b_abstract":[
      "This study introduces a meta-learning-based approach for low-resource Tabla\nStroke Transcription (TST) and $t\\bar{a}la$ identification in Hindustani\nclassical music. Using Model-Agnostic Meta-Learning (MAML), we address the\nchallenge of limited annotated datasets, enabling rapid adaptation to new tasks\nwith minimal data. The method is validated across various datasets, including\ntabla solo and concert recordings, demonstrating robustness in polyphonic audio\nscenarios. We propose two novel $t\\bar{a}la$ identification techniques based on\nstroke sequences and rhythmic patterns. Additionally, the approach proves\neffective for Automatic Drum Transcription (ADT), showcasing its flexibility\nfor Indian and Western percussion music. Experimental results show that the\nproposed method outperforms existing techniques in low-resource settings,\nsignificantly contributing to music transcription and studying musical\ntraditions through computational tools."
    ],
    "b_categories":[
      [
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04583",
    "c_title":[
      "Existence of Deadlock-Free Routing for Arbitrary Networks"
    ],
    "c_abstract":[
      "Given a network of routing nodes, represented as a directed graph, we prove\nthe following necessary and sufficient condition for the existence of\ndeadlock-free message routing: The directed graph must contain two\nedge-disjoint directed trees rooted at the same node, one tree directed into\nthe root node and the other directed away from the root node.\n  While the sufficiency of this condition is known, its necessity, to the best\nof our knowledge, has not been previously recognized or proven. Although not\ndirectly applicable to the construction of deadlock-free routing schemes, this\nresult provides a fundamental insight into the nature of deadlock-free networks\nand may lead to the development of improved tools for designing and verifying\nsuch schemes."
    ],
    "c_categories":[
      [
        "cs.DC",
        "cs.NI",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-776",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14232",
    "b_title":[
      "Bolide infrasound signal morphology and yield estimates: A case study of\n  two events detected by a dense acoustic sensor network"
    ],
    "b_abstract":[
      "Two bolides (2 June 2016 and 4 April 2019) were detected at multiple regional\ninfrasound stations with many of the locations receiving multiple detections.\nAnalysis of the received signals was used to estimate the yield, location and\ntrajectory, and the type of shock that produced the received signal. The\nresults from the infrasound analysis were compared with ground truth\ninformation that was collected through other sensing modalities. This\nmulti-modal framework offers an expanded perspective on the processes governing\nbolide shock generation and propagation. The majority of signal features showed\nreasonable agreement between the infrasound-based interpretation and the other\nobservational modalities, though the yield estimate from the 2019 bolide was\nsignificantly lower using the infrasound detections. There was also evidence\nsuggesting that one of the detections was from a cylindrical shock that was\ninitially propagating upward, which is unusual though not impossible."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM",
        "physics.ao-ph",
        "physics.geo-ph",
        "physics.ins-det",
        "physics.space-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18657",
    "c_title":[
      "Enhancing Large Language Model Efficiencyvia Symbolic Compression: A\n  Formal Approach Towards Interpretability"
    ],
    "c_abstract":[
      "Large language models (LLMs) face significant token efficiency bottlenecks in\ncode generation and logical reasoning tasks, a challenge that directly impacts\ninference cost and model interpretability. This paper proposes a formal\nframework based on symbolic compression,integrating combinatory logic,\ninformation-theoretic optimal encoding, and context-aware inference techniques\nto achieve a step-change improvement in token efficiency while preserving\nsemantic integrity. We establish a mathematical framework within a functional\nprogramming paradigm, derive the quantitative relationship between symbolic\ndensity and model interpretability, and propose a differentiable compression\nfactor metric to evaluate encoding efficiency. Furthermore, we leverage\nparameter-efficient fine-tuning (PEFT) techniques to achieve a low-cost\napplication of the GAEL language. Experimental results show that this method\nachieves a 78.3% token compression rate in code generation tasks while\nimproving logical traceability by 62% through structural explicitness. This\nresearch provides new theoretical tools for efficient inference in LLMs and\nopens a symbolic path for modelinterpretability research."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-777",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12108",
    "b_title":[
      "Using the Path of Least Resistance to Explain Deep Networks"
    ],
    "b_abstract":[
      "Integrated Gradients (IG), a widely used axiomatic path-based attribution\nmethod, assigns importance scores to input features by integrating model\ngradients along a straight path from a baseline to the input. While effective\nin some cases, we show that straight paths can lead to flawed attributions. In\nthis paper, we identify the cause of these misattributions and propose an\nalternative approach that treats the input space as a Riemannian manifold,\ncomputing attributions by integrating gradients along geodesics. We call this\nmethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we\nintroduce two techniques: a k-Nearest Neighbours-based approach for smaller\nmodels and a Stochastic Variational Inference-based method for larger ones.\nAdditionally, we propose a new axiom, Strong Completeness, extending the axioms\nsatisfied by IG. We show that this property is desirable for attribution\nmethods and that GIG is the only method that satisfies it. Through experiments\non both synthetic and real-world data, we demonstrate that GIG outperforms\nexisting explainability methods, including IG."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01748",
    "c_title":[
      "Fast Expectation Value Calculation Speedup of Quantum Approximate\n  Optimization Algorithm: HoLCUs QAOA"
    ],
    "c_abstract":[
      "In this paper, we present a new method for calculating expectation values of\noperators that can be expressed as a linear combination of unitary (LCU)\noperators. This method allows to perform this calculation in a single quantum\ncircuit measuring a single qubit, which speeds up the computation process. This\nmethod is general for any quantum algorithm and is of particular interest in\nthe acceleration of variational quantum algorithms, both in real devices and in\nsimulations. We analyze its application to the parameter optimization process\nof the Quantum Approximate Optimization Algorithm (QAOA) and the case of having\ndegenerate values in the matrix of the Ising problem. Finally, we apply it to\nseveral Quadratic Unconstrained Binary Optimization (QUBO) problems to analyze\nthe speedup of the method in circuit simulators."
    ],
    "c_categories":[
      [
        "cs.ET",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-778",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16491",
    "b_title":[
      "The Impact of Generative AI Coding Assistants on Developers Who Are\n  Visually Impaired"
    ],
    "b_abstract":[
      "The rapid adoption of generative AI in software development has impacted the\nindustry, yet its effects on developers with visual impairments remain largely\nunexplored. To address this gap, we used an Activity Theory framework to\nexamine how developers with visual impairments interact with AI coding\nassistants. For this purpose, we conducted a study where developers who are\nvisually impaired completed a series of programming tasks using a generative AI\ncoding assistant. We uncovered that, while participants found the AI assistant\nbeneficial and reported significant advantages, they also highlighted\naccessibility challenges. Specifically, the AI coding assistant often\nexacerbated existing accessibility barriers and introduced new challenges. For\nexample, it overwhelmed users with an excessive number of suggestions, leading\ndevelopers who are visually impaired to express a desire for ``AI timeouts.''\nAdditionally, the generative AI coding assistant made it more difficult for\ndevelopers to switch contexts between the AI-generated content and their own\ncode. Despite these challenges, participants were optimistic about the\npotential of AI coding assistants to transform the coding experience for\ndevelopers with visual impairments. Our findings emphasize the need to apply\nactivity-centered design principles to generative AI assistants, ensuring they\nbetter align with user behaviors and address specific accessibility needs. This\napproach can enable the assistants to provide more intuitive, inclusive, and\neffective experiences, while also contributing to the broader goal of enhancing\naccessibility in software development."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10033",
    "c_title":[
      "Decay rates of $\\Lambda_b^0 \\to \\Lambda_c^+ \\ell^- \\bar\\nu_\\ell$ using\n  helicity analysis and phase-moment parametrization"
    ],
    "c_abstract":[
      "Based on the helicity method, formulae for the semileptonic transition of\n$\\Lambda_b^0 \\to \\Lambda_c^+ \\ell^- \\bar \\nu_\\ell$ including lepton mass\neffects are derived. In order to calculate the form factors of the $\\Lambda_b$\nbaryon transition matrix element, we employ the phase-moment parameterization\nand perform fits to the Lattice QCD data. With the help of the obtained form\nfactors, six helicity amplitudes and the differential decay widths are\nevaluated. Through appropriate angular integrations, we express the helicity\nflip, helicity nonflip integrated decay rates, and the lepton-side\nforward-backward asymmetry. We present a numerical analysis of these physical\nobservables. We obtain the mentioned physical quantities by performing fits to\nthe Lattice QCD data using the well-known Boyd-Grinstein-Lebed parametrization.\nComparisons with other experimental and theoretical data are also discussed."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-779",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17072",
    "b_title":[
      "Multi-Span Optical Power Spectrum Evolution Modeling using ML-based\n  Multi-Decoder Attention Framework"
    ],
    "b_abstract":[
      "We implement a ML-based attention framework with component-specific decoders,\nimproving optical power spectrum prediction in multi-span networks. By reducing\nthe need for in-depth training on each component, the framework can be scaled\nto multi-span topologies with minimal data collection, making it suitable for\nbrown-field scenarios."
    ],
    "b_categories":[
      [
        "cs.LG",
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03615",
    "c_title":[
      "A note on the twisted degree $6$ $L$-function for Hermitian cusp forms\n  of degree $2$"
    ],
    "c_abstract":[
      "Let $F$ be a cuspidal Hermitian eigenform of degree two over $\\mathbb{Q}(i)$,\nwith first Fourier-Jacobi coefficient not identically zero. Building on a paper\nby Das and Jha, we prove the meromorphic continuation to $\\mathbb{C}$ and the\nfunctional equation of a degree six $L$-function attached to $F$ by Gritsenko,\ntwisted by a Dirichlet character."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-780",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02212",
    "b_title":[
      "A mixed-precision quantum-classical algorithm for solving linear systems"
    ],
    "b_abstract":[
      "We address the problem of solving a system of linear equations via the\nQuantum Singular Value Transformation (QSVT). One drawback of the QSVT\nalgorithm is that it requires huge quantum resources if we want to achieve an\nacceptable accuracy. To reduce the quantum cost, we propose a hybrid\nquantum-classical algorithm that improves the accuracy and reduces the cost of\nthe QSVT by adding iterative refinement in mixed-precision A first quantum\nsolution is computed using the QSVT, in low precision, and then refined in\nhigher precision until we get a satisfactory accuracy. For this solver, we\npresent an error and complexity analysis, and first experiments using the\nquantum software stack myQLM."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2502.03339",
    "c_title":[
      "A new method for structural diagnostics with muon tomography and deep\n  learning"
    ],
    "c_abstract":[
      "This work investigates the production of high-resolution images of typical\nsupport elements in concrete structures by means of the muon tomography\n(muography). By exploiting detailed Monte Carlo radiation-matter simulations,\nwe demonstrate the feasibility of the reconstruction of 1 cm--thick iron tubes\ninside 30 cm--deep concrete blocks, regarded as an important testbed within the\nstructural diagnostics community. In addition, we present a new method for\nintegrating simulated data with advanced deep learning techniques in order to\nimprove the muon imaging of concrete structures. Through deep learning\nenhancement techniques, this results into a dramatic improvement of the image\nquality, as well as into a significant reduction of the data acquisition time,\nwhich are two critical limitations within the usual practice of muography for\ncivil engineering diagnostics."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-ph",
        "physics.comp-ph",
        "physics.geo-ph",
        "physics.ins-det"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-781",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13968",
    "b_title":[
      "Betsu-Betsu: Multi-View Separable 3D Reconstruction of Two Interacting\n  Objects"
    ],
    "b_abstract":[
      "Separable 3D reconstruction of multiple objects from multi-view RGB images --\nresulting in two different 3D shapes for the two objects with a clear\nseparation between them -- remains a sparsely researched problem. It is\nchallenging due to severe mutual occlusions and ambiguities along the objects'\ninteraction boundaries. This paper investigates the setting and introduces a\nnew neuro-implicit method that can reconstruct the geometry and appearance of\ntwo objects undergoing close interactions while disjoining both in 3D, avoiding\nsurface inter-penetrations and enabling novel-view synthesis of the observed\nscene. The framework is end-to-end trainable and supervised using a novel\nalpha-blending regularisation that ensures that the two geometries are well\nseparated even under extreme occlusions. Our reconstruction method is\nmarkerless and can be applied to rigid as well as articulated objects. We\nintroduce a new dataset consisting of close interactions between a human and an\nobject and also evaluate on two scenes of humans performing martial arts. The\nexperiments confirm the effectiveness of our framework and substantial\nimprovements using 3D and novel view synthesis metrics compared to several\nexisting approaches applicable in our setting."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02371",
    "c_title":[
      "The Effect of Capital Share on Income Inequality: Identifying the Time\n  Patterns"
    ],
    "c_abstract":[
      "This study explores the link between the capital share and income inequality\nover the past four decades across 56 countries. Calculating the capital share\nfrom national accounts alongside top income share data from the World\nInequality Database, which is based on the Distributional National Accounts\nmethodology, we ensure the consistency in the theory and measurement. Employing\na structural econometric approach, we account for heterogeneous and\ntime-varying transmission coefficients from the capital share to personal\nincome inequality. Our findings reveal that a one percentage point (pp)\nincrease in the capital share raises the income share of the top 5% by 0.17 pp\non average. Advanced economies show a stable transmission coefficient with\nrising capital and labor income inequality, while emerging economies experience\nan increasing transmission coefficient alongside growing capital income\ninequality. In contrast, a third group exhibits a declining transmission\ncoefficient and rising labor income inequality. Overall, changes in the capital\nshare account for approximately 50% of the rise in income inequality,\nunderscoring its pivotal role over the last four decades."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-782",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13533",
    "b_title":[
      "The Status Quo and Future of AI-TPACK for Mathematics Teacher Education\n  Students: A Case Study in Chinese Universities"
    ],
    "b_abstract":[
      "As artificial intelligence (AI) technology becomes increasingly prevalent in\nthe filed of education, there is a growing need for mathematics teacher\neducation students (MTES) to demonstrate proficiency in the integration of AI\nwith the technological pedagogical content knowledge (AI-TPACK). To study the\nissue, we firstly devised an systematic AI-TPACK scale and test on 412 MTES\nfrom seven universities. Through descriptive statistical analyses, we found\nthat the current status of AI-TPACK for MTES in China is at a basic,\npreliminary stage. Secondly, we compared MTES between three different grades on\nthe six variables and found that there is no discernible difference, which\nsuggested that graduate studies were observed to have no promotion in the\ndevelopment of AI-TPACK competencies. Thirdly, we proposed a new AI-TPACK\nstructural equation model (AI-TPACK-SEM) to explore the impact of self-efficacy\nand teaching beliefs on AI-TPACK. Our findings indicate a positive correlation\nbetween self-efficacy and AI-TPACK. We also come to a conclusion that may be\ncontrary to common perception, excessive teaching beliefs may impede the\nadvancement of AI-TPACK. Overall, this paper revealed the current status of\nAI-TPACK for MTES in China for the first time, designed a dedicated SEM to\nstudy the effect of specific factors on AI-TPACK, and proposed some suggestions\non future developments."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06075",
    "c_title":[
      "The ultraviolet luminosity function of star-forming galaxies between\n  redshifts of 0.4 and 0.6"
    ],
    "c_abstract":[
      "We combine ultraviolet imaging of the 13H survey field, taken with the\nXMM-Newton Optical Monitor telescope (XMM-OM) and the Neil Gehrels Swift\nObservatory Ultraviolet and Optical Telescope (UVOT) in the UVM2 band, to\nmeasure rest-frame ultraviolet 1500A luminosity functions of star-forming\ngalaxies with redshifts between 0.4 and 0.6. In total the UVM2 imaging covers a\nsky area of 641 square arcmin, and we detect 273 galaxies in the UVM2 image\nwith 0.4<z<0.6. The luminosity function is fit by a Schechter function with\nbest-fit values for the faint end slope alpha = -1.8 +0.4 -0.3 and\ncharacteristic absolute magnitude M* = -19.1 +0.3 -0.4. In common with XMM-OM\nbased studies at higher redshifts, our best-fitting value for M* is fainter\nthan previous measurements. We argue that the purging of active galactic nuclei\nfrom the sample, facilitated by the co-spatial X-ray survey carried out with\nXMM-Newton is important for the determination of M*. At the brightest absolute\nmagnitudes (M1500<-18.5) the average UV colour of our galaxies is consistent\nwith that of minimal-extinction local analogues, but the average UV colour is\nredder for galaxies at fainter absolute magnitudes, suggesting that higher\nlevels of dust attenuation enter the sample at absolute magnitudes somewhat\nfainter than M*."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-783",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15168",
    "b_title":[
      "mStyleDistance: Multilingual Style Embeddings and their Evaluation"
    ],
    "b_abstract":[
      "Style embeddings are useful for stylistic analysis and style transfer;\nhowever, only English style embeddings have been made available. We introduce\nMultilingual StyleDistance (mStyleDistance), a multilingual style embedding\nmodel trained using synthetic data and contrastive learning. We train the model\non data from nine languages and create a multilingual STEL-or-Content benchmark\n(Wegmann et al., 2022) that serves to assess the embeddings' quality. We also\nemploy our embeddings in an authorship verification task involving different\nlanguages. Our results show that mStyleDistance embeddings outperform existing\nmodels on these multilingual style benchmarks and generalize well to unseen\nfeatures and languages. We make our model publicly available at\nhttps:\/\/huggingface.co\/StyleDistance\/mstyledistance ."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13614",
    "c_title":[
      "Exact Results for SYM on $Y^{p,q}$ and $S^2\\times S^2$ with Conical\n  Singularities"
    ],
    "c_abstract":[
      "We compute the full partition function, including flux and instanton\ncontributions, for an $\\mathcal{N}=1$ theory of vector multiplets and\nhypermultiplets on five-dimensional toric Sasakian manifolds $Y^{p,q}$.\nDimensionally reducing, we obtain the partition function on a class of\nmanifolds whose topology is $S^2\\times S^2$, for equivariant Donaldson-Witten\nand Pestun-like theories. Generalizing the procedure to branched covers of\n$Y^{p,q}$, and exploiting an equivalence with spaces containing orbifold\nsingularities, we compute, for instance, the partition function of an\n$\\mathcal{N}=2$ theory on the product of two spindles."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-784",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02345",
    "b_title":[
      "CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for\n  Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented\n  3D MRI"
    ],
    "b_abstract":[
      "The detection of Alzheimer disease (AD) from clinical MRI data is an active\narea of research in medical imaging. Recent advances in quantum computing,\nparticularly the integration of parameterized quantum circuits (PQCs) with\nclassical machine learning architectures, offer new opportunities to develop\nmodels that may outperform traditional methods. However, quantum machine\nlearning (QML) remains in its early stages and requires further experimental\nanalysis to better understand its behavior and limitations. In this paper, we\npropose an end to end hybrid classical quantum convolutional neural network (CQ\nCNN) for AD detection using clinically formatted 3D MRI data. Our approach\ninvolves developing a framework to make 3D MRI data usable for machine\nlearning, designing and training a brain tissue segmentation model (Skull Net),\nand training a diffusion model to generate synthetic images for the minority\nclass. Our converged models exhibit potential quantum advantages, achieving\nhigher accuracy in fewer epochs than classical models. The proposed beta8 3\nqubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA)\nmodels while requiring significantly fewer computational resources. In\nparticular, the architecture employs only 13K parameters (0.48 MB), reducing\nthe parameter count by more than 99.99% compared to current SOTA models.\nFurthermore, the diffusion-generated data used to train our quantum models, in\nconjunction with real samples, preserve clinical structural standards,\nrepresenting a notable first in the field of QML. We conclude that CQCNN\narchitecture like models, with further improvements in gradient optimization\ntechniques, could become a viable option and even a potential alternative to\nclassical models for AD detection, especially in data limited and resource\nconstrained clinical settings."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01802",
    "c_title":[
      "Radio Observation of the Pulsar Wind Nebula in SNR G11.2-0.3"
    ],
    "c_abstract":[
      "Pulsar wind nebulae (PWNe) are important sources for understanding galactic\nhigh-energy processes, but it is controversial until now about how high-energy\nparticles in PWNe are accelerated and transported. Lacking radio counterparts\nof X-ray PWNe (the proposed acceleration sites) introduce difficulties to\nbetter understandings in multi wavelengths. Our recent 3, 6, and 16\\,cm\nhigh-resolution observations of G11.2$-$0.3 PWN with the Australia Telescope\nCompact Array (ATCA) uniquely show morphological similarity with its X-ray PWN\n(a torus\/jet feature). Spectral indices of the radio torus and jet are around\n-0.09 and -0.10, respectively. Meanwhile for the jet region, the spectral break\nbetween radio and X-ray spectra implies particle acceleration mechanisms other\nthan a diffusive shock acceleration. Polarization results suggest a helical\nB-field inside the jet, the equipartition B-field strength of which is below\n100\\,$\\mu$G."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-785",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04338",
    "b_title":[
      "Inference of noise intensity and phase response from noisy synchronous\n  oscillators"
    ],
    "b_abstract":[
      "Numerous biological and microscale systems exhibit synchronization in noisy\nenvironments. The theory of such noisy oscillators and their synchronization\nhas been developed and experimentally demonstrated, but inferring the noise\nintensity and phase response is not always straightforward. In this study, we\npropose a useful formula that enables us to infer the noise intensity and phase\nresponse of a noisy oscillator synchronized with periodic external forcing.\nThrough asymptotic approximations for small noise, we show that noisy\nsynchronous oscillators satisfy a simple relationship among the noise intensity\nand measurable quantities, i.e., the stationary distribution of the oscillation\nphase and stationary probability current obtained as the average phase\nvelocity, which is verified through systematic numerical analysis. The proposed\nformula facilitates a unified analysis and design of synchronous oscillators in\nweakly noisy environments."
    ],
    "b_categories":[
      [
        "nlin.AO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11091",
    "c_title":[
      "Aerial Vision-and-Language Navigation with Grid-based View Selection and\n  Map Construction"
    ],
    "c_abstract":[
      "Aerial Vision-and-Language Navigation (Aerial VLN) aims to obtain an unmanned\naerial vehicle agent to navigate aerial 3D environments following human\ninstruction. Compared to ground-based VLN, aerial VLN requires the agent to\ndecide the next action in both horizontal and vertical directions based on the\nfirst-person view observations. Previous methods struggle to perform well due\nto the longer navigation path, more complicated 3D scenes, and the neglect of\nthe interplay between vertical and horizontal actions. In this paper, we\npropose a novel grid-based view selection framework that formulates aerial VLN\naction prediction as a grid-based view selection task, incorporating vertical\naction prediction in a manner that accounts for the coupling with horizontal\nactions, thereby enabling effective altitude adjustments. We further introduce\na grid-based bird's eye view map for aerial space to fuse the visual\ninformation in the navigation history, provide contextual scene information,\nand mitigate the impact of obstacles. Finally, a cross-modal transformer is\nadopted to explicitly align the long navigation history with the instruction.\nWe demonstrate the superiority of our method in extensive experiments."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-786",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16941",
    "b_title":[
      "Gaussian Difference: Find Any Change Instance in 3D Scenes"
    ],
    "b_abstract":[
      "Instance-level change detection in 3D scenes presents significant challenges,\nparticularly in uncontrolled environments lacking labeled image pairs,\nconsistent camera poses, or uniform lighting conditions. This paper addresses\nthese challenges by introducing a novel approach for detecting changes in\nreal-world scenarios. Our method leverages 4D Gaussians to embed multiple\nimages into Gaussian distributions, enabling the rendering of two coherent\nimage sequences. We segment each image and assign unique identifiers to\ninstances, facilitating efficient change detection through ID comparison.\nAdditionally, we utilize change maps and classification encodings to categorize\n4D Gaussians as changed or unchanged, allowing for the rendering of\ncomprehensive change maps from any viewpoint. Extensive experiments across\nvarious instance-level change detection datasets demonstrate that our method\nsignificantly outperforms state-of-the-art approaches like C-NERF and CYWS-3D,\nespecially in scenarios with substantial lighting variations. Our approach\noffers improved detection accuracy, robustness to lighting changes, and\nefficient processing times, advancing the field of 3D change detection."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11983",
    "c_title":[
      "Circuit Design based on Feature Similarity for Quantum Generative\n  Modeling"
    ],
    "c_abstract":[
      "Quantum generative models may achieve an advantage on quantum devices by\ntheir inherent probabilistic nature and efficient sampling strategies. However,\ncurrent approaches mostly rely on general-purpose circuits, such as the\nhardware efficient ansatz paired with a random initialization strategy, which\nare known to suffer from trainability issues such as barren plateaus. To\naddress these issues, a tensor network pretraining framework that initializes a\nquantum circuit ansatz with a classically computed high-quality solution for a\nlinear entanglement structure has been proposed in literature. In order to\nimprove the classical solution, the quantum circuit needs to be extended, while\nit is still an open question how the extension affects trainability. In this\nwork, we propose the metric-based extension heuristic to design an extended\ncircuit based on a similarity metric measured between the dataset features. We\nvalidate this method on the bars and stripes dataset and carry out experiments\non financial data. Our results underline the importance of problem-informed\ncircuit design and show that the metric-based extension heuristic offers the\nmeans to introduce inductive bias while designing a circuit under limited\nresources."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-787",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02019",
    "b_title":[
      "Benchmarking Constraint-Based Bayesian Structure Learning Algorithms:\n  Role of Network Topology"
    ],
    "b_abstract":[
      "Modeling the associations between real world entities from their multivariate\ncross-sectional profiles can provide cues into the concerted working of these\nentities as a system. Several techniques have been proposed for deciphering\nthese associations including constraint-based Bayesian structure learning (BSL)\nalgorithms that model them as directed acyclic graphs. Benchmarking these\nalgorithms have typically focused on assessing the variation in performance\nmeasures such as sensitivity as a function of the dimensionality represented by\nthe number of nodes in the DAG, and sample size. The present study elucidates\nthe importance of network topology in benchmarking exercises. More\nspecifically, it investigates variations in sensitivity across distinct network\ntopologies while constraining the nodes, edges, and sample-size to be\nidentical, eliminating these as potential confounders. Sensitivity of three\npopular constraint-based BSL algorithms (Peter-Clarke, Grow-Shrink, Incremental\nAssociation Markov Blanket) in learning the network structure from multivariate\ncross-sectional profiles sampled from network models with sub-linear, linear,\nand super-linear DAG topologies generated using preferential attachment is\ninvestigated. Results across linear and nonlinear models revealed statistically\nsignificant $(\\alpha=0.05)$ decrease in sensitivity estimates from sub-linear\nto super-linear topology constitutively across the three algorithms. These\nresults are demonstrated on networks with nodes $(N_{nods}=48,64)$, noise\nstrengths $(\\sigma =3,6)$ and sample size $(N = 2^{10})$. The findings\nelucidate the importance of accommodating the network topology in\nconstraint-based BSL benchmarking exercises."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11591",
    "c_title":[
      "Pathology Image Compression with Pre-trained Autoencoders"
    ],
    "c_abstract":[
      "The growing volume of high-resolution Whole Slide Images in digital\nhistopathology poses significant storage, transmission, and computational\nefficiency challenges. Standard compression methods, such as JPEG, reduce file\nsizes but often fail to preserve fine-grained phenotypic details critical for\ndownstream tasks. In this work, we repurpose autoencoders (AEs) designed for\nLatent Diffusion Models as an efficient learned compression framework for\npathology images. We systematically benchmark three AE models with varying\ncompression levels and evaluate their reconstruction ability using pathology\nfoundation models. We introduce a fine-tuning strategy to further enhance\nreconstruction fidelity that optimizes a pathology-specific learned perceptual\nmetric. We validate our approach on downstream tasks, including segmentation,\npatch classification, and multiple instance learning, showing that replacing\nimages with AE-compressed reconstructions leads to minimal performance\ndegradation. Additionally, we propose a K-means clustering-based quantization\nmethod for AE latents, improving storage efficiency while maintaining\nreconstruction quality. We provide the weights of the fine-tuned autoencoders\nat\nhttps:\/\/huggingface.co\/collections\/StonyBrook-CVLab\/pathology-fine-tuned-aes-67d45f223a659ff2e3402dd0."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-788",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08830",
    "b_title":[
      "Binary quadratic forms: modern developments"
    ],
    "b_abstract":[
      "In this work, we offer a historical stroll through the vast topic of binary\nquadratic forms. We begin with a quick review of their history and then an\noverview of contemporary algebraic developments on the subject."
    ],
    "b_categories":[
      [
        "math.HO",
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02351",
    "c_title":[
      "High Temperature Superconductivity in the Cuprates: Phenomena from a\n  Theorist's Point of View"
    ],
    "c_abstract":[
      "I present a selection of experimental results on metallic cuprates, both\nabove the superconducting transition temperature $T_c$ (often called the\nstrange metal state) and in the superconducting state. It highlights this still\npoorly understood part of the physical world. After an introduction, I talk\nbriefly about the pseudogap regime and about the unusual linear resistivity\nphenomenon. Several empirical correlations between observed quantities are\nmentioned, e.g. $T_c$ and superfluid density (Uemura), $T_c$ and next nearest\nneighbour hopping, slope of the linear resistivity and $T_c$. In the belief\nthat a comprehensive explanation may need an understanding of the extremely\nstrongly correlated metal, a few initial steps in this direction are outlined."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "cond-mat.supr-con",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-789",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13345",
    "b_title":[
      "Controllability scores of linear time-varying network systems"
    ],
    "b_abstract":[
      "For large-scale network systems, network centrality based on control theory\nplays a crucial role in understanding their properties and controlling them\nefficiently. The controllability score is such a centrality index and can give\na physically meaningful measure. Nevertheless, the existing work is limited to\nlinear time-invariant (LTI) systems and the controllability score cannot be\napplied to linear time-varying (LTV) systems, which include essential models\nsuch as temporal networks for real application. This paper extends it to apply\nto LTV systems. Since it is defined as an optimal solution to some optimization\nproblem, it is not necessarily uniquely determined. Its uniqueness must be\nguaranteed for reproducibility and interpretability. This paper also shows its\nuniqueness in most practical cases, which guarantees its use as a network\ncentrality. In addition, we propose a data-driven method to compute it for its\npractical use. Finally, in numerical experiments, we compare controllability\nscores between LTI and LTV systems and assess the performance of the proposed\ndata-driven method."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17477",
    "c_title":[
      "Bacterial dimensions sensitively regulate surface diffusivity and\n  residence time"
    ],
    "c_abstract":[
      "Run-and-tumble is a common but vital strategy that bacteria employ to explore\nenvironment suffused with boundaries, as well as to escape from entrapment. In\nthis study we reveal how this strategy and the resulting dynamical behavior can\nbe sensitively regulated by bacterial dimensions. Our results demonstrate that\nthe logarithm of the surface residence time for bacteria with constant tumble\nbias is linearly related to a dimensionless parameter of bacterial intrinsic\nsize characteristics, where a small variation in bacterial dimensions, which is\nnatural in a suspension, reproduces well the experimentally observed large\nvariation in bacterial residence time. Furthermore, our results predict that\nthe optimal tumble bias corresponding to the maximum surface diffusivity\ndepends strongly on bacterial dimensions, where the same small variation in\nbacterial dimensions gives rise to a strongly diversified optimal tumble bias\nand an order of magnitude change in surface diffusivity."
    ],
    "c_categories":[
      [
        "cond-mat.soft",
        "cond-mat.stat-mech",
        "physics.bio-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-790",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20506",
    "b_title":[
      "Surveying the Giant HII Regions of the Milky Way with SOFIA: VII.\n  Galactic Center Regions Sgr B1, Sgr B2, and Sgr C"
    ],
    "b_abstract":[
      "This study examines the mid-infrared properties of Giant HII (GHII) regions\nin the Milky Way's Central Molecular Zone (CMZ) -- Sgr B1, Sgr B2, and Sgr C --\nusing SOFIA-FORCAST imaging at 25 and 37 microns. It compares these\nmid-infrared data with previous multi-wavelength observations to explore their\npresent star formation activity and global properties. The study identifies 77\nmassive young stellar object (MYSO) candidates in and around the three regions.\nSgr B2 appears to host the youngest MYSOs and have much higher extinction than\nthe other regions, containing several radio sources not detected in the\nmid-infrared even at 37 microns. Meanwhile, cm radio continuum regions of Sgr\nB1 shows remarkable correspondence to its mid-infrared emission. Sgr C has\nfewer confirmed MYSOs, and seems to have a higher fraction of low-mass young\nstellar objects and contamination from more evolved interloper\/foreground\nstars. Derived MYSO densities are consistent with GHII regions elsewhere in the\nGalactic plane, though the CMZ GHII regions appear to have less prolific\npresent star formation overall. Unlike Sgr B2, the cm continuum emission in Sgr\nB1 and Sgr C GHII regions appears to be absent cold dust and molecular gas,\nsuggesting environmental differences, possibly driven by turbulence and rapid\ndynamical changes near the Galactic Center. Furthermore, unlike typical GHII\nregions, Sgr B1 and Sgr C are significantly ionized by evolved interloper\nstars, which likely did not form within these regions. In these ways, Sgr B1\nand Sgr C deviate from classical GHII region behavior, thus potentially\nrepresenting a new category of GHII region or challenging their classification\nas GHII regions."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06431",
    "c_title":[
      "FCVSR: A Frequency-aware Method for Compressed Video Super-Resolution"
    ],
    "c_abstract":[
      "Compressed video super-resolution (SR) aims to generate high-resolution (HR)\nvideos from the corresponding low-resolution (LR) compressed videos. Recently,\nsome compressed video SR methods attempt to exploit the spatio-temporal\ninformation in the frequency domain, showing great promise in super-resolution\nperformance. However, these methods do not differentiate various frequency\nsubbands spatially or capture the temporal frequency dynamics, potentially\nleading to suboptimal results. In this paper, we propose a deep frequency-based\ncompressed video SR model (FCVSR) consisting of a motion-guided adaptive\nalignment (MGAA) network and a multi-frequency feature refinement (MFFR)\nmodule. Additionally, a frequency-aware contrastive loss is proposed for\ntraining FCVSR, in order to reconstruct finer spatial details. The proposed\nmodel has been evaluated on three public compressed video super-resolution\ndatasets, with results demonstrating its effectiveness when compared to\nexisting works in terms of super-resolution performance (up to a 0.14dB gain in\nPSNR over the second-best model) and complexity."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-791",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14378",
    "b_title":[
      "Extremal Self-Dual Codes and Linear Complementary Dual Codes from Double\n  Circulant Codes"
    ],
    "b_abstract":[
      "This paper explores extremal self-dual double circulant (DC) codes and linear\ncomplementary dual (LCD) codes of arbitrary length over the Galois field\n$\\mathbb F_2$. We establish the sufficient and necessary conditions for DC\ncodes and bordered DC codes to be self-dual and identify the conditions for\nself-dual DC codes of length up to 44 to be extremal or non-extremal.\nAdditionally, The self-duality and extremality between DC codes and bordered DC\ncodes are also examined. Finally, sufficient conditions for bordered DC codes\nto be LCD codes over $\\mathbb F_2$ under Euclidean inner product are presented."
    ],
    "b_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.04578",
    "c_title":[
      "Ludwig-Soret microscopy with vibrational photothermal effect"
    ],
    "c_abstract":[
      "Vibrational microscopy provides label-free, bond-selective chemical contrast\nby detecting molecular vibrations, making it invaluable for biomedical\nresearch. While conventional methods rely on the direct detection of Raman\nscattering or infrared absorption, recently developed vibrational photothermal\n(ViP) microscopy achieves chemical contrast indirectly through refractive index\n(RI) changes. This indirect approach enables unique imaging capabilities beyond\ntraditional chemical imaging. Here, we introduce a novel application of ViP\nmicroscopy: label-free intracellular thermophoretic (Soret) imaging, which\nvisualizes biomolecular transport driven by temperature gradients. ViP-induced\nSoret (ViPS) imaging leverages a steady-state temperature distribution\ngenerated by optical heating through vibrational photothermal effect, combined\nwith time-resolved RI imaging via optical diffraction tomography (ODT). Using\nViPS imaging, we measured thermophoretic behavior in living COS7 cells,\ndetermining intracellular diffusion and Soret coefficients. Notably, we\nobserved a reversed direction of molecular transport (negative Soret effect) in\nthe cytoplasm compared to the nucleus, possibly driven by\nthermophoresis-induced diffusiophoresis. Furthermore, time-lapse imaging under\nCO2-depleted conditions revealed a remarkable reduction in thermophoretic\nactivity, suggesting glass formation during the dying process, likely due to\npolymer aggregation. ViPS imaging represents a new frontier in intracellular\nthermophoretic studies, expanding the capabilities of vibrational microscopy."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-792",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10537",
    "b_title":[
      "Divisi: Interactive Search and Visualization for Scalable Exploratory\n  Subgroup Analysis"
    ],
    "b_abstract":[
      "Analyzing data subgroups is a common data science task to build intuition\nabout a dataset and identify areas to improve model performance. However,\nsubgroup analysis is prohibitively difficult in datasets with many features,\nand existing tools limit unexpected discoveries by relying on user-defined or\nstatic subgroups. We propose exploratory subgroup analysis as a set of tasks in\nwhich practitioners discover, evaluate, and curate interesting subgroups to\nbuild understanding about datasets and models. To support these tasks we\nintroduce Divisi, an interactive notebook-based tool underpinned by a fast\napproximate subgroup discovery algorithm. Divisi's interface allows data\nscientists to interactively re-rank and refine subgroups and to visualize their\noverlap and coverage in the novel Subgroup Map. Through a think-aloud study\nwith 13 practitioners, we find that Divisi can help uncover surprising patterns\nin data features and their interactions, and that it encourages more thorough\nexploration of subtypes in complex data."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16492",
    "c_title":[
      "Cosmic Bulk Flow Analysis in Modified Gravity Theories: $f(R)$ and\n  Perturbed $f(R)$ Models with Neutrino Coupling"
    ],
    "c_abstract":[
      "In this study, we explore the characteristics of bulk flow across various\nredshift ranges within the frameworks of $f(R)$ gravity, perturbed $f(R)$\ngravity, and perturbed $f(R)$ gravity coupled with neutrinos. Our investigation\nreveals profound insights into large-scale cosmic flows and their interactions\nwith major cosmic structures, such as the Sloan Great Wall (SGW) and the King\nGhidorah Supercluster (KGSc). We find that incorporating neutrinos into the\nperturbed $f(R)$ gravity model results in a substantial increase in bulk flow\nvelocities across all redshifts, with notable enhancements in the higher\nredshift ranges, where velocities can exceed $3000 \\, \\mathrm{km\/s}$ in the\n$0.8 < z < 1.4$ range. Moreover, the direction of the bulk flow in this model\nclosely aligns with the dark energy dipole, especially at redshifts $z > 0.4$,\nshowing near-perfect congruence with cosmic superclusters. This suggests a\nsignificant interaction between neutrinos and cosmic structures, influencing\ncosmic acceleration. At lower redshifts, such as $0.1 < z < 0.2$, the bulk flow\naligns with the SGW, while in the $0.4 < z < 0.6$ range, it aligns with the\nKGSc. In the low redshift range $0.001 < z < 0.016$, although velocities are\nlower, neutrinos still subtly increase the bulk flow velocity and maintain\nalignment with nearby cosmic structures, like the Local Supercluster. Our\nresults underscore the critical role of neutrinos in shaping cosmic flows and\noffer new insights into the interplay between dark energy, neutrinos, and\nmodified gravity models."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-793",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09440",
    "b_title":[
      "A multi-class non-local macroscopic model with time delay for mixed\n  autonomous \/ human-driven traffic"
    ],
    "b_abstract":[
      "In this paper, we present a class of systems of non-local conservation laws\nin one space-dimension incorporating time delay, which can be used to\ninvestigate the interaction between autonomous and human-driven vehicles, each\ncharacterized by a different reaction time and interaction range. We construct\napproximate solutions using a Hilliges-Weidlich scheme and we provide uniform L\n$\\infty$ and BV estimates which ensure the convergence of the scheme, thus\nobtaining existence of entropy weak solutions of bounded variation. Uniqueness\nfollows from an L 1 stability result derived from the entropy condition.\nAdditionally, we provide numerical simulations to illustrate applications to\nmixed autonomous \/ human-driven traffic flow modeling. In particular, we show\nthat the presence of autonomous vehicles improves overall traffic flow and\nstability."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.AP",
        "math.NA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15623",
    "c_title":[
      "Dynamic Knowledge Selector and Evaluator for recommendation with\n  Knowledge Graph"
    ],
    "c_abstract":[
      "In recent years recommendation systems typically employ the edge information\nprovided by knowledge graphs combined with the advantages of high-order\nconnectivity of graph networks in the recommendation field. However, this\nmethod is limited by the sparsity of labels, cannot learn the graph structure\nwell, and a large number of noisy entities in the knowledge graph will affect\nthe accuracy of the recommendation results. In order to alleviate the above\nproblems, we propose a dynamic knowledge-selecting and evaluating method guided\nby collaborative signals to distill information in the knowledge graph.\nSpecifically, we use a Chain Route Evaluator to evaluate the contributions of\ndifferent neighborhoods for the recommendation task and employ a Knowledge\nSelector strategy to filter the less informative knowledge before evaluating.\nWe conduct baseline model comparison and experimental ablation evaluations on\nthree public datasets. The experiments demonstrate that our proposed model\noutperforms current state-of-the-art baseline models, and each modules\neffectiveness in our model is demonstrated through ablation experiments."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-794",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04866",
    "b_title":[
      "Identifying Flare Locations Through Exoplanet Transit Occultations"
    ],
    "b_abstract":[
      "M dwarfs are the most common stars in the galaxy, with long lifespans, a high\noccurrence rate of rocky planets, and close-in habitable zones. However, high\nstellar activity in the form of frequent flaring and any associated coronal\nmass ejections may drive atmospheric escape with the bombardment of radiation\nand high-energy particles, drastically impacting the habitability of these\nsystems. The stellar latitude where flares and coronal mass ejections occur\ndetermines the space weather that exoplanets are subject to, with high-energy\nparticle events associated with equatorial flares producing significant\natmospheric erosion. However, the flaring latitudes for M dwarfs remain largely\nunconstrained. To aid in the effort to locate these flaring regions we explore\nthe applicability of flare occultations using optical photometry to identify\nthe latitudes of flares. As a planet transits in front of an ongoing flare the\ntiming and geometry of the transit can be used to constrain the latitude and\nlongitude of the flare. We predict the probability of detecting an occultation\nfor known transiting planets and eclipsing binaries. From this, we estimate\n3-22 detectable occultations exist within the TESS primary mission photometry,\nwith the majority occurring in eclipsing binary observations. To demonstrate\nthis technique, we analyze a candidate flare occultation event for the\neclipsing binary CM Draconis."
    ],
    "b_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14250",
    "c_title":[
      "A Parallel Hybrid Action Space Reinforcement Learning Model for\n  Real-world Adaptive Traffic Signal Control"
    ],
    "c_abstract":[
      "Adaptive traffic signal control (ATSC) can effectively reduce vehicle travel\ntimes by dynamically adjusting signal timings but poses a critical challenge in\nreal-world scenarios due to the complexity of real-time decision-making in\ndynamic and uncertain traffic conditions. The burgeoning field of intelligent\ntransportation systems, bolstered by artificial intelligence techniques and\nextensive data availability, offers new prospects for the implementation of\nATSC. In this study, we introduce a parallel hybrid action space reinforcement\nlearning model (PH-DDPG) that optimizes traffic signal phase and duration of\ntraffic signals simultaneously, eliminating the need for sequential\ndecision-making seen in traditional two-stage models. Our model features a\ntask-specific parallel hybrid action space tailored for adaptive traffic\ncontrol, which directly outputs discrete phase selections and their associated\ncontinuous duration parameters concurrently, thereby inherently addressing\ndynamic traffic adaptation through unified parametric optimization. %Our model\nfeatures a unique parallel hybrid action space that allows for the simultaneous\noutput of each action and its optimal parameters, streamlining the\ndecision-making process. Furthermore, to ascertain the robustness and\neffectiveness of this approach, we executed ablation studies focusing on the\nutilization of a random action parameter mask within the critic network, which\ndecouples the parameter space for individual actions, facilitating the use of\npreferable parameters for each action. The results from these studies confirm\nthe efficacy of this method, distinctly enhancing real-world applicability"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-795",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10559",
    "b_title":[
      "SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in\n  3D MRIs of the Knee Joint"
    ],
    "b_abstract":[
      "Accurate morphometric assessment of cartilage-such as thickness\/volume-via\nMRI is essential for monitoring knee osteoarthritis. Segmenting cartilage\nremains challenging and dependent on extensive expert-annotated datasets, which\nare heavily subjected to inter-reader variability. Recent advancements in\nVisual Foundational Models (VFM), especially memory-based approaches, offer\nopportunities for improving generalizability and robustness. This study\nintroduces a deep learning (DL) method for cartilage and meniscus segmentation\nfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awareness\nand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) during\ntraining and applied a segmentation mask propagation technique to enhance\nannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, two\nautomatic transformer-based models (SaMRI2D and SaMRI3D), and a\ntransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from\n270 patients using public and internal datasets and evaluated on 57 external\ncases, including multi-radiologist annotations and different data acquisitions.\nModel performance was assessed against reference standards using Dice Score\n(DSC) and Intersection over Union (IoU), with additional morphometric\nevaluations to further quantify segmentation accuracy. SAMRI-2 model, trained\nwith HSS, outperformed all other models, achieving an average DSC improvement\nof 5 points, with a peak improvement of 12 points for tibial cartilage. It also\ndemonstrated the lowest cartilage thickness errors, reducing discrepancies by\nup to threefold. Notably, SAMRI-2 maintained high performance with as few as\nthree user clicks per volume, reducing annotation effort while ensuring\nanatomical precision. This memory-based VFM with spatial awareness offers a\nnovel approach for reliable AI-assisted knee MRI segmentation, advancing DL in\nmusculoskeletal imaging."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05463",
    "c_title":[
      "Search for Higgs boson exotic decays into Lorentz-boosted light bosons\n  in the four-$\\tau$ final state at $\\sqrt{s}=13$ TeV with the ATLAS detector"
    ],
    "c_abstract":[
      "A search for exotic decays of the Higgs boson into a pair of low-mass scalars\nthat subsequently decay into $\\tau$-leptons, $H\\rightarrow aa\\rightarrow\n\\tau^+\\tau^-\\tau^+\\tau^-$, is presented. In models with Yukawa-like couplings,\nthe decay to $\\tau$-leptons is favoured for light $a$-bosons, with mass in the\nrange of $2m_{\\tau} < m_a < 2m_{b}$. Results are presented in the range of\n$4\\,\\mathrm{GeV} < m_a < 15\\,\\mathrm{GeV} $ using the $140\\,\\mathrm{fb}^{-1}$\nof proton-proton collisions at $\\sqrt{s}=13$ TeV recorded with the ATLAS\ndetector during Run 2 of the Large Hadron Collider. This search focuses on\ndi-$\\tau$ pairs where one of the $\\tau$-leptons decays to hadrons and\nneutrinos, and the other decays to a muon and neutrinos. In this mass range,\nthe $a\\rightarrow \\tau^+\\tau^-$ is Lorentz-boosted and a dedicated muon removal\ntechnique is used to reconstruct the di-$\\tau$ pairs. No significant excess\nabove the Standard Model background prediction is observed. Upper limits on\n$(\\sigma(H)\/\\sigma_{\\mathrm{SM}}(H))\\times \\mathcal{B}(H\\rightarrow\naa\\rightarrow 4\\tau)$ at $95\\%$ confidence level are provided, ranging from\n$0.03$ to $0.10$ depending on the $a$-boson mass."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-796",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06785",
    "b_title":[
      "3DCoMPaT200: Language-Grounded Compositional Understanding of Parts and\n  Materials of 3D Shapes"
    ],
    "b_abstract":[
      "Understanding objects in 3D at the part level is essential for humans and\nrobots to navigate and interact with the environment. Current datasets for\npart-level 3D object understanding encompass a limited range of categories. For\ninstance, the ShapeNet-Part and PartNet datasets only include 16, and 24 object\ncategories respectively. The 3DCoMPaT dataset, specifically designed for\ncompositional understanding of parts and materials, contains only 42 object\ncategories. To foster richer and fine-grained part-level 3D understanding, we\nintroduce 3DCoMPaT200, a large-scale dataset tailored for compositional\nunderstanding of object parts and materials, with 200 object categories with\n$\\approx$5 times larger object vocabulary compared to 3DCoMPaT and $\\approx$ 4\ntimes larger part categories. Concretely, 3DCoMPaT200 significantly expands\nupon 3DCoMPaT, featuring 1,031 fine-grained part categories and 293 distinct\nmaterial classes for compositional application to 3D object parts.\nAdditionally, to address the complexities of compositional 3D modeling, we\npropose a novel task of Compositional Part Shape Retrieval using ULIP to\nprovide a strong 3D foundational model for 3D Compositional Understanding. This\nmethod evaluates the model shape retrieval performance given one, three, or six\nparts described in text format. These results show that the model's performance\nimproves with an increasing number of style compositions, highlighting the\ncritical role of the compositional dataset. Such results underscore the\ndataset's effectiveness in enhancing models' capability to understand complex\n3D shapes from a compositional perspective. Code and Data can be found at\nhttp:\/\/github.com\/3DCoMPaT200\/3DCoMPaT200"
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01898",
    "c_title":[
      "Dynamical Solution to the Eta Problem in Spectator Field Models"
    ],
    "c_abstract":[
      "We study a class of spectator field models that addresses the eta problem\nwhile providing a natural explanation for the observed slight deviation of the\nspectrum of curvature perturbations from scale-invariance. In particular, we\nanalyze the effects of quantum corrections on the quadratic potential of the\nspectator field given by its gravitational coupling to the Ricci scalar and the\ninflaton energy, so-called the Hubble-induced mass term. These quantum\ncorrections create a minimum around which the potential is flatter and to which\nthe spectator field is attracted. We demonstrate that this attractor dynamics\ncan naturally generate the observed slightly red-tilted spectrum of curvature\nperturbations. Furthermore, focusing on a curvaton model with a quadratic\nvacuum potential, we compute the primordial non-Gaussianity parameter\n$f_{\\text{NL}}$ and derive a predictive relationship between $f_{\\text{NL}}$\nand the running of the scalar spectral index. This relationship serves as a\ntestable signature of the model. Finally, we extend the idea to a broader class\nof models where the spectator field is an angular component of a complex scalar\nfield."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-797",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11098",
    "b_title":[
      "AI-assisted hyper-dimensional broadband quantum memory with efficiency\n  above 90% in warm atoms"
    ],
    "b_abstract":[
      "High-dimensional broadband quantum memory significantly expands quantum\ninformation processing capabilities, but the memory efficiency becomes\ninsufficient when extended to high dimensions. We demonstrate an efficient\nquantum memorize for hyper-dimensional photons encoded with orbital angular\nmomentum (OAM) and spin angular momentum (SAM). OAM information is encoded from\n-5 to +5, combined with spin angular momentum encoding, enabling up to 22\ndimensions. To ensure high memory efficiency, an artificial intelligent\nalgorithm, a modified Differential Evolution (DE) algorithm using Chebyshev\nsampling, is developed to obtain a perfect signal-control waveform matching.\nMemory efficiency is experimentally achieved 92% for single-mode Gaussian\nsignal, 91% for information dimension of 6 and 80% for dimensional number to\n22. The fidelity is achieved up to 99% for single-mode Gaussian signal, 96% for\nOAM information and 97% for SAM one, which is far beyond no-cloning limitation.\nOur results demonstrate superior performance and potential applications in\nhigh-dimensional quantum information processing. This achievement provides a\ncrucial foundation for future quantum communication and quantum computing."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2502.08290",
    "c_title":[
      "Investigating Solar Wind Outflows from Open-Closed Magnetic Field\n  Structures Using Coordinated Solar Orbiter and Hinode Observations"
    ],
    "c_abstract":[
      "ESA\/NASA's Solar Orbiter (SO) allows us to study the solar corona at closer\ndistances and from different perspectives, which helps us to gain significant\ninsights into the origins of the solar wind. In this work, we present the\nanalysis of solar wind outflows from two locations: a narrow open-field\ncorridor and a small, mid-latitude coronal hole. These outflows were observed\noff-limb by the Metis coronagraph onboard SO and on-disk by the Extreme\nUltraviolet Imaging Spectrometer (EIS) onboard Hinode. Magnetic field\nextrapolations suggest that the upflow regions seen in EIS were the sources of\nthe outflowing solar wind observed with Metis. We find that the plasma\nassociated with the narrow open-field corridor has higher electron densities\nand lower outflow velocities compared to the coronal hole plasma in the middle\ncorona, even though the plasma properties of the two source regions in the low\ncorona are found to be relatively similar. The speed of solar wind from the\nopen-field corridor also shows no correlation with the magnetic field expansion\nfactor, unlike the coronal hole. These pronounced differences at higher\naltitudes may arise from the dynamic nature of the low-middle corona, in which\nreconnection can readily occur and may play an important role in driving solar\nwind variability."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-798",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19107",
    "b_title":[
      "The Shady Light of Art Automation"
    ],
    "b_abstract":[
      "Generative artificial intelligence (generative AI) has entered the mainstream\nculture and become a subject of extensive academic investigation. However, the\ncharacter and background of its impact on art require subtler scrutiny and more\nnuanced contextualization. This paper summarizes a broader study of the roles\nthat AI's conceptual and ideological substrata play in influencing art notions.\nThe focus is on divergent but coalescing and often questionable ideas, values,\nand political views that generative AI and other art-related AI technologies\npropagate from the computer science and AI\/tech industry to the contemporary\nart and culture. The paper maps the main areas of this complex relationship and\nconcisely critiques their key aspects."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14738",
    "c_title":[
      "DESI DR2 Results II: Measurements of Baryon Acoustic Oscillations and\n  Cosmological Constraints"
    ],
    "c_abstract":[
      "We present baryon acoustic oscillation (BAO) measurements from more than 14\nmillion galaxies and quasars drawn from the Dark Energy Spectroscopic\nInstrument (DESI) Data Release 2 (DR2), based on three years of operation. For\ncosmology inference, these galaxy measurements are combined with DESI\nLyman-$\\alpha$ forest BAO results presented in a companion paper. The DR2 BAO\nresults are consistent with DESI DR1 and SDSS, and their distance-redshift\nrelationship matches those from recent compilations of supernovae (SNe) over\nthe same redshift range. The results are well described by a flat $\\Lambda$CDM\nmodel, but the parameters preferred by BAO are in mild, $2.3\\sigma$ tension\nwith those determined from the cosmic microwave background (CMB), although the\nDESI results are consistent with the acoustic angular scale $\\theta_*$ that is\nwell-measured by Planck. This tension is alleviated by dark energy with a\ntime-evolving equation of state parametrized by $w_0$ and $w_a$, which provides\na better fit to the data, with a favored solution in the quadrant with $w_0>-1$\nand $w_a<0$. This solution is preferred over $\\Lambda$CDM at $3.1\\sigma$ for\nthe combination of DESI BAO and CMB data. When also including SNe, the\npreference for a dynamical dark energy model over $\\Lambda$CDM ranges from\n$2.8-4.2\\sigma$ depending on which SNe sample is used. We present evidence from\nother data combinations which also favor the same behavior at high\nsignificance. From the combination of DESI and CMB we derive 95% upper limits\non the sum of neutrino masses, finding $\\sum m_\\nu<0.064$ eV assuming\n$\\Lambda$CDM and $\\sum m_\\nu<0.16$ eV in the $w_0w_a$ model. Unless there is an\nunknown systematic error associated with one or more datasets, it is clear that\n$\\Lambda$CDM is being challenged by the combination of DESI BAO with other\nmeasurements and that dynamical dark energy offers a possible solution."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-799",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16011",
    "b_title":[
      "MEL: Legal Spanish Language Model"
    ],
    "b_abstract":[
      "Legal texts, characterized by complex and specialized terminology, present a\nsignificant challenge for Language Models. Adding an underrepresented language,\nsuch as Spanish, to the mix makes it even more challenging. While pre-trained\nmodels like XLM-RoBERTa have shown capabilities in handling multilingual\ncorpora, their performance on domain specific documents remains underexplored.\nThis paper presents the development and evaluation of MEL, a legal language\nmodel based on XLM-RoBERTa-large, fine-tuned on legal documents such as BOE\n(Bolet\\'in Oficial del Estado, the Spanish oficial report of laws) and congress\ntexts. We detail the data collection, processing, training, and evaluation\nprocesses. Evaluation benchmarks show a significant improvement over baseline\nmodels in understanding the legal Spanish language. We also present case\nstudies demonstrating the model's application to new legal texts, highlighting\nits potential to perform top results over different NLP tasks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09107",
    "c_title":[
      "Anosov deformations of Barbot representations"
    ],
    "c_abstract":[
      "We construct for each conformal structure on a closed orientable surface of\ngenus at least 2 a proper slice in the character variety of representations of\nthe associated surface group into SL(3,R) that belongs to the Barbot component\nand show that the corresponding representations are Borel Anosov. We describe a\nfibered geometric structure in the space of full flags associated with these\nrepresentations."
    ],
    "c_categories":[
      [
        "math.DG",
        "math.DS",
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-800",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00447",
    "b_title":[
      "Resolving the Problem of Multiple Control Parameters in Optimized\n  Borel-Type Summation"
    ],
    "b_abstract":[
      "One of the most often used methods of summing divergent series in physics is\nthe Borel-type summation with control parameters improving convergence, which\nare defined by some optimization conditions. The well known annoying problem in\nthis procedure is the occurrence of multiple solutions for control parameters.\nWe suggest a method for resolving this problem, based on the minimization of\ncost functional. Control parameters can be introduced by employing the\nBorel-Leroy or Mittag-Leffler transforms. Also, two novel transformations are\nproposed using fractional integrals and fractional derivatives. New cost\nfunctionals are advanced, based on lasso and ridge selection criteria, and\ntheir performance is studied for a number of models. The developed method is\nshown to provide good accuracy for the calculated quantities."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "hep-ph",
        "math-ph",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03637",
    "c_title":[
      "4D Radar Ground Truth Augmentation with LiDAR-to-4D Radar Data Synthesis"
    ],
    "c_abstract":[
      "Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object\ndetection, as it enhances object density by leveraging ground truth bounding\nboxes (GT bboxes). However, directly applying GT-Aug to 4D Radar tensor data\noverlooks important measurements outside the GT bboxes-such as\nsidelobes-leading to synthetic distributions that deviate from real-world 4D\nRadar data. To address this limitation, we propose 4D Radar Ground Truth\nAugmentation (4DR GT-Aug). Our approach first augments LiDAR data and then\nconverts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS)\nmodule, which explicitly accounts for measurements both inside and outside GT\nbboxes. In doing so, it produces 4D Radar data distributions that more closely\nresemble real-world measurements, thereby improving object detection accuracy.\nExperiments on the K-Radar dataset show that the proposed method achieves\nimproved performance compared to conventional GT-Aug in object detection for 4D\nRadar. The implementation code is available at\nhttps:\/\/github.com\/kaist-avelab\/K-Radar."
    ],
    "c_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-801",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05544",
    "b_title":[
      "Quantum kinetic theory of semiclassical Boltzmann equation with side\n  jump and skew scattering"
    ],
    "b_abstract":[
      "The semiclassical Boltzmann equation is widely used to study transport\neffects. It is usually introduced in an intuitive fashion, which could cause\nconfusion, e.g., over the collision integral with skew scattering. Actually,\nthe Boltzmann equation is closely linked to the quantum density matrix,\nalthough term-by-term correspondence between the two is yet to be established.\nHere we start from the quantum Liouville equation in the interactive picture\nand show that the diagonal components of the equation yield the Boltzmann\nequation in homogeneous systems in an applied uniform electric field in the\nsemiclassical limit, while the off-diagonal components give the anomalous\nvelocity induced by Berry curvature and the side-jump velocity. The\nskew-scattering contribution is obtained when we include corrections beyond the\nfirst-Born approximation. The result derived from the denstiy matrix agrees\nwith the semiclassical one from wave-packet analysis, showing that the\nsemiclassical Boltzmann equation is more than an equation built from intuition,\nand it can be derived with the density matrix. Our work further clarifies the\norigin of the equation and eliminates the puzzles surrounding it."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18203",
    "c_title":[
      "Joint Design and Pricing of Extended Warranties for Multiple Automobiles\n  with Different Price Bands"
    ],
    "c_abstract":[
      "Extended warranties (EWs) are significant source of revenue for\ncapital-intensive products like automobiles. Such products consist of multiple\nsubsystems, providing flexibility in EW customization, for example, bundling a\ntailored set of subsystems in an EW contract. This, in turn, enables the\ncreation of a service menu with different EW contract options. From the\nperspective of a third-party EW provider servicing a fleet of automobile\nbrands, we develop a novel model to jointly optimize the design and pricing of\nEWs in order to maximize the profit. Specifically, the problem is to determine\nwhich contracts should be included in the EW menu and identify the appropriate\nprice for each contract. As the complexity of the joint optimization problem\nincreases exponentially with the number of subsystems, two solution approaches\nare devised to solve the problem. The first approach is based on a\nmixed-integer second-order cone programming reformulation, which guarantees\noptimality but is applicable only for a small number of subsystems. The second\napproach utilizes a two-step iteration process, offering enhanced computational\nefficiency in scenarios with a large number of subsystems. Through numerical\nexperiments, the effectiveness of our model is validated, particularly in\nscenarios characterized by high failure rates and a large number of subsystems."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-802",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09358",
    "b_title":[
      "RetSTA: An LLM-Based Approach for Standardizing Clinical Fundus Image\n  Reports"
    ],
    "b_abstract":[
      "Standardization of clinical reports is crucial for improving the quality of\nhealthcare and facilitating data integration. The lack of unified standards,\nincluding format, terminology, and style, is a great challenge in clinical\nfundus diagnostic reports, which increases the difficulty for large language\nmodels (LLMs) to understand the data. To address this, we construct a bilingual\nstandard terminology, containing fundus clinical terms and commonly used\ndescriptions in clinical diagnosis. Then, we establish two models,\nRetSTA-7B-Zero and RetSTA-7B. RetSTA-7B-Zero, fine-tuned on an augmented\ndataset simulating clinical scenarios, demonstrates powerful standardization\nbehaviors. However, it encounters a challenge of limitation to cover a wider\nrange of diseases. To further enhance standardization performance, we build\nRetSTA-7B, which integrates a substantial amount of standardized data generated\nby RetSTA-7B-Zero along with corresponding English data, covering diverse\ncomplex clinical scenarios and achieving report-level standardization for the\nfirst time. Experimental results demonstrate that RetSTA-7B outperforms other\ncompared LLMs in bilingual standardization task, which validates its superior\nperformance and generalizability. The checkpoints are available at\nhttps:\/\/github.com\/AB-Story\/RetSTA-7B."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06835",
    "c_title":[
      "Interplay between Multipolar Order and Multipole-Induced\n  Superconductivity in PrTi$_{2}$Al$_{20}$"
    ],
    "c_abstract":[
      "Multipolar moments entail a new route to tackle frontier problems in\nsuperconductivity (SC). A key progress in the search for multipolar SC is the\ndiscovery of Pr$Tr_2$Al$_{20}$ ($Tr =$ Ti, V), which possesses quadrupolar and\noctupolar but no magnetic dipolar moments. The Kondo entanglement of these\nmultipolar moments with conduction electrons leads to exotic SC within the\nmultipolar ordered phase, though the precise nature of the SC remains\nunexplored. We experimentally investigate the SC gap structure of SC in\nPrTi$_{2}$Al$_{20}$ and its La-doping evolution. Our results indicate\ndeviations from a single $s$-wave gap, instead favoring nodal $d$-wave or\nmultiple gaps. While the SC is robust against La dilution, the SC gap structure\nchanges with minimal La doping, coinciding with a sharp change in the\nferroquadrupolar (FQ) order. This suggests an intimate link between the\nquadrupolar order parameter and SC pairing, providing insight into the\ncoexistence of SC with multipolar order."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-803",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17164",
    "b_title":[
      "Leading-order deflection of particles by a moving Schwarzschild lens\n  with a two-dimensional velocity"
    ],
    "b_abstract":[
      "The gravitational deflection effect of relativistic massive and massless\nparticles up to the first post-Minkowskian order caused by a moving\nSchwarzschild black hole with a two-dimensional equatorial velocity, which\ncontains the radial and transversal components, is studied analytically, and a\nnew unified formula for the deflection angle is achieved. The expression of the\nangle matches well with the results of the weak deflection of relativistic\nparticles induced by a radially moving Schwarzschild source given in the\nliterature, when the transversal component of the lens velocity vanishes. The\njoint velocity effect, which consists of the influences of the transversal and\nradial motions of the lens on the leading-order Schwarzschild deflection of the\nmassive particles and light, is then discussed in the context of general\nrelativity. We analyze the order of magnitude of this kinematical effect and\nevaluate the possibility of its astronomical detection subsequently."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03816",
    "c_title":[
      "The optical and infrared are connected"
    ],
    "c_abstract":[
      "Galaxies are often modelled as composites of separable components with\ndistinct spectral signatures, implying that different wavelength ranges are\nonly weakly correlated. They are not. We present a data-driven model which\nexploits subtle correlations between physical processes to accurately predict\ninfrared (IR) WISE photometry from a neural summary of optical SDSS spectra.\nThe model achieves accuracies of $\\chi^2_N \\approx 1$ for all photometric bands\nin WISE, as well as good colors. We are also able to tightly constrain\ntypically IR-derived properties, e.g. the bolometric luminosities of AGN and\ndust parameters such as $\\mathrm{q_{PAH}}$. We find that current SED-fitting\nmethods are incapable of making comparable predictions, and that model\nmisspecification often leads to correlated biases in star-formation rates and\nAGN luminosities. To help improve SED models, we determine what features of the\noptical spectrum are responsible for our improved predictions, and identify\nseveral lines (CaII, SrII, FeI, [OII] and H$\\alpha$), which point to the\ncomplex chronology of star formation and chemical enrichment being incorrectly\nmodelled."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-804",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17618",
    "b_title":[
      "Periodic Boundary Conditions for Bosonic Path Integral Molecular\n  Dynamics"
    ],
    "b_abstract":[
      "We develop an algorithm for bosonic path integral molecular dynamics (PIMD)\nsimulations with periodic boundary conditions (PBC) that scales quadratically\nwith the number of particles. Path integral methods are a powerful tool to\nsimulate bosonic condensed phases, which exhibit fundamental physical phenomena\nsuch as Bose--Einstein condensation and superfluidity. Recently, we developed a\nquadratic scaling algorithm for bosonic PIMD, but employed an ad hoc treatment\nof PBC. Here we rigorously enforce PBC in bosonic PIMD. It requires summing\nover the spring energies of all periodic images in the partition function, and\na naive implementation scales exponentially with the system size. We present an\nalgorithm for bosonic PIMD simulations of periodic systems that scales only\nquadratically. We benchmark our implementation on the free Bose gas and a model\nsystem of cold atoms in optical lattices. We also study an approximate\ntreatment of PBC based on the minimum-image convention, and derive a numerical\ncriterion to determine when it is valid."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas",
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08279",
    "c_title":[
      "SmartEraser: Remove Anything from Images using Masked-Region Guidance"
    ],
    "c_abstract":[
      "Object removal has so far been dominated by the mask-and-inpaint paradigm,\nwhere the masked region is excluded from the input, leaving models relying on\nunmasked areas to inpaint the missing region. However, this approach lacks\ncontextual information for the masked area, often resulting in unstable\nperformance. In this work, we introduce SmartEraser, built with a new removing\nparadigm called Masked-Region Guidance. This paradigm retains the masked region\nin the input, using it as guidance for the removal process. It offers several\ndistinct advantages: (a) it guides the model to accurately identify the object\nto be removed, preventing its regeneration in the output; (b) since the user\nmask often extends beyond the object itself, it aids in preserving the\nsurrounding context in the final result. Leveraging this new paradigm, we\npresent Syn4Removal, a large-scale object removal dataset, where instance\nsegmentation data is used to copy and paste objects onto images as removal\ntargets, with the original images serving as ground truths. Experimental\nresults demonstrate that SmartEraser significantly outperforms existing\nmethods, achieving superior performance in object removal, especially in\ncomplex scenes with intricate compositions."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-805",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17101",
    "b_title":[
      "Numerical study of synaptic behavior in amorphous HfO2-based\n  ferroelectric-like FETs generated by voltage-driven ion migration"
    ],
    "b_abstract":[
      "The continuous effort in making artificial neural networks more alike to\nhuman brain calls for the hardware elements to implement biological\nsynapse-like functionalities. The recent experimental demonstration of\nferroelectric-like FETs promises low-power operation as compared to the\nconventional ferroelectric switching devices. This work presents an in-house\nnumerical tool, which self-consistently solves the electrostatics and\ntime-dependent electronic and ionic transport. The tool is exploited to analyze\nthe effect that various physical parameters such as mobility and ion\nconcentration could have on the design of the ferroelectric-like FETs. Their\nsuitability in emulating different functions of the biological synapses is also\ndemonstrated."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19701",
    "c_title":[
      "Extending the Hegselmann-Krause Model of Opinion Dynamics to include AI\n  Oracles"
    ],
    "c_abstract":[
      "The Hegselmann-Krause (HK) model of opinion dynamics describes how opinions\nheld by individuals in a community change over time in response to the opinions\nof others and their access to the true value, T, to which these opinions\nrelate. Here, I extend the simple HK model to incorporate an Artificially\nIntelligent (AI) Oracle that averages the opinions of members of the community.\nAgent-based simulations show that (1) if individuals only have access to the\nOracle (and not T), and incorporate the Oracle's opinion as they update their\nopinions, then all opinions will converge on a common value; (2) in contrast,\nif all individuals also have access to T, then all opinions will ultimately\nconverge to T, but the presence of an Oracle may delay the time to convergence;\n(3) if only some individuals have access to T, opinions may not converge to T,\nbut under certain conditions, universal access to the Oracle will guarantee\nconvergence to T; and (4) whether or not the Oracle only accesses the opinions\nof individuals who have access to T, or whether it accesses the opinions of\neveryone in the community, makes no marked difference to the extent to which\nthe average opinion differs from T."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-806",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14825",
    "b_title":[
      "Search for a heavy pseudoscalar Higgs boson decaying to a 125 GeV Higgs\n  boson and a Z boson in final states with two tau and two light leptons in\n  proton-proton collisions at $\\sqrt{s}$ = 13 TeV"
    ],
    "b_abstract":[
      "A search for a heavy pseudoscalar Higgs boson, A, decaying to a 125 GeV Higgs\nboson h and a Z boson is presented. The h boson is identified via its decay to\na pair of tau leptons, while the Z boson is identified via its decay to a pair\nof electrons or muons. The search targets the production of the A boson via the\ngluon-gluon fusion process, gg $\\to$ A, and in association with bottom quarks,\n$\\mathrm{b\\bar{b}}$A. The analysis uses a data sample corresponding to an\nintegrated luminosity of 138 fb$^{-1}$ collected with the CMS detector at the\nCERN LHC in proton-proton collisions at a centre-of-mass energy of $\\sqrt{s}$ =\n13 TeV. Constraints are set on the product of the cross sections of the A\nproduction mechanisms and the A $\\to$ Zh decay branching fraction. The observed\n(expected) upper limit at 95% confidence level ranges from 0.049 (0.060) pb to\n1.02 (0.79) pb for the gg $\\to$ A process and from 0.053 (0.059) pb to 0.79\n(0.61) pb for the $\\text{b}\\bar{\\text{b}}$A process in the probed range of the\nA boson mass, $m_\\text{A}$, from 225 GeV to 1 TeV. The results of the search\nare used to constrain parameters within the\n${\\text{M}_{\\text{h,EFT}}^{\\text{125}}}$ benchmark scenario of the minimal\nsupersymmetric extension of the standard model. Values of $\\tan\\beta$ below 2.2\nare excluded in this scenario at 95% confidence level for all $m_\\text{A}$\nvalues in the range from 225 to 350 GeV."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03035",
    "c_title":[
      "Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization\n  Degradation for Mathematical Reasoning"
    ],
    "c_abstract":[
      "Large language models have achieved significant advancements in complex\nmathematical reasoning benchmarks, such as MATH. However, their substantial\ncomputational requirements present challenges for practical deployment. Model\nquantization has emerged as an effective strategy to reduce memory usage and\ncomputational costs by employing lower precision and bit-width representations.\nIn this study, we systematically evaluate the impact of quantization on\nmathematical reasoning tasks. Our results demonstrate that aggressive\nquantization methods like AWQ and GPTQ introduce up to 32.39% accuracy\ndegradation (average 11.31%) on Llama-3 models, particularly in numerical\ncomputation and reasoning planning. To address this, we introduce a\nmultidimensional evaluation framework combining qualitative capability analysis\nand quantitative error assessment. We further develop targeted recovery\nstrategies, showing that fine-tuning quantized models on only 545 task-specific\nexamples for 3 minutes on 4 GPUs effectively restores reasoning capabilities to\nnear full-precision levels. Additionally, our error assessment pipeline\nachieves 98.9% accuracy in diagnosing and localizing errors across 3,366\nfailure cases, providing actionable insights for mitigating\nquantization-induced degradation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-807",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13005",
    "b_title":[
      "Bipolaron dynamics in the one-dimensional SSH model"
    ],
    "b_abstract":[
      "Characterizing bipolaron binding, and understanding how it depends on\nelectron-phonon interaction, is crucial to unraveling the nature of emergent\nmany-body states in strongly interacting electron-phonon systems. So far, most\nstudies of bipolarons have been limited to the Holstein model, in which the\ncoupling constant is momentum-independent. The paradigmatic example of\nmomentum-dependent electron-phonon interaction comes from the system in which\nphonon distortions modify electron hopping, the SSH model. Already individual\npolarons in the SSH model are richer than the Holstein model counterparts, and\nfeature a phase transition into the finite momentum ground state with\nincreasing electron-phonon interaction. In this paper, we use a variational\napproach to study bipolarons in the one-dimensional SSH model and discuss their\nground state, dispersion, and excitation spectra. We explore the full parameter\nrange of the system, including the adiabatic regime of slow phonons, which was\ninaccessible to previous theoretical studies. In agreement with earlier\nstudies, we find that in the anti-adiabatic strongly interacting regime,\nbipolarons have low effective mass. By contrast, in the adiabatic case, we find\nthat increasing electron-phonon interactions results in an exponential increase\nof the bipolaron mass. We establish the existence of multiple branches of bound\nexcited states of SSH bipolaron and discuss the signatures of these bound\nstates in dynamics. We show that in the anti-adiabatic regime, response\nfunctions obey a parity selection rule, that imposes symmetry constraints on\nthe excitation spectra and provides a clear signature of SSH bipolarons."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11898",
    "c_title":[
      "LLMs for Translation: Historical, Low-Resourced Languages and\n  Contemporary AI Models"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) have demonstrated remarkable adaptability in\nperforming various tasks, including machine translation (MT), without explicit\ntraining. Models such as OpenAI's GPT-4 and Google's Gemini are frequently\nevaluated on translation benchmarks and utilized as translation tools due to\ntheir high performance. This paper examines Gemini's performance in translating\nan 18th-century Ottoman Turkish manuscript, Prisoner of the Infidels: The\nMemoirs of Osman Agha of Timisoara, into English. The manuscript recounts the\nexperiences of Osman Agha, an Ottoman subject who spent 11 years as a prisoner\nof war in Austria, and includes his accounts of warfare and violence. Our\nanalysis reveals that Gemini's safety mechanisms flagged between 14 and 23\npercent of the manuscript as harmful, resulting in untranslated passages. These\nsafety settings, while effective in mitigating potential harm, hinder the\nmodel's ability to provide complete and accurate translations of historical\ntexts. Through real historical examples, this study highlights the inherent\nchallenges and limitations of current LLM safety implementations in the\nhandling of sensitive and context-rich materials. These real-world instances\nunderscore potential failures of LLMs in contemporary translation scenarios,\nwhere accurate and comprehensive translations are crucial-for example,\ntranslating the accounts of modern victims of war for legal proceedings or\nhumanitarian documentation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-808",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14754",
    "b_title":[
      "Kharitonov's Theorem with Degree Drop: a Wronskian Approach"
    ],
    "b_abstract":[
      "In this paper, we present a simplified proof of Kharitonov's Theorem, an\nimportant result on determining the Hurwitz stability of interval polynomials.\nOur new approach to the proof, which is based on the Wronskian of a pair of\npolynomials, is not only more elementary in comparison to known methods, but is\nable to handle the degree drop case with ease."
    ],
    "b_categories":[
      [
        "math.CA",
        "math.CV",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05254",
    "c_title":[
      "Distribution of singular values in large sample cross-covariance\n  matrices"
    ],
    "c_abstract":[
      "For two large matrices ${\\mathbf X}$ and ${\\mathbf Y}$ with Gaussian i.i.d.\\\nentries and dimensions $T\\times N_X$ and $T\\times N_Y$, respectively, we derive\nthe probability distribution of the singular values of $\\mathbf{X}^T\n\\mathbf{Y}$ in different parameter regimes. This extends the Marchenko-Pastur\nresult for the distribution of eigenvalues of empirical sample covariance\nmatrices to singular values of empirical cross-covariances. Our results will\nhelp to establish statistical significance of cross-correlations in many\ndata-science applications."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn",
        "math.ST",
        "physics.data-an",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-809",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09003",
    "b_title":[
      "RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach\n  for Large Language Models"
    ],
    "b_abstract":[
      "Supervised fine-tuning is a standard method for adapting pre-trained large\nlanguage models (LLMs) to downstream tasks. Quantization has been recently\nstudied as a post-training technique for efficient LLM deployment. To obtain\nquantized fine-tuned LLMs, conventional pipelines would first fine-tune the\npre-trained models, followed by post-training quantization. This often yields\nsuboptimal performance as it fails to leverage the synergy between fine-tuning\nand quantization. To effectively realize low-bit quantization of weights,\nactivations, and KV caches in LLMs, we propose an algorithm named Rotated\nStraight-Through-Estimator (RoSTE), which combines quantization-aware\nsupervised fine-tuning (QA-SFT) with an adaptive rotation strategy that\nidentifies an effective rotation configuration to reduce activation outliers.\nWe provide theoretical insights on RoSTE by analyzing its prediction error when\napplied to an overparameterized least square quantized training problem. Our\nfindings reveal that the prediction error is directly proportional to the\nquantization error of the converged weights, which can be effectively managed\nthrough an optimized rotation configuration. Experiments on Pythia, Qwen and\nLlama models of different sizes demonstrate the effectiveness of RoSTE.\nCompared to existing post-SFT quantization baselines, our method consistently\nachieves superior performances across various tasks and different LLM\narchitectures."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10023",
    "c_title":[
      "Spatially Multiplexed Interferometric Microscopy with one-dimensional\n  diffraction grating"
    ],
    "c_abstract":[
      "Digital holographic microscopy (DHM) applied to quantitative phase imaging\n(QPI) has been successfully demonstrated as a powerful label-free method to\nanalyse the optical properties of cells. Spatially multiplexed interferometric\nmicroscopy (SMIM) is a DHM technique that implements a common-path\ninterferometric layout in the embodiment of a standard microscope to achieve\nQPI. More concretely, SMIM introduces three minimal modifications: 1) replaces\nthe broadband illumination of the microscope by a coherent or partially\ncoherent light source, 2) divides the input plane into two or three regions for\ntransmission in parallel of both imaging and reference beams, and 3) includes a\none-dimensional diffraction grating or a beam splitter cube for holographic\nrecording. Hence, SMIM is a cost-effective, extremely simple, and highly stable\nmanner of converting a standard bright field microscope into a holographic one.\nThe goal of this contribution is to provide a review of the SMIM approaches\nimplemented using a one-dimensional (1D) diffraction grating, and highlight\nvast range of capabilities including super-resolved, reflective, transflective,\nnoise-reduced and single-shot slightly off-axis amplitude and phase imaging."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-810",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05797",
    "b_title":[
      "Self-generated time crystal in hybrid Josephson junctions"
    ],
    "b_abstract":[
      "Time crystals represent a non-equilibrium state of matter with broken\ntime-translation symmetry that repeats itself at regular time intervals. Though\ninitially envisioned as a self-generated and self-sustained periodic motion,\ntheir realization has usually required the utilization of external periodic\ninputs or modulations. While at first it looked like, for a time crystal to\nexist, the initial proposal had to be abandoned, the recent evidence of\ninherent time crystals is bringing back the idea of self-generated time crystal\nunder the spotlight. In this work, we demonstrate the appearance of a\nself-generated space-time crystalline order in hybrid Josephson junctions with\nthe ferromagnet interface without any external influence. The presence of the\nexchange and the Dzyaloshinskii-Moriya interactions in a ferromagnet with\nbroken structural inversion symmetry modifies the current phase relation and\nthe critical current due to the coupling between the magnetic moment and\nJosephson phase. This breaks the time translation symmetry leading to the\nappearance of the time-crystalline order in the spatiotemporal dependence of\nsuperconducting current, which evolves with the double of the modulation\nfrequency. Due to its unique origin and properties, this inherent time\ncrystalline order stands out from the commonly known classification of time\ncrystals into discrete and continuous ones. A self-generated time crystal is\ndemonstrated in two types of hybrid Josephson junctions: the\nsuperconductor-ferromagnet-superconductor on a topological insulator and the\nsuperconductor-three layer ferromagnet-superconductor. Further, we also show\nthat a recently developed magnetometry device that visualizes a supercurrent\nflow in the Josephson junction at the nanoscale can be used as a platform for\nexperimental detection of space-time crystalline order in hybrid Josephson\njunctions."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09429",
    "c_title":[
      "ADAGE: A generic two-layer framework for adaptive agent based modelling"
    ],
    "c_abstract":[
      "Agent-based models (ABMs) are valuable for modelling complex, potentially\nout-of-equilibria scenarios. However, ABMs have long suffered from the Lucas\ncritique, stating that agent behaviour should adapt to environmental changes.\nFurthermore, the environment itself often adapts to these behavioural changes,\ncreating a complex bi-level adaptation problem. Recent progress integrating\nmulti-agent reinforcement learning into ABMs introduces adaptive agent\nbehaviour, beginning to address the first part of this critique, however, the\napproaches are still relatively ad hoc, lacking a general formulation, and\nfurthermore, do not tackle the second aspect of simultaneously adapting\nenvironmental level characteristics in addition to the agent behaviours. In\nthis work, we develop a generic two-layer framework for ADaptive AGEnt based\nmodelling (ADAGE) for addressing these problems. This framework formalises the\nbi-level problem as a Stackelberg game with conditional behavioural policies,\nproviding a consolidated framework for adaptive agent-based modelling based on\nsolving a coupled set of non-linear equations. We demonstrate how this generic\napproach encapsulates several common (previously viewed as distinct) ABM tasks,\nsuch as policy design, calibration, scenario generation, and robust behavioural\nlearning under one unified framework. We provide example simulations on\nmultiple complex economic and financial environments, showing the strength of\nthe novel framework under these canonical settings, addressing long-standing\ncritiques of traditional ABMs."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "econ.GN",
        "q-fin.CP",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-811",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05366",
    "b_title":[
      "An effective estimation of multivariate density functions using\n  extended-beta kernels with Bayesian adaptive bandwidths"
    ],
    "b_abstract":[
      "Multivariate kernel density estimations have received much spate of interest.\nIn addition to conventional methods of (non-)classical associated-kernels for\n(un)bounded densities and bandwidth selections, the multiple extended-beta\nkernel (MEBK) estimators with Bayesian adaptive bandwidths are invested to gain\na deeper and better insight into the estimation of multivariate density\nfunctions. Being unimodal, the univariate extended-beta smoother has an\nadaptable compact support which is suitable for each dataset, always limited.\nThe support of the density MBEK estimator can be known or estimated by extreme\nvalues. Thus, asymptotical properties for the (non-)normalized estimators are\nestablished. Explicit and general choices of bandwidths using the flexible\nBayesian adaptive method are provided. Behavioural analyses, specifically\nundertaken on the sensitive edges of the estimator support, are studied and\ncompared to Gaussian and gamma kernel estimators. Finally, simulation studies\nand three applications on original and usual real-data sets of the proposed\nmethod yielded very interesting advantages with respect to its flexibility as\nwell as its universality."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11239",
    "c_title":[
      "Towards identifying possible fault-tolerant advantage of quantum linear\n  system algorithms in terms of space, time and energy"
    ],
    "c_abstract":[
      "Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law,\ncan offer superpolynomial speedups for certain problems. Yet its advantages in\nefficiency for tasks like machine learning remain under investigation, and\nquantum noise complicates resource estimations and classical comparisons. We\nprovide a detailed estimation of space, time, and energy resources for\nfault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL)\nalgorithm, a quantum linear system solver relevant to linear algebra and\nmachine learning. Excluding memory and data transfer, possible quantum\nadvantages over the classical conjugate gradient method could emerge at $N\n\\approx 2^{33} \\sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical\nqubits, ${O}(10^{12}\\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface\ncode fault-tolerance with three types of magic state distillation (15-1,\n116-12, 225-1). Key parameters include condition number, sparsity, and\nprecision $\\kappa, s\\approx{O}(10\\sim100)$, $\\epsilon\\sim0.01$, and physical\nerror $10^{-5}$. Our resource estimator adjusts $N, \\kappa, s, \\epsilon$,\nproviding a map of quantum-classical boundaries and revealing where a practical\nquantum advantage may arise. Our work quantitatively determine how advanced a\nfault-tolerant quantum computer should be to achieve possible, significant\nbenefits on problems related to real-world."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "math.OC",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-812",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04675",
    "b_title":[
      "Enhancing Financial VQA in Vision Language Models using Intermediate\n  Structured Representations"
    ],
    "b_abstract":[
      "Chart interpretation is crucial for visual data analysis, but accurately\nextracting information from charts poses significant challenges for automated\nmodels. This study investigates the fine-tuning of DEPLOT, a modality\nconversion module that translates the image of a plot or chart to a linearized\ntable, on a custom dataset of 50,000 bar charts. The dataset comprises simple,\nstacked, and grouped bar charts, targeting the unique structural features of\nthese visualizations. The finetuned DEPLOT model is evaluated against its base\nversion using a test set of 1,000 images and two metrics: Relative Mapping\nSimilarity (RMS), which measures categorical mapping accuracy, and Relative\nNumber Set Similarity (RNSS), which evaluates numerical interpretation\naccuracy. To further explore the reasoning capabilities of large language\nmodels (LLMs), we curate an additional set of 100 bar chart images paired with\nquestion answer sets. Our findings demonstrate that providing a structured\nintermediate table alongside the image significantly enhances LLM reasoning\nperformance compared to direct image queries."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11566",
    "c_title":[
      "Ergodic closing lemmas and invariant Lagrangians"
    ],
    "c_abstract":[
      "Motivated by the ergodic closing lemma of Ma\\~n\\'e, we investigate the\n$C^\\infty$ closing lemma in higher-dimensional Hamiltonian systems, with a\nfocus on the statistical behavior of periodic orbits generated by\n$C^\\infty$-small perturbations. We demonstrate that, under certain\nFloer-theoretic conditions, invariant or recurrent Lagrangian submanifolds can\ngive rise to periodic orbits whose statistical properties are controllable. For\ninstance, we show that for Hamiltonian systems preserving the zero section in\n$T^*\\mathbb{T}^n$, $C^\\infty$ generically, there exist periodic orbits\nconverging to an invariant measure supported on the zero section."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.SG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-813",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08367",
    "b_title":[
      "Embodied Crowd Counting"
    ],
    "b_abstract":[
      "Occlusion is one of the fundamental challenges in crowd counting. In the\ncommunity, various data-driven approaches have been developed to address this\nissue, yet their effectiveness is limited. This is mainly because most existing\ncrowd counting datasets on which the methods are trained are based on passive\ncameras, restricting their ability to fully sense the environment. Recently,\nembodied navigation methods have shown significant potential in precise object\ndetection in interactive scenes. These methods incorporate active camera\nsettings, holding promise in addressing the fundamental issues in crowd\ncounting. However, most existing methods are designed for indoor navigation,\nshowing unknown performance in analyzing complex object distribution in large\nscale scenes, such as crowds. Besides, most existing embodied navigation\ndatasets are indoor scenes with limited scale and object quantity, preventing\nthem from being introduced into dense crowd analysis. Based on this, a novel\ntask, Embodied Crowd Counting (ECC), is proposed. We first build up an\ninteractive simulator, Embodied Crowd Counting Dataset (ECCD), which enables\nlarge scale scenes and large object quantity. A prior probability distribution\nthat approximates realistic crowd distribution is introduced to generate\ncrowds. Then, a zero-shot navigation method (ZECC) is proposed. This method\ncontains a MLLM driven coarse-to-fine navigation mechanism, enabling active\nZ-axis exploration, and a normal-line-based crowd distribution analysis method\nfor fine counting. Experimental results against baselines show that the\nproposed method achieves the best trade-off between counting accuracy and\nnavigation cost."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04672",
    "c_title":[
      "Equivalence of the pearly tree immersed Lagrangian Floer theory and the\n  Hamiltonian immersed Lagrangian Floer theory"
    ],
    "c_abstract":[
      "The goal of this paper is to prove an equivalence relation between the\nimmersed Lagrangian Floer theory, defined using pearly tree discs, and local\nHamiltonian flows, i.e., Hamiltonian flows performed in the Weinstein tubular\nneighborhood. This is a generalization of Alston-Bao's work."
    ],
    "c_categories":[
      [
        "math.DG",
        "math.GT",
        "math.SG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-814",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07031",
    "b_title":[
      "Negative Local Partial Density of States"
    ],
    "b_abstract":[
      "Real quantum systems can exhibit a local object called local partial density\nof states (LPDOS) that cannot be proved within the axiomatic approach of\nquantum mechanics. We demonstrate that real mesoscopic system that can exhibit\nFano resonances will show this object and also very counterintuitively it can\nbecome negative, resulting in the enhancement of coherent currents."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn",
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17469",
    "c_title":[
      "PixleepFlow: A Pixel-Based Lifelog Framework for Predicting Sleep\n  Quality and Stress Level"
    ],
    "c_abstract":[
      "The analysis of lifelogs can yield valuable insights into an individual's\ndaily life, particularly with regard to their health and well-being. The\naccurate assessment of quality of life is necessitated by the use of diverse\nsensors and precise synchronization. To rectify this issue, this study proposes\nthe image-based sleep quality and stress level estimation flow (PixleepFlow).\nPixleepFlow employs a conversion methodology into composite image data to\nexamine sleep patterns and their impact on overall health. Experiments were\nconducted using lifelog datasets to ascertain the optimal combination of data\nformats. In addition, we identified which sensor information has the greatest\ninfluence on the quality of life through Explainable Artificial\nIntelligence(XAI). As a result, PixleepFlow produced more significant results\nthan various data formats. This study was part of a written-based competition,\nand the additional findings from the lifelog dataset are detailed in Section\nSection IV. More information about PixleepFlow can be found at\nhttps:\/\/github.com\/seongjiko\/Pixleep."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-815",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18525",
    "b_title":[
      "Magnetically-assisted vorticity production in decaying acoustic\n  turbulence"
    ],
    "b_abstract":[
      "We study vorticity production in isothermal, subsonic, acoustic\n(nonvortical), decaying turbulence due to the presence of magnetic fields.\nUsing three-dimensional numerical simulations, we always find that the\nresulting turbulent kinetic energy cascade follows the ordinary Kolmogorov\nphenomenology involving a constant spectral energy flux. For acoustic\nturbulence, the corresponding nondimensional prefactor is larger than the\nstandard Kolmogorov constant due to an inefficiency in dissipating kinetic\nenergy. We find that the Lorentz force can not only drive the direct production\nof vortical motions, but it can also facilitate the conversion of acoustic\nenergy into vortical energy. This conversion is shown to be quadratic in the\nmagnetic field strength and linear in the acoustic flow speed. By contrast, the\ndirect production of vortical motions by the magnetic field is linear in the\nfield strength. Our results suggest that magnetic fields play a crucial role in\nvorticity production in cosmological flows, particularly in scenarios where\nsignificant acoustic turbulence is prevalent. We also discuss the implications\nof our findings for the early universe, where magnetic fields may convert\nacoustic turbulence generated during cosmological phase transitions into\nvortical turbulence."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08801",
    "c_title":[
      "Enhanced Estimation Techniques for Certified Radii in Randomized\n  Smoothing"
    ],
    "c_abstract":[
      "This paper presents novel methods for estimating certified radii in\nrandomized smoothing, a technique crucial for certifying the robustness of\nneural networks against adversarial perturbations. Our proposed techniques\nsignificantly improve the accuracy of certified test-set accuracy by providing\ntighter bounds on the certified radii. We introduce advanced algorithms for\nboth discrete and continuous domains, demonstrating their effectiveness on\nCIFAR-10 and ImageNet datasets. The new methods show considerable improvements\nover existing approaches, particularly in reducing discrepancies in certified\nradii estimates. We also explore the impact of various hyperparameters,\nincluding sample size, standard deviation, and temperature, on the performance\nof these methods. Our findings highlight the potential for more efficient\ncertification processes and pave the way for future research on tighter\nconfidence sequences and improved theoretical frameworks. The study concludes\nwith a discussion of potential future directions, including enhanced estimation\ntechniques for discrete domains and further theoretical advancements to bridge\nthe gap between empirical and theoretical performance in randomized smoothing."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-816",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12432",
    "b_title":[
      "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel\n  Tool Invocation"
    ],
    "b_abstract":[
      "Although current Large Language Models (LLMs) exhibit impressive\ncapabilities, performing complex real-world tasks still requires tool learning.\nMainstream methods, such as CoT\/ReAct, rely on step-by-step tool invocation to\ninteract with external environments, but they are limited in perceptual scope\nand lack adequate task-planning capability. To address these limitations, other\nstudies introduce the first Search-based Decision Tree (DFSDT), which still\nsuffers from the high computational cost. In this paper, we introduce a novel\nparallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).\nFirst, we transform traditional tree-based tool search paths into Directed\nAcyclic Graph (DAG) structure, generating a high-quality parallel tool\ninvocation dataset. The DTA-Llama is then trained on the dataset to learn to\niteratively divide the current task into several parallel tool invocation\nsub-tasks and aggregate the invocation results to decide the next actions.\nFurthermore, we introduce an efficient inference framework inspired by the\nProcess\/Threads mechanism when applying the DTA-Llama to practical tasks.\nExperimental results show that our approach substantially enhances task\nperformance while reducing token consumption and inference time. Llama2-7B,\nusing our method, is comparable to the official parallel function calling\nmethod of GPT-3.5. The relevant code, dataset, and model weights are available\nat https:\/\/corn0205.github.io\/"
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09087",
    "c_title":[
      "On the First-Passage Time Fluctuation Theorem in Complex Biomolecular\n  Networks"
    ],
    "c_abstract":[
      "A fluctuation theorem is examined for the first-passage time of a\nbiomolecular machine in a nonequilibrium steady-state. For such machines in\nwhich the driven, observable process is coupled to a hidden process in a\nkinetically cooperative fashion, the entropy produced along first-passage\ntrajectories is no longer uniform, resulting in a breakdown of this relation.\nHere, we consider the canonical model for this type of system, a kinetic scheme\nfor conformation-modulated single-enzyme catalysis, as we (i) determine the\ncircumstances under which this fluctuation theorem can be restored; (ii) assess\nwhat its violation reveals about the hidden dynamics; and (iii) characterize\nthe general form of the deviation from this relation. Kinetic evaluations are\nperformed using a novel, efficient pathway analysis technique, allowing us to\nattain some surprising and fairly straightforward results from relatively\ncomplex calculations. We find that in the absence of hidden current, a\nfluctuation theorem can be written for the first-passage time of the observable\nprocess, and we demonstrate that this is a general feature applicable to a wide\nvariety of complex networks. The validity of this relation can be\nexperimentally tested, with its violation serving as a signature of hidden\ndetailed balance breaking. In addition, we obtain a remarkably compact exact\nexpression for the integrated correction to this first-passage time fluctuation\ntheorem, which indicates that the kinetic branching ratio, defined as the ratio\nof the forward observable process probability to the backward one, is bounded\nby the entropy production associated with the first-passage work (i.e., the\nwork applied along a first-passage trajectory). These results provide detailed\ninsight into the rich connections between dynamic measurements and the\nunderlying nonequilibrium thermodynamics in complex biomolecular networks."
    ],
    "c_categories":[
      [
        "physics.bio-ph",
        "physics.chem-ph",
        "q-bio.MN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-817",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13336",
    "b_title":[
      "Gradient-Free Adversarial Purification with Diffusion Models"
    ],
    "b_abstract":[
      "Adversarial training and adversarial purification are two effective and\npractical defense methods to enhance a model's robustness against adversarial\nattacks. However, adversarial training necessitates additional training, while\nadversarial purification suffers from low time efficiency. More critically,\ncurrent defenses are designed under the perturbation-based adversarial threat\nmodel, which is ineffective against the recently proposed unrestricted\nadversarial attacks. In this paper, we propose an effective and efficient\nadversarial defense method that counters both perturbation-based and\nunrestricted adversarial attacks. Our defense is inspired by the observation\nthat adversarial attacks are typically located near the decision boundary and\nare sensitive to pixel changes. To address this, we introduce adversarial\nanti-aliasing to mitigate adversarial modifications. Additionally, we propose\nadversarial super-resolution, which leverages prior knowledge from clean\ndatasets to benignly recover images. These approaches do not require additional\ntraining and are computationally efficient without calculating gradients.\nExtensive experiments against both perturbation-based and unrestricted\nadversarial attacks demonstrate that our defense method outperforms\nstate-of-the-art adversarial purification methods."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02900",
    "c_title":[
      "Optimisation of space-time periodic eigenvalues"
    ],
    "c_abstract":[
      "The goal of this paper is to provide a qualitative analysis of the\noptimisation of space-time periodic principal eigenvalues. Namely, considering\na fixed time horizon $T$ and the $d$-dimensional torus $\\mathbb{T}^d$, let, for\nany $m\\in L^\\infty((0,T)\\times\\mathbb{T}^d)$, $\\lambda(m)$ be the principal\neigenvalue of the operator $\\partial_t-\\Delta-m$ endowed with (time-space)\nperiodic boundary conditions. The main question we set out to answer is the\nfollowing: how to choose $m$ so as to minimise $\\lambda(m)$? This question\nstems from population dynamics. We prove that in several cases it is always\nbeneficial to rearrange $m$ with respect to time in a symmetric way, which is\nthe first comparison result for the rearrangement in time of parabolic\nequations. Furthermore, we investigate the validity (or lack thereof) of\nTalenti inequalities for the rearrangement in time of parabolic equations. The\nnumerical simulations which illustrate our results were obtained by developing\na framework within which it is possible to optimise criteria with respect to\nfunctions having a prescribed rearrangement (or distribution function)."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-818",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02839",
    "b_title":[
      "Contaminating Electromagnetic Transients in LISA Gravitational Wave\n  Localization Volumes. I: The Intrinsic Rates"
    ],
    "b_abstract":[
      "The Laser Interferometer Space Antenna (LISA) will soon detect gravitational\nwaves (GWs) emitted by massive black hole (MBH) mergers. Some theoretical\nmodels have predicted transient electromagnetic (EM) emission from these\nmergers, enabling the association of LISA GW sources with their EM counterparts\nvia telescope follow-up. However, the number of unrelated EM transients that\nmight contaminate telescope searches for the true transient counterparts of\nLISA MBH mergers is unknown. We investigate the expected numbers of unrelated\nEM transients that will coincide with simulated LISA localization volumes of\nMBH mergers, as a function of the merger total mass and redshift. We find that\nthe number of potential contaminants in LISA localization volumes drops to\nunity for mergers at $z \\lesssim 0.8$ and at 1 hour before coalescence. After\ncoalescence, the parameter space corresponding to a maximum of one potential\ncontaminant expands to $z \\lesssim 1.5$. In contrast, if the redshifts for all\ntransients detected in LISA sky localization regions are not available, the\nnumber of potential contaminants increases by an average factor of $\\sim100$,\nand never drops below unity. Overall, we expect the average number of\ncontaminating transients in telescope follow-up of LISA MBH mergers to be\nnon-negligible, especially without redshift information for the detected\ntransients. We recommend that endeavors designing follow-up strategies of LISA\nevents should focus on: (1) building large redshift catalogs for host galaxies,\n(2) developing robust real-time transient classification algorithms, (3) and\ncoordinating telescope resources to obtain redshifts for candidate transient EM\ncounterparts in a timely manner."
    ],
    "b_categories":[
      [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01575",
    "c_title":[
      "Diameter Constraints in $2$-distance Graphs"
    ],
    "c_abstract":[
      "For any finite, simple graph $G = (V,E)$, its $2$-distance graph $G_2$ is a\ngraph having the same vertex set $V$ where two vertices are adjacent if and\nonly if their distance is $2$ in $G$. Connectivity and diameter properties of\nthese graphs have been well studied. For example, it has been shown that if\n$diam(G) = k \\geq 3$ then $\\lceil \\frac{1}{2} k \\rceil \\leq diam(G_2)$, and\nthat this bound is sharp. In this paper, we prove that $diam(G_2) = \\infty$\n(that is, $G_2$ is disconnected) or otherwise $diam(G_2) \\leq k + 2$. In\naddition, this inequality is sharp for $k \\in \\{3,4\\}$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-819",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01335",
    "b_title":[
      "ConceptVAE: Self-Supervised Fine-Grained Concept Disentanglement from 2D\n  Echocardiographies"
    ],
    "b_abstract":[
      "While traditional self-supervised learning methods improve performance and\nrobustness across various medical tasks, they rely on single-vector embeddings\nthat may not capture fine-grained concepts such as anatomical structures or\norgans. The ability to identify such concepts and their characteristics without\nsupervision has the potential to improve pre-training methods, and enable novel\napplications such as fine-grained image retrieval and concept-based outlier\ndetection. In this paper, we introduce ConceptVAE, a novel pre-training\nframework that detects and disentangles fine-grained concepts from their style\ncharacteristics in a self-supervised manner. We present a suite of loss terms\nand model architecture primitives designed to discretise input data into a\npreset number of concepts along with their local style. We validate ConceptVAE\nboth qualitatively and quantitatively, demonstrating its ability to detect\nfine-grained anatomical structures such as blood pools and septum walls from 2D\ncardiac echocardiographies. Quantitatively, ConceptVAE outperforms traditional\nself-supervised methods in tasks such as region-based instance retrieval,\nsemantic segmentation, out-of-distribution detection, and object detection.\nAdditionally, we explore the generation of in-distribution synthetic data that\nmaintains the same concepts as the training data but with distinct styles,\nhighlighting its potential for more calibrated data generation. Overall, our\nstudy introduces and validates a promising new pre-training technique based on\nconcept-style disentanglement, opening multiple avenues for developing models\nfor medical image analysis that are more interpretable and explainable than\nblack-box approaches."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05023",
    "c_title":[
      "Euclid: Detecting Solar System objects in Euclid images and classifying\n  them using Kohonen self-organising maps"
    ],
    "c_abstract":[
      "The ESA Euclid mission will survey more than 14,000 deg$^2$ of the sky in\nvisible and near-infrared wavelengths, mapping the extra-galactic sky to\nconstrain our cosmological model of the Universe. Although the survey focusses\non regions further than 15 deg from the ecliptic, it should allow for the\ndetection of more than about $10^5$ Solar System objects (SSOs). After\nsimulating the expected signal from SSOs in Euclid images acquired with the\nvisible camera (VIS), we describe an automated pipeline developed to detect\nmoving objects with an apparent velocity in the range of 0.1-10 arcsec\/h,\ntypically corresponding to sources in the outer Solar System (from Centaurs to\nKuiper-belt objects). In particular, the proposed detection scheme is based on\nSourcextractor software and on applying a new algorithm capable of associating\nmoving objects amongst different catalogues. After applying a suite of filters\nto improve the detection quality, we study the expected purity and completeness\nof the SSO detections. We also show how a Kohonen self-organising neural\nnetwork can be successfully trained (in an unsupervised fashion) to classify\nstars, galaxies, and SSOs. By implementing an early-stopping method in the\ntraining scheme, we show that the network can be used in a predictive way,\nallowing one to assign the probability of each detected object being a member\nof each considered class."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-820",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11758",
    "b_title":[
      "A Review Paper of the Effects of Distinct Modalities and ML Techniques\n  to Distracted Driving Detection"
    ],
    "b_abstract":[
      "Distracted driving remains a significant global challenge with severe human\nand economic repercussions, demanding improved detection and intervention\nstrategies. While previous studies have extensively explored single-modality\napproaches, recent research indicates that these systems often fall short in\nidentifying complex distraction patterns, particularly cognitive distractions.\nThis systematic review addresses critical gaps by providing a comprehensive\nanalysis of machine learning (ML) and deep learning (DL) techniques applied\nacross various data modalities - visual,, sensory, auditory, and multimodal. By\ncategorizing and evaluating studies based on modality, data accessibility, and\nmethodology, this review clarifies which approaches yield the highest accuracy\nand are best suited for specific distracted driving detection goals. The\nfindings offer clear guidance on the advantages of multimodal versus\nsingle-modal systems and capture the latest advancements in the field.\nUltimately, this review contributes valuable insights for developing robust\ndistracted driving detection frameworks, supporting enhanced road safety and\nmitigation strategies."
    ],
    "b_categories":[
      [
        "cs.CV",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10276",
    "c_title":[
      "A Latent Causal Inference Framework for Ordinal Variables"
    ],
    "c_abstract":[
      "Ordinal variables, such as on the Likert scale, are common in applied\nresearch. Yet, existing methods for causal inference tend to target nominal or\ncontinuous data. When applied to ordinal data, this fails to account for the\ninherent ordering or imposes well-defined relative magnitudes. Hence, there is\na need for specialised methods to compute interventional effects between\nordinal variables while accounting for their ordinality. One potential\nframework is to presume a latent Gaussian Directed Acyclic Graph (DAG) model:\nthat the ordinal variables originate from marginally discretising a set of\nGaussian variables whose latent covariance matrix is constrained to satisfy the\nconditional independencies inherent in a DAG. Conditioned on a given latent\ncovariance matrix and discretisation thresholds, we derive a closed-form\nfunction for ordinal causal effects in terms of interventional distributions in\nthe latent space. Our causal estimation combines naturally with algorithms to\nlearn the latent DAG and its parameters, like the Ordinal Structural EM\nalgorithm. Simulations demonstrate the applicability of the proposed approach\nin estimating ordinal causal effects both for known and unknown structures of\nthe latent graph. As an illustration of a real-world use case, the method is\napplied to survey data of 408 patients from a study on the functional\nrelationships between symptoms of obsessive-compulsive disorder and depression."
    ],
    "c_categories":[
      [
        "stat.ME",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-821",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05920",
    "b_title":[
      "IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative\n  Language Model Pretraining"
    ],
    "b_abstract":[
      "Recent advancements in large language models have intensified the need for\nefficient and deployable models within limited inference budgets. Structured\npruning pipelines have shown promise in token efficiency compared to training\ntarget-size models from scratch. In this paper, we advocate incorporating\nenlarged model pretraining, which is often ignored in previous works, into\npruning. We study the enlarge-and-prune pipeline as an integrated system to\naddress two critical questions: whether it is worth pretraining an enlarged\nmodel even when the model is never deployed, and how to optimize the entire\npipeline for better pruned models. We propose an integrated enlarge-and-prune\npipeline, which combines enlarge model training, pruning, and recovery under a\nsingle cosine annealing learning rate schedule. This approach is further\ncomplemented by a novel iterative structured pruning method for gradual\nparameter removal. The proposed method helps to mitigate the knowledge loss\ncaused by the rising learning rate in naive enlarge-and-prune pipelines and\nenable effective redistribution of model capacity among surviving neurons,\nfacilitating smooth compression and enhanced performance. We conduct\ncomprehensive experiments on compressing 2.8B models to 1.3B with up to 2T\ntokens in pretraining. It demonstrates the integrated approach not only\nprovides insights into the token efficiency of enlarged model pretraining but\nalso achieves superior performance of pruned models."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08996",
    "c_title":[
      "Calculus with combinatorial differential forms for fluid flow analysis\n  in porous and fractured media"
    ],
    "c_abstract":[
      "The fabric of porous and fractured media contains solid regions (grains) and\nvoids. The space conducting fluids is a system of connected voids with variable\ngeometries. Relative to the grain sizes, the voids can be voluminous with three\ncomparable large extensions, narrow expansive with two comparable large\nextensions and one smaller extension, and thin long with one comparable large\nextension and two smaller extensions. The widely used representation of void\nspaces by systems of spheres connected by cylinders (pore network models) is an\nacceptable approximation for some special cases, but not for most porous and\nfractured media. We propose a flexible method for modelling such media by\nmapping their measured fabric's characteristics - void and grain volume\ndistributions and shapes - onto polyhedral tessellations of space. The map\nassigns voluminous voids and grains to polyhedrons (3D), narrow expansive voids\nto some polyhedral faces (2D), and thin long voids to some polyhedral edges\n(1D), as dictated by experimental data. The analysis of transport through such\ndiscrete structures with components of different dimensions is performed by a\nnovel mathematical method, which uses combinatorial differential forms to\nrepresent physical properties and their fluxes, as well as structure-preserving\noperators on such forms to formulate the conservation laws exactly and directly\nin matrix form, ready for computation. The method allows for individual\nmaterial properties, such as conductivity, to be assigned to voids of all\ndimensions, so that the three types of voids are suitably represented. Publicly\navailable XCT images of four different rocks are used to test the method."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-822",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10411",
    "b_title":[
      "TrueReason: An Exemplar Personalised Learning System Integrating\n  Reasoning with Foundational Models"
    ],
    "b_abstract":[
      "Personalised education is one of the domains that can greatly benefit from\nthe most recent advances in Artificial Intelligence (AI) and Large Language\nModels (LLM). However, it is also one of the most challenging applications due\nto the cognitive complexity of teaching effectively while personalising the\nlearning experience to suit independent learners. We hypothesise that one\npromising approach to excelling in such demanding use cases is using a\n\\emph{society of minds}. In this chapter, we present TrueReason, an exemplar\npersonalised learning system that integrates a multitude of specialised AI\nmodels that can mimic micro skills that are composed together by a LLM to\noperationalise planning and reasoning. The architecture of the initial\nprototype is presented while describing two micro skills that have been\nincorporated in the prototype. The proposed system demonstrates the first step\nin building sophisticated AI systems that can take up very complex cognitive\ntasks that are demanded by domains such as education."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.IR",
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12561",
    "c_title":[
      "Spanning trees in directed square cycles"
    ],
    "c_abstract":[
      "We classify weakly connected spanning closed (WCSC) subgraphs of\n$\\overrightarrow{C_n^2}$, the square of a directed $n$-vertex cycle. Then we\nshow that every spanning tree of $\\overrightarrow{C_n^2}$ is contained in a\nunique nontrivial WCSC subgraph of $\\overrightarrow{C_n^2}$. As a result, we\nobtain a purely combinatorial derivation of the formula for the number of\ndirected spanning trees of $\\overrightarrow{C_n^2}$. Moreover, we obtain the\nformula for the number of directed spanning trees of $\\overrightarrow{C_n^2}$,\nwhich is a Jacobsthal number."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-823",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10573",
    "b_title":[
      "The Geometry of Tokens in Internal Representations of Large Language\n  Models"
    ],
    "b_abstract":[
      "We investigate the relationship between the geometry of token embeddings and\ntheir role in the next token prediction within transformer models. An important\naspect of this connection uses the notion of empirical measure, which encodes\nthe distribution of token point clouds across transformer layers and drives the\nevolution of token representations in the mean-field interacting picture. We\nuse metrics such as intrinsic dimension, neighborhood overlap, and cosine\nsimilarity to observationally probe these empirical measures across layers. To\nvalidate our approach, we compare these metrics to a dataset where the tokens\nare shuffled, which disrupts the syntactic and semantic structure. Our findings\nreveal a correlation between the geometric properties of token embeddings and\nthe cross-entropy loss of next token predictions, implying that prompts with\nhigher loss values have tokens represented in higher-dimensional spaces."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14457",
    "c_title":[
      "Flux trapping in NbTiN strips and structures"
    ],
    "c_abstract":[
      "We use scanning superconducting quantum interference device (SQUID)\nmicroscopy to image vortices in superconducting strips fabricated from NbTiN\nthin films. We repeatedly cool superconducting strips with different width in\nan applied magnetic field and image the individual vortices. From these images\nwe determine the threshold field at which the first vortex enters a strip, as\nwell as the number and spatial configuration of vortices beyond this threshold\nfield. We model vortex behavior with and without considering the effect of\npinning by numercially minimizing the Gibbs free energy of vortices in the\nstrips. Our measurements provide a first benchmark to understand the flux\ntrapping properties of NbTiN thin films directly relevant to NbTiN-based\nsuperconducting circuits and devices."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-824",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06030",
    "b_title":[
      "Towards Universal Text-driven CT Image Segmentation"
    ],
    "b_abstract":[
      "Computed tomography (CT) is extensively used for accurate visualization and\nsegmentation of organs and lesions. While deep learning models such as\nconvolutional neural networks (CNNs) and vision transformers (ViTs) have\nsignificantly improved CT image analysis, their performance often declines when\napplied to diverse, real-world clinical data. Although foundation models offer\na broader and more adaptable solution, their potential is limited due to the\nchallenge of obtaining large-scale, voxel-level annotations for medical images.\nIn response to these challenges, prompting-based models using visual or text\nprompts have emerged. Visual-prompting methods, such as the Segment Anything\nModel (SAM), still require significant manual input and can introduce ambiguity\nwhen applied to clinical scenarios. Instead, foundation models that use text\nprompts offer a more versatile and clinically relevant approach. Notably,\ncurrent text-prompt models, such as the CLIP-Driven Universal Model, are\nlimited to text prompts already encountered during training and struggle to\nprocess the complex and diverse scenarios of real-world clinical applications.\nInstead of fine-tuning models trained from natural imaging, we propose\nOpenVocabCT, a vision-language model pretrained on large-scale 3D CT images for\nuniversal text-driven segmentation. Using the large-scale CT-RATE dataset, we\ndecompose the diagnostic reports into fine-grained, organ-level descriptions\nusing large language models for multi-granular contrastive learning. We\nevaluate our OpenVocabCT on downstream segmentation tasks across nine public\ndatasets for organ and tumor segmentation, demonstrating the superior\nperformance of our model compared to existing methods. All code, datasets, and\nmodels will be publicly released at https:\/\/github.com\/ricklisz\/OpenVocabCT."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04926",
    "c_title":[
      "Discovery of a pair of very metal-poor stars enriched in neutron-capture\n  elements: The proto-disk r-II star BPS CS 29529-0089 and the\n  Gaia-Sausage-Enceladus r-I star TYC 9219-2422-1"
    ],
    "c_abstract":[
      "R-process enhanced metal-poor stars (\\EuFe$\\geq+0.3$ and \\FeH$\\leq-1.0$) are\nrare objects whose study can provide clues to the astrophysical sites of the\nrapid neutron capture process. In this study, we investigate the detailed\nchemical abundance patterns of two of these anomalous stars, originally\nidentified among stars observed by the GALAH survey. Our aim is to obtain the\ndetailed chemical abundance pattern of these stars with spectroscopy at higher\nresolution and signal-to-noise ratio. We use a calibration of the infrared flux\nmethod to determine accurate effective temperatures, and \\Gaia~ parallaxes\ntogether with broadband photometry and theoretical bolometric corrections to\ndetermine surface gravity. Metallicities and chemical abundances are determined\nwith model atmospheres and spectrum synthesis. We also integrate stellar orbits\nfor a complete chemodynamic analysis. e determine abundances for up to 47\nchemical species (44 elements), of which 27 are neutron-capture elements.\nCorrections because of deviations from the local thermodynamical equilibrium\nare applied to the metallicities and 12 elements. We find that one of the\nstars, BPS CS 29529-0089, is a proto-disk star of the Milky Way of r-II type,\nwith \\EuFe=+1.79~dex. The second star, TYC 9219-2422-1, is part of the halo and\nassociated with the Gaia-Sausage-Enceladus merger event. It is of r-I type with\n[Eu\/Fe] = +0.54. Abundances of Th are also provided for both stars. BPS CS\n29529-0089 is the most extreme example of r-process enhanced star known with\ndisk-like kinematics and that is not carbon enhanced. TYC 9219-2422-1 is found\nto be an archetypal Gaia-Sausage-Enceladus star. Their abundances of C, Mg, Ni,\nSc, Mn, and Al seem consistent with expectations for stars enriched by a single\npopulation III core collapse supernova, despite their relatively high\nmetallicities ([Fe\/H] $\\sim$ $-$2.4)."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-825",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03137",
    "b_title":[
      "Distributionally Robust Control Synthesis for Stochastic Systems with\n  Safety and Reach-Avoid Specifications"
    ],
    "b_abstract":[
      "We investigate the problem of synthesizing distributionally robust control\npolicies for stochastic systems under safety and reach-avoid specifications.\nUsing a game-theoretical framework, we consider the setting where the\nprobability distribution of the disturbance at each time step is selected from\nan ambiguity set defined by the Wasserstein distance. The goal is to synthesize\na distributionally robust control policy that ensures the satisfaction\nprobability exceeds a specified threshold under any distribution within the\nambiguity set. First, for both safety and reach-avoid specifications, we\nestablish the existence of optimal policies by leveraging the dynamic\nprogramming principles. Then we demonstrate how the associated optimization\nproblem can be efficiently solved using the dual representation of Wasserstein\ndistributionally robust optimization. Furthermore, for safety specifications in\nparticular, we introduce a novel concept of distributionally robust control\nbarrier certificates and show how these enable the efficient synthesis of\ncontrollers through sum-of-squares programming techniques. Finally, our\nexperimental results reveal that incorporating distributional robustness during\nthe synthesis phase significantly improves the satisfaction probability during\nonline execution, even with limited statistical knowledge of the disturbance\ndistribution."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14068",
    "c_title":[
      "Riemann-Liouville integrals in Besov spaces"
    ],
    "c_abstract":[
      "Criteria for the fulfillment of inequalities in weighted smoothness function\nspaces of Besov type with Riemann-Liouville operators of natural orders on the\nreal axis and semi-axes are found. The obtained estimates are refined under\nadditional conditions on weights."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-826",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15504",
    "b_title":[
      "Jeffrey's update rule as a minimizer of Kullback-Leibler divergence"
    ],
    "b_abstract":[
      "In this paper, we show a more concise and high level proof than the original\none, derived by researcher Bart Jacobs, for the following theorem: in the\ncontext of Bayesian update rules for learning or updating internal states that\nproduce predictions, the relative entropy between the observations and the\npredictions is reduced when applying Jeffrey's update rule to update the\ninternal state."
    ],
    "b_categories":[
      [
        "cs.CR",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18068",
    "c_title":[
      "Physics on and off the light cone"
    ],
    "c_abstract":[
      "We study light-front physics and conformal symmetry, and their interplay both\non and off the light cone. The full symmetry of the light cone is conformal\nsymmetry not just Lorentz symmetry. Spontaneously breaking conformal symmetry\ngives masses to particles and takes them off the light cone. Canonical\nquantization specifies equal-time commutators on the light cone. Equal\ninstant-time and equal light-front-time commutators look very different, but\ncan be shown to be equivalent by looking at unequal-time commutators. We\ndiscuss the connection of the light-front approach to the infinite momentum\nframe approach, and show that vacuum graphs are outside this framework. We show\nthat there is a light-front structure to both AdS\/CFT and the eikonal\napproximation. While mass generation involves scale breaking mass scales, we\nshow that such mass scales can arise via dynamical symmetry breaking in the\npresence of scale invariant interactions at a renormalization group fixed\npoint."
    ],
    "c_categories":[
      [
        "hep-ph",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-827",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13205",
    "b_title":[
      "Non-local high-$p_t$ transport in anisotropic QCD matter"
    ],
    "b_abstract":[
      "We perform a numerical study of non-local partonic transport in anisotropic\nQCD matter, relevant to the evolution of hard probes in the aftermath of\nhigh-energy nuclear scattering events. The recently derived master equation,\nobtained from QFT considerations, differs from Boltzmann transport by\nincorporating a non-local elastic scattering kernel arising from density\ngradients. After rewriting the master equation in a form suitable for numerical\nimplementation and assuming a static density profile, we compare the non-local\nevolution to Boltzmann transport, demonstrating that the new interaction kernel\nis essential for accurately describing the azimuthal structure of the\nfinal-state momentum distribution. We further study the non-local partonic\ntransport in the case of a matter profile governed by two-dimensional\nhydrodynamics, accounting for its flow and generalizing the evolution equation.\nOur results demonstrate the necessity of going beyond classical transport at\nhigh-$p_t$ to accurately capture the structure of jets propagating through\nstructured QCD matter. The master equation used in the numerical simulations\ncan be seamlessly integrated into state-of-the-art transport codes."
    ],
    "b_categories":[
      [
        "hep-ph",
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17450",
    "c_title":[
      "A Constraint-Preserving Neural Network Approach for Solving Mean-Field\n  Games Equilibrium"
    ],
    "c_abstract":[
      "Neural network-based methods have demonstrated effectiveness in solving\nhigh-dimensional Mean-Field Games (MFG) equilibria, yet ensuring mathematically\nconsistent density-coupled evolution remains a major challenge. This paper\nproposes the NF-MKV Net, a neural network approach that integrates\nprocess-regularized normalizing flow (NF) with state-policy-connected\ntime-series neural networks to solve MKV FBSDEs and their associated\nfixed-point formulations of MFG equilibria. The method first reformulates MFG\nequilibria as MKV FBSDEs, embedding density evolution into equation\ncoefficients within a probabilistic framework. Neural networks are then\nemployed to approximate value functions and their gradients. To enforce\nvolumetric invariance and temporal continuity, NF architectures impose loss\nconstraints on each density transfer function."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-828",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16243",
    "b_title":[
      "EP240414a: A Gamma-Ray Burst Jet Weakened by an Extended Circumstellar\n  Material"
    ],
    "b_abstract":[
      "The recent Einstein Probe (EP) event EP240414a exhibits several unusual\nobservational features. Its prompt and afterglow emissions place it between\nlong gamma-ray bursts (LGRBs) and low-luminosity GRBs (LLGRBs). The event is\nfollowed by a fast optical transient (AT~2024gsa), initially exhibiting a\nthermal-like spectrum but later evolving into an unusually red peak at $\\sim\n3-5$ days, which is difficult to explain with thermal emission. Using our\ngeneralized analytic framework for jet propagation in a circumstellar material\n(CSM; Hamidani et al. 2025), we explore a scenario in which a conventional LGRB\njet is launched in a progenitor surrounded by a dense CSM. For a CSM of $\\sim\n0.03 M_\\odot$ extending to $\\sim 3\\times 10^{13}$ cm, we find that the jet is\nsignificantly weakened before breaking out, becoming ``barely failed'', an\nintermediate state between successful (LGRB) and completely failed (LLGRB)\njets. This scenario naturally explains EP240414a's multi-wavelength\nobservations, with the early thermal component produced by cocoon cooling\nemission, and the red peak explained by non-thermal afterglow emission from the\nmildly relativistic barely failed jet (and its inner cocoon). Our work\ndemonstrates the important role of extended CSM in shaping GRB jets and\nillustrates how early multi-wavelength follow-up observations can reveal the\nphysically diverse nature of jet-driven transients."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04504",
    "c_title":[
      "Integrating anatomy and electrophysiology in the healthy human heart:\n  Insights from biventricular statistical shape analysis using universal\n  coordinates"
    ],
    "c_abstract":[
      "A cardiac digital twin is a virtual replica of a patient-specific heart,\nmimicking its anatomy and physiology. A crucial step of building a cardiac\ndigital twin is anatomical twinning, where the computational mesh of the\ndigital twin is tailored to the patient-specific cardiac anatomy. In a number\nof studies, the effect of anatomical variation on clinically relevant\nfunctional measurements like electrocardiograms (ECGs) is investigated, using\ncomputational simulations. While such a simulation environment provides\nresearchers with a carefully controlled ground truth, the impact of anatomical\ndifferences on functional measurements in real-world patients remains\nunderstudied. In this study, we develop a biventricular statistical shape model\nand use it to quantify the effect of biventricular anatomy on ECG-derived and\ndemographic features, providing novel insights for the development of digital\ntwins of cardiac electrophysiology. To this end, a dataset comprising\nhigh-resolution cardiac CT scans from 271 healthy individuals, including\nathletes, is utilized. Furthermore, a novel, universal, ventricular\ncoordinate-based method is developed to establish lightweight shape\ncorrespondence. The performance of the shape model is rigorously established,\nfocusing on its dimensionality reduction capabilities and the training data\nrequirements. Additionally, a comprehensive synthetic cohort is made available,\nfeaturing ready-to-use biventricular meshes with fiber structures and\nanatomical region annotations. These meshes are well-suited for\nelectrophysiological simulations."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-829",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08222",
    "b_title":[
      "Data-driven Spatial Classification using Multi-Arm Bandits for\n  Monitoring with Energy-Constrained Mobile Robots"
    ],
    "b_abstract":[
      "We consider the spatial classification problem for monitoring using data\ncollected by a coordinated team of mobile robots. Such classification problems\narise in several applications including search-and-rescue and precision\nagriculture. Specifically, we want to classify the regions of a search\nenvironment into interesting and uninteresting as quickly as possible using a\nteam of mobile sensors and mobile charging stations. We develop a data-driven\nstrategy that accommodates the noise in sensed data and the limited energy\ncapacity of the sensors, and generates collision-free motion plans for the\nteam. We propose a bi-level approach, where a high-level planner leverages a\nmulti-armed bandit framework to determine the potential regions of interest for\nthe drones to visit next based on the data collected online. Then, a low-level\npath planner based on integer programming coordinates the paths for the team to\nvisit the target regions subject to the physical constraints. We characterize\nseveral theoretical properties of the proposed approach, including anytime\nguarantees and task completion time. We show the efficacy of our approach in\nsimulation, and further validate these observations in physical experiments\nusing mobile robots."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04447",
    "c_title":[
      "A possible trail of dust from a young, highly-extincted brown dwarf in\n  the outskirts of the Trapezium Cluster"
    ],
    "c_abstract":[
      "We present the JWST discovery of a highly-extincted ($A_V\\sim52$) candidate\nbrown dwarf ($\\sim0.018$M$_\\odot$) in the outskirts of the Trapezium Cluster\nthat appears to be coincident with the end of a $\\sim 1700\\,$au long,\nremarkably uniformly wide, dark trail that broadens only slightly at the end\nopposite the point source. We examine whether a dusty trail associated with a\nhighly-extincted brown dwarf could plausibly be detected with JWST and explore\npossible origins. We show that a dusty trail associated with the brown dwarf\ncould be observable if dust within it is larger than that in the ambient\nmolecular cloud. For example, if the ambient cloud has a standard\n$\\sim0.25$$\\mu$m maximum grain size and the trail contains micron-sized grains,\nthen the trail will have a scattering opacity over an order of magnitude larger\ncompared to the surroundings in NIRCam short-wavelength filters. We use a\nsimple model to show that a change in maximum grain size can reproduce the high\n$A_V$ and the multi-filter NIRCam contrast seen between the trail and its\nsurroundings. We propose and explore two possible mechanisms that could be\nresponsible for the trail: i) a weak FUV radiation-driven wind from the\ncircum-brown dwarf disc due to the O stars in the region and ii) a\nBondi-Hoyle-Lyttleton accretion wake. The former would be the most distant\nknown case of the Trapezium stars' radiation driving winds from a disc, and the\nlatter would be the first known example of ``late'' infall from the\ninterstellar medium onto a low mass object in a high-mass star-forming region."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-830",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11676",
    "b_title":[
      "Cosmic Large-Scale Structure Formation from Newtonian Particle Dynamics"
    ],
    "b_abstract":[
      "We present results for the cosmic non-linear density-fluctuation power\nspectrum based on the analytical formalism developed in [1] which allows us to\nstudy cosmic structure formation based on Newtonian particle dynamics in\nphase-space. This framework provides a field-theory approach to a perturbative\nsolution of the BBGKY-hierarchy where the resulting loop-expansion of the\ntheory introduces a natural truncation criterion. We show that we are able to\nreproduce structure growth on large scales $k \\leq 0.2\n\\mathrm{h}\\,\\mathrm{Mpc}^{-1}$ to very high precision while on small and\nintermediate scales we find deviations of the order of $10\\%$ from current\nnumerical simulations. The results strongly suggest that a significant\nimprovement may be achieved by restructuring the perturbation theory."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00527",
    "c_title":[
      "Never too Prim to Swim: An LLM-Enhanced RL-based Adaptive S-Surface\n  Controller for AUVs under Extreme Sea Conditions"
    ],
    "c_abstract":[
      "The adaptivity and maneuvering capabilities of Autonomous Underwater Vehicles\n(AUVs) have drawn significant attention in oceanic research, due to the\nunpredictable disturbances and strong coupling among the AUV's degrees of\nfreedom. In this paper, we developed large language model (LLM)-enhanced\nreinforcement learning (RL)-based adaptive S-surface controller for AUVs.\nSpecifically, LLMs are introduced for the joint optimization of controller\nparameters and reward functions in RL training. Using multi-modal and\nstructured explicit task feedback, LLMs enable joint adjustments, balance\nmultiple objectives, and enhance task-oriented performance and adaptability. In\nthe proposed controller, the RL policy focuses on upper-level tasks, outputting\ntask-oriented high-level commands that the S-surface controller then converts\ninto control signals, ensuring cancellation of nonlinear effects and\nunpredictable external disturbances in extreme sea conditions. Under extreme\nsea conditions involving complex terrain, waves, and currents, the proposed\ncontroller demonstrates superior performance and adaptability in high-level\ntasks such as underwater target tracking and data collection, outperforming\ntraditional PID and SMC controllers."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-831",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00941",
    "b_title":[
      "C2S-AE: CSI to Sensing enabled by an Auto-Encoder-based Framework"
    ],
    "b_abstract":[
      "Next-generation mobile networks are set to utilize integrated sensing and\ncommunication (ISAC) as a critical technology, providing significant support\nfor sectors like the industrial Internet of Things (IIoT), extended reality\n(XR), and smart home applications. A key challenge in ISAC implementation is\nthe extraction of sensing parameters from radio signals, a task that\nconventional methods struggle to achieve due to the complexity of acquiring\nsensing channel data. In this paper, we introduce a novel auto-encoder\n(AE)-based framework to acquire sensing information using channel state\ninformation (CSI). Specifically, our framework, termed C2S (CSI to sensing)-AE,\nlearns the relationship between CSI and the delay power spectrum (DPS), from\nwhich the range information can be readily accessed. To validate our\nframework's performance, we conducted measurements of DPS and CSI in real-world\nscenarios and introduced the dataset 'SHU7'. Our extensive experiments\ndemonstrate that the framework excels in C2S extrapolation, surpassing existing\nmethods in terms of accuracy for both delay and signal strength of individual\npaths. This innovative approach holds the potential to greatly enhance sensing\ncapabilities in future mobile networks, paving the way for more robust and\nversatile ISAC applications."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09207",
    "c_title":[
      "Modeling and Physics of Multiferroic Perovskite Manganites"
    ],
    "c_abstract":[
      "A new type of multiferroicity was experimentally discovered in 2003 in a\nperovskite manganite TbMnO$_3$ where its ferroelectricity is induced by\ncycloidally ordered Mn spins. Susequently, such spin-cycloid multiferroic phase\nwas also discovered in $R$MnO$_3$ with other rare-earth ions $R$=Dy,\nEu$_{1-x}$Y$_x$, Tb$_{1-x}$Gd$_x$, etc. In this class of materials, the\nmagnetism and ferroelectricity are inseparably coupled, and resulting strong\nmagnetoelectric coupling enables us to control\/manipulate the electricity\n(magnetism) by magnetic (electric) fields. Moreover, many interesting\nmagnetoelectric phenomena due to their cross correlation have been discovered.\nIn this article, we discuss a microscopic theoretical model for $R$MnO$_3$\nconstructed by taking into account their precise electronic and lattice\nstructures and overview the theoretical works based on this model which\nelucidated rich magnetoelectric phenomena of $R$MnO$_3$. The perovskite\nmanganites are not only the first-discovered spin-spiral multiferroic materials\nbut also a typical class of materials that exhibits most of the magnetoelectric\nphenomena manifested in many other multiferroics. Therefore, the comprehensive\nunderstanding of $R$MnO$_3$ directly leads to the clarification of universal\nphysics of magnetoelectric phenomena in multiferroic materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-832",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16603",
    "b_title":[
      "Superadditivity at Large Charge"
    ],
    "b_abstract":[
      "The weak gravity conjecture has been invoked to conjecture that the\ndimensions of charged operators in a CFT should obey a superadditivity relation\n(sometimes referred to as convexity). In this paper, we study superadditivity\nof the operator spectrum in theories expanded about the semi-classical saddle\npoint that dominates correlators of large charge operators. We explore this in\ntwo contexts. The first is a model with two scalar fields that carry different\ncharges, at a non-trivial Wilson-Fisher fixed point. A careful analysis of the\nsemi-classics for this two field model demonstrates that 'quantum' violations\nof superadditivity (those not forbidden by the conjecture) persist in the large\ncharge regime. We then turn to study the general properties of CFTs at large\ncharge as bottom-up EFTs. By a trial and error procedure we come up with a\nseemingly consistent family of examples violating the conjecture. In so doing\nthe presence of a genuine dilaton field appears necessary. On the one hand our\nresult demonstrates that the superadditivity conjecture cannot be proven purely\non the basis of a bottom-up analysis. On the other hand, the need for a\ndilaton, with the corresponding infinite fine tuning, indicates the\nconjecture-violating EFTs are unlikely to be UV completable."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03316",
    "c_title":[
      "Hidden $SL_2(\\mathbb{Z})$-symmetry in $BC_l^{(2)}$"
    ],
    "c_abstract":[
      "A well-known \\(\\Gamma_\\theta\\)-action on the characters of integrable highest\nweight modules over the affine Lie algebra of type \\(BC_l^{(2)}\\) at a positive\nlevel is extended to an \\(\\mathrm{SL}_2(\\mathbb{Z})\\)-action at a positive even\nlevel by supplementing their twisted characters."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-833",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14893",
    "b_title":[
      "Incorporating Sustainability in Electronics Design: Obstacles and\n  Opportunities"
    ],
    "b_abstract":[
      "Life cycle assessment (LCA) is a methodology for holistically measuring the\nenvironmental impact of a product from initial manufacturing to end-of-life\ndisposal. However, the extent to which LCA informs the design of computing\ndevices remains unclear. To understand how this information is collected and\napplied, we interviewed 17 industry professionals with experience in LCA or\nelectronics design, systematically coded the interviews, and investigated\ncommon themes. These themes highlight the challenge of LCA data collection and\nreveal distributed decision-making processes where responsibility for\nsustainable design choices, and their associated costs, is often ambiguous. Our\nanalysis identifies opportunities for HCI technologies to support LCA\ncomputation and its integration into the design process to facilitate\nsustainability-oriented decision-making. While this work provides a nuanced\ndiscussion about sustainable design in the information and communication\ntechnologies (ICT) hardware industry, we hope our insights will also be\nvaluable to other sectors."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13116",
    "c_title":[
      "New gravitational wave probe of vector dark matter"
    ],
    "c_abstract":[
      "The longitudinal components of massive vector fields generated during\ninflation constitute a well-motivated dark matter candidate, with interesting\nphenomenological implications. During the epoch of radiation domination\nfollowing inflation, their spectrum exhibits a peak at small scales, whose\namplitude and position are governed by the parameters of the dark matter model.\nWe calculate the stochastic gravitational wave spectrum induced at second order\nin fluctuations by such a longitudinal vector peak. We demonstrate that the\namplitude of the gravitational wave spectrum can, in principle, reach\nsignificant values at nano-Hertz frequencies or lower. This result suggests a\nnovel gravitational wave probe to test inflationary vector dark matter\nscenarios, independent from assumptions on the coupling of dark vectors to the\nStandard Model. Additionally, we derive new analytical formulas for the\nlongitudinal vector transfer functions during radiation domination, offering a\nvaluable tool for characterising the convolution integrals that govern the\nproperties of the induced gravitational waves."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "gr-qc",
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-834",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14097",
    "b_title":[
      "A comprehensive study of bound-states for the nonlinear Schr\\\"odinger\n  equation on single-knot metric graphs"
    ],
    "b_abstract":[
      "We study the existence and qualitative properties of action ground-states\n(that is, bound-states with minimal action) {of the nonlinear Schr\\\"odinger\nequation} over single-knot metric graphs -- which are made of half-lines, loops\nand pendants, all connected at a single vertex. First, we prove existence of\naction ground-state for generic single-knot graphs, even in the absence of an\nassociated variational problem. Second, for regular single-knot graphs of\nlength $\\ell$, we perform a complete analysis of positive monotone\nbound-states. Furthermore, we characterize all positive bound-states when\n$\\ell$ is small and prove some symmetry-breaking results for large $\\ell$.\nFinally, we apply the results to some particular graphs to illustrate the\ncomplex relation between action ground-states and the topological {and metric}\nfeatures of the underlying metric graph.\n  The proofs are nonvariational, using a careful phase-plane analysis, the\nstudy of sections of period functions, asymptotic estimates and blowup\narguments. We show, in particular, how nonvariational techniques are\ncomplementary to variational ones in order to deeply understand bound-states of\nthe nonlinear Schr\\\"odinger equation on metric graphs."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.02886",
    "c_title":[
      "Advancements in Mobile Edge Computing and Open RAN: Leveraging\n  Artificial Intelligence and Machine Learning for Wireless Systems"
    ],
    "c_abstract":[
      "Mobile Edge Computing (MEC) and Open Radio Access Networks (ORAN) are\ntransformative technologies in the development of next-generation wireless\ncommunication systems. MEC pushes computational resources closer to end-users,\nenabling low latency and efficient processing, while ORAN promotes\ninteroperability and openness in radio networks, thereby fostering innovation.\nThis paper explores recent advancements in these two domains, with a particular\nfocus on how Artificial Intelligence (AI) and Machine Learning (ML) techniques\nare being utilized to solve complex wireless challenges. In MEC, Deep\nReinforcement Learning (DRL) is leveraged for optimizing computation\noffloading, ensuring energy-efficient solutions, and meeting Quality of Service\n(QoS) requirements. In ORAN, AI\/ML is used to develop intelligent xApps for\nnetwork slicing, scheduling, and online training to enhance network\nadaptability. This reading report provides an in-depth analysis of multiple key\npapers, discusses the methodologies employed, and highlights the impact of\nthese technologies in improving network efficiency and scalability."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-835",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18689",
    "b_title":[
      "The initial mass-remnant mass relation for core collapse supernovae"
    ],
    "b_abstract":[
      "The first direct detection of gravitational waves in 2015 marked the\nbeginning of a new era for the study of compact objects. Upcoming detectors,\nsuch as the Einstein Telescope, are expected to add thousands of binary\ncoalescences to the list. However, from a theoretical perspective, our\nunderstanding of compact objects is hindered by many uncertainties, and a\ncomprehensive study of the nature of stellar remnants from core-collapse\nsupernovae is still lacking. In this work, we investigate the properties of\nstellar remnants using a homogeneous grid of rotating and non-rotating massive\nstars at various metallicities from Limongi and Chieffi 2018. We simulate the\nsupernova explosion of the evolved progenitors using the HYdrodynamic Ppm\nExplosion with Radiation diffusION (HYPERION) code (Limongi and Chieffi 2020),\nassuming a thermal bomb model calibrated to match the main properties of\nSN1987A. We find that the heaviest black hole that can form depends on the\ninitial stellar rotation, metallicity, and the assumed criterion for the onset\nof pulsational pair-instability supernovae. Non-rotating progenitors at\n$\\big[\\rm Fe\/H \\big]=-3$ can form black holes up to $\\sim 87 M_\\odot$, falling\nwithin the theorized pair-instability mass gap. Conversely, enhanced wind mass\nloss prevents the formation of BHs more massive than $\\sim 41.6 M_\\odot$ from\nrotating progenitors. We use our results to study the black hole mass\ndistribution from a population of $10^6$ isolated massive stars following a\nKroupa initial mass function. Finally, we provide fitting formulas to compute\nthe mass of compact remnants as a function of stellar progenitor properties.\nOur up-to-date prescriptions can be easily implemented in rapid population\nsynthesis codes."
    ],
    "b_categories":[
      [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04285",
    "c_title":[
      "Exponentially Better Bounds for Quantum Optimization via Dynamical\n  Simulation"
    ],
    "c_abstract":[
      "We provide several quantum algorithms for continuous optimization that do not\nrequire any gradient estimation. Instead, we encode the optimization problem\ninto the dynamics of a physical system and coherently simulate the time\nevolution. This allows us, in certain cases, to obtain exponentially better\nquery upper bounds relative to the best known upper bounds for gradient-based\noptimization schemes which utilize quantum computers only for the evaluation of\ngradients. Our first two algorithms can find local optima of a differentiable\nfunction $f: \\mathbb{R}^N \\rightarrow \\mathbb{R}$ by simulating either\nclassical or quantum dynamics with friction via a time-dependent Hamiltonian.\nWe show that these methods require $O(N\\kappa^2\/h_x^2\\epsilon)$ queries to a\nphase oracle to find an $\\epsilon$-approximate local optimum of a locally\nquadratic objective function, where $\\kappa$ is the condition number of the\nHessian matrix and $h_x$ is the discretization spacing. In contrast, we show\nthat gradient-based methods require $O(N(1\/\\epsilon)^{\\kappa \\log(3)\/4})$\nqueries. Our third algorithm can find the global optimum of $f$ by preparing a\nclassical low-temperature thermal state via simulation of the classical\nLiouvillian operator associated with the Nos\\'e Hamiltonian. We use results\nfrom the quantum thermodynamics literature to bound the thermalization time for\nthe discrete system. Additionally, we analyze barren plateau effects that\ncommonly plague quantum optimization algorithms and observe that our approach\nis vastly less sensitive to this problem than standard gradient-based\noptimization. Our results suggests that these dynamical optimization approaches\nmay be far more scalable for future quantum machine learning, optimization and\nvariational experiments than was widely believed."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-836",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08040",
    "b_title":[
      "On Constructing Finite Automata by Relational Programming"
    ],
    "b_abstract":[
      "We consider ways to construct a transducer for a given set of input word to\noutput symbol pairs. This is motivated by the need for representing game\nplaying programs in a low-level mathematical format that can be analyzed by\nalgebraic tools. This is different from the classical applications of finite\nstate automata, thus the usual optimization techniques are not directly\napplicable. Therefore, we use relational programming tools to find minimal\ntransducers realizing a given set of input-output pairs."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11439",
    "c_title":[
      "Stability and Nucleation of Dipole Strings in Uniaxial Chiral Magnets"
    ],
    "c_abstract":[
      "We report on the stability of the magnetic dipole string (DS), a\nthree-dimensional magnetic texture formed by two coupled Bloch points with\nopposite topological charges, separated by an equilibrium distance. Previous\nstudies demonstrated the stability of such configurations through geometric\nconfinement or coupling with local perturbations in the magnetization field,\nsuch as skyrmion strings or dislocations in helical modulations. Here, we show\nthat, in uniaxial chiral magnets, an isolated DS remains stable in an\nunperturbed vacuum, thus representing a true three-dimensional soliton. The\nphase diagram illustrates the stability of the DS embedded in the conical or\nhelical phases across a broad range of material parameters and external\nmagnetic fields. Using the geodesic nudged elastic band method applied to a\nregularized micromagnetic model, we demonstrate that isolated DSs are protected\nfrom collapse by an energy barrier. Stochastic spin-lattice simulations\ndemonstrate that DSs can spontaneously nucleate during in-field annealing. This\nwork aims to stimulate the experimental observation of DSs and further\nexploration of uniaxial chiral magnets."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-837",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08540",
    "b_title":[
      "Knowledge prompt chaining for semantic modeling"
    ],
    "b_abstract":[
      "The task of building semantics for structured data such as CSV, JSON, and XML\nfiles is highly relevant in the knowledge representation field. Even though we\nhave a vast of structured data on the internet, mapping them to domain\nontologies to build semantics for them is still very challenging as it requires\nthe construction model to understand and learn graph-structured knowledge.\nOtherwise, the task will require human beings' effort and cost. In this paper,\nwe proposed a novel automatic semantic modeling framework: Knowledge Prompt\nChaining. It can serialize the graph-structured knowledge and inject it into\nthe LLMs properly in a Prompt Chaining architecture. Through this knowledge\ninjection and prompting chaining, the model in our framework can learn the\nstructure information and latent space of the graph and generate the semantic\nlabels and semantic graphs following the chains' insturction naturally. Based\non experimental results, our method achieves better performance than existing\nleading techniques, despite using reduced structured input data."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16966",
    "c_title":[
      "A note on elliptic curves on toric surfaces"
    ],
    "c_abstract":[
      "In this paper, we study the Severi varieties parametrizing integral curves of\ngeometric genus one on polarized toric surfaces in characteristic zero and\ndescribe their irreducible components. We show that the irreducible components\nare in natural bijection with certain affine sublattices of the lattice of\ncharacters of the toric surface. The sublattices are described explicitly in\nterms of the polygon defining the polarization of the toric surface."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-838",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11144",
    "b_title":[
      "Consistency of heritability estimation from summary statistics in\n  high-dimensional linear models"
    ],
    "b_abstract":[
      "In Genome-Wide Association Studies (GWAS), heritability is defined as the\nfraction of variance of an outcome explained by a large number of genetic\npredictors in a high-dimensional polygenic linear model. This work studies the\nasymptotic properties of the most common estimator of heritability from summary\nstatistics called linkage disequilibrium score (LDSC) regression, together with\na simpler and closely related estimator called GWAS heritability (GWASH). These\nestimators are analyzed in their basic versions and under various modifications\nused in practice including weighting and standardization. We show that, with\nsome variations, two conditions which we call weak dependence (WD) and\nbounded-kurtosis effects (BKE) are sufficient for consistency of both the basic\nLDSC with fixed intercept and GWASH estimators, for both Gaussian and\nnon-Gaussian predictors. For Gaussian predictors it is shown that these\nconditions are also necessary for consistency of GWASH (with truncation) and\nsimulations suggest that necessity holds too when the predictors are\nnon-Gaussian. We also show that, with properly truncated weights, weighting\ndoes not change the consistency results, but standardization of the predictors\nand outcome, as done in practice, introduces bias in both LDSC and GWASH if the\ntwo essential conditions are violated. Finally, we show that, when population\nstratification is present, all the estimators considered are biased, and the\nbias is not remedied by using the LDSC regression estimator with free\nintercept, as originally suggested by the authors of that estimator."
    ],
    "b_categories":[
      [
        "math.ST",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15773",
    "c_title":[
      "Search for continuous gravitational waves from neutron stars in five\n  globular clusters with a phase-tracking hidden Markov model in the third LIGO\n  observing run"
    ],
    "c_abstract":[
      "A search is performed for continuous gravitational waves emitted by unknown\nneutron stars in five nearby globular clusters using data from the third Laser\nInterferometer Gravitational-Wave Observatory (LIGO) observing run, over the\nfrequency range $100$--$800\\,\\mathrm{Hz}$. The search uses a hidden Markov\nmodel to track both the frequency and phase of the continuous wave signal from\none coherent segment to the next. It represents the first time that a\nphase-tracking hidden Markov model has been used in a LIGO search. After\napplying vetoes to reject candidates consistent with non-Gaussian artifacts, no\nsignificant candidates are detected. Estimates of the strain sensitivity at\n95\\% confidence $h_{0,\\mathrm{eff}}^{95\\%}$ and corresponding neutron star\nellipticity $\\epsilon^{95\\%}$ are presented. The best strain sensitivity,\n$h_{0,\\mathrm{eff}}^{95\\%} = 2.7 \\times 10^{-26}$ at $211\\,\\mathrm{Hz}$, is\nachieved for the cluster NGC6544."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-839",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01193",
    "b_title":[
      "Leibniz's contested infinitesimals: Further depictions"
    ],
    "b_abstract":[
      "We contribute to the lively debate in current scholarship on the Leibnizian\ncalculus. In a recent text, Arthur and Rabouin argue that non-Archimedean\ncontinua are incompatible with Leibniz's concepts of number, quantity and\nmagnitude.\n  They allege that Leibniz viewed infinitesimals as contradictory, and claim to\ndeduce such a conclusion from an analysis of the Leibnizian definition of\nquantity. However, their argument is marred by numerous errors, deliberate\nomissions, and misrepresentations, stemming in a number of cases from flawed\nanalyses in their earlier publications.\n  We defend the thesis, traceable to the classic study by Henk Bos, that\nLeibniz used genuine infinitesimals, which he viewed as fictional mathematical\nentities (and not merely shorthand for talk about more ordinary quantities) on\npar with negatives and imaginaries."
    ],
    "b_categories":[
      [
        "math.HO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.07189",
    "c_title":[
      "Beamforming Design for Beyond Diagonal RIS-Aided Cell-Free Massive MIMO\n  Systems"
    ],
    "c_abstract":[
      "Reconfigurable intelligent surface (RIS)-aided cell-free (CF) massive\nmultiple-input multiple-output (mMIMO) is a promising architecture for further\nimproving spectral efficiency (SE) with low cost and power consumption.\nHowever, conventional RIS has inevitable limitations due to its capability of\nonly reflecting signals. In contrast, beyond-diagonal RIS (BD-RIS), with its\nability to both reflect and transmit signals, has gained great attention. This\ncorrespondence focuses on using BD-RIS to improve the sum SE of CF mMIMO\nsystems. This requires completing the beamforming design under the transmit\npower constraints and unitary constraints of the BD-RIS, by optimizing active\nand passive beamformer simultaneously. To tackle this issue, we introduce an\nalternating optimization algorithm that decomposes it using fractional\nprogramming and solves the subproblems alternatively. Moreover, to address the\nchallenge introduced by the unitary constraint on the beamforming matrix of the\nBD-RIS, a manifold optimization algorithm is proposed to solve the problem\noptimally. Simulation results show that BD-RISs outperform RISs\ncomprehensively, especially in the case of the full connected architecture\nwhich achieves the best performance, enhancing the sum SE by around 40%\ncompared to ideal RISs."
    ],
    "c_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-840",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16450",
    "b_title":[
      "Make Literature-Based Discovery Great Again through Reproducible\n  Pipelines"
    ],
    "b_abstract":[
      "By connecting disparate sources of scientific literature, literature\\-\/based\ndiscovery (LBD) methods help to uncover new knowledge and generate new research\nhypotheses that cannot be found from domain-specific documents alone. Our work\nfocuses on bisociative LBD methods that combine bisociative reasoning with LBD\ntechniques. The paper presents LBD through the lens of reproducible science to\nensure the reproducibility of LBD experiments, overcome the inconsistent use of\nbenchmark datasets and methods, trigger collaboration, and advance the LBD\nfield toward more robust and impactful scientific discoveries. The main novelty\nof this study is a collection of Jupyter Notebooks that illustrate the steps of\nthe bisociative LBD process, including data acquisition, text preprocessing,\nhypothesis formulation, and evaluation. The contributed notebooks implement a\nselection of traditional LBD approaches, as well as our own ensemble-based,\noutlier-based, and link prediction-based approaches. The reader can benefit\nfrom hands-on experience with LBD through open access to benchmark datasets,\ncode reuse, and a ready-to-run Docker recipe that ensures reproducibility of\nthe selected LBD methods."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06163",
    "c_title":[
      "VACT: A Video Automatic Causal Testing System and a Benchmark"
    ],
    "c_abstract":[
      "With the rapid advancement of text-conditioned Video Generation Models\n(VGMs), the quality of generated videos has significantly improved, bringing\nthese models closer to functioning as ``*world simulators*'' and making\nreal-world-level video generation more accessible and cost-effective. However,\nthe generated videos often contain factual inaccuracies and lack understanding\nof fundamental physical laws. While some previous studies have highlighted this\nissue in limited domains through manual analysis, a comprehensive solution has\nnot yet been established, primarily due to the absence of a generalized,\nautomated approach for modeling and assessing the causal reasoning of these\nmodels across diverse scenarios. To address this gap, we propose VACT: an\n**automated** framework for modeling, evaluating, and measuring the causal\nunderstanding of VGMs in real-world scenarios. By combining causal analysis\ntechniques with a carefully designed large language model assistant, our system\ncan assess the causal behavior of models in various contexts without human\nannotation, which offers strong generalization and scalability. Additionally,\nwe introduce multi-level causal evaluation metrics to provide a detailed\nanalysis of the causal performance of VGMs. As a demonstration, we use our\nframework to benchmark several prevailing VGMs, offering insight into their\ncausal reasoning capabilities. Our work lays the foundation for systematically\naddressing the causal understanding deficiencies in VGMs and contributes to\nadvancing their reliability and real-world applicability."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-841",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09328",
    "b_title":[
      "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against\n  Model Extraction Attacks"
    ],
    "b_abstract":[
      "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from $12,000$ to $200$ with zero training cost."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14682",
    "c_title":[
      "Dual-Source SPIR over a noiseless MAC without Data Replication or Shared\n  Randomness"
    ],
    "c_abstract":[
      "Information-theoretically secure Symmetric Private Information Retrieval\n(SPIR) is known to be infeasible over noiseless channels with a single server.\nKnown solutions to overcome this infeasibility involve additional resources\nsuch as database replication, shared randomness, or noisy channels. In this\npaper, we propose an alternative approach for achieving SPIR with\ninformation-theoretic security guarantees, without relying on shared\nrandomness, noisy channels, or data replication. Specifically, we demonstrate\nthat it is sufficient to use a noiseless binary adder multiple-access channel,\nwhere inputs are controlled by two non-colluding servers and the output is\nobserved by the client, alongside a public noiseless communication channel\nbetween the client and the servers. Furthermore, in this setting, we\ncharacterize the optimal file rates, i.e., the file lengths normalized by the\nnumber of channel uses, that can be transferred."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-842",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08114",
    "b_title":[
      "Change Captioning in Remote Sensing: Evolution to SAT-Cap -- A\n  Single-Stage Transformer Approach"
    ],
    "b_abstract":[
      "Change captioning has become essential for accurately describing changes in\nmulti-temporal remote sensing data, providing an intuitive way to monitor\nEarth's dynamics through natural language. However, existing change captioning\nmethods face two key challenges: high computational demands due to multistage\nfusion strategy, and insufficient detail in object descriptions due to limited\nsemantic extraction from individual images. To solve these challenges, we\npropose SAT-Cap based on the transformers model with a single-stage feature\nfusion for remote sensing change captioning. In particular, SAT-Cap integrates\na Spatial-Channel Attention Encoder, a Difference-Guided Fusion module, and a\nCaption Decoder. Compared to typical models that require multi-stage fusion in\ntransformer encoder and fusion module, SAT-Cap uses only a simple cosine\nsimilarity-based fusion module for information integration, reducing the\ncomplexity of the model architecture. By jointly modeling spatial and channel\ninformation in Spatial-Channel Attention Encoder, our approach significantly\nenhances the model's ability to extract semantic information from objects in\nmulti-temporal remote sensing images. Extensive experiments validate the\neffectiveness of SAT-Cap, achieving CIDEr scores of 140.23% on the LEVIR-CC\ndataset and 97.74% on the DUBAI-CC dataset, surpassing current state-of-the-art\nmethods. The code and pre-trained models will be available online."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09895",
    "c_title":[
      "$\\eta$, $\\eta^\\prime$ mesons from lattice QCD in fully physical\n  conditions"
    ],
    "c_abstract":[
      "We determine masses and mixing parameters of the $\\eta$ and $M_{\\eta^\\prime}$\nmeson in lattice QCD. The calculations are carried out on a set of 13 ETMC\ngauge ensembles with $N_f=2+1+1$ (maximally) twisted-mass Clover-improved\nquarks. These ensemble cover four values of the lattice spacing\n$a=0.057\\mathrm{fm},...,0.092\\mathrm{fm}$ and pion masses from\n$140\\mathrm{MeV}$ to $360\\mathrm{MeV}$, including three ensembles at physical\nquark masses and six ensembles with $M_\\pi<200\\mathrm{MeV}$. The strange-quark\ncontribution is treated in a mixed-action approach using Osterwalder-Seiler\nfermions to avoid complications due to flavor mixing in the heavy quark sector\nand to enable the use of the one-end trick in the computation of strange\nquark-disconnected diagrams. With the strange-quark mass tuned to its physical\nvalue and several ensembles having close-to-physical light-quark mass,\nuncertainties related to the chiral extrapolations are reduced significantly\ncompared to earlier studies. Physical results are computed with fully\ncontrolled systematics from a combined chiral, continuum and infinite-volume\nextrapolation, and a full error budget is obtained from model averages over of\nvarious fit ans\\\"atze and data cuts. Our results for the masses are given by\n$M_\\eta=551(16)\\mathrm{MeV}$ and $M_{\\eta^\\prime}=972(20)\\mathrm{MeV}$,\nrespectively, where statistical and systematic errors have been added in\nquadrature. For the mixing angle and decay-constant parameters the\nFeldmann-Kroll-Stech scheme is employed to compute them from pseudoscalar\nmatrix elements in the quark-flavor basis. For the mixing angle we obtain\n$\\phi^\\mathrm{phys}=39.3(2.0)^\\circ$ and our results for the decay-constant\nparameters are given by $f_l^\\mathrm{phys}=138.6(4.4)\\mathrm{MeV}$ and\n$f_s^\\mathrm{phys}=170.7(3.3)\\mathrm{MeV}$."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-843",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09318",
    "b_title":[
      "FpgaHub: Fpga-centric Hyper-heterogeneous Computing Platform for Big\n  Data Analytics"
    ],
    "b_abstract":[
      "Modern data analytics requires a huge amount of computing power and processes\na massive amount of data. At the same time, the underlying computing platform\nis becoming much more heterogeneous on both hardware and software. Even though\nspecialized hardware, e.g., FPGA- or GPU- or TPU-based systems, often achieves\nbetter performance than a CPU-only system due to the slowing of Moore's law,\nsuch systems are limited in what they can do. For example, GPU-only approaches\nsuffer from severe IO limitations. To truly exploit the potential of hardware\nheterogeneity, we present FpgaHub, an FPGA-centric hyper-heterogeneous\ncomputing platform for big data analytics. The key idea of FpgaHub is to use\nreconfigurable computing to implement a versatile hub complementing other\nprocessors (CPUs, GPUs, DPUs, programmable switches, computational storage,\netc.). Using an FPGA as the basis, we can take advantage of its highly\nreconfigurable nature and rich IO interfaces such as PCIe, networking, and\non-board memory, to place it at the center of the architecture and use it as a\ndata and control plane for data movement, scheduling, pre-processing, etc.\nFpgaHub enables architectural flexibility to allow exploring the rich design\nspace of heterogeneous computing platforms."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04079",
    "c_title":[
      "Structural Parameters of the Thin Disk Population from Evolved Stars in\n  Solar Neighborhood"
    ],
    "c_abstract":[
      "This study investigates the structural parameters of the thin-disk population\nby analyzing the spatial distribution of evolved stars in the solar\nneighbourhood. From the $\\it Gaia$ Data Release 3 database, about 39.1 million\nstars within 1 kpc and with relative parallax errors\n$\\sigma_{\\varpi}\/\\varpi\\leq 0.10$ were selected. The photometric data was\ncorrected for extinction using a Galactic dust map. The sample was refined by\nconsidering the color-magnitude region $M_{\\rm G}\\times (G_{\\rm BP}-G_{\\rm\nRP})_0$ associated with evolved stars, applying a stricter parallax error limit\nof $\\sigma_{\\varpi}\/\\varpi\\leq 0.02$, and yielding 671,600 stars. The star\nsample was divided into 36 regions based on their Galactic coordinates, with\nevolved stars in the absolute magnitude range of $-1< M_{\\rm G}~{\\rm (mag)}\\leq\n4$ further split into five one-unit magnitude intervals. This led to 180\nsubgroups whose space density profiles were modelled using a single-component\nGalaxy model. The analysis shows that the space densities are in agreement with\nthe literature and that the scale heights vary with $200<H~{\\rm (pc)}<600$\ninterval to their absolute magnitudes. Red clump stars in the solar\nneighbourhood were also estimated to have a scale height of $295\\pm10$ pc.\nThese findings indicate that evolved stars with bright absolute magnitudes\noriginate from the evolution of the early spectral-type stars with short scale\nheight, while fainter ones come from the evolution of the intermediate\nspectral-type stars with large scale height, suggesting variations in scale\nheight reflect the contribution of Galactic evolution processes."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-844",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18423",
    "b_title":[
      "Retrieval Dexterity: Efficient Object Retrieval in Clutters with\n  Dexterous Hand"
    ],
    "b_abstract":[
      "Retrieving objects buried beneath multiple objects is not only challenging\nbut also time-consuming. Performing manipulation in such environments presents\nsignificant difficulty due to complex contact relationships. Existing methods\ntypically address this task by sequentially grasping and removing each\noccluding object, resulting in lengthy execution times and requiring\nimpractical grasping capabilities for every occluding object. In this paper, we\npresent a dexterous arm-hand system for efficient object retrieval in\nmulti-object stacked environments. Our approach leverages large-scale parallel\nreinforcement learning within diverse and carefully designed cluttered\nenvironments to train policies. These policies demonstrate emergent\nmanipulation skills (e.g., pushing, stirring, and poking) that efficiently\nclear occluding objects to expose sufficient surface area of the target object.\nWe conduct extensive evaluations across a set of over 10 household objects in\ndiverse clutter configurations, demonstrating superior retrieval performance\nand efficiency for both trained and unseen objects. Furthermore, we\nsuccessfully transfer the learned policies to a real-world dexterous\nmulti-fingered robot system, validating their practical applicability in\nreal-world scenarios. Videos can be found on our project website\nhttps:\/\/ChangWinde.github.io\/RetrDex."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06270",
    "c_title":[
      "Sectorial Exclusion Criteria in the Marxist Analysis of the Average Rate\n  of Profit: The United States Case (1960-2020)"
    ],
    "c_abstract":[
      "The long-term estimation of the Marxist average rate of profit does not\nadhere to a theoretically grounded standard regarding which economic activities\nshould or should not be included for such purposes, which is relevant because\nmethodological non-uniformity can be a significant source of overestimation or\nunderestimation, generating a less accurate reflection of the capital\naccumulation dynamics. This research aims to provide a standard Marxist\ndecision criterion regarding the inclusion and exclusion of economic activities\nfor the calculation of the Marxist average profit rate for the case of United\nStates economic sectors from 1960 to 2020, based on the Marxist definition of\nproductive labor, its location in the circuit of capital, and its relationship\nwith the production of surplus value. Using wavelet-transformed Daubechies\nfilters with increased symmetry, empirical mode decomposition, Hodrick-Prescott\nfilter embedded in unobserved components model, and a wide variety of unit root\ntests the internal theoretical consistency of the presented criteria is\nevaluated. Also, the objective consistency of the theory is evaluated by a\ndynamic factor auto-regressive model, Principal Component Analysis, Singular\nValue Decomposition and Backward Elimination with Linear and Generalized Linear\nModels. The results are consistent both theoretically and econometrically with\nthe logic of Marx's political economy."
    ],
    "c_categories":[
      [
        "econ.EM",
        "econ.GN",
        "econ.TH",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-845",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14511",
    "b_title":[
      "Strong coupling quantum electrodynamics Hartree-Fock response theory"
    ],
    "b_abstract":[
      "The development of reliable ab initio methods for light-matter strong\ncoupling is necessary for a deeper understanding of molecular polaritons. The\nrecently developed strong coupling quantum electrodynamics Hartree-Fock model\n(SC-QED-HF) provides cavity-consistent molecular orbitals, overcoming several\ndifficulties related to the simpler QED-HF wave function. In this paper, we\nfurther develop this method by implementing the response theory for SC-QED-HF.\nWe compare the derived linear response equations with the time-dependent QED-HF\ntheory and discuss the validity of equivalence relations connecting matter and\nelectromagnetic observables. Our results show that electron-photon correlation\ninduces an excitation redshift compared to the time-dependent QED-HF energies,\nand we discuss the effect of the dipole self-energy on the ground and excited\nstate properties with different basis sets."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00813",
    "c_title":[
      "HLoRA: Efficient Federated Learning System for LLM Heterogeneous\n  Fine-Tuning"
    ],
    "c_abstract":[
      "Federated learning systems have been identified as an efficient approach to\nscaling distributed model training with a large amount of participants or data\nowners while guaranteeing data privacy. To apply the current most popular\npre-trained large language models to other domains with data privacy guarantee\nrequirements, existing works propose fine-tuning the pre-trained large language\nmodels in federated learning environments across data owners using the\nparameter efficient fine-tuning approaches, LoRA. To address the resource and\ndata heterogeneous issues for the participants, previous works adopted\nheterogeneous LoRA using different ranks for different clients and pending\ntheir rank, which brings bias for the parameter aggregation.\n  To address this issue, we propose HLoRA, an efficient federated learning\nsystem utilizing a modified LoRA approach that incorporates rank heterogeneity\nto optimize communication and computational efficiency. Experimental results,\nconducted using the Microsoft Research Paraphrase Corpus (MRPC), Quora Question\nPairs (QQP) and Recognizing Textual Entailment (RTE), within the Plato\nfederated learning framework, demonstrate that our method not only reduces\nresource demands but also outperforms traditional LoRA applications in terms of\nconvergence speed and final model accuracy. This study shows that our approach\ncan significantly improve the practical deployment of federated LLM\nfine-tuning, particularly in environments with diverse client resources."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-846",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02509",
    "b_title":[
      "Facial Attractiveness Prediction in Live Streaming: A New Benchmark and\n  Multi-modal Method"
    ],
    "b_abstract":[
      "Facial attractiveness prediction (FAP) has long been an important computer\nvision task, which could be widely applied in live streaming for facial\nretouching, content recommendation, etc. However, previous FAP datasets are\neither small, closed-source, or lack diversity. Moreover, the corresponding FAP\nmodels exhibit limited generalization and adaptation ability. To overcome these\nlimitations, in this paper we present LiveBeauty, the first large-scale\nlive-specific FAP dataset, in a more challenging application scenario, i.e.,\nlive streaming. 10,000 face images are collected from a live streaming platform\ndirectly, with 200,000 corresponding attractiveness annotations obtained from a\nwell-devised subjective experiment, making LiveBeauty the largest open-access\nFAP dataset in the challenging live scenario. Furthermore, a multi-modal FAP\nmethod is proposed to measure the facial attractiveness in live streaming.\nSpecifically, we first extract holistic facial prior knowledge and multi-modal\naesthetic semantic features via a Personalized Attractiveness Prior Module\n(PAPM) and a Multi-modal Attractiveness Encoder Module (MAEM), respectively,\nthen integrate the extracted features through a Cross-Modal Fusion Module\n(CMFM). Extensive experiments conducted on both LiveBeauty and other\nopen-source FAP datasets demonstrate that our proposed method achieves\nstate-of-the-art performance. Dataset will be available soon."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17417",
    "c_title":[
      "Spin-forbidden excitations in the magneto-optical spectra of CrI$_3$\n  tuned by covalency"
    ],
    "c_abstract":[
      "Spin-forbidden ($\\Delta S \\neq 0$) multiplet excitations and their coupling\nto magnetic properties are of increasing importance for magneto-optical studies\nof correlated materials. Nonetheless, the mechanisms for optically brightening\nthese transitions and their generality remain poorly understood. Here, we\nreport magnetic circular dichroism (MCD) spectroscopy on the van der Waals\n(vdW) ferromagnet (FM) CrI$_3$. Previously unreported spin-forbidden ($\\Delta S\n= 1$) ${}^4A_{2\\mathrm{g}} \\to{}^2E_\\mathrm{g}\/{}^2T_{1\\mathrm{g}}$ Cr${}^{3+}$\n$dd$ excitations are observed near the ligand-to-metal charge transfer (LMCT)\nexcitation threshold. The assignment of these excitations and their Cr$^{3+}$\nmultiplet character is established through complementary Cr $L_3$-edge resonant\ninelastic X-ray scattering (RIXS) measurements along with charge transfer\nmultiplet (CTM) calculations and chemical trends in the chromium trihalide\nseries (CrX$_3$, X = Cl, Br, I). We utilize the high sensitivity of MCD\nspectroscopy to study the thickness dependent optical response. The\nspin-forbidden excitations remain robust down to the monolayer limit and\nexhibit a significant magnetic field tunability across the antiferromagnetic to\nFM transition in few-layer samples. This behavior is associated to changes in\nthe metal-ligand covalency with magnetic state, as supported by our CTM\nanalysis. Our results clarify the magneto-optical response of CrI$_3$ and\nidentify covalency as a central mechanism for the brightening and\nfield-tunability of spin-forbidden multiplet excitations."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-847",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15798",
    "b_title":[
      "Mixture of Lookup Experts"
    ],
    "b_abstract":[
      "Mixture-of-Experts (MoE) activates only a subset of experts during inference,\nallowing the model to maintain low inference FLOPs and latency even as the\nparameter count scales up. However, since MoE dynamically selects the experts,\nall the experts need to be loaded into VRAM. Their large parameter size still\nlimits deployment, and offloading, which load experts into VRAM only when\nneeded, significantly increase inference latency. To address this, we propose\nMixture of Lookup Experts (MoLE), a new MoE architecture that is efficient in\nboth communication and VRAM usage. In MoLE, the experts are Feed-Forward\nNetworks (FFNs) during training, taking the output of the embedding layer as\ninput. Before inference, these experts can be re-parameterized as lookup tables\n(LUTs) that retrieves expert outputs based on input ids, and offloaded to\nstorage devices. Therefore, we do not need to perform expert computations\nduring inference. Instead, we directly retrieve the expert's computation\nresults based on input ids and load them into VRAM, and thus the resulting\ncommunication overhead is negligible. Experiments show that, with the same\nFLOPs and VRAM usage, MoLE achieves inference speeds comparable to dense models\nand significantly faster than MoE with experts offloading, while maintaining\nperformance on par with MoE."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04516",
    "c_title":[
      "The aerodynamic performance of a transonic airfoil with spanwise forcing"
    ],
    "c_abstract":[
      "Spanwise wall forcing in the form of streamwise-travelling waves is applied\nto the suction side of a transonic airfoil with a shock wave to reduce\naerodynamic drag. The study, conducted using direct numerical simulations,\nextends earlier findings by Quadrio et al. (J. Fluid Mech. vol. 942, 2022, R2)\nand confirms that the wall manipulation shifts the shock wave on the suction\nside towards the trailing edge of the profile, thereby enhancing its\naerodynamic efficiency. A parametric study over the parameters of wall forcing\nis carried out for the Mach number set at 0.7 and the Reynolds number at\n300,000. Similarities and differences with the incompressible plane case are\ndiscussed; for the first time, we describe how the interaction between the\nshock wave and the boundary layer is influenced by flow control via spanwise\nforcing. With suitable combinations of control parameters, the shock is\ndelayed, and results in a separated region whose length correlates well with\nfriction reduction. The analysis of the transient process following the sudden\napplication of control is used to link flow separation with the intensification\nof the shock wave."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-848",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20897",
    "b_title":[
      "Beyond Demographics: Fine-tuning Large Language Models to Predict\n  Individuals' Subjective Text Perceptions"
    ],
    "b_abstract":[
      "People naturally vary in their annotations for subjective questions and some\nof this variation is thought to be due to the person's sociodemographic\ncharacteristics. LLMs have also been used to label data, but recent work has\nshown that models perform poorly when prompted with sociodemographic\nattributes, suggesting limited inherent sociodemographic knowledge. Here, we\nask whether LLMs can be trained to be accurate sociodemographic models of\nannotator variation. Using a curated dataset of five tasks with standardized\nsociodemographics, we show that models do improve in sociodemographic prompting\nwhen trained but that this performance gain is largely due to models learning\nannotator-specific behaviour rather than sociodemographic patterns. Across all\ntasks, our results suggest that models learn little meaningful connection\nbetween sociodemographics and annotation, raising doubts about the current use\nof LLMs for simulating sociodemographic variation and behaviour."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17928",
    "c_title":[
      "Measuring decoherence due to quantum vacuum fluctuations"
    ],
    "c_abstract":[
      "The interaction of a particle with vacuum fluctuations -- which theoretically\nexist even in the complete absence of matter -- can lead to observable\nirreversible decoherence, if it were possible to switch on and off the particle\ncharge suddenly. We compute the leading order decoherence effect for such a\nscenario and propose an experimental setup for its detection. Such a\nmeasurement might provide further insights into the nature of vacuum\nfluctuations and a novel precision test for the decoherence theory."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "gr-qc",
        "hep-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-849",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07042",
    "b_title":[
      "Building networks of shared research interests by embedding words into a\n  representation space"
    ],
    "b_abstract":[
      "Departments within a university are not only administrative units, but also\nan effort to gather investigators around common fields of academic study. A\npervasive challenge is connecting members with shared research interests both\nwithin and between departments. Here I describe a workflow that adapts methods\nfrom natural language processing to generate a network connecting $n=79$\nmembers of a university department, or multiple departments within a faculty\n($n=278$), based on common topics in their research publications. After\nextracting and processing terms from $n=16,901$ abstracts in the PubMed\ndatabase, the co-occurrence of terms is encoded in a sparse document-term\nmatrix. Based on the angular distances between the presence-absence vectors for\nevery pair of terms, I use the uniform manifold approximation and projection\n(UMAP) method to embed the terms into a representational space such that terms\nthat tend to appear in the same documents are closer together. Each author's\ncorpus defines a probability distribution over terms in this space. Using the\nWasserstein distance to quantify the similarity between these distributions, I\ngenerate a distance matrix among authors that can be analyzed and visualized as\na graph. I demonstrate that this nonparametric method produces clusters with\ndistinct themes that are consistent with some academic divisions, while\nidentifying untapped connections among members. A documented workflow\ncomprising Python and R scripts is available under the MIT license at\nhttps:\/\/github.com\/PoonLab\/tragula."
    ],
    "b_categories":[
      [
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15732",
    "c_title":[
      "The geometric impact of the quantum Hall interface on a cone"
    ],
    "c_abstract":[
      "Recently, quantum Hall interface has become a popular subject of research;\ndistinct from that of the quantum Hall edge, which is constrained by external\nbackground confinement, the interface has the freedom to move, likely towards a\nstring-like state. In disk geometry, it was known that the interface energy has\nan extra correction due to its curvature which depends on the size of the disk.\nIn this work, we analytically calculate the energy of the integer quantum Hall\ninterface on a cone surface which has the advantage that its curvature is more\neasily adjustable. By tuning the length and curvature of the interface by the\ncone angle parameter $\\beta$, we analyze the dependence of the quantum Hall\ninterface energy on the curvature and verify this geometric correction.\nMoreover, we find that the tip of the cone geometry has an extra contribution\nto the energy that reflects on the $u_2,u_4$ term."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-850",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16320",
    "b_title":[
      "The Integral Chow Rings of the Moduli Stacks of Hyperelliptic Prym Pairs\n  I"
    ],
    "b_abstract":[
      "This paper is the first in a series dedicated to computing the integral Chow\nrings of the moduli stacks of Prym pairs. In this work, we compute the Chow\nring for Prym pairs arising from a single pair of Weierstrass points and from\nat most $(g-1)\/2 $ pairs when the genus $g$ of the curve is odd."
    ],
    "b_categories":[
      [
        "math.AG",
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.21057",
    "c_title":[
      "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its\n  Application to Quadrotor Control"
    ],
    "c_abstract":[
      "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-851",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15024",
    "b_title":[
      "Low degree conjecture implies sharp computational thresholds in\n  stochastic block model"
    ],
    "b_abstract":[
      "We investigate implications of the (extended) low-degree conjecture (recently\nformalized in [MW23]) in the context of the symmetric stochastic block model.\nAssuming the conjecture holds, we establish that no polynomial-time algorithm\ncan weakly recover community labels below the Kesten-Stigum (KS) threshold. In\nparticular, we rule out polynomial-time estimators that, with constant\nprobability, achieve correlation with the true communities that is\nsignificantly better than random. Whereas, above the KS threshold,\npolynomial-time algorithms are known to achieve constant correlation with the\ntrue communities with high probability[Mas14,AS15].\n  To our knowledge, we provide the first rigorous evidence for the sharp\ntransition in recovery rate for polynomial-time algorithms at the KS threshold.\nNotably, under a stronger version of the low-degree conjecture, our lower bound\nremains valid even when the number of blocks diverges. Furthermore, our results\nprovide evidence of a computational-to-statistical gap in learning the\nparameters of stochastic block models.\n  In contrast to prior work, which either (i) rules out polynomial-time\nalgorithms for hypothesis testing with 1-o(1) success probability [Hopkins18,\nBBK+21a] under the low-degree conjecture, or (ii) rules out low-degree\npolynomials for learning the edge connection probability matrix [LG23], our\napproach provides stronger lower bounds on the recovery and learning problem.\n  Our proof combines low-degree lower bounds from [Hopkins18, BBK+21a] with\ngraph splitting and cross-validation techniques. In order to rule out general\nrecovery algorithms, we employ the correlation preserving projection method\ndeveloped in [HS17]."
    ],
    "b_categories":[
      [
        "cs.CC",
        "cs.LG",
        "math.ST",
        "stat.CO",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13601",
    "c_title":[
      "Forecasted Detection Limits on the (Dark) Matter Density in Supermassive\n  Black Hole Binaries for LISA"
    ],
    "c_abstract":[
      "Supermassive black hole binaries (SMBHBs) are among the most powerful known\nsources of gravitational waves (GWs). Accordingly, these systems could dominate\nGW emission in the micro- and millihertz frequency range. Within this domain,\nSMBHs evolve rapidly and merge with each other. Dynamical friction from stars\nand gas at the centers of galaxies typically helps to bring together two SMBHs\nwhen they are at relatively far separations ($\\approx$ kpc $-$ 100 pc), but\nbecomes less efficient at smaller separations. However, dark matter (DM) spikes\naround SMBHs could enhance dynamical friction at close separations and, thus,\nshorten the evolution times. In this paper, we simulate the effects of DM\nspikes on GW signals in the micro- to millihertz frequency range and confirm\nthat the GW signals from SMBHBs with DM spikes can be clearly distinguished\nfrom those without any additional matter. Making use of the projected\nsensitivity curve of the Laser Interferometer Space Antenna (LISA), we forecast\nupper limits for the (dark) matter density for given future SMBHB observations.\nWe then compare these thresholds with the theoretical density profiles expected\nfor self-interacting dark matter (SIDM) spikes."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-852",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14314",
    "b_title":[
      "ODVerse33: Is the New YOLO Version Always Better? A Multi Domain\n  benchmark from YOLO v5 to v11"
    ],
    "b_abstract":[
      "You Look Only Once (YOLO) models have been widely used for building real-time\nobject detectors across various domains. With the increasing frequency of new\nYOLO versions being released, key questions arise. Are the newer versions\nalways better than their previous versions? What are the core innovations in\neach YOLO version and how do these changes translate into real-world\nperformance gains? In this paper, we summarize the key innovations from YOLOv1\nto YOLOv11, introduce a comprehensive benchmark called ODverse33, which\nincludes 33 datasets spanning 11 diverse domains (Autonomous driving,\nAgricultural, Underwater, Medical, Videogame, Industrial, Aerial, Wildlife,\nRetail, Microscopic, and Security), and explore the practical impact of model\nimprovements in real-world, multi-domain applications through extensive\nexperimental results. We hope this study can provide some guidance to the\nextensive users of object detection models and give some references for future\nreal-time object detector development."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15709",
    "c_title":[
      "The significance of \"stripes\" in the physics of the cuprates, the\n  Hubbard model, and other highly correlated electronic systems"
    ],
    "c_abstract":[
      "\"Stripes\" - meaning unidirectional charge-density-waves, sometimes (but not\nalways) accompanied by spin-density-waves with twice the period - are now known\nto arise in broad swathes of the cuprate phase diagram, and appear as a strong\nordering tendency in numerical studies of Hubbard-like models of highly\ncorrelated electron systems. Jan Zaanen's work played a seminal role in\npredicting their existence, and exploring their possible significance. They are\n{\\it not} related to any weak-coupling physics associated with some form of\nFermi-surface nesting. And whether one likes them or not, they are surprisingly\ndifficult to avoid; in the Hubbard model, for example, they often appear as an\nalternative order that can out-compete the otherwise favored $d$-wave\nsuperconductivity."
    ],
    "c_categories":[
      [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-853",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12181",
    "b_title":[
      "3D ReX: Causal Explanations in 3D Neuroimaging Classification"
    ],
    "b_abstract":[
      "Explainability remains a significant problem for AI models in medical\nimaging, making it challenging for clinicians to trust AI-driven predictions.\nWe introduce 3D ReX, the first causality-based post-hoc explainability tool for\n3D models. 3D ReX uses the theory of actual causality to generate\nresponsibility maps which highlight the regions most crucial to the model's\ndecision. We test 3D ReX on a stroke detection model, providing insight into\nthe spatial distribution of features relevant to stroke."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18131",
    "c_title":[
      "An approximate solution of a case of perturbed Fokker-Planck equation"
    ],
    "c_abstract":[
      "This paper focuses on finding an approximate solution of a kind of\nFokker-Planck equation with time-dependent perturbations. A formulation of the\napproximate solution of the equation is constructed, and then the existence of\nthe formulation is proved. The related Hamiltonian dynamical system explains\nthe estimations. Our work provides a more comprehensive understanding of the\nbehaviour of systems described by this Fokker-Planck equation and the\ncorresponding stochastic differential equation."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-854",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02248",
    "b_title":[
      "On Concentration Inequality of the Laplacian Matrix of Erd\\H{o}s-R\\'enyi\n  Graphs"
    ],
    "b_abstract":[
      "This paper focuses on the concentration properties of the spectral norm of\nthe normalized Laplacian matrix for Erd\\H{o}s-R\\'enyi random graphs. First, We\nachieve the optimal bound that can be attained in the further question posed by\nLe et al. [24] for the regularized Laplacian matrix. Beyond that, we also\nestablish a uniform concentration inequality for the spectral norm of the\nLaplacian matrix in the homogeneous case, relying on a key tool: the uniform\nconcentration property of degrees, which may be of independent interest.\nAdditionally, we prove that after normalizing the eigenvector corresponding to\nthe largest eigenvalue, the spectral norm of the Laplacian matrix concentrates\naround 1, which may be useful in special cases."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15773",
    "c_title":[
      "Is It Navajo? Accurate Language Detection in Endangered Athabaskan\n  Languages"
    ],
    "c_abstract":[
      "Endangered languages, such as Navajo - the most widely spoken Native American\nlanguage - are significantly underrepresented in contemporary language\ntechnologies, exacerbating the challenges of their preservation and\nrevitalization. This study evaluates Google's Language Identification (LangID)\ntool, which does not currently support any Native American languages. To\naddress this, we introduce a random forest classifier trained on Navajo and\ntwenty erroneously suggested languages by LangID. Despite its simplicity, the\nclassifier achieves near-perfect accuracy (97-100%). Additionally, the model\ndemonstrates robustness across other Athabaskan languages - a family of Native\nAmerican languages spoken primarily in Alaska, the Pacific Northwest, and parts\nof the Southwestern United States - suggesting its potential for broader\napplication. Our findings underscore the pressing need for NLP systems that\nprioritize linguistic diversity and adaptability over centralized,\none-size-fits-all solutions, especially in supporting underrepresented\nlanguages in a multicultural world. This work directly contributes to ongoing\nefforts to address cultural biases in language models and advocates for the\ndevelopment of culturally localized NLP tools that serve diverse linguistic\ncommunities."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-855",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14604",
    "b_title":[
      "Noisy Test-Time Adaptation in Vision-Language Models"
    ],
    "b_abstract":[
      "Test-time adaptation (TTA) aims to address distribution shifts between source\nand target data by relying solely on target data during testing. In open-world\nscenarios, models often encounter noisy samples, i.e., samples outside the\nin-distribution (ID) label space. Leveraging the zero-shot capability of\npre-trained vision-language models (VLMs), this paper introduces Zero-Shot\nNoisy TTA (ZS-NTTA), focusing on adapting the model to target data with noisy\nsamples during test-time in a zero-shot manner. We find existing TTA methods\nunderperform under ZS-NTTA, often lagging behind even the frozen model. We\nconduct comprehensive experiments to analyze this phenomenon, revealing that\nthe negative impact of unfiltered noisy data outweighs the benefits of clean\ndata during model updating. Also, adapting a classifier for ID classification\nand noise detection hampers both sub-tasks. Built on this, we propose a\nframework that decouples the classifier and detector, focusing on developing an\nindividual detector while keeping the classifier frozen. Technically, we\nintroduce the Adaptive Noise Detector (AdaND), which utilizes the frozen\nmodel's outputs as pseudo-labels to train a noise detector. To handle clean\ndata streams, we further inject Gaussian noise during adaptation, preventing\nthe detector from misclassifying clean samples as noisy. Beyond the ZS-NTTA,\nAdaND can also improve the zero-shot out-of-distribution (ZS-OOD) detection\nability of VLMs. Experiments show that AdaND outperforms in both ZS-NTTA and\nZS-OOD detection. On ImageNet, AdaND achieves a notable improvement of $8.32\\%$\nin harmonic mean accuracy ($\\text{Acc}_\\text{H}$) for ZS-NTTA and $9.40\\%$ in\nFPR95 for ZS-OOD detection, compared to SOTA methods. Importantly, AdaND is\ncomputationally efficient and comparable to the model-frozen method. The code\nis publicly available at: https:\/\/github.com\/tmlr-group\/ZS-NTTA."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06234",
    "c_title":[
      "A brief history of supermembranes"
    ],
    "c_abstract":[
      "``When to the sessions of sweet silent thought I summon up re-membranes of\nthings past, I sigh the lack of many a thing I sought''. (Apologies to William\nShakespeare)"
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-856",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13826",
    "b_title":[
      "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline\n  Professional Videos"
    ],
    "b_abstract":[
      "Humans acquire knowledge through three cognitive stages: perceiving\ninformation, comprehending knowledge, and adapting knowledge to solve novel\nproblems. Videos serve as an effective medium for this learning process,\nfacilitating a progression through these cognitive stages. However, existing\nvideo benchmarks fail to systematically evaluate the knowledge acquisition\ncapabilities in Large Multimodal Models (LMMs). To address this gap, we\nintroduce Video-MMMU, a multi-modal, multi-disciplinary benchmark designed to\nassess LMMs' ability to acquire and utilize knowledge from videos. Video-MMMU\nfeatures a curated collection of 300 expert-level videos and 900\nhuman-annotated questions across six disciplines, evaluating knowledge\nacquisition through stage-aligned question-answer pairs: Perception,\nComprehension, and Adaptation. A proposed knowledge gain metric,\n{\\Delta}knowledge, quantifies improvement in performance after video viewing.\nEvaluation of LMMs reveals a steep decline in performance as cognitive demands\nincrease and highlights a significant gap between human and model knowledge\nacquisition, underscoring the need for methods to enhance LMMs' capability to\nlearn and adapt from videos."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11795",
    "c_title":[
      "Morita theory for quantales"
    ],
    "c_abstract":[
      "Morita theory for quantales is developed. The main result of the paper is a\ncharacterization of those quantaloids (categories enriched in the symmetric\nmonoidal closed category of sup-lattices) that are equivalent to modular\ncategories over quantales. Based on this characterization, necessary and\nsufficient conditions are derived for two quantales to be Morita-equivalent, i.\ne. have equivalent module categories. As an application, it is shown that the\ncategory of internal sup-lattices in a Grothendieck topos is equivalent to the\nmodule category over a suitable chosen ordinary quantale."
    ],
    "c_categories":[
      [
        "math.CT",
        "math.QA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-857",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08206",
    "b_title":[
      "SAT-Based Techniques for Lexicographically Smallest Finite Models"
    ],
    "b_abstract":[
      "This paper proposes SAT-based techniques to calculate a specific normal form\nof a given finite mathematical structure (model). The normal form is obtained\nby permuting the domain elements so that the representation of the structure is\nlexicographically smallest possible. Such a normal form is of interest to\nmathematicians as it enables easy cataloging of algebraic structures. In\nparticular, two structures are isomorphic precisely when their normal forms are\nthe same. This form is also natural to inspect as mathematicians have been\nusing it routinely for many decades.\n  We develop a novel approach where a SAT solver is used in a black-box fashion\nto compute the smallest representative. The approach constructs the\nrepresentative gradually and searches the space of possible isomorphisms,\nrequiring a small number of variables. However, the approach may lead to a\nlarge number of SAT calls and therefore we devise propagation techniques to\nreduce this number. The paper focuses on finite structures with a single binary\noperation (encompassing groups, semigroups, etc.). However, the approach is\ngeneralizable to arbitrary finite structures. We provide an implementation of\nthe proposed algorithm and evaluate it on a variety of algebraic structures."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02755",
    "c_title":[
      "Topotactic Growth of Zintl Phase Eu$_5$In$_2$As$_6$ Nanowires with\n  Antiferromagnetic Behavior"
    ],
    "c_abstract":[
      "We demonstrate a topotactic transformation of zincblende InAs(Sb) nanowires\ninto the Zintl phase Eu$_5$In$_2$As$_6$ through a vapor-solid mutual exchange\nprocess involving Eu and In in molecular beam epitaxy. This conversion\npreserves the polyhedral coordination lattice of the parent InAs(Sb) structure\nwhile inducing orthorhombic symmetry in the product phase, Eu$_5$In$_2$As$_6$,\nin which quasi-one-dimensional [InAs$_3$]$^6$$^-$ chains with tetrahedral sites\nalign along the <110> direction of the zincblende structure. Local and global\nmagnetic characterization identified two distinct antiferromagnetic phase\ntransitions at approximately 7 K and 16 K in Eu$_5$In$_2$As$_6$ nanowires,\npotentially classified as altermagnetic phases. The versatility of the\ntopotactic conversion of III-V semiconductor nanowires provides a platform for\ndesigning functional Zintl materials with tunable magnetic properties, making\nthem promising candidates for spintronic applications."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-858",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14723",
    "b_title":[
      "LeakageDetector: An Open Source Data Leakage Analysis Tool in Machine\n  Learning Pipelines"
    ],
    "b_abstract":[
      "Code quality is of paramount importance in all types of software development\nsettings. Our work seeks to enable Machine Learning (ML) engineers to write\nbetter code by helping them find and fix instances of Data Leakage in their\nmodels. Data Leakage often results from bad practices in writing ML code. As a\nresult, the model effectively ''memorizes'' the data on which it trains,\nleading to an overly optimistic estimate of the model performance and an\ninability to make generalized predictions. ML developers must carefully\nseparate their data into training, evaluation, and test sets to avoid\nintroducing Data Leakage into their code. Training data should be used to train\nthe model, evaluation data should be used to repeatedly confirm a model's\naccuracy, and test data should be used only once to determine the accuracy of a\nproduction-ready model. In this paper, we develop LEAKAGEDETECTOR, a Python\nplugin for the PyCharm IDE that identifies instances of Data Leakage in ML code\nand provides suggestions on how to remove the leakage."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12116",
    "c_title":[
      "Efficient PINNs: Multi-Head Unimodular Regularization of the Solutions\n  Space"
    ],
    "c_abstract":[
      "We present a machine learning framework to facilitate the solution of\nnonlinear multiscale differential equations and, especially, inverse problems\nusing Physics-Informed Neural Networks (PINNs). This framework is based on what\nis called multihead (MH) training, which involves training the network to learn\na general space of all solutions for a given set of equations with certain\nvariability, rather than learning a specific solution of the system. This setup\nis used with a second novel technique that we call Unimodular Regularization\n(UR) of the latent space of solutions. We show that the multihead approach,\ncombined with the regularization, significantly improves the efficiency of\nPINNs by facilitating the transfer learning process thereby enabling the\nfinding of solutions for nonlinear, coupled, and multiscale differential\nequations."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "hep-th",
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-859",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08772",
    "b_title":[
      "Persistent Sheaf Laplacian Analysis of Protein Flexibility"
    ],
    "b_abstract":[
      "Protein flexibility, measured by the B-factor or Debye-Waller factor, is\nessential for protein functions such as structural support, enzyme activity,\ncellular communication, and molecular transport. Theoretical analysis and\nprediction of protein flexibility are crucial for protein design, engineering,\nand drug discovery. In this work, we introduce the persistent sheaf Laplacian\n(PSL), an effective tool in topological data analysis, to model and analyze\nprotein flexibility. By representing the local topology and geometry of protein\natoms through the multiscale harmonic and non-harmonic spectra of PSLs, the\nproposed model effectively captures protein flexibility and provides accurate,\nrobust predictions of protein B-factors. Our PSL model demonstrates an increase\nin accuracy of 32% compared to the classical Gaussian network model (GNM) in\npredicting B-factors for a dataset of 364 proteins. Additionally, we construct\na blind machine learning prediction method utilizing global and local protein\nfeatures. Extensive computations and comparisons validate the effectiveness of\nthe proposed PSL model for B-factor predictions."
    ],
    "b_categories":[
      [
        "q-bio.BM",
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.15216",
    "c_title":[
      "Approximate weighted 3-coloring"
    ],
    "c_abstract":[
      "The paper considers the NP-hard graph vertex coloring problem, which differs\nfrom traditional problems in which it is required to color vertices with a\ngiven (or minimal) number of colors so that adjacent vertices have different\ncolors. In the problem under consideration, a simple edge-weighted graph is\ngiven. It is required to color its vertices in 3 colors to minimize the total\nweight of monochromatic (one-color) edges, i.e. edges with the same colors of\ntheir end vertices. This problem is poorly investigated. Previously, we\ndeveloped graph decomposition algorithms that, in particular, allowed us to\nconstruct lower bounds for the optimum, as well as several greedy algorithms.\nIn this paper, several new approximation algorithms are proposed. Among them\nare variable neighborhood search, simulated annealing, genetic algorithm and\ngraph clustering with further finding the optimal coloring in each cluster. A\nnumerical experiment was conducted on random graphs, as well as on real\ncommunication graphs. The characteristics of the algorithms are presented both\nin tables and graphically. The developed algorithms have shown high efficiency."
    ],
    "c_categories":[
      [
        "cs.DM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-860",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16855",
    "b_title":[
      "Stack Transformer Based Spatial-Temporal Attention Model for Dynamic\n  Multi-Culture Sign Language Recognition"
    ],
    "b_abstract":[
      "Hand gesture-based Sign Language Recognition (SLR) serves as a crucial\ncommunication bridge between deaf and non-deaf individuals. Existing SLR\nsystems perform well for their cultural SL but may struggle with multi-cultural\nsign languages (McSL). To address these challenges, this paper proposes a Stack\nSpatial-Temporal Transformer Network that leverages multi-head attention\nmechanisms to capture both spatial and temporal dependencies with hierarchical\nfeatures using the Stack Transfer concept. In the proceed, firstly, we applied\na fully connected layer to make a embedding vector which has high expressive\npower from the original dataset, then fed them a stack newly proposed\ntransformer to achieve hierarchical features with short-range and long-range\ndependency. The network architecture is composed of several stages that process\nspatial and temporal relationships sequentially, ensuring effective feature\nextraction. After making the fully connected layer, the embedding vector is\nprocessed by the Spatial Multi-Head Attention Transformer, which captures\nspatial dependencies between joints. In the next stage, the Temporal Multi-Head\nAttention Transformer captures long-range temporal dependencies, and again, the\nfeatures are concatenated with the output using another skip connection. The\nprocessed features are then passed to the Feed-Forward Network (FFN), which\nrefines the feature representations further. After the FFN, additional skip\nconnections are applied to combine the output with earlier layers, followed by\na final normalization layer to produce the final output feature tensor. This\nprocess is repeated for 10 transformer blocks. The extensive experiment shows\nthat the JSL, KSL and ASL datasets achieved good performance accuracy. Our\napproach demonstrates improved performance in McSL, and it will be consider as\na novel work in this domain."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07876",
    "c_title":[
      "Photoneutron reactions on gold in the giant dipole resonance region:\n  reaction cross sections and average kinetic energies of $(\\gamma,\\,xn)$\n  photoneutrons"
    ],
    "c_abstract":[
      "In this work, we present new data on the $^{197}$Au photoneutron reactions in\nand above the giant dipole resonance region, obtained by using 8 to 39~MeV\nquasi-monochromatic $\\gamma$-ray beams produced at the NewSUBARU facility in\nJapan and a high-and-flat efficiency neutron detection system. We report\nabsolute cross sections and mean photoneutron energies for the\n$^{197}$Au$(\\gamma,\\,inX)$ reactions with $i$~=~1 to 4. The photoabsorption\ncross section was obtained as the sum of the $(\\gamma,\\,inX)$ reaction cross\nsections. The giant dipole resonance parameter values were obtained by fitting\nthe experimental photoabsorption cross sections. The present photoabsorption\ncross sections are in good agreement with the Saclay results of\nVeyssiere~\\emph{et al.}. Thus, our study does not support the recommendation of\nBerman~\\emph{et al.} of lowering the Saclay photoabsorption cross sections by\n8$\\%$. We observed a non-statistical high-energy neutron emission in the\n$(\\gamma,\\,n)$ reaction in the low-energy region between $S_n$ and 10~MeV. The\npresent results are compared with data from the literature and statistical\nmodel calculations performed with the TALYS and EMPIRE codes."
    ],
    "c_categories":[
      [
        "nucl-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-861",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01513",
    "b_title":[
      "Out-of-equilibrium dynamical properties of Bose-Einstein condensates in\n  a ramped up weak disorder"
    ],
    "b_abstract":[
      "We theoretically study how the superfluid and condensate deformation of a\nweakly interacting ultracold Bose gas evolve during the ramp-up of an external\nweak disorder potential. Both resulting deformations turn out to consist of two\ndistinct contributions, namely a reversible equilibrium one, already predicted\nby Huang and Meng in 1992, and a nonequilibrium dynamical one, whose magnitude\ndepends on the details of the ramping protocol. For the specific case of the\nexponential ramp-up protocol, we are able to derive analytical time-dependent\nexpressions for the above quantities. After a sufficiently long time, a steady\nstate emerges that is generically out of equilibrium. We take the first step in\ninvestigating its properties by studying its relaxation dynamics. In addition,\nwe analyze the two-time correlation function and elucidate its relation to the\nequilibrium and the dynamical part of the condensate deformation."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01187",
    "c_title":[
      "NET-SA: An Efficient Secure Aggregation Architecture Based on In-Network\n  Computing"
    ],
    "c_abstract":[
      "Privacy-preserving machine learning (PPML) enables clients to collaboratively\ntrain deep learning models without sharing private datasets, but faces privacy\nleakage risks due to gradient leakage attacks. Prevailing methods leverage\nsecure aggregation strategies to enhance PPML, where clients leverage masks and\nsecret sharing to further protect gradient data while tolerating participant\ndropouts. These methods, however, require frequent inter-client communication\nto negotiate keys and perform secret sharing, leading to substantial\ncommunication overhead. To tackle this issue, we propose NET-SA, an efficient\nsecure aggregation architecture for PPML based on in-network computing. NET-SA\nemploys seed homomorphic pseudorandom generators for local gradient masking and\nutilizes programmable switches for seed aggregation. Accurate and secure\ngradient aggregation is then performed on the central server based on masked\ngradients and aggregated seeds. This design effectively reduces communication\noverhead due to eliminating the communication-intensive phases of seed\nagreement and secret sharing, with enhanced dropout tolerance due to overcoming\nthe threshold limit of secret sharing. Extensive experiments on server clusters\nand Intel Tofino programmable switch demonstrate that NET-SA achieves up to 77x\nand 12x enhancements in runtime and 2x decrease in total client communication\ncost compared with state-of-the-art methods."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.DC",
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-862",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07338",
    "b_title":[
      "Ultrafast 4D scanning transmission electron microscopy for imaging of\n  localized optical fields"
    ],
    "b_abstract":[
      "Ultrafast electron microscopy aims for imaging transient phenomena occurring\non nanoscale. One of its goals is to visualize localized optical and plasmonic\nmodes generated by coherent excitation in the vicinity of various types of\nnanostructures. Such imaging capability was enabled by photon-induced\nnear-field optical microscopy, which is based on spectral filtering of\nelectrons inelastically scattered due to the stimulated interaction with the\nnear-field. Here we report on the development of ultrafast 4D scanning\ntransmission electron microscopy, which allows us to image the transverse\ncomponents of the optical near-field while avoiding the need of electron\nspectral filtering. We demonstrate that this method is capable of imaging\noptical near-fields of a tungsten nanotip and ponderomotive potential of an\noptical standing wave with a spatial resolution of 21 nm."
    ],
    "b_categories":[
      [
        "physics.ins-det",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17826",
    "c_title":[
      "\"Overpartitionized\" Rogers--Ramanujan type identities"
    ],
    "c_abstract":[
      "Many classical $q$-series identities, such as the Rogers--Ramanujan\nidentities, yield combinatorial interpretations in terms of integer partitions.\nHere we consider algebraically manipulating some of the classical $q$-series to\nyield natural combinatorial interpretations in terms of overpartitions.\nBijective proofs are supplied as well."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-863",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14876",
    "b_title":[
      "Strong CWoLa: Binary Classification Without Background Simulation"
    ],
    "b_abstract":[
      "Supervised deep learning methods have been successful in the field of high\nenergy physics, and the trend within the field is to move away from high level\nreconstructed variables to lower level, higher dimensional features. Supervised\nmethods require labelled data, which is typically provided by a simulator. As\nthe number of features increases, simulation accuracy decreases, leading to\ngreater domain shift between training and testing data when using lower-level\nfeatures. This work demonstrates that the classification without labels\nparadigm can be used to remove the need for background simulation when training\nsupervised classifiers. This can result in classifiers with higher performance\non real data than those trained on simulated data."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12890",
    "c_title":[
      "Analyzing and Exploiting Branch Mispredictions in Microcode"
    ],
    "c_abstract":[
      "We present uSpectre, a new class of transient execution attacks that exploit\nmicrocode branch mispredictions to transiently leak sensitive data. We find\nthat many long-known and recently-discovered transient execution attacks, which\nwere previously categorized as Spectre or Meltdown variants, are actually\ninstances of uSpectre on some Intel microarchitectures. Based on our\nobservations, we discover multiple new uSpectre attacks and present a defense\nagainst uSpectre vulnerabilities, called uSLH."
    ],
    "c_categories":[
      [
        "cs.AR",
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-864",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14584",
    "b_title":[
      "Search for dark matter subhalos among unassociated Fermi-LAT sources in\n  presence of dataset shift"
    ],
    "b_abstract":[
      "We search for dark matter (DM) annihilating subhalos of the Milky Way halo\namong the Fermi Large Area Telescope (LAT) unassociated sources. We construct,\nfor the first time, a statistical model of the unassociated sources at\nlatitudes above 10 degrees. The latter is built as a combination of both DM\nannihilation subhalos as well as Galactic and extragalactic astrophysical\ncomponents. The astrophysical components are constructed based on distributions\nof associated sources, while the distribution of DM subhalos is derived from\nMonte Carlo simulations. In this model we take into account the differences in\nthe distributions of associated and unassociated sources including both\ncovariate and prior probability shifts (both being forms of ``dataset\nshifts''). Previous searches of DM subhalos were based on classify-and-count\nstrategies, while the approach adopted in this work is based on quantification\nlearning, which allows one to determine a well-defined statistical\ninterpretation of the contribution of a population of DM subhalos to the\nunassociated Fermi-LAT sources. In the $b\\bar{b}$ annihilation channel and for\na range of DM masses from 10 GeV to 1 TeV, we don't find a significant\ncontribution from DM subhalos and derive a statistical 95% confidence upper\nlimit on the DM annihilation cross section in this channel. While the derived\nlimits are consistent with previous classify-and-count approaches, our\ngenerative statistical model opens new avenues for population studies of\nFermi-LAT sources and, more generally, for searches of anomalies on top of\nbackgrounds in presence of statistical and systematic uncertainties."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01522",
    "c_title":[
      "Byzantine Distributed Function Computation"
    ],
    "c_abstract":[
      "We study the distributed function computation problem with $k$ users of which\nat most $s$ may be controlled by an adversary and characterize the set of\nfunctions of the sources the decoder can reconstruct robustly in the following\nsense -- if the users behave honestly, the function is recovered with high\nprobability (w.h.p.); if they behave adversarially, w.h.p, either one of the\nadversarial users will be identified or the function is recovered with\nvanishingly small distortion."
    ],
    "c_categories":[
      [
        "cs.CR",
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-865",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04667",
    "b_title":[
      "An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding"
    ],
    "b_abstract":[
      "This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19815",
    "c_title":[
      "Spontaneous magnon decay in two-dimensional altermagnets"
    ],
    "c_abstract":[
      "We show that magnons in two-dimensional altermagnets can spontaneously decay\nat zero temperature. The decay rate is determined by quantum fluctuations and\nscattering processes involving the decay of a single magnon into three. These\nprocesses are kinematically allowed due to the convexity of the altermagnetic\nmagnon dispersion. For small wavevectors $k$ the decay rate is proportional to\n$k^5$ with a direction-dependent prefactor which is maximal along the diagonals\nof the Brillouin zone. Moreover, for a given momentum only magnons with one\nspecific chirality can spontaneously decay."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-866",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16906",
    "b_title":[
      "AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning\n  Abilities of Large Language Models"
    ],
    "b_abstract":[
      "While logical reasoning evaluation of Large Language Models (LLMs) has\nattracted significant attention, existing benchmarks predominantly rely on\nmultiple-choice formats that are vulnerable to random guessing, leading to\noverestimated performance and substantial performance fluctuations. To obtain\nmore accurate assessments of models' reasoning capabilities, we propose an\nautomated method for synthesizing open-ended logic puzzles, and use it to\ndevelop a bilingual benchmark, AutoLogi. Our approach features program-based\nverification and controllable difficulty levels, enabling more reliable\nevaluation that better distinguishes models' reasoning abilities. Extensive\nevaluation of eight modern LLMs shows that AutoLogi can better reflect true\nmodel capabilities, with performance scores spanning from 35% to 73% compared\nto the narrower range of 21% to 37% on the source multiple-choice dataset.\nBeyond benchmark creation, this synthesis method can generate high-quality\ntraining data by incorporating program verifiers into the rejection sampling\nprocess, enabling systematic enhancement of LLMs' reasoning capabilities across\ndiverse datasets."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18381",
    "c_title":[
      "Efficient Inference in First Passage Time Models"
    ],
    "c_abstract":[
      "First passage time models describe the time it takes for a random process to\nexit a region of interest and are widely used across various scientific fields.\nFast and accurate numerical methods for computing the likelihood function in\nthese models are essential for efficient statistical inference. Specifically,\nin mathematical psychology, generalized drift diffusion models (GDDMs) are an\nimportant class of first passage time models that describe the latent\npsychological processes underlying simple decision-making scenarios. GDDMs\nmodel the joint distribution over choices and response times as the first\nhitting time of a one-dimensional stochastic differential equation (SDE) to\npossibly time-varying upper and lower boundaries. They are widely applied to\nextract parameters associated with distinct cognitive and neural mechanisms.\nHowever, current likelihood computation methods struggle with common scenarios\nwhere drift rates covary dynamically with exogenous covariates in each trial,\nsuch as in the attentional drift diffusion model (aDDM). In this work, we\npropose a fast and flexible algorithm for computing the likelihood function of\nGDDMs based on a large class of SDEs satisfying the Cherkasov condition. Our\nmethod divides each trial into discrete stages, employs fast analytical results\nto compute stage-wise densities, and integrates these to compute the overall\ntrial-wise likelihood. Numerical examples demonstrate that our method not only\nyields accurate likelihood evaluations for efficient statistical inference, but\nalso significantly outperforms existing approaches in terms of speed."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.CO",
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-867",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14258",
    "b_title":[
      "JuDGE: Benchmarking Judgment Document Generation for Chinese Legal\n  System"
    ],
    "b_abstract":[
      "This paper introduces JuDGE (Judgment Document Generation Evaluation), a\nnovel benchmark for evaluating the performance of judgment document generation\nin the Chinese legal system. We define the task as generating a complete legal\njudgment document from the given factual description of the case. To facilitate\nthis benchmark, we construct a comprehensive dataset consisting of factual\ndescriptions from real legal cases, paired with their corresponding full\njudgment documents, which serve as the ground truth for evaluating the quality\nof generated documents. This dataset is further augmented by two external legal\ncorpora that provide additional legal knowledge for the task: one comprising\nstatutes and regulations, and the other consisting of a large collection of\npast judgment documents. In collaboration with legal professionals, we\nestablish a comprehensive automated evaluation framework to assess the quality\nof generated judgment documents across various dimensions. We evaluate various\nbaseline approaches, including few-shot in-context learning, fine-tuning, and a\nmulti-source retrieval-augmented generation (RAG) approach, using both general\nand legal-domain LLMs. The experimental results demonstrate that, while RAG\napproaches can effectively improve performance in this task, there is still\nsubstantial room for further improvement. All the codes and datasets are\navailable at: https:\/\/github.com\/oneal2000\/JuDGE."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12905",
    "c_title":[
      "Fundamental constraints on quantum fluctuations: Conservation laws,\n  reality, and no-signaling"
    ],
    "c_abstract":[
      "Quantum fluctuations and noise are fundamental in quantum technologies,\naffecting computing, sensing, cryptography, and thermodynamics. These include\nfluctuations in the variation of energy, charge, and other observables driven\nby interactions with lasers, amplifiers, and baths. Despite the precise rules\nquantum mechanics provides for measuring observables at single points in time,\nno standard framework exists for characterizing the fluctuations of their\nvariations over time. This gap not only makes physical conclusions dependent on\nthe chosen measurement protocol but also leads to inconsistencies in\nfluctuation predictions, impacting quantum technologies. We propose four basic\ncriteria that any consistent measurement of these variations must satisfy,\ngrounded in conservation laws, the no-signaling principle, and expected\nconstraints on physical realism. We demonstrate that only one protocol fulfills\nall these criteria: the two-times quantum observables. This result enables the\nextension of key quantum information concepts, such as entanglement, steering,\nand Bell's inequalities, to processes rather than instantaneous observables.\nBeyond resolving ambiguities in quantum fluctuation measurements, our framework\noffers a foundation for improved fluctuation control in quantum devices, with\npotential applications in quantum computing, metrology, and thermodynamics."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-868",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17892",
    "b_title":[
      "Object Detection with Deep Learning for Rare Event Search in the GADGET\n  II TPC"
    ],
    "b_abstract":[
      "In the pursuit of identifying rare two-particle events within the GADGET II\nTime Projection Chamber (TPC), this paper presents a comprehensive approach for\nleveraging Convolutional Neural Networks (CNNs) and various data processing\nmethods. To address the inherent complexities of 3D TPC track reconstructions,\nthe data is expressed in 2D projections and 1D quantities. This approach\ncapitalizes on the diverse data modalities of the TPC, allowing for the\nefficient representation of the distinct features of the 3D events, with no\nloss in topology uniqueness. Additionally, it leverages the computational\nefficiency of 2D CNNs and benefits from the extensive availability of\npre-trained models. Given the scarcity of real training data for the rare\nevents of interest, simulated events are used to train the models to detect\nreal events. To account for potential distribution shifts when predominantly\ndepending on simulations, significant perturbations are embedded within the\nsimulations. This produces a broad parameter space that works to account for\npotential physics parameter and detector response variations and uncertainties.\nThese parameter-varied simulations are used to train sensitive 2D CNN object\ndetectors. When combined with 1D histogram peak detection algorithms, this\nmulti-modal detection framework is highly adept at identifying rare,\ntwo-particle events in data taken during experiment 21072 at the Facility for\nRare Isotope Beams (FRIB), demonstrating a 100% recall for events of interest.\nWe present the methods and outcomes of our investigation and discuss the\npotential future applications of these techniques."
    ],
    "b_categories":[
      [
        "nucl-ex",
        "physics.data-an",
        "physics.ins-det"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03576",
    "c_title":[
      "Clone-Resistant Weights in Metric Spaces: A Framework for Handling\n  Redundancy Bias"
    ],
    "c_abstract":[
      "We are given a set of elements in a metric space. The distribution of the\nelements is arbitrary, possibly adversarial. Can we weigh the elements in a way\nthat is resistant to such (adversarial) manipulations? This problem arises in\nvarious contexts. For instance, the elements could represent data points,\nrequiring robust domain adaptation. Alternatively, they might represent tasks\nto be aggregated into a benchmark; or questions about personal political\nopinions in voting advice applications. This article introduces a theoretical\nframework for dealing with such problems. We propose clone-proof representation\nfunctions as a solution concept. These functions distribute importance across\nelements of a set such that similar objects (``clones'') share (some of) their\nweights, thus avoiding a potential bias introduced by their multiplicity. Our\nframework extends the maximum uncertainty principle to accommodate general\nmetric spaces and includes a set of axioms - symmetry, continuity, and\nclone-proofness - that guide the construction of representation functions.\nFinally, we address the existence of representation functions satisfying our\naxioms in the significant case of Euclidean spaces and propose a general method\nfor their construction."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-869",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14082",
    "b_title":[
      "Communicating Activations Between Language Model Agents"
    ],
    "b_abstract":[
      "Communication between multiple language model (LM) agents has been shown to\nscale up the reasoning ability of LMs. While natural language has been the\ndominant medium for inter-LM communication, it is not obvious this should be\nthe standard: not only does natural language communication incur high inference\ncosts that scale quickly with the number of both agents and messages, but also\nthe decoding process abstracts away too much rich information that could be\notherwise accessed from the internal activations. In this work, we propose a\nsimple technique whereby LMs communicate via activations; concretely, we pause\nan LM $\\textit{B}$'s computation at an intermediate layer, combine its current\nactivation with another LM $\\textit{A}$'s intermediate activation via some\nfunction $\\textit{f}$, then pass $\\textit{f}$'s output into the next layer of\n$\\textit{B}$ and continue the forward pass till decoding is complete. This\napproach scales up LMs on new tasks with zero additional parameters and data,\nand saves a substantial amount of compute over natural language communication.\nWe test our method with various functional forms $\\textit{f}$ on two\nexperimental setups--multi-player coordination games and reasoning\nbenchmarks--and find that it achieves up to $27.0\\%$ improvement over natural\nlanguage communication across datasets with $<$$1\/4$ the compute, illustrating\nthe superiority and robustness of activations as an alternative \"language\" for\ncommunication between LMs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18741",
    "c_title":[
      "Non-perturbative formulation of resonances in quantum mechanics based on\n  exact WKB method"
    ],
    "c_abstract":[
      "We study quasi-stationary states in quantum mechanics using the exact WKB\nanalysis as a non-perturbative framework. While previous works focus mainly on\nstable systems, we explore quasi-stable states such as resonances. As a\nconcrete example, we analyze the inverted Rosen--Morse potential, which\nexhibits barrier resonance. This model allows exact solutions, enabling a\ndirect comparison with exact WKB predictions. We provide a simple analytic\npicture of resonance and demonstrate consistency between exact and WKB-based\nresults, extending the applicability of exact WKB analysis to non-polynomial\npotentials."
    ],
    "c_categories":[
      [
        "hep-th",
        "nucl-th",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-870",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03683",
    "b_title":[
      "Ruling out AGNs as the dominant source of cosmic reionization with JWST"
    ],
    "b_abstract":[
      "Cosmic reionization represents the latest phase transition of the\nintergalactic medium (IGM) in the Universe. It has long been debated whether\ngalaxies or active galactic nuclei (AGNs) are the major source of Lyman\ncontinuum (LyC) photons responsible for reionization. Previous observations\nslightly favored galaxies as the major ionizing source. However, the James Webb\nSpace Telescope (JWST) recently discovered an unexpectedly high density of AGN\ncandidates at high redshift, which has largely enhanced the influence of AGNs.\nHere we derive a definitive upper bound on the AGN contribution to reionization\nusing the latest JWST data, and conclusively rule out AGNs as the dominant\nionizing source during the epoch of reionization (EoR). We build a sample of\nobjects (including galaxies and AGNs) in a specific redshift range between 7.15\nand 7.75 that has a high completeness. Each object is then decomposed into a\npoint-source component and an extended component in their rest-frame far-UV\nJWST images. Assuming all point-source components are AGNs, we obtain an\nabsolute upper limit for the density of the AGN population. This fiducial AGN\nsample reaches an unprecedentedly low luminosity of $M_{\\rm UV} \\approx -15$\nmag. Based on this sample, we find that AGNs can contribute at most one third\nof the LyC photons required to ionize the Universe in this redshift range. Our\nresult implies that galaxies dominate the ionizing source during the EoR."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09100",
    "c_title":[
      "Logical Reasoning in Large Language Models: A Survey"
    ],
    "c_abstract":[
      "With the emergence of advanced reasoning models like OpenAI o3 and\nDeepSeek-R1, large language models (LLMs) have demonstrated remarkable\nreasoning capabilities. However, their ability to perform rigorous logical\nreasoning remains an open question. This survey synthesizes recent advancements\nin logical reasoning within LLMs, a critical area of AI research. It outlines\nthe scope of logical reasoning in LLMs, its theoretical foundations, and the\nbenchmarks used to evaluate reasoning proficiency. We analyze existing\ncapabilities across different reasoning paradigms - deductive, inductive,\nabductive, and analogical - and assess strategies to enhance reasoning\nperformance, including data-centric tuning, reinforcement learning, decoding\nstrategies, and neuro-symbolic approaches. The review concludes with future\ndirections, emphasizing the need for further exploration to strengthen logical\nreasoning in AI systems."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-871",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13967",
    "b_title":[
      "FlexTok: Resampling Images into 1D Token Sequences of Flexible Length"
    ],
    "b_abstract":[
      "Image tokenization has enabled major advances in autoregressive image\ngeneration by providing compressed, discrete representations that are more\nefficient to process than raw pixels. While traditional approaches use 2D grid\ntokenization, recent methods like TiTok have shown that 1D tokenization can\nachieve high generation quality by eliminating grid redundancies. However,\nthese methods typically use a fixed number of tokens and thus cannot adapt to\nan image's inherent complexity. We introduce FlexTok, a tokenizer that projects\n2D images into variable-length, ordered 1D token sequences. For example, a\n256x256 image can be resampled into anywhere from 1 to 256 discrete tokens,\nhierarchically and semantically compressing its information. By training a\nrectified flow model as the decoder and using nested dropout, FlexTok produces\nplausible reconstructions regardless of the chosen token sequence length. We\nevaluate our approach in an autoregressive generation setting using a simple\nGPT-style Transformer. On ImageNet, this approach achieves an FID<2 across 8 to\n128 tokens, outperforming TiTok and matching state-of-the-art methods with far\nfewer tokens. We further extend the model to support to text-conditioned image\ngeneration and examine how FlexTok relates to traditional 2D tokenization. A\nkey finding is that FlexTok enables next-token prediction to describe images in\na coarse-to-fine \"visual vocabulary\", and that the number of tokens to generate\ndepends on the complexity of the generation task."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05655",
    "c_title":[
      "Memory preservation in highly-connected quantum networks"
    ],
    "c_abstract":[
      "Complex quantum networks are powerful tools in the modeling of transport\nphenomena, particularly for biological systems, and enable the study of\nemergent entanglement structures or topology effects in of many-body quantum\nsystems. Here, we study the transport properties of a quantum network described\nby the paradigmatic XXZ Hamiltonian, with non-trivial graph connectivity and\ntopology, and long-range interaction. Adopting a combination of analytical and\nnumerical methods to analyze the properties of increasingly complex\narchitectures, we find that all-to-all connected regular network preserves over\nlong times the memory of initially injected excitations, tracing it back to the\nsystem symmetries and the cooperative shielding. We then develop understanding\nof the conditions for this property to survive in quantum networks with either\npower-law node connectivity or complex, small-world type, architectures.\nInterestingly, we find that memory preserving effects occur also in sparse and\nmore irregular graphs, though to a significantly lower degree. We discuss the\nimplications of these properties in biology-related problems, such as an\napplication to Weber's law in neuroscience, and their implementation in\nspecific quantum technologies via biomimicry."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-872",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17356",
    "b_title":[
      "On the Coexistence and Ensembling of Watermarks"
    ],
    "b_abstract":[
      "Watermarking, the practice of embedding imperceptible information into media\nsuch as images, videos, audio, and text, is essential for intellectual property\nprotection, content provenance and attribution. The growing complexity of\ndigital ecosystems necessitates watermarks for different uses to be embedded in\nthe same media. However, to detect and decode all watermarks, they need to\ncoexist well with one another. We perform the first study of coexistence of\ndeep image watermarking methods and, contrary to intuition, we find that\nvarious open-source watermarks can coexist with only minor impacts on image\nquality and decoding robustness. The coexistence of watermarks also opens the\navenue for ensembling watermarking methods. We show how ensembling can increase\nthe overall message capacity and enable new trade-offs between capacity,\naccuracy, robustness and image quality, without needing to retrain the base\nmodels."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01515",
    "c_title":[
      "DiagrammaticLearning: A Graphical Language for Compositional Training\n  Regimes"
    ],
    "c_abstract":[
      "Motivated by deep learning regimes with multiple interacting yet distinct\nmodel components, we introduce learning diagrams, graphical depictions of\ntraining setups that capture parameterized learning as data rather than code. A\nlearning diagram compiles to a unique loss function on which component models\nare trained. The result of training on this loss is a collection of models\nwhose predictions ``agree\" with one another. We show that a number of popular\nlearning setups such as few-shot multi-task learning, knowledge distillation,\nand multi-modal learning can be depicted as learning diagrams. We further\nimplement learning diagrams in a library that allows users to build diagrams of\nPyTorch and Flux.jl models. By implementing some classic machine learning use\ncases, we demonstrate how learning diagrams allow practitioners to build\ncomplicated models as compositions of smaller components, identify\nrelationships between workflows, and manipulate models during or after\ntraining. Leveraging a category theoretic framework, we introduce a rigorous\nsemantics for learning diagrams that puts such operations on a firm\nmathematical foundation."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "math.CT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-873",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03990",
    "b_title":[
      "Data-Driven Probabilistic Air-Sea Flux Parameterization"
    ],
    "b_abstract":[
      "Accurately quantifying air-sea fluxes is important for understanding air-sea\ninteractions and improving coupled weather and climate systems. This study\nintroduces a probabilistic framework to represent the highly variable nature of\nair-sea fluxes, which is missing in deterministic bulk algorithms. Assuming\nGaussian distributions conditioned on the input variables, we use artificial\nneural networks and eddy-covariance measurement data to estimate the mean and\nvariance by minimizing negative log-likelihood loss. The trained neural\nnetworks provide alternative mean flux estimates to existing bulk algorithms,\nand quantify the uncertainty around the mean estimates. Stochastic\nparameterization of air-sea turbulent fluxes can be constructed by sampling\nfrom the predicted distributions. Tests in a single-column forced upper-ocean\nmodel suggest that changes in flux algorithms influence sea surface temperature\nand mixed layer depth seasonally. The ensemble spread in stochastic runs is\nmost pronounced during spring restratification."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.ao-ph",
        "stat.AP",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06631",
    "c_title":[
      "Conformal Predictions for Human Action Recognition with Vision-Language\n  Models"
    ],
    "c_abstract":[
      "Human-In-The-Loop (HITL) frameworks are integral to many real-world computer\nvision systems, enabling human operators to make informed decisions with AI\nassistance. Conformal Predictions (CP), which provide label sets with rigorous\nguarantees on ground truth inclusion probabilities, have recently gained\ntraction as a valuable tool in HITL settings. One key application area is video\nsurveillance, closely associated with Human Action Recognition (HAR). This\nstudy explores the application of CP on top of state-of-the-art HAR methods\nthat utilize extensively pre-trained Vision-Language Models (VLMs). Our\nfindings reveal that CP can significantly reduce the average number of\ncandidate classes without modifying the underlying VLM. However, these\nreductions often result in distributions with long tails. To address this, we\nintroduce a method based on tuning the temperature parameter of the VLMs to\nminimize these tails without requiring additional calibration data. Our code is\nmade available on GitHub at the address https:\/\/github.com\/tbary\/CP4VLM."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-874",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14891",
    "b_title":[
      "CoDiff: Conditional Diffusion Model for Collaborative 3D Object\n  Detection"
    ],
    "b_abstract":[
      "Collaborative 3D object detection holds significant importance in the field\nof autonomous driving, as it greatly enhances the perception capabilities of\neach individual agent by facilitating information exchange among multiple\nagents. However, in practice, due to pose estimation errors and time delays,\nthe fusion of information across agents often results in feature\nrepresentations with spatial and temporal noise, leading to detection errors.\nDiffusion models naturally have the ability to denoise noisy samples to the\nideal data, which motivates us to explore the use of diffusion models to\naddress the noise problem between multi-agent systems. In this work, we propose\nCoDiff, a novel robust collaborative perception framework that leverages the\npotential of diffusion models to generate more comprehensive and clearer\nfeature representations. To the best of our knowledge, this is the first work\nto apply diffusion models to multi-agent collaborative perception.\nSpecifically, we project high-dimensional feature map into the latent space of\na powerful pre-trained autoencoder. Within this space, individual agent\ninformation serves as a condition to guide the diffusion model's sampling. This\nprocess denoises coarse feature maps and progressively refines the fused\nfeatures. Experimental study on both simulated and real-world datasets\ndemonstrates that the proposed framework CoDiff consistently outperforms\nexisting relevant methods in terms of the collaborative object detection\nperformance, and exhibits highly desired robustness when the pose and delay\ninformation of agents is with high-level noise."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06862",
    "c_title":[
      "Poincar\\'e Inequality for Local Log-Polyak-Lojasiewicz Measures :\n  Non-asymptotic Analysis in Low-temperature Regime"
    ],
    "c_abstract":[
      "Potential functions in highly pertinent applications, such as deep learning\nin over-parameterized regime, are empirically observed to admit non-isolated\nminima. To understand the convergence behavior of stochastic dynamics in such\nlandscapes, we propose to study the class of \\logPLmeasure\\ measures\n$\\mu_\\epsilon \\propto \\exp(-V\/\\epsilon)$, where the potential $V$ satisfies a\nlocal Polyak-{\\L}ojasiewicz (P\\L) inequality, and its set of local minima is\nprovably \\emph{connected}. Notably, potentials in this class can exhibit local\nmaxima and we characterize its optimal set S to be a compact $\\mathcal{C}^2$\n\\emph{embedding submanifold} of $\\mathbb{R}^d$ without boundary. The\n\\emph{non-contractibility} of S distinguishes our function class from the\nclassical convex setting topologically. Moreover, the embedding structure\ninduces a naturally defined Laplacian-Beltrami operator on S, and we show that\nits first non-trivial eigenvalue provides an \\emph{$\\epsilon$-independent}\nlower bound for the \\Poincare\\ constant in the \\Poincare\\ inequality of\n$\\mu_\\epsilon$. As a direct consequence, Langevin dynamics with such non-convex\npotential $V$ and diffusion coefficient $\\epsilon$ converges to its equilibrium\n$\\mu_\\epsilon$ at a rate of $\\tilde{\\mathcal{O}}(1\/\\epsilon)$, provided\n$\\epsilon$ is sufficiently small. Here $\\tilde{\\mathcal{O}}$ hides logarithmic\nterms."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.CA",
        "math.FA",
        "math.PR",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-875",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13677",
    "b_title":[
      "Value-Oriented Forecast Combinations for Unit Commitment"
    ],
    "b_abstract":[
      "Value-oriented forecasts for two-stage power system operational problems have\nbeen demonstrated to reduce cost, but prove to be computationally challenging\nfor large-scale systems because the underlying optimization problem must be\ninternalized into the forecast model training. Therefore, existing approaches\ntypically scale poorly in the usable training data or require relaxations of\nthe underlying optimization. This paper presents a method for value-oriented\nforecast combinations using progressive hedging, which unlocks high-fidelity,\nat-scale models and large-scale datasets in training. We also derive a direct\none-shot training model for reference and study how different modifications of\nthe training model impact the solution quality. Our method reduces operation\ncost by 1.8% on average and trains forecast combinations for a 2736-bus test\nsystem with one year of data within 20 hours."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04561",
    "c_title":[
      "OpenOmni: Advancing Open-Source Omnimodal Large Language Models with\n  Progressive Multimodal Alignment and Real-Time Self-Aware Emotional Speech\n  Synthesis"
    ],
    "c_abstract":[
      "Recent advancements in omnimodal learning have significantly improved\nunderstanding and generation across images, text, and speech, yet these\ndevelopments remain predominantly confined to proprietary models. The lack of\nhigh-quality omnimodal datasets and the challenges of real-time emotional\nspeech synthesis have notably hindered progress in open-source research. To\naddress these limitations, we introduce \\name, a two-stage training framework\nthat integrates omnimodal alignment and speech generation to develop a\nstate-of-the-art omnimodal large language model. In the alignment phase, a\npre-trained speech model undergoes further training on text-image tasks,\nenabling (near) zero-shot generalization from vision to speech, outperforming\nmodels trained on tri-modal datasets. In the speech generation phase, a\nlightweight decoder is trained on speech tasks with direct preference\noptimization, enabling real-time emotional speech synthesis with high fidelity.\nExperiments show that \\name surpasses state-of-the-art models across omnimodal,\nvision-language, and speech-language benchmarks. It achieves a 4-point absolute\nimprovement on OmniBench over the leading open-source model VITA, despite using\n5x fewer training samples and a smaller model size (7B vs. 7x8B). Additionally,\n\\name achieves real-time speech generation with <1s latency at\nnon-autoregressive mode, reducing inference time by 5x compared to\nautoregressive methods, and improves emotion classification accuracy by 7.7\\%"
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-876",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12937",
    "b_title":[
      "R1-VL: Learning to Reason with Multimodal Large Language Models via\n  Step-wise Group Relative Policy Optimization"
    ],
    "b_abstract":[
      "Recent studies generally enhance MLLMs' reasoning capabilities via supervised\nfine-tuning on high-quality chain-of-thought reasoning data, which often leads\nmodels to merely imitate successful reasoning paths without understanding what\nthe wrong reasoning paths are. In this work, we aim to enhance the MLLMs'\nreasoning ability beyond passively imitating positive reasoning paths. To this\nend, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new\nonline reinforcement learning framework that enables MLLMs to self-improve\nreasoning ability via simple, effective and dense step-wise rewarding.\nSpecifically, StepGRPO introduces two novel rule-based reasoning rewards:\nStep-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity\nReward (StepRVR). StepRAR rewards the reasoning paths that contain necessary\nintermediate reasoning steps via a soft key-step matching technique, while\nStepRAR rewards reasoning paths that follow a well-structured and logically\nconsistent reasoning process through a reasoning completeness and logic\nevaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series\nof MLLMs with outstanding capabilities in step-by-step reasoning. Extensive\nexperiments over 8 benchmarks demonstrate the superiority of our methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05115",
    "c_title":[
      "Constructing PDFs of spatially dependent fields using finite elements"
    ],
    "c_abstract":[
      "A probability density function (PDF) of a spatially dependent field provides\na means of calculating moments of the field or, equivalently, the proportion of\na spatial domain that is mapped to a given set of values. This paper describes\na finite element approach to estimating the PDF of a spatially dependent field\nand its numerical implementation in the Python package NumDF."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA",
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-877",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05021",
    "b_title":[
      "Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for\n  Interpretable LLM Safety"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit\nweaknesses in traditional safety alignment, which often relies on rigid refusal\nheuristics or representation engineering to block harmful outputs. While they\nare effective for direct adversarial attacks, they fall short of broader safety\nchallenges requiring nuanced, context-aware decision-making. To address this,\nwe propose Reasoning-enhanced Finetuning for interpretable LLM Safety\n(Rational), a novel framework that trains models to engage in explicit safe\nreasoning before response. Fine-tuned models leverage the extensive pretraining\nknowledge in self-generated reasoning to bootstrap their own safety through\nstructured reasoning, internalizing context-sensitive decision-making. Our\nfindings suggest that safety extends beyond refusal, requiring context\nawareness for more robust, interpretable, and adaptive responses. Reasoning is\nnot only a core capability of LLMs but also a fundamental mechanism for LLM\nsafety. Rational employs reasoning-enhanced fine-tuning, allowing it to reject\nharmful prompts while providing meaningful and context-aware responses in\ncomplex scenarios."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01742",
    "c_title":[
      "Constraining the geometry of the gas surrounding a typical galaxy at $z\n  = 3.4$ with Ly$\\alpha$ polarization"
    ],
    "c_abstract":[
      "Ly$\\alpha$ emission is the strongest tracer of recombining ionized hydrogen\nin young, star-forming galaxies, but its origin is still debated. Ly$\\alpha$\narises when emitted photons scatter in neutral hydrogen and, so far,\nobservational efforts have mostly focused on the Ly$\\alpha$ surface brightness\nand spectral profile, which depend on the neutral hydrogen column density,\ngeometry, kinematics, powering mechanism and on the region from which the\nphotons are emitted. Different processes produce similar spectra, but have\ndifferent degrees of polarization, that we can use to discriminate between\nthem. In this paper, we present the first spectropolarimetric observations of a\ntypical star-forming galaxy at $z\\sim 3.4$, strongly lensed by the cluster of\ngalaxies Abell 2895, taken with the PMOS mode of the VLT\/FORS2 instrument. We\nmeasure a Ly$\\alpha$ degree of polarization $1\\sigma$ upper limit of $4.6\\%$.\nWe develop new Ly$\\alpha$ radiative transfer models to reproduce the\nobservations, that can be explained by assuming the star-forming galaxy being\nembedded in a CGM with a biconical outflow geometry, with an opening angle of\nthe wind $\\theta_{o,Wind}\\sim 30^\\circ$ for line-of-sight angles $\\theta_{LOS}\n\\leq 20^\\circ$, $\\theta_{o,Wind}\\sim 45^\\circ$ for $\\theta_{LOS}\\leq 20^\\circ$,\n$\\theta_{o,Wind}\\sim 60^\\circ$ for $\\theta_{LOS}\\leq 20^\\circ$, and\n$\\theta_{o,Wind}\\sim 75^\\circ$ for $\\theta_{LOS}\\leq 40^\\circ$, where\n$\\theta_{LOS}=0^\\circ$ means observing in the direction of the outflow. We\nnotice that the constraints from polarization are complementary to those from\nthe spectral line profile. This study shows the potential of adding\nmeasurements of the Ly$\\alpha$ degree of polarization to constrain the geometry\nof the gas surrounding typical star-forming galaxies and paves the way to\nspatially resolved studies that will allow us to disentangle between different\nLy$\\alpha$ origin mechanisms."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-878",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06082",
    "b_title":[
      "A Fair and Optimal Approach to Sequential Health Rationing"
    ],
    "b_abstract":[
      "The COVID-19 pandemic underscored the urgent need for fair and effective\nallocation of scarce resources, from hospital beds to vaccine distribution. In\nthis paper, we study a healthcare rationing problem where identical units of a\nresource are divided into different categories, and agents are assigned based\non priority rankings. % We first introduce a simple and efficient algorithm\nthat satisfies four fundamental axioms critical to practical applications:\neligible compliance, non-wastefulness, respect for priorities, and maximum\ncardinality. This new algorithm is not only conceptually simpler but also\ncomputationally faster than the Reverse Rejecting rules proposed in recent\nwork. % We then extend our analysis to a more general sequential setting, where\ncategories can be processed both sequentially and simultaneously. For this\nbroader framework, we introduce a novel algorithm that preserves the four\nfundamental axioms while achieving additional desirable properties that\nexisting rules fail to satisfy. Furthermore, we prove that when a strict\nprecedence order over categories is imposed, this rule is the unique mechanism\nthat satisfies these properties."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11997",
    "c_title":[
      "Deep Photometric and Astrometric Investigation of the Non-relaxed Star\n  Cluster Stock 3 using Gaia DR3"
    ],
    "c_abstract":[
      "The study presents both photometric and kinematic analyses of the non-relaxed\nopen cluster Stock 3 with Gaia DR3 which found to be positioned at 2.945 $\\pm$\n0.700 kpc and having an age of 16.00 $\\pm$ 4.00 Myr. We analyse the data to\ninfer the membership and thus determine the total mass, IMF and the dynamical\nand kinematical status."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-879",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10638",
    "b_title":[
      "Studying Classifier(-Free) Guidance From a Classifier-Centric\n  Perspective"
    ],
    "b_abstract":[
      "Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17850",
    "c_title":[
      "Twisted torus knots with Horadam parameters"
    ],
    "c_abstract":[
      "Sangyop Lee has done much work to determine the knot types of twisted torus\nknots, including classifying the twisted torus knots which are the unknot.\nAmong the unknotted twisted torus knots are those of the form $(F_{n+2}, F_n,\nF_{n+1}, -1)$, where $F_i$ is the $i$th Fibonacci number. Here, we consider\ntwisted torus knots with parameters that are defined recursively, similarly to\nthe Fibonacci sequence. We call these \\textit{Horadam parameters}, after the\ngeneralization of the Fibonacci sequence introduced by A.F. Horadam. Here, we\nprovide families of twisted torus knots that generalize Lee's work with Horadam\nparameters. Additionally, we provide lists of primitive\/primitive and\nprimitive\/Seifert twisted torus knots and connect these lists to the Horadam\ntwisted torus knots."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-880",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17005",
    "b_title":[
      "Phase coherence of charge-$6e$ superconductors via a frustrated Kagome\n  XY antiferromagnet"
    ],
    "b_abstract":[
      "Recent experimental evidence for the charge-$6e$ condensed phase in kagome\nsuperconductors has generated significant interest. We investigate the\nunconventional superconductivity in the kagome superconductor\n$\\mathrm{CsV_3Sb_5}$, focusing on the emergence of charge-$6e$\nsuperconductivity (SC) at temperatures higher than the conventional charge-$2e$\nSC state. By modeling the phase coherence of the SC order parameter using a\nfrustrated antiferromagnetic XY model on an emergent kagome lattice, we show\nthat the condensation of fractional vortices with $1\/3$ vorticity stabilizes\nphase coherence in $\\exp(i3\\theta)$, giving rise to the charge-$6e$ SC state.\nUsing a tensor network approach tailored for frustrated spin systems, we\nidentify a Berezinskii-Kosterlitz-Thouless transition at $T_c\/J \\simeq 0.075$,\nwhere the unbinding of $1\/3$ fractional vortex-antivortex pairs transforms the\nsystem from the charge-$6e$ SC phase to the normal phase. Below $T_c$, the\n$1\/3$ fractional vortex correlations exhibit power-law decay, while the integer\nvortex correlations decay exponentially, reflecting the dominance of\ncharge-$6e$ SC in the absence of charge-$2e$ SC. Our results provide a\ntheoretical understanding of the charge-$6e$ SC in two-dimensional kagome\nsuperconductors, emphasizing the interplay between fractional vortices,\nfrustration, and topology in stabilizing this exotic SC phase."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06283",
    "c_title":[
      "Dafny as Verification-Aware Intermediate Language for Code Generation"
    ],
    "c_abstract":[
      "Using large language models (LLMs) to generate source code from natural\nlanguage prompts is a popular and promising idea with a wide range of\napplications. One of its limitations is that the generated code can be faulty\nat times, often in a subtle way, despite being presented to the user as\ncorrect. In this paper, we explore ways in which formal methods can assist with\nincreasing the quality of code generated by an LLM. Instead of emitting code in\na target language directly, we propose that the user guides the LLM to first\ngenerate an opaque intermediate representation, in the verification-aware\nlanguage Dafny, that can be automatically validated for correctness against\nagreed on specifications. The correct Dafny program is then compiled to the\ntarget language and returned to the user. All user-system interactions\nthroughout the procedure occur via natural language; Dafny code is never\nexposed. We describe our current prototype and report on its performance on the\nHumanEval Python code generation benchmarks."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LO",
        "cs.PL",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-881",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18075",
    "b_title":[
      "Variational inference for hierarchical models with conditional scale and\n  skewness corrections"
    ],
    "b_abstract":[
      "Gaussian variational approximations are widely used for summarizing posterior\ndistributions in Bayesian models, especially in high-dimensional settings.\nHowever, a drawback of such approximations is the inability to capture skewness\nor more complex features of the posterior. Recent work suggests applying\nskewness corrections to existing Gaussian or other symmetric approximations to\naddress this limitation. We propose to incorporate the skewness correction into\nthe definition of an approximating variational family. We consider\napproximating the posterior for hierarchical models, in which there are\n``global'' and ``local'' parameters. A baseline variational approximation is\ndefined as the product of a Gaussian marginal posterior for global parameters\nand a Gaussian conditional posterior for local parameters given the global\nones. Skewness corrections are then considered. The adjustment of the\nconditional posterior term for local variables is adaptive to the global\nparameter value. Optimization of baseline variational parameters is performed\njointly with the skewness correction. Our approach allows the location, scale\nand skewness to be captured separately, without using additional parameters for\nskewness adjustments. The proposed method substantially improves accuracy for\nonly a modest increase in computational cost compared to state-of-the-art\nGaussian approximations. Good performance is demonstrated in generalized linear\nmixed models and multinomial logit discrete choice models."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06793",
    "c_title":[
      "Differentially Private Gradient-Tracking-Based Distributed Stochastic\n  Optimization over Directed Graphs"
    ],
    "c_abstract":[
      "This paper proposes a new differentially private gradient-tracking-based\ndistributed stochastic optimization algorithm over directed graphs.\nSpecifically, privacy noises are added to each agent's state and tracking\nvariable to prevent information leakage, and then perturbed states and tracking\nvariables are transmitted to neighbors. We design two novel schemes of the\niteration step-sizes and the sampling number for the algorithm. By using the\nsampling parameter-controlled subsampling method, both schemes enhance the\ndifferential privacy level, and achieve the finite cumulative privacy budget\neven over infinite iterations. The convergence rate of the algorithm is shown\nfor both nonconvex with the Polyak-Lojasiewicz condition and strongly convex\nobjectives: Scheme (S1) achieves the polynomial convergence rate, and Scheme\n(S2) achieves the exponential convergence rate. The trade-off between the\nprivacy and the convergence rate is presented. The algorithm's effectiveness\nand superior performance over the existing works are demonstrated through\nnumerical examples of distributed training on benchmark datasets \"MNIST\" and\n\"CIFAR-10\"."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-882",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01824",
    "b_title":[
      "Digital quantum simulation of bosonic systems and quantum\n  complementarity"
    ],
    "b_abstract":[
      "Digital quantum simulation has emerged as a powerful approach to investigate\ncomplex quantum systems using digital quantum computers. Many-particle bosonic\nsystems and intricate optical experimental setups pose significant challenges\nfor classical simulation methods. Utilizing a recently developed formalism that\nmaps bosonic operators to Pauli operators via the Gray code, we digitally\nsimulate interferometric variants of Afshar's experiment on IBM's quantum\ncomputers. We investigate the analogous experiments of Unruh and Pessoa\nJ\\'unior, exploring discussions on the apparent violation of Bohr's\ncomplementarity principle when considering the entire experimental setup.\nFurthermore, we analyze these experiments within the framework of an updated\nquantum complementarity principle, which applies to specific quantum state\npreparations and remains consistent with the foundational principles of quantum\nmechanics. Our quantum computer demonstration results are in good agreement\nwith the theoretical predictions and underscore the potential of quantum\ncomputers as effective simulators for bosonic systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.09243",
    "c_title":[
      "GarmentPile: Point-Level Visual Affordance Guided Retrieval and\n  Adaptation for Cluttered Garments Manipulation"
    ],
    "c_abstract":[
      "Cluttered garments manipulation poses significant challenges due to the\ncomplex, deformable nature of garments and intricate garment relations. Unlike\nsingle-garment manipulation, cluttered scenarios require managing complex\ngarment entanglements and interactions, while maintaining garment cleanliness\nand manipulation stability. To address these demands, we propose to learn\npoint-level affordance, the dense representation modeling the complex space and\nmulti-modal manipulation candidates, while being aware of garment geometry,\nstructure, and inter-object relations. Additionally, as it is difficult to\ndirectly retrieve a garment in some extremely entangled clutters, we introduce\nan adaptation module, guided by learned affordance, to reorganize\nhighly-entangled garments into states plausible for manipulation. Our framework\ndemonstrates effectiveness over environments featuring diverse garment types\nand pile configurations in both simulation and the real world. Project page:\nhttps:\/\/garmentpile.github.io\/."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-883",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02235",
    "b_title":[
      "Survey on Question Answering over Visually Rich Documents: Methods,\n  Challenges, and Trends"
    ],
    "b_abstract":[
      "The field of visually-rich document understanding, which involves interacting\nwith visually-rich documents (whether scanned or born-digital), is rapidly\nevolving and still lacks consensus on several key aspects of the processing\npipeline. In this work, we provide a comprehensive overview of state-of-the-art\napproaches, emphasizing their strengths and limitations, pointing out the main\nchallenges in the field, and proposing promising research directions."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14492",
    "c_title":[
      "The effect of Q-condition in elliptic equations involving Hardy\n  potential and singular convection term"
    ],
    "c_abstract":[
      "Using an approach by contradiction we prove the existence and uniqueness of a\nweak solution to a quasi-linear elliptic boundary value problem with singular\nconvection term and Hardy Potential. Whose simplest model is\n  \\begin{equation*} \\Scale[0.8]{\\ds u \\in W_0^{1,2}(\\mathcal{O})\\cap\nL^\\infty(\\mathcal{O}) : -\\Delta u=-\\mathcal{A}\\text{div}\\left(\\frac{x}{\\vert\nx\\vert^2}u\\right)+\\lambda \\frac{u}{\\vert x\\vert^2}+f(x),} \\end{equation*} where\n\\(\\mathcal{O}\\) is a bounded open set in \\(\\mathbb{R}^N\\),\n$\\left(\\mathcal{A},\\lambda\\right) \\in \\left(0, \\infty\\right)^2$ and \\(f\\in\nW^{-1,2}(\\mathcal{O})\\).\n  Additionally, by taking advantage of the regularizing effect of the\ninteraction between the coefficient of the zero order term and the datum, we\nestablish the existence, uniqueness and regularity of a weak solution to a\nquasi-linear boundary value problem whose simplest example is \\begin{equation*}\n\\Scale[0.8]{\\ds u \\in W_0^{1,2}(\\mathcal{O})\\cap L^\\infty(\\mathcal{O}) :\n-\\Delta u +a(x)\\vert u\\vert^{p-2}u=-\\mathcal{A}\\text{div}\\left(\\frac{x}{\\vert\nx\\vert^2}u\\right)+\\lambda \\frac{u}{\\vert x\\vert^2}+f(x),} \\end{equation*} under\nsuitable assumptions on $a$ and $f$."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-884",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18652",
    "b_title":[
      "Classical Information Exchange Between Particles"
    ],
    "b_abstract":[
      "The flow of information within many-body systems is a fundamental feature of\nphysical interaction. Given an underlying classical physics model for the\ninteraction between a particle and its environment, we give meaning to and\nquantify the information passed between them over time. We show that the\nmaximum information exchange rate is proportional to the ratio of\ninter-particle energy flow and initial particle energy -- a sort of\nsignal-to-noise ratio. In addition, a single time-point (as opposed to\ntrajectory) observability relation emerges."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12371",
    "c_title":[
      "Localization of critical points in annular conical sets via the method\n  of Nehari manifold"
    ],
    "c_abstract":[
      "Using the Nehari manifold method, we establish sufficient conditions such\nthat a smooth functional attains a ground state within an annular domain of a\nclosed cone. The localization we obtain immediately allows for multiplicity\nwhen applied to disjoint conical sets. To illustrate our results, we consider a\ntwo-point boundary value problem and obtain a solution within a shell of a\nclosed cone, defined in terms of a Harnack inequality with respect to the\nenergy norm. The conditions imposed on the nonlinear term naturally extend\nthose from classical examples in the literature which were derived using the\nmethod of Nehari manifold on the entire domain."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-885",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03592",
    "b_title":[
      "Solar Panel Mapping via Oriented Object Detection"
    ],
    "b_abstract":[
      "Maintaining the integrity of solar power plants is a vital component in\ndealing with the current climate crisis. This process begins with analysts\ncreating a detailed map of a plant with the coordinates of every solar panel,\nmaking it possible to quickly locate and mitigate potential faulty solar\npanels. However, this task is extremely tedious and is not scalable for the\never increasing capacity of solar power across the globe. Therefore, we propose\nan end-to-end deep learning framework for detecting individual solar panels\nusing a rotated object detection architecture. We evaluate our approach on a\ndiverse dataset of solar power plants collected from across the United States\nand report a mAP score of 83.3%."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02419",
    "c_title":[
      "On the existence and regularity of weakly nonlinear stationary Boltzmann\n  equations : a Fredholm alternative approach"
    ],
    "c_abstract":[
      "The celebrated Fredholm alternative theorem works for the setting of identity\ncompact operators. This idea has been widely used to solve linear partial\ndifferential equations \\cite{Evans}. In this article, we demonstrate a\ngeneralized Fredholm theory in the setting of identity power compact operators,\nwhich was suggested in Cercignani and Palczewski \\cite{CP} to solve the\nexistence of the stationary Boltzmann equation in a slab domain. We carry out\nthe detailed analysis based on this generalized Fredholm theory to prove the\nexistence theory of the stationary Boltzmann equation in bounded\nthree-dimensional convex domains. To prove that the integral form of the\nlinearized Boltzmann equation satisfies the identity power compact setting\nrequires the regularizing effect of the solution operators. Once the existence\nand regularity theories for the linear case are established, with suitable\nbilinear estimates, the nonlinear existence theory is accomplished."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-886",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03087",
    "b_title":[
      "Propagation of chaos for multi-species moderately interacting particle\n  systems up to Newtonian singularity"
    ],
    "b_abstract":[
      "We derive a class of multi-species aggregation-diffusion systems from\nstochastic interacting particle systems via relative entropy method with\nquantitative bounds. We show an algebraic $L^1$-convergence result using\nmoderately interacting particle systems approximating attractive\/repulsive\nsingular potentials up to Newtonian\/Coulomb singularities without additional\ncut-off on the particle level. The first step is to make use of the relative\nentropy between the joint distribution of the particle system and an\napproximated limiting aggregation-diffusion system. A crucial argument in the\nproof is to show convergence in probability by a stopping time argument. The\nsecond step is to obtain a quantitative convergence rate to the limiting\naggregation-diffusion system from the approximated PDE system. This is shown by\nevaluating a combination of relative entropy and $L^2$-distance."
    ],
    "b_categories":[
      [
        "math.AP",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06327",
    "c_title":[
      "Prompt-Driven Continual Graph Learning"
    ],
    "c_abstract":[
      "Continual Graph Learning (CGL), which aims to accommodate new tasks over\nevolving graph data without forgetting prior knowledge, is garnering\nsignificant research interest. Mainstream solutions adopt the memory\nreplay-based idea, ie, caching representative data from earlier tasks for\nretraining the graph model. However, this strategy struggles with scalability\nissues for constantly evolving graphs and raises concerns regarding data\nprivacy. Inspired by recent advancements in the prompt-based learning paradigm,\nthis paper introduces a novel prompt-driven continual graph learning\n(PROMPTCGL) framework, which learns a separate prompt for each incoming task\nand maintains the underlying graph neural network model fixed. In this way,\nPROMPTCGL naturally avoids catastrophic forgetting of knowledge from previous\ntasks. More specifically, we propose hierarchical prompting to instruct the\nmodel from both feature- and topology-level to fully address the variability of\ntask graphs in dynamic continual learning. Additionally, we develop a\npersonalized prompt generator to generate tailored prompts for each graph node\nwhile minimizing the number of prompts needed, leading to constant memory\nconsumption regardless of the graph scale. Extensive experiments on four\nbenchmarks show that PROMPTCGL achieves superior performance against existing\nCGL approaches while significantly reducing memory consumption. Our code is\navailable at https:\/\/github.com\/QiWang98\/PromptCGL."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-887",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05581",
    "b_title":[
      "Constraining the Scattered Light properties of LTT 9779 b Using HST\/WFC3\n  UVIS"
    ],
    "b_abstract":[
      "A planet's albedo is a fundamental property that sets its energy budget by\ndictating the fraction of incident radiation absorbed versus reflected back to\nspace. Generally, optical eclipse observations have revealed the majority of\nhot, giant planets to have low albedos, indicating dayside atmospheres\ndominated by absorption instead of reflection. However, there are several\nexceptions to this rule, including the ultra-hot-Neptune LTT 9779b, which have\nbeen found to have high geometric albedos. We observed four eclipses of LTT\n9779b with the G280 grism of the Hubble Space Telescope's WFC3 UVIS mode;\ntargeting the scattering signatures of the cloud condensate species causing the\nplanet's elevated reflectivity. However, we do not definitively detect the\nplanet's eclipse in our observations, with injection-recovery tests yielding a\n3-$\\sigma$ upper limit of 113 ppm on the eclipse depth of LTT 9779b in the\n0.2-0.8$\\mu$m waveband. We create reflectance spectrum grids for LTT 9779b's\ndayside using VIRGA\/PICASO and compare to our UVIS limit, as well as previously\npublished CHEOPS and TESS eclipse photometry. We find that silicate condensates\nare best able to explain LTT 9779b's highly-reflective dayside. Our forward\nmodel grids only enable weak constraints on vertical mixing efficiency, and\nsuggest that, regardless of their particular composition, the clouds are likely\ncomposed of smaller and more reflective particles. Our work facilitates a\ndeeper understanding of the reflectance properties of LTT 9779b as well as the\nUVIS spectroscopic mode itself, which will remain the community's primary\naccess to UV wavelengths until next-generation telescopes like the Habitable\nWorlds Observatory."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01917",
    "c_title":[
      "How to Steer LLM Latents for Hallucination Detection?"
    ],
    "c_abstract":[
      "Hallucinations in LLMs pose a significant concern to their safe deployment in\nreal-world applications. Recent approaches have leveraged the latent space of\nLLMs for hallucination detection, but their embeddings, optimized for\nlinguistic coherence rather than factual accuracy, often fail to clearly\nseparate truthful and hallucinated content. To this end, we propose the\nTruthfulness Separator Vector (TSV), a lightweight and flexible steering vector\nthat reshapes the LLM's representation space during inference to enhance the\nseparation between truthful and hallucinated outputs, without altering model\nparameters. Our two-stage framework first trains TSV on a small set of labeled\nexemplars to form compact and well-separated clusters. It then augments the\nexemplar set with unlabeled LLM generations, employing an optimal\ntransport-based algorithm for pseudo-labeling combined with a confidence-based\nfiltering process. Extensive experiments demonstrate that TSV achieves\nstate-of-the-art performance with minimal labeled data, exhibiting strong\ngeneralization across datasets and providing a practical solution for\nreal-world LLM applications."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-888",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11246",
    "b_title":[
      "MemeSense: An Adaptive In-Context Framework for Social Commonsense\n  Driven Meme Moderation"
    ],
    "b_abstract":[
      "Memes present unique moderation challenges due to their subtle, multimodal\ninterplay of images, text, and social context. Standard systems relying\npredominantly on explicit textual cues often overlook harmful content\ncamouflaged by irony, symbolism, or cultural references. To address this gap,\nwe introduce MemeSense, an adaptive in-context learning framework that fuses\nsocial commonsense reasoning with visually and semantically related reference\nexamples. By encoding crucial task information into a learnable cognitive shift\nvector, MemeSense effectively balances lexical, visual, and ethical\nconsiderations, enabling precise yet context-aware meme intervention. Extensive\nevaluations on a curated set of implicitly harmful memes demonstrate that\nMemeSense substantially outperforms strong baselines, paving the way for safer\nonline communities. Code and data available at:\nhttps:\/\/github.com\/sayantan11995\/MemeSense"
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY",
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10466",
    "c_title":[
      "Accelerating Expansion of the Universe in Modified Symmetric\n  Teleparallel Gravity"
    ],
    "c_abstract":[
      "In the last century, theoretical and experimental developments have\nestablished the General Relativity theory as the most successful theory for\ndescribing the gravitational phenomenon. On the other hand, in the last two\ndecades, multiple observational probes have strongly favored the discovery of\nthe acceleration of cosmic expansion. The observational enhancement and\ndevelopment in precision cosmology indicate a requirement to go beyond General\nRelativity and to search for an alternate description that can resolve the\npersistent issues. In Chapter 1, we highlight some important elements of\nobservational cosmology. In Chapters 2 and 3, we investigate the f(Q) gravity\nin the presence of viscosity in the cosmic fluid. In Chapters 4 and 5, we\nexplore the constraints on the various classes of non-linear f(Q) gravity\nmodels in both coincident and non-coincident formalism, respectively. In\nChapter 6, we present a covariant formulation and energy balance equation for\nthe f(Q,T) gravity, which is an extension of f(Q) gravity. Finally, in Chapter\n7, we briefly summarize the outcomes of the present thesis and the future\nscope."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-889",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14716",
    "b_title":[
      "Functions and operators of the polyharmonic and polyanalytic Clifford\n  fine structures on the $S$-spectrum"
    ],
    "b_abstract":[
      "The spectral theory on the $S$-spectrum originated to give quaternionic\nquantum mechanics a precise mathematical foundation and as a spectral theory\nfor linear operators in vector analysis.\n  This theory has proven to be significantly more general than initially\nanticipated, naturally extending to fully Clifford operators and revealing\nunexpected connections with the spectral theory based on the monogenic\nspectrum, developed over forty years ago by A. McIntosh and collaborators.\n  In recent years, we have combined slice hyperholomorphic functions with the\nFueter-Sce mapping theorem, also called Fueter-Sce extension theorem, to\nbroaden the class of functions and operators to which the theory can be\napplied. This generalization has led to the definition of what we call the {\\em\nfine structures on the $S$-spectrum}, consisting of classes of functions that\nadmit an integral representation and their associated functional calculi.\n  In this paper, we focus on the fine structures within the Clifford algebra\nsetting, particularly addressing polyharmonic functions, polyanalytic\nfunctions, holomorphic Cliffordian functions and their associated functional\ncalculi defined via integral representation formulas.\n  Moreover, we demonstrate that the monogenic functional calculus, defined via\nthe monogenic Cauchy formula, and the $F$-functional calculus of the fine\nstructures, defined via the Fueter-Sce mapping theorem in integral form, yield\nthe same operator."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.14793",
    "c_title":[
      "Tracking time-varying signals with quantum-enhanced atomic magnetometers"
    ],
    "c_abstract":[
      "Quantum entanglement, in the form of spin squeezing, is known to improve the\nsensitivity of atomic instruments to static or slowly-varying quantities.\nSensing transient events presents a distinct challenge, requires different\nanalysis methods, and has not been shown to benefit from entanglement in\npractically-important scenarios such as spin-precession magnetometry (SPM).\nHere we adapt estimation control techniques introduced in\narXiv:2403.14764(2024) to the experimental setting of SPM and analogous\ntechniques. We demonstrate that real-time tracking of fluctuating fields\nbenefits from measurement-induced spin-squeezing and that quantum limits\ndictated by decoherence are within reach of today's experiments. We illustrate\nthis quantum advantage by single-shot tracking, within the coherence time of a\nspin-precession magnetometer, of a magnetocardiography signal overlain with\nbroadband noise."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-890",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12349",
    "b_title":[
      "General Field Evaluation in High-Order Meshes on GPUs"
    ],
    "b_abstract":[
      "Robust and scalable function evaluation at any arbitrary point in the\nfinite\/spectral element mesh is required for querying the partial differential\nequation solution at points of interest, comparison of solution between\ndifferent meshes, and Lagrangian particle tracking. This is a challenging\nproblem, particularly for high-order unstructured meshes partitioned in\nparallel with MPI, as it requires identifying the element that overlaps a given\npoint and computing the corresponding reference space coordinates. We present a\nrobust and efficient technique for general field evaluation in large-scale\nhigh-order meshes with quadrilaterals and hexahedra. In the proposed method, a\ncombination of globally partitioned and processor-local maps are used to first\ndetermine a list of candidate MPI ranks, and then locally candidate elements\nthat could contain a given point. Next, element-wise bounding boxes further\nreduce the list of candidate elements. Finally, Newton's method with trust\nregion is used to determine the overlapping element and corresponding reference\nspace coordinates. Since GPU-based architectures have become popular for\naccelerating computational analyses using meshes with tensor-product elements,\nspecialized kernels have been developed to utilize the proposed methodology on\nGPUs. The method is also extended to enable general field evaluation on surface\nmeshes. The paper concludes by demonstrating the use of proposed method in\nvarious applications ranging from mesh-to-mesh transfer during r-adaptivity to\nLagrangian particle tracking."
    ],
    "b_categories":[
      [
        "cs.CE",
        "cs.MS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01660",
    "c_title":[
      "Non-convergence to the optimal risk for Adam and stochastic gradient\n  descent optimization in the training of deep neural networks"
    ],
    "c_abstract":[
      "Despite the omnipresent use of stochastic gradient descent (SGD) optimization\nmethods in the training of deep neural networks (DNNs), it remains, in\nbasically all practically relevant scenarios, a fundamental open problem to\nprovide a rigorous theoretical explanation for the success (and the\nlimitations) of SGD optimization methods in deep learning. In particular, it\nremains an open question to prove or disprove convergence of the true risk of\nSGD optimization methods to the optimal true risk value in the training of\nDNNs. In one of the main results of this work we reveal for a general class of\nactivations, loss functions, random initializations, and SGD optimization\nmethods (including, for example, standard SGD, momentum SGD, Nesterov\naccelerated SGD, Adagrad, RMSprop, Adadelta, Adam, Adamax, Nadam, Nadamax, and\nAMSGrad) that in the training of any arbitrary fully-connected feedforward DNN\nit does not hold that the true risk of the considered optimizer converges in\nprobability to the optimal true risk value. Nonetheless, the true risk of the\nconsidered SGD optimization method may very well converge to a strictly\nsuboptimal true risk value."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-891",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14308",
    "b_title":[
      "A novel method for quantifying enzyme immobilization in porous carriers\n  using simple NMR relaxometry"
    ],
    "b_abstract":[
      "Enzyme immobilization plays a crucial role in enhancing the stability and\nrecyclability of enzymes for industrial applications. However, traditional\nmethods for quantifying enzyme loading within porous carriers are limited by\ntime-consuming workflows, cumulative errors, and the inability to probe enzymes\nadsorbed inside the pores. In this study, we introduce Time-Domain Nuclear\nMagnetic Resonance (TD-NMR) relaxometry as a novel, non-invasive technique for\ndirectly quantifying enzyme adsorption within porous carriers. Focusing on\nepoxy methyl acrylate carriers, commonly used in biocatalysis, we correlate\nchanges in T2 relaxation times with enzyme concentration, leading to the\ndevelopment of an NMR-based pore-filling ratio that quantifies enzyme loading.\nValidation experiments demonstrate that TD-NMR-derived adsorption curves align\nclosely with traditional photometric measurements, offering a reliable and\nreproducible alternative for enzyme quantification. The accessibility of\ntabletop TD-NMR spectrometers makes this technique a practical and\ncost-effective tool for optimizing biocatalytic processes. Furthermore, the\nmethod holds promise for real-time monitoring of adsorption dynamics and could\nbe adapted for a wider range of carrier materials and enzymes."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04154",
    "c_title":[
      "CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised\n  Monocular 3D Detection"
    ],
    "c_abstract":[
      "Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-892",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08945",
    "b_title":[
      "COADVISE: Covariate Adjustment with Variable Selection in Randomized\n  Controlled Trials"
    ],
    "b_abstract":[
      "Adjusting for covariates in randomized controlled trials can enhance the\ncredibility and efficiency of treatment effect estimation. However, handling\nnumerous covariates and their complex (non-linear) transformations poses a\nchallenge. Motivated by the case study of the Best Apnea Interventions for\nResearch (BestAIR) trial data from the National Sleep Research Resource (NSRR),\nwhere the number of covariates (p=114) is comparable to the sample size\n(N=196), we propose a principled Covariate Adjustment with Variable Selection\n(COADVISE) framework. COADVISE enables variable selection for covariates most\nrelevant to the outcome while accommodating both linear and nonlinear\nadjustments. This framework ensures consistent estimates with improved\nefficiency over unadjusted estimators and provides robust variance estimation,\neven under outcome model misspecification. We demonstrate efficiency gains\nthrough theoretical analysis, extensive simulations, and a re-analysis of the\nBestAIR trial data to compare alternative variable selection strategies,\noffering cautionary recommendations. A user-friendly R package, Coadvise, is\navailable to facilitate practical implementation."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10535",
    "c_title":[
      "Lead Times in Flux: Analyzing Airbnb Booking Dynamics During Global\n  Upheavals (2018-2022)"
    ],
    "c_abstract":[
      "Short-term shifts in booking behaviors can disrupt forecasting in the travel\nand hospitality industry, especially during global crises. Traditional metrics\nlike average or median lead times often overlook important distribution\nchanges. This study introduces a normalized L1 (Manhattan) distance to assess\nAirbnb booking lead time divergences from 2018 to 2022, focusing on the\nCOVID-19 pandemic across four major U.S. cities. We identify a two-phase\ndisruption: an abrupt change at the pandemic's onset followed by partial\nrecovery with persistent deviations from pre-2018 patterns. Our method reveals\nchanges in travelers' planning horizons that standard statistics miss,\nhighlighting the need to analyze the entire lead-time distribution for more\naccurate demand forecasting and pricing strategies. The normalized L1 metric\nprovides valuable insights for tourism stakeholders navigating ongoing market\nvolatility."
    ],
    "c_categories":[
      [
        "q-fin.ST",
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-893",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18250",
    "b_title":[
      "Dynamic Model Fine-Tuning For Extreme MIMO CSI Compression"
    ],
    "b_abstract":[
      "Efficient channel state information (CSI) compression is crucial in frequency\ndivision duplexing (FDD) massive multiple-input multiple-output (MIMO) systems\ndue to excessive feedback overhead. Recently, deep learning-based compression\ntechniques have demonstrated superior performance across various data types,\nincluding CSI. However, these approaches often experience performance\ndegradation when the data distribution changes due to their limited\ngeneralization capabilities. To address this challenge, we propose a model\nfine-tuning approach for CSI feedback in massive MIMO systems. The idea is to\nfine-tune the encoder\/decoder network models in a dynamic fashion using the\nrecent CSI samples. First, we explore encoder-only fine-tuning, where only the\nencoder parameters are updated, leaving the decoder and latent parameters\nunchanged. Next, we consider full-model fine-tuning, where the encoder and\ndecoder models are jointly updated. Unlike encoder-only fine-tuning, full-model\nfine-tuning requires the updated decoder and latent parameters to be\ntransmitted to the decoder side. To efficiently handle this, we propose\ndifferent prior distributions for model updates, such as uniform and truncated\nGaussian to entropy code them together with the compressed CSI and account for\nadditional feedback overhead imposed by conveying the model updates. Moreover,\nwe incorporate quantized model updates during fine-tuning to reflect the impact\nof quantization in the deployment phase. Our results demonstrate that\nfull-model fine-tuning significantly enhances the rate-distortion (RD)\nperformance of neural CSI compression. Furthermore, we analyze how often the\nfull-model fine-tuning should be applied in a new wireless environment and\nidentify an optimal period interval for achieving the best RD trade-off."
    ],
    "b_categories":[
      [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06475",
    "c_title":[
      "SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph\n  Construction Using Large Language Models"
    ],
    "c_abstract":[
      "The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is\nconstructed from stroke-related articles using mathematical and large language\nmodels (LLMs). SKG-LLM extracts and organizes complex relationships from the\nbiomedical literature, using it to increase the accuracy and depth of KG in\nstroke research. In the proposed method, GPT-4 was used for data\npre-processing, and the extraction of embeddings was also done by GPT-4 in the\nwhole KG construction process. The performance of the proposed model was tested\nwith two evaluation criteria: Precision and Recall. For further validation of\nthe proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the\nproposed KG-LLM approach performs better, especially in precision and recall.\nBy including GPT-4 in the preprocessing process, the SKG-LLM model achieved a\nprecision score of 0.906 and a recall score of 0.923. Expert reviews further\nimproved the results and increased precision to 0.923 and recall to 0.918. The\nknowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges,\nwhich are 13 distinct types of nodes and 24 types of edges."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-894",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10930",
    "b_title":[
      "Reduced Order Modeling with Shallow Recurrent Decoder Networks"
    ],
    "b_abstract":[
      "Reduced Order Modeling is of paramount importance for efficiently inferring\nhigh-dimensional spatio-temporal fields in parametric contexts, enabling\ncomputationally tractable parametric analyses, uncertainty quantification and\ncontrol. However, conventional dimensionality reduction techniques are\ntypically limited to known and constant parameters, inefficient for nonlinear\nand chaotic dynamics, and uninformed to the actual system behavior. In this\nwork, we propose sensor-driven SHallow REcurrent Decoder networks for Reduced\nOrder Modeling (SHRED-ROM). Specifically, we consider the composition of a long\nshort-term memory network, which encodes the temporal dynamics of limited\nsensor data in multiple scenarios, and a shallow decoder, which reconstructs\nthe corresponding high-dimensional states. SHRED-ROM is a robust decoding-only\nstrategy that circumvents the numerically unstable approximation of an inverse\nwhich is required by encoding-decoding schemes. To enhance computational\nefficiency and memory usage, the full-order state snapshots are reduced by,\ne.g., proper orthogonal decomposition, allowing for compressive training of the\nnetworks with minimal hyperparameter tuning. Through applications on chaotic\nand nonlinear fluid dynamics, we show that SHRED-ROM (i) accurately\nreconstructs the state dynamics for new parameter values starting from limited\nfixed or mobile sensors, independently on sensor placement, (ii) can cope with\nboth physical, geometrical and time-dependent parametric dependencies, while\nbeing agnostic to their actual values, (iii) can accurately estimate unknown\nparameters, and (iv) can deal with different data sources, such as\nhigh-fidelity simulations, coupled fields and videos."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17984",
    "c_title":[
      "The IACOB project XIV. New clues on the location of the TAMS in the\n  massive star domain"
    ],
    "c_abstract":[
      "Massive stars play a very important role in many astrophysical fields. Yet,\nsome fundamental aspects of their evolution remain poorly constrained. In this\nregard, there is an open debate on the width of the main-sequence (MS) phase.\nWe aim to create an updated Hertzsprung-Russell (HR) diagram that includes a\nvolume-limited and statistically significant sample of massive stars. Our goal\nis to use this sample to investigate the extension of the MS, including\ninformation about projected rotational velocities ($v\\sin i$) and the\nspectroscopic binary status. We combine spectroscopic parameters derived with\nFASTWIND stellar atmosphere code and Gaia distances to obtain stellar\nparameters for 876 Galactic luminous O- and B-type stars gathered within the\nIACOB project. We use the ${\\tt iacob-broad}$ tool to derive $v\\sin i$\nestimates and multi-epoch spectra to identify single\/double-line spectroscopic\nbinaries (SB1\/SB2). We present an HR diagram for 670 stars located within\n2500pc balancing completeness and number. We evaluate the extension of the MS\nin terms of the drop in the relative number of stars as a function of effective\ntemperature ($T_{\\rm eff}$). We find a consistent boundary at $\\approx$22.5kK\nwithin the full range of luminosities that we use to delineate the terminal-age\nmain sequence (TAMS). We obtain a smooth decrease of the highest $v\\sin i$ with\n$T_{\\rm eff}$ along the MS, likely limited by the critical velocity. We\nconsider this effect combined with a lower expected fraction of stars beyond\nthe MS as the best explanation for the lack of fast-rotating objects in the\npost-MS region. Our results favor low to mild initial rotation for the full\nsample and a binary past for the tail of fast-rotating stars. The prominence of\nSB1\/SB2 systems in the MS, and the 25% decrease in the relative fraction of SB1\nsystems when crossing the TAMS can further delineate its location."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-895",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03070",
    "b_title":[
      "The bilinear Hessian for large scale optimization"
    ],
    "b_abstract":[
      "Second order information is useful in many ways in smooth optimization\nproblems, including for the design of step size rules and descent directions,\nor the analysis of the local properties of the objective functional. However,\nthe computation and storage of the Hessian matrix using second order partial\nderivatives is prohibitive in many contexts, and in particular in large scale\nproblems. In this work, we propose a new framework for computing and presenting\nsecond order information in analytic form. The key novel insight is that the\nHessian for a problem can be worked with efficiently by computing its bilinear\nform or operator form using Taylor expansions, instead of introducing a basis\nand then computing the Hessian matrix. Our new framework is suited for\nhigh-dimensional problems stemming e.g. from imaging applications, where\ncomputation of the Hessian matrix is unfeasible. We also show how this can be\nused to implement Newton's step rule, Daniel's Conjugate Gradient rule, or\nQuasi-Newton schemes, without explicit knowledge of the Hessian matrix, and\nillustrate our findings with a simple numerical experiment."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.12905",
    "c_title":[
      "Fundamental constraints on quantum fluctuations: Conservation laws,\n  reality, and no-signaling"
    ],
    "c_abstract":[
      "Quantum fluctuations and noise are fundamental in quantum technologies,\naffecting computing, sensing, cryptography, and thermodynamics. These include\nfluctuations in the variation of energy, charge, and other observables driven\nby interactions with lasers, amplifiers, and baths. Despite the precise rules\nquantum mechanics provides for measuring observables at single points in time,\nno standard framework exists for characterizing the fluctuations of their\nvariations over time. This gap not only makes physical conclusions dependent on\nthe chosen measurement protocol but also leads to inconsistencies in\nfluctuation predictions, impacting quantum technologies. We propose four basic\ncriteria that any consistent measurement of these variations must satisfy,\ngrounded in conservation laws, the no-signaling principle, and expected\nconstraints on physical realism. We demonstrate that only one protocol fulfills\nall these criteria: the two-times quantum observables. This result enables the\nextension of key quantum information concepts, such as entanglement, steering,\nand Bell's inequalities, to processes rather than instantaneous observables.\nBeyond resolving ambiguities in quantum fluctuation measurements, our framework\noffers a foundation for improved fluctuation control in quantum devices, with\npotential applications in quantum computing, metrology, and thermodynamics."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-896",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16318",
    "b_title":[
      "Direct Numerical Simulation of Hydrogen Combustion in a Real-Size IC\n  Engine"
    ],
    "b_abstract":[
      "This study presents the first Direct Numerical Simulation (DNS) of hydrogen\ncombustion in a real-size internal combustion engine, investigating the complex\ndynamics of ignition, flame propagation, and flame-wall interaction under\nengine-relevant conditions. The simulation focuses on ultra-lean hydrogen\noperation at equivalence ratio $\\phi=0.4$ and 800 rpm, utilizing a\nstate-of-the-art spectral element solver optimized for GPU architectures. The\ncomputational domain encompasses the full engine geometry. Results highlight\nthe strong coupling between the flame dynamics and the coherent flow structures\nduring early flame kernel development, while differential diffusion effects\nlead to increased reactivity at positive flame curvatures, a phenomenon that\nhas only been studied in canonical configurations of freely propagating\nhydrogen\/air flames. As the flame approaches the walls, distinct behavior is\nobserved during head-on and side-wall quenching scenarios, characterized by\ndifferent spatial distributions of wall heat flux. The findings provide\ninsights into hydrogen combustion in real engines, essential for the\ndevelopment of clean and efficient hydrogen-fueled powertrains."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05071",
    "c_title":[
      "Fredholm anomalies on manifold with corners of low codimensions and\n  conormal corner cycles"
    ],
    "c_abstract":[
      "Given a connected manifold with corners $X$ of any codimension there is a\nvery basic and computable homology theory called conormal homology defined in\nterms of faces and orientations of their conormal bundles, and whose cycles\ncorrespond geometrically to corner's cycles, these conormal homology groups are\ndenoted by $H^{cn}_*(X)$. Using our previous works we define an index morphism\n$$K^0(^bT^*X)\\stackrel{Ind_{ev,cn}^X}{\\longrightarrow}H_{ev}^{cn}(X)$$ for $X$\na manifold with corners of codimension less or equal to three and called here\nthe even conormal index morphism. In the case that $X$ is compact and connected\nand $D$ is an elliptic $b-$pseudodifferential operator in the associated\n$b-$calculus of $X$ we know, by our previous works and other authors works,\nthat, up to adding an identity operator, $D$ can be perturbed (with a\nregularizing operator in the calculus) to a Fredholm operator iff\n$Ind_{ev,cn}^X([\\sigma_D])$ (where $[\\sigma_D]\\in K^0(^bT^*X)$ is the principal\nsymbol class) vanishes in the even conormal homology group $H_{ev}^{cn}(X)$.\nThe main result of this paper is the explicit computation of the even and odd\nconormal index morphisms $Ind_{ev\/odd,cn}^X(\\sigma)\\in H_{ev\/odd}^{cn}(X)$ for\n$X$ a manifold with corners of codimension less or equal to three. The\ncoefficients of the conormal corner cycles $Ind_{ev\/odd,cn}^X(\\sigma)$ are\ngiven in terms of some suspended Atiyah-Singer indices of the maximal\ncodimension faces of $X$ and in terms of some suspended Atiyah-Patodi-Singer\nindices of the non-maximal codimension faces of $X$. As a corollary we give a\ncomplete caracterization to the obstruction of the Fredholm perturbation\nproperty for closed manifolds with corners of codimension less or equal to\nthree in terms of the above mentioned indices of the faces, this allows us as\nwell to give such a characterization in terms of the respective topological\nindices."
    ],
    "c_categories":[
      [
        "math.KT",
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-897",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19770",
    "b_title":[
      "TAPE: Tailored Posterior Difference for Auditing of Machine Unlearning"
    ],
    "b_abstract":[
      "With the increasing prevalence of Web-based platforms handling vast amounts\nof user data, machine unlearning has emerged as a crucial mechanism to uphold\nusers' right to be forgotten, enabling individuals to request the removal of\ntheir specified data from trained models. However, the auditing of machine\nunlearning processes remains significantly underexplored. Although some\nexisting methods offer unlearning auditing by leveraging backdoors, these\nbackdoor-based approaches are inefficient and impractical, as they necessitate\ninvolvement in the initial model training process to embed the backdoors. In\nthis paper, we propose a TAilored Posterior diffErence (TAPE) method to provide\nunlearning auditing independently of original model training. We observe that\nthe process of machine unlearning inherently introduces changes in the model,\nwhich contains information related to the erased data. TAPE leverages\nunlearning model differences to assess how much information has been removed\nthrough the unlearning operation. Firstly, TAPE mimics the unlearned posterior\ndifferences by quickly building unlearned shadow models based on first-order\ninfluence estimation. Secondly, we train a Reconstructor model to extract and\nevaluate the private information of the unlearned posterior differences to\naudit unlearning. Existing privacy reconstructing methods based on posterior\ndifferences are only feasible for model updates of a single sample. To enable\nthe reconstruction effective for multi-sample unlearning requests, we propose\ntwo strategies, unlearned data perturbation and unlearned influence-based\ndivision, to augment the posterior difference. Extensive experimental results\nindicate the significant superiority of TAPE over the state-of-the-art\nunlearning verification methods, at least 4.5$\\times$ efficiency speedup and\nsupporting the auditing for broader unlearning scenarios."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07306",
    "c_title":[
      "Variable Bregman Majorization-Minimization Algorithm and its Application\n  to Dirichlet Maximum Likelihood Estimation"
    ],
    "c_abstract":[
      "We propose a novel Bregman descent algorithm for minimizing a convex function\nthat is expressed as the sum of a differentiable part (defined over an open\nset) and a possibly nonsmooth term. The approach, referred to as the Variable\nBregman Majorization-Minimization (VBMM) algorithm, extends the Bregman\nProximal Gradient method by allowing the Bregman function used in the\ndivergence to adaptively vary at each iteration, provided it satisfies a\nmajorizing condition on the objective function. This adaptive framework enables\nthe algorithm to approximate the objective more precisely at each iteration,\nthereby allowing for accelerated convergence compared to the traditional\nBregman Proximal Gradient descent. We establish the convergence of the VBMM\nalgorithm to a minimizer under mild assumptions on the family of metrics used.\nFurthermore, we introduce a novel application of both the Bregman Proximal\nGradient method and the VBMM algorithm to the estimation of the\nmultidimensional parameters of a Dirichlet distribution through the\nmaximization of its log-likelihood. Numerical experiments confirm that the VBMM\nalgorithm outperforms existing approaches in terms of convergence speed."
    ],
    "c_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-898",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06274",
    "b_title":[
      "HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational\n  Pharmacovigilance"
    ],
    "b_abstract":[
      "Drug-side effect research is vital for understanding adverse reactions\narising in complex multi-drug therapies. However, the scarcity of higher-order\ndatasets that capture the combinatorial effects of multiple drugs severely\nlimits progress in this field. Existing resources such as TWOSIDES primarily\nfocus on pairwise interactions. To fill this critical gap, we introduce HODDI,\nthe first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S.\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\nrecords spanning the past decade, to advance computational pharmacovigilance.\nHODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique\nside effects, specifically curated to capture multi-drug interactions and their\ncollective impact on adverse effects. Comprehensive statistical analyses\ndemonstrate HODDI's extensive coverage and robust analytical metrics, making it\na valuable resource for studying higher-order drug relationships. Evaluating\nHODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP)\ncan outperform graph models, while hypergraph models demonstrate superior\nperformance in capturing complex multi-drug interactions, further validating\nHODDI's effectiveness. Our findings highlight the inherent value of\nhigher-order information in drug-side effect prediction and position HODDI as a\nbenchmark dataset for advancing research in pharmacovigilance, drug safety, and\npersonalized medicine. The dataset and codes are available at\nhttps:\/\/github.com\/TIML-Group\/HODDI."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02610",
    "c_title":[
      "Primordial Black Hole stellar microlensing constraints: understanding\n  their dependence on the density and velocity distributions"
    ],
    "c_abstract":[
      "Microlensing surveys of stars in the Large Magellanic Cloud constrain the\nfraction of the Milky Way halo in Primordial Black Holes (PBHs) with mass\n$10^{-9} \\lesssim M\/M_{\\odot} \\lesssim 10^{4}$. Various studies have reached\ndifferent conclusions on the uncertainties in these constraints due to\nuncertainties in the Dark Matter (DM) distribution. We therefore revisit the\ndependence of the microlensing differential event rate, and hence exclusion\nlimits, on the DM density and velocity distributions. The constraints on the\nabundance of low- and high-mass PBHs depend, respectively, on the long- and\nshort-duration tails of the differential event rate distribution. Long-duration\nevents are due to PBHs moving close to the line of sight and their rate (and\nhence the constraints on low-mass PBHs) has a fairly weak ($\\sim 10\\%$)\ndependence on the DM density and velocity distributions. Short-duration events\nare due to PBHs close to the observer and their rate (and hence the constraints\non moderate- and high-mass PBHs) depends much more strongly on the DM velocity\ndistribution. An accurate calculation of the local DM velocity distribution is\ntherefore crucial for accurately calculating PBH stellar microlensing\nconstraints."
    ],
    "c_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-899",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03828",
    "b_title":[
      "Observation of $D^+\\to \\bar K_1(1270)^0\\mu^+\\nu_\\mu$ and $D^0\\to\n  K_1(1270)^-\\mu^+\\nu_\\mu$"
    ],
    "b_abstract":[
      "By analyzing 7.93 $\\rm fb^{-1}$ of $e^+e^-$ collision data collected at the\ncenter-of-mass energy of 3.773 GeV with the BESIII detector operated at the\nBEPCII collider, we report the observation of the semimuonic decays of $D^+\\to\n\\bar K_1(1270)^0\\mu^+\\nu_\\mu$ and $D^0\\to K_1(1270)^-\\mu^+\\nu_\\mu$ with\nstatistical significances of $12.5\\sigma$ and $6.0\\sigma$, respectively. Their\ndecay branching fractions are determined to be ${\\mathcal B}[D^{+}\\to\n\\bar{K}_1(1270)^0 \\mu^{+}\\nu_{\\mu}]=(2.36\\pm0.20^{+0.18}_{-0.27}\\pm\n0.48)\\times10^{-3}$ and ${\\mathcal B}[D^{0}\\to K_1(1270)^{-}\n\\mu^{+}\\nu_{\\mu}]=(0.78\\pm0.11^{+0.05}_{-0.09}\\pm 0.15)\\times10^{-3}$, where\nthe first and second uncertainties are statistical and systematic,\nrespectively, and the third originates from the input branching fraction of\n$\\bar K_{1}(1270)^0\\to K^- \\pi^+\\pi^0$ or $K_1(1270)^-\\to K^-\\pi^+\\pi^-$.\nCombining our branching fractions with the previous measurements of ${\\mathcal\nB}[D^+\\to \\bar K_1(1270)^0e^+\\nu_{e}]$ and ${\\mathcal B}[D^0\\to\nK_1(1270)^-e^+\\nu_{e}]$, we determine the branching fraction ratios to be\n${\\mathcal B}[D^+\\to \\bar K_1(1270)^0\\mu^+\\nu_{\\mu}]\/{\\mathcal B}[D^+\\to \\bar\nK_1(1270)^0e^+\\nu_{e}]=1.03 \\pm 0.14 \\substack{+0.11\\\\-0.15}$ and ${\\mathcal\nB}[D^0\\to K_1(1270)^-\\mu^+\\nu_{\\mu}]\/{\\mathcal B}[D^0\\to\nK_1(1270)^-e^+\\nu_{e}]=0.74\\pm 0.13 \\substack{+0.08\\\\-0.13}$. Using the\nbranching fractions measured in this work and the world-average lifetimes of\nthe $D^+$ and $D^0$ mesons, we determine the semimuonic partial decay width\nratio to be $\\Gamma [D^+\\to \\bar K_1(1270)^0 \\mu^+\\nu_\\mu]\/\\Gamma [D^0\\to\nK_1(1270)^- \\mu^+\\nu_\\mu]=1.22\\pm 0.10\\substack{+0.06\\\\-0.09}$, which is\nconsistent with unity as predicted by isospin conservation."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15090",
    "c_title":[
      "Analyze the Neurons, not the Embeddings: Understanding When and Where\n  LLM Representations Align with Humans"
    ],
    "c_abstract":[
      "Modern large language models (LLMs) achieve impressive performance on some\ntasks, while exhibiting distinctly non-human-like behaviors on others. This\nraises the question of how well the LLM's learned representations align with\nhuman representations. In this work, we introduce a novel approach to the study\nof representation alignment: we adopt a method from research on activation\nsteering to identify neurons responsible for specific concepts (e.g., 'cat')\nand then analyze the corresponding activation patterns. Our findings reveal\nthat LLM representations closely align with human representations inferred from\nbehavioral data. Notably, this alignment surpasses that of word embeddings,\nwhich have been center stage in prior work on human and model alignment.\nAdditionally, our approach enables a more granular view of how LLMs represent\nconcepts. Specifically, we show that LLMs organize concepts in a way that\nreflects hierarchical relationships interpretable to humans (e.g.,\n'animal'-'dog')."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-900",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04201",
    "b_title":[
      "Nonreciprocal ballistic transport in multi-layer Weyl Semimetal films\n  with surface engineering"
    ],
    "b_abstract":[
      "Weyl semimetal (WSM) thin films possess unique electronic properties that\ndiffer from bulk materials. In this article, we study the nonreciprocal\nballistic transport of the WSM thin films caused by surface modification. We\nfind that the surface states contribute predominantly to the nonreciprocity,\nwhile the bulk states provide a negative correction. Our calculation shows a\nkind of quantum size effect that the nonreciprocal signal decreases as the WSM\nfilm becomes thicker, and diverges when the Fermi energy is near the bottom of\na sub-band. On the other hand, it is found that the density of states in\nmulti-layer systems possesses some properties roughly independent of thickness.\nA single-variable theory is developed to explain it"
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03032",
    "c_title":[
      "Analyze Feature Flow to Enhance Interpretation and Steering in Language\n  Models"
    ],
    "c_abstract":[
      "We introduce a new approach to systematically map features discovered by\nsparse autoencoder across consecutive layers of large language models,\nextending earlier work that examined inter-layer feature links. By using a\ndata-free cosine similarity technique, we trace how specific features persist,\ntransform, or first appear at each stage. This method yields granular flow\ngraphs of feature evolution, enabling fine-grained interpretability and\nmechanistic insights into model computations. Crucially, we demonstrate how\nthese cross-layer feature maps facilitate direct steering of model behavior by\namplifying or suppressing chosen features, achieving targeted thematic control\nin text generation. Together, our findings highlight the utility of a causal,\ncross-layer interpretability framework that not only clarifies how features\ndevelop through forward passes but also provides new means for transparent\nmanipulation of large language models."
    ],
    "c_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-901",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12330",
    "b_title":[
      "The Gap Between Principle and Practice of Lossy Image Coding"
    ],
    "b_abstract":[
      "Lossy image coding is the art of computing that is principally bounded by the\nimage's rate-distortion function. This bound, though never accurately\ncharacterized, has been approached practically via deep learning technologies\nin recent years. Indeed, learned image coding schemes allow direct optimization\nof the joint rate-distortion cost, thereby outperforming the handcrafted image\ncoding schemes by a large margin. Still, it is observed that there is room for\nfurther improvement in the rate-distortion performance of learned image coding.\nIn this article, we identify the gap between the ideal rate-distortion function\nforecasted by Shannon's information theory and the empirical rate-distortion\nfunction achieved by the state-of-the-art learned image coding schemes,\nrevealing that the gap is incurred by five different effects: modeling effect,\napproximation effect, amortization effect, digitization effect, and asymptotic\neffect. We design simulations and experiments to quantitively evaluate the last\nthree effects, which demonstrates the high potential of future lossy image\ncoding technologies."
    ],
    "b_categories":[
      [
        "cs.IT",
        "cs.LG",
        "math.IT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03148",
    "c_title":[
      "Partial Convolution Meets Visual Attention"
    ],
    "c_abstract":[
      "Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-902",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04271",
    "b_title":[
      "On Fact and Frequency: LLM Responses to Misinformation Expressed with\n  Uncertainty"
    ],
    "b_abstract":[
      "We study LLM judgments of misinformation expressed with uncertainty. Our\nexperiments study the response of three widely used LLMs (GPT-4o, LlaMA3,\nDeepSeek-v2) to misinformation propositions that have been verified false and\nthen are transformed into uncertain statements according to an uncertainty\ntypology. Our results show that after transformation, LLMs change their\nfactchecking classification from false to not-false in 25% of the cases.\nAnalysis reveals that the change cannot be explained by predictors to which\nhumans are expected to be sensitive, i.e., modality, linguistic cues, or\nargumentation strategy. The exception is doxastic transformations, which use\nlinguistic cue phrases such as \"It is believed ...\".To gain further insight, we\nprompt the LLM to make another judgment about the transformed misinformation\nstatements that is not related to truth value. Specifically, we study LLM\nestimates of the frequency with which people make the uncertain statement. We\nfind a small but significant correlation between judgment of fact and\nestimation of frequency."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02171",
    "c_title":[
      "Enhanced Phonon-Phonon Interactions and Weakened Electron-Phonon\n  Coupling in Charge-Density-Wave Topological Semimetal EuAl4 with a Possible\n  Intermediate Electronic State"
    ],
    "c_abstract":[
      "The origin of charge density wave (CDW) is a long-term open issue.\nFurthermore, the evolution of phonon-phonon interactions (PPI) across CDW\ntransitions has rarely been investigated. Besides, whether electron-phonon\ncoupling (EPC) would be weakened or enhanced after CDW transitions is still\nunder debate. Additionally, CDW provides a fertile ground for uncovering\nintriguing intermediate electronic states. Here, we report a Raman spectroscopy\nstudy of the PPI and EPC in topological semimetal EuAl4 exhibiting a CDW phase\nbelow temperature Tc ~ 145 K. The free-charge-carrier-density (nc) and\ntemperature dependences of the Fano asymmetric factors (1\/|q|) of the two\nphonon modes A1g and B1g indicates that below Tc, the EPC becomes weakened\nprobably due to the reduction of the nc. Interestingly, in the temperature\nrange from 50 to 145 K, the steep growth of the 1\/|q| leading to the\nsignificant deviation from the linear dependence on the nc, together with the\nshoulder-like features in the temperature evolutions of the 1\/|q| and the nc\naround 50 K, implies the possible existence of an intermediate electronic state\nwith the EPC distinctly larger than the CDW ground state in EuAl4. Furthermore,\nbelow Tc, the faster decrease in the full width at half maxima of the B1g\nphonon mode representing the collective vibrations of the CDW-modulated Al1\natoms suggests that a remarkable growth of the PPI for the B1g phonon mode\nafter the CDW phase transition, which is in contrast to the weakening of the\nEPC and thus may mainly arise from the strengthening of lattice anharmonicity\nin EuAl4. Our results not only highlight the significance of the enhanced PPI\nand the weakened EPC in completely understanding the formation of the CDW phase\nbut also initiate the exploration of novel intermediate electronic states in\nEuAl4."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-903",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09695",
    "b_title":[
      "Modified large-$N$ approach to gapless spin liquids, magnetic orders,\n  and dynamics: Application to triangular lattice antiferromagnets"
    ],
    "b_abstract":[
      "Recent work has shown that the triangular lattice spin-$1\/2$ $J_1$-$J_2$\nHeisenberg and XXZ antiferromagnets may exhibit coplanar or supersolid orders\nproximate to a gapless Dirac spin liquid phase. We explore a distinct\n$SU(2N)\\!\\!\\times\\!\\!SU(M)$ fermionic parton approach, complemented by\nvariational Monte Carlo calculations for the spin-$1\/2$ model, to study the\nphase diagram of these models. We also calculate their dynamical spin response\nincluding parton interactions within a random phase approximation, and discuss\nimplications for neutron scattering on triangular lattice cobaltates\nBa$_3$CoSb$_2$O$_9$, Na$_2$BaCo(PO$_4$)$_2$, K$_2$Co(SeO$_3$)$_2$,\nRb$_2$Co(SeO$_3$)$_2$, and Yb-based magnet KYbSe$_2$."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04316",
    "c_title":[
      "Who Does the Giant Number Pile Like Best: Analyzing Fairness in Hiring\n  Contexts"
    ],
    "c_abstract":[
      "Large language models (LLMs) are increasingly being deployed in high-stakes\napplications like hiring, yet their potential for unfair decision-making and\noutcomes remains understudied, particularly in generative settings. In this\nwork, we examine the fairness of LLM-based hiring systems through two\nreal-world tasks: resume summarization and retrieval. By constructing a\nsynthetic resume dataset and curating job postings, we investigate whether\nmodel behavior differs across demographic groups and is sensitive to\ndemographic perturbations. Our findings reveal that race-based differences\nappear in approximately 10% of generated summaries, while gender-based\ndifferences occur in only 1%. In the retrieval setting, all evaluated models\ndisplay non-uniform selection patterns across demographic groups and exhibit\nhigh sensitivity to both gender and race-based perturbations. Surprisingly,\nretrieval models demonstrate comparable sensitivity to non-demographic changes,\nsuggesting that fairness issues may stem, in part, from general brittleness\nissues. Overall, our results indicate that LLM-based hiring systems, especially\nat the retrieval stage, can exhibit notable biases that lead to discriminatory\noutcomes in real-world contexts."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-904",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00843",
    "b_title":[
      "Solving an infinite number of purely exponential Diophantine equations\n  with four terms"
    ],
    "b_abstract":[
      "An important unsolved problem in Diophantine number theory is to establish a\ngeneral method to effectively find all solutions to any given $S$-unit equation\nwith at least four terms. Although there are many works contributing to this\nproblem in literature, most of which handle purely exponential Diophantine\nequations, it can be said that all of them only solve finitely many equations\nin a natural distinction. In this paper, we study infinitely many purely\nexponential Diophantine equations with four terms of consecutive bases. Our\nresult states that all solutions to the equation $n^x+(n+1)^y+(n+2)^z=(n+3)^w$\nin positive integers $n,x,y,z,w$ with $n \\equiv 3 \\pmod{4}$ are given by\n$(n,x,y,z,w)=(3,3,1,1,2), (3,3,3,3,3)$. The proof uses elementary congruence\narguments developed in the study of ternary case, Baker's method in both\nrational and $p$-adic cases, and the algorithm of Bert\\'ok and Hajdu based on a\nvariant of Skolem's conjecture on purely exponential equations."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.18386",
    "c_title":[
      "Mastering the growth of antimonene on Bi2Se3: strategies and insights"
    ],
    "c_abstract":[
      "Antimonene, the two-dimensional phase of antimony, appears in two distinct\nallotropes when epitaxially grown on Bi2Se3: the puckered asymmetric washboard\n({\\alpha}) and buckled honeycomb ({\\beta}) bilayer structures. As-deposited\nantimony films exhibit varying proportions of single {\\alpha} and {\\beta}\nstructures. We identify the conditions necessary for ordered, pure-phase growth\nof single to triple {\\beta}-antimonene bilayers. Additionally, we determine\ntheir electronic structure, work function, and characteristic core-level\nbinding energies, offering an explanation for the relatively large chemical\nshifts observed among the different phases. This study not only establishes a\nprotocol for achieving a single {\\beta} phase of antimonene but also provides\nkey signatures for distinguishing between the different allotropes using\nstandard spectroscopic and microscopic techniques."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-905",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13507",
    "b_title":[
      "Iterative Shaping of Multi-Particle Aggregates based on Action Trees and\n  VLM"
    ],
    "b_abstract":[
      "In this paper, we address the problem of manipulating multi-particle\naggregates using a bimanual robotic system. Our approach enables the autonomous\ntransport of dispersed particles through a series of shaping and pushing\nactions using robotically-controlled tools. Achieving this advanced\nmanipulation capability presents two key challenges: high-level task planning\nand trajectory execution. For task planning, we leverage Vision Language Models\n(VLMs) to enable primitive actions such as tool affordance grasping and\nnon-prehensile particle pushing. For trajectory execution, we represent the\nevolving particle aggregate's contour using truncated Fourier series, providing\nefficient parametrization of its closed shape. We adaptively compute trajectory\nwaypoints based on group cohesion and the geometric centroid of the aggregate,\naccounting for its spatial distribution and collective motion. Through\nreal-world experiments, we demonstrate the effectiveness of our methodology in\nactively shaping and manipulating multi-particle aggregates while maintaining\nhigh system cohesion."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14868",
    "c_title":[
      "Theoretical Predictions for the Inner Dark Matter Distribution in the\n  Milky Way Informed by Simulations"
    ],
    "c_abstract":[
      "We build a theoretical range for the Milky Way's (MW) inner dark matter (DM)\ndistribution informed by the FIRE-2, Auriga, VINTERGATAN-GM, and TNG50\nsimulation suites assuming the canonical cold dark matter (CDM) model. The DM\ndensity profiles in Auriga, VINTERGATAN-GM, and TNG50 can be approximately\nmodeled using the adiabatic contraction prescription of Gnedin et al. 2004,\nwhile FIRE-2 has stronger baryonic feedback, leading to a departure from the\nadiabatic contraction model. The simulated halos that are adiabatically\ncontracted are close to spherical (axis ratio $q \\in [0.75-0.9]$ at $5^\\circ$),\nwhereas halos that experience strong baryonic feedback are oblate ($q \\in\n[0.5-0.7]$). Using the adiabatic contraction and strong baryonic feedback\nmodels, along with the observed stellar distribution of the MW, the inner\nlogarithmic density slope for CDM in the MW is predicted to range from $ -0.5$\nto $-1.3$. The $J$-factor, which determines the DM-annihilation flux, averaged\nover a solid angle of $5^\\circ$ ($10^\\circ$) is predicted to span the range\n$0.8$-$30$ ($0.6$-$10$) $\\times 10^{23} \\rm{GeV}^2\/\\rm{cm}^5$. The $D$-factor,\nwhich determines the flux due to DM decay, is predicted to be in the range\n$0.6$-$2$ ($0.5-1$) $\\times10^{23} \\rm{GeV}\/\\rm{cm}^2$.\n  GitHub: The results for this work can be found at\nhttps:\/\/github.com\/abdelazizhussein\/MW-Inner-DM-Profile."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-906",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20974",
    "b_title":[
      "Improving Open-world Continual Learning under the Constraints of Scarce\n  Labeled Data"
    ],
    "b_abstract":[
      "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories\/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https:\/\/github.com\/liyj1201\/OFCL."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06586",
    "c_title":[
      "Mission Analysis for the First-Ever Saturn Trojan 2019 UO$_{14}$"
    ],
    "c_abstract":[
      "In mid-2024, asteroid 2019 UO$_{14}$ was identified as the first-ever Saturn\nTrojan through ground-based archival observations and numerical simulations.\nTrojans, including those associated with Jupiter and other planets, raise\nimportant questions about the formation processes of our solar system.\nExploring this Trojan object with spacecraft may provide direct answers and\ndefinitive evidence regarding these questions. This paper thoroughly\ninvestigates potential mission scenarios to the first Saturn Trojan, 2019\nUO$_{14}$, to determine the necessary launch window and spacecraft\nspecifications. First, by assuming a ballistic flight using chemical engines,\noptimal sequences of events, including (powered) gravity-assist maneuvers and\ndeep-space maneuvers, are identified through a meta-heuristic global trajectory\noptimization algorithm. The analysis indicates that flyby exploration is\nfeasible with a launch window around 2034 and a $\\Delta V$ ranging from 92 m\/s\nto 1041 m\/s within an 11-year mission duration, while a rendezvous can be\nachieved with a departure around 2035 and a $\\Delta V$ of 2-3 km\/s.\nSpecifically, the itinerary via Saturn requires a $\\Delta V$ of 2 km\/s and a\nflight time of 24.6 years, while the route via Jupiter results in a $\\Delta V$\nof 3 km\/s and a flight time of 13.4 years. Given that the orbital motion of\nouter solar system objects is relatively slow, low-thrust propulsion, which\ngradually accelerates the spacecraft, proves to be effective. Consequently,\nlow-thrust trajectories to 2019 UO$_{14}$ were examined. The results\ndemonstrate that a rendezvous can be accomplished with nearly the same\ndeparture epoch, time of flight, and $\\Delta V$ as in the ballistic flight,\nsuggesting that low-thrust propulsion is highly compatible with the rendezvous\nscenario, as it significantly reduces the propellant mass fraction."
    ],
    "c_categories":[
      [
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-907",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03424",
    "b_title":[
      "Rigidity of Furstenberg entropy under ucp maps"
    ],
    "b_abstract":[
      "Given a tracial von Neumann algebra $(M,\\tau)$, we prove that a state\npreserving $M$-bimodular ucp map between two stationary W$^*$-extensions of\n$(M,\\tau)$ preserves the Furstenberg entropy if and only if it induces an\nisomorphism between the Radon-Nikodym factors. With a similar proof, we extend\nthis result to quasi-factor maps between stationary spaces of locally compact\ngroups and prove an entropy separation between unique stationary and amenable\nspaces. As applications, we use these results to establish rigidity phenomena\nfor unique stationary Poisson boundaries."
    ],
    "b_categories":[
      [
        "math.DS",
        "math.GR",
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19615",
    "c_title":[
      "A Method for Evaluating the Interpretability of Machine Learning Models\n  in Predicting Bond Default Risk Based on LIME and SHAP"
    ],
    "c_abstract":[
      "Interpretability analysis methods for artificial intelligence models, such as\nLIME and SHAP, are widely used, though they primarily serve as post-model for\nanalyzing model outputs. While it is commonly believed that the transparency\nand interpretability of AI models diminish as their complexity increases,\ncurrently there is no standardized method for assessing the inherent\ninterpretability of the models themselves. This paper uses bond market default\nprediction as a case study, applying commonly used machine learning algorithms\nwithin AI models. First, the classification performance of these algorithms in\ndefault prediction is evaluated. Then, leveraging LIME and SHAP to assess the\ncontribution of sample features to prediction outcomes, the paper proposes a\nnovel method for evaluating the interpretability of the models themselves. The\nresults of this analysis are consistent with the intuitive understanding and\nlogical expectations regarding the interpretability of these models."
    ],
    "c_categories":[
      [
        "cs.LG",
        "q-fin.GN"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-908",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17337",
    "b_title":[
      "Global $C^{1,\\alpha}$ regularity for Monge-Amp\\`ere equations on planar\n  convex domains"
    ],
    "b_abstract":[
      "In this paper, we establish the global H\\\"older gradient estimate for\nsolutions to the Dirichlet problem of the Monge-Amp\\`ere equation $\\det D^2u =\nf$ on strictly convex but not uniformly convex domain $\\Omega$."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06675",
    "c_title":[
      "Fermionic fields in a four-dimensional Bonnor-Melvin-Lambda space-time"
    ],
    "c_abstract":[
      "In this paper, we investigate how the gravitational field generated by a\nfour-dimensional electrovacuum cosmological space-time influences the dynamics\nof fermionic fields governed by the Dirac equation, while also considering the\neffects of topology. We derive the radial wave equation corresponding to the\nrelativistic Dirac equation and subsequently obtain analytical solutions for\nthe energy levels and wave functions of the fermionic field within our chosen\nframework. Our analysis reveals that various parameters, including geometric\ntopology, the cosmological constant, and quantum numbers, play significant\nroles in determining the eigenvalue solution of the quantum particles.\nSpecifically, we demonstrate that the presence of the topological parameter\ndisrupts the degeneracy of the energy spectrum."
    ],
    "c_categories":[
      [
        "gr-qc",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-909",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10114",
    "b_title":[
      "Non-Gibbsian Multivariate Ewens Probability Distributions on Regular\n  Trees"
    ],
    "b_abstract":[
      "Ewens' sampling formula (ESF) provides the probability distribution governing\nthe number of distinct genetic types and their respective frequencies at a\nselectively neutral locus under the infinitely-many-alleles model of mutation.\nA natural and significant question arises: ``Is the Ewens probability\ndistribution on regular trees Gibbsian?\"\n  In this paper, we demonstrate that Ewens probability distributions can be\nregarded as non-Gibbsian distributions on regular trees and derive a sufficient\ncondition for the consistency condition. This study lays the groundwork for a\nnew direction in the theory of non-Gibbsian probability distributions on trees."
    ],
    "b_categories":[
      [
        "math.FA",
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02796",
    "c_title":[
      "Hyperbolic free-surface jets"
    ],
    "c_abstract":[
      "If a body of inviscid fluid is disturbed, it will typically eject a jet of\nfluid. If the effects of gravity and surface tension are negligible, these jets\ntravel in straight lines, with the tips approaching a constant velocity. It has\nbeen observed that these jets can have a broad base, tapering progressively\ntoward the tip, but the mathematical form of their profile has not been\nsuccessfully analysed in earlier works. In this paper, we describe the simplest\ncase, in two dimensions: an infinitely deep body of inviscid fluid, with no\nsurface tension or gravitational forces acting, responds to an impulsive\ndisturbance. We find that, contrary to some earlier suggestions, the jet has a\nhyperbolic profile (away from its tip and its base)."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-910",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10794",
    "b_title":[
      "Distraction is All You Need for Multimodal Large Language Model\n  Jailbreaking"
    ],
    "b_abstract":[
      "Multimodal Large Language Models (MLLMs) bridge the gap between visual and\ntextual data, enabling a range of advanced applications. However, complex\ninternal interactions among visual elements and their alignment with text can\nintroduce vulnerabilities, which may be exploited to bypass safety mechanisms.\nTo address this, we analyze the relationship between image content and task and\nfind that the complexity of subimages, rather than their content, is key.\nBuilding on this insight, we propose the Distraction Hypothesis, followed by a\nnovel framework called Contrasting Subimage Distraction Jailbreaking (CS-DJ),\nto achieve jailbreaking by disrupting MLLMs alignment through multi-level\ndistraction strategies. CS-DJ consists of two components: structured\ndistraction, achieved through query decomposition that induces a distributional\nshift by fragmenting harmful prompts into sub-queries, and visual-enhanced\ndistraction, realized by constructing contrasting subimages to disrupt the\ninteractions among visual elements within the model. This dual strategy\ndisperses the model's attention, reducing its ability to detect and mitigate\nharmful content. Extensive experiments across five representative scenarios and\nfour popular closed-source MLLMs, including GPT-4o-mini, GPT-4o, GPT-4V, and\nGemini-1.5-Flash, demonstrate that CS-DJ achieves average success rates of\n52.40% for the attack success rate and 74.10% for the ensemble attack success\nrate. These results reveal the potential of distraction-based approaches to\nexploit and bypass MLLMs' defenses, offering new insights for attack\nstrategies."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09722",
    "c_title":[
      "The Bullseye: HST, Keck\/KCWI, and Dragonfly Characterization of a Giant\n  Nine-Ringed Galaxy"
    ],
    "c_abstract":[
      "We report the discovery and multiwavelength followup of LEDA 1313424\n(\"Bullseye\"), a collisional ring galaxy (CRG) with nine readily-identified\nrings -- the most so far reported for a CRG. These data shed new light on the\nrapid, multi-ring phase of CRG evolution. Using Hubble Space Telescope (HST)\nimaging, we identify and measure nine ring structures, several of which are\n\"piled up\" near the center of the galaxy, while others extend to tens of kpc\nscales. We also identify faint patches of emission at large radii ($\\sim$70\nkpc) in the HST imaging, and confirm the association of this emission with the\ngalaxy via spectroscopy. Deep ground based imaging using the Dragonfly\nTelephoto Array finds evidence that this patch of emission is part of an older,\nfading ring from the collision. We find that the locations of the detected\nrings are an excellent match to predictions from analytic theory, if the galaxy\nwas a 10-ring system whose outermost ring has faded away. We identify the\nlikely impacting galaxy via Keck\/KCWI spectroscopy, finding evidence for gas\nextending between it and the Bullseye. The overall size of this galaxy rivals\nthat of known Giant Low Surface Brightness Galaxies (GLSBs) such as Malin I,\nlending credence to the hypothesis that CRGs can evolve into GLSBs as their\nrings expand and fade. Analysis of the HI content in this galaxy from ALFALFA\nfinds significantly elevated neutral hydrogen with respect to the galaxy's\nstellar mass, another feature in alignment with GLSB systems."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-911",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18771",
    "b_title":[
      "Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data\n  Contamination's Impact on Machine Translation"
    ],
    "b_abstract":[
      "Data contamination -- the accidental consumption of evaluation examples\nwithin the pre-training data -- can undermine the validity of evaluation\nbenchmarks. In this paper, we present a rigorous analysis of the effects of\ncontamination on language models at 1B and 8B scales on the machine translation\ntask. Starting from a carefully decontaminated train-test split, we\nsystematically introduce contamination at various stages, scales, and data\nformats to isolate its effect and measure its impact on performance metrics.\nOur experiments reveal that contamination with both source and target\nsubstantially inflates BLEU scores, and this inflation is 2.5 times larger (up\nto 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and\ntarget-only contamination generally produce smaller, less consistent\nover-estimations. Finally, we study how the temporal distribution and frequency\nof contaminated samples influence performance over-estimation across languages\nwith varying degrees of data resources."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14889",
    "c_title":[
      "Long-time asymptotics of 3-solitary waves for the damped nonlinear\n  Klein-Gordon equation"
    ],
    "c_abstract":[
      "We consider the damped nonlinear Klein-Gordon equation: \\begin{align*}\n\\partial_{t}^2u-\\Delta u+2\\alpha \\partial_{t}u+u-|u|^{p-1}u=0, \\ & (t,x) \\in\n\\mathbb{R} \\times \\mathbb{R}^d, \\end{align*} where $\\alpha>0$, $1\\leq d\\leq 5$\nand energy sub-critical exponents $p>2$. In this paper, we prove that\n3-solitary waves behave as if the three solitons are on a line. Furthermore,\nthe solitary waves have alternative signs and their distances are of order\n$\\log{t}$."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-912",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09744",
    "b_title":[
      "KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity\n  Recognition and Normalization for Dysmorphology Physical Examination Reports"
    ],
    "b_abstract":[
      "The objective of BioCreative8 Track 3 is to extract phenotypic key medical\nfindings embedded within EHR texts and subsequently normalize these findings to\ntheir Human Phenotype Ontology (HPO) terms. However, the presence of diverse\nsurface forms in phenotypic findings makes it challenging to accurately\nnormalize them to the correct HPO terms. To address this challenge, we explored\nvarious models for named entity recognition and implemented data augmentation\ntechniques such as synonym marginalization to enhance the normalization step.\nOur pipeline resulted in an exact extraction and normalization F1 score 2.6\\%\nhigher than the mean score of all submissions received in response to the\nchallenge. Furthermore, in terms of the normalization F1 score, our approach\nsurpassed the average performance by 1.9\\%. These findings contribute to the\nadvancement of automated medical data extraction and normalization techniques,\nshowcasing potential pathways for future research and application in the\nbiomedical domain."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08265",
    "c_title":[
      "Fast and Cheap Covariance Smoothing"
    ],
    "c_abstract":[
      "We introduce the Tensorized-and-Restricted Krylov (TReK) method, a simple and\nefficient algorithm for estimating covariance tensors with large observational\nsizes. TReK extends the conjugate gradient method to incorporate range\nrestrictions, enabling its use in a variety of covariance smoothing\napplications. By leveraging matrix-level operations, it achieves significant\nimprovements in both computational speed and memory cost, improving over\nexisting methods by an order of magnitude. TReK ensures finite-step convergence\nin the absence of rounding errors and converges fast in practice, making it\nwell-suited for large-scale problems. The algorithm is also highly flexible,\nsupporting a wide range of forward and projection tensors."
    ],
    "c_categories":[
      [
        "stat.AP",
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-913",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19250",
    "b_title":[
      "ObjectVLA: End-to-End Open-World Object Manipulation Without\n  Demonstration"
    ],
    "b_abstract":[
      "Imitation learning has proven to be highly effective in teaching robots\ndexterous manipulation skills. However, it typically relies on large amounts of\nhuman demonstration data, which limits its scalability and applicability in\ndynamic, real-world environments. One key challenge in this context is object\ngeneralization, where a robot trained to perform a task with one object, such\nas \"hand over the apple,\" struggles to transfer its skills to a semantically\nsimilar but visually different object, such as \"hand over the peach.\" This gap\nin generalization to new objects beyond those in the same category has yet to\nbe adequately addressed in previous work on end-to-end visuomotor policy\nlearning. In this paper, we present a simple yet effective approach for\nachieving object generalization through Vision-Language-Action (VLA) models,\nreferred to as \\textbf{ObjectVLA}. Our model enables robots to generalize\nlearned skills to novel objects without requiring explicit human demonstrations\nfor each new target object. By leveraging vision-language pair data, our method\nprovides a lightweight and scalable way to inject knowledge about the target\nobject, establishing an implicit link between the object and the desired\naction. We evaluate ObjectVLA on a real robotic platform, demonstrating its\nability to generalize across 100 novel objects with a 64\\% success rate in\nselecting objects not seen during training. Furthermore, we propose a more\naccessible method for enhancing object generalization in VLA models, using a\nsmartphone to capture a few images and fine-tune the pre-trained model. These\nresults highlight the effectiveness of our approach in enabling object-level\ngeneralization and reducing the need for extensive human demonstrations, paving\nthe way for more flexible and scalable robotic learning systems."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07993",
    "c_title":[
      "What is a Sketch-and-Precondition Derivation for Low-Rank Approximation?\n  Inverse Power Error or Inverse Power Estimation?"
    ],
    "c_abstract":[
      "Randomized sketching accelerates large-scale numerical linear algebra by\nreducing computational complexity. While the traditional sketch-and-solve\napproach reduces the problem size directly through sketching, the\nsketch-and-precondition method leverages sketching to construct a computational\nfriendly preconditioner. This preconditioner improves the convergence speed of\niterative solvers applied to the original problem, maintaining accuracy in the\nfull space. Furthermore, the convergence rate of the solver improves at least\nlinearly with the sketch size. Despite its potential, developing a\nsketch-and-precondition framework for randomized algorithms in low-rank matrix\napproximation remains an open challenge. We introduce the Error-Powered\nSketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for\nthe Lagrange form as a sketch-and-precondition variant for randomized low-rank\napproximation. Our method achieves theoretical guarantees, including a\nconvergence rate that improves at least linearly with the sketch size."
    ],
    "c_categories":[
      [
        "cs.CC",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "stat.CO",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-914",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14015",
    "b_title":[
      "Bayesian Optimization with Lower Confidence Bounds for Minimization\n  Problems with Known Outer Structure"
    ],
    "b_abstract":[
      "This paper considers Bayesian optimization (BO) for problems with known outer\nproblem structure. In contrast to the classic BO setting, where the objective\nfunction itself is unknown and needs to be iteratively estimated from noisy\nobservations, we analyze the case where the objective has a known outer\nstructure - given in terms of a loss function - while the inner structure - an\nunknown input-output model - is again iteratively estimated from noisy\nobservations of the model outputs. We introduce a novel lower confidence bound\nalgorithm for this particular problem class which exploits the known outer\nproblem structure. The proposed method is analyzed in terms of regret for the\nspecial case of convex loss functions and probabilistic parametric models which\nare linear in the uncertain parameters. Numerical examples illustrate the\nsuperior performance of structure-exploiting methods compared to\nstructure-agnostic approaches."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.13716",
    "c_title":[
      "16 Ways to Gallop: Energetics and Body Dynamics of High-Speed\n  Quadrupedal Gaits"
    ],
    "c_abstract":[
      "Galloping is a common high-speed gait in both animals and quadrupedal robots,\nyet its energetic characteristics remain insufficiently explored. This study\nsystematically analyzes a large number of possible galloping gaits by\ncategorizing them based on the number of flight phases per stride and the phase\nrelationships between the front and rear legs, following Hildebrand's framework\nfor asymmetrical gaits. Using the A1 quadrupedal robot from Unitree, we model\ngalloping dynamics as a hybrid dynamical system and employ trajectory\noptimization (TO) to minimize the cost of transport (CoT) across a range of\nspeeds. Our results reveal that rotary and transverse gallop footfall sequences\nexhibit no fundamental energetic difference, despite variations in body yaw and\nroll motion. However, the number of flight phases significantly impacts energy\nefficiency: galloping with no flight phases is optimal at lower speeds, whereas\ngalloping with two flight phases minimizes energy consumption at higher speeds.\nWe validate these findings using a quadratic programming (QP)-based controller,\ndeveloped in our previous work, in Gazebo simulations. These insights advance\nthe understanding of quadrupedal locomotion energetics and may inform future\nlegged robot designs for adaptive, energy-efficient gait transitions."
    ],
    "c_categories":[
      [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-915",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09839",
    "b_title":[
      "Coarse tree-width"
    ],
    "b_abstract":[
      "We prove two theorems about tree-decompositions in the setting of coarse\ngraph theory. First, we show that a graph $G$ admits a tree-decomposition in\nwhich each bag is contained in the union of a bounded number of balls of\nbounded radius, if and only if $G$ admits a quasi-isometry to a graph with\nbounded tree-width. (The ``if'' half is easy, but the ``only if'' half is\nchallenging.) This generalizes a recent result of Berger and Seymour,\nconcerning tree-decompositions when each bag has bounded radius.\n  Second, we show that if $G$ admits a quasi-isometry $\\phi$ to a graph $H$ of\nbounded path-width, then $G$ admits a quasi-isometry (with error only an\nadditive constant) to a graph of bounded path-width. Indeed, we will show a\nmuch stronger statement: that we can assign a non-negative integer length to\neach edge of $H$, such that the same function $\\phi$ is a quasi-isometry (with\nerror only an additive constant) to this weighted version of $H$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.07294",
    "c_title":[
      "Distilling Knowledge into Quantum Vision Transformers for Biomedical\n  Image Classification"
    ],
    "c_abstract":[
      "Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-916",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15247",
    "b_title":[
      "Anisotropic Exchange Spin Model to Investigate the Curie Temperature\n  Dispersion of Finite-Size L10-FePt Magnetic Nanoparticles"
    ],
    "b_abstract":[
      "We developed an anisotropic spin model that accounts for magnetic anisotropy\nand evaluated the Curie temperature (Tc) dispersion due to finite size effects\nin L10-FePt nanoparticles. In heat-assisted magnetic recording (HAMR) media, a\nnext-generation magnetic recording technology, high-density recording is\nachieved by locally heating L10-FePt nanoparticles near their Tc and rapidly\ncooling them. However, variations in Tc caused by differences in particle size\nand shape can compromise recording stability and areal density capacity, making\nthe control of Tc dispersion critical. In this study, we constructed atomistic\nLLG models to explicitly incorporate the spin exchange anisotropy of L10-FePt,\nbased on parameters determined by first-principles calculations. Using this\nmodel, we evaluated the impact of particle size on Tc dispersion. As a result,\n(1) the Tc dispersion critical to the performance of HAMR can be reproduced,\nwhereas it was previously underestimated by isotropic models and (2)\napproximately 70% of the experimentally observed Tc dispersion can be\nattributed to particle size effects. This research highlights the role of\nexchange anisotropy in amplifying finite-size effects and underscores the\nimportance of size control in HAMR media."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.19086",
    "c_title":[
      "Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image\n  Classification"
    ],
    "c_abstract":[
      "X-ray imaging is pivotal in medical diagnostics, offering non-invasive\ninsights into a range of health conditions. Recently, vision-language models,\nsuch as the Contrastive Language-Image Pretraining (CLIP) model, have\ndemonstrated potential in improving diagnostic accuracy by leveraging\nlarge-scale image-text datasets. However, since CLIP was not initially designed\nfor medical images, several CLIP-like models trained specifically on medical\nimages have been developed. Despite their enhanced performance, issues of\nfairness - particularly regarding demographic attributes - remain largely\nunaddressed. In this study, we perform a comprehensive fairness analysis of\nCLIP-like models applied to X-ray image classification. We assess their\nperformance and fairness across diverse patient demographics and disease\ncategories using zero-shot inference and various fine-tuning techniques,\nincluding Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation\n(LoRA), and full fine-tuning. Our results indicate that while fine-tuning\nimproves model accuracy, fairness concerns persist, highlighting the need for\nfurther fairness interventions in these foundational models."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-917",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15642",
    "b_title":[
      "Training Neural ODEs Using Fully Discretized Simultaneous Optimization"
    ],
    "b_abstract":[
      "Neural Ordinary Differential Equations (Neural ODEs) represent\ncontinuous-time dynamics with neural networks, offering advancements for\nmodeling and control tasks. However, training Neural ODEs requires solving\ndifferential equations at each epoch, leading to high computational costs. This\nwork investigates simultaneous optimization methods as a faster training\nalternative. In particular, we employ a collocation-based, fully discretized\nformulation and use IPOPT--a solver for large-scale nonlinear optimization--to\nsimultaneously optimize collocation coefficients and neural network parameters.\nUsing the Van der Pol Oscillator as a case study, we demonstrate faster\nconvergence compared to traditional training methods. Furthermore, we introduce\na decomposition framework utilizing Alternating Direction Method of Multipliers\n(ADMM) to effectively coordinate sub-models among data batches. Our results\nshow significant potential for (collocation-based) simultaneous Neural ODE\ntraining pipelines."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01457",
    "c_title":[
      "Structural Deep Encoding for Table Question Answering"
    ],
    "c_abstract":[
      "Although Transformers-based architectures excel at processing textual\ninformation, their naive adaptation for tabular data often involves flattening\nthe table structure. This simplification can lead to the loss of essential\ninter-dependencies between rows, columns, and cells, while also posing\nscalability challenges for large tables. To address these issues, prior works\nhave explored special tokens, structured embeddings, and sparse attention\npatterns. In this paper, we conduct a comprehensive analysis of tabular\nencoding techniques, which highlights the crucial role of attention sparsity in\npreserving structural information of tables. We also introduce a set of novel\nsparse attention mask designs for tabular data, that not only enhance\ncomputational efficiency but also preserve structural integrity, leading to\nbetter overall performance."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-918",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16708",
    "b_title":[
      "BASS XLV: Quantifying AGN Selection Effects in the Chandra COSMOS-Legacy\n  Survey with BASS"
    ],
    "b_abstract":[
      "Deep extragalactic X-ray surveys, such as the Chandra COSMOS-Legacy field\n(CCLS), are prone to be biased against active galactic nuclei (AGN) with high\ncolumn densities due to their lower count rates at a given luminosity. To\nquantify this selection effect, we forward model nearby ($z\\sim0.05$) AGN from\nthe BAT AGN Spectroscopic Survey (BASS) with well-characterized ($\\gtrsim$1000\ncts) broadband X-ray spectra (0.5-195 keV) to simulate the CCLS absorption\ndistribution. We utilize the BASS low-redshift analogs with similar\nluminosities to the CCLS ($L_\\mathrm{2-10\\ keV}^\\mathrm{int}\\sim10^{42-45}\\\n\\mathrm{erg}\\ \\mathrm{s}^{-1}$), which are much less affected by obscuration\nand low-count statistics, as the seed for our simulations, and follow the\nspectral fitting of the CCLS. Our simulations reveal that Chandra would fail to\ndetect the majority (53.3%; 563\/1056) of obscured ($N_\\mathrm{H}>10^{22}\\\n\\mathrm{cm}^{-2}$) simulated BASS AGN given the observed redshift and\nluminosity distribution of the CCLS. Even for detected sources with sufficient\ncounts ($\\geq30$) for spectral modeling, the level of obscuration is\nsignificantly overestimated. This bias is most extreme for objects whose best\nfit indicates a high-column density AGN ($N_\\mathrm{H}\\geq10^{24}\\\n\\mathrm{cm}^{-2}$), since the majority (66.7%; 18\/27) of these are actually\nunobscured sources ($N_\\mathrm{H}<10^{22}\\ \\mathrm{cm}^{-2}$). This implies\nthat previous studies may have significantly overestimated the increase in the\nobscured fraction with redshift and the fraction of luminous obscured AGN. Our\nfindings highlight the importance of directly considering obscuration biases\nand forward modeling in X-ray surveys, as well as the need for\nhigher-sensitivity X-ray missions such as the Advanced X-ray Imaging Satellite\n(AXIS), and the importance of multi-wavelength indicators to estimate\nobscuration in distant supermassive black holes."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08653",
    "c_title":[
      "Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor\n  Graph"
    ],
    "c_abstract":[
      "Event prediction tasks often handle spatio-temporal data distributed in a\nlarge spatial area. Different regions in the area exhibit different\ncharacteristics while having latent correlations. This spatial heterogeneity\nand correlations greatly affect the spatio-temporal distributions of event\noccurrences, which has not been addressed by state-of-the-art models. Learning\nspatial dependencies of events in a continuous space is challenging due to its\nfine granularity and a lack of prior knowledge. In this work, we propose a\nnovel Graph Spatio-Temporal Point Process (GSTPP) model for fine-grained event\nprediction. It adopts an encoder-decoder architecture that jointly models the\nstate dynamics of spatially localized regions using neural Ordinary\nDifferential Equations (ODEs). The state evolution is built on the foundation\nof a novel Self-Adaptive Anchor Graph (SAAG) that captures spatial\ndependencies. By adaptively localizing the anchor nodes in the space and\njointly constructing the correlation edges between them, the SAAG enhances the\nmodel's ability of learning complex spatial event patterns. The proposed GSTPP\nmodel greatly improves the accuracy of fine-grained event prediction. Extensive\nexperimental results show that our method greatly improves the prediction\naccuracy over existing spatio-temporal event prediction approaches."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-919",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13120",
    "b_title":[
      "Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language\n  in a Coreference Context"
    ],
    "b_abstract":[
      "Gender-inclusive language is often used with the aim of ensuring that all\nindividuals, regardless of gender, can be associated with certain concepts.\nWhile psycholinguistic studies have examined its effects in relation to human\ncognition, it remains unclear how Large Language Models (LLMs) process\ngender-inclusive language. Given that commercial LLMs are gaining an\nincreasingly strong foothold in everyday applications, it is crucial to examine\nwhether LLMs in fact interpret gender-inclusive language neutrally, because the\nlanguage they generate has the potential to influence the language of their\nusers. This study examines whether LLM-generated coreferent terms align with a\ngiven gender expression or reflect model biases. Adapting psycholinguistic\nmethods from French to English and German, we find that in English, LLMs\ngenerally maintain the antecedent's gender but exhibit underlying masculine\nbias. In German, this bias is much stronger, overriding all tested\ngender-neutralization strategies."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18631",
    "c_title":[
      "Report on Reproducibility in Condensed Matter Physics"
    ],
    "c_abstract":[
      "We present recommendations for how to improve reproducibility in the field of\ncondensed matter physics. This area of physics has consistently produced both\nfundamental insights into the functioning of matter as well as transformative\ninventions. Our recommendations result from a collaboration that includes\nresearchers in academia and government laboratories, scientific journalists,\nlegal professionals, representatives of publishers, professional societies, and\nother experts. The group met in person in May 2024 at a conference at the\nUniversity of Pittsburgh to discuss the growing challenges related to research\nreproducibility in condensed matter physics. We discuss best practices and\npolicies at all stages of the scientific process to safeguard the value\ncondensed matter research brings to society. We look forward to comments and\nsuggestions, especially regarding subfield-specific recommendations, and will\nincorporate them into the next version of the report."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.other",
        "cond-mat.str-el",
        "cond-mat.supr-con",
        "physics.soc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-920",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11330",
    "b_title":[
      "Learning to reset in target search problems"
    ],
    "b_abstract":[
      "Target search problems are central to a wide range of fields, from biological\nforaging to the optimization algorithms. Recently, the ability to reset the\nsearch has been shown to significantly improve the searcher's efficiency.\nHowever, the optimal resetting strategy depends on the specific properties of\nthe search problem and can often be challenging to determine. In this work, we\npropose a reinforcement learning (RL)-based framework to train agents capable\nof optimizing their search efficiency in environments by learning how to reset.\nFirst, we validate the approach in a well-established benchmark: the Brownian\nsearch with resetting. There, RL agents consistently recover strategies closely\nresembling the sharp resetting distribution, known to be optimal in this\nscenario. We then extend the framework by allowing agents to control not only\nwhen to reset, but also their spatial dynamics through turning actions. In this\nmore complex setting, the agents discover strategies that adapt both resetting\nand turning to the properties of the environment, outperforming the proposed\nbenchmarks. These results demonstrate how reinforcement learning can serve both\nas an optimization tool and a mechanism for uncovering new, interpretable\nstrategies in stochastic search processes with resetting."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03717",
    "c_title":[
      "Materialist: Physically Based Editing Using Single-Image Inverse\n  Rendering"
    ],
    "c_abstract":[
      "To perform image editing based on single-view, inverse physically based\nrendering, we present a method combining a learning-based approach with\nprogressive differentiable rendering. Given an image, our method leverages\nneural networks to predict initial material properties. Progressive\ndifferentiable rendering is then used to optimize the environment map and\nrefine the material properties with the goal of closely matching the rendered\nresult to the input image. We require only a single image while other inverse\nrendering methods based on the rendering equation require multiple views. In\ncomparison to single-view methods that rely on neural renderers, our approach\nachieves more realistic light material interactions, accurate shadows, and\nglobal illumination. Furthermore, with optimized material properties and\nillumination, our method enables a variety of tasks, including physically based\nmaterial editing, object insertion, and relighting. We also propose a method\nfor material transparency editing that operates effectively without requiring\nfull scene geometry. Compared with methods based on Stable Diffusion, our\napproach offers stronger interpretability and more realistic light refraction\nbased on empirical results."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-921",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12930",
    "b_title":[
      "Planarity ranks of modular varieties of semigroups"
    ],
    "b_abstract":[
      "By the planarity rank of a semigroup variety we mean the largest number of\ngenerators of a free semigroup of a variety with respect to which the semigroup\nadmits a planar Cayley graph. Since the time when L.M.Martynov formulated the\nproblem of describing the planarity ranks of semigroup varieties, many specific\nresults have been obtained in this direction. A modular variety of semigroups\nis a variety of semigroups with a modular lattice of subvarieties. In this\npaper, we calculate the exact values of the planarity ranks of an infinite\ncountable set of all possible modular varieties of semigroups. It turns out\nthat these values do not exceed 3. Machine calculations are mostly used in the\nproof. Prover9 and Mace4 are used to check the equalities of elements of free\nsemigroups of varieties defined by a large number of identities. To prove the\nnon-planarity of graphs, the Pontryagin-Kuratovsky criterion is used, and the\nColin de Verdiere invariant is indirectly used to justify planarity."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18962",
    "c_title":[
      "Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data\n  Boostrapping"
    ],
    "c_abstract":[
      "Modern foundation models often undergo iterative ``bootstrapping'' in their\npost-training phase: a model generates synthetic data, an external verifier\nfilters out low-quality samples, and the high-quality subset is used for\nfurther fine-tuning. Over multiple iterations, the model's performance\nimproves--raising a crucial question: how should the total budget on generation\nand training be allocated across iterations to maximize final performance? In\nthis work, we develop a theoretical framework to analyze budget allocation\nstrategies. Specifically, we show that constant policies fail to converge with\nhigh probability, while increasing policies--particularly exponential growth\npolicies--exhibit significant theoretical advantages. Experiments on image\ndenoising with diffusion probabilistic models and math reasoning with large\nlanguage models show that both exponential and polynomial growth policies\nconsistently outperform constant policies, with exponential policies often\nproviding more stable performance."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-922",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18836",
    "b_title":[
      "Transfer Learning for Nonparametric Contextual Dynamic Pricing"
    ],
    "b_abstract":[
      "Dynamic pricing strategies are crucial for firms to maximize revenue by\nadjusting prices based on market conditions and customer characteristics.\nHowever, designing optimal pricing strategies becomes challenging when\nhistorical data are limited, as is often the case when launching new products\nor entering new markets. One promising approach to overcome this limitation is\nto leverage information from related products or markets to inform the focal\npricing decisions. In this paper, we explore transfer learning for\nnonparametric contextual dynamic pricing under a covariate shift model, where\nthe marginal distributions of covariates differ between source and target\ndomains while the reward functions remain the same. We propose a novel Transfer\nLearning for Dynamic Pricing (TLDP) algorithm that can effectively leverage\npre-collected data from a source domain to enhance pricing decisions in the\ntarget domain. The regret upper bound of TLDP is established under a simple\nLipschitz condition on the reward function. To establish the optimality of\nTLDP, we further derive a matching minimax lower bound, which includes the\ntarget-only scenario as a special case and is presented for the first time in\nthe literature. Extensive numerical experiments validate our approach,\ndemonstrating its superiority over existing methods and highlighting its\npractical utility in real-world applications."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04373",
    "c_title":[
      "FGU3R: Fine-Grained Fusion via Unified 3D Representation for Multimodal\n  3D Object Detection"
    ],
    "c_abstract":[
      "Multimodal 3D object detection has garnered considerable interest in\nautonomous driving. However, multimodal detectors suffer from dimension\nmismatches that derive from fusing 3D points with 2D pixels coarsely, which\nleads to sub-optimal fusion performance. In this paper, we propose a multimodal\nframework FGU3R to tackle the issue mentioned above via unified 3D\nrepresentation and fine-grained fusion, which consists of two important\ncomponents. First, we propose an efficient feature extractor for raw and pseudo\npoints, termed Pseudo-Raw Convolution (PRConv), which modulates multimodal\nfeatures synchronously and aggregates the features from different types of\npoints on key points based on multimodal interaction. Second, a Cross-Attention\nAdaptive Fusion (CAAF) is designed to fuse homogeneous 3D RoI (Region of\nInterest) features adaptively via a cross-attention variant in a fine-grained\nmanner. Together they make fine-grained fusion on unified 3D representation.\nThe experiments conducted on the KITTI and nuScenes show the effectiveness of\nour proposed method."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-923",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17705",
    "b_title":[
      "A Bayesian Integrative Mixed Modeling Framework for Analysis of the\n  Adolescent Brain and Cognitive Development Study"
    ],
    "b_abstract":[
      "Integrating high-dimensional, heterogeneous data from multi-site cohort\nstudies with complex hierarchical structures poses significant feature\nselection and prediction challenges. We extend the Bayesian Integrative\nAnalysis and Prediction (BIP) framework to enable simultaneous feature\nselection and outcome modeling in data of nested hierarchical structure. We\napply the proposed Bayesian Integrative Mixed Modeling (BIPmixed) framework to\nthe Adolescent Brain Cognitive Development (ABCD) Study, leveraging multi-view\ndata, including structural and functional MRI and early life adversity (ELA)\nmetrics, to identify relevant features and predict the behavioral outcome.\nBIPmixed incorporates 2-level nested random effects, to enhance\ninterpretability and make predictions in hierarchical data settings. Simulation\nstudies illustrate BIPmixed's robustness in distinct random effect settings,\nhighlighting its use for complex study designs. Our findings suggest that\nBIPmixed effectively integrates multi-view data while accounting for nested\nsampling, making it a valuable tool for analyzing large-scale studies with\nhierarchical data."
    ],
    "b_categories":[
      [
        "stat.AP",
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15339",
    "c_title":[
      "DER Hosting capacity for distribution networks: definitions, attributes,\n  use-cases and challenges"
    ],
    "c_abstract":[
      "The rapid adoption of distributed energy resources (DERs) has outpaced grid\nmodernization, leading to capacity limitations that challenge their further\nintegration. Hosting Capacity Assessment (HCA) is a critical tool for\nevaluating how much DER capacity a grid can handle without breaching\noperational limits. HCA serves multiple goals: enabling higher DER penetration,\naccelerating grid connection times, guiding infrastructure upgrades or flexible\nresource deployment, ensuring equitable policies, and improving grid\nflexibility while minimizing curtailment. HCA lacks a universal definition,\nvarying by modelling approaches, uncertainty considerations, and objectives.\nThis paper addresses five key questions to standardize and enhance HCA\npractices. First, it classifies HCA objectives associated with different\nstakeholders such as system operators, consumers, market operators and\nconsumers. Second, it examines model attributes, including modelling\nsophistication, data requirements, and uncertainty handling, thus balancing\ncomplexity with computational efficiency. Third, it explores HCA applications,\nsuch as planning grid investments or operational decisions, and summarizes use\ncases associated with HCA. Fourth, it emphasizes the need for periodic updates\nto reflect dynamic grid conditions, evolving technologies, and new DER\ninstallations. Finally, it identifies challenges, such as ensuring data\nquality, managing computational demands, and aligning short-term and long-term\ngoals. By addressing these aspects, this paper provides a structured approach\nto perform and apply HCA, offering insights for engineers, planners, and\npolicymakers to manage DER integration effectively."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-924",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17463",
    "b_title":[
      "Model reduction of convection-dominated viscous conservation laws using\n  implicit feature tracking and landmark image registration"
    ],
    "b_abstract":[
      "Reduced-order models (ROMs) remain generally unreliable for\nconvection-dominated problems, such as those encountered in hypersonic flows,\ndue to the slowly decaying Kolmogorov $n$-width of linear subspace\napproximations, known as the Kolmogorov barrier. This limitation hinders the\naccuracy of traditional ROMs and necessitates impractical amounts of training\ndata during the offline phase. To address this challenge, we introduce a novel\nlandmark-based registration procedure tailored for ROMs of convection-dominated\nproblems. Our approach leverages limited training data and incorporates a\nnonlinear transformation of the data using a landmark-based registration\ntechnique combined with radial basis function (RBF) interpolation. During the\noffline phase, we align dominant convective features in a reference domain,\nresulting in a rapid decay of error relative to the reduced space dimension.\nLandmarks are generated through a three-step process: (1) detecting shocks via\nedge detection techniques, (2) sampling using Monte Carlo methods, and (3)\ndomain partitioning with $k$-means clustering, where cluster centroids serve as\nlandmarks. Accurate landmark correspondence is achieved by minimizing pairing\ndistances for similar features. The online phase integrates standard\nminimum-residual ROM methodologies, extending the optimization space to include\nadmissible domain mappings. We validate our approach on two test cases: a\nspace-time Burgers' equation parameterized by the initial condition, and a\nhypersonic viscous flow over a cylinder parameterized by the Mach number.\nResults demonstrate the efficacy of the proposed method in overcoming the\nKolmogorov barrier and enhancing the reliability of ROMs for\nconvection-dominated problems."
    ],
    "b_categories":[
      [
        "cs.NA",
        "math.NA",
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18588",
    "c_title":[
      "Inkspire: Supporting Design Exploration with Generative AI through\n  Analogical Sketching"
    ],
    "c_abstract":[
      "With recent advancements in the capabilities of Text-to-Image (T2I) AI\nmodels, product designers have begun experimenting with them in their work.\nHowever, T2I models struggle to interpret abstract language and the current\nuser experience of T2I tools can induce design fixation rather than a more\niterative, exploratory process. To address these challenges, we developed\nInkspire, a sketch-driven tool that supports designers in prototyping product\ndesign concepts with analogical inspirations and a complete\nsketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we\nconducted an exchange session with designers and distilled design goals for\nimproving T2I interactions. In a within-subjects study comparing Inkspire to\nControlNet, we found that Inkspire supported designers with more inspiration\nand exploration of design ideas, and improved aspects of the co-creative\nprocess by allowing designers to effectively grasp the current state of the AI\nto guide it towards novel design intentions."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-925",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11100",
    "b_title":[
      "The Role of Hydrogen and Oxygen Interstitial Defects in Crystalline Si\n  cells: Mechanism of Device Degradation in Humid Environment"
    ],
    "b_abstract":[
      "The efficiency of silicon solar cells gradually decreases in various\nenvironments, with humidity being a key factor contributing to this decline.\nThis study investigates the humidity-induced failure mechanisms in crystalline\nsilicon solar cells. Using density functional theory and the non-equilibrium\nGreen's function method, we systematically examine the microscopic diffusion\nmechanisms of hydrogen and oxygen defects and their impact on photovoltaic\nperformance. Hydrogen and oxygen are interstitial defects that can introduce\nboth deep-level and resonant-state recombination centers, thereby reducing\ncarrier lifetime and solar cell efficiency. Furthermore, hydrogen exhibits\nprominent diffusion pathways, particularly in its +1 and 0 charge states at the\nBC site ( \"H\" _\"i(BC)\" ^\"+1\" and \"H\" _\"i(BC)\" ^\"0\" ), while oxygen in its +1\nand 0 charge states shows a higher diffusion barrier at the BC1 site ( \"O\"\n_\"i(BC1)\" ^\"+1\" and \"O\" _\"i(BC1)\" ^\"0\" ). These defects, induced by moisture\nand temperature fluctuations, exacerbate the degradation of solar cell\nperformance. By analyzing these defect behaviors, this research provides\nvaluable insights into the failure mechanisms of Si solar cells, especially\nunder humid conditions."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06646",
    "c_title":[
      "Evaluating and Aligning Human Economic Risk Preferences in LLMs"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) are increasingly used in decision-making\nscenarios that involve risk assessment, yet their alignment with human economic\nrationality remains unclear. In this study, we investigate whether LLMs exhibit\nrisk preferences consistent with human expectations across different personas.\nSpecifically, we assess whether LLM-generated responses reflect appropriate\nlevels of risk aversion or risk-seeking behavior based on individual's persona.\nOur results reveal that while LLMs make reasonable decisions in simplified,\npersonalized risk contexts, their performance declines in more complex economic\ndecision-making tasks. To address this, we propose an alignment method designed\nto enhance LLM adherence to persona-specific risk preferences. Our approach\nimproves the economic rationality of LLMs in risk-related applications,\noffering a step toward more human-aligned AI decision-making."
    ],
    "c_categories":[
      [
        "cs.CL",
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-926",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07414",
    "b_title":[
      "Cost-Effective Design of Grid-tied Community Microgrid"
    ],
    "b_abstract":[
      "This study aims to develop a cost-effective microgrid design that optimally\nbalances the economic feasibility, reliability, efficiency, and environmental\nimpact in a grid-tied community microgrid. A multi-objective optimization\nframework is employed, integrating HOMER Pro for system sizing with deep\nreinforcement learning (DRL). Sensitivity analyses are conducted to evaluate\nthe system performance under varying load demand and renewable energy\nfluctuations, while an economic sensitivity assessment examines the impact of\nelectricity prices and capital costs on the Levelized Cost of Energy (LCOE).\nThe proposed microgrid configuration achieves high reliability, satisfying 100%\nof the load, even under adverse weather conditions. The proposed framework\nattains an efficiency of 91.99% while maintaining a carbon footprint of 302,747\nkg\/year, which is approximately 95% lower than that of the grid system. The\neconomic analysis indicates a net present cost (NPC) of $4.83M with a\ncompetitive LCOE of $0.208\/kWh. In addition, the operation cost is $201,473 per\nyear with a capital investment of $1.42M, rendering it a financially viable\nalternative to conventional grid-dependent systems.This work can be valuable in\nidentifying effective solutions for supplying reliable and cost-effective power\nto regional and remote areas."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07993",
    "c_title":[
      "What is a Sketch-and-Precondition Derivation for Low-Rank Approximation?\n  Inverse Power Error or Inverse Power Estimation?"
    ],
    "c_abstract":[
      "Randomized sketching accelerates large-scale numerical linear algebra by\nreducing computational complexity. While the traditional sketch-and-solve\napproach reduces the problem size directly through sketching, the\nsketch-and-precondition method leverages sketching to construct a computational\nfriendly preconditioner. This preconditioner improves the convergence speed of\niterative solvers applied to the original problem, maintaining accuracy in the\nfull space. Furthermore, the convergence rate of the solver improves at least\nlinearly with the sketch size. Despite its potential, developing a\nsketch-and-precondition framework for randomized algorithms in low-rank matrix\napproximation remains an open challenge. We introduce the Error-Powered\nSketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for\nthe Lagrange form as a sketch-and-precondition variant for randomized low-rank\napproximation. Our method achieves theoretical guarantees, including a\nconvergence rate that improves at least linearly with the sketch size."
    ],
    "c_categories":[
      [
        "cs.CC",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "stat.CO",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-927",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06765",
    "b_title":[
      "Comfortability of quantum walks on embedded graphs on surfaces"
    ],
    "b_abstract":[
      "In this paper, a quantum walk model which reflects the underlying embedding\non the surface is proposed. We obtain the scattering matrix of this quantum\nwalk model characterized by the faces on the surface, and find a detection of\nthe orientablility of the underlying embedding by the scattering information.\nThe comfortability is the square norm of the stationary state restricted to the\ninternal and reflected by the underlying embedding. We find that quantum walker\nfeels more comfortable to a surface with small genus in some natural setting."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.08594",
    "c_title":[
      "3D Point Cloud Generation via Autoregressive Up-sampling"
    ],
    "c_abstract":[
      "We introduce a pioneering autoregressive generative model for 3D point cloud\ngeneration. Inspired by visual autoregressive modeling (VAR), we conceptualize\npoint cloud generation as an autoregressive up-sampling process. This leads to\nour novel model, PointARU, which progressively refines 3D point clouds from\ncoarse to fine scales. PointARU follows a two-stage training paradigm: first,\nit learns multi-scale discrete representations of point clouds, and then it\ntrains an autoregressive transformer for next-scale prediction. To address the\ninherent unordered and irregular structure of point clouds, we incorporate\nspecialized point-based up-sampling network modules in both stages and\nintegrate 3D absolute positional encoding based on the decoded point cloud at\neach scale during the second stage. Our model surpasses state-of-the-art (SoTA)\ndiffusion-based approaches in both generation quality and parameter efficiency\nacross diverse experimental settings, marking a new milestone for\nautoregressive methods in 3D point cloud generation. Furthermore, PointARU\ndemonstrates exceptional performance in completing partial 3D shapes and\nup-sampling sparse point clouds, outperforming existing generative models in\nthese tasks."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-928",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09015",
    "b_title":[
      "Generalized Cross-Entropy Benchmarking for Random Circuits with\n  Ergodicity"
    ],
    "b_abstract":[
      "Cross-entropy benchmarking is a central technique used to certify a quantum\nchip in recent experiments. To better understand its mathematical foundation\nand develop new benchmarking schemes, we introduce the concept of ergodicity to\nrandom circuit sampling and find that the Haar random quantum circuit satisfies\nan ergodicity condition -- the average of certain types of post-processing\nfunction over the output bit strings is close to the average over the unitary\nensemble. For noiseless random circuits, we prove that the ergodicity holds for\npolynomials of degree $t$ with positive coefficients and when the random\ncircuits form a unitary $2t$-design. For strong enough noise, the ergodicity\ncondition is violated. This suggests that ergodicity is a property that can be\nexploited to certify a quantum chip. We formulate the deviation of ergodicity\nas a measure for quantum chip benchmarking and show that it can be used to\nestimate the circuit fidelity for global depolarizing noise and weakly\ncorrelated noise. For a quadratic post-processing function, our framework\nrecovers Google's result on estimating the circuit fidelity via linear\ncross-entropy benchmarking (XEB), and we give a sufficient condition on the\nnoise model characterizing when such estimation is valid. Our results establish\nan interesting connection between ergodicity and noise in random circuits and\nprovide new insights into designing quantum benchmarking schemes."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [

      ]
    ],
    "c_id":"2503.09663",
    "c_title":[
      "BYOS: Knowledge-driven Large Language Models Bring Your Own Operating\n  System More Excellent"
    ],
    "c_abstract":[
      "Kernel configurations play an important role in the performance of Operating\nSystem (OS). However, with the rapid iteration of OS, finding the proper\nconfigurations that meet specific requirements can be challenging, which can be\nprimarily attributed to the default kernel provided by vendors does not take\nthe requirements of specific workloads into account, and the heavyweight tuning\nprocess cannot catch up with the rapid evolving pace of the kernel. To address\nthese challenges, we propose BYOS, a novel framework powered by Large Language\nModels (LLMs) to customize kernel configurations for diverse user requirements.\nBy integrating OS-oriented Dual-layer Knowledge Graph (OD-KG) and corresponding\nreasoning strategy, BYOS enhanced the LLM's understanding of the\ncharacteristics and capabilities of OS, thus enabling customized,\ncost-effective, and convenient generation of kernel configurations. Experiments\nshow that the kernels configured by BYOS outperform the default\nvendor-configured kernels by 7.1% to 155.4%, demonstrating the effectiveness\nand efficiency of BYOS in customizing kernel configurations. Our code is\navailable at https:\/\/github.com\/LHY-24\/BYOS."
    ],
    "c_categories":[
      [
        "cs.OS",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-929",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17760",
    "b_title":[
      "Probabilistic Dual Frames and Minimization of Dual Frame Potentials"
    ],
    "b_abstract":[
      "This paper studies probabilistic dual frames and associated dual frame\npotentials from the optimal mass transport perspective. The main contribution\nin this work shows that given a probabilistic frame, its dual frame potential\nis minimized if and only if the probabilistic frame is tight and the\nprobabilistic dual frame is the canonical dual. In particular, the tightness\ncondition can be dropped if the probabilistic dual frame potential is minimized\nonly among probabilistic dual frames of pushforward type."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10122",
    "c_title":[
      "Modern Hopfield Networks with Continuous-Time Memories"
    ],
    "c_abstract":[
      "Recent research has established a connection between modern Hopfield networks\n(HNs) and transformer attention heads, with guarantees of exponential storage\ncapacity. However, these models still face challenges scaling storage\nefficiently. Inspired by psychological theories of continuous neural resource\nallocation in working memory, we propose an approach that compresses large\ndiscrete Hopfield memories into smaller, continuous-time memories. Leveraging\ncontinuous attention, our new energy function modifies the update rule of HNs,\nreplacing the traditional softmax-based probability mass function with a\nprobability density, over the continuous memory. This formulation aligns with\nmodern perspectives on human executive function, offering a principled link\nbetween attractor dynamics in working memory and resource-efficient memory\nallocation. Our framework maintains competitive performance with HNs while\nleveraging a compressed memory, reducing computational costs across synthetic\nand video datasets."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-930",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13340",
    "b_title":[
      "A Python Toolkit for Plotting Double Star Observations with 1:1 Aspect\n  Ratio"
    ],
    "b_abstract":[
      "Accurate visualization of double star astrometric data is essential for\neffective analysis and interpretation. This article presents a Python toolkit\ndesigned for astronomers who need to plot measurements from diverse sources --\nhistorical, Gaia DR3, and the Las Cumbres Observatory (LCO) network -- while\nmaintaining a 1:1 aspect ratio to avoid visually distorting the data. The\ntoolkit is composed of three scripts: one that handles polar coordinates (P.A.,\nseparation), one for Cartesian (X, Y) coordinates, and another with the option\nto include predicted theoretical points. This paper describes the purpose,\nfunctionality, and usage of these scripts, including example figures,\ninstallation guides, and licensing information.\n  This toolkit has been used by the author and collaborators in published and\nsubmitted research on double star systems, demonstrating its versatility for\nboth professional and student-driven investigations."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04832",
    "c_title":[
      "Memory Capacity of Nonlinear Recurrent Networks: Is it Informative?"
    ],
    "c_abstract":[
      "The total memory capacity (MC) of linear recurrent neural networks (RNNs) has\nbeen proven to be equal to the rank of the corresponding Kalman controllability\nmatrix, and it is almost surely maximal for connectivity and input weight\nmatrices drawn from regular distributions. This fact questions the usefulness\nof this metric in distinguishing the performance of linear RNNs in the\nprocessing of stochastic signals. This note shows that the MC of random\nnonlinear RNNs yields arbitrary values within established upper and lower\nbounds depending just on the input process scale. This confirms that the\nexisting definition of MC in linear and nonlinear cases has no practical value."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-931",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04389",
    "b_title":[
      "Overcoming Vision Language Model Challenges in Diagram Understanding: A\n  Proof-of-Concept with XML-Driven Large Language Models Solutions"
    ],
    "b_abstract":[
      "Diagrams play a crucial role in visually conveying complex relationships and\nprocesses within business documentation. Despite recent advances in\nVision-Language Models (VLMs) for various image understanding tasks, accurately\nidentifying and extracting the structures and relationships depicted in\ndiagrams continues to pose significant challenges. This study addresses these\nchallenges by proposing a text-driven approach that bypasses reliance on VLMs'\nvisual recognition capabilities. Instead, it utilizes the editable source\nfiles--such as xlsx, pptx or docx--where diagram elements (e.g., shapes, lines,\nannotations) are preserved as textual metadata. In our proof-of-concept, we\nextracted diagram information from xlsx-based system design documents and\ntransformed the extracted shape data into textual input for Large Language\nModels (LLMs). This approach allowed the LLM to analyze relationships and\ngenerate responses to business-oriented questions without the bottleneck of\nimage-based processing. Experimental comparisons with a VLM-based method\ndemonstrated that the proposed text-driven framework yielded more accurate\nanswers for questions requiring detailed comprehension of diagram\nstructures.The results obtained in this study are not limited to the tested\n.xlsx files but can also be extended to diagrams in other documents with source\nfiles, such as Office pptx and docx formats. These findings highlight the\nfeasibility of circumventing VLM constraints through direct textual extraction\nfrom original source files. By enabling robust diagram understanding through\nLLMs, our method offers a promising path toward enhanced workflow efficiency\nand information analysis in real-world business scenarios."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09607",
    "c_title":[
      "The role of triple evolution in the formation of LISA double white\n  dwarfs"
    ],
    "c_abstract":[
      "Galactic double white dwarfs will be prominent gravitational-wave sources for\nthe Laser Interferometer Space Antenna (LISA). While previous studies have\nprimarily focused on formation scenarios in which binaries form and evolve in\nisolation, we present the first detailed study of the role of triple stellar\nevolution in forming the population of LISA double white dwarfs. In this work,\nwe present the first detailed study of the role of triple stellar evolution in\nforming the population of LISA double white dwarfs. We use the multiple stellar\nevolution code (MSE) to model the stellar evolution, binary interactions, and\nthe dynamics of triple star systems then use a Milky Way-like galaxy from the\nTNG50 simulations to construct a representative sample of LISA double white\ndwarfs. In our simulations about $7\\times10^6$ Galactic double white dwarfs in\nthe LISA frequency bandwidth originate from triple systems, whereas\n$\\sim4\\times10^6$ form from isolated binary stars. The properties of double\nwhite dwarfs formed in triples closely resemble those formed from isolated\nbinaries, but we also find a small number of systems $\\sim\\mathcal{O}(10)$ that\nreach extreme eccentricities $(>0.9)$, a feature unique to the dynamical\nformation channels. Our population produces $\\approx 10^{4} $ individually\nresolved double white dwarfs (from triple and binary channels) and an\nunresolved stochastic foreground below the level of the LISA instrumental\nnoise. About $57\\,\\%$ of double white dwarfs from triple systems retain a bound\nthird star when entering the LISA frequency bandwidth. However, we expect the\ntertiary stars to be too distant to have a detectable imprint in the\ngravitational-wave signal of the inner binary."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-932",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20517",
    "b_title":[
      "Abelian congruences and similarity in varieties with a weak difference\n  term"
    ],
    "b_abstract":[
      "This is the first of three papers motivated by the author's desire to\nunderstand and explain \"algebraically\" one aspect of Dmitriy Zhuk's proof of\nthe CSP Dichotomy Theorem. In this paper we study abelian congruences in\nvarieties having a weak difference term. Each class of the congruence supports\nan abelian group structure; if the congruence is minimal, each class supports\nthe structure of a vector space over a division ring determined by the\ncongruence. A construction due to J. Hagemann, C. Herrmann and R. Freese in the\ncongruence modular setting extends to varieties with a weak difference term,\nand provides a \"universal domain\" for the abelian groups or vector spaces that\narise from the classes of the congruence within a single class of the\nannihilator of the congruence. The construction also supports an extension of\nFreese's similarity relation (between subdirectly irreducible algebras) from\nthe congruence modular setting to varieties with a weak difference term."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.09444",
    "c_title":[
      "The orbital parameters of the binary BLAP HD133729 : advantages of the\n  frequency modulation method"
    ],
    "c_abstract":[
      "We derive all the orbital parameters of the blue large-amplitude pulsator\n(BLAP) in the binary system HD133729 by exploiting the frequency modulation\n(FM) method, which is based on the analytical relations between the orbital\nparameters and a multiplet separated by the orbital frequency in the frequency\nspectrum of the light curve. Because the FM method uses the entire data through\nthe Fourier transform, it is the most effective use of high-precision\nphotometry data, taken over a long timespan by the TESS space mission, for\ndetermining orbital parameters."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-933",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16128",
    "b_title":[
      "Coupling deep and handcrafted features to assess smile genuineness"
    ],
    "b_abstract":[
      "Assessing smile genuineness from video sequences is a vital topic concerned\nwith recognizing facial expression and linking them with the underlying\nemotional states. There have been a number of techniques proposed underpinned\nwith handcrafted features, as well as those that rely on deep learning to\nelaborate the useful features. As both of these approaches have certain\nbenefits and limitations, in this work we propose to combine the features\nlearned by a long short-term memory network with the features handcrafted to\ncapture the dynamics of facial action units. The results of our experiments\nindicate that the proposed solution is more effective than the baseline\ntechniques and it allows for assessing the smile genuineness from video\nsequences in real-time."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11624",
    "c_title":[
      "Chiral cat code: Enhanced error correction induced by higher-order\n  nonlinearities"
    ],
    "c_abstract":[
      "We introduce a Schr\\\"odinger chiral cat qubit, a novel bosonic quantum code\ngeneralizing Kerr cat qubits that exploits higher-order nonlinearities.\nCompared to a standard Kerr cat, the chiral cat qubit allows additional\ncorrection of bit-flip errors within the Hilbert space of a single bosonic\noscillator. Indeed, this code displays optical bistability, i.e., the\nsimultaneous presence of multiple long-lived states. Two of them define the\ncode space and two define an error space. Thanks to the chiral structure of the\nphase space of this system, the error space can be engineered to ``capture''\nbit flip events in the code space (a bit-flip trap), without affecting the\nquantum information stored in the system. Therefore, it is possible to perform\ndetection and correction of errors. We demonstrate how this topological effect\ncan be particularly efficient in the presence of large dephasing. We provide\nconcrete examples of the performance of the code and show the possibility of\napplying quantum operations rapidly and efficiently. Beyond the interest in\nthis single technological application, our work demonstrates how the topology\nof phase space can enhance the performance of bosonic codes."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-934",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06891",
    "b_title":[
      "Oscillations of Solitonic Galactic Cores in Ultralight Dark Matter"
    ],
    "b_abstract":[
      "A remarkable feature of dark matter consisting of ultralight bosonic\nparticles is the emergence of superfluid Bose-Einstein condensate structures on\ngalactic scales. We investigate the oscillations of the solitonic dark matter\nstructure in the central galactic region by numerically solving the\nBogoliubov-de Gennes problem, accounting for perturbations in the gravitational\npotential and local self-interactions. Our findings reveal that the central\nsolitonic core, formed by the balance of gravitational attraction, quantum\npressure, and repulsive interactions, exhibits significant oscillatory\nbehaviour. These oscillations, characterized by distinct eigenmodes, provide\ninsights into the dynamical properties of solitonic dark matter structures and\ntheir observational implications and contributions to galactic structure\nformation and evolution."
    ],
    "b_categories":[
      [
        "astro-ph.CO",
        "astro-ph.GA",
        "nlin.PS"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18146",
    "c_title":[
      "Linear operators preserving volume polynomials"
    ],
    "c_abstract":[
      "We study linear operators preserving the property of being a volume\npolynomial. More, precisely we show that a linear operator preserves this\nproperty if the associated symbol is itself a volume polynomial. This can be\nseen as an analogue to theorems by Borcea-Br\\\"and\\'en and Br\\\"and\\'en-Huh for\nstable polynomials and Lorentzian polynomials, respectively."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.CA",
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-935",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01752",
    "b_title":[
      "Re-Embeddings of Special Border Basis Schemes"
    ],
    "b_abstract":[
      "Border basis schemes are open subschemes of the Hilbert scheme of $\\mu$\npoints in an affine space $\\mathbb{A}^n$. They have easily describable systems\nof generators of their vanishing ideals for a natural embedding into a large\naffine space $\\mathbb{A}^{\\mu\\nu}$. Here we bring together several techniques\nfor re-embedding affine schemes into lower dimensional spaces which we\ndeveloped in the last years. We study their efficacy for some special types of\nborder basis schemes such as MaxDeg border basis schemes, L-shape and\nsimplicial border basis schemes, as well as planar border basis schemes. A\nparticular care is taken to make these re-embeddings efficiently computable and\nto check when we actually get an isomorphism with $\\mathbb{A}^{n\\mu}$, i.e.,\nwhen the border basis scheme is an affine cell."
    ],
    "b_categories":[
      [
        "math.AC",
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15153",
    "c_title":[
      "Investigating the Adaptive Robustness with Knowledge Conflicts in\n  LLM-based Multi-Agent Systems"
    ],
    "c_abstract":[
      "Recent advances in Large Language Models (LLMs) have upgraded them from\nsophisticated text generators to autonomous agents capable of corporation and\ntool use in multi-agent systems (MASs). However, the robustness of these\nLLM-based MASs, especially under knowledge conflicts, remains unclear. In this\npaper, we design four comprehensive metrics to investigate the robustness of\nMASs when facing mild or task-critical knowledge conflicts. We first analyze\nmild knowledge conflicts introduced by heterogeneous agents and find that they\ndo not harm system robustness but instead improve collaborative\ndecision-making. Next, we investigate task-critical knowledge conflicts by\nsynthesizing knowledge conflicts and embedding them into one of the agents. Our\nresults show that these conflicts have surprisingly little to no impact on MAS\nrobustness. Furthermore, we observe that MASs demonstrate certain\nself-repairing capabilities by reducing their reliance on knowledge conflicts\nand adopting alternative solution paths to maintain stability. Finally, we\nconduct ablation studies on the knowledge conflict number, agent number, and\ninteraction rounds, finding that the self-repairing capability of MASs has\nintrinsic limits, and all findings hold consistently across various factors.\nOur code is publicly available at\nhttps:\/\/github.com\/wbw625\/MultiAgentRobustness."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-936",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11960",
    "b_title":[
      "Consider What Humans Consider: Optimizing Commit Message Leveraging\n  Contexts Considered By Human"
    ],
    "b_abstract":[
      "Commit messages are crucial in software development, supporting maintenance\ntasks and communication among developers. While Large Language Models (LLMs)\nhave advanced Commit Message Generation (CMG) using various software contexts,\nsome contexts developers consider to write high-quality commit messages are\noften missed by CMG techniques and can't be easily retrieved or even retrieved\nat all by automated tools. To address this, we propose Commit Message\nOptimization (CMO), which enhances human-written messages by leveraging LLMs\nand search-based optimization. CMO starts with human-written messages and\niteratively improves them by integrating key contexts and feedback from\nexternal evaluators. Our extensive evaluation shows CMO generates commit\nmessages that are significantly more Rational, Comprehensive, and Expressive\nwhile outperforming state-of-the-art CMG methods and human messages 40.3% to\n78.4% of the time. Moreover, CMO can support existing CMG techniques to further\nimprove message quality and generate high-quality messages when the\nhuman-written ones are left blank."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09518",
    "c_title":[
      "Projecting Unequal Time Fields and Correlators of Large Scale Structure"
    ],
    "c_abstract":[
      "Many large scale structure surveys sort their observations into redshift bins\nand treat every tracer as being located at the mean redshift of its bin, a\ntreatment which we refer to as the equal time approximation. Recently, a new\nmethod was developed which allows for the estimation and correction of errors\nintroduced by this approximation, which we refer to as the unequal time\ncorrelator-level projection. For single tracer power spectra, corrections arise\nat second order and above in a series expansion, with first order terms\nsurviving only in multi-tracer analyses. In this paper we develop a new method\nwhich we refer to as the unequal time field level projection. This formalism\nprojects the fields individually onto the celestial sphere, displaced from\nindividual reference times, before defining their correlators. This method\nintroduces new, first order correction terms even in the case of single tracer\npower spectra. Specifically, new first order terms are introduced which apply\nto both cross-bin and single bin correlators. All of these new corrections\noriginate with derivatives over combinations of a delta function, a cross-bin\nphase term, and the power spectrum itself and stem from the introduction of two\nunequal time Fourier transforms into the analysis. We analyse these corrections\nin the context of a linearly biased power spectrum divided between two redshift\nbins and find that they can lead to non-trivial corrections, particularly to\ncross-bin correlators. We also show that these terms can be replicated by\nappropriately extending the correlator-level analysis to include a second\nFourier transform which allows for a full redshift bin integration."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-937",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14229",
    "b_title":[
      "On the multi-$\\mathbf{q}$ characteristics of magnetic ground states of\n  honeycomb cobalt oxides"
    ],
    "b_abstract":[
      "The Kitaev honeycomb model has received significant attention for its exactly\nsolvable quantum spin liquid ground states and fractionalized excitations. For\nrealizing the model, layered cobalt oxides have been considered a promising\nplatform. Yet, in contrast to the conventional wisdom about single-$\\mathbf{q}$\nzigzag magnetic order inferred from previous studies of the Na$_2$IrO$_3$ and\n$\\alpha$-RuCl$_3$ candidate materials, recent experiments on two of the\nrepresentative honeycomb cobalt oxides, hexagonal Na$_2$Co$_2$TeO$_6$ and\nmonoclinic Na$_3$Co$_2$SbO$_6$, have uncovered evidence for more complex\nmulti-$\\mathbf{q}$ variants of the zigzag order. This review surveys on\nexperimental strategies to distinguish between single- and multi-$\\mathbf{q}$\norders, along with the crystallographic symmetries of the cobalt oxides in\ncomparison to the previously studied systems. General formation mechanism of\nmulti-$\\mathbf{q}$ order is also briefly discussed. The goal is to provide some\nrationales for examining the relevance of multi-$\\mathbf{q}$ order in the\nhoneycomb cobalt oxides, along with its implications on the microscopic model\nof these intriguing quantum magnets."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15293",
    "c_title":[
      "A Reynolds-semi-robust method with hybrid velocity and pressure for the\n  unsteady incompressible Navier--Stokes equations"
    ],
    "c_abstract":[
      "In this paper we propose and analyze a new Finite Element method for the\nsolution of the two- and three-dimensional incompressible Navier--Stokes\nequations based on a hybrid discretization of both the velocity and pressure\nvariables. The proposed method is pressure-robust, i.e., irrotational forcing\nterms do not affect the approximation of the velocity, and\nReynolds-quasi-robust, with error estimates that, for smooth enough exact\nsolutions, do not depend on the inverse of the viscosity. We carry out an\nin-depth convergence analysis highlighting pre-asymptotic convergence rates and\nvalidate the theoretical findings with a complete set of numerical experiments."
    ],
    "c_categories":[
      [
        "cs.NA",
        "math.NA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-938",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08224",
    "b_title":[
      "HRAvatar: High-Quality and Relightable Gaussian Head Avatar"
    ],
    "b_abstract":[
      "Reconstructing animatable and high-quality 3D head avatars from monocular\nvideos, especially with realistic relighting, is a valuable task. However, the\nlimited information from single-view input, combined with the complex head\nposes and facial movements, makes this challenging. Previous methods achieve\nreal-time performance by combining 3D Gaussian Splatting with a parametric head\nmodel, but the resulting head quality suffers from inaccurate face tracking and\nlimited expressiveness of the deformation model. These methods also fail to\nproduce realistic effects under novel lighting conditions. To address these\nissues, we propose HRAvatar, a 3DGS-based method that reconstructs\nhigh-fidelity, relightable 3D head avatars. HRAvatar reduces tracking errors\nthrough end-to-end optimization and better captures individual facial\ndeformations using learnable blendshapes and learnable linear blend skinning.\nAdditionally, it decomposes head appearance into several physical properties\nand incorporates physically-based shading to account for environmental\nlighting. Extensive experiments demonstrate that HRAvatar not only reconstructs\nsuperior-quality heads but also achieves realistic visual effects under varying\nlighting conditions."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03451",
    "c_title":[
      "The dwarf irregular galaxy NGC 6822. II. Young, intermediate and old\n  stellar populations: comparison between theory and observations"
    ],
    "c_abstract":[
      "This paper presents a quantitative analysis of the stellar content in the\nLocal Group dwarf irregular galaxy NGC 6822 by comparing stellar evolution\nmodels and observations in color-magnitude diagrams (CMDs) and color-color\ndiagrams (CC-Ds). Our analysis is based on optical ground-based g,r,i\nphotometry, and deep archive HST photometry of two fields in the galaxy disk.\nWe compared young, intermediate-age, and old stellar populations with\nisochrones from the BaSTI-IAC library and found that NGC 6822 hosts a quite\nmetal-rich ([Fe\/H] = -0.7 to -0.4) young component with an age ranging from 20\nto 100 Myr. The intermediate-age population experienced a modest chemical\nenrichment between 4 and 8 Gyr ago while stars older than 11 Gyr have a low\nmetal abundance ([Fe\/H] ~ -1.70). We also identified the AGB clump population\nwith a luminosity peak at i ~ 23.35 mag. Our analysis of both the CMD and the\noptical-NIR-MIR CC-Ds of AGB oxygen- and carbon-rich stars, using the\nPARSEC+COLIBRI isochrones with and without circumstellar dust, reveal that this\nstellar component exhibits a spread in age from 1 to 2 Gyr and in metallicity\nbetween [Fe\/H]=-1.30 and -1.70. The stellar models we used reproduce very well\nthe two distinct color sequences defined by AGB O- and C-rich stars in the\nvarious optical-NIR-MIR CC-Ds, suggesting that they are reliable diagnostics to\nidentify and characterise intermediate-age stellar populations. However, we\nalso find that evolutionary prescriptions in the optical i-(r-i) CMDs predict,\nat fixed color, systematically lower luminosities than observed AGB stars."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-939",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14943",
    "b_title":[
      "3D Engine-ready Photorealistic Avatars via Dynamic Textures"
    ],
    "b_abstract":[
      "As the digital and physical worlds become more intertwined, there has been a\nlot of interest in digital avatars that closely resemble their real-world\ncounterparts. Current digitization methods used in 3D production pipelines\nrequire costly capture setups, making them impractical for mass usage among\ncommon consumers. Recent academic literature has found success in\nreconstructing humans from limited data using implicit representations (e.g.,\nvoxels used in NeRFs), which are able to produce impressive videos. However,\nthese methods are incompatible with traditional rendering pipelines, making it\ndifficult to use them in applications such as games. In this work, we propose\nan end-to-end pipeline that builds explicitly-represented photorealistic 3D\navatars using standard 3D assets. Our key idea is the use of\ndynamically-generated textures to enhance the realism and visually mask\ndeficiencies in the underlying mesh geometry. This allows for seamless\nintegration with current graphics pipelines while achieving comparable visual\nquality to state-of-the-art 3D avatar generation methods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10984",
    "c_title":[
      "The Problem of the Priors, or Posteriors?"
    ],
    "c_abstract":[
      "The problem of the priors is well known: it concerns the challenge of\nidentifying norms that govern one's prior credences. I argue that a key to\naddressing this problem lies in considering what I call the problem of the\nposteriors -- the challenge of identifying norms that directly govern one's\nposterior credences, which then induce constraints on the priors via the\ndiachronic requirement of conditionalization. This forward-looking approach can\nbe summarized as: Think ahead, work backward. Although this idea can be traced\nto Freedman (1963), Carnap (1963), and Shimony (1970), it has received little\nattention in philosophy. In this paper, I initiate a systematic defense of\nforward-looking Bayesianism, addressing potential objections from more\ntraditional views (both subjectivist and objectivist) and arguing for its\nadvantages. In particular, I develop a specific approach to forward-looking\nBayesianism -- one that treats the convergence of posterior credences to the\ntruth as a fundamental rather than derived normative requirement. This\napproach, called convergentist Bayesianism, is argued to be crucial for a\nBayesian foundation of Ockham's razor and related inference methods in\nstatistics and machine learning."
    ],
    "c_categories":[
      [
        "cs.AI",
        "math.PR",
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-940",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08043",
    "b_title":[
      "PolyLUT: Ultra-low Latency Polynomial Inference with Hardware-Aware\n  Structured Pruning"
    ],
    "b_abstract":[
      "Standard deep neural network inference involves the computation of\ninterleaved linear maps and nonlinear activation functions. Prior work for\nultra-low latency implementations has hardcoded these operations inside FPGA\nlookup tables (LUTs). However, FPGA LUTs can implement a much greater variety\nof functions. In this paper, we propose a novel approach to training DNNs for\nFPGA deployment using multivariate polynomials as the basic building block. Our\nmethod takes advantage of the flexibility offered by the soft logic, hiding the\npolynomial evaluation inside the LUTs with minimal overhead. By using\npolynomial building blocks, we achieve the same accuracy using considerably\nfewer layers of soft logic than by using linear functions, leading to\nsignificant latency and area improvements. LUT-based implementations also face\na significant challenge: the LUT size grows exponentially with the number of\ninputs. Prior work relies on a priori fixed sparsity, with results heavily\ndependent on seed selection. To address this, we propose a structured pruning\nstrategy using a bespoke hardware-aware group regularizer that encourages a\nparticular sparsity pattern that leads to a small number of inputs per neuron.\nWe demonstrate the effectiveness of PolyLUT on three tasks: network intrusion\ndetection, jet identification at the CERN Large Hadron Collider, and MNIST."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14829",
    "c_title":[
      "Stochastic Volatility Model with Sticky Drawdown and Drawup Processes: A\n  Deep Learning Approach"
    ],
    "c_abstract":[
      "We propose a new financial model, the stochastic volatility model with sticky\ndrawdown and drawup processes (SVSDU model), which enables us to capture the\nfeatures of winning and losing streaks that are common across financial markets\nbut can not be captured simultaneously by the existing financial models.\nMoreover, the SVSDU model retains the advantages of the stochastic volatility\nmodels. Since there are not closed-form option pricing formulas under the SVSDU\nmodel and the existing simulation methods for the sticky diffusion processes\nare really time-consuming, we develop a deep neural network to solve the\ncorresponding high-dimensional parametric partial differential equation (PDE),\nwhere the solution to the PDE is the pricing function of a European option\naccording to the Feynman-Kac Theorem, and validate the accuracy and efficiency\nof our deep learning approach. We also propose a novel calibration framework\nfor our model, and demonstrate the calibration performances of our models on\nboth simulated data and historical data. The calibration results on SPX option\ndata show that the SVSDU model is a good representation of the asset value\ndynamic, and both winning and losing streaks are accounted for in option\nvalues. Our model opens new horizons for modeling and predicting the dynamics\nof asset prices in financial markets."
    ],
    "c_categories":[
      [
        "q-fin.MF",
        "q-fin.PR"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-941",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05312",
    "b_title":[
      "Unveiling structure-property correlations in ferroelectric\n  $Hf_{0.5}Zr_{0.5}O_2$ films using variational autoencoders"
    ],
    "b_abstract":[
      "While $Hf_{0.5}Zr_{0.5}O_2$ (HZO) thin films hold significant promise for\nmodern nanoelectronic devices, a comprehensive understanding of the interplay\nbetween their polycrystalline structure and electrical properties remains\nelusive. Here, we present a novel framework combining phase-field (PF) modeling\nwith Variational Autoencoders (VAEs) to uncover structure-property correlations\nin polycrystalline HZO. Leveraging PF simulations, we constructed a\nhigh-fidelity dataset of $P-V$ loops by systematically varying critical\nmaterial parameters, including grain size, polar grain fraction, and\ncrystalline orientation. The VAEs effectively encoded hysteresis loops into a\nlow-dimensional latent space, capturing electrical properties while\ndisentangling complex material parameters interdependencies. We further\ndemonstrate a VAE-based inverse design approach to optimize $P-V$ loop\nfeatures, enabling the tailored design of device-specific key performance\nindicators (KPIs), including coercive field, remanent polarization, and loop\narea. The proposed approach offers a pathway to systematically explore and\noptimize the material design space for ferroelectric nanoelectronics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06974",
    "c_title":[
      "Higher-rank GBS groups: non-positive curvature and biautomaticity"
    ],
    "c_abstract":[
      "We characterise when a rank $n$ generalised Baumslag-Solitar group is CAT(0)\nand when it is biautomatic."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-942",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18852",
    "b_title":[
      "Data-Driven and Theory-Guided Pseudo-Spectral Seismic Imaging Using Deep\n  Neural Network Architectures"
    ],
    "b_abstract":[
      "Full Waveform Inversion (FWI) reconstructs high-resolution subsurface models\nvia multi-variate optimization but faces challenges with solver selection and\ndata availability. Deep Learning (DL) offers a promising alternative, bridging\ndata-driven and physics-based methods. While FWI in DL has been explored in the\ntime domain, the pseudo-spectral approach remains underutilized, despite its\nsuccess in classical FWI.\n  This thesis integrates pseudo-spectral FWI into DL, formulating both\ndata-driven and theory-guided approaches using Deep Neural Networks (DNNs) and\nRecurrent Neural Networks (RNNs). These methods were theoretically derived,\ntested on synthetic and Marmousi datasets, and compared with deterministic and\ntime-domain approaches.\n  Results show that data-driven pseudo-spectral DNNs outperform classical FWI\nin deeper and over-thrust regions due to their global approximation capability.\nTheory-guided RNNs yield greater accuracy, with lower error and better fault\nidentification. While DNNs excel in velocity contrast recovery, RNNs provide\nsuperior edge definition and stability in shallow and deep sections.\n  Beyond enhancing FWI performance, this research identifies broader\napplications of DL-based inversion and outlines future directions for these\nframeworks."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13321",
    "c_title":[
      "Study of Magnetic Field Resilient High Impedance High-Kinetic Inductance\n  Superconducting Resonators"
    ],
    "c_abstract":[
      "Superconducting resonators with high-kinetic inductance play a central role\nin hybrid quantum circuits, enabling strong coupling with quantum systems with\nsmall electric dipole moment and improved parametric amplification. However,\noptimizing these resonators simultaneously for high internal quality factors\n($Q_i$) and resilience to strong magnetic fields remains challenging. In this\nstudy, we systematically compare superconducting resonators fabricated from\nniobium nitride (NbN) and granular aluminum (grAl) thin films, each having\nsimilar kinetic inductance values ($L_k \\sim 100$ pH\/sq). At zero magnetic\nfield, resonators made from grAl exhibit higher $Q_i$ compared to their NbN\ncounterparts. However, under applied magnetic fields, NbN resonators\ndemonstrate significantly better resilience. Moreover, NbN resonators exhibit\nan unexpected increase in $Q_i$ at intermediate in-plane magnetic fields\n($B_{\\parallel} \\sim 1$ T), which we attribute to an enhanced frequency\ndetuning that reduce coupling to two-level system defects. In contrast, grAl\nresonators show a distinct critical field above which $Q_i$ rapidly decreases,\nstrongly depending on resonator cross-section respect to the applied field\ndirection. Characterization of the nonlinear properties at zero magnetic field\nreveals that the self-Kerr coefficient in grAl resonators is more than an order\nof magnitude higher than in NbN resonators, making grAl particularly attractive\nfor applications requiring pronounced nonlinear interactions. Our findings\nillustrate a clear trade-off between the two materials: NbN offers superior\nmagnetic-field resilience beneficial for hybrid circuit quantum electrodynamics\napplications, while grAl is more advantageous in low-field regimes demanding\nhigh impedance and strong nonlinearity."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall",
        "cond-mat.supr-con",
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-943",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11290",
    "b_title":[
      "EmoAgent: Multi-Agent Collaboration of Plan, Edit, and Critic, for\n  Affective Image Manipulation"
    ],
    "b_abstract":[
      "Affective Image Manipulation (AIM) aims to alter an image's emotional impact\nby adjusting multiple visual elements to evoke specific feelings.Effective AIM\nis inherently complex, necessitating a collaborative approach that involves\nidentifying semantic cues within source images, manipulating these elements to\nelicit desired emotional responses, and verifying that the combined adjustments\nsuccessfully evoke the target emotion.To address these challenges, we introduce\nEmoAgent, the first multi-agent collaboration framework for AIM. By emulating\nthe cognitive behaviors of a human painter, EmoAgent incorporates three\nspecialized agents responsible for planning, editing, and critical evaluation.\nFurthermore, we develop an emotion-factor knowledge retriever, a\ndecision-making tree space, and a tool library to enhance EmoAgent's\neffectiveness in handling AIM. Experiments demonstrate that the proposed\nmulti-agent framework outperforms existing methods, offering more reasonable\nand effective emotional expression."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02347",
    "c_title":[
      "Equivalence between sofic metric mean dimension and sofic $p$-metric\n  mean dimension with a product formula"
    ],
    "c_abstract":[
      "In this paper, we prove the equivalence between sofic $p$-metric mean\ndimension and sofic metric mean dimension. This answers a question of Hayes in\n\\cite{HB }. Furthermore, we establish the product formula for the sofic\n$p$-metric mean dimension."
    ],
    "c_categories":[
      [
        "math.CA",
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-944",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04003",
    "b_title":[
      "Understanding and Detecting Compatibility Issues in Android Auto Apps"
    ],
    "b_abstract":[
      "Mobile platforms now power not only smartphones but also in-vehicle systems\nlike Android Auto and CarPlay. Despite an ecosystem of over 3.5 million Android\napps and more than 200 million Android Auto-compatible vehicles, only a few\nhundred apps have been adapted for automotive use. To better understand this\ngap, we studied 147 reported issues related to Android Auto and identified\ntheir root causes. We found that more than 70% of issues result from UI\nincompatibilities, 24% from media playback errors, and around 5% from failures\nin voice command handling, showing a lack of effective tools for developers. We\nintroduce CarCompat, a static analysis framework that detects compatibility\nproblems in Android Auto apps. CarCompat constructs a Car-Control Flow Graph\n(CCFG) to capture interactions among app components, lifecycle methods, and\nplatform-specific callbacks. It applies specialized checkers to detect UI\nviolations, media playback errors, and issues with voice command handling. We\nevaluated CarCompat on a dataset of 54 Android Auto apps and detected 25 new\nissues, 4 of which were confirmed by developers, and 2 developers have already\nreleased their fixes. The results show that CarCompat helps developers identify\nand fix compatibility issues, improving the in-vehicle experience."
    ],
    "b_categories":[
      [
        "cs.PL",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16047",
    "c_title":[
      "Interpreting the $X(2370)$ and $X(2600)$ as light tetraquark states"
    ],
    "c_abstract":[
      "Inspired by the states $X(2370)$ and $X(2600)$ reported by the BESIII\nCollaboration, we systematically investigate the mass spectra of light compact\ntetraquark states with configurations $ud\\bar{u}\\bar{d}$, $us\\bar{u}\\bar{s}$,\nand $ss\\bar{s}\\bar{s}$ in the $J^{PC}=0^{-+}$ and $2^{-+}$ channels using the\nQCD sum rules approach. To effectively describe these tetraquark states, we\nconstruct appropriate interpolating tetraquark currents featuring three Lorentz\nindices while avoiding derivative operators. Through meticulous calculations of\ncorrelation functions up to dimension 10 condensates, we extract the mass\nspectra for both $0^{-+}$ and $2^{-+}$ states by employing the projection\noperator technique. Our results indicate that the masses of light tetraquarks\nspan $1.5-2.5~\\text{GeV}$ for $0^{-+}$ states and $2.4-2.7~\\text{GeV}$ for\n$2^{-+}$ states. Notably, our analysis suggests that the $X(2370)$ state could\nbe interpreted as a $0^{-+}$ $us\\bar{u}\\bar{s}$ or $ss\\bar{s}\\bar{s}$\ntetraquark state, while the $X(2600)$ state is likely to be a $2^{-+}$\n$us\\bar{u}\\bar{s}$ tetraquark. These intriguing findings warrant further\ndetailed investigation in future studies to better understand the nature of\nthese states."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-945",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04901",
    "b_title":[
      "On the Difficulty of Constructing a Robust and Publicly-Detectable\n  Watermark"
    ],
    "b_abstract":[
      "This work investigates the theoretical boundaries of creating\npublicly-detectable schemes to enable the provenance of watermarked imagery.\nMetadata-based approaches like C2PA provide unforgeability and\npublic-detectability. ML techniques offer robust retrieval and watermarking.\nHowever, no existing scheme combines robustness, unforgeability, and\npublic-detectability. In this work, we formally define such a scheme and\nestablish its existence. Although theoretically possible, we find that at\npresent, it is intractable to build certain components of our scheme without a\nleap in deep learning capabilities. We analyze these limitations and propose\nresearch directions that need to be addressed before we can practically realize\nrobust and publicly-verifiable provenance."
    ],
    "b_categories":[
      [
        "cs.CR",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03359",
    "c_title":[
      "Aspects of a randomly growing cluster in $\\reals^d,d\\geq 2"
    ],
    "c_abstract":[
      "We consider a simple model of a growing cluster of points in $\\Re^d,d\\geq 2$.\nBeginning with a point $X_1$ located at the origin, we generate a random\nsequence of points $X_1,X_2,\\ldots,X_i,\\ldots,$. To generate $X_{i},i\\geq 2$ we\nchoose a uniform integer $j$ in $[i-1]=\\{1,2,\\ldots,i-1\\}$ and then let\n$X_{i}=X_j+D_i$ where $D_i=(\\delta_1,\\ldots,\\delta_d)$. Here the $\\delta_j$ are\nindependent copies of the Normal distribution $N(0,\\sigma_i)$, where\n$\\sigma_i=i^{-\\alpha}$ for some $\\alpha>0$. We prove that for any $\\alpha>0$\nthe resulting point set is bounded a.s., and moreover, that the points\ngenerated look like samples from a $\\beta$-dimensional subset of $\\Re^d$ from\nthe standpoint of the minimum lengths of combinatorial structures on the\npoint-sets, where $\\beta=\\min(d,1\/\\alpha)$."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-946",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07616",
    "b_title":[
      "The Ingenuity Mars Helicopter Specified and Analyzed with the Real-time\n  Mode-aware Dataflow Model"
    ],
    "b_abstract":[
      "Ingenuity is an autonomous Cyber-Pysical System (CPS) that has successfully\ncompleted more than 70 flights over Mars between 2021 and 2024. Ensuring the\nsafety of its mission is paramount, as any failure could result in catastrophic\neconomic damage and significant financial losses. Dataflow Models of\nComputation and Communication (DF MoCCs) serve as a formal framework for\nspecifying and analyzing the timing behavior of such CPSs. In particular, the\nReal-time Mode-aware Dataflow (RMDF) model is highly suitable to specify and\nanalyze real-time and mode-dependent Cyber-Physical Systems (CPSs) like\nIngenuity. This paper showcases the application of RMDF for the specification\nand analysis of Ingenuity. We propose a dataflow specification of Ingenuity,\nanalyze its timing behavior, and provide a feasibility test. Finally, we\nproposed a plausible explanation of the timing anomaly that occurred during the\nsixth flight of Ingenuity."
    ],
    "b_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14078",
    "c_title":[
      "Left invertible quasi-isometric liftings"
    ],
    "c_abstract":[
      "Quasi-isometric liftings similar to isometries, for the operators similar to\ncontractions in Hilbert spaces, are investigated. The existence of such\nliftings is established, and their applications are explored for specific\noperator classes, including quasicontractions. A particular focus is placed on\noperators that admit left invertible minimal quasi-isometric liftings. These\noperators are characterized within the framework of $A$-contractions, and the\nmatrix structures of their liftings are analyzed, highlighting parallels with\nthe isometric liftings of contractions."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-947",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05682",
    "b_title":[
      "Task-oriented Uncertainty Collaborative Learning for Label-Efficient\n  Brain Tumor Segmentation"
    ],
    "b_abstract":[
      "Multi-contrast magnetic resonance imaging (MRI) plays a vital role in brain\ntumor segmentation and diagnosis by leveraging complementary information from\ndifferent contrasts. Each contrast highlights specific tumor characteristics,\nenabling a comprehensive understanding of tumor morphology, edema, and\npathological heterogeneity. However, existing methods still face the challenges\nof multi-level specificity perception across different contrasts, especially\nwith limited annotations. These challenges include data heterogeneity,\ngranularity differences, and interference from redundant information. To\naddress these limitations, we propose a Task-oriented Uncertainty Collaborative\nLearning (TUCL) framework for multi-contrast MRI segmentation. TUCL introduces\na task-oriented prompt attention (TPA) module with intra-prompt and\ncross-prompt attention mechanisms to dynamically model feature interactions\nacross contrasts and tasks. Additionally, a cyclic process is designed to map\nthe predictions back to the prompt to ensure that the prompts are effectively\nutilized. In the decoding stage, the TUCL framework proposes a dual-path\nuncertainty refinement (DUR) strategy which ensures robust segmentation by\nrefining predictions iteratively. Extensive experimental results on limited\nlabeled data demonstrate that TUCL significantly improves segmentation accuracy\n(88.2\\% in Dice and 10.853 mm in HD95). It shows that TUCL has the potential to\nextract multi-contrast information and reduce the reliance on extensive\nannotations. The code is available at:\nhttps:\/\/github.com\/Zhenxuan-Zhang\/TUCL_BrainSeg."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07911",
    "c_title":[
      "Cut-off phenomenon and asymptotic mixing for multivariate general linear\n  processes"
    ],
    "c_abstract":[
      "The small noise cut-off phenomenon in continuous time and space has been\nstudied in the recent literature for the linear and non-linear stable Langevin\ndynamics with additive L\\'evy drivers - understood as abrupt thermalization of\nthe system along a particular time scale to its dynamical equilibrium - both\nfor the total variation distance and the Wasserstein distance. The main result\nof this article establishes sufficient conditions for the window and profile\ncut-off phenomenon, which are flexible enough to cover the renormalized\n(non-Markovian) Ornstein--Uhlenbeck process driven by fractional Brownian\nmotion and a large class of Gaussian and non-Gaussian, homogeneous and\nnon-homogeneous drivers with (possible) finite second moments. The sufficient\nconditions are stated both for the total variation distance and the Wasserstein\ndistance. Important examples are the multidimensional fractional\nOrnstein--Uhlenbeck process, the empirical sampling process of a fractional\nOrnstein--Uhlenbeck process, an Ornstein--Uhlenbeck processes driven by an\nOrnstein--Uhlenbeck process and the inhomogeneous Ornstein--Uhlenbeck process\narising in simulated annealing."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-948",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09434",
    "b_title":[
      "Redistribute Ensemble Training for Mitigating Memorization in Diffusion\n  Models"
    ],
    "b_abstract":[
      "Diffusion models, known for their tremendous ability to generate high-quality\nsamples, have recently raised concerns due to their data memorization behavior,\nwhich poses privacy risks. Recent methods for memory mitigation have primarily\naddressed the issue within the context of the text modality in cross-modal\ngeneration tasks, restricting their applicability to specific conditions. In\nthis paper, we propose a novel method for diffusion models from the perspective\nof visual modality, which is more generic and fundamental for mitigating\nmemorization. Directly exposing visual data to the model increases memorization\nrisk, so we design a framework where models learn through proxy model\nparameters instead. Specially, the training dataset is divided into multiple\nshards, with each shard training a proxy model, then aggregated to form the\nfinal model. Additionally, practical analysis of training losses illustrates\nthat the losses for easily memorable images tend to be obviously lower. Thus,\nwe skip the samples with abnormally low loss values from the current mini-batch\nto avoid memorizing. However, balancing the need to skip memorization-prone\nsamples while maintaining sufficient training data for high-quality image\ngeneration presents a key challenge. Thus, we propose IET-AGC+, which\nredistributes highly memorizable samples between shards, to mitigate these\nsamples from over-skipping. Furthermore, we dynamically augment samples based\non their loss values to further reduce memorization. Extensive experiments and\nanalysis on four datasets show that our method successfully reduces memory\ncapacity while maintaining performance. Moreover, we fine-tune the pre-trained\ndiffusion models, e.g., Stable Diffusion, and decrease the memorization score\nby 46.7\\%, demonstrating the effectiveness of our method. Code is available in:\nhttps:\/\/github.com\/liuxiao-guan\/IET_AGC."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17382",
    "c_title":[
      "The nonmodal kinetic theory of the macroscale convective flows of\n  magnetized plasma, generated by the inhomogeneous microturbulenc"
    ],
    "c_abstract":[
      "In this paper, we develop the nonmodal kinetic theory of the macroscale\nconvective flows of magnetized plasma, which stem from the average motion of\nions and electrons in the electric field of the spatially inhomogeneous\nmicroturbulence. This theory bases on the two-scales approach to the solution\nof the Vlasov-Poisson system of equations for magnetized plasma, in which the\nsolutions depend simultaneously on micro and macro scales. The developed theory\npredicts the generation of the sheared poloidal convective flow and of the\nradial compressed flow with radial flow velocity gradient. It was found that\nthe macroscale (radial) inhomogeneity of the spectral intensity of the\nmicroturbulence is the condition necessary for the development of the\ntwo-dimensional non-diffusive convective plasma flows. The developed theory\nincludes the theory of the evolution of the microscale turbulence in the\nsheared-compressed convective flows, formed by the microturbulence, and the\ntheory of the slow macroscale evolution of a bulk of plasma by the\ncompressed-sheared convective flows."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-949",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06062",
    "b_title":[
      "Personalized Language Model Learning on Text Data Without User\n  Identifiers"
    ],
    "b_abstract":[
      "In many practical natural language applications, user data are highly\nsensitive, requiring anonymous uploads of text data from mobile devices to the\ncloud without user identifiers. However, the absence of user identifiers\nrestricts the ability of cloud-based language models to provide personalized\nservices, which are essential for catering to diverse user needs. The trivial\nmethod of replacing an explicit user identifier with a static user embedding as\nmodel input still compromises data anonymization. In this work, we propose to\nlet each mobile device maintain a user-specific distribution to dynamically\ngenerate user embeddings, thereby breaking the one-to-one mapping between an\nembedding and a specific user. We further theoretically demonstrate that to\nprevent the cloud from tracking users via uploaded embeddings, the local\ndistributions of different users should either be derived from a linearly\ndependent space to avoid identifiability or be close to each other to prevent\naccurate attribution. Evaluation on both public and industrial datasets using\ndifferent language models reveals a remarkable improvement in accuracy from\nincorporating anonymous user embeddings, while preserving real-time inference\nrequirement."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02209",
    "c_title":[
      "Jamming transition and normal modes of polydispersed soft particle\n  packing"
    ],
    "c_abstract":[
      "The jamming transition of soft particles characterized by narrow size\ndistributions has been well studied by physicists. However, polydispersed\nsystems are more relevant to engineering, and the influence of polydispersity\non jamming phenomena is still unexplored. Here, we numerically investigate\njamming transitions of polydispersed soft particles in two dimensions. We find\nthat polydispersity strongly influences contact forces, local coordination, and\nthe jamming transition density. In contrast, the critical scaling of pressure\nand elastic moduli is not affected by the particle size distribution.\nConsistent with this observation, we find that the vibrational density of\nstates is also insensitive to the polydispersity. Our results suggest that,\nregardless of particle size distributions, both mechanical and vibrational\nproperties of soft particle packings near jamming are governed by the distance\nto jamming."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-950",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06496",
    "b_title":[
      "Modeling Nonlinear Optics with the Transfer Matrix Method"
    ],
    "b_abstract":[
      "The Transfer Matrix Method (TMM) is a widely used technique for modeling\nlinear propagation of electromagnetic waves through stratified layered media.\nHowever, since its extension to inhomogeneous and nonlinear systems is not\nstraightforward, much more computationally demanding methods such as\nFinite-difference time-domain (FDTD) or Method of lines (MoL) are typically\nused. In this work, we extend the TMM framework to incorporate the effects of\nnonlinearity. We consider the case when strong coupling between excitons\n(electron-hole pairs) and photons leads to the formation of exciton-polaritons.\nThis extension is crucial for accurately simulating the behavior of light in\npolariton microcavities, where nonlinearities arising from exciton-exciton\ninteractions play a key role. We perform efficient simulations of light\ntransmission and reflection in a multidimensional system using the plane wave\nbasis. Additionally, we compare our extended TMM approach with the\nstate-of-the-art admittance transfer method, and highlight the computational\nadvantage of extended TMM for large-scale systems. The extended TMM not only\nprovides a robust and computationally efficient numerical framework, but also\npaves the way for the development of future low-power nonlinear optical\ndevices, polariton-based photonic circuits, and quantum photonic technologies."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18656",
    "c_title":[
      "Solution Theory of Hamilton-Jacobi-Bellman Equations in Spectral Barron\n  Spaces"
    ],
    "c_abstract":[
      "We study the solution theory of the whole-space static (elliptic)\nHamilton-Jacobi-Bellman (HJB) equation in spectral Barron spaces. We prove that\nunder the assumption that the coefficients involved are spectral Barron\nfunctions and the discount factor is sufficiently large, there exists a\nsequence of uniformly bounded spectral Barron functions that converges locally\nuniformly to the solution. As a consequence, the solution of the HJB equation\ncan be approximated by two-layer neural networks without curse of\ndimensionality."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-951",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01940",
    "b_title":[
      "Toward a Low-Cost Perception System in Autonomous Vehicles: A Spectrum\n  Learning Approach"
    ],
    "b_abstract":[
      "We present a cost-effective new approach for generating denser depth maps for\nAutonomous Driving (AD) and Autonomous Vehicles (AVs) by integrating the images\nobtained from deep neural network (DNN) 4D radar detectors with conventional\ncamera RGB images. Our approach introduces a novel pixel positional encoding\nalgorithm inspired by Bartlett's spatial spectrum estimation technique. This\nalgorithm transforms both radar depth maps and RGB images into a unified pixel\nimage subspace called the Spatial Spectrum, facilitating effective learning\nbased on their similarities and differences. Our method effectively leverages\nhigh-resolution camera images to train radar depth map generative models,\naddressing the limitations of conventional radar detectors in complex vehicular\nenvironments, thus sharpening the radar output. We develop spectrum estimation\nalgorithms tailored for radar depth maps and RGB images, a comprehensive\ntraining framework for data-driven generative models, and a camera-radar\ndeployment scheme for AV operation. Our results demonstrate that our approach\nalso outperforms the state-of-the-art (SOTA) by 27.95% in terms of\nUnidirectional Chamfer Distance (UCD)."
    ],
    "b_categories":[
      [
        "cs.CV",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03995",
    "c_title":[
      "Modeling fast X-ray variability around an accreting black hole"
    ],
    "c_abstract":[
      "X-ray inter-band time lags are observed during the outbursts of black hole\nX-ray binaries (BHXRBs). Timing analysis of fast variability in low Fourier\nfrequency bands shows that high-energy photons lag behind low-energy photons, a\nphenomenon referred to as hard lag. Conversely, in high Fourier frequency\nbands, low-energy photons lag behind high-energy photons, known as soft lag.\nThis frequency-dependent lag spectrum suggests that the lags arise from\ndifferent physical processes. Notably, a trend has been observed wherein the\nlags shift towards shorter timescales during the rising hard state, indicating\nan evolution in the inner accretion flow. In this study, we simulate these\ninter-band lags by conducting Monte Carlo simulations of the rapid variability\nwithin the geometry of a jet base corona. We consider both inward propagating\naccretion rate fluctuations and reverberation (light crossing) delays in our\nsimulations. We successfully reproduce both low-frequency hard lags and\nhigh-frequency soft lags in a self-consistent manner. We replicate the observed\nevolution of the frequency-dependent lag spectra by varying the geometrical\nscale of the corona and the viscous frequency of the disc. Finally, we discuss\nthe potential of a spherical corona and emphasize that polarization\nobservations from the Imaging X-ray Polarimetry Explorer (IXPE) and the\nenhanced X-ray Timing and Polarimetry mission (eXTP) will be crucial for\ndistinguishing the corona's geometry in future studies."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-952",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02494",
    "b_title":[
      "Analyzing Similarity Metrics for Data Selection for Language Model\n  Pretraining"
    ],
    "b_abstract":[
      "Similarity between training examples is used to curate pretraining datasets\nfor language models by many methods -- for diversification and to select\nexamples similar to high-quality data. However, similarity is typically\nmeasured with off-the-shelf embedding models that are generic or trained for\ntasks such as retrieval. This paper introduces a framework to analyze the\nsuitability of embedding models specifically for data curation in the language\nmodel pretraining setting. We quantify the correlation between similarity in\nthe embedding space to similarity in pretraining loss between different\ntraining examples, and how diversifying in the embedding space affects\npretraining quality. We analyze a variety of embedding models in our framework,\nwith experiments using the Pile dataset for pretraining a 1.7B parameter\ndecoder-only language model. We find that the embedding models we consider are\nall useful for pretraining data curation. Moreover, a simple approach of\naveraging per-token embeddings proves to be surprisingly competitive with more\nsophisticated embedding models -- likely because the latter are not designed\nspecifically for pretraining data curation. Indeed, we believe our analysis and\nevaluation framework can serve as a foundation for the design of embedding\nmodels that specifically reason about similarity in pretraining datasets."
    ],
    "b_categories":[
      [
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14386",
    "c_title":[
      "Can one-loop corrections to the one-gluon exchange potential adequately\n  describe the charmed meson spectrum?"
    ],
    "c_abstract":[
      "We investigate the charmed meson spectrum using a constituent quark model\n(CQM) with one-loop corrections applied to the one-gluon exchange (OGE)\npotential. The study aims to understand if these one-loop corrections\nsufficiently account for the charmed meson spectrum observed experimentally,\nwithout invoking exotic configurations like tetraquarks. Within this model,\ncharmed mesons' masses are computed, comparing theoretical predictions to\nexperimental data. The results suggest that the model, with one-loop OGE\ncorrections, generally reproduces mass splittings and level ordering observed\nfor charmed mesons. Discrepancies, particularly in P-wave states, are addressed\nby incorporating higher-order interaction terms. The findings emphasize that\nwhile the traditional quark model is limited in fully describing charmed\nmesons, enhanced potential terms may bridge the gap with experimental\nobservations. The study contributes a framework for predicting excited charmed\nmeson states for future experimental validation."
    ],
    "c_categories":[
      [
        "hep-ex",
        "hep-lat",
        "hep-ph",
        "nucl-ex",
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-953",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02717",
    "b_title":[
      "Astromer 2"
    ],
    "b_abstract":[
      "Foundational models have emerged as a powerful paradigm in deep learning\nfield, leveraging their capacity to learn robust representations from\nlarge-scale datasets and effectively to diverse downstream applications such as\nclassification. In this paper, we present Astromer 2 a foundational model\nspecifically designed for extracting light curve embeddings. We introduce\nAstromer 2 as an enhanced iteration of our self-supervised model for light\ncurve analysis. This paper highlights the advantages of its pre-trained\nembeddings, compares its performance with that of its predecessor, Astromer 1,\nand provides a detailed empirical analysis of its capabilities, offering deeper\ninsights into the model's representations. Astromer 2 is pretrained on 1.5\nmillion single-band light curves from the MACHO survey using a self-supervised\nlearning task that predicts randomly masked observations within sequences.\nFine-tuning on a smaller labeled dataset allows us to assess its performance in\nclassification tasks. The quality of the embeddings is measured by the F1 score\nof an MLP classifier trained on Astromer-generated embeddings. Our results\ndemonstrate that Astromer 2 significantly outperforms Astromer 1 across all\nevaluated scenarios, including limited datasets of 20, 100, and 500 samples per\nclass. The use of weighted per-sample embeddings, which integrate intermediate\nrepresentations from Astromer's attention blocks, is particularly impactful.\nNotably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS dataset\ncompared to prior models, showcasing robust generalization to new datasets.\nThis enhanced performance, especially with minimal labeled data, underscores\nthe potential of Astromer 2 for more efficient and scalable light curve\nanalysis."
    ],
    "b_categories":[
      [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17429",
    "c_title":[
      "CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation"
    ],
    "c_abstract":[
      "While 3D instance segmentation has made significant progress, current methods\nstruggle to address realistic scenarios where new categories emerge over time\nwith natural class imbalance. This limitation stems from existing datasets,\nwhich typically feature few well-balanced classes. Although few datasets\ninclude unbalanced class annotations, they lack the diverse incremental\nscenarios necessary for evaluating methods under incremental settings.\nAddressing these challenges requires frameworks that handle both incremental\nlearning and class imbalance. However, existing methods for 3D incremental\nsegmentation rely heavily on large exemplar replay, focusing only on\nincremental learning while neglecting class imbalance. Moreover,\nfrequency-based tuning for balanced learning is impractical in these setups due\nto the lack of prior class statistics. To overcome these limitations, we\npropose a framework to tackle both \\textbf{C}ontinual \\textbf{L}earning and\nclass \\textbf{Imb}alance for \\textbf{3D} instance segmentation\n(\\textbf{CLIMB-3D}). Our proposed approach combines Exemplar Replay (ER),\nKnowledge Distillation (KD), and a novel Imbalance Correction (IC) module.\nUnlike prior methods, our framework minimizes ER usage, with KD preventing\nforgetting and supporting the IC module in compiling past class statistics to\nbalance learning of rare classes during incremental updates. To evaluate our\nframework, we design three incremental scenarios based on class frequency,\nsemantic similarity, and random grouping that aim to mirror real-world dynamics\nin 3D environments. Experimental results show that our proposed framework\nachieves state-of-the-art performance, with an increase of up to 16.76\\% in mAP\ncompared to the baseline. Code will be available at:\n\\href{https:\/\/github.com\/vgthengane\/CLIMB3D}{https:\/\/github.com\/vgthengane\/CLIMB3D}"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-954",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09528",
    "b_title":[
      "SteROI-D: System Design and Mapping for Stereo Depth Inference on\n  Regions of Interest"
    ],
    "b_abstract":[
      "Machine learning algorithms have enabled high quality stereo depth estimation\nto run on Augmented and Virtual Reality (AR\/VR) devices. However, high energy\nconsumption across the full image processing stack prevents stereo depth\nalgorithms from running effectively on battery-limited devices. This paper\nintroduces SteROI-D, a full stereo depth system paired with a mapping\nmethodology. SteROI-D exploits Region-of-Interest (ROI) and temporal sparsity\nat the system level to save energy. SteROI-D's flexible and heterogeneous\ncompute fabric supports diverse ROIs. Importantly, we introduce a systematic\nmapping methodology to effectively handle dynamic ROIs, thereby maximizing\nenergy savings. Using these techniques, our 28nm prototype SteROI-D design\nachieves up to 4.35x reduction in total system energy compared to a baseline\nASIC."
    ],
    "b_categories":[
      [
        "cs.AR",
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10099",
    "c_title":[
      "Several Representations of $\\alpha$-Mutual Information and\n  Interpretations as Privacy Leakage Measures"
    ],
    "c_abstract":[
      "In this paper, we present several novel representations of $\\alpha$-mutual\ninformation ($\\alpha$-MI) in terms of R{\\' e}nyi divergence and conditional\nR{\\' e}nyi entropy. The representations are based on the variational\ncharacterizations of $\\alpha$-MI using a reverse channel. Based on these\nrepresentations, we provide several interpretations of the $\\alpha$-MI as\nprivacy leakage measures using generalized mean and gain functions. Further, as\nbyproducts of the representations, we propose novel conditional R{\\' e}nyi\nentropies that satisfy the property that conditioning reduces entropy and\ndata-processing inequality."
    ],
    "c_categories":[
      [
        "cs.IT",
        "math.IT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-955",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11655",
    "b_title":[
      "Explainable Sentiment Analysis with DeepSeek-R1: Performance,\n  Efficiency, and Few-Shot Learning"
    ],
    "b_abstract":[
      "Recent advancements in large language models (LLMs) have significantly\nenhanced sentiment analysis capabilities. However, the trade-offs between model\nperformance, efficiency, and explainability of some latest models remain\nunderexplored. This study presents the first comprehensive evaluation of the\nDeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment\nanalysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We\nsystematically analyze their performance under few-shot prompting conditions,\nscaling up to 50-shot configurations to assess in-context learning\neffectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive\naccuracy, particularly in multi-class sentiment tasks, while offering enhanced\ninterpretability through its detailed reasoning process. Additionally, we\nhighlight the impact of increasing few-shot examples on model performance and\ndiscuss key trade-offs between explainability and computational efficiency."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.21205",
    "c_title":[
      "Stability of axial free-boundary hyperplanes in circular cones"
    ],
    "c_abstract":[
      "Given an axially-symmetric, $(n+1)$-dimensional convex cone $\\Omega\\subset\n\\mathbb{R}^{n+1}$, we study the stability of the free-boundary minimal surface\n$\\Sigma$ obtained by intersecting $\\Omega$ with a $n$-plane that contains the\naxis of $\\Omega$. In the case $n=2$, $\\Sigma$ is always unstable, as a special\ncase of the vertex-skipping property recently proved in a paper by the same\nauthors. Conversely, as soon as $n \\ge 3$ and $\\Omega$ has a sufficiently large\naperture (depending on the dimension $n$), we show that $\\Sigma$ is strictly\nstable. For our stability analysis, we introduce a Lipschitz flow\n$\\Sigma_{t}[f]$ of deformations of $\\Sigma$ associated with a\ncompactly-supported, scalar deformation field $f$, which satisfies the key\nproperty $\\partial \\Sigma_{t}[f] \\subset \\partial \\Omega$ for all $t\\in\n\\mathbb{R}$. Then, we compute the lower-right second variation of the area of\n$\\Sigma$ along the flow, and ultimately show that it is positive by exploiting\nits connection with a functional inequality studied in the context of\nreaction-diffusion problems."
    ],
    "c_categories":[
      [
        "math.AP",
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-956",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17425",
    "b_title":[
      "Introducing Visual Perception Token into Multimodal Large Language Model"
    ],
    "b_abstract":[
      "To utilize visual information, Multimodal Large Language Model (MLLM) relies\non the perception process of its vision encoder. The completeness and accuracy\nof visual perception significantly influence the precision of spatial\nreasoning, fine-grained understanding, and other tasks. However, MLLM still\nlacks the autonomous capability to control its own visual perception processes,\nfor example, selectively reviewing specific regions of an image or focusing on\ninformation related to specific object categories. In this work, we propose the\nconcept of Visual Perception Token, aiming to empower MLLM with a mechanism to\ncontrol its visual perception processes. We design two types of Visual\nPerception Tokens, termed the Region Selection Token and the Vision Re-Encoding\nToken. MLLMs autonomously generate these tokens, just as they generate text,\nand use them to trigger additional visual perception actions. The Region\nSelection Token explicitly identifies specific regions in an image that require\nfurther perception, while the Vision Re-Encoding Token uses its hidden states\nas control signals to guide additional visual perception processes. Extensive\nexperiments demonstrate the advantages of these tokens in handling spatial\nreasoning, improving fine-grained understanding, and other tasks. On average,\nthe introduction of Visual Perception Tokens improves the performance of a 2B\nmodel by 23.6\\%, increasing its score from 0.572 to 0.708, and even outperforms\na 7B parameter model by 13.4\\% (from 0.624). Please check out our repo\nhttps:\/\/github.com\/yu-rp\/VisualPerceptionToken"
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05699",
    "c_title":[
      "Fast and memory efficient strong simulation of noisy adaptive linear\n  optical circuits"
    ],
    "c_abstract":[
      "Exactly computing the full output distribution of linear optical circuits\nremains a challenge, as existing methods are either time-efficient but\nmemory-intensive or memory-efficient but slow. Moreover, any realistic\nsimulation must account for noise, and any viable quantum computing scheme\nbased on linear optics requires feedforward. In this paper, we propose an\nalgorithm that models the output amplitudes as partial derivatives of a\nmultivariate polynomial. The algorithm explores the lattice of all intermediate\npartial derivatives, where each derivative is used to compute more efficiently\nones with higher degree. In terms of memory, storing one path from the root to\nthe leaves is sufficient to iterate over all amplitudes and requires only $2^n$\nelements, as opposed to $\\binom{n+m-1}{n}$ for the fastest state of the art\nmethod. This approach effectively balances the time-memory trade-off while\nextending to both noisy and feedforward scenarios with negligible cost. To the\nbest of our knowledge, this is the first approach in the literature to meet all\nthese requirements. We demonstrate how this method enables the simulation of\nsystems that were previously out of reach, while providing a concrete\nimplementation and complexity analysis."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-957",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03304",
    "b_title":[
      "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient\n  Zeroth-order LLM Fine-tuning"
    ],
    "b_abstract":[
      "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose \\textbf{Di}vergence-driven\n\\textbf{Z}eroth-\\textbf{O}rder (\\textbf{DiZO}) optimization. DiZO conducts\ndivergence-driven layer adaptation by incorporating projections to ZO updates,\ngenerating diverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48\\% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07887",
    "c_title":[
      "Active magneto-mechanical metamaterial with the wave transmission and\n  Poisson's ratio controlled via the magnetic field"
    ],
    "c_abstract":[
      "In recent years, there has been a notable increase in the significance of\nactive mechanical metamaterials capable of being remotely manipulated through\nchanges in external stimuli. While research in this area has achieved\nconsiderable success in controlling reconfiguration to induce shape morphing or\nalter static mechanical properties, the active control of wave propagation\nwithin these systems remains largely unexplored. In this study, we propose a\nmagneto-mechanical metamaterial that can be entirely governed by adjusting the\nmagnitude and direction of an external magnetic field. We demonstrate that such\na system offers remote control over its Poisson's ratio, allowing for\ntransitions from strongly auxetic to positive Poisson's ratio configurations.\nAdditionally, our system enables manipulation of the phononic band structure,\nfacilitating the formation of complete band gaps across different frequency\nranges depending on the stage of the magnetically guided reconfiguration\nprocess. The potential for achieving such active control over the properties\nand behavior of these materials holds great promise for various applications,\nincluding robotics and smart vibration dampers that can be remotely controlled."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-958",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04049",
    "b_title":[
      "Neural Network Surrogate Model for Junction Temperature and Hotspot\n  Position in $3$D Multi-Layer High Bandwidth Memory (HBM) Chiplets under\n  Varying Thermal Conditions"
    ],
    "b_abstract":[
      "As the demand for computational power increases, high-bandwidth memory (HBM)\nhas become a critical technology for next-generation computing systems.\nHowever, the widespread adoption of HBM presents significant thermal management\nchallenges, particularly in multilayer through-silicon-via (TSV) stacked\nstructures under varying thermal conditions, where accurate prediction of\njunction temperature and hotspot position is essential during the early design.\nThis work develops a data-driven neural network model for the fast prediction\nof junction temperature and hotspot position in 3D HBM chiplets. The model,\ntrained with a data set of $13,494$ different combinations of thermal condition\nparameters, sampled from a vast parameter space characterized by\nhigh-dimensional combination (up to $3^{27}$), can accurately and quickly infer\nthe junction temperature and hotspot position for any thermal conditions in the\nparameter space. Moreover, it shows good generalizability for other thermal\nconditions not considered in the parameter space. The data set is constructed\nusing accurate finite element solvers. This method not only minimizes the\nreliance on costly experimental tests and extensive computational resources for\nfinite element analysis but also accelerates the design and optimization of\ncomplex HBM systems, making it a valuable tool for improving thermal management\nand performance in high-performance computing applications."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02873",
    "c_title":[
      "Pseudo-Anosov surfaces and Dynamics in 3-manifolds"
    ],
    "c_abstract":[
      "We determine which closed orientable $3$-manifolds $M$ admit a\nself-homeomorphism restricting to a pseudo-Anosov map on an incompressible\nsubsurface $\\Sigma$, which we call a pseudo-Anosov surface. When $M$ is\nirreducible, we show that the self-homeomorphism of $M$ is isotopic rel\n$\\Sigma$ to a \"partially pseudo-Anosov\" homeomorphism, a notion that we will\nintroduce. This is motivated by the corresponding results for Anosov tori in\nirreducible $3$-manifolds, and the connection to partially hyperbolic\ndiffeomorphisms, obtained by F. Rodriguez-Hertz, J. Rodriguez-Hertz and R.\nUres."
    ],
    "c_categories":[
      [
        "math.DS",
        "math.GR",
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-959",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17524",
    "b_title":[
      "Multimodal Bearing Fault Classification Under Variable Conditions: A 1D\n  CNN with Transfer Learning"
    ],
    "b_abstract":[
      "Bearings play an integral role in ensuring the reliability and efficiency of\nrotating machinery - reducing friction and handling critical loads. Bearing\nfailures that constitute up to 90% of mechanical faults highlight the\nimperative need for reliable condition monitoring and fault detection. This\nstudy proposes a multimodal bearing fault classification approach that relies\non vibration and motor phase current signals within a one-dimensional\nconvolutional neural network (1D CNN) framework. The method fuses features from\nmultiple signals to enhance the accuracy of fault detection. Under the baseline\ncondition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the model\nreaches an accuracy of 96% with addition of L2 regularization. This represents\na notable improvement of 2% compared to the non-regularized model. In addition,\nthe model demonstrates robust performance across three distinct operating\nconditions by employing transfer learning (TL) strategies. Among the tested TL\nvariants, the approach that preserves parameters up to the first max-pool layer\nand then adjusts subsequent layers achieves the highest performance. While this\napproach attains excellent accuracy across varied conditions, it requires more\ncomputational time due to its greater number of trainable parameters. To\naddress resource constraints, less computationally intensive models offer\nfeasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal\n1D CNN framework with late fusion and TL strategies lays a foundation for more\naccurate, adaptable, and efficient bearing fault classification in industrial\nenvironments with variable operating conditions."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01889",
    "c_title":[
      "Non-Cooperative Games with Uncertainty"
    ],
    "c_abstract":[
      "This paper introduces a framework for finite non-cooperative games where each\nplayer faces a globally uncertain parameter with no common prior. Every player\nchooses both a mixed strategy and projects an emergent subjective prior to the\nuncertain parameters. We define an \"Extended Equilibrium\" by requiring that no\nplayer can improve her expected utility via a unilateral change of strategy,\nand the emergent subjective priors are such that they maximize the expected\nregret of the players. A fixed-point argument -- based on Brouwer's fixed point\ntheorem and mimicking the construction of Nash -- ensures existence.\nAdditionally, the \"No Fictional Faith\" theorem shows that any subjective\nequilibrium prior must stay non-concentrated if the parameter truly matters to\na player. This approach provides a framework that unifies regret-based\nstatistical decision theory and game theory, yielding a tool for handling\nstrategic decision-making in the presence of deeply uncertain parameters."
    ],
    "c_categories":[
      [
        "econ.TH",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics",
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-960",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08435",
    "b_title":[
      "Stability and Dynamics of Three-Mode Coupling in $\\delta$ Scuti Stars"
    ],
    "b_abstract":[
      "Recent observations of $\\delta$ Scuti stars find evidence of nonlinear\nthree-mode coupling in their oscillation spectra. There are two types of\nthree-mode coupling likely to be important in $\\delta$ Scuti stars: (i) direct\ncoupling, in which two linearly unstable modes (driven by the kappa-mechanism)\nexcite a linearly stable mode, and (ii) parametric coupling, in which one\nlinearly unstable mode excites two linearly stable modes. Breger & Montgomery\n(2014) find especially strong evidence of direct coupling in the $\\delta$ Scuti\nstar KIC 8054146. However, direct coupling is inherently unstable and cannot be\nthe mechanism by which the modes saturate and achieve nonlinear equilibrium. By\nintegrating the amplitude equations of small mode networks, we show that the\nmodes can achieve equilibrium if parametric coupling operates in tandem with\ndirect coupling. Using mode parameters calculated from a $\\delta$ Scuti model,\nwe also find that parametric and direct coupling are likely to be\nsimultaneously active. Importantly, parametric coupling does not necessarily\ndisrupt the correlations found in KIC 8054146 between the amplitudes and phases\nof the directly coupled modes. We conclude that $\\delta$ Scuti stars are likely\nimpacted by both parametric and direct coupling and that accounting for both in\nfuture large mode network calculations may help explain the complicated mode\ndynamics observed in many $\\delta$ Scuti stars."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16471",
    "c_title":[
      "Feature Space Perturbation: A Panacea to Enhanced Transferability\n  Estimation"
    ],
    "c_abstract":[
      "Leveraging a transferability estimation metric facilitates the non-trivial\nchallenge of selecting the optimal model for the downstream task from a pool of\npre-trained models. Most existing metrics primarily focus on identifying the\nstatistical relationship between feature embeddings and the corresponding\nlabels within the target dataset, but overlook crucial aspect of model\nrobustness. This oversight may limit their effectiveness in accurately ranking\npre-trained models. To address this limitation, we introduce a feature\nperturbation method that enhances the transferability estimation process by\nsystematically altering the feature space. Our method includes a Spread\noperation that increases intra-class variability, adding complexity within\nclasses, and an Attract operation that minimizes the distances between\ndifferent classes, thereby blurring the class boundaries. Through extensive\nexperimentation, we demonstrate the efficacy of our feature perturbation method\nin providing a more precise and robust estimation of model transferability.\nNotably, the existing LogMe method exhibited a significant improvement, showing\na 28.84% increase in performance after applying our feature perturbation\nmethod."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-961",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12638",
    "b_title":[
      "Single-Carrier Waveform Design for Joint Sensing and Communication"
    ],
    "b_abstract":[
      "The emergence of 6G wireless networks demands solutions that seamlessly\nintegrate communication and sensing. This letter proposes a novel waveform\ndesign for joint sensing and communication (JSAC) systems, combining\nsingle-carrier interleaved frequency division multiplexing (SC-IFDM), a 5G\ncommunication candidate signal, with frequency modulated continuous wave\n(FMCW), widely used for sensing. The proposed waveform leverages the sparse\nnature of FMCW within SC-IFDM to achieve orthogonal integration in three steps:\nSC-IFDM symbols are allocated alongside the sparse FMCW, followed by the\nSC-IFDM transform into the time domain, and a cyclic prefix (CP) is applied in\nwhich phase shifts are introduced to the FMCW. Additionally, an enhanced\nchannel estimation method is incorporated to boost system performance.\nSimulation results demonstrate the proposed waveform's ability to deliver\nhigh-resolution sensing and superior communication performance, surpassing\ntraditional multicarrier designs."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17566",
    "c_title":[
      "Viscous accretion and ejection from tori around black holes in general\n  relativity"
    ],
    "c_abstract":[
      "We systematically perform long-term (millions of Schwarzschild time)\naxisymmetric viscous hydrodynamics simulations for tori around black holes in\ngeneral relativity supposing the super Eddington accretion flow. The initial\ncondition for the tori is modeled simply by the Fishbone-Moncrief torus with a\nconstant specific angular momentum $j$ but with a wide variety of $j$. We find\nthat for a given density profile, the fraction of the mass infall onto the\nblack hole is approximately proportional to $j^{-1}$, indicating that only a\nminor fraction of the matter in the torus formed far from the black hole falls\ninto the black hole while the majority is ejected with the typical average\nvelocity of a few percent of the speed of light. We also find that the mass\nejection is driven only outside $\\approx 2\\,r_\\mathrm{ISCO}$ where\n$r_\\mathrm{ISCO}$ is the areal radius of the innermost stable circular orbit\naround black holes, which depends strongly on the black hole spin. We derive an\napproximate fitting formula for the spin-dependence on the mass infall fraction\nas $\\propto r_\\mathrm{ISCO}^{0.7}$, which suggests that the rapid growth of\nsupermassive black holes proceeded primarily by the accretion of the matter\nwith the angular momentum counter-rotating with the black hole spin."
    ],
    "c_categories":[
      [
        "astro-ph.HE",
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-962",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02846",
    "b_title":[
      "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs"
    ],
    "b_abstract":[
      "Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or\nnonsensical information) when serving as AI assistants in various domains.\nSince hallucinations always come with truthful content in the LLM responses,\nprevious factuality alignment methods that conduct response-level preference\nlearning inevitably introduced noises during training. Therefore, this paper\nproposes a fine-grained factuality alignment method based on Direct Preference\nOptimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as\nmask signals, Mask-DPO only learns from factually correct sentences in the\npreferred samples and prevents the penalty on factual contents in the not\npreferred samples, which resolves the ambiguity in the preference learning.\nExtensive experimental results demonstrate that Mask-DPO can significantly\nimprove the factuality of LLMs responses to questions from both in-domain and\nout-of-domain datasets, although these questions and their corresponding topics\nare unseen during training. Only trained on the ANAH train set, the score of\nLlama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%,\neven surpassing the score of Llama3.1-70B-Instruct (53.44%), while its\nFactScore on the out-of-domain Biography dataset is also improved from 30.29%\nto 39.39%. We further study the generalization property of Mask-DPO using\ndifferent training sample scaling strategies and find that scaling the number\nof topics in the dataset is more effective than the number of questions. We\nprovide a hypothesis of what factual alignment is doing with LLMs, on the\nimplication of this phenomenon, and conduct proof-of-concept experiments to\nverify it. We hope the method and the findings pave the way for future research\non scaling factuality alignment."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12336",
    "c_title":[
      "Controlling complex dynamics with synthetic magnetism in optomechanical\n  systems: A route to enhanced sensor performance"
    ],
    "c_abstract":[
      "This paper explores the intricate dynamical behavior of an optomechanical\nsystem consisting of an optical resonator that drives two mechanically coupled\nresonators via phase-dependent phonon hopping. Addressing previous limitations\nin comprehending the dynamics of such systems, we derive the system's\nsemiclassical dynamical equations from the optomechanical Hamiltonian,\nresulting in a set of six first-order ordinary differential equations. We\nsubsequently illustrate the emergence of novel dynamic behaviors and\ndemonstrate their pertinence for the development of new devices. The system\nexhibits either two or no steady states, contingent upon the incident\nradiation, mechanical coupling rate, and frequency detuning. Our stability\nanalysis indicates that the stability of these states is determined by the same\nfactors. We identify complex dynamical behaviors, including monostable and\nbistable self-excited quasi-periodic characteristics, the coexistence of hidden\noscillations, and chaotic dynamics, and we propose a method for their control.\nThese findings bear significant implications for applications in\nultra-sensitive sensing, chaos-based communication, and tunable phononic\ncircuits. This study enhances the broader understanding of complex dynamical\nsystems in optomechanics, paving the way for the development of advanced\noptomechanical devices with controlled dynamics for stable and reliable\noperation."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-963",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12059",
    "b_title":[
      "On Product Lie Algebroids, and Collective Motion"
    ],
    "b_abstract":[
      "This work explores the geometrical\/algebraic framework of Lie algebroids,\nwith a specific focus on the decoupling and coupling phenomena within the\nbicocycle double cross product realization. The bicocycle double cross product\ntheory serves as the most general method for (de)coupling an algebroid into the\ndirect sum of two vector bundles in the presence of mutual\n\\textit{representations}, along with two twisted cocycle terms. Consequently,\nit encompasses unified product, double cross product (matched pairs),\nsemi-direct product, and cocycle extension frameworks as particular instances.\nIn addition to algebraic constructions, the research extends to both reversible\nand irreversible Lagrangian and Hamiltonian dynamics on (de)coupled Lie\nalgebroids, as well as Euler-Poincar\\'{e}-(Herglotz) and Lie-Poisson-(Herglotz)\ndynamics on (de)coupled Lie algebras, providing insights into potential\nphysical applications."
    ],
    "b_categories":[
      [
        "math-ph",
        "math.DG",
        "math.MP"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03500",
    "c_title":[
      "The ubiquity of variable radio emission and spin-down rates in pulsars"
    ],
    "c_abstract":[
      "Pulsars are often lauded for their (relative) rotational and radio emission\nstability over long time scales. However, long-term observing programmes are\nidentifying an increasing number of pulsars that deviate from this preconceived\nnotion. Using Gaussian process regression and Bayesian inference techniques, we\ninvestigated the emission and rotational stability of 259 isolated radio\npulsars that have been monitored using Murriyang, the Parkes 64 m radio\ntelescope, over the past three decades. We found that 238 pulsars display\nsignificant variability in their spin-down rates, 52 of which also exhibit\nchanges in profile shape. Including 23 known state-switching pulsars, this\nrepresents the largest catalogue of variable pulsars identified to date and\nindicates that these behaviours are ubiquitous among the wider population. The\nintensity of spin-down fluctuations positively scales with increasing pulsar\nspin-down rate, with only a marginal dependence on spin-frequency. This may\nhave substantial implications for ongoing searches for gravitational waves in\nthe ensemble timing of millisecond pulsars. We also discuss challenges in\nexplaining the physical origins of quasi-periodic and transient\nprofile\/spin-down variations detected among a subset of our pulsars."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-964",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15370",
    "b_title":[
      "Tangles: Unpacking Extended Collision Experiences with Soma Trajectories"
    ],
    "b_abstract":[
      "We reappraise the idea of colliding with robots, moving from a position that\ntries to avoid or mitigate collisions to one that considers them an important\nfacet of human interaction. We report on a soma design workshop that explored\nhow our bodies could collide with telepresence robots, mobility aids, and a\nquadruped robot. Based on our findings, we employed soma trajectories to\nanalyse collisions as extended experiences that negotiate key transitions of\nconsent, preparation, launch, contact, ripple, sting, untangle, debris and\nreflect. We then employed these ideas to analyse two collision experiences, an\naccidental collision between a person and a drone, and the deliberate design of\na robot to play with cats, revealing how real-world collisions involve the\ncomplex and ongoing entanglement of soma trajectories. We discuss how viewing\ncollisions as entangled trajectories, or tangles, can be used analytically, as\na design approach, and as a lens to broach ethical complexity."
    ],
    "b_categories":[
      [
        "cs.HC",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18346",
    "c_title":[
      "Testing Thresholds and Spectral Properties of High-Dimensional Random\n  Toroidal Graphs via Edgeworth-Style Expansions"
    ],
    "c_abstract":[
      "We study high-dimensional random geometric graphs (RGGs) of edge-density $p$\nwith vertices uniformly distributed on the $d$-dimensional torus and edges\ninserted between sufficiently close vertices with respect to an $L_q$-norm. We\nfocus on distinguishing an RGG from an Erd\\H{o}s--R\\'enyi (ER) graph if both\nmodels have edge probability $p$. So far, most results considered either\nspherical RGGs with $L_2$-distance or toroidal RGGs under $L_\\infty$-distance.\nHowever, for general $L_q$-distances, many questions remain open, especially if\n$p$ is allowed to depend on $n$. The main reason for this is that RGGs under\n$L_q$-distances can not easily be represented as the logical AND of their\n1-dimensional counterparts, as for $L_\\infty$ geometries. To overcome this, we\ndevise a novel technique for quantifying the dependence between edges based on\nmodified Edgeworth expansions.\n  Our technique yields the first tight algorithmic upper bounds for\ndistinguishing toroidal RGGs under general $L_q$ norms from ER-graphs for fixed\n$p$ and $q$. We achieve this by showing that signed triangles can distinguish\nthe two models when $d\\ll n^3p^3$ for the whole regime of $c\/n<p<1$.\nAdditionally, our technique yields an improved information-theoretic lower\nbound for this task, showing that the two distributions converge whenever\n$d=\\tilde{\\Omega}(n^3p^2)$, which is just as strong as the currently best known\nlower bound for spherical RGGs in case of general $p$ from Liu et al.\n[STOC'22]. Finally, our expansions allow us to tightly characterize the\nspectral properties of toroidal RGGs both under $L_q$-distances for fixed $1\\le\nq<\\infty$, and $L_\\infty$-distance. Our results partially resolve a conjecture\nof Bangachev and Bresler [COLT'24] and prove that the distance metric, rather\nthan the underlying space, is responsible for the observed differences in the\nbehavior of spherical and toroidal RGGs."
    ],
    "c_categories":[
      [
        "math.PR",
        "math.ST",
        "stat.TH"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-965",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01053",
    "b_title":[
      "Commitment, Conflict, and Status Quo in Bargaining"
    ],
    "b_abstract":[
      "Each period, two players bargain over a unit of surplus. Each player chooses\nbetween remaining flexible and committing to a take-it-or-leave-it offer at a\ncost. If players' committed demands are incompatible, then the current-period\nsurplus is destroyed in the conflict. When both players are flexible, the\nsurplus is split according to the status quo, which is the division in the last\nperiod where there was no conflict. We show that when players are patient and\nthe cost of commitment is small, there exist a class of symmetric Markov\nPerfect equilibria that are asymptotically efficient and renegotiation proof,\nin which players commit to fair demands in almost all periods."
    ],
    "b_categories":[
      [
        "cs.GT",
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.04718",
    "c_title":[
      "Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation"
    ],
    "c_abstract":[
      "Scene flow estimation is a foundational task for many robotic applications,\nincluding robust dynamic object detection, automatic labeling, and sensor\nsynchronization. Two types of approaches to the problem have evolved: 1)\nSupervised and 2) optimization-based methods. Supervised methods are fast\nduring inference and achieve high-quality results, however, they are limited by\nthe need for large amounts of labeled training data and are susceptible to\ndomain gaps. In contrast, unsupervised test-time optimization methods do not\nface the problem of domain gaps but usually suffer from substantial runtime,\nexhibit artifacts, or fail to converge to the right solution. In this work, we\nmitigate several limitations of existing optimization-based methods. To this\nend, we 1) introduce a simple voxel grid-based model that improves over the\nstandard MLP-based formulation in multiple dimensions and 2) introduce a new\nmultiframe loss formulation. 3) We combine both contributions in our new\nmethod, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only\nby EulerFlow among unsupervised methods while achieving comparable performance\nat a fraction of the computational cost. Floxels achieves a massive speedup of\nmore than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10\nminutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels\nachieves a speedup of ~14x."
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-966",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03326",
    "b_title":[
      "Arc Blanc: a real time ocean simulation framework"
    ],
    "b_abstract":[
      "The oceans cover the vast majority of the Earth. Therefore, their simulation\nhas many scientific, industrial and military interests, including computer\ngraphics domain. By fully exploiting the multi-threading power of GPU and CPU,\ncurrent state-of-the-art tools can achieve real-time ocean simulation, even if\nit is sometimes needed to reduce the physical realism for large scenes.\nAlthough most of the building blocks for implementing an ocean simulator are\ndescribed in the literature, a clear explanation of how they interconnect is\nlacking. Hence, this paper proposes to bring all these components together,\ndetailing all their interactions, in a comprehensive and fully described\nreal-time framework that simulates the free ocean surface and the coupling\nbetween solids and fluid. This article also presents several improvements to\nenhance the physical realism of our model. The two main ones are: calculating\nthe real-time velocity of ocean fluids at any depth; computing the input of the\nfluid to solid coupling algorithm."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13718",
    "c_title":[
      "On a polygon version of Wiegmann-Zabrodin formula"
    ],
    "c_abstract":[
      "Let $P$ be a convex polygon in ${\\mathbb C}$ and let $\\Delta_{D, P}$ be the\noperator of the Dirichlet boundary value problem for the Lapalcian\n$\\Delta=-4\\partial_z\\partial_{\\bar z}$ in $P$. We derive a variational formula\nfor the logarithm of the $\\zeta$-regularized determinant of $\\Delta_{D, P}$ for\narbitrary infinitesimal deformations of the polygon $P$ in the class of\npolygons (with the same number of vertices). For a simply connected domain with\nsmooth boundary such a formula was recently discovered by Wiegmann and Zabrodin\nas a non obvious corollary of the Alvarez variational formula, for domains with\ncorners this approach is unavailable (at least for those deformations that do\nnot preserve the corner angles) and we have to develop another one."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.MP",
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-967",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11710",
    "b_title":[
      "The Worse The Better: Content-Aware Viewpoint Generation Network for\n  Projection-related Point Cloud Quality Assessment"
    ],
    "b_abstract":[
      "Through experimental studies, however, we observed the instability of final\npredicted quality scores, which change significantly over different viewpoint\nsettings. Inspired by the \"wooden barrel theory\", given the default\ncontent-independent viewpoints of existing projection-related PCQA approaches,\nthis paper presents a novel content-aware viewpoint generation network (CAVGN)\nto learn better viewpoints by taking the distribution of geometric and\nattribute features of degraded point clouds into consideration. Firstly, the\nproposed CAVGN extracts multi-scale geometric and texture features of the\nentire input point cloud, respectively. Then, for each default\ncontent-independent viewpoint, the extracted geometric and texture features are\nrefined to focus on its corresponding visible part of the input point cloud.\nFinally, the refined geometric and texture features are concatenated to\ngenerate an optimized viewpoint. To train the proposed CAVGN, we present a\nself-supervised viewpoint ranking network (SSVRN) to select the viewpoint with\nthe worst quality projected image to construct a default-optimized viewpoint\ndataset, which consists of thousands of paired default viewpoints and\ncorresponding optimized viewpoints. Experimental results show that the\nprojection-related PCQA methods can achieve higher performance using the\nviewpoints generated by the proposed CAVGN."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10409",
    "c_title":[
      "Cyclicity of sliding cycles with singularities of regularized piecewise\n  smooth visible-invisible two-folds"
    ],
    "c_abstract":[
      "In this paper we study the cyclicity of sliding cycles for regularized\npiecewise smooth visible-invisible two-folds, in the presence of singularities\nof the Filippov sliding vector field located away from two-folds. We obtain a\nslow-fast system after cylindrical blow-up and use a well-known connection\nbetween the divergence integral along orbits and transition maps for vector\nfields. Since properties of the divergence integral depend on the location and\nmultiplicity of singularities, we divide the sliding cycles into different\nclasses, which can then produce different types of cyclicity results. As an\nexample, we apply our results to regularized piecewise linear systems."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-968",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00416",
    "b_title":[
      "GO-GAN: Geometry Optimization Generative Adversarial Network for\n  Achieving Optimized Structures with Targeted Physical Properties"
    ],
    "b_abstract":[
      "This paper presents GO-GAN, a novel Generative Adversarial Network (GAN)\narchitecture for geometry optimization (GO), specifically to generate\nstructures based on user-specified input parameters. The architecture for\nGO-GAN proposed here combines a \\texttt{Pix2Pix} GAN with a new input\nmechanism, involving a dynamic batch gradient descent-based training loop that\nleverages dataset symmetries. The model, implemented here using\n\\texttt{TensorFlow} and \\texttt{Keras}, is trained using input images\nrepresenting scalar physical properties generated by a custom MatLab code.\nAfter training, GO-GAN rapidly generates optimized geometries from input images\nrepresenting scalar inputs of the physical properties. Results demonstrate\nGO-GAN's ability to produce acceptable designs with desirable variations. These\nvariations are followed by the influence of discriminators during training and\nare of practical significance in ensuring adherence to specifications while\nenabling creative exploration of the design space."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05681",
    "c_title":[
      "A Belyi-type criterion for vector bundles on curves defined over a\n  number field"
    ],
    "c_abstract":[
      "Let $X_0$ be an irreducible smooth projective curve defined over\n$\\overline{\\mathbb Q}$ and $f_0 : X_0 \\rightarrow\n\\mathbb{P}^1_{\\overline{\\mathbb Q}}$ a nonconstant morphism whose branch locus\nis contained in the subset $\\{0,1, \\infty\\} \\subset\n\\mathbb{P}^1_{\\overline{\\mathbb Q}}$. For any vector bundle $E$ on $X =\nX_0\\times_{{\\rm Spec}\\,\\overline{\\mathbb Q}} {\\rm Spec} \\mathbb{C}$, consider\nthe direct image $f_*E$ on $\\mathbb{P}^1_{\\mathbb C}$, where $f= (f_0)_{\\mathbb\nC}$. It decomposes into a direct sum of line bundles and also it has a natural\nparabolic structure. We prove that $E$ is the base change, to $\\mathbb C$, of a\nvector bundle on $X_0$ if and only if there is an isomorphism $f_*E\n\\stackrel{\\sim}{\\rightarrow} \\bigoplus_{i=1}^r {\\mathcal O}_{{\\mathbb\nP}^1_{\\mathbb C}}(m_i)$, where $r = {\\rm rank}(f_*E)$, that takes the parabolic\nstructure on $f_*E$ to a parabolic structure on $\\bigoplus_{i=1}^r {\\mathcal\nO}_{{\\mathbb P}^1_{\\mathbb C}}(m_i)$ defined over $\\overline{\\mathbb Q}$."
    ],
    "c_categories":[
      [
        "math.AG",
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-969",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05848",
    "b_title":[
      "A simple derived categorical generalization of Ulrich bundles"
    ],
    "b_abstract":[
      "We define special objects, Ulrich objects, on a derived category of polarized\nsmooth projective variety as a generalization of Ulrich bundles to the derived\ncategory. These are defined by the cohomological conditions that are the same\nform as a cohomological criterion determining Ulrichness for sheaves. This\npaper gives a characterization of the Ulrich object similar to the one in\n[ES03]. As an application, we have provided a new approach to the\nEisenbud-Schreyer question by using the notions of the generator of the derived\ncategory. We also have given an example of Ulrich objects that are not sheaf by\nthe Yoneda extension."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02259",
    "c_title":[
      "Expensive Homeomorphism of Convex Bodies"
    ],
    "c_abstract":[
      "In this paper, we address the longstanding question of whether expansive\nhomeomorphisms can exist within convex bodies in Euclidean spaces. Utilizing\nfundamental tools from topology, including the Borsuk-Ulam theorem and\nBrouwer's fixed-point theorem, we establish the nonexistence of such mappings.\nThrough an inductive approach based on dimension and the extension of boundary\nhomeomorphisms, we demonstrate that expansive homeomorphisms are incompatible\nwith the compact and convex structure of these bodies. This work highlights the\ninterplay between topological principles and metric geometry, offering new\ninsights into the constraints imposed by convexity."
    ],
    "c_categories":[
      [
        "cs.CG",
        "math.GN",
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-970",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08530",
    "b_title":[
      "Residually Dominated Groups in Henselian Valued Fields of\n  Equicharacteristic Zero"
    ],
    "b_abstract":[
      "We introduce \\emph{residually dominated groups} in pure henselian valued\nfields of equicharacteristic zero as an analogue of stably dominated groups\nintroduced by Hrushovski and Rideau-Kikuchi. We show that when $G$ is a\nresidually dominated group, there is a finite-to-one group homomorphism from\nits connected component into a connected stably dominated group, and we study\nthe functoriality and universality properties of this map. Moreover, we prove\nthat there is a group homomorphism into a definable group in the residue field\nthat witnesses the residual domination. In our proofs, we use the results of\nMontenegro, Onshuus, and Simon on groups definable in $\\mathrm{NTP}_2$-theories\nthat extend the theory of fields. Along the way, we also provide an algebraic\ncharacterization of residually dominated types, generalizing the work by Ealy,\nHaskell and Simon for stably dominated types in algebraically closed valued\nfields and study the properties of residually dominated types."
    ],
    "b_categories":[
      [
        "math.LO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17846",
    "c_title":[
      "Predicting the spectrum and decay constants of positive-parity\n  heavy-strange mesons using domain-wall fermions"
    ],
    "c_abstract":[
      "We present a lattice-QCD calculation of the masses and decay constants of the\npositive-parity heavy-strange mesons $D^*_{s0}$, $D_{s1}$, $B^*_{s0}$, and\n$B_{s1}$. The calculations are performed with domain-wall fermions for the\nlight and strange quarks and an anisotropic clover action for the charm and\nbottom quarks. We use seven different RBC\/UKQCD ensembles with pion masses\nranging from a near-physical 139 MeV up to 431 MeV. We consider two different\nanalysis types, with or without two-meson operators at the source. We observe\nthe expected below-threshold ground states. The fits without the two-meson\noperators appear to be more stable, but may overestimate the ground-state\nenergies, while preliminary fits with two-meson operators at the source only\nappear to underestimate the ground-state energies."
    ],
    "c_categories":[
      [
        "hep-lat",
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-971",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01390",
    "b_title":[
      "Scalable and Accurate Application-Level Crash-Consistency Testing via\n  Representative Testing"
    ],
    "b_abstract":[
      "Crash consistency is essential for applications that must persist data.\nCrash-consistency testing has been commonly applied to find crash-consistency\nbugs in applications. The crash-state space grows exponentially as the number\nof operations in the program increases, necessitating techniques for pruning\nthe search space. However, state-of-the-art crash-state space pruning is far\nfrom ideal. Some techniques look for known buggy patterns or bound the\nexploration for efficiency, but they sacrifice coverage and may miss bugs\nlodged deep within applications. Other techniques eliminate redundancy in the\nsearch space by skipping identical crash states, but they still fail to scale\nto larger applications.\n  In this work, we propose representative testing: a new crash-state space\nreduction strategy that achieves high scalability and high coverage. Our key\nobservation is that the consistency of crash states is often correlated, even\nif those crash states are not identical. We build Pathfinder, a\ncrash-consistency testing tool that implements an update behaviors-based\nheuristic to approximate a small set of representative crash states.\n  We evaluate Pathfinder on POSIX-based and MMIO-based applications, where it\nfinds 18 (7 new) bugs across 8 production-ready systems. Pathfinder scales more\neffectively to large applications than prior works and finds 4x more bugs in\nPOSIX-based applications and 8x more bugs in MMIO-based applications compared\nto state-of-the-art systems."
    ],
    "b_categories":[
      [
        "cs.OS",
        "cs.PL",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09543",
    "c_title":[
      "The main jet axis of the W49B supernova remnant"
    ],
    "c_abstract":[
      "We identify an axis connecting two opposite `ears' in the supernova remnant\nW49B and morphological signatures of three arcs around this axis that we claim\nare sections of full circum-jet rings. Based on recent identifications of\nmorphological signatures of jets in core-collapse supernovae (CCSNe), including\nejecta-rich axes, we reexamine images of W49B and identify a heavy element-rich\nprotrusion (ear) as a jet-inflated structure. We identify the opposite ear and\na clump at its tip as the signature of the opposite jets. The line connecting\nthe two clumps at the tips of the two opposite ears forms the main jet axis of\nW49B. We compare the three arcs around the main jet axis in W49B to the\ncircum-jet rings of the jets in the Cygnus A galaxy and deduce that these arcs\nare sections of full circum-jet rings in W49B. In W49B, the jets are long gone,\nas in some planetary nebulae with circum-jet rings. Identifying the main jet\naxis is incompatible with a type Ia supernova. It leaves two possibilities:\nthat jets exploded W49B as a CCSN, i.e., the jittering jets explosion mechanism\nwhere the pair of jets we identify is one of many that exploded the star, or\nthat the explosion was a common envelope jet supernova with a thermonuclear\noutburst, i.e., both the pair of jets and thermonuclear outburst exploded the\ncore of a red supergiant star as a pre-existing neutron star tidally destroyed\nit."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-972",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21199",
    "b_title":[
      "Negative correlations in Ising models of credit risk"
    ],
    "b_abstract":[
      "We analyze a subclass of Ising models in the context of credit risk, focusing\non Dandelion models when the correlations $\\rho$ between the central node and\neach non-central node are negative. We establish the possible range of values\nfor $\\rho$ and derive an explicit formula linking the correlation between any\npair of non-central nodes to $\\rho$. The paper concludes with a simulation\nstudy."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.09941",
    "c_title":[
      "TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points\n  for 3D Environment Awareness"
    ],
    "c_abstract":[
      "3D semantic occupancy has rapidly become a research focus in the fields of\nrobotics and autonomous driving environment perception due to its ability to\nprovide more realistic geometric perception and its closer integration with\ndownstream tasks. By performing occupancy prediction of the 3D space in the\nenvironment, the ability and robustness of scene understanding can be\neffectively improved. However, existing occupancy prediction tasks are\nprimarily modeled using voxel or point cloud-based approaches: voxel-based\nnetwork structures often suffer from the loss of spatial information due to the\nvoxelization process, while point cloud-based methods, although better at\nretaining spatial location information, face limitations in representing\nvolumetric structural details. To address this issue, we propose a dual-modal\nprediction method based on 3D Gaussian sets and sparse points, which balances\nboth spatial location and volumetric structural information, achieving higher\naccuracy in semantic occupancy prediction. Specifically, our method adopts a\nTransformer-based architecture, taking 3D Gaussian sets, sparse points, and\nqueries as inputs. Through the multi-layer structure of the Transformer, the\nenhanced queries and 3D Gaussian sets jointly contribute to the semantic\noccupancy prediction, and an adaptive fusion mechanism integrates the semantic\noutputs of both modalities to generate the final prediction results.\nAdditionally, to further improve accuracy, we dynamically refine the point\ncloud at each layer, allowing for more precise location information during\noccupancy prediction. We conducted experiments on the Occ3DnuScenes dataset,\nand the experimental results demonstrate superior performance of the proposed\nmethod on IoU based metrics."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-973",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03905",
    "b_title":[
      "Partially hyperbolic symplectomorphism with C^1 bundles"
    ],
    "b_abstract":[
      "We prove dynamical coherence for partial hyperbolic symplectomorphism in\ndimension 4 whose stable and unstable bundles are C^1."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09780",
    "c_title":[
      "MUSE observations of V1425 Aql reveal an arc-shaped nova shell"
    ],
    "c_abstract":[
      "Nova shells are the remnants of a nova eruption in a cataclysmic variable\nsystem. By studying their geometry we can better understand the physical\nmechanisms that shape them during the nova eruption. A nova shell that\nchallenges our current understanding of these processes is the shell observed\naround V1425 Aql. It has at least two different components: an inner and\nsymmetric shell, and an outer and asymmetric shell, with the latter expanding\nfaster than the former. The physical reason behind the asymmetric ejecta is not\nclear. We aim to characterize the properties and differences between these two\ncomponents to understand the origin behind the unusual shape. We acquired MUSE\ndata to study the spatial position and kinematics of the expanding gas across\nthe shell. Our analysis includes channel maps, position-velocity diagrams, and\nthe reconstruction of the 3D geometry of the nova shell. Several emission lines\nare detected within the MUSE wavelength coverage, including but not limited to\nBalmer, Oxygen, Nitrogen, and Helium lines. There are significant differences\nin the spectra of the inner and outer shells, with the latter being observed\nonly in forbidden transitions, while the inner shows a mix of forbidden and\nallowed ones. Our analysis reveals that the outer shell has a geometry\nconsistent with an arc-shaped structure that partially encircles the more\nspherical inner shell. Within the inner shell, clumpy structures start to be\nnoticeable in the lines of H$\\alpha$+[Nii]. We have constrained the geometry of\nthe outer shell to an arc-shaped structure, although the physical reason behind\nits origin is still eluding us. Further monitoring of the evolution of both\nshells in this object might help to clarify the mechanism behind this unusual\nconfiguration."
    ],
    "c_categories":[
      [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-974",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12119",
    "b_title":[
      "Photostriction Facilitates Relaxation of Lattice Distortion in\n  Two-Dimensional Perovskites"
    ],
    "b_abstract":[
      "The photostriction effect, a light-induced mechanical deformation in\nmaterials, originates from the intricate interplay between lattice structure\nand electronic excitation. In photovoltaic semiconductors, this effect plays a\ncrucial role in shaping non-equilibrium structural responses, yet its\nfundamental mechanism remains elusive. Here, we uncover lattice expansion and\nstructural reconfiguration in two-dimensional (2D) perovskites driven by\nphotoinduced excitation using first-principles calculations. Our findings\nreveal that the photoinduced carriers lead to a substantial lattice expansion\nby about 2%. The expanded lattice facilitates strain relaxation with the\namplitude of 20% by increasing interatomic distances and reducing internal\nstresses, thereby enhancing structural stability. The lattice dynamics can be\nsystematically engineered through photodoping density, unveiling a new pathway\nto modulate light-matter interactions in 2D perovskites. These insights not\nonly advance the understanding of optically driven structural dynamics but also\noffer a guiding principle for optimizing next-generation high-efficiency\nphotovoltaic devices and optoelectronics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07729",
    "c_title":[
      "Autoencoded UMAP-Enhanced Clustering for Unsupervised Learning"
    ],
    "c_abstract":[
      "We propose a novel approach to unsupervised learning by constructing a\nnon-linear embedding of the data into a low-dimensional space followed by any\nconventional clustering algorithm. The embedding promotes clusterability of the\ndata and is comprised of two mappings: the encoder of an autoencoder neural\nnetwork and the output of UMAP algorithm. The autoencoder is trained with a\ncomposite loss function that incorporates both a conventional data\nreconstruction as a regularization component and a clustering-promoting\ncomponent built using the spectral graph theory. The two embeddings and the\nsubsequent clustering are integrated into a three-stage unsupervised learning\nframework, referred to as Autoencoded UMAP-Enhanced Clustering (AUEC). When\napplied to MNIST data, AUEC significantly outperforms the state-of-the-art\ntechniques in terms of clustering accuracy."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-975",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08622",
    "b_title":[
      "Forecasting Drought Using Machine Learning in California"
    ],
    "b_abstract":[
      "Drought is a frequent and costly natural disaster in California, with major\nnegative impacts on agricultural production and water resource availability,\nparticularly groundwater. This study investigated the performance of applying\ndifferent machine learning approaches to predicting the U.S. Drought Monitor\nclassification in California. Four approaches were used: a convolutional neural\nnetwork (CNN), random forest, XGBoost, and long short term memory (LSTM)\nrecurrent neural network, and compared to a baseline persistence model. We\nevaluated the models' performance in predicting severe drought (USDM drought\ncategory D2 or higher) using a macro F1 binary classification metric. The LSTM\nmodel emerged as the top performer, followed by XGBoost, CNN, and random\nforest. Further evaluation of our results at the county level suggested that\nthe LSTM model would perform best in counties with more consistent drought\npatterns and where severe drought was more common, and the LSTM model would\nperform worse where drought scores increased rapidly. Utilizing 30 weeks of\nhistorical data, the LSTM model successfully forecasted drought scores for a\n12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to less\nthan half a drought category on a scale of 0 to 5. Additionally, the LSTM\nachieved a macro F1 score of 0.9, indicating high accuracy in binary\nclassification for severe drought conditions. Evaluation of different window\nand future horizon sizes in weeks suggested that at least 24 weeks of data\nwould result in the best performance, with best performance for shorter horizon\nsizes, particularly less than eight weeks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16446",
    "c_title":[
      "Auxiliary Discrminator Sequence Generative Adversarial Networks\n  (ADSeqGAN) for Few Sample Molecule Generation"
    ],
    "c_abstract":[
      "In this work, we introduce Auxiliary Discriminator Sequence Generative\nAdversarial Networks (ADSeqGAN), a novel approach for molecular generation in\nsmall-sample datasets. Traditional generative models often struggle with\nlimited training data, particularly in drug discovery, where molecular datasets\nfor specific therapeutic targets, such as nucleic acids binders and central\nnervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by\nintegrating an auxiliary random forest classifier as an additional\ndiscriminator into the GAN framework, significantly improves molecular\ngeneration quality and class specificity.\n  Our method incorporates pretrained generator and Wasserstein distance to\nenhance training stability and diversity. We evaluate ADSeqGAN on a dataset\ncomprising nucleic acid-targeting and protein-targeting small molecules,\ndemonstrating its superior ability to generate nucleic acid binders compared to\nbaseline models such as SeqGAN, ORGAN, and MolGPT. Through an oversampling\nstrategy, ADSeqGAN also significantly improves CNS drug generation, achieving a\nhigher yield than traditional de novo models. Critical assessments, including\ndocking simulations and molecular property analysis, confirm that\nADSeqGAN-generated molecules exhibit strong binding affinities, enhanced\nchemical diversity, and improved synthetic feasibility.\n  Overall, ADSeqGAN presents a novel framework for generative molecular design\nin data-scarce scenarios, offering potential applications in computational drug\ndiscovery. We have demonstrated the successful applications of ADSeqGAN in\ngenerating synthetic nucleic acid-targeting and CNS drugs in this work."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-976",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03582",
    "b_title":[
      "Scaling Crowdsourced Election Monitoring: Construction and Evaluation of\n  Classification Models for Multilingual and Cross-Domain Classification\n  Settings"
    ],
    "b_abstract":[
      "The adoption of crowdsourced election monitoring as a complementary\nalternative to traditional election monitoring is on the rise. Yet, its\nreliance on digital response volunteers to manually process incoming election\nreports poses a significant scaling bottleneck. In this paper, we address the\nchallenge of scaling crowdsourced election monitoring by advancing the task of\nautomated classification of crowdsourced election reports to multilingual and\ncross-domain classification settings. We propose a two-step classification\napproach of first identifying informative reports and then categorising them\ninto distinct information types. We conduct classification experiments using\nmultilingual transformer models such as XLM-RoBERTa and multilingual embeddings\nsuch as SBERT, augmented with linguistically motivated features. Our approach\nachieves F1-Scores of 77\\% for informativeness detection and 75\\% for\ninformation type classification. We conduct cross-domain experiments, applying\nmodels trained in a source electoral domain to a new target electoral domain in\nzero-shot and few-shot classification settings. Our results show promising\npotential for model transfer across electoral domains, with F1-Scores of 59\\%\nin zero-shot and 63\\% in few-shot settings. However, our analysis also reveals\na performance bias in detecting informative English reports over Swahili,\nlikely due to imbalances in the training data, indicating a need for caution\nwhen deploying classification models in real-world election scenarios."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16824",
    "c_title":[
      "Posterior Inference with Diffusion Models for High-dimensional Black-box\n  Optimization"
    ],
    "c_abstract":[
      "Optimizing high-dimensional and complex black-box functions is crucial in\nnumerous scientific applications. While Bayesian optimization (BO) is a\npowerful method for sample-efficient optimization, it struggles with the curse\nof dimensionality and scaling to thousands of evaluations. Recently, leveraging\ngenerative models to solve black-box optimization problems has emerged as a\npromising framework. However, those methods often underperform compared to BO\nmethods due to limited expressivity and difficulty of uncertainty estimation in\nhigh-dimensional spaces. To overcome these issues, we introduce \\textbf{DiBO},\na novel framework for solving high-dimensional black-box optimization problems.\nOur method iterates two stages. First, we train a diffusion model to capture\nthe data distribution and an ensemble of proxies to predict function values\nwith uncertainty quantification. Second, we cast the candidate selection as a\nposterior inference problem to balance exploration and exploitation in\nhigh-dimensional spaces. Concretely, we fine-tune diffusion models to amortize\nposterior inference. Extensive experiments demonstrate that our method\noutperforms state-of-the-art baselines across various synthetic and real-world\nblack-box optimization tasks. Our code is publicly available\n\\href{https:\/\/github.com\/umkiyoung\/DiBO}{here}"
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-977",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06420",
    "b_title":[
      "Explaining Control Policies through Predicate Decision Diagrams"
    ],
    "b_abstract":[
      "Safety-critical controllers of complex systems are hard to construct\nmanually. Automated approaches such as controller synthesis or learning provide\na tempting alternative but usually lack explainability. To this end, learning\ndecision trees (DTs) have been prevalently used towards an interpretable model\nof the generated controllers. However, DTs do not exploit shared\ndecision-making, a key concept exploited in binary decision diagrams (BDDs) to\nreduce their size and thus improve explainability. In this work, we introduce\npredicate decision diagrams (PDDs) that extend BDDs with predicates and thus\nunite the advantages of DTs and BDDs for controller representation. We\nestablish a synthesis pipeline for efficient construction of PDDs from DTs\nrepresenting controllers, exploiting reduction techniques for BDDs also for\nPDDs."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15685",
    "c_title":[
      "Advancing quantum imaging through learning theory"
    ],
    "c_abstract":[
      "We quantify performance of quantum imaging by modeling it as a learning task\nand calculating the Resolvable Expressive Capacity (REC). Compared to the\ntraditionally applied Fisher information matrix approach, REC provides a\nsingle-parameter interpretation of overall imaging quality for specific\nmeasurements that applies in the regime of finite samples. We first examine\nimaging performance for two-point sources and generally distributed sources,\nreferred to as compact sources, both of which have intensity distributions\nconfined within the Rayleigh limit of the imaging system. Our findings indicate\nthat REC increases stepwise as the sample number reaches certain thresholds,\nwhich are dependent on the source's size. Notably, these thresholds differ\nbetween direct imaging and superresolution measurements (e.g., spatial-mode\ndemultiplexing (SPADE) measurement in the case of Gaussian point spread\nfunctions (PSF)). REC also enables the extension of our analysis to more\ngeneral scenarios involving multiple compact sources, beyond the previously\nstudied scenarios. For closely spaced compact sources with Gaussian PSFs, our\nnewly introduced orthogonalized SPADE method outperforms the naively separate\nSPADE method, as quantified by REC."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [

      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-978",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17687",
    "b_title":[
      "Topological insulator constrictions -- Dirac particles in a\n  magneto-chiral box"
    ],
    "b_abstract":[
      "We study magneto-transport through topological insulator nanowires shaped in\nthe form of a constriction, as can be obtained by etching techniques. The\nmagnetic field is coaxial, potentially turning the nanowire into a\nmagneto-chiral junction. We show in a detailed analytical and numerical study\nthat two main transport regimes emerge, depending on the central narrow region\nbeing short or long as compared to the magnetic length at the junction entrance\nand exit. In both cases the central region hosts Dirac-particle-in-a-box states\ndue to magnetic confinement, whose conductance properties are strongly\ninfluenced by Landau levels at the ends of the constriction. Notably, in the\nlow-energy regime only chiral states with a specific handedness can transport\ncharge across the junction. Based on these properties and general symmetry\nconsiderations we argue that the shaped nanowire should exhibit strong\nmagneto-chiral non-reciprocal transport beyond linear response. We employ a\nnumerical tight-binding implementation of an effective 2D model on a\nnon-homogeneous grid, capable of simulating samples of realistic sizes, and\ntest its soundness against full simulations for scaled-down 3D topological\ninsulator wires."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01119",
    "c_title":[
      "Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic\n  Reconstruction"
    ],
    "c_abstract":[
      "Open-vocabulary panoptic reconstruction offers comprehensive scene\nunderstanding, enabling advances in embodied robotics and photorealistic\nsimulation. In this paper, we propose PanopticRecon++, an end-to-end method\nthat formulates panoptic reconstruction through a novel cross-attention\nperspective. This perspective models the relationship between 3D instances (as\nqueries) and the scene's 3D embedding field (as keys) through their attention\nmap. Unlike existing methods that separate the optimization of queries and keys\nor overlook spatial proximity, PanopticRecon++ introduces learnable 3D\nGaussians as instance queries. This formulation injects 3D spatial priors to\npreserve proximity while maintaining end-to-end optimizability. Moreover, this\nquery formulation facilitates the alignment of 2D open-vocabulary instance IDs\nacross frames by leveraging optimal linear assignment with instance masks\nrendered from the queries. Additionally, we ensure semantic-instance\nsegmentation consistency by fusing query-based instance segmentation\nprobabilities with semantic probabilities in a novel panoptic head supervised\nby a panoptic loss. During training, the number of instance query tokens\ndynamically adapts to match the number of objects. PanopticRecon++ shows\ncompetitive performance in terms of 3D and 2D segmentation and reconstruction\nperformance on both simulation and real-world datasets, and demonstrates a user\ncase as a robot simulator. Our project website is at:\nhttps:\/\/yuxuan1206.github.io\/panopticrecon_pp\/"
    ],
    "c_categories":[
      [
        "cs.CV",
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-979",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12645",
    "b_title":[
      "Understanding Gradient Orthogonalization for Deep Learning via\n  Non-Euclidean Trust-Region Optimization"
    ],
    "b_abstract":[
      "Optimization with matrix gradient orthogonalization has recently demonstrated\nimpressive results in the training of deep neural networks (Jordan et al.,\n2024; Liu et al., 2025). In this paper, we provide a theoretical analysis of\nthis approach. In particular, we show that the orthogonalized gradient method\ncan be seen as a first-order trust-region optimization method, where the\ntrust-region is defined in terms of the matrix spectral norm. Motivated by this\nobservation, we provide the first theoretical analysis of the stochastic\nnon-Euclidean trust-region gradient method with momentum, which recovers the\nMuon optimizer (Jordan et al., 2024) as a special case. In addition, we\nestablish the convergence of the normalized SGD with momentum (Cutkosky and\nMehta, 2020) in the constrained and composite setting, show that its iteration\ncomplexity of finding an $\\varepsilon$-accurate solution can be improved from\n$\\mathcal{O}(\\varepsilon^{-3.5})$ to $\\mathcal{O}(\\varepsilon^{-3})$ under the\nstar-convexity assumption, and obtain similar results for the Muon algorithm.\nFinally, our theoretical findings provide an explanation for the practical\nsuperiority of Muon compared to the Orthogonal-SGDM algorithm of Tuddenham et\nal. (2022)."
    ],
    "b_categories":[
      [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.20807",
    "c_title":[
      "Digital Player: Evaluating Large Language Models based Human-like Agent\n  in Games"
    ],
    "c_abstract":[
      "With the rapid advancement of Large Language Models (LLMs), LLM-based\nautonomous agents have shown the potential to function as digital employees,\nsuch as digital analysts, teachers, and programmers. In this paper, we develop\nan application-level testbed based on the open-source strategy game \"Unciv\",\nwhich has millions of active players, to enable researchers to build a \"data\nflywheel\" for studying human-like agents in the \"digital players\" task. This\n\"Civilization\"-like game features expansive decision-making spaces along with\nrich linguistic interactions such as diplomatic negotiations and acts of\ndeception, posing significant challenges for LLM-based agents in terms of\nnumerical reasoning and long-term planning. Another challenge for \"digital\nplayers\" is to generate human-like responses for social interaction,\ncollaboration, and negotiation with human players. The open-source project can\nbe found at https:\/github.com\/fuxiAIlab\/CivAgent."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-980",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18716",
    "b_title":[
      "A Mega-FPS low light camera"
    ],
    "b_abstract":[
      "From biology and astronomy to quantum optics, there is a critical need for\nhigh frame rate, high quantum efficiency imaging. In practice, most cameras\nonly satisfy one of these requirements. Here we introduce interlaced fast\nkinetics imaging, a technique that allows burst video acquisition at frame\nrates up to 3.33 Mfps using a commercial EMCCD camera with single-photon\nsensitivity. This approach leverages EMCCD's intrinsic fast row transfer\ndynamics by introducing a tilted lens array into the imaging path, creating a\nspatially distributed grid of exposed pixels, each aligned to its own column of\nthe sensor. The remaining unexposed pixels serve as in-situ storage registers,\nallowing subsequent frames to be captured after just one row shift operation.\nOur interlaced fast kinetics camera maintains 50% contrast for square wave\nintensity modulation frequencies up to 1.61 MHz. We provide benchmarks of the\nvideo performance by capturing two dimensional videos of spatially evolving\npatterns that repeat every 2$\\mu$s, with spatial resolution of 11$\\times$15\npixels. Our approach is compatible with commercial EMCCDs and opens a new route\nto ultra-fast imaging at single-photon sensitivity with applications from fast\nfluorescence imaging to photon correlation measurement."
    ],
    "b_categories":[
      [
        "physics.atom-ph",
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11909",
    "c_title":[
      "Bridging the Communication Gap: Evaluating AI Labeling Practices for\n  Trustworthy AI Development"
    ],
    "c_abstract":[
      "As artificial intelligence (AI) becomes integral to economy and society,\ncommunication gaps between developers, users, and stakeholders hinder trust and\ninformed decision-making. High-level AI labels, inspired by frameworks like EU\nenergy labels, have been proposed to make the properties of AI models more\ntransparent. Without requiring deep technical expertise, they can inform on the\ntrade-off between predictive performance and resource efficiency. However, the\npractical benefits and limitations of AI labeling remain underexplored. This\nstudy evaluates AI labeling through qualitative interviews along four key\nresearch questions. Based on thematic analysis and inductive coding, we found a\nbroad range of practitioners to be interested in AI labeling (RQ1). They see\nbenefits for alleviating communication gaps and aiding non-expert\ndecision-makers, however limitations, misunderstandings, and suggestions for\nimprovement were also discussed (RQ2). Compared to other reporting formats,\ninterviewees positively evaluated the reduced complexity of labels, increasing\noverall comprehensibility (RQ3). Trust was influenced most by usability and the\ncredibility of the responsible labeling authority, with mixed preferences for\nself-certification versus third-party certification (RQ4). Our Insights\nhighlight that AI labels pose a trade-off between simplicity and complexity,\nwhich could be resolved by developing customizable and interactive labeling\nframeworks to address diverse user needs. Transparent labeling of resource\nefficiency also nudged interviewee priorities towards paying more attention to\nsustainability aspects during AI development. This study validates AI labels as\na valuable tool for enhancing trust and communication in AI, offering\nactionable guidelines for their refinement and standardization."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-981",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17470",
    "b_title":[
      "Quantum Cross-section of Near-extremal Black Holes"
    ],
    "b_abstract":[
      "We explore how to detect the large quantum fluctuations in the throat of a\nnear-extremal black hole, where the dynamics are governed by the Schwarzian\ntheory. To this end, we scatter a low-frequency wave of a massless, minimal\nscalar off the black hole and calculate the absorption cross-section. In the\nsemiclassical regime, where the Schwarzian is weakly coupled, we recover the\nuniversal result that the cross-section equals the horizon area. However, in\nthe strongly coupled regime, where quantum fluctuations dominate, we find that\nthe absorption cross-section exceeds the semiclassical prediction. This result\nmay seem counterintuitive, given that the density of black hole states is\nsuppressed in this regime. Nevertheless, two effects outweigh this suppression.\nFirst, quantum fluctuations enhance absorption transitions between individual\nstates, with the effect becoming stronger closer to the ground state. Second,\nthese fluctuations significantly reduce stimulated emission. We conclude that a\nmeasurement showing an enhanced absorption cross-section serves as a clear\nsignature of the large quantum fluctuations in the geometry."
    ],
    "b_categories":[
      [
        "gr-qc",
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04818",
    "c_title":[
      "Prompting Science Report 1: Prompt Engineering is Complicated and\n  Contingent"
    ],
    "c_abstract":[
      "This is the first of a series of short reports that seek to help business,\neducation, and policy leaders understand the technical details of working with\nAI through rigorous testing. In this report, we demonstrate two things:\n  - There is no single standard for measuring whether a Large Language Model\n(LLM) passes a benchmark, and that choosing a standard has a big impact on how\nwell the LLM does on that benchmark. The standard you choose will depend on\nyour goals for using an LLM in a particular case.\n  - It is hard to know in advance whether a particular prompting approach will\nhelp or harm the LLM's ability to answer any particular question. Specifically,\nwe find that sometimes being polite to the LLM helps performance, and sometimes\nit lowers performance. We also find that constraining the AI's answers helps\nperformance in some cases, though it may lower performance in other cases.\n  Taken together, this suggests that benchmarking AI performance is not\none-size-fits-all, and also that particular prompting formulas or approaches,\nlike being polite to the AI, are not universally valuable."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-982",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04782",
    "b_title":[
      "GaussianVideo: Efficient Video Representation via Hierarchical Gaussian\n  Splatting"
    ],
    "b_abstract":[
      "Efficient neural representations for dynamic video scenes are critical for\napplications ranging from video compression to interactive simulations. Yet,\nexisting methods often face challenges related to high memory usage, lengthy\ntraining times, and temporal consistency. To address these issues, we introduce\na novel neural video representation that combines 3D Gaussian splatting with\ncontinuous camera motion modeling. By leveraging Neural ODEs, our approach\nlearns smooth camera trajectories while maintaining an explicit 3D scene\nrepresentation through Gaussians. Additionally, we introduce a spatiotemporal\nhierarchical learning strategy, progressively refining spatial and temporal\nfeatures to enhance reconstruction quality and accelerate convergence. This\nmemory-efficient approach achieves high-quality rendering at impressive speeds.\nExperimental results show that our hierarchical learning, combined with robust\ncamera motion modeling, captures complex dynamic scenes with strong temporal\nconsistency, achieving state-of-the-art performance across diverse video\ndatasets in both high- and low-motion scenarios."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00993",
    "c_title":[
      "Weak-Strong Uniqueness and the d'Alembert Paradox"
    ],
    "c_abstract":[
      "We prove conditional weak-strong uniqueness of the potential Euler solution\nfor external flow around a smooth body in three space dimensions, within the\nclass of viscosity weak solutions with the same initial data. Our sufficient\ncondition is the vanishing of the streamwise component of the skin friction in\nthe inviscid limit, somewhat weaker than the condition of Bardos-Titi in\nbounded domains. Because global-in-time existence of the smooth potential\nsolution leads back to the d'Alembert paradox, we argue that weak-strong\nuniqueness is not a valid criterion for \"relevant\" notions of generalized Euler\nsolution and that our condition is likely to be violated in the inviscid limit.\nWe prove also that the Drivas-Nguyen condition on uniform continuity at the\nwall of the normal velocity component implies weak-strong uniqueness within the\ngeneral class of admissible weak Euler solutions in bounded domains."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-983",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13819",
    "b_title":[
      "Simplicity of singular value spectrum of random matrices and two-point\n  quantitative invertibility"
    ],
    "b_abstract":[
      "Let $A$ be an $n\\times n$ random matrix with independent, identically\ndistributed mean 0, variance 1 subgaussian entries. We prove that $$\n\\mathbb{P}(A\\text{ has distinct singular values})\\geq 1-e^{-cn} $$ for some\n$c>0$, confirming a conjecture of Vu. This result is then generalized to\nsingular values of rectangular random matrices with i.i.d. entries.\n  We also prove that for two fixed real numbers $\\lambda_1,\\lambda_2$ with a\nsufficient lower bound on $|\\lambda_1-\\lambda_2|$, we have a joint singular\nvalue small ball estimate for any $\\epsilon>0$ $$\n\\mathbb{P}(\\sigma_{min}(A-\\lambda_1I_n)\\leq\\epsilon\nn^{-1\/2},\\sigma_{min}(A-\\lambda_2I_n)\\leq\\epsilon n^{-1\/2})\\leq\nC\\epsilon^2+e^{-cn}, $$ where $\\sigma_{min}(A)$ is the minimal singular value\nof a square matrix $A$ and $I_n$ is the identity matrix. For much smaller\n$|\\lambda_1-\\lambda_2|$ we derive a similar estimate with $C$ replaced by\n$C\\sqrt{n}\/|\\lambda_1-\\lambda_2|$. This generalizes the one-point estimate of\nRudelson and Vershynin, which proves $\\mathbb{P}(\\sigma_{min}(A)\\leq \\epsilon\nn^{-1\/2})\\leq C\\epsilon+e^{-cn}$. Analogous two-point bounds are proven when\n$A$ has i.i.d. real and complex parts, with $\\epsilon^4$ in place of\n$\\epsilon^2$ on the right hand side of the estimate and for any complex numbers\n$\\lambda_1,\\lambda_2$. These two point estimates can be used to derive strong\nanticoncentration bounds for an arbitrary linear combination of two eigenvalues\nof $A$."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.15652",
    "c_title":[
      "Primordial Origin of Methane on Eris and Makemake Supported by D\/H\n  Ratios"
    ],
    "c_abstract":[
      "Deuterium, a heavy isotope of hydrogen, is a key tracer of the formation of\nthe Solar System. Recent JWST observations have expanded the dataset of D\/H\nratios in methane on the KBOs Eris and Makemake, providing new insights into\ntheir origins. This study examines the elevated D\/H ratios in methane on these\nKBOs in the context of protosolar nebula dynamics and chemistry, and proposes a\nprimordial origin for the methane, in contrast to previous hypotheses\nsuggesting abiotic production by internal heating. A time-dependent disk model\ncoupled with a deuterium chemistry module was used to simulate the isotopic\nexchange between methane and hydrogen. Observational constraints, including the\nD\/H ratio measured in methane in comet 67P\/Churyumov-Gerasimenko, were used to\nrefine the primordial D\/H abundance. The simulations show that the observed D\/H\nratios in methane on Eris and Makemake are consistent with a primordial origin.\nThe results suggest that methane on these KBOs likely originates from the\nprotosolar nebula, similar to cometary methane, and was sequestered in solid\nform -- either as pure condensates or clathrates -- within their building\nblocks prior to accretion. These results provide a { simple} explanation for\nthe high D\/H ratios in methane on Eris and Makemake, without the need to invoke\ninternal production mechanisms."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-984",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05928",
    "b_title":[
      "Triangle-free cyclic conjugacy class graph of a finite group"
    ],
    "b_abstract":[
      "We generalize the enhanced power graph by replacing elements with conjugacy\nclasses. The main result of this paper is to determine when this graph is\ntriangle-free."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12034",
    "c_title":[
      "Application of Machine Learning Techniques for Secure Traffic in\n  NoC-based Manycores"
    ],
    "c_abstract":[
      "Like most computer systems, a manycore can also be the target of security\nattacks. It is essential to ensure the security of the NoC since all\ninformation travels through its channels, and any interference in the traffic\nof messages can reflect on the entire chip, causing communication problems.\nAmong the possible attacks on NoC, Denial of Service (DoS) attacks are the most\ncited in the literature. The state of the art shows a lack of work that can\ndetect such attacks through learning techniques. On the other hand, these\ntechniques are widely explored in computer network security via an Intrusion\nDetection System (IDS). In this context, the main goal of this document is to\npresent the progress of a work that explores an IDS technique using machine\nlearning and temporal series for detecting DoS attacks in NoC-based manycore\nsystems. To fulfill this goal, it is necessary to extract traffic data from a\nmanycore NoC and execute the learning techniques in the extracted data.\nHowever, while low-level platforms offer precision and slow execution,\nhigh-level platforms offer higher speed and data incompatible with reality.\nTherefore, a platform is being developed using the OVP tool, which has a higher\nlevel of abstraction. To solve the low precision problem, the developed\nplatform will have its data validated with a low-level platform."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-985",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10547",
    "b_title":[
      "HyperCam: Low-Power Onboard Computer Vision for IoT Cameras"
    ],
    "b_abstract":[
      "We present HyperCam, an energy-efficient image classification pipeline that\nenables computer vision tasks onboard low-power IoT camera systems. HyperCam\nleverages hyperdimensional computing to perform training and inference\nefficiently on low-power microcontrollers. We implement a low-power wireless\ncamera platform using off-the-shelf hardware and demonstrate that HyperCam can\nachieve an accuracy of 93.60%, 84.06%, 92.98%, and 72.79% for MNIST,\nFashion-MNIST, Face Detection, and Face Identification tasks, respectively,\nwhile significantly outperforming other classifiers in resource efficiency.\nSpecifically, it delivers inference latency of 0.08-0.27s while using\n42.91-63.00KB flash memory and 22.25KB RAM at peak. Among other machine\nlearning classifiers such as SVM, xgBoost, MicroNets, MobileNetV3, and\nMCUNetV3, HyperCam is the only classifier that achieves competitive accuracy\nwhile maintaining competitive memory footprint and inference latency that meets\nthe resource requirements of low-power camera systems."
    ],
    "b_categories":[
      [
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09208",
    "c_title":[
      "Refined enumeration of two-rowed set-valued standard tableaux via\n  two-coloured Motzkin paths"
    ],
    "c_abstract":[
      "We derive formulae for the number of set-valued standard tableaux of\ntwo-rowed shapes, keeping track of the total number of entries, the number of\nentries in the first row, and the number of entries in the second row. Key in\nthe proofs is a bijection with two-coloured Motzkin paths followed by\ngenerating function computations and coefficient extraction helped by the\nLagrange inversion formula."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-986",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05409",
    "b_title":[
      "Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV\n  in Ocean Environment"
    ],
    "b_abstract":[
      "This paper proposes a vision-in-the-loop simulation environment for deep\nmonocular pose estimation of a UAV operating in an ocean environment. Recently,\na deep neural network with a transformer architecture has been successfully\ntrained to estimate the pose of a UAV relative to the flight deck of a research\nvessel, overcoming several limitations of GPS-based approaches. However,\nvalidating the deep pose estimation scheme in an actual ocean environment poses\nsignificant challenges due to the limited availability of research vessels and\nthe associated operational costs. To address these issues, we present a\nphoto-realistic 3D virtual environment leveraging recent advancements in\nGaussian splatting, a novel technique that represents 3D scenes by modeling\nimage pixels as Gaussian distributions in 3D space, creating a lightweight and\nhigh-quality visual model from multiple viewpoints. This approach enables the\ncreation of a virtual environment integrating multiple real-world images\ncollected in situ. The resulting simulation enables the indoor testing of\nflight maneuvers while verifying all aspects of flight software, hardware, and\nthe deep monocular pose estimation scheme. This approach provides a\ncost-effective solution for testing and validating the autonomous flight of\nshipboard UAVs, specifically focusing on vision-based control and estimation\nalgorithms."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09177",
    "c_title":[
      "Jordan-Holder Theorem for profinite groups and applications"
    ],
    "c_abstract":[
      "We generalize the notions of composition series and composition factors for\nprofinite groups, and prove a profinite version of the Jordan-Holder Theorem.\nWe apply this to prove a Galois Theorem for infinite prosolvable extensions. In\naddition, we investigate the connection between the abstract and topological\ncomposition factors of a nonstrongly complete profinite group."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-987",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01753",
    "b_title":[
      "Detecting Turbulent Patterns in Particulate Pipe Flow by Streak Angle\n  Visualization"
    ],
    "b_abstract":[
      "Detecting the transition from laminar to turbulent flow in particulate pipe\nsystems remains a complex issue in fluid dynamics, often requiring\nsophisticated and costly experimental apparatus. This research presents an\ninnovative streak visualization method designed to offer a simple and robust\napproach to identify transitional turbulent patterns in particulate pipe flows\nwith neutrally buoyant particles. The technique employs a laser arrangement and\na low-cost camera setup to capture particle-generated streaks within the fluid,\nenabling real-time observation of flow patterns. Validation of the proposed\nmethod was conducted through comparison with established techniques like\nParticle Image Velocimetry (PIV) and pressure drop measurements, confirming its\naccuracy and reliability. Experiments demonstrate the streak visualization\nmethod's capacity to differentiate between laminar, transitional, and turbulent\nflow regimes by analyzing the standard deviation of streak angles. The method\nis especially efficient at low particle concentration, ie precisely where other\nmore established methods become less effective. Furthermore, this technique\nenables us to identify a critical Reynolds number using Kullback-Leibler\ndivergence built on the statistical distribution of streak angles, which is\nconsistent with previous studies.\n  Because it is effective at low concentrations and robust, this streak\nvisualization technique opens new perspectives for the characterization of\nparticulate pipe flows not only in the confines of the laboratory but also in\nless controlled industrial multi-phase flows where determining the laminar or\nturbulent nature of the flow is a prerequisite for flowmeter calibration."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02336",
    "c_title":[
      "AdaSkip: Adaptive Sublayer Skipping for Accelerating Long-Context LLM\n  Inference"
    ],
    "c_abstract":[
      "Long-context large language models (LLMs) inference is increasingly critical,\nmotivating a number of studies devoted to alleviating the substantial storage\nand computational costs in such scenarios. Layer-wise skipping methods are\npromising optimizations but rarely explored in long-context inference. We\nobserve that existing layer-wise skipping strategies have several limitations\nwhen applied in long-context inference, including the inability to adapt to\nmodel and context variability, disregard for sublayer significance, and\ninapplicability for the prefilling phase. This paper proposes \\sysname, an\nadaptive sublayer skipping method specifically designed for long-context\ninference. \\sysname adaptively identifies less important layers by leveraging\non-the-fly similarity information, enables sublayer-wise skipping, and\naccelerates both the prefilling and decoding phases. The effectiveness of\n\\sysname is demonstrated through extensive experiments on various long-context\nbenchmarks and models, showcasing its superior inference performance over\nexisting baselines."
    ],
    "c_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-988",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05656",
    "b_title":[
      "Small-Scale Testbeds for Connected and Automated Vehicles and Robot\n  Swarms: Challenges and a Roadmap"
    ],
    "b_abstract":[
      "This article proposes a roadmap to address the current challenges in\nsmall-scale testbeds for Connected and Automated Vehicles (CAVs) and robot\nswarms. The roadmap is a joint effort of participants in the workshop \"1st\nWorkshop on Small-Scale Testbeds for Connected and Automated Vehicles and Robot\nSwarms,\" held on June 2 at the IEEE Intelligent Vehicles Symposium (IV) 2024 in\nJeju, South Korea. The roadmap contains three parts: 1) enhancing accessibility\nand diversity, especially for underrepresented communities, 2) sharing best\npractices for the development and maintenance of testbeds, and 3) connecting\ntestbeds through an abstraction layer to support collaboration. The workshop\nfeatures eight invited speakers, four contributed papers [1]-[4], and a\npresentation of a survey paper on testbeds [5]. The survey paper provides an\nonline comparative table of more than 25 testbeds, available at\nhttps:\/\/bassamlab.github.io\/testbeds-survey. The workshop's own website is\navailable at https:\/\/cpm-remote.lrt.unibw-muenchen.de\/iv24-workshop."
    ],
    "b_categories":[
      [
        "cs.MA",
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18649",
    "c_title":[
      "Effective field theory for triple-Q magnetic orders on a hexagonal\n  lattice"
    ],
    "c_abstract":[
      "We develop a comprehensive Ginzburg-Landau theory describing triple-Q\nmagnetic orders on hexagonal lattices, focusing on $O(N)$ models with $N=2$ and\n$N=3$. Through systematic analysis of symmetry-allowed terms in the free\nenergy, we establish complete phase diagrams governed by competing interaction\nparameters. Our theory reveals distinct magnetic configurations including\nsingle-Q, double-Q, and triple-Q states, each characterized by unique symmetry\nbreaking patterns and collective excitations. The framework provides\nfundamental insights into complex magnetic orders recently observed in\nmaterials such as $\\alpha$-RuCl$_3$ and Na$_2$Co$_2$TeO$_6$, where the\ninterplay between geometric frustration and multiple ordering vectors leads to\nexotic magnetic states. Our results establish clear connections between\nmicroscopic interactions, broken symmetries, and experimentally observable\nproperties, offering a powerful tool for understanding and predicting novel\nmagnetic phases in frustrated magnets."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-989",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01654",
    "b_title":[
      "Fundamental polytope for the isometry group of an alcove"
    ],
    "b_abstract":[
      "A fundamental alcove $\\mathcal{A}$ is a tile in a paving of a vector space\n$V$ by an affine reflection group $W_{\\mathrm{aff}}$. Its geometry encodes\nessential features of $W_{\\mathrm{aff}}$, such as its affine Dynkin diagram\n$\\widetilde{D}$ and fundamental group $\\Omega$. In this article we investigate\nits full isometry group $\\mathrm{Aut}(\\mathcal{A})$. It is well known that the\nisometry group of a regular polyhedron is generated by hyperplane reflections\non its faces. Being a simplex, an alcove $\\mathcal{A}$ is the simplest of\npolyhedra, nevertheless it is seldom a regular one. In our first main result we\nshow that $\\mathrm{Aut}(\\mathcal{A})$ is isomorphic to\n$\\mathrm{Aut}(\\widetilde{D})$. Building on this connection, we establish that\n$\\mathrm{Aut}(\\mathcal{A})$ is an abstract Coxeter group, with generators given\nby affine isometric involutions of the ambient space. Although these\ninvolutions are seldom reflections, our second main result leverages them to\nconstruct, by slicing the Komrakov--Premet fundamental polytope $\\mathcal{K}$\nfor the action of $\\Omega$, a family of fundamental polytopes for the action of\n$\\mathrm{Aut}(\\mathcal{A})$ on $\\mathcal{A}$, whose vertices are contained in\nthe vertices of $\\mathcal{K}$ and whose faces are parametrized by the so-called\nbalanced minuscule roots, which we introduce here. In an appendix, we discuss\nsome related negative results on stratified centralizers and equivariant\ntriangulations."
    ],
    "b_categories":[
      [
        "math.CO",
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07706",
    "c_title":[
      "Annealed mean-field epidemiological model on scale-free networks with a\n  mitigating factor"
    ],
    "c_abstract":[
      "An annealed version of the quenched mean-field model for epidemic spread is\nintroduced and investigated analytically and assisted by numerical\ncalculations. The interaction between individuals follows a prescription that\nis used to generate a scale-free network, and we have adjusted the number of\nconnections to produce a sparse network. Specifically, the model's behavior\nnear the infection threshold is examined, as well as the behavior of the\nstationary prevalence and the probability that a connection between individuals\nencounters an infected one. We found that these functions display a\nmonotonically increasing dependence on the infection rate. Subsequently, a\nmodification that mimics the mitigation in the probability of encountering an\ninfected individual is introduced, following an old idea rooted in the\nMalthus-Verhulst model. We found that this modification drastically changes the\nprobability that a connection meets an infected individual. However, despite\nthis change, it does not alter the monotonically increasing behavior of the\nstationary prevalence."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech",
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology",
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-990",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14900",
    "b_title":[
      "Deep Contrastive Unlearning for Language Models"
    ],
    "b_abstract":[
      "The past a few years have witnessed the great success of large language\nmodels, demonstrating powerful capabilities in comprehending textual data and\ngenerating human-like languages. Large language models achieve success by being\ntrained on vast amounts of textual data, including online sources with\ncopyrighted content and user-generated knowledge. However, this comes at a\ncost: the potential risk of exposing users' privacy and violating copyright\nprotections. Thus, to safeguard individuals' \"right to be forgotten\", there has\nbeen increasing interests in machine unlearning -- the process of removing\ninformation carried by particular training samples from a model while not\ndeteriorating its predictive quality. This is a challenging task due to the\nblack-box nature of language models. Most existing studies focus on mitigating\nthe impact of those forgot samples upon a model's outputs, and do not\nexplicitly consider the geometric distributions of samples in the latent space\nof a model. To address this issue, we propose a machine unlearning framework,\nnamed Deep Contrastive Unlearning for fine-Tuning (DeepCUT) language models.\nOur proposed model achieves machine unlearning by directly optimizing the\nlatent space of a model. Comprehensive experiments on real-world datasets\ndemonstrate the effectiveness and efficiency of DeepCUT with consistent and\nsignificant improvement over baseline methods."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12323",
    "c_title":[
      "Adversarial Debiasing for Unbiased Parameter Recovery"
    ],
    "c_abstract":[
      "Advances in machine learning and the increasing availability of\nhigh-dimensional data have led to the proliferation of social science research\nthat uses the predictions of machine learning models as proxies for measures of\nhuman activity or environmental outcomes. However, prediction errors from\nmachine learning models can lead to bias in the estimates of regression\ncoefficients. In this paper, we show how this bias can arise, propose a test\nfor detecting bias, and demonstrate the use of an adversarial machine learning\nalgorithm in order to de-bias predictions. These methods are applicable to any\nsetting where machine-learned predictions are the dependent variable in a\nregression. We conduct simulations and empirical exercises using ground truth\nand satellite data on forest cover in Africa. Using the predictions from a\nnaive machine learning model leads to biased parameter estimates, while the\npredictions from the adversarial model recover the true coefficients."
    ],
    "c_categories":[
      [
        "cs.LG",
        "stat.ML"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-991",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02928",
    "b_title":[
      "Large Language Model Guided Self-Debugging Code Generation"
    ],
    "b_abstract":[
      "Automated code generation is gaining significant importance in intelligent\ncomputer programming and system deployment. However, current approaches often\nface challenges in computational efficiency and lack robust mechanisms for code\nparsing and error correction. In this work, we propose a novel framework,\nPyCapsule, with a simple yet effective two-agent pipeline and efficient\nself-debugging modules for Python code generation. PyCapsule features\nsophisticated prompt inference, iterative error handling, and case testing,\nensuring high generation stability, safety, and correctness. Empirically,\nPyCapsule achieves up to 5.7% improvement of success rate on HumanEval, 10.3%\non HumanEval-ET, and 24.4% on BigCodeBench compared to the state-of-art\nmethods. We also observe a decrease in normalized success rate given more\nself-debugging attempts, potentially affected by limited and noisy error\nfeedback in retention. PyCapsule demonstrates broader impacts on advancing\nlightweight and efficient code generation for artificial intelligence systems."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06599",
    "c_title":[
      "Spillover effects between climate policy uncertainty, energy markets,\n  and food markets: A time-frequency analysis"
    ],
    "c_abstract":[
      "The study examines the return connectedness between climate policy\nuncertainty (CPU), clean energy, fossil energy, and food markets. Using the\ntime-domain method of Diebold and Yilmaz (2012) and frequency-domain methods of\nBarun{\\'{i}}k and K{\\v{r}}hl{\\'{i}}k (2018), we find substantial spillover\neffects between these markets. Furthermore, high frequency domain is the\nprimary driver of overall connectedness. In addition, CPU is a net contributor\nof return shocks in the short term, whereas it turns to be a net recipient in\nthe medium and long terms. Across all frequencies, clean energy and oils are\nconsistent net recipients, while meat is a dominant net contributor."
    ],
    "c_categories":[
      [
        "econ.GN",
        "q-fin.EC"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-992",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18876",
    "b_title":[
      "QMe14S, A Comprehensive and Efficient Spectral Dataset for Small Organic\n  Molecules"
    ],
    "b_abstract":[
      "Developing machine learning protocols for molecular simulations requires\ncomprehensive and efficient datasets. Here we introduce the QMe14S dataset,\ncomprising 186,102 small organic molecules featuring 14 elements (H, B, C, N,\nO, F, Al, Si, P, S, Cl, As, Se, Br) and 47 functional groups. Using density\nfunctional theory at the B3LYP\/TZVP level, we optimized the geometries and\ncalculated properties including energy, atomic charge, atomic force, dipole\nmoment, quadrupole moment, polarizability, octupole moment, first\nhyperpolarizability, and Hessian. At the same level, we obtained the harmonic\nIR, Raman and NMR spectra. Furthermore, we conducted ab initio molecular\ndynamics simulations to generate dynamic configurations and extract\nnonequilibrium properties, including energy, forces, and Hessians. By\nleveraging our E(3)-equivariant message-passing neural network (DetaNet), we\ndemonstrated that models trained on QMe14S outperform those trained on the\npreviously developed QM9S dataset in simulating molecular spectra. The QMe14S\ndataset thus serves as a comprehensive benchmark for molecular simulations,\noffering valuable insights into structure-property relationships."
    ],
    "b_categories":[
      [
        "cs.LG",
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics",
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18005",
    "c_title":[
      "Fault Localization via Fine-tuning Large Language Models with Mutation\n  Generated Stack Traces"
    ],
    "c_abstract":[
      "Abrupt and unexpected terminations of software are termed as software\ncrashes. They can be challenging to analyze. Finding the root cause requires\nextensive manual effort and expertise to connect information sources like stack\ntraces, source code, and logs. Typical approaches to fault localization require\neither test failures or source code. Crashes occurring in production\nenvironments, such as that of SAP HANA, provide solely crash logs and stack\ntraces. We present a novel approach to localize faults based only on the stack\ntrace information and no additional runtime information, by fine-tuning large\nlanguage models (LLMs). We address complex cases where the root cause of a\ncrash differs from the technical cause, and is not located in the innermost\nframe of the stack trace. As the number of historic crashes is insufficient to\nfine-tune LLMs, we augment our dataset by leveraging code mutators to inject\nsynthetic crashes into the code base. By fine-tuning on 64,369 crashes\nresulting from 4.1 million mutations of the HANA code base, we can correctly\npredict the root cause location of a crash with an accuracy of 66.9\\% while\nbaselines only achieve 12.6% and 10.6%. We substantiate the generalizability of\nour approach by evaluating on two additional open-source databases, SQLite and\nDuckDB, achieving accuracies of 63% and 74%, respectively. Across all our\nexperiments, fine-tuning consistently outperformed prompting non-finetuned LLMs\nfor localizing faults in our datasets."
    ],
    "c_categories":[
      [
        "cs.LG",
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-993",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13026",
    "b_title":[
      "Deriving the paradox: original derivation of Hawking radiation"
    ],
    "b_abstract":[
      "We revisit Hawking's original derivation of the evaporation process in a\nnon-stationary spacetime, presenting it in a clear and pedagogical manner, with\na focus on the spherical collapse of a star into a black hole. Our analysis\nhighlights the underlying assumptions in the calculations, clarifying their\nphysical significance, potential implications, and the limitations of this\napproach."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09517",
    "c_title":[
      "Coupled Rendezvous and Docking Maneuver control of satellite using\n  Reinforcement learning-based Adaptive Fixed-Time Sliding Mode Controller"
    ],
    "c_abstract":[
      "Satellite dynamics in unknown environments are inherently uncertain due to\nfactors such as varying gravitational fields, atmospheric drag, and\nunpredictable interactions with space debris or other celestial bodies.\nTraditional sliding mode controllers with fixed parameters often struggle to\nmaintain optimal performance under these fluctuating conditions. Therefore, an\nadaptive controller is essential to address these challenges by continuously\ntuning its gains in real-time. In this paper, we have tuned the slopes of the\nFixed-time Sliding surface adaptively using reinforcement learning for coupled\nrendezvous and docking maneuver of chaser satellite with the target satellite\nin an unknown space environment. The neural network model is used to determine\nthe optimal gains of reaching law of the fixed-time sliding surface. We have\nassumed that we don't have an accurate model of the system so we have added\nnoise in the tangent space instead of directly on the manifold to preserve the\ngeometric structure of the system while ensuring mathematically consistent\nuncertainty propagation. The reinforcement learning is used as an approximator\nto represent the value function of the agent to estimate the dynamical model of\nthe system using the Actor-Critic method. The proposed control algorithm\nintegrates a neural network and a sliding mode controller in a cascade loop\narchitecture, where the tracking error dynamically tunes the sliding surface\ngains. Global fixed-time stability of the closed-loop feedback system is proved\nwithin the Lyapunov framework. This comprehensive approach of fixed-time\nsliding mode controller using a Reinforcement Learning based ensures the\ncompletion of the mission efficiently while addressing the critical challenges\nposed by the uncertain environment. The simulation results presented support\nthe claims made."
    ],
    "c_categories":[
      [
        "cs.SY",
        "eess.SY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-994",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00383",
    "b_title":[
      "Theoretical Insights in Model Inversion Robustness and Conditional\n  Entropy Maximization for Collaborative Inference Systems"
    ],
    "b_abstract":[
      "By locally encoding raw data into intermediate features, collaborative\ninference enables end users to leverage powerful deep learning models without\nexposure of sensitive raw data to cloud servers. However, recent studies have\nrevealed that these intermediate features may not sufficiently preserve\nprivacy, as information can be leaked and raw data can be reconstructed via\nmodel inversion attacks (MIAs). Obfuscation-based methods, such as noise\ncorruption, adversarial representation learning, and information filters,\nenhance the inversion robustness by obfuscating the task-irrelevant redundancy\nempirically. However, methods for quantifying such redundancy remain elusive,\nand the explicit mathematical relation between this redundancy minimization and\ninversion robustness enhancement has not yet been established. To address that,\nthis work first theoretically proves that the conditional entropy of inputs\ngiven intermediate features provides a guaranteed lower bound on the\nreconstruction mean square error (MSE) under any MIA. Then, we derive a\ndifferentiable and solvable measure for bounding this conditional entropy based\non the Gaussian mixture estimation and propose a conditional entropy\nmaximization (CEM) algorithm to enhance the inversion robustness. Experimental\nresults on four datasets demonstrate the effectiveness and adaptability of our\nproposed CEM; without compromising feature utility and computing efficiency,\nplugging the proposed CEM into obfuscation-based defense mechanisms\nconsistently boosts their inversion robustness, achieving average gains ranging\nfrom 12.9\\% to 48.2\\%. Code is available at\n\\href{https:\/\/github.com\/xiasong0501\/CEM}{https:\/\/github.com\/xiasong0501\/CEM}."
    ],
    "b_categories":[
      [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science",
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.18100",
    "c_title":[
      "Realizing degree sequences with $\\mathcal S_3$-connected graphs"
    ],
    "c_abstract":[
      "A graph $G$ is $\\mathcal S_3$-connected if, for any mapping $\\beta : V (G)\n\\mapsto {\\mathbb Z}_3$ with $\\sum_{v\\in V(G)} \\beta(v)\\equiv 0\\pmod3$, there\nexists a strongly connected orientation $D$ satisfying\n$d^{+}_D(v)-d^{-}_D(v)\\equiv \\beta(v)\\pmod{3}$ for any $v \\in V(G)$. It is\nknown that $\\mathcal S_3$-connected graphs are contractible configurations for\nthe property of flow index strictly less than three. In this paper, we provide\na complete characterization of graphic sequences that have an\n$\\mathcal{S}_{3}$-connected realization: A graphic sequence $\\pi=(d_1,\\,\n\\ldots,\\, d_n )$ has an $\\mathcal S_3$-connected realization if and only if\n$\\min \\{d_1,\\, \\ldots,\\, d_n\\} \\ge 4$ and $\\sum^n_{i=1}d_i \\ge 6n - 4$.\nConsequently, every graphic sequence $\\pi=(d_1,\\, \\ldots,\\, d_n )$ with $\\min\n\\{d_1,\\, \\ldots,\\, d_n\\} \\ge 6$ has a realization $G$ with flow index strictly\nless than three. This supports a conjecture of Li, Thomassen, Wu and Zhang\n[European J. Combin., 70 (2018) 164-177] that every $6$-edge-connected graph\nhas flow index strictly less than three."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-995",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08056",
    "b_title":[
      "Magnetic Dichroism in Rutile NiF$_2$: Separating Altermagnetic and\n  Ferromagnetic Effects"
    ],
    "b_abstract":[
      "We present numerical simulations of x-ray magnetic circular dichroism (XMCD)\nat the L$_{2,3}$ edge of Ni in the weakly ferromagnetic altermagnet NiF$_2$.\nOur results predict a significant XMCD signal for light propagating\nperpendicular to the magnetic moments, which are approximately aligned along\nthe [100] easy-axis direction. The analysis shows that the altermagnetic and\nferromagnetic contributions to the XMCD signal can be uniquely distinguished by\ntheir dependence on an applied magnetic field. By varying the angle of the\nfield relative to the easy axis, the in-plane orientation of both the N\\'eel\nvector and the net magnetization can be systematically controlled. We further\ndemonstrate that the XMCD signal, even under fields as strong as 40 T and for\nany in-plane orientation, can be accurately described as a linear combination\nof two spectral components, with geometrical prefactors determined by the field\nmagnitude and direction. This insight enables experimental validation of the\ndistinctive relationship between the N\\'eel vector orientation and the x-ray\nHall vector in the rutile structure. Quantitative simulations supporting these\nfindings are provided."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16152",
    "c_title":[
      "DUPRE: Data Utility Prediction for Efficient Data Valuation"
    ],
    "c_abstract":[
      "Data valuation is increasingly used in machine learning (ML) to decide the\nfair compensation for data owners and identify valuable or harmful data for\nimproving ML models. Cooperative game theory-based data valuation, such as Data\nShapley, requires evaluating the data utility (e.g., validation accuracy) and\nretraining the ML model for multiple data subsets. While most existing works on\nefficient estimation of the Shapley values have focused on reducing the number\nof subsets to evaluate, our framework, \\texttt{DUPRE}, takes an alternative yet\ncomplementary approach that reduces the cost per subset evaluation by\npredicting data utilities instead of evaluating them by model retraining.\nSpecifically, given the evaluated data utilities of some data subsets,\n\\texttt{DUPRE} fits a \\emph{Gaussian process} (GP) regression model to predict\nthe utility of every other data subset. Our key contribution lies in the design\nof our GP kernel based on the sliced Wasserstein distance between empirical\ndata distributions. In particular, we show that the kernel is valid and\npositive semi-definite, encodes prior knowledge of similarities between\ndifferent data subsets, and can be efficiently computed. We empirically verify\nthat \\texttt{DUPRE} introduces low prediction error and speeds up data\nvaluation for various ML models, datasets, and utility functions."
    ],
    "c_categories":[
      [
        "cs.GT",
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-996",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06304",
    "b_title":[
      "Optimization and Benchmarking of Monolithically Stackable Gain Cell\n  Memory for Last-Level Cache"
    ],
    "b_abstract":[
      "The Last Level Cache (LLC) is the processor's critical bridge between on-chip\nand off-chip memory levels - optimized for high density, high bandwidth, and\nlow operation energy. To date, high-density (HD) SRAM has been the conventional\ndevice of choice; however, with the slowing of transistor scaling, as reflected\nin the industry's almost identical HD SRAM cell size from 5 nm to 3 nm,\nalternative solutions such as 3D stacking with advanced packaging like hybrid\nbonding are pursued (as demonstrated in AMD's V-cache). Escalating data demands\nnecessitate ultra-large on-chip caches to decrease costly off-chip memory\nmovement, pushing the exploration of device technology toward monolithic 3D\n(M3D) integration where transistors can be stacked in the back-end-of-line\n(BEOL) at the interconnect level. M3D integration requires fabrication\ntechniques compatible with a low thermal budget (<400 degC). Among promising\nBEOL device candidates are amorphous oxide semiconductor (AOS) transistors,\nparticularly desirable for their ultra-low leakage (<fA\/um), enabling\npersistent data retention (>seconds) when used in a gain-cell configuration.\nThis paper examines device, circuit, and system-level tradeoffs when optimizing\nBEOL-compatible AOS-based 2-transistor gain cell (2T-GC) for LLC. A cache\nearly-exploration tool, NS-Cache, is developed to model caches in advanced 7\nand 3 nm nodes and is integrated with the Gem5 simulator to systematically\nbenchmark the impact of the newfound density\/performance when compared to\nHD-SRAM, MRAM, and 1T1C eDRAM alternatives for LLC."
    ],
    "b_categories":[
      [
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00478",
    "c_title":[
      "Orthogonality of spin $q$-Whittaker polynomials"
    ],
    "c_abstract":[
      "The inhomogeneous spin $q$-Whittaker polynomials are a family of symmetric\npolynomials which generalize the Macdonald polynomials at $t=0$. In this paper\nwe prove that they are orthogonal with respect to a variant of the Sklyanin\nmeasure on the $n$ dimensional torus and as a result they form a basis of the\nspace of symmetric polynomials in $n$ variables. Instrumental to the proof are\ninhomogeneous eigenrelations, which partially generalize those of Macdonald\npolynomials. We also consider several special cases of the inhomogeneous spin\n$q$-Whittaker polynomials, which include variants of symmetric Grothendieck\npolynomials or spin Whittaker functions."
    ],
    "c_categories":[
      [
        "math-ph",
        "math.CO",
        "math.MP",
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Physics",
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-997",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13993",
    "b_title":[
      "On a Diophantine Inequality with Primes Yielding Square-Free Sums with\n  Given Numbers"
    ],
    "b_abstract":[
      "Let $\\alpha\\in \\mathbb{R}\\setminus\\mathbb{Q}$ and $\\beta\\in \\mathbb{R}$ be\ngiven. Suppose that $a_1,\\ldots,a_s$ are distinct positive integers that do not\ncontain a reduced residue system modulo $p^2$ for any prime $p$. We prove that\nthere exist infinitely many primes $p$ such that the inequality $||\\alpha\np+\\beta||<p^{-1\/10}$ holds and all the numbers $p+a_1,\\ldots,p+a_s$ are\nsquare-free."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.09964",
    "c_title":[
      "Fractional-flux oscillations of Josephson critical currents in multi-gap\n  superconductors: a test for unconventional superconductivity"
    ],
    "c_abstract":[
      "Josephson-junction interferometry has played a pivotal role in uncovering\nunconventional superconductivity in the cuprates. Using a Ginzburg-Landau-like\napproach, we generalize previous results to the genuine multi-gap case. Thus,\nwe show that fractional flux oscillations of the Josephson critical current can\narise as a direct consequence of multi-gap superconductivity. These\noscillations reveal key information about the underlying superconducting\nstates, including the unconventional $s_\\pm$-wave state. Thus, our findings\nsuggest new phase-sensitive experiments to characterize the Cooper pairing of\nnew emerging superconductors such as the nickelates."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci",
        "cond-mat.quant-gas",
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-998",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09741",
    "b_title":[
      "Asymptotic behavior of clusters in hierarchical species sampling models"
    ],
    "b_abstract":[
      "Consider a sample of size $N$ from a population governed by a hierarchical\nspecies sampling model. We study the large $N$ asymptotic behavior of the\nnumber ${\\bf K}_N$ of clusters and the number ${\\bf M}_{r,N}$ of clusters with\nfrequency $r$ in the sample. In particular, we show almost sure and $L^p$\nconvergence for ${\\bf M}_{r,N}$, obtain Gaussian fluctuation theorems for ${\\bf\nK}_N$, and establish large deviation principles for both ${\\bf K}_N$ and ${\\bf\nM}_{r,N}$. Our approach relies on a random sample size representation of the\nnumber of clusters through the corresponding non-hierarchical species sampling\nmodel."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06859",
    "c_title":[
      "ActiveInitSplat: How Active Image Selection Helps Gaussian Splatting"
    ],
    "c_abstract":[
      "Gaussian splatting (GS) along with its extensions and variants provides\noutstanding performance in real-time scene rendering while meeting reduced\nstorage demands and computational efficiency. While the selection of 2D images\ncapturing the scene of interest is crucial for the proper initialization and\ntraining of GS, hence markedly affecting the rendering performance, prior works\nrely on passively and typically densely selected 2D images. In contrast, this\npaper proposes `ActiveInitSplat', a novel framework for active selection of\ntraining images for proper initialization and training of GS. ActiveInitSplat\nrelies on density and occupancy criteria of the resultant 3D scene\nrepresentation from the selected 2D images, to ensure that the latter are\ncaptured from diverse viewpoints leading to better scene coverage and that the\ninitialized Gaussian functions are well aligned with the actual 3D structure.\nNumerical tests on well-known simulated and real environments demonstrate the\nmerits of ActiveInitSplat resulting in significant GS rendering performance\nimprovement over passive GS baselines, in the widely adopted LPIPS, SSIM, and\nPSNR metrics."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-999",
    "date":"",
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06447",
    "b_title":[
      "Biquadratic Tensors: Eigenvalues and Structured Tensors"
    ],
    "b_abstract":[
      "The covariance tensors in statistics{, elasticity tensor in solid mechanics,\nRiemann curvature tensor in relativity theory are all biquadratic tensors that\nare weakly symmetric, but not symmetric in general. Motivated by this, in this\npaper, we consider nonsymmetric biquadratic tensors, and study possible\nconditions and algorithms for identifying positive semi-definiteness and\ndefiniteness of such biquadratic tensors. We extend M-eigenvalues to\nnonsymmetric biquadratic tensors, prove that a general biquadratic tensor has\nat least one M-eigenvalue, and show that a general biquadratic tensor is\npositive semi-definite if and only if all of its M-eigenvalues are nonnegative,\nand a general biquadratic tensor is positive definite if and only if all of its\nM-eigenvalues are positive. We present a Gershgorin-type theorem for\nbiquadratic tensors, and show that (strictly) diagonally dominated biquadratic\ntensors are positive semi-definite (definite). We introduce Z-biquadratic\ntensors, M-biquadratic tensors, strong M-biquadratic tensors, B$_0$-biquadratic\ntensors and B-biquadratic tensors. We show that M-biquadratic tensors and\nsymmetric B$_0$-biquadratic tensors are positive semi-definite, and that strong\nM-biquadratic tensors and symmetric B-biquadratic tensors are positive\ndefinite. A Riemannian LBFGS method for computing the smallest M-eigenvalue of\na general biquadratic tensor is presented. Numerical results are reported."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12594",
    "c_title":[
      "Non-holomorphic $A_4$ modular invariance for fermion masses and mixing\n  in SU(5) GUT"
    ],
    "c_abstract":[
      "Addressing the fermion flavor structures using modular invariance is a\nchallenging task in the framework of quark-lepton unification. Building on\nrecent applications of modular symmetry in non-supersymmetric models, we\npropose the first renormalizable $SU(5)$ grand unified theory incorporating\nlevel 3 non-holomorphic modular symmetry, $\\Gamma_3 \\simeq A_4$. This framework\nconstrains Yukawa couplings to polyharmonic Maa{\\ss} forms, significantly\nreducing the number of free parameters while enhancing the predictive power of\nthe models. We present a comprehensive analysis of fermion masses and mixing\nwhile tackling key GUT queries such as gauge coupling unification and proton\ndecay. Beyond the minimal $SU(5)$ framework, the Higgs sector incorporates the\n$45_H$ dimensional Higgs field crucial in differentiating the masses of down\nquarks and charged leptons, and the fermion sector is extended with three\nright-handed neutrinos enabling neutrino masses via the type-I seesaw\nmechanism. We analyze two benchmark models with distinct modular weight and\n$A_4$ charge assignments. The predicted effective Majorana mass $m_{\\beta\n\\beta}$ values align with current neutrinoless double-beta decay experiments,\nand the effective neutrino mass $m_\\beta$ is within the reach of future beta\ndecay searches. The predicted sum of neutrino masses, $\\sum m_i$, satisfies the\nupper bound set by recent cosmological observations. The gauge coupling\nunification is achieved through a light scalar triplet $\\phi_3 \\sim (3,3,-1\/3)$\nand a scalar octet $\\phi_5 \\sim (8,2,1\/2)$ belonging to the $45_H$ Higgs, while\nproton decay constraints require a highly suppressed Yukawa couplings."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":2411.01019,
    "date":null,
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6",
      "b1"
    ],
    "c_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "c_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "c_categories":[
      "q-bio.CB",
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.11084,
    "date":null,
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "c_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00036,
    "date":null,
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b24"
    ],
    "c_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "c_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.0064,
    "date":null,
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The Llama 3 Herd of Models"
    ],
    "c_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00609,
    "date":null,
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "c_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00726,
    "date":null,
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05236,
    "date":null,
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2",
      "b0"
    ],
    "c_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "c_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "c_categories":[
      "eess.SP",
      "cs.SY"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.02815,
    "date":null,
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.AI",
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "c_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00561,
    "date":null,
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "c_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.01144,
    "date":null,
    "a_title":"LEARNER: Learning Granular Labels from Coarse Labels using Contrastive\n  Learning",
    "a_abstract":"A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "explanation":"Recent years have seen increasing use of deep learning\n(DL) in predicting diseases using biomedical imaging, such as\npredicting COVID-19 severity using lung ultrasound (LUS)\ndata.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Investigating training-test data splitting strategies for automated segmentation and scoring of COVID-19 lung ultrasound images."
    ],
    "b_abstract":[
      "Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods."
    ],
    "b_categories":[
      "Lung Ultrasound"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A Simple Framework for Contrastive Learning of Visual Representations"
    ],
    "c_abstract":[
      "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00922,
    "date":null,
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.02695,
    "date":null,
    "a_title":"An ADHD Diagnostic Interface Based on EEG Spectrograms and Deep Learning\n  Techniques",
    "a_abstract":"This paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by employing deep\nlearning (DL) techniques on electroencephalography (EEG) signals. This method\naddresses the limitations of current behavior-based diagnostic methods, which\noften lead to misdiagnosis and gender bias. By utilizing a publicly available\nEEG dataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to extract features\nfor ADHD classification. The model achieved a high precision, recall, and an\noverall F1 score of 0.9. Feature extraction highlighted significant brain\nregions (frontopolar, parietal, and occipital lobes) associated with ADHD.\nThese insights guided the creation of a three-part digital diagnostic system,\nfacilitating cost-effective and accessible ADHD screening, especially in school\nenvironments. This system enables earlier and more accurate identification of\nstudents at risk for ADHD, providing timely support to enhance their\ndevelopmental outcomes. This study showcases the potential of integrating EEG\nanalysis with DL to enhance ADHD diagnostics, presenting a viable alternative\nto traditional methods.",
    "explanation":"his paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by em-\nploying deep learning (DL) techniques on electroencephalography\n(EEG) signals.  By utilizing a publicly available EEG\ndataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to ex-\ntract features for ADHD classification. ",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "EEG data for ADHD \/ Control children"
    ],
    "b_abstract":[
      "Participants were 61 children with ADHD and 60 healthy controls (boys and girls, ages 7-12). The ADHD children were diagnosed by an experienced psychiatrist to DSM-IV criteria, and have taken Ritalin for up to 6 months. None of the children in the control group had a history of psychiatric disorders, epilepsy, or any report of high-risk behaviors. EEG recording was performed based on 10-20 standard by 19 channels (Fz, Cz, Pz, C3, T3, C4, T4, Fp1, Fp2, F3, F4, F7, F8, P3, P4, T5, T6, O1, O2) at 128 Hz sampling frequency. The A1 and A2 electrodes were the references located on earlobes. Since one of the deficits in ADHD children is visual attention, the EEG recording protocol was based on visual attention tasks. In the task, a set of pictures of cartoon characters was shown to the children and they were asked to count the characters. The number of characters in each image was randomly selected between 5 and 16, and the size of the pictures was large enough to be easily visible and countable by children. To have a continuous stimulus during the signal recording, each image was displayed immediately and uninterrupted after the child\u2019s response. Thus, the duration of EEG recording throughout this cognitive visual task was dependent on the child\u2019s performance (i.e. response speed)."
    ],
    "b_categories":[
      "Neurotherapeutics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Deep Residual Learning for Image Recognition"
    ],
    "c_abstract":[
      "Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8\u00d7 VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03522,
    "date":null,
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "c_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.20007,
    "date":null,
    "a_title":"Uncertainty Quantified Deep Learning and Regression Analysis Framework\n  for Image Segmentation of Skin Cancer Lesions",
    "a_abstract":"Deep learning models (DLMs) frequently achieve accurate segmentation and\nclassification of tumors from medical images. However, DLMs lacking feedback on\ntheir image segmentation mechanisms, such as Dice coefficients and confidence\nin their performance, face challenges when processing previously unseen images\nin real-world clinical settings. Uncertainty estimates to identify DLM\npredictions at the cellular or single-pixel level that require clinician review\ncan enhance trust. However, their deployment requires significant computational\nresources. This study reports two DLMs, one trained from scratch and another\nbased on transfer learning, with Monte Carlo dropout or Bayes-by-backprop\nuncertainty estimations to segment lesions from the publicly available The\nInternational Skin Imaging Collaboration-19 dermoscopy image database with\ncancerous lesions. A novel approach to compute pixel-by-pixel uncertainty\nestimations of DLM segmentation performance in multiple clinical regions from a\nsingle dermoscopy image with corresponding Dice scores is reported for the\nfirst time. Image-level uncertainty maps demonstrated correspondence between\nimperfect DLM segmentation and high uncertainty levels in specific skin tissue\nregions, with or without lesions. Four new linear regression models that can\npredict the Dice performance of DLM segmentation using constants and\nuncertainty measures, either individually or in combination from lesions,\ntissue structures, and non-tissue pixel regions critical for clinical diagnosis\nand prognostication in skin images (Spearman's correlation, p < 0.05), are\nreported for the first time for low-compute uncertainty estimation workflows.",
    "explanation":"Deep learning models (DLMs) frequently achieve\naccurate segmentation and classification of tumors from medical\nimages.  DLMs lacking feedback on their image seg-\nmentation mechanisms such as Dice coefficients and confidence in\ntheir performance face challenges processing previously unseen\nimages in real-world clinical settings. A novel\napproach to compute pixel-by-pixel uncertainty estimations of\nDLM segmentation performance in multiple clinical regions from\na single dermatoscopy image with corresponding Dice scores\nis reported for the first time. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning tools have gained tremendous attention in applied machine learning. However such for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about uncertainty, but usually come with prohibitive computational cost. this paper we develop new theoretical casting dropout training deep neural networks (NNs) as approximate inference Gaussian processes. A direct result of theory gives us uncertainty NNs -- extracting information from existing that has been thrown away so far. This mitigates the problem representing without sacrificing either complexity or test accuracy. We perform an extensive study properties dropout's Various network architectures non-linearities are assessed on tasks classification, using MNIST example. show considerable improvement predictive log-likelihood RMSE compared state-of-the-art methods, finish by reinforcement"
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions"
    ],
    "c_abstract":[
      "Training of neural networks for automated diagnosis pigmented skin lesions is hampered by the small size and lack diversity available datasets dermatoscopic images. We tackle this problem releasing HAM10000 (\"Human Against Machine with 10000 training images\") dataset. collected images from different populations acquired stored modalities. Given we had to apply acquisition cleaning methods developed semi-automatic workflows utilizing specifically trained networks. The final dataset consists 10015 which are released as a set academic machine learning purposes publicly through ISIC archive. This benchmark can be used comparisons human experts. Cases include representative collection all important diagnostic categories in realm lesions. More than 50% have been confirmed pathology, while ground truth rest cases was either follow-up, expert consensus, or confirmation in-vivo confocal microscopy."
    ],
    "c_categories":[
      "Data"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04715,
    "date":null,
    "a_title":"NeuroFly: A framework for whole-brain single neuron reconstruction",
    "a_abstract":"Neurons, with their elongated, tree-like dendritic and axonal structures,\nenable efficient signal integration and long-range communication across brain\nregions. By reconstructing individual neurons' morphology, we can gain valuable\ninsights into brain connectivity, revealing the structure basis of cognition,\nmovement, and perception. Despite the accumulation of extensive 3D microscopic\nimaging data, progress has been considerably hindered by the absence of\nautomated tools to streamline this process. Here we introduce NeuroFly, a\nvalidated framework for large-scale automatic single neuron reconstruction.\nThis framework breaks down the process into three distinct stages:\nsegmentation, connection, and proofreading. In the segmentation stage, we\nperform automatic segmentation followed by skeletonization to generate\nover-segmented neuronal fragments without branches. During the connection\nstage, we use a 3D image-based path following approach to extend each fragment\nand connect it with other fragments of the same neuron. Finally, human\nannotators are required only to proofread the few unresolved positions. The\nfirst two stages of our process are clearly defined computer vision problems,\nand we have trained robust baseline models to solve them. We validated\nNeuroFly's efficiency using in-house datasets that include a variety of\nchallenging scenarios, such as dense arborizations, weak axons, images with\ncontamination. We will release the datasets along with a suite of visualization\nand annotation tools for better reproducibility. Our goal is to foster\ncollaboration among researchers to address the neuron reconstruction challenge,\nultimately accelerating advancements in neuroscience research. The dataset and\ncode are available at https:\/\/github.com\/beanli161514\/neurofly",
    "explanation":"Despite the accumulation of extensive 3D microscopic imaging data,\nprogress has been considerably hindered by the absence of\nautomated tools to streamline this process.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "BigNeuron: a resource to benchmark and predict performance of algorithms for automated tracing of neurons in light microscopy datasets"
    ],
    "b_abstract":[
      "BigNeuron is an open community bench-testing platform with the goal of setting open standards for accurate and fast automatic neuron tracing. We gathered a diverse set of image volumes across several species that is representative of the data obtained in many neuroscience laboratories interested in neuron tracing. Here, we report generated gold standard manual annotations for a subset of the available imaging datasets and quantified tracing quality for 35 automatic tracing algorithms. The goal of generating such a hand-curated diverse dataset is to advance the development of tracing algorithms and enable generalizable benchmarking. Together with image quality features, we pooled the data in an interactive web application that enables users and developers to perform principal component analysis, t -distributed stochastic neighbor embedding, correlation and clustering, visualization of imaging and tracing data, and benchmarking of automatic tracing algorithms in user-defined data subsets. The image quality metrics explain most of the variance in the data, followed by neuromorphological features related to neuron size. We observed that diverse algorithms can provide complementary information to obtain accurate results and developed a method to iteratively combine methods and generate consensus reconstructions. The consensus trees obtained provide estimates of the neuron structure ground truth that typically outperform single algorithms in noisy datasets. However, specific algorithms may outperform the consensus tree strategy in specific imaging conditions. Finally, to aid users in predicting the most accurate automatic tracing results without manual annotations for comparison, we used support vector machine regression to predict reconstruction quality given an image volume and a set of automatic tracings. This resource describes a collection of neurons from a variety of light microscopy-based datasets, which can serve as a gold standard for testing automated tracing algorithms, as shown by comparison of the performance of 35 algorithms."
    ],
    "b_categories":[
      "Bioinformatics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Tracing weak neuron fibers"
    ],
    "c_abstract":[
      "Precise reconstruction of neuronal arbors is important for circuitry mapping. Many auto-tracing algorithms have been developed toward full reconstruction. However, it still challenging to trace the weak signals neurite fibers that often correspond axons.We proposed a method, named NeuMiner, tracing by combining two strategies: an online sample mining strategy and modified gamma transformation. NeuMiner improved recall (voxel values <20) large margin, from 5.1 27.8%. This prominent axons, which increased 6.4 times, compared 2.0 times dendrites. Both strategies were shown be beneficial fiber recognition, they reduced average axonal spatial distances gold standards 46 13%, respectively. The improvement was observed on prevalent automatic can applied any other tracers image types.Source codes are freely available GitHub (https:\/\/github.com\/crazylyf\/neuronet\/tree\/semantic_fnm). Image visualization, preprocessing conducted Vaa3D platform, accessible at repository (https:\/\/github.com\/Vaa3D). All training testing images cropped high-resolution fMOST mouse brains downloaded Brain Library (https:\/\/www.brainimagelibrary.org\/), corresponding https:\/\/doi.brainimagelibrary.org\/doi\/10.35077\/g.25.Supplementary data Bioinformatics online."
    ],
    "c_categories":[
      "Imaging"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05188,
    "date":null,
    "a_title":"AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive\n  Outcome for Infant Brain Injury",
    "a_abstract":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000\nnewborns, with 30% to 50% of cases resulting in adverse neurocognitive\noutcomes. However, these outcomes can only be reliably assessed as early as age\n2. Therefore, early and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improving clinical\ndecision-making, guiding treatment decisions and assessing novel therapies.\nHowever, a major challenge in developing deep learning models for this purpose\nis the scarcity of large, annotated HIE datasets. We have assembled the first\nand largest public dataset, however it contains only 156 cases with 2-year\nneurocognitive outcome labels. In contrast, we have collected 8,859 normal\nbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are\navailable for brain age estimation using deep learning models. In this paper,\nwe introduce AGE2HIE to transfer knowledge learned by deep learning models from\nhealthy controls brain MRIs to a diseased cohort, from structural to diffusion\nMRIs, from regression of continuous age estimation to prediction of the binary\nneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2\nweeks). Compared to training from scratch, transfer learning from brain age\nestimation significantly improves not only the prediction accuracy (3% or 2%\nimprovement in same or multi-site), but also the model generalization across\ndifferent sites (5% improvement in cross-site validation).",
    "explanation":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of\nevery 1,000 newborns, with 30% to 50% of cases resulting in\nadverse neurocognitive outcomes. However, these outcomes\ncan only be reliably assessed as early as age 2. Therefore,\nearly and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improv-\ning clinical decision-making, guiding treatment decisions and\nassessing novel therapies",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Limitations of conventional magnetic resonance imaging as a predictor of death or disability following neonatal hypoxic-ischemic encephalopathy in the late hypothermia trial"
    ],
    "b_abstract":[
      "Objective: To investigate if magnetic resonance imaging (MRI) is an accurate predictor for death or moderate-severe disability at 18-22 months of age among infants with neonatal encephalopathy in a trial of cooling initiated at 6-24 hours. Study design: Subgroup analysis of infants \u226536 weeks of gestation with moderate-severe neonatal encephalopathy randomized at 6-24 postnatal hours to hypothermia or usual care in a multicenter trial of late hypothermia. MRI scans were performed per each center's practice and interpreted by 2 central readers using the Eunice Kennedy Shriver National Institute of Child Health and Human Development injury score (6 levels, normal to hemispheric devastation). Neurodevelopmental outcomes were assessed at 18-22 months of age. Results: Of 168 enrollees, 128 had an interpretable MRI and were seen in follow-up (n = 119) or died (n = 9). MRI findings were predominantly acute injury and did not differ by cooling treatment. At 18-22 months, death or severe disability occurred in 20.3%. No infant had moderate disability. Agreement between central readers was moderate (weighted kappa 0.56, 95% CI 0.45-0.67). The adjusted odds of death or severe disability increased 3.7-fold (95% CI 1.8-7.9) for each increment of injury score. The area under the curve for severe MRI patterns to predict death or severe disability was 0.77 and the positive and negative predictive values were 36% and 100%, respectively. Conclusions: MRI injury scores were associated with neurodevelopmental outcome at 18-22 months among infants in the Late Hypothermia Trial. However, the results suggest caution when using qualitative interpretations of MRI images to provide prognostic information to families following perinatal hypoxia-ischemia."
    ],
    "b_categories":[
      "Pediatrics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "What is being transferred in transfer learning?"
    ],
    "c_abstract":[
      "One desired capability for machines is the ability to transfer their knowledge of one domain another where data (usually) scarce. Despite ample adaptation learning in various deep applications, we yet do not understand what enables a successful and which part network responsible that. In this paper, provide new tools analyses address these fundamental questions. Through series on transferring block-shuffled images, separate effect feature reuse from low-level statistics show that some benefit comes latter. We present when training pre-trained weights, model stays same basin loss landscape different instances such are similar space close parameter space."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.19345,
    "date":null,
    "a_title":"3D Wasserstein generative adversarial network with dense U-Net based\n  discriminator for preclinical fMRI denoising",
    "a_abstract":"Functional magnetic resonance imaging (fMRI) is extensively used in clinical\nand preclinical settings to study brain function, however, fMRI data is\ninherently noisy due to physiological processes, hardware, and external noise.\nDenoising is one of the main preprocessing steps in any fMRI analysis pipeline.\nThis process is challenging in preclinical data in comparison to clinical data\ndue to variations in brain geometry, image resolution, and low signal-to-noise\nratios. In this paper, we propose a structure-preserved algorithm based on a 3D\nWasserstein generative adversarial network with a 3D dense U-net based\ndiscriminator called, 3D U-WGAN. We apply a 4D data configuration to\neffectively denoise temporal and spatial information in analyzing preclinical\nfMRI data. GAN-based denoising methods often utilize a discriminator to\nidentify significant differences between denoised and noise-free images,\nfocusing on global or local features. To refine the fMRI denoising model, our\nmethod employs a 3D dense U-Net discriminator to learn both global and local\ndistinctions. To tackle potential over-smoothing, we introduce an adversarial\nloss and enhance perceptual similarity by measuring feature space distances.\nExperiments illustrate that 3D U-WGAN significantly improves image quality in\nresting-state and task preclinical fMRI data, enhancing signal-to-noise ratio\nwithout introducing excessive structural changes in existing methods. The\nproposed method outperforms state-of-the-art methods when applied to simulated\nand real data in a fMRI analysis pipeline.",
    "explanation":"Denoising is one of the main preprocessing steps in any fMRI analysis pipeline. In this\npaper, we propose a structure-preserved algorithm based on a 3D Wasserstein\ngenerative adversarial network with a 3D dense U-net based discriminator called,\n3D U-WGAN. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "On the use of preclinical imaging to explore the principles of brain function in rodent models and their relevance for illnesses of the human mind"
    ],
    "b_abstract":[
      "Dear Editor, We recently published in Translational Psychiatry an article that examine the strategies for evaluating brain function at the wholebrain level [1]. In this review, we covered several methods, from functional MRI to functional ultrasound to calcium imaging. For each technique, we wrote a brief history of its development, the physical notion, some key applications, its potentials, and its limitations. We concluded that methods for imaging the rodent brain at the network level are growing and will advance our understanding of brain function. A commentary by Zhuo and colleagues further enhances the complexity of addressing the issue of \u201ctranslation\u201d from animal models to patients for the discipline of psychiatry [2]. They propose that the approaches employed to develop an animal model for a psychiatric disease need to be thoroughly scrutinized and, perhaps, revised. For example, most rodent models of mental diseases are to-date established using a simple pharmacological infusion [3] and\/or psychosocial stimulation [4]. The key concern posed, however, is how these manipulations change the brain\u2019s structure and function, and whether these models genuinely reflect the pathophysiology of human mental illnesses. Especially since it is difficult to evaluate whether one can speak of inverse inference from rodents to humans. This is a true and acceptable statement. However, this is exactly what preclinical imaging aims to deliver. By mapping the dynamic responses of brain networks in animal models and compare them, if possible, with those reported in clinical studies, we can obtain quantitative data and parameters to establish whether our models are effectively translational [5]. If these metrics demonstrate temporal and spatial similarity in network-level modifications as those observed in humans, we can pursue further inquiry utilizing more intrusive and more specific methods for brain recordings in animal models. Otherwise, we must have the confidence and the correctness to move forward and attempt other solutions. Two recent examples. In 2019 we established a causal association between activity of the noradrenergic nucleus locus coeruleus (LC) and the engagement of numerous large-scale brain networks in mice, in particular of the salience and amygdala networks [6]. In addition, we could link network-changes with direct markers of norepinephrine (NE) turnover and with the distribution of NE receptors over the entire brain. The hypothesis that specific brain networks dynamics are related to LC activity and to NE receptor density derives from stress-research and pharmacological studies in humans [7, 8]. However, since it is impossible to selectively stimulate LC in people, it has remained a hypothesis for more than a decade. Our preclinical work helped confirm this causal relationship and this has direct implications for interpreting the results of clinical imaging studies on stress and anxiety behavior. More recently, the Gozzi lab described how chronic local neuronal suppression via overexpression of a potassium channel or acute silencing via chemogenetics result in a paradoxical hyperconnectivity [9]; an intriguing finding often reported in humans after stroke [10] and in early stages of Alzheimer\u2019s disease [11], but never truly understood. Using in vivo electrophysiology, they showed local inhibition improves low frequency (0.1\u20134 Hz) oscillatory power via suppression of neuronal activity not phaselocked to slow rhythms, resulting in increased slow and \u03b4 band coherence between areas that display fMRI overconnectivity. These data present causal evidence that cortical inactivation can counterintuitively augment fMRI connectivity via greater, lesslocalized slow oscillatory processes. Once again, this could be only achieved by combining functional MRI and electrophysiology with neuromodulation in animal models. These and other examples give a peek of what the future of preclinical imaging might look like: a field of research capable of delivering causal explanations to the hypotheses presented by human neuroscience, neurology and psychiatry. Lastly, I would argue against statements like \u201cthe computational complexity of human brains is billions of times that of mouse brain\u201d. While this may be true from a numerical standpoint of mere neuronal counts, preclinical neuroimaging\u2019s objective should not be per se to map every single neuron in real time but of identifying the general neural and cellular principles governing the assembly of brain networks and its breakdown in brain disorders. The field is relatively new but is moving fast and has already produced some important insights. The future is challenging and will require time, devotion and an optimal synergy between engineering, chemistry, biology, and computer science. If the community will be patient and supportive enough, there will be further important discoveries in the future."
    ],
    "b_categories":[
      "Psychiatry"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "GAN\uff08Generative Adversarial Nets\uff09"
    ],
    "c_abstract":[
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal \u00bd everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18784,
    "date":null,
    "a_title":"MRI Breast tissue segmentation using nnU-Net for biomechanical modeling",
    "a_abstract":"Integrating 2D mammography with 3D magnetic resonance imaging (MRI) is\ncrucial for improving breast cancer diagnosis and treatment planning. However,\nthis integration is challenging due to differences in imaging modalities and\nthe need for precise tissue segmentation and alignment. This paper addresses\nthese challenges by enhancing biomechanical breast models in two main aspects:\nimproving tissue identification using nnU-Net segmentation models and\nevaluating finite element (FE) biomechanical solvers, specifically comparing\nNiftySim and FEBio. We performed a detailed six-class segmentation of breast\nMRI data using the nnU-Net architecture, achieving Dice Coefficients of 0.94\nfor fat, 0.88 for glandular tissue, and 0.87 for pectoral muscle. The overall\nforeground segmentation reached a mean Dice Coefficient of 0.83 through an\nensemble of 2D and 3D U-Net configurations, providing a solid foundation for 3D\nreconstruction and biomechanical modeling. The segmented data was then used to\ngenerate detailed 3D meshes and develop biomechanical models using NiftySim and\nFEBio, which simulate breast tissue's physical behaviors under compression. Our\nresults include a comparison between NiftySim and FEBio, providing insights\ninto the accuracy and reliability of these simulations in studying breast\ntissue responses under compression. The findings of this study have the\npotential to improve the integration of 2D and 3D imaging modalities, thereby\nenhancing diagnostic accuracy and treatment planning for breast cancer.",
    "explanation":"Integrating 2D mammography with 3D magnetic resonance\nimaging (MRI) is crucial for improving breast cancer diagnosis and treat-\nment planning. However, this integration is challenging due to differences\nin imaging modalities and the need for precise tissue segmentation and\nalignment. This paper addresses these challenges by enhancing biome-\nchanical breast models in two main aspects: improving tissue identifica-\ntion using nnU-Net segmentation models and evaluating finite element\n(FE) biomechanical solvers, specifically comparing NiftySim and FEBio.\u00a0",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Multimodal Breast Parenchymal Patterns Correlation Using a Patient-Specific Biomechanical Model"
    ],
    "c_abstract":[
      "In this paper, we aim to produce a realistic 2-D projection of the breast parenchymal distribution from a 3-D breast magnetic resonance image (MRI). To evaluate the accuracy of our simulation, we compare our results with the local breast density (i.e., density map) obtained from the complementary full-field digital mammogram. To achieve this goal, we have developed a fully automatic framework, which registers MRI volumes to X-ray mammograms using a subject-specific biomechanical model of the breast. The optimization step modifies the position, orientation, and elastic parameters of the breast model to perform the alignment between the images. When the model reaches an optimal solution, the MRI glandular tissue is projected and compared with the one obtained from the corresponding mammograms. To reduce the loss of information during the ray-casting, we introduce a new approach that avoids resampling the MRI volume. In the results, we focus our efforts on evaluating the agreement of the distributions of glandular tissue, the degree of structural similarity, and the correlation between the real and synthetic density maps. Our approach obtained a high-structural agreement regardless the glandularity of the breast, whilst the similarity of the glandular tissue distributions and correlation between both images increase in denser breasts. Furthermore, the synthetic images show continuity with respect to large structures in the density maps."
    ],
    "c_categories":[
      "Imaging"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00663,
    "date":null,
    "a_title":"Deep Learning for Longitudinal Gross Tumor Volume Segmentation in\n  MRI-Guided Adaptive Radiotherapy for Head and Neck Cancer",
    "a_abstract":"Accurate segmentation of gross tumor volume (GTV) is essential for effective\nMRI-guided adaptive radiotherapy (MRgART) in head and neck cancer. However,\nmanual segmentation of the GTV over the course of therapy is time-consuming and\nprone to interobserver variability. Deep learning (DL) has the potential to\novercome these challenges by automatically delineating GTVs. In this study, our\nteam, $\\textit{UW LAIR}$, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume\nsegmentation. To this end, we developed a series of DL models for longitudinal\nGTV segmentation. The backbone of our models for both tasks was SegResNet with\ndeep supervision. For Task 1, we trained the model using a combined dataset of\npre-RT and mid-RT MRI data, which resulted in the improved aggregated Dice\nsimilarity coefficient (DSCagg) on an internal testing set compared to models\ntrained solely on pre-RT MRI data. In Task 2, we introduced mask-aware\nattention modules, enabling pre-RT GTV masks to influence intermediate features\nlearned from mid-RT data. This attention-based approach yielded slight\nimprovements over the baseline method, which concatenated mid-RT MRI with\npre-RT GTV masks as input. In the final testing phase, the ensemble of 10\npre-RT segmentation models achieved an average DSCagg of 0.794, with 0.745 for\nprimary GTV (GTVp) and 0.844 for metastatic lymph nodes (GTVn) in Task 1. For\nTask 2, the ensemble of 10 mid-RT segmentation models attained an average\nDSCagg of 0.733, with 0.607 for GTVp and 0.859 for GTVn, leading us to\n$\\textbf{achieve 1st place}$. In summary, we presented a collection of DL\nmodels that could facilitate GTV segmentation in MRgART, offering the potential\nto streamline radiation oncology workflows. Our code and model weights are\navailable at https:\/\/github.com\/xtie97\/HNTS-MRG24-UWLAIR.",
    "explanation":"In this study, our team, UW LAIR, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume seg-\nmentation. To this end, we developed a series of DL models for longitudinal GTV\nsegmentation",
    "b_id":[
      "b4",
      "b2"
    ],
    "b_title":[
      "Deep Learning for Automatic Gross Tumor Volumes Contouring in Esophageal Cancer Based on Contrast-Enhanced Computed Tomography Images: A Multi-Institutional Study",
      "ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of Pneumothorax"
    ],
    "b_abstract":[
      "Purpose To develop and externally validate an automatic artificial intelligence (AI) tool for delineating gross tumor volume (GTV) in patients with esophageal squamous cell carcinoma (ESCC), which can assist in neo-adjuvant or radical radiation therapy treatment planning. Methods and Materials In this multi-institutional study, contrast-enhanced CT images from 580 eligible ESCC patients were retrospectively collected. The GTV contours delineated by 2 experts via consensus were used as ground truth. A 3-dimensional deep learning model was developed for GTV contouring in the training cohort and internally and externally validated in 3 validation cohorts. The AI tool was compared against 12 board-certified experts in 25 patients randomly selected from the external validation cohort to evaluate its assistance in improving contouring performance and reducing variation. Contouring performance was measured using dice similarity coefficient (DSC) and average surface distance. Additionally, our previously established radiomics model for predicting pathologic complete response was used to compare AI-generated and ground truth contours, to assess the potential of the AI contouring tool in radiomics analysis. Results The AI tool demonstrated good GTV contouring performance in multicenter validation cohorts, with median DSC values of 0.865, 0.876, and 0.866 and median average surface distance values of 0.939, 0.789, and 0.875 mm, respectively. Furthermore, the AI tool significantly improved contouring performance for half of 12 board-certified experts (DSC values, 0.794-0.835 vs 0.856-0.881, P = .003-0.048), reduced the intra- and interobserver variations by 37.4% and 55.2%, respectively, and saved contouring time by 77.6%. In the radiomics analysis, 88.7% of radiomic features from ground truth and AI-generated contours demonstrated stable reproducibility, and similar pathologic complete response prediction performance for these contours (P = .430) was observed. Conclusions Our AI contouring tool can improve GTV contouring performance and facilitate radiomics analysis in ESCC patients, which indicates its potential for GTV contouring during radiation therapy treatment planning and radiomics studies.",
      "Radiology narrative reports often describe characteristics of a patient's disease, including its location, size, and shape. Motivated by the recent success multimodal learning, we hypothesized that this descriptive text could guide medical image analysis algorithms. We proposed novel vision-language model, ConTEXTual Net, for task pneumothorax segmentation on chest radiographs. Net extracts language features from physician-generated free-form radiology using pre-trained model. then introduced cross-attention between intermediate embeddings an encoder-decoder convolutional neural network to enable guidance analysis. was trained CANDID-PTX dataset consisting 3196 positive cases with annotations 6 different physicians as well clinical reports. Using cross-validation, achieved Dice score 0.716\u00b10.016, which similar degree inter-reader variability (0.712\u00b10.044) computed subset data. It outperformed vision-only models (Swin UNETR: 0.670\u00b10.015, ResNet50 U-Net: 0.677\u00b10.015, GLoRIA: 0.686\u00b10.014, nnUNet 0.694\u00b10.016) competing model (LAVT: 0.706\u00b10.009). Ablation studies confirmed it information led performance gains. Additionally, show certain augmentation methods degraded Net's breaking image-text concordance. also evaluated effects activation functions in module, highlighting efficacy our chosen architectural design."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "MRI-Guided Adaptive Radiation Therapy"
    ],
    "c_abstract":[
      "Magnetic resonance imaging-guided radiation therapy (MRIgRT) has improved soft tissue contrast over computed tomography (CT) based image-guided RT. Superior visualization of the target and surrounding radiosensitive structures has the potential to improve oncological outcomes partly due to safer dose-escalation and adaptive planning. In this review, we highlight the workflow of adaptive MRIgRT planning, which includes simulation imaging, daily MRI, identifying isocenter shifts, contouring, plan optimization, quality control, and delivery. Increased utilization of MRIgRT will depend on addressing technical limitations of this technology, while addressing treatment efficacy, cost-effectiveness, and workflow training."
    ],
    "c_categories":[
      "Oncology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18602,
    "date":null,
    "a_title":"Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for\n  Medical Image Analysis",
    "a_abstract":"Purpose: To explore best-practice approaches for generating synthetic chest\nX-ray images and augmenting medical imaging datasets to optimize the\nperformance of deep learning models in downstream tasks like classification and\nsegmentation. Materials and Methods: We utilized a latent diffusion model to\ncondition the generation of synthetic chest X-rays on text prompts and\/or\nsegmentation masks. We explored methods like using a proxy model and using\nradiologist feedback to improve the quality of synthetic data. These synthetic\nimages were then generated from relevant disease information or geometrically\ntransformed segmentation masks and added to ground truth training set images\nfrom the CheXpert, CANDID-PTX, SIIM, and RSNA Pneumonia datasets to measure\nimprovements in classification and segmentation model performance on the test\nsets. F1 and Dice scores were used to evaluate classification and segmentation\nrespectively. One-tailed t-tests with Bonferroni correction assessed the\nstatistical significance of performance improvements with synthetic data.\nResults: Across all experiments, the synthetic data we generated resulted in a\nmaximum mean classification F1 score improvement of 0.150453 (CI:\n0.099108-0.201798; P=0.0031) compared to using only real data. For\nsegmentation, the maximum Dice score improvement was 0.14575 (CI:\n0.108267-0.183233; P=0.0064). Conclusion: Best practices for generating\nsynthetic chest X-ray images for downstream tasks include conditioning on\nsingle-disease labels or geometrically transformed segmentation masks, as well\nas potentially using proxy modeling for fine-tuning such generations.",
    "explanation":"We utilized a latent diffusion model to condition the generation of synthetic chest X-rays on text prompts and\/or segmentation masks",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Rsna pneumonia detection challenge"
    ],
    "b_abstract":[
      "In this competition, you\u2019re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs. Here\u2019s the backstory and why solving this problem matters. Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country. While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis. CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift. To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA\u00ae) has reached out to Kaggle\u2019s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review. Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018."
    ],
    "b_categories":[
      "Imaging"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14",
      "b9"
    ],
    "c_title":[
      "Adding Conditional Control to Text-to-Image Diffusion Models",
      "Highresolution image synthesis with latent diffusion models"
    ],
    "c_abstract":[
      "We present ControlNet, a neural network architecture to add spatial conditioning controls large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large models, and reuses their deep robust encoding layers with billions of images as strong backbone learn diverse set conditional controls. The is connected \"zero convolutions\" (zero-initialized convolution layers) that progressively grow parameters from zero ensure no harmful noise could affect finetuning. test various controls, e.g., edges, depth, segmentation, human pose, etc., Stable Diffusion, using single or multiple conditions, without prompts. show training ControlNets small (<50k) (>1m) datasets. Extensive results may facilitate wider applications control image",
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18902,
    "date":null,
    "a_title":"MSEMG: Surface Electromyography Denoising with a Mamba-based Efficient\n  Network",
    "a_abstract":"Surface electromyography (sEMG) recordings can be contaminated by\nelectrocardiogram (ECG) signals when the monitored muscle is closed to the\nheart. Traditional signal-processing-based approaches, such as high-pass\nfiltering and template subtraction, have been used to remove ECG interference\nbut are often limited in their effectiveness. Recently, neural-network-based\nmethods have shown greater promise for sEMG denoising, but they still struggle\nto balance both efficiency and effectiveness. In this study, we introduce\nMSEMG, a novel system that integrates the Mamba State Space Model with a\nconvolutional neural network to serve as a lightweight sEMG denoising model. We\nevaluated MSEMG using sEMG data from the Non-Invasive Adaptive Prosthetics\ndatabase and ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The\nresults show that MSEMG outperforms existing methods, generating higher-quality\nsEMG signals with fewer parameters. The source code for MSEMG is available at\nhttps:\/\/github.com\/tonyliu0910\/MSEMG.",
    "explanation":"Surface electromyography (sEMG) recordings can\nbe contaminated by electrocardiogram (ECG) signals when the\nmonitored muscle is closed to the heart. In this study, we introduce MSEMG, a novel\nsystem that integrates the Mamba state space model with a\nconvolutional neural network to serve as a lightweight sEMG\ndenoising mode",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Biomechanics and motor control of human movement"
    ],
    "b_abstract":[
      "Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 its Relationship with Physiology Anatomy. 1.3 Scope of Textbook. 1.4 References. 2 Signal Processing. 2.0 2.1 Auto- Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging Repetitive Waveforms. 2.4 3 Kinematics. 3.0 Historical Development Complexity Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging 3.4 Processing Raw Data. 3.5 Calculation Other Variables. 3.6 Problems Based on 3.7 4 Anthropometry. 4.0 Anthropometry in Movement Biomechanics. 4.1 Density, Mass, Inertial Properties. 4.2 Experimental Measures. 4.3 Muscle 4.4 Anthropometric 4.5 5 Kinetics: Forces Moments Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers Plates. 5.3 Bone-on-Bone During Dynamic Conditions. 5.4 Kinetic 5.5 6 Mechanical Work, Energy, Power. 6.0 6.1 Efficiency. 6.2 Forms Energy Storage. 6.3 Internal External Work. 6.4 Power Balances at Joints Within Segments. 6.5 6.6 7 Three-Dimensional Kinematics Kinetics. 7.0 7.1 Axes Systems. 7.2 Marker Anatomical 7.3 Determination Segment Angular Velocities Accelerations. 7.4 Analysis Reaction Moments. 7.5 Suggested Further Reading. 7.6 8 Synthesis Human Movement-Forward Solutions. 8.0 8.1 Review Forward Solution 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 Torques. 8.5 Designation Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 9 Mechanics. 9.0 9.1 Force-Length Characteristics Muscles. 9.2 Force-Velocity Characteristics. 9.3 Modeling. 9.4 10 Kinesiological Electromyography. 10.0 10.1 Electrophysiology Contraction. 10.2 Recording Electromyogram. 10.3 Electromyogram,. 10.4 between Electromyogram 10.5 11 Synergies. 11.0 11.1 The Support Moment Synergy. 11.2 Medial\/Lateral Anterior\/Posterior Balance Standing. 11.3 during Walking. 11.4 APPENDICES. A. Kinematic, Kinetic, Figure A.1 Walking Trial-Marker Locations Mass Frame Rate Information. Table Coordinate Data (cm). A.2( a ) Filtered Kinematics-Rib Cage Greater Trochanter (Hip). b Kinematics-Femoral Lateral Epicondyle (Knee) Head Fibula. c Kinematics-Lateral Malleolus (Ankle) Heel. d Kinematics-Fifth Metatarsal Toe. A.3( Linear Kinematics-Foot. Kinematics-Leg. Kinematics-Thigh. Kinematics-1\/2 HAT. A.4 Relative Joint Kinematics-Ankle, Knee, Hip. A.5( Force-Ankle Knee. Force-Hip. A.6 Potential, Total Energies-Foot, Leg, Thigh, and1\/2 A.7 Generation\/Absorption Transfer-Ankle, B. Units Definitions Related Electromyographical Measurements. B.1 Base SI Units. B.2 Derived Index."
    ],
    "b_categories":[
      "Biomechanics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    ],
    "c_abstract":[
      "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution recurrent structured state space models (SSMs) have been developed to address Transformers' computational inefficiency long sequences, but they not performed well important modalities language. We identify that a key weakness is their inability perform content-based reasoning, make several improvements. First, simply letting SSM parameters be functions input addresses with discrete modalities, allowing model selectively propagate or forget information along sequence length dimension depending current token. Second, even though this change prevents use efficient convolutions, we design hardware-aware parallel algorithm mode. integrate these selective SSMs into simplified end-to-end neural network without MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) scaling length, performance improves real data up million-length sequences. As general backbone, achieves state-of-the-art across language, audio, genomics. On language modeling, our Mamba-3B outperforms Transformers same size matches twice size, both pretraining downstream evaluation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03551,
    "date":null,
    "a_title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation",
    "a_abstract":"Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "explanation":"However, fibrosis appears\nas irregular, diffuse patterns with unclear boundaries, lead-\ning to high inter-observer variability and time-intensive man-\nual annotation. To tackle this challenge, we propose DiffSeg,\na novel weakly supervised semantic segmentation (WSSS)\nmethod that uses image-level annotations to generate pixel-\nlevel fibrosis segmentation, reducing the need for fine-grained\nmanual labeling. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Interobserver Variability in the CT Assessment of Honeycombing in the Lungs"
    ],
    "b_abstract":[
      "To quantify observer agreement and analyze causes of disagreement in identifying honeycombing at chest computed tomography (CT).The institutional review board approved this multiinstitutional HIPAA-compliant retrospective study, informed patient consent was not required. Five core study members scored 80 CT images with a five-point scale (5 = definitely yes to 1 no) establish reference standard for the identification honeycombing. Forty-three observers from various subspecialties geographic regions by using same scoring system. Weighted \u03ba values scores compared were analyzed investigate intergroup differences. Images divided into four groups allow analysis imaging features cases which there disagreement: on presence honeycombing, absence other (none preceding three applied).Agreement 43 moderate (Cohen weighted values: 0.40-0.58). There no significant differences among defined either subspecialty or region (Tukey-Kramer test, P .38 >.99). In 29% cases, These included mixed traction bronchiectasis, large cysts, superimposed pulmonary emphysema.Identification is subjective, largely caused conditions that mimic"
    ],
    "b_categories":[
      "Radiology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation"
    ],
    "c_abstract":[
      "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.09469,
    "date":null,
    "a_title":"An Explainable Attention Model for Cervical Precancer Risk\n  Classification using Colposcopic Images",
    "a_abstract":"Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease.",
    "explanation":"This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-\nAID-Net model based on patients colposcopy images. The model comprises a Convolutional Block\nAttention Module (CBAM) and convolutional layers that extract interpretable and representative\nfeatures of colposcopic images to distinguish high-risk and low-risk cervical precancer. ",
    "b_id":[
      "b36"
    ],
    "b_title":[
      "CBAM: Convolutional block attention module"
    ],
    "b_abstract":[
      "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "The accuracy of colposcopic biopsy: Analyses from the placebo arm of the Gardasil clinical trials"
    ],
    "c_abstract":[
      "We evaluated the overall agreement between colposcopically directed biopsies and definitive excisional specimens within context of three clinical trials. A total 737 women aged 16-45 who had a cervical biopsy taken 6 months before their therapy were included. Per-protocol, colposcopists to also obtain representative immediately therapy. Using adjudicated histological diagnoses, initial same day correlated with surgically excised specimens. The therapy, diagnoses was 42% (weighted kappa = 0.34) (95% CI: 0.29-0.39). underestimation intraepithelial neoplasia grade 2\/3 or adenocarcinoma in situ (CIN2-3\/AIS) CIN3\/AIS 26 42%, respectively. When allowing for one degree variance correlation, 92% CIN2-3\/AIS. specimen 56% 0.41) 0.36-0.47), CIN2-3\/AIS 57%. There significant associations when patients stratified by age, number biopsies, lesion size, presence human papillomavirus (HPV)16\/18 region. Of 178 diagnostic endocervical curettages performed, 14 (7.9%) found any HPV disease. Colposcopic accuracy improved CIN2 grouped as single predictive measure high-grade Colposcopy functioned well allowed one-degree difference surgical histologic interpretations, done practice. Taking more than colposcopic could improve patient management."
    ],
    "c_categories":[
      "Clinical Trial"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.14752,
    "date":null,
    "a_title":"Comparative Analysis of nnUNet and MedNeXt for Head and Neck Tumor\n  Segmentation in MRI-guided Radiotherapy",
    "a_abstract":"Radiation therapy (RT) is essential in treating head and neck cancer (HNC),\nwith magnetic resonance imaging(MRI)-guided RT offering superior soft tissue\ncontrast and functional imaging. However, manual tumor segmentation is\ntime-consuming and complex, and therfore remains a challenge. In this study, we\npresent our solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI\nimages. We utilized the HNTS-MRG2024 dataset, which consists of 150 MRI scans\nfrom patients diagnosed with HNC, including original and registered pre-RT and\nmid-RT T2-weighted images with corresponding segmentation masks for GTVp and\nGTVn. We employed two state-of-the-art models in deep learning, nnUNet and\nMedNeXt. For Task 1, we pretrained models on pre-RT registered and mid-RT\nimages, followed by fine-tuning on original pre-RT images. For Task 2, we\ncombined registered pre-RT images, registered pre-RT segmentation masks, and\nmid-RT data as a multi-channel input for training. Our solution for Task 1\nachieved 1st place in the final test phase with an aggregated Dice Similarity\nCoefficient of 0.8254, and our solution for Task 2 ranked 8th with a score of\n0.7005. The proposed solution is publicly available at Github Repository.",
    "explanation":"Radiation therapy (RT) is essential in treating head and neck cancer\n(HNC), with magnetic resonance imaging(MRI)-guided RT offering superior soft tis-\nsue contrast and functional imaging. However, manual tumor segmentation is time-\nconsuming and complex, and therfore remains a challenge. In this study, we present\nour solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI im-\nages. We employed two state-of-the-art models in deep learning, nnUNet and MedNeXt.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "\u201cApr\u00e8s Mois, Le D\u00e9luge\u201d: Preparing for the Coming Data Flood in the MRI-Guided Radiotherapy Era"
    ],
    "b_abstract":[
      "Magnetic resonance imaging provides a sea of quantitative and semi-quantitative data. While radiation oncologists already navigate pool clinical (semantic) data, the tide will swell with advent hybrid MRI\/linear accelerator devices increasing interest in MRI-guided radiotherapy (MRIgRT), including adaptive MRIgRT. The variety MR sequences (of greater complexity than single parameter Hounsfield unit CT scanning routinely used radiotherapy), workflow fractionation, sheer quantity daily images acquired are challenges for scaling this technology. Biomedical informatics, which is science information biomedicine, can provide helpful insights looming transition. Funneling MRIgRT data into clinically meaningful streams requires committing to flow inter-institutional accessibility interoperability initiatives, standardizing dosimetry methods, streamlining linear workflow, MRI acquisition post-processing, current topic review attempt conceptually ford using informatics approaches as theoretical bridge."
    ],
    "b_categories":[
      "Oncology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https:\/\/github.com\/MIC-DKFZ\/MedNeXt.",
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06785,
    "date":null,
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "c_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT. Code at \\url{https:\/\/github.com\/Ma-Lab-Berkeley\/CRATE}."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  }
]